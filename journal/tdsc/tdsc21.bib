@article{DBLP:journals/tdsc/LiGAKST24,
	author = {Yi{-}Fan Li and
                  Yang Gao and
                  Gbadebo Ayoade and
                  Latifur Khan and
                  Anoop Singhal and
                  Bhavani Thuraisingham},
	title = {Heterogeneous Domain Adaptation for Multistream Classification on
                  Cyber Threat Data},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {1--11},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3181682},
	doi = {10.1109/TDSC.2022.3181682},
	timestamp = {Sun, 21 Jul 2024 18:16:56 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiGAKST24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Under a newly introduced setting of multistream classification, two data streams are involved, which are referred to as source and target streams. The source stream continuously generates data instances from a certain domain with labels, while the target stream does the same task without labels from another domain. Existing approaches assume that domains for both data streams are identical, which is not quite true, since data streams from different sources may contain distinct features. Indeed, they may even have different numbers of features. Furthermore, obtaining labels for every instance in a data stream is often expensive and time-consuming. Therefore, it has become an important topic to explore if classes of labeled instances from other related streams are helpful to predict the classes of unlabeled instances in a different stream. Note that domains of source and target streams may have distinct feature spaces and data distributions. Our objective is to predict class labels of data instances in the target stream by using the classifiers trained by the source stream. We propose a framework of multistream classification by using projected data from a common latent feature space, which is embedded from both source and target domains. This framework is also crucial for enterprise system defenders to detect cross-platform attacks, such as Advanced Persistent Threats (APTs). Empirical valuation and analysis on both real-world and synthetic datasets are performed to validate the effectiveness of our proposed algorithm, comparing to state-of-the-art techniques. Experimental results show that our approach significantly outperforms other existing approaches.}
}


@article{DBLP:journals/tdsc/ZhouAAAA24,
	author = {Xugui Zhou and
                  Bulbul Ahmed and
                  James H. Aylor and
                  Philip Asare and
                  Homa Alemzadeh},
	title = {Hybrid Knowledge and Data Driven Synthesis of Runtime Monitors for
                  Cyber-Physical Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {12--30},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3242653},
	doi = {10.1109/TDSC.2023.3242653},
	timestamp = {Sat, 10 Feb 2024 18:05:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhouAAAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in sensing and computing technology have led to the proliferation of Cyber-Physical Systems (CPS) in safety-critical domains. However, the increasing device complexity, shrinking technology sizes, and shorter time to market have resulted in significant challenges in ensuring the reliability, safety, and security of CPS. This article presents a hybrid knowledge and data-driven approach for designing run-time context-aware safety monitors that can detect early signs of hazards and mitigate them in CPS. We propose a framework for formal specification of unsafe system context using Signal Temporal Logic (STL) combined with two optimization approaches for scenario-specific refinement and integration of STL specifications using data collected from closed-loop CPS simulations. We demonstrate the effectiveness of our approach in simulation using an autonomous driving system (ADS) and two closed-loop artificial pancreas systems (APS) as well as a publicly-available clinical trial dataset. The results show that a safety monitor developed with the proposed approaches demonstrates up to 4.7 times increase in average prediction accuracy (F1 score) over several well-designed baseline monitors while reducing both false-positive and false-negative rates in most scenarios.}
}


@article{DBLP:journals/tdsc/ChengWHBLLR24,
	author = {Peng Cheng and
                  Yuexin Wu and
                  Yuan Hong and
                  Zhongjie Ba and
                  Feng Lin and
                  Li Lu and
                  Kui Ren},
	title = {UniAP: Protecting Speech Privacy With Non-Targeted Universal Adversarial
                  Perturbations},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {31--46},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3242292},
	doi = {10.1109/TDSC.2023.3242292},
	timestamp = {Fri, 21 Feb 2025 08:48:13 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ChengWHBLLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ubiquitous microphones on smart devices considerably raise users’ concerns about speech privacy. Since the microphones are primarily controlled by hardware/software developers, profit-driven organizations can easily collect and analyze individuals’ daily conversations on a large scale with deep learning models, and users have no means to stop such privacy-violating behavior. In this article, we propose UniAP to empower users with the capability of protecting their speech privacy from the large-scale analysis without affecting their routine voice activities. Based on our observation of the recognition model, we utilize adversarial learning to generate quasi-imperceptible perturbations to disturb speech signals captured by nearby microphones, thus obfuscating the recognition results of recordings into meaningless contents. As validated in experiments, our perturbations can protect user privacy regardless of what users speak and when they speak. The jamming performance stability is further improved by training optimization. Additionally, the perturbations are robust against noise removal techniques. Extensive evaluations show that our perturbations achieve successful jamming rates of more than 87% in the digital domain and at least 90% and 70% for common and challenging settings, respectively, in the real-life chatting scenario. Moreover, our perturbations, solely trained on DeepSpeech, exhibit good transferability over other models based on similar architecture.}
}


@article{DBLP:journals/tdsc/DolevGNW24,
	author = {Shlomi Dolev and
                  Bingyong Guo and
                  Jianyu Niu and
                  Ziyu Wang},
	title = {SodsBC: {A} Post-Quantum by Design Asynchronous Blockchain Framework},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {47--62},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3243588},
	doi = {10.1109/TDSC.2023.3243588},
	timestamp = {Sat, 10 Feb 2024 18:05:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/DolevGNW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a new framework for asynchronous permissioned blockchain with high performance and post-quantum security. The framework contains two quantum-secure asynchronous Byzantine fault tolerance (aBFT) protocols, SodsBC and SodsBC++. We leverage concurrent preprocessing to accelerate the preparation of three cryptographic objects for the repeated consensus procedure, including common random coins as the needed randomness, secret shares of symmetric encryption keys for censorship resilience, and nested hash values for external validation predicates. The key idea behind our design is that the concurrent preprocessing mechanism can be well-supported by the consensus process of blockchains. The consumed objects in a block have been generated and globally agreed upon in a previous block. All our preprocessed objects utilize proven or commonly believed to be post-quantum cryptographic tools to resist an adversary equipped with quantum computation capabilities. We evaluate our protocols and their competitors in AWS in a typical setting where, the number of participants is 100 and each block part has 20,000 transactions. The results show that SodsBC and SodsBC++ reduce the latency of two state-of-the-art but quantum-sensitive competitors Honeybadger and Dumbo by 53% and 6%, respectively.}
}


@article{DBLP:journals/tdsc/MeiXXYL24,
	author = {Lin Mei and
                  Chungen Xu and
                  Lei Xu and
                  Xingliang Yuan and
                  Joseph K. Liu},
	title = {Practical Multi-Source Multi-Client Searchable Encryption With Forward
                  Privacy: Refined Security Notion and New Constructions},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {63--77},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3245638},
	doi = {10.1109/TDSC.2023.3245638},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/MeiXXYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-source multi-client (M/M) searchable encryption has drawn increasing attention as data sharing becomes prevalent in the digital economics era. It allows data from multiple sources to be securely outsourced to third parties and queried by authorized clients. In response to these demands, various schemes sprung up in the last few years. However, empirical results show that they suffer from performance limitations. Specifically, they either require per-interaction in per-query between data sources and clients or time-consuming public-key encryption. To address these issues, we propose a searchable encryption scheme that allows authorized clients to efficiently search encrypted data from multiple sources. Compared to previous schemes, our design reduces the interaction overhead of authorization and query with the aid of a set-constrained pseudo-random function. Given practical considerations in the M/M setting, we further refine the forward privacy (FP) as “FP with client” and “FP with server” for data addition. To achieve these new security notions, we construct a new M/M scheme only with efficient symmetric cryptographic tools. We perform a formal security analysis of the proposed schemes and implement them to compare with prior arts. The theoretical and experimental results confirm that our designs are practical with lower communication and computation overhead.}
}


@article{DBLP:journals/tdsc/DidehbanSGSL24,
	author = {Moslem Didehban and
                  Hwisoo So and
                  Prudhvi Gali and
                  Aviral Shrivastava and
                  Kyoungwoo Lee},
	title = {Generic Soft Error Data and Control Flow Error Detection by Instruction
                  Duplication},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {78--92},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3245842},
	doi = {10.1109/TDSC.2023.3245842},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DidehbanSGSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transient faults or soft errors are considered one of the most daunting reliability challenges for microprocessors. Software solutions for soft error protection are attractive because they can provide flexible and effective error protection. For instance, nZDC (Didehban and Shrivastava 2016) state-of-the-art instruction duplication error protection scheme achieves a high degree of error detection by verifying the results of memory write operations and utilizes an effective control-flow checking mechanism. However, nZDC control-flow checking mechanism is architecture-dependent and suffers from some vulnerability holes. In this work, we address these issues by substituting nZDC control-flow checking mechanism with a general (ISA-independent) scheme and propose two transformations, coarse-grained scheduling, and asymmetric control-flow signatures, for hard-to-detect control flow errors. Fault injection experiments on different hardware components of synthesizable Verilog description of an OpenRISC-based microprocessor reveal that the proposed transformation shows 85% less silent data corruptions compared to nZDC. In addition, programs protected by the proposed scheme run on average around 37% faster than nZDC-protected programs.}
}


@article{DBLP:journals/tdsc/LiuLCWZMX24,
	author = {Ziqin Liu and
                  Zhenpeng Lin and
                  Yueqi Chen and
                  Yuhang Wu and
                  Yalong Zou and
                  Dongliang Mu and
                  Xinyu Xing},
	title = {Towards Unveiling Exploitation Potential With Multiple Error Behaviors
                  for Kernel Bugs},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {93--109},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3246170},
	doi = {10.1109/TDSC.2023.3246170},
	timestamp = {Mon, 27 Jan 2025 17:42:28 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuLCWZMX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, fuzz testing has significantly expedited the vulnerability discovery of Linux kernel. Security analysts use the manifested error behaviors to infer the exploitability of one bug and thus prioritize the patch development. However, only using an error behavior in the report, security analysts might underestimate the exploitability of the kernel bug because it could manifest various error behaviors indicating different exploitation potentials. In this work, we conduct an empirical study on multiple error behaviors of kernel bugs to understand 1) the prevalence of multiple error behaviors and the possible impact of multiple error behaviors towards the exploitation potential; 2) the factors that manifest multiple error behaviors with different exploitation potential. We collected all the fixed kernel bugs reported on Syzbot from September 2017 to January 2022, including 3,352 bug reports. We observed that multiple error behaviors manifested by kernel bugs are prevalent in the real world, and more error behaviors help unveil the exploitability of kernel bugs. Then we organized Linux kernel experts to analyze a sample of kernel bug dataset (484 bug reports, unique 162 bugs) and identified 6 key contributing factors to the mutiple error behaviors. Finally, based on the empirical findings, we propose an object-driven fuzzing technique to explore all possible error behaviors that a kernel bug might bring about. To evaluate the utility of our proposed technique, we implement our fuzzing tool GREBE and apply it to 60 real-world Linux kernel bugs. On average, GREBE could manifest 2+ additional error behaviors for each of the kernel bugs. For 26 kernel bugs, GREBE discovers higher exploitation potential. We report to kernel vendors some of the bugs – the exploitability of which was wrongly assessed and the corresponding patch has not yet been carefully applied – resulting in their rapid patch adoption.}
}


@article{DBLP:journals/tdsc/LiuYWWL24,
	author = {Gao Liu and
                  Zheng Yan and
                  Dongliang Wang and
                  Haiguang Wang and
                  Tieyan Li},
	title = {DePTVM: Decentralized Pseudonym and Trust Value Management for Integrated
                  Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {110--124},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3246799},
	doi = {10.1109/TDSC.2023.3246799},
	timestamp = {Mon, 03 Mar 2025 22:24:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuYWWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Evaluating and sharing user equipment (UE) trust across multiple network domains can greatly support security and trust management of future integrated heterogeneous networks. But the dilemma between identity privacy preservation and trust evaluation efficacy causes a big challenge in pseudonym and trust value management. Most existing approaches either rely on a trusted third party (TTP) and non-collusive parties, or deploy trusted execution environments (TEEs). They cannot be applied directly into a trustless heterogeneous network environment, where network domains do not trust with each other and it is hard to setup a fully trusted party. In this article, we propose DePTVM, a decentralized pseudonym and trust value management scheme for integrated heterogeneous networks, where different network operators jointly maintain a list of < pseudonym, trust value> pairs by employing verifiable shuffling and trust obfuscation based on blockchain in order to support anonymous trust evaluation and ensure pseudonym unlinkability. We analyze DePTVM with respect to correctness, unforgeability, anonymity and unlinkability, and evaluate its performance through simulations. Experimental results show that trust synchronization can be achieved across domains within 9 seconds with our experimental settings and the time taken by the most complex operation (i.e., verifiable shuffling) of operator agent increases linearly with the scale of maintained list. Analysis and experimental results imply DePTVM's potential in practical applications.}
}


@article{DBLP:journals/tdsc/LiZSLJW24,
	author = {Ruixuan Li and
                  Zhenyong Zhang and
                  Jun Shao and
                  Rongxing Lu and
                  Xiaoqi Jia and
                  Guiyi Wei},
	title = {The Potential Harm of Email Delivery: Investigating the {HTTPS} Configurations
                  of Webmail Services},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {125--138},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3246600},
	doi = {10.1109/TDSC.2023.3246600},
	timestamp = {Sat, 10 Feb 2024 18:05:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiZSLJW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Webmail, protected by the HTTPS protocol, only works correctly if both the server and client implement HTTPS-related features without vulnerability. Nevertheless, the deployment situation of these features in the webmail world is still unclear. To this end, we perform the first end-to-end and large-scale measurement of webmail service. For the server side, we first build an email address set with a size of 2.2 billion. Then we construct two webmail domain datasets: one contains 21 k domains filtered from the email address set; the other only includes 34 domains but supports more than 75% of the 2.2 billion email addresses. After performing a comprehensive measurement on these two webmail domain datasets, we find that some features are poorly deployed. Furthermore, we also rank servers by analyzing the properties of HTTPS-related features. For the client side, we investigate implement of HTTPS-related features in 50 different combinations of web browsers and operating systems (OSes). We find that even the latest browsers have poor support for some features. For example, Firefox in all OSes does not support CT. Our findings highlight that the full deployment of the security features for the HTTPS ecosystem is still a challenge, even in the webmail service.}
}


@article{DBLP:journals/tdsc/YangWYFZ24,
	author = {Tianyu Yang and
                  Hanzhou Wu and
                  Biao Yi and
                  Guorui Feng and
                  Xinpeng Zhang},
	title = {Semantic-Preserving Linguistic Steganography by Pivot Translation
                  and Semantic-Aware Bins Coding},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {139--152},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3247493},
	doi = {10.1109/TDSC.2023.3247493},
	timestamp = {Sat, 10 Feb 2024 18:05:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/YangWYFZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Linguistic steganography (LS) aims to embed secret information into a highly encoded text for covert communication. It can be roughly divided to two main categories, i.e., modification based LS (MLS) and generation based LS (GLS). MLS embeds secret data by slightly modifying a given text without impairing the meaning of the text, whereas GLS uses a well trained language model to directly generate a text carrying secret data. A common disadvantage for MLS methods is that the embedding payload is very small, whose return is well preserving the semantic quality of the text. In contrast, GLS enables the data hider to embed a large payload, which has to pay the high price of uncontrollable semantics. In this article, we propose a novel LS method to modify a given text by pivoting it between two different languages and embed secret data using a semantic-aware information encoding strategy. Our purpose is to alter the expression of the given text, enabling a large payload to be embedded while keeping the semantic information unchanged. Experiments have shown that the proposed work not only achieves a large embedding payload, but also shows superior performance in maintaining the semantic consistency and resisting linguistic steganalysis.}
}


@article{DBLP:journals/tdsc/YanLZWLZLL24,
	author = {Haonan Yan and
                  Xiaoguang Li and
                  Wenjing Zhang and
                  Rui Wang and
                  Hui Li and
                  Xingwen Zhao and
                  Fenghua Li and
                  Xiaodong Lin},
	title = {Automatic Evasion of Machine Learning-Based Network Intrusion Detection
                  Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {153--167},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3247585},
	doi = {10.1109/TDSC.2023.3247585},
	timestamp = {Wed, 07 Aug 2024 08:00:25 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YanLZWLZLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network intrusion detection systems (IDS) are often considered effective to thwart cyber attacks. Currently, state-of-the-art (SOTA) IDSs are mainly based on machine learning (ML) including deep learning (DL) models, which suffer from their own security issues, especially evasion attacks by using adversarial examples. However, previous studies mostly focus on extracted features rather than the traffic sample itself, and/or assume that the adversary knows the information of the target model more or less, which severely restricts attack feasibility in practice. In this paper, we re-investigate this problem in a more realistic label-only black-box scenario and propose a practical evasion attack strategy to solve the above limitations. In this newly considered case that the adversary morphs the traffic sample and only obtains the results accepted or rejected without other knowledge, we successfully leverage the model extraction and transfer attack to evade the detection. The entire attack strategy is automated and a comprehensive evaluation is performed. Final results show that the proposed strategy effectively evades seven typical ML-based IDSs and one SOTA DL-based IDS with an average success rate of over 75\\%. We also discuss the corresponding countermeasures against our attack, which finally highlight the need for effective defenses against our attack.}
}


@article{DBLP:journals/tdsc/LiCJZYLWPL24,
	author = {Yuwei Li and
                  Yuan Chen and
                  Shouling Ji and
                  Xuhong Zhang and
                  Guanglu Yan and
                  Alex X. Liu and
                  Chunming Wu and
                  Zulie Pan and
                  Peng Lin},
	title = {G-Fuzz: {A} Directed Fuzzing Framework for gVisor},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {168--185},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3244825},
	doi = {10.1109/TDSC.2023.3244825},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiCJZYLWPL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {gVisor is a Google-published application-level kernel for containers. As gVisor is lightweight and has sound isolation, it has been widely used in many IT enterprises [1], [2], [3]. When a new vulnerability of the upstream gVisor is found, it is important for the downstream developers to test the corresponding code to maintain the security. To achieve this aim, directed fuzzing is promising. Nevertheless, there are many challenges in applying existing directed fuzzing methods for gVisor. The core reason is that existing directed fuzzers are mainly for general C/C++ applications, while gVisor is an OS kernel written in the Go language. To address the above challenges, we propose G-Fuzz, a directed fuzzing framework for gVisor. There are three core methods in G-Fuzz, including lightweight and fine-grained distance calculation, target related syscall inference and utilization, and exploration and exploitation dynamic switch. Note that the methods of G-Fuzz are general and can be transferred to other OS kernels. We conduct extensive experiments to evaluate the performance of G-Fuzz. Compared to Syzkaller, the state-of-the-art kernel fuzzer, G-Fuzz outperforms it significantly. Furthermore, we have rigorously evaluated the importance for each core method of G-Fuzz. G-Fuzz has been deployed in industry and has detected multiple serious vulnerabilities.}
}


@article{DBLP:journals/tdsc/CamaraFAUZ24,
	author = {Xabier S{\'{a}}ez de C{\'{a}}mara and
                  Jose Luis Flores and
                  Crist{\'{o}}bal Arellano and
                  Aitor Urbieta and
                  Urko Zurutuza},
	title = {Gotham Testbed: {A} Reproducible IoT Testbed for Security Experiments
                  and Dataset Generation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {186--203},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3247166},
	doi = {10.1109/TDSC.2023.3247166},
	timestamp = {Fri, 08 Mar 2024 13:21:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/CamaraFAUZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing adoption of the Internet of Things (IoT) has brought a significant increase in attacks targeting those devices. Machine learning (ML) methods have shown promising results for intrusion detection; however, the scarcity of IoT datasets remains a limiting factor in developing ML-based security systems for IoT scenarios. Static datasets get outdated due to evolving IoT architectures and threat landscape; meanwhile, the testbeds used to generate them are rarely published. This article presents the Gotham testbed, a reproducible and flexible security testbed extendable to accommodate new emulated devices, services or attackers. Gotham is used to build an IoT scenario composed of 100 emulated devices communicating via MQTT, CoAP and RTSP protocols, among others, in a topology composed of 30 switches and 10 routers. The scenario presents three threat actors, including the entire Mirai botnet lifecycle and additional red-teaming tools performing DoS, scanning, and attacks targeting IoT protocols. The testbed has many purposes, including a cyber range, testing security solutions, and capturing network and application data to generate datasets. We hope that researchers can leverage and adapt Gotham to include other devices, state-of-the-art attacks and topologies to share scenarios and datasets that reflect the current IoT settings and threat landscape.}
}


@article{DBLP:journals/tdsc/YanYHLH24,
	author = {Hongyang Yan and
                  Anli Yan and
                  Li Hu and
                  Jiaming Liang and
                  Haibo Hu},
	title = {MTL-Leak: Privacy Risk Assessment in Multi-Task Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {204--215},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3247869},
	doi = {10.1109/TDSC.2023.3247869},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YanYHLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-task learning (MTL) supports simultaneous training over multiple related tasks and learns the shared representation. While improving the generalization ability of training on a single task, MTL has higher privacy risk than traditional single-task learning because more sensitive information is extracted and learned in a correlated manner. Unfortunately, very few works have attempted to address the privacy risks posed by MTL. In this article, we first investigate such risk by designing model extraction attack (MEA) and membership inference attack (MIA) in MTL. Then we evaluate the privacy risks on six MTL model architectures and two popular MTL datasets, whose results show that both the number of tasks and the complexity of training data play an important role in the attack performance. Our investigation shows that MTL is more vulnerable than traditional single-task learning under both attacks.}
}


@article{DBLP:journals/tdsc/MadalaDT24,
	author = {Kaushik Madala and
                  Hyunsook Do and
                  Bastian Tenbergen},
	title = {{ADSA} - Association-Driven Safety Analysis to Expose Unknown Safety
                  Issues},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {216--228},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3248606},
	doi = {10.1109/TDSC.2023.3248606},
	timestamp = {Mon, 03 Mar 2025 22:24:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/MadalaDT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous systems are susceptible to unknown safety issues due to overlooked dependencies among components of the system and the entities that are part of its operating environment. The current safety analysis techniques aids in identifying known safety issues but not overlooked/unknown safety issues. To identify unknown safety issues due to problematic interactions between components, in our previous work, we proposed safety assessment for concurrent components (SACC). Despite being more effective than FMEA and goal modeling, SACC suffers from some limitations such as not considering environmental entities and their properties, and a manual process for identifying associated components for the collective analysis. For a complex system with a large number of components, such an analysis can result in overlooking safety issues. To address these limitations, in this paper, we propose an association-driven safety analysis (ADSA) approach, which is extended and built on SACC. The approach uses a property-relation (PR) table and modified association rule mining algorithm to identify components and environmental entities that need to be considered together to detect overlooked or unknown safety issues. We evaluated our approach using four robotic systems and compared with SACC and systems theoretic process analysis (STPA). Our results show that our proposed approach, in particular using behavioral dependencies, is effective at exposing unknown safety issues.}
}


@article{DBLP:journals/tdsc/YangH24,
	author = {Benyuan Yang and
                  Hesuan Hu},
	title = {Delegation Security Analysis in Workflow Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {229--240},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3248602},
	doi = {10.1109/TDSC.2023.3248602},
	timestamp = {Sat, 10 Feb 2024 18:05:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/YangH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User delegation is a type of access control mechanisms that allow a person to delegate all or part of his\n/\nher authorities to others. It is an important access control policy that can significantly improve workflow flexibility. A crucial requirement after delegations is to check the satisfiability of workflow, i.e., determining whether there exists a valid execution schedule (\nES\n) in the workflow that can ensure it to proceed from the beginning to the end while satisfying all authorization constraints. Existing works perform in a centralized manner to find such a valid\nES\nby exploring all\nES\ns. Unfortunately, the enumeration of\nES\ns is highly inefficient from the perspective of computational complexity. This study proposes a novel approach to overcoming this difficulty in a distributed way. First, we use Petri nets (PNs) to formalize workflow and user delegations. Then, we directly specify a conflict-free workflow that satisfies all authorization constraints. Hence, determining the satisfiability of a workflow amounts to directly checking the existence of\nES\ns in the corresponding conflict-free workflow. Finally, we present a distributed strategy, which is of polynomial complexity, to determine the existence of\nES\ns.}
}


@article{DBLP:journals/tdsc/HuangMRZLC24,
	author = {Ke Huang and
                  Yi Mu and
                  Fatemeh Rezaeibagha and
                  Xiaosong Zhang and
                  Xiong Li and
                  Sheng Cao},
	title = {Monero With Multi-Grained Redaction},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {241--253},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3251735},
	doi = {10.1109/TDSC.2023.3251735},
	timestamp = {Sat, 10 Feb 2024 18:05:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/HuangMRZLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Monero is a privacy-centric cryptocurrency that allows users to obscure their transactions with multiple input and output addresses. Current research on Monero mainly focuses on identifying design vulnerabilities or optimizing towards stronger privacy, security, etc. For example, improving the design of ring confidential transaction (RingCT) protocol proposed by Noether et al. As revealed by Ali et al. in USENIX 2016, new blockchains have inadequate nodes and network computing resources to resist powerful attack (e.g., 51% attack). Obviously, Monero blockchain is not an exception. Ateniese et al. proposed the notion of redactable blockchain in EuroS $ \\& amp;$ P 2017, which begins the trend of formalizing blockchain with extra cryptographic primitives. The motivation is to turn an immutable blockchain into a mutable ledger by adapting the blockchain design and integrating with new cryptographic schemes. In such a setting, users could use their private keys to perform the secure multi-party computation to reverse blockchain history. The idea of redactable blockchain has attracted many researchers to pursuit this topic. However, few works have considered the privacy-preserving setting. Even fewer have practised their designs in an actual cryptocurrency. In this paper, we seek to adapt the RingCT protocol with several building blocks. Our proposal achieves most of the desired properties for blockchain redaction. It allows multiple tracing authorities to collaboratively trace users’ identities, and a system manager to perform multi-grained (including block-level, transaction-level, accumulator-level and commitment-level) redaction on block contents. Our proposal can be seen as an extension of RingCT protocol. We give rigorous security requirements and comprehensive analysis of our scheme. The performance evaluation suggested that our scheme suffers from some unscalabilities in large-scale implementations. A more elegant design to achieve stronger security and ideal scalability is deemed as a challenging and interesting future work.}
}


@article{DBLP:journals/tdsc/WangSLWJWL24,
	author = {Jie Wang and
                  Kun Sun and
                  Lingguang Lei and
                  Yuewu Wang and
                  Jiwu Jing and
                  Shengye Wan and
                  Qi Li},
	title = {CacheIEE: Cache-Assisted Isolated Execution Environment on {ARM} Multi-Core
                  Platforms},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {254--269},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3251418},
	doi = {10.1109/TDSC.2023.3251418},
	timestamp = {Sat, 10 Feb 2024 18:05:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WangSLWJWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {ARM TrustZone technology has been widely used to create Trusted Execution Environments (TEEs) for enhancing the security of applications. However, the increasing number of installed security-sensitive applications in the secure world will inevitably enlarge the trusted computing base (TCB) of TEE systems. To minimize the TCB of the secure world and increase application portability, Isolated Execution Environments (IEEs) are proposed to protect applications in enclaves created in the normal world. However, existing IEE systems cannot provide the same level of security as the TEE systems, particularly, on resolving the multi-vector attacks that include both physical memory disclosure attacks and software attacks. In this article, we develop a new cache-assisted IEE system called CacheIEE that creates enclaves in the L1 data cache of the normal world to protect sensitive data against multi-vector attacks. First, by always storing the sensitive data in the L1 data cache, CacheIEE can effectively prevent physical memory disclosure attacks. Second, we protect the L1 data cache against untrusted rich OS running in other cores. To support more applications, CacheIEE can process large-size sensitive data in the L1 data cache with constrained capacity. We implement a system prototype of CacheIEE and verify its security and practicability.}
}


@article{DBLP:journals/tdsc/WuFLYSX24,
	author = {Liqiang Wu and
                  Shaojing Fu and
                  Yuchuan Luo and
                  Hongyang Yan and
                  Heyuan Shi and
                  Ming Xu},
	title = {A Robust and Lightweight Privacy-Preserving Data Aggregation Scheme
                  for Smart Grid},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {270--283},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3252593},
	doi = {10.1109/TDSC.2023.3252593},
	timestamp = {Fri, 22 Mar 2024 09:05:21 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WuFLYSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving data aggregation (PPDA) enables data availability and privacy preservation simultaneously in smart grid. However, existing methods, such as masking and homomorphic encryption, cannot simultaneously offer strong privacy preservation, fault tolerance for both smart meters and aggregators, verifiable aggregation, and lightweight encryption. To tackle these challenges, we design HTV-PRE, a homomorphic threshold proxy re-encryption scheme with re-encryption verifiability. HTV-PRE involves only linear operations and resists quantum attacks after being instanced by ideal lattices. By leveraging HTV-PRE, we propose a robust and lightweight data aggregation scheme with strong privacy preservation for smart grid. Robustness ensures fault tolerance and error detection. Even if some smart meters or aggregators are faulty, data aggregation can still work without imposing expensive computation on other smart meters or requiring additional trust assumptions. Additionally, to detect aggregators’ errors, a proof for the aggregated result is presented so that anyone can verify whether the result has been correctly computed or not. The verifiable aggregation adds no computation/communication overhead on the user side. The performance evaluations demonstrate that our PPDA scheme significantly offloads computation overhead from smart meters and control center to the edge, and its user encryption is up to 4x faster than existing approaches.}
}


@article{DBLP:journals/tdsc/CeldranSBPS24,
	author = {Alberto Huertas Celdr{\'{a}}n and
                  Pedro Miguel S{\'{a}}nchez S{\'{a}}nchez and
                  G{\'{e}}r{\^{o}}me Bovet and
                  Gregorio Mart{\'{\i}}nez P{\'{e}}rez and
                  Burkhard Stiller},
	title = {CyberSpec: Behavioral Fingerprinting for Intelligent Attacks Detection
                  on Crowdsensing Spectrum Sensors},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {284--297},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3252918},
	doi = {10.1109/TDSC.2023.3252918},
	timestamp = {Thu, 29 Feb 2024 20:54:53 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/CeldranSBPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrated sensing and communication is a novel paradigm using crowdsensing spectrum sensors to help with the management of spectrum scarcity. However, well-known vulnerabilities of resource-constrained spectrum sensors and the possibility of being manipulated by users with physical access complicate their protection against spectrum sensing data falsification (SSDF) attacks. Most recent literature suggests using behavioral fingerprinting and Machine/Deep Learning (ML/DL) for improving similar cybersecurity issues. Nevertheless, the applicability of these techniques in resource-constrained devices, the impact of attacks affecting spectrum data integrity, and the performance and scalability of models suitable for heterogeneous sensors types are still open challenges. To improve limitations, this work presents seven SSDF attacks affecting spectrum sensors and introduces CyberSpec, an ML/DL-oriented framework using device behavioral fingerprinting to detect anomalies produced by SSDF attacks. CyberSpec has been implemented and validated in ElectroSense, a real crowdsensing RF monitoring platform where several configurations of the proposed SSDF attacks have been executed in different sensors. A pool of experiments with different unsupervised ML/DL-based models has demonstrated the suitability of CyberSpec detecting the previous attacks within an acceptable timeframe.}
}


@article{DBLP:journals/tdsc/BansalSAB24,
	author = {Urvashi Bansal and
                  Geeta Sikka and
                  Lalit Kumar Awasthi and
                  Bharat K. Bhargava},
	title = {Quantitative Evaluation of Extensive Vulnerability Set Using Cost
                  Benefit Analysis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {298--308},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3253121},
	doi = {10.1109/TDSC.2023.3253121},
	timestamp = {Sat, 10 Feb 2024 18:05:39 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/BansalSAB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The significant expansion in network size to support new paradigms such as cloud computing, IoT (Internet of Things), etc. together with the exponential increase in vulnerabilities has challenged the existing security mechanisms greatly. These challenges have opened many avenues for research in network security. However, while attack graphs play an important role in analyzing vulnerabilities, analyzing large attack graphs itself is a major issue. Therefore, it is necessary to extract only the critical part of the attack graph. Although technologies have been developed for attack path characterization, there is a lack of hybrid technology that can differentiate between similar behavior attack paths. We have proposed a cost-based path characterization technique that takes the attack node's vulnerability complexity into account and significantly reduces the number of vulnerabilities that need to be patched to avoid the major segment of attack graph. Moreover, we have used a real network prototype to validate the performance of the proposed scheme. The proposed scheme works well in cases where some vulnerabilities have similar risk scores. To the best of our knowledge, this is the first time that a cost-effective approach for attack path analysis has been proposed.}
}


@article{DBLP:journals/tdsc/LiangLXLZWL24,
	author = {Hongliang Liang and
                  Xiangyu Li and
                  Da Xiao and
                  Jie Liu and
                  Yanjie Zhou and
                  Aibo Wang and
                  Jin Li},
	title = {Generative Pre-Trained Transformer-Based Reinforcement Learning for
                  Testing Web Application Firewalls},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {309--324},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3252523},
	doi = {10.1109/TDSC.2023.3252523},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiangLXLZWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web Application Firewalls (WAFs) are widely deployed to protect key web applications against multiple security threats, so it is important to test WAFs regularly to prevent attackers from bypassing them easily. Machine-learning-based black-box WAF testing is gaining more attention, though existing learning-based approaches have strict requirements on the source and scale of payload data and suffer from the local optimum problem, limiting their effectiveness and practical application. We propose GPTFuzzer, a practical and effective generation-based approach to test WAFs by generating attack payloads token-by-token. Specifically, we fine-tune a Generative Pre-trained Transformer language model with reinforcement learning to make GPTFuzzer have the least restrictions on payload data and thus more applicable in practice, and we use reward modeling and KL-divergence penalty to improve the effectiveness of our approach and mitigate the local optimum issue. We implement GPTFuzzer and evaluate it on two well-known open-source WAFs against three kinds of common attacks. Experimental results show that GPTFuzzer significantly outperforms state-of-the-art approaches, i.e., ML-Driven and RAT, finding up to 7.8× (3.2× on average) more bypassing payloads within 1,250,000 requests, or finding out all bypassing payloads using up to 8.1× (3.3× on average) fewer requests.}
}


@article{DBLP:journals/tdsc/LiangYCLL24,
	author = {Hongliang Liang and
                  Xinglin Yu and
                  Xianglin Cheng and
                  Jie Liu and
                  Jin Li},
	title = {Multiple Targets Directed Greybox Fuzzing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {325--339},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3253120},
	doi = {10.1109/TDSC.2023.3253120},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiangYCLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Directed greybox fuzzing (DGF) can quickly discover or reproduce bugs in programs by seeking to reach a program location or explore some locations in order. However, due to their static stage division and coarse-grained energy scheduling, prior DGF tools perform poorly when facing multiple target locations (targets for short). In this paper, we present multiple targets directed greybox fuzzing which aims to reach multiple programs locations in a fuzzing campaign. Specifically, we propose a novel strategy to adaptively coordinate exploration and exploitation stages, and a novel energy scheduling strategy by considering more relations between seeds and target locations. We implement our approaches in a tool called LeoFuzz and evaluate it on crash reproduction, true positives verification, and vulnerability exposure in real-world programs. Experimental results show that LeoFuzz outperforms six state-of-the-art fuzzers, i.e., QYSM, AFLGo, Lolly, Berry, Beacon and WindRanger in terms of effectiveness and efficiency. Moreover, LeoFuzz has detected 23 new vulnerabilities in real-world programs, and 12 of them have been assigned CVE IDs.}
}


@article{DBLP:journals/tdsc/LiWZZ24,
	author = {Sheng Li and
                  Zichi Wang and
                  Xiudong Zhang and
                  Xinpeng Zhang},
	title = {Robust Image Steganography Against General Downsampling Operations
                  With Lossless Secret Recovery},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {340--352},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3253691},
	doi = {10.1109/TDSC.2023.3253691},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiWZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Resisting the operations in lossy channels is a challenge for image steganography. In this article, we propose a novel robust steganographic method to resist the image downsampling operation. Unlike the existing schemes, our method guarantees lossless secret recovery from the stego-image after general image downsampling operations, which considers the undetectability of the stego-images on both sides (sender and receiver) of the lossy channel. We first downsample the cover image to get its downsampled version on the receiver side, and select a set of embeddable pixels (i.e., the pixels that can be modified for data embedding) from the downsampled image. Then, we generate a stego-image on the receiver side (termed as the receiver stego-image) such that the distortion caused by the data embedding is minimized. Based on the receiver stego-image, we modify the cover image to produce the stego-image on the sender side (termed as the sender stego-image). The modification takes the embedding cost into account and makes sure that the downsampled version of the sender stego-image produces the same embeddable pixels as the receiver stego-image. Experimental results show that our method performs significantly better than the existing schemes in terms of robustness and undetectability for resisting general image downsampling operations.}
}


@article{DBLP:journals/tdsc/HuangLYLS24,
	author = {Cheng Huang and
                  Dongxiao Liu and
                  Anjia Yang and
                  Rongxing Lu and
                  Xuemin Shen},
	title = {Multi-Client Secure and Efficient DPF-Based Keyword Search for Cloud
                  Storage},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {353--371},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3253786},
	doi = {10.1109/TDSC.2023.3253786},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/HuangLYLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a multi-client secure and efficient keyword search scheme for cloud storage, which is built upon distributed point function (DPF). Specifically, outsourced keyword indexes are encoded by using garbled bloom filter and cuckoo filter, instead of bloom filter adopted by most of the state-of-the-art DPF-based schemes. In this way, clients can apply cuckoo hashing into DPF and utilize a segmentation method to interact with cloud servers for keyword search, and servers can obliviously aggregate DPF evaluation results to perform the search. Accordingly, the computational complexity at server side can be significantly reduced. Furthermore, the proposed scheme preserves constant downlink overheads, which is more communication-efficient for multi-keyword conjunctive search. To achieve privacy preservation and access control for multiple clients, we propose a double encryption method to encrypt outsourced indexes and correspondingly put forward an authorization algorithm from set-constrained pseudorandom functions by which fine-grained search-authorized keys can be generated, and collusion attacks among clients are addressed by integrating Wegman-Carter message authentication codes and cover-free systems. Since our scheme is designed under both semi-honest and malicious models (i.e., malicious servers may return incorrect query results), we use a simulation-based proof to formally demonstrate its security properties. Finally, we develop a proof-of-concept prototype and perform extensive experiments to show our scheme's practicality and efficiency in terms of computation, communication, and storage overheads.}
}


@article{DBLP:journals/tdsc/ShenLWLBLXR24,
	author = {Yijie Shen and
                  Feng Lin and
                  Chao Wang and
                  Tiantian Liu and
                  Zhongjie Ba and
                  Li Lu and
                  Wenyao Xu and
                  Kui Ren},
	title = {MotoPrint: Reconfigurable Vibration Motor Fingerprint via Homologous
                  Signals Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {372--387},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3253507},
	doi = {10.1109/TDSC.2023.3253507},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ShenLWLBLXR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device fingerprints can satisfy the high-security requirement of modern mobile applications (e.g., mobile payments) by guaranteeing the operation is performed on a trusted device. However, existing works on device fingerprints are weak to leakage, which leads to an irreversible failure of the device fingerprint authentication system after suffering from fingerprint theft attacks. The vulnerability drives us to propose a reconfigurable device fingerprint, i.e., MotoPrint, that can recover the system after suffering from such attacks. MotoPrint stems from the motor vibration that can represent in both signals of the accelerometer and the gyroscope (i.e., they are homologous motion signals). Therefore, we designed a two-path feature extracting network and a sensor-independent training strategy to eliminate sensor noise that can decline authentication performance. In addition, MotoPrint has a complete reconfiguration mechanism to cope with fingerprint leakage, which brings the damaged authentication system back to health. The evaluation of 80 stand-alone vibration motors and 20 in-built ones shows that MotoPrint can achieve high authentication accuracy of 98.5%. Meanwhile, we also demonstrate the reconfigured MotoPrint, which can also effectively indicate the device's uniqueness with over 98% accuracy, is independent of MotoPrints under other stimulating codes.}
}


@article{DBLP:journals/tdsc/CaiLLC24,
	author = {Jianping Cai and
                  Ximeng Liu and
                  Jiayin Li and
                  Kim{-}Kwang Raymond Choo},
	title = {Differentially Private Non-Negative Consistent Release for Large-Scale
                  Hierarchical Trees},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {388--402},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3253520},
	doi = {10.1109/TDSC.2023.3253520},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/CaiLLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hierarchical trees are widely used in differentially private statistical releases. Existing fast specialized algorithms guarantee hierarchical consistency but not non-negativity, which may incur meaningless negative values due to randomness. Quadratic programming can achieve optimally non-negative consistent releases, but traditional numerical-based methods face significant performance challenges when handling large-scale hierarchical trees. In this article, we construct the element set of Lagrange multiplier coefficients\nK\nthat satisfy the first type of KKT condition (values\n≥0\nand gradients\n=0\n). Applying Generation Matrix, we find that meticulously constructing an unconstrained set\nS⊆K\n, we can further find a larger\nS⊆K\nuntil\nS=K\n, as demonstrated in our proof (we also term this as the Unconstrained Set Expansion Theorem). Based on the theorem, we design an efficient Generation Matrix-based optimally non-negative consistent release algorithm (GMNC), which can easily handle large-scale hierarchical trees with more than 100 million nodes. Our experiments show that GMNC has an extremely high iteration efficiency with no more than 20 (only\n2∼8\non average) iterations even in the worst case. Compared to Interior Point Convex Method, GMNC improves the data scale processing limit up to 33.4 times in our experimental environment while requiring only 0.7% of the running time.}
}


@article{DBLP:journals/tdsc/PanSWYCLLLR24,
	author = {Ziyue Pan and
                  Wenbo Shen and
                  Xingkai Wang and
                  Yutian Yang and
                  Rui Chang and
                  Yao Liu and
                  Chengwei Liu and
                  Yang Liu and
                  Kui Ren},
	title = {Ambush From All Sides: Understanding Security Threats in Open-Source
                  Software {CI/CD} Pipelines},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {403--418},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3253572},
	doi = {10.1109/TDSC.2023.3253572},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/PanSWYCLLLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The continuous integration and continuous deployment (CI/CD) pipelines are widely adopted on Internet hosting platforms, such as GitHub. However, current CI/CD pipelines suffer from malicious code and severe vulnerabilities. Even worse, people have not been fully aware of its attack surfaces and the corresponding impacts. Therefore, in this paper, we conduct a large-scale measurement and a systematic analysis to reveal the attack surfaces of the CI/CD pipeline and quantify their security impacts. Specifically, for the measurement, we collect a data set of 320,000+ CI/CD pipeline-configured GitHub repositories and build an analysis tool to parse the CI/CD pipelines and extract security-critical usages. Our measurement reveals that the script runtimes are prone to code hiding while the script usage update is not in time, giving attackers chances to hide malicious code and exploit existing vulnerabilities. Moreover, even the scripts from verified creators may contain severe vulnerabilities. Besides current CI/CD ecosystem heavily relies on several core scripts, which may lead to a single point of failure. While the CI/CD pipelines contain sensitive information/operations, making them the attacker's favorite targets. Inspired by the measurement findings, we abstract the threat model and the attack approach toward CI/CD pipelines, followed by a systematic analysis of attack surfaces, attack strategies, and the corresponding impacts. We further launch case studies on five attacks in real-world CI/CD environments to validate the revealed attack surfaces. Finally, we give suggestions on mitigating attacks on CI/CD scripts, including securing CI/CD configurations, securing CI/CD scripts, and improving CI/CD infrastructure.}
}


@article{DBLP:journals/tdsc/LuoFLKR24,
	author = {Meng Luo and
                  Bo Feng and
                  Long Lu and
                  Engin Kirda and
                  Kui Ren},
	title = {On the Complexity of the Web's {PKI:} Evaluating Certificate
                  Validation of Mobile Browsers},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {419--433},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3255869},
	doi = {10.1109/TDSC.2023.3255869},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LuoFLKR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Digital certificates are frequently used to secure communications between users and web servers. Critical to the Web’s PKI is the secure validation of digital certificates. Nonetheless, certificate validation itself is complex and error-prone. Moreover, it is also undermined by particular constraints of mobile browsers. However, these issues have long been overlooked. In this article, we undertook the first systematic and large-scale study of the certificate validation mechanism within popular mobile browsers to highlight the necessity of reassessing it among all released browsers. To this end, we first compile a comprehensive test suite to identify security flaws in certificate validation from various aspects. By designing and implementing a generic, automated testing pipeline, we effectively evaluate 30 popular browsers on two mobile OS versions and compare them with five representative desktop browsers. We found the latest mobile browsers Accept as many as 33.2% invalid certificates and Reject merely 5.4% invalid ones on average, leaving the majority of them to be decided by users who usually have little expertise. Our findings shed light on the severity and inconsistency of certificate validation flaws across mobile browsers, which are likely to expose users to MITM attacks, spoofing attacks, and so forth.}
}


@article{DBLP:journals/tdsc/PriscoSP24,
	author = {Roberto De Prisco and
                  Alfredo De Santis and
                  Francesco Palmieri},
	title = {Bounds and Protocols for Graph-Based Distributed Secret Sharing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {434--448},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3261239},
	doi = {10.1109/TDSC.2023.3261239},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/PriscoSP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed Secret Sharing is a (multi) secret sharing model in which the shares are distributed over storage nodes of a network and each participant is able to reconstruct a specific secret by accessing a subset of the storage nodes. In this work, we provide new Distributed (multi) Secret Sharing Protocols for a specific class of access structures, namely those that can be described with a graph. The protocols improve on previous results allowing a faster encoding and decoding phase while maintaining optimal storage requirements. Moreover, our protocols can manage any kind of graph, while previous protocols have been designed only for complete graphs, and we provide a complete characterization of graph-based protocols. We also prove some tight bounds on the size of the information held in the storage nodes and communication complexity by using an information-theoretic approach. Finally, we also introduce a computationally secure technique for the general case that allows improvements in the size of the needed disk space if secrecy is computational, that is, if the scheme is robust against resource-bounded adversaries.}
}


@article{DBLP:journals/tdsc/LiuHXHR24,
	author = {Jianwei Liu and
                  Yinghui He and
                  Chaowei Xiao and
                  Jinsong Han and
                  Kui Ren},
	title = {Time to Think the Security of WiFi-Based Behavior Recognition Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {449--462},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3261328},
	doi = {10.1109/TDSC.2023.3261328},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuHXHR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Behavior recognition plays an essential role in numerous behavior-driven applications (e.g., virtual reality and smart home) and even in the security-critical applications (e.g., security surveillance and elder healthcare). Recently, WiFi-based behavior recognition (WBR) technique stands out among many behavior recognition techniques due to its advantages of being non-intrusive, device-free, and ubiquitous. However, existing WBR research mainly focuses on improving the recognition precision, while rarely studying the security aspects. In this article, we reveal that WBR systems are vulnerable to manipulating physical signals. For instance, our observation shows that WiFi signals can be changed by jamming signals. By exploiting the vulnerability, we propose two approaches to generate physically online adversarial samples to perform untargeted attack and targeted attack, respectively. The effectiveness of these attacks are extensively evaluated over four real-world WBR systems. The experiment results show that our attack approaches can achieve 80% and 60% success rates for untargeted attack and targeted attack in physical world, respectively. We also show that our attack approaches can be generalized to other WiFi-based sensing applications, such as user authentication.}
}


@article{DBLP:journals/tdsc/ZhangLKWWL24,
	author = {Runnan Zhang and
                  Gang Liu and
                  Hongzhaoning Kang and
                  Quan Wang and
                  Bo Wan and
                  Nan Luo},
	title = {Anonymity in Attribute-Based Access Control: Framework and Metric},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {463--475},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3261309},
	doi = {10.1109/TDSC.2023.3261309},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangLKWWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymous access is an effective method for preserving privacy in access control. This study assumes that anonymous access control requires both frameworks and policies. Numerous solutions have been proposed for anonymous access at the framework level. In this study, these solutions are analyzed and quantified using a unified attribute-based access control (ABAC) anonymous access reference framework. Anonymous access at the framework level is the first line of defense, and inappropriate policies may undermine subject anonymity. An anonymity metric is proposed at the policy level to prevent authorization authority from re-identification using specific attributes and policies. The anonymity metric evaluates the risk of re-identifying a subject due to inappropriate access requests, as well as subject attribute assignment schemes and policies. This study is the first to focus on anonymity at the policy level in ABAC. Furthermore, a formal definition of anonymity suitable for ABAC is proposed. The feasibility of the proposed anonymity metric is verified through simulations.}
}


@article{DBLP:journals/tdsc/ZhangJPSFLW24,
	author = {Yi Zhang and
                  Xiaofeng Jia and
                  Bianjing Pan and
                  Jun Shao and
                  Liming Fang and
                  Rongxing Lu and
                  Guiyi Wei},
	title = {Anonymous Multi-Hop Payment for Payment Channel Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {476--485},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3262681},
	doi = {10.1109/TDSC.2023.3262681},
	timestamp = {Wed, 02 Oct 2024 07:43:05 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangJPSFLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Payment Channel Networks (PCNs) have flourished as one of the most promising solutions to the blockchain scalability problem. Unfortunately, the existing PCN solutions either fail to provide path privacy guarantees or require the not-always-true All-Anonymous-Connected assumption (i.e., an anonymous communication channel always exists for any two participants). To alleviate these problems, we first present a new cryptographic primitive named anonymous multi-hop payment (AMHP), which is an improvement of anonymous multi-hop lock (AMHL). Using AMHP and payment channels, we can have a new PCN solution with path privacy but removing the All-Anonymous-Connected assumption. After that, we present the first AMHP scheme, called AMHL+, by adapting the generic construction of AMHL, but at the cost of high communication overhead. To reduce the communication cost, we further present a new AMHP scheme (named EAMHL+) using bilinear pairing. The communication cost of the EAMHL+ is reduced by 92.3% compared to the AMHL+. The rigorous security analysis demonstrates that the EAMHL+ holds consistency, balance security, and path privacy. Finally, we implement the proposed AMHP schemes using Java. The extensive experimental results show that, though the EAMHL+ requires more computational cost than the AMHL+, it is more efficient than the latter in terms of communication overhead.}
}


@article{DBLP:journals/tdsc/SarmadiFKGK24,
	author = {Alireza Sarmadi and
                  Hao Fu and
                  Prashanth Krishnamurthy and
                  Siddharth Garg and
                  Farshad Khorrami},
	title = {Privacy-Preserving Collaborative Learning Through Feature Extraction},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {486--498},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3263507},
	doi = {10.1109/TDSC.2023.3263507},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/SarmadiFKGK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a framework in which multiple entities collaborate to build a machine learning model while preserving privacy of their data. The approach utilizes feature embeddings from shared/per-entity feature extractors transforming data into a feature space for cooperation between entities. We propose two specific methods and compare them with a baseline method. In Shared Feature Extractor (SFE) Learning, the entities use a shared feature extractor to compute feature embeddings of samples. In Locally Trained Feature Extractor (LTFE) Learning, each entity uses a separate feature extractor, and models are trained using concatenated features from all entities. As a baseline, in Cooperatively Trained Feature Extractor (CTFE) Learning, the entities train models by sharing raw data. Secure multi-party algorithms are utilized to train models without revealing data or features in plain text. We investigate the trade-offs among SFE, LTFE, and CTFE in regard to performance, privacy leakage (using an off-the-shelf membership inference attack), and computational cost. LTFE provides the most privacy, followed by SFE, and then CTFE. Computational cost is lowest for SFE and the relative speed of CTFE and LTFE depends on network architecture. CTFE and LTFE provide the best accuracy. We use three different datasets for evaluations.}
}


@article{DBLP:journals/tdsc/LuoWY24,
	author = {Fucai Luo and
                  Haiyan Wang and
                  Xingfu Yan},
	title = {Comments on "VERSA: Verifiable Secure Aggregation for Cross-Device
                  Federated Learning"},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {1},
	pages = {499--500},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3253082},
	doi = {10.1109/TDSC.2023.3253082},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LuoWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) allows a large number of users to collaboratively train machine learning (ML) models by sending only their local gradients to a central server for aggregation in each training iteration, without sending their raw training data. The main security issues of FL, that is, the privacy of the gradient vector and the correctness verification of the aggregated gradient, are gaining increasing attention from industry and academia. To protect the privacy of the gradient, a secure aggregation was proposed; to verify the correctness of the aggregated gradient, a verifiable secure aggregation that requires the server to provide a verifiable aggregated gradient was proposed. In 2021, Hahn et al. proposed VERSA, a verifiable secure aggregation. However, in this article, we will point out a flaw in VERSA, which indicates that VERSA does not work. To address the flaw, we present several approaches with different advantages and disadvantages. We hope that by identifying the flaw, similar errors can be avoided in future designs of verifiable secure aggregation.}
}


@article{DBLP:journals/tdsc/LiuZZTHHR24,
	author = {Jianwei Liu and
                  Xiang Zou and
                  Leqi Zhao and
                  Yusheng Tao and
                  Sideng Hu and
                  Jinsong Han and
                  Kui Ren},
	title = {Privacy Leakage in Wireless Charging},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {501--514},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3173063},
	doi = {10.1109/TDSC.2022.3173063},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuZZTHHR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless charging is becoming an essential power supply pattern for electronic devices. Currently, mainstream smartphones are almost compatible with wireless charging. However, when the charging efficiency is continuously improved, its security challenge still remains open yet overlooked. In this paper, we reveal that severe security flaws exist in the wireless charging procedure of off-the-shelf commodity smartphones. Specifically, we find that an attacker can utilize the electromagnetic induction effect between the wireless charger and the smartphone to detect the activities and operations performed on the smartphone. We term such attack as EM-Surfing side-channel attack and build a theoretical model to show its feasibility. To explore the hazard of EM-Surfing, we propose a three-module attack method, with which we conduct real-world experiments over three mainstream models of smartphones. The results show that the attacker can achieve over 99%, 96%, 94%, and 97% accuracy when inferring the passcode, keystroke, App information, and speech content, respectively. We also design an App named SecCharging to prevent smartphones from EM-Surfing attacks. The defense experiment results demonstrate that SecCharging can mitigate the threats posed by EM-Surfing effectively.}
}


@article{DBLP:journals/tdsc/XueYZSMWZ24,
	author = {Yinxing Xue and
                  Jiaming Ye and
                  Wei Zhang and
                  Jun Sun and
                  Lei Ma and
                  Haijun Wang and
                  Jianjun Zhao},
	title = {xFuzz: Machine Learning Guided Cross-Contract Fuzzing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {515--529},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3182373},
	doi = {10.1109/TDSC.2022.3182373},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XueYZSMWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart contract transactions are increasingly interleaved by cross-contract calls. While many tools have been developed to identify a common set of vulnerabilities, the cross-contract vulnerability is overlooked by existing tools. Cross-contract vulnerabilities are exploitable bugs that manifest in the presence of more than two interacting contracts. Existing methods are however limited to analyze a maximum of two contracts at the same time. Detecting cross-contract vulnerabilities is highly non-trivial. With multiple interacting contracts, the search space is much larger than that of a single contract. To address this problem, we present xFuzz, a machine learning guided smart contract fuzzing framework. The machine learning models are trained with novel features (e.g., word vectors and instructions) and are used to filter likely benign program paths. Comparing with existing static tools, machine learning model is proven to be more robust, avoiding directly adopting manually-defined rules in specific tools. We compare xFuzz with three state-of-the-art tools on 7,391 contracts. xFuzz detects 18 exploitable cross-contract vulnerabilities, of which 15 vulnerabilities are exposed for the first time. Furthermore, our approach is shown to be efficient in detecting non-cross-contract vulnerabilities as well—using less than 20% time as that of other fuzzing tools, xFuzz detects twice as many vulnerabilities.}
}


@article{DBLP:journals/tdsc/LiSHLJQ24,
	author = {Qian Li and
                  Chao Shen and
                  Qingyuan Hu and
                  Chenhao Lin and
                  Xiang Ji and
                  Saiyu Qi},
	title = {Towards Gradient-Based Saliency Consensus Training for Adversarial
                  Robustness},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {530--541},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3184594},
	doi = {10.1109/TDSC.2022.3184594},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiSHLJQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent works, robust networks have consistently exhibited more discriminative saliency map that proves to indicate sufficient adversarial robustness. In existed safe training paradigms e.g., adversarial training, however, the progressive saliency information regarding on what input semantic feature model prediction relies, have not yet been fully-explored. Due to this, we consider the incorporation of posterior saliency properties of robust model in training, as an efficient supervision signal on robust learning. It thus provides an alternative direction to enhance robustness, from the saliency interpretability perspective. In this article, to harden model we propose to optimize the discrimination of intermediate gradient-based saliency and maintain its consensus in training, which encourage model to behave according to task-relevant feature from the salient region such as object edges in image. Then, we introduce Adversarially Gradient-based Saliency Consensus Training method, dubbed Adv-GSCT. Within it, we preserve the similarity between the learned model saliency and the target one as label, approximated in the most offending case representing the least but essential information scenario. Meanwhile, a constructed pseudo-input coupled with feature importance, is feed into model to ensure the discrimination of estimated target saliency. Besides providing a novel insight into adversarial defense, Adv-GSCT differs from the current most effective adversarial training and does not need multiple iterative generations of adversarial perturbation whose computational cost and sensitivity direction of prediction concern. Finally, extensive performance evaluations on MNIST, CIFAR-10 and ImageNet datasets demonstrate the superiority of our proposed method.}
}


@article{DBLP:journals/tdsc/ChengNLWZS24,
	author = {Xiao Cheng and
                  Xu Nie and
                  Ningke Li and
                  Haoyu Wang and
                  Zheng Zheng and
                  Yulei Sui},
	title = {How About Bug-Triggering Paths? - Understanding and Characterizing
                  Learning-Based Vulnerability Detectors},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {542--558},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3192419},
	doi = {10.1109/TDSC.2022.3192419},
	timestamp = {Sun, 19 Jan 2025 13:48:33 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ChengNLWZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning and its promising branch deep learning have proven to be effective in a wide range of application domains. Recently, several efforts have shown success in applying deep learning techniques for automatic vulnerability discovery, as alternatives to traditional static bug detection. In principle, these learning-based approaches are built on top of classification models using supervised learning. Depending on the different granularities to detect vulnerabilities, these approaches rely on learning models which are typically trained with well-labeled source code to predict whether a program method, a program slice, or a particular code line contains a vulnerability or not. The effectiveness of these models is normally evaluated against conventional metrics including precision, recall and F1 score. In this paper, we show that despite yielding promising numbers, the above evaluation strategy can be insufficient and even misleading when evaluating the effectiveness of current learning-based approaches. This is because the underlying learning models only produce the classification results or report individual/isolated program statements, but are unable to pinpoint bug-triggering paths, which is an effective way for bug fixing and the main aim of static bug detection. Our key insight is that a program method or statement can only be stated as vulnerable in the context of a bug-triggering path. In this work, we systematically study the gap between recent learning-based approaches and conventional static bug detectors in terms of fine-grained metrics called BTP metrics using bug-triggering paths. We then characterize and compare the quality of the prediction results of existing learning-based detectors under different granularities. Finally, our comprehensive empirical study reveals several key issues and challenges in developing classification models to pinpoint bug-triggering paths and calls for more advanced learning-based bug detection techniques.}
}


@article{DBLP:journals/tdsc/JiangZQLX24,
	author = {Wenbo Jiang and
                  Tianwei Zhang and
                  Han Qiu and
                  Hongwei Li and
                  Guowen Xu},
	title = {Incremental Learning, Incremental Backdoor Threats},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {559--572},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3201234},
	doi = {10.1109/TDSC.2022.3201234},
	timestamp = {Wed, 29 Jan 2025 14:51:06 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/JiangZQLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Class incremental learning from a pre-trained DNN model is gaining lots of popularity. Unfortunately, the pre-trained model also introduces a new attack vector, which enables an adversary to inject a backdoor into it and further compromise the downstream models learned from it. Prior works proposed backdoor attacks against the pre-trained models in the transfer learning scenario. However, they become less effective when the adversary does not have the knowledge of the downstream tasks or new data, which is more practical and considered in this paper. To this end, we design the first latent backdoor attacks against incremental learning. We propose two novel techniques, which can effectively and stealthily embed a backdoor into the pre-trained model. Such backdoor can only be activated when the pre-trained model is extended to a downstream model with incremental learning. It has a very high attack success rate, and is able to bypass existing backdoor detection approaches. Extensive experiments confirm the effectiveness of our attacks over different datasets and incremental learning methods, as well as strong robustness against state-of-the-art backdoor defense mechanisms including Neural Cleanse, Fine-Pruning and STRIP.}
}


@article{DBLP:journals/tdsc/SanchezCSIBPS24,
	author = {Pedro Miguel S{\'{a}}nchez S{\'{a}}nchez and
                  Alberto Huertas Celdr{\'{a}}n and
                  Timo Schenk and
                  Adrian Lars Benjamin Iten and
                  G{\'{e}}r{\^{o}}me Bovet and
                  Gregorio Mart{\'{\i}}nez P{\'{e}}rez and
                  Burkhard Stiller},
	title = {Studying the Robustness of Anti-Adversarial Federated Learning Models
                  Detecting Cyberattacks in IoT Spectrum Sensors},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {573--584},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3204535},
	doi = {10.1109/TDSC.2022.3204535},
	timestamp = {Mon, 15 Apr 2024 08:25:48 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SanchezCSIBPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device fingerprinting combined with Machine and Deep Learning (ML/DL) report promising performance when detecting spectrum sensing data falsification (SSDF) attacks. However, the amount of data needed to train models and the scenario privacy concerns limit the applicability of centralized ML/DL. Federated learning (FL) addresses these drawbacks but is vulnerable to adversarial participants and attacks. The literature has proposed countermeasures, but more effort is required to evaluate the performance of FL detecting SSDF attacks and their robustness against adversaries. Thus, the first contribution of this work is to create an FL-oriented dataset modeling the behavior of resource-constrained spectrum sensors affected by SSDF attacks. The second contribution is a pool of experiments analyzing the robustness of FL models according to i) three families of sensors, ii) eight SSDF attacks, iii) four FL scenarios dealing with anomaly detection and binary classification, iv) up to 33% of participants implementing data and model poisoning attacks, and v) four aggregation functions acting as anti-adversarial mechanisms. In conclusion, FL achieves promising performance when detecting SSDF attacks. Without anti-adversarial mechanisms, FL models are particularly vulnerable with >16% of adversaries. Coordinate-wise-median is the best mitigation for anomaly detection, but binary classifiers are still affected with >33% of adversaries.}
}


@article{DBLP:journals/tdsc/SongTRXLWG24,
	author = {Qun Song and
                  Rui Tan and
                  Chao Ren and
                  Yan Xu and
                  Yang Lou and
                  Jianping Wang and
                  Hoay Beng Gooi},
	title = {On Credibility of Adversarial Examples Against Learning-Based Grid
                  Voltage Stability Assessment},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {585--599},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3213012},
	doi = {10.1109/TDSC.2022.3213012},
	timestamp = {Sat, 27 Apr 2024 21:29:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SongTRXLWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Voltage stability assessment is essential for maintaining reliable power grid operations. Stability assessment approaches using deep learning address the shortfalls of the traditional time-domain simulation-based approaches caused by increased system complexity. However, deep learning models are shown to be vulnerable to adversarial examples in the field of computer vision. While this vulnerability has been noticed by the power grid cybersecurity research, the domain-specific analysis on the requirements imposed upon effective attack implementation is still lacking. Although these attack requirements are usually reasonable in computer vision tasks, they can be stringent in the context of power grids. In this paper, we conduct a systematic investigation on the attack requirements and credibility of six representative adversarial example attacks based on a voltage stability assessment application for the New England 10-machine 39-bus power system. We show that (1) compromising about half the transmission system buses’ voltage traces is a rule-of-thumb attack requirement; (2) the universal adversarial perturbations regardless of the original clean voltage trajectory possess the same credibility as the widely studied false data injection attacks on power grid state estimation, while the input-specific adversarial perturbations are less credible; (3) the prevailing strong adversarial training thwarts the universal perturbations but fails in defending certain input-specific perturbations. To advance defense to cope with both universal and input-specific adversarial examples, we propose a new approach that simultaneously estimates the predictive uncertainty of any given input of voltage trajectory and thwarts the attacks effectively.}
}


@article{DBLP:journals/tdsc/RenWLLG24,
	author = {Ge Ren and
                  Jun Wu and
                  Gaolei Li and
                  Shenghong Li and
                  Mohsen Guizani},
	title = {Protecting Intellectual Property With Reliable Availability of Learning
                  Models in AI-Based Cybersecurity Services},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {600--617},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3222972},
	doi = {10.1109/TDSC.2022.3222972},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/RenWLLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Artificial intelligence (AI)-based cybersecurity services offer significant promise in many scenarios, including malware detection, content supervision, and so on. Meanwhile, many commercial and government applications have raised the need for intellectual property protection of using deep neural network (DNN). Existing studies (e.g., watermarking techniques) on intellectual property protection only aim at inserting secret information into DNNs, allowing producers to detect whether the given DNN infringes on their own copyrights. However, since the availability protection of learning models is rarely considered, the piracy model can still work with high accuracy. In this paper, a novel model locking (M-LOCK) scheme for the DNN is proposed to enhance its availability protection, where the DNN produces poor accuracy if a specific token is absent, while it maps only the tokenized inputs into correct predictions. The proposed scheme performs the verification process during the DNN inference operation, actively protecting models’ intellectual property copyright at each query. Specifically, to train the token-sensitive decision-making boundaries of DNNs, a data poisoning-based model manipulation (DPMM) method is also proposed, which minimizes the correlation between the dummy outputs and correct predictions. Extensive experiments demonstrate the proposed scheme could achieve high reliability and effectiveness across various benchmark datasets as well as typical model protection methods.}
}


@article{DBLP:journals/tdsc/RoyBAD24,
	author = {Prithwiraj Roy and
                  Shameek Bhattacharjee and
                  Sahar Abedzadeh and
                  Sajal K. Das},
	title = {Noise Resilient Learning for Attack Detection in Smart Grid {PMU}
                  Infrastructure},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {618--635},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3223288},
	doi = {10.1109/TDSC.2022.3223288},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/RoyBAD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Falsified data from compromised Phasor Measurement Units (PMUs) in a smart grid induce Energy Management Systems (EMS) to have an inaccurate estimation of the state of the grid, disrupting various operations of the power grid. Moreover, the PMUs deployed at the distribution layer of a smart grid show dynamic fluctuations in their data streams, which make it extremely challenging to design effective learning frameworks for anomaly based attack detection. In this paper, we propose a noise resilient learning framework for anomaly based attack detection specifically for distribution layer PMU infrastructure, that show real time indicators of data falsifications attacks while offsetting the effect of false alarms caused by the noise. Specifically, we propose a feature extraction framework that uses some Pythagorean Means of the active power from a cluster of PMUs, reducing multi-dimensional nature of the PMU data streams via quick Big Data summarization. We also propose a robust and noise resilient methodology for learning thresholds based on generalized robust estimation theory of our invariant feature. We experimentally validate our approach and demonstrate improved reliability performance using two completely different datasets collected from real distribution level PMU infrastructures.}
}


@article{DBLP:journals/tdsc/FangQQZCZC24,
	author = {Han Fang and
                  Yupeng Qiu and
                  Guorui Qin and
                  Jiyi Zhang and
                  Kejiang Chen and
                  Weiming Zhang and
                  Ee{-}Chien Chang},
	title = {DP\({}^{\mbox{2}}\)Dataset Protection by Data Poisoning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {636--649},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2022.3227945},
	doi = {10.1109/TDSC.2022.3227945},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/FangQQZCZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data poisoning can be served as an effective way to protect the dataset from surrogate training, whereby the performance of the surrogate model could be greatly influenced if trained with poisoned dataset. This paper focuses on an advanced scenario where the attacker might be an experienced malicious employee who has the white-box access to the dataset and black-box access (can only query) to original business model (e.g. MLaaS model). Under this condition, three main requirements must be satisfied: imperceptibility, robustness and stealthiness. In this paper, we propose a novel dataset protection method by data poisoning dubbed DP2 to meet the requirements. To achieve imperceptibility and robustness, we propose a poisoning mechanism which is conducted by a designed dual-U-Net-based poisoning network, by training with the reference mapping strategy and the corresponding noise layer, the imperceptibility and robustness can be both achieved. As for stealthiness, we propose a recover-net to eliminate the perturbation, so that the business model with black-box access could be an enclose version of the recover-net and the original business model. Besides, based on the recover-net, the poisoned dataset could be re-applied for the normal use. Various experiments indicate superior performance of the proposed scheme in the view of imperceptibility and robustness compared with other schemes. The solution which makes the poisoned data recoverable greatly ensures the stealthiness, and the derived recoverability of poisoned data could be utilized in other scenarios.}
}


@article{DBLP:journals/tdsc/WangGGYN24,
	author = {Ping Wang and
                  Haichang Gao and
                  Xiaoyan Guo and
                  Zhongni Yuan and
                  Jiawei Nian},
	title = {Improving the Security of Audio CAPTCHAs With Adversarial Examples},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {650--667},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3236367},
	doi = {10.1109/TDSC.2023.3236367},
	timestamp = {Tue, 19 Nov 2024 20:28:41 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WangGGYN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {CAPTCHAs (completely automated public Turing tests to tell computers and humans apart) have been the main protection against malicious attacks on public systems for many years. Audio CAPTCHAs, as one of the most important CAPTCHA forms, provide an effective test for visually impaired users. However, in recent years, most of the existing audio CAPTCHAs have been successfully attacked by machine learning-based audio recognition algorithms, showing their insecurity. In this article, a generative adversarial network (GAN)-based method is proposed to generate adversarial audio CAPTCHAs. This method is implemented by using a generator to synthesize noise, a discriminator to make it similar to the target and a threshold function to limit the size of the perturbation; then, the synthetic perturbation is combined with the original audio to generate the adversarial audio CAPTCHA. The experimental results demonstrate that the addition of adversarial examples can greatly reduce the recognition accuracy of automatic models and improve the robustness of different types of audio CAPTCHAs. We also explore ensemble learning strategies to improve the transferability of the proposed adversarial audio CAPTCHA methods. To investigate the effect of adversarial CAPTCHAs on human users, a user study is also conducted.}
}


@article{DBLP:journals/tdsc/XuMSLZ24,
	author = {Wenhan Xu and
                  Hui Ma and
                  Zishuai Song and
                  Jianhao Li and
                  Rui Zhang},
	title = {Gringotts: An Encrypted Version Control System With Less Trust on
                  Servers},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {668--684},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3251365},
	doi = {10.1109/TDSC.2023.3251365},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/XuMSLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Version Control System (VCS) plays an essential role in software supply chain, as it manages code projects and enables efficient collaboration. For a private repository, where source code is a high-profile asset and needs to be protected, VCS’ security is extremely important. Traditional (unencrypted or encrypted) VCS solutions rely on a trusted service provider to host the code and enforce access control, which is not realistic enough for real-world threats. If the service provider peep in or the hackers break into the repository, the read & write privilege to the sensitive code is totally lost. Therefore, we consider whether one can relax the assumption on the server by introducing a covert adversary, namely, it may act maliciously, but will not misbehave if it can be caught doing so. However, protecting sensitive code and enforcing access control on a covert adversarial server is a challenging task. Existing encryption-based VCS solutions failed to address this challenge, as they offered limited access control functionalities, introduced heavy key management overhead or storage overhead. Moreover, the crucial feature of compression of the source files were missing in an encrypted and versioned storage. To address these problems, we introduce Gringotts, an end-to-end encrypted VCS, tailored for read & write access control, version control and source file compression. We present a formal model and propose a scheme with detailed analysis. We also implement and evaluate Gringotts on top-10 most starred code projects on GitHub. The results demonstrate that Gringotts introduces low latency (less than 0.3 s) for commit encryption and decryption, supports fine-grained access control and rich version control functionalities with practical performance.}
}


@article{DBLP:journals/tdsc/JiangLXZL24,
	author = {Wenbo Jiang and
                  Hongwei Li and
                  Guowen Xu and
                  Tianwei Zhang and
                  Rongxing Lu},
	title = {A Comprehensive Defense Framework Against Model Extraction Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {685--700},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3261327},
	doi = {10.1109/TDSC.2023.3261327},
	timestamp = {Wed, 29 Jan 2025 14:51:06 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/JiangLXZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a promising service, Machine Learning as a Service (MLaaS) provides personalized inference functions for clients through paid APIs. Nevertheless, it is vulnerable to model extraction attacks, in which an attacker can extract a functionally-equivalent model by repeatedly querying the APIs with crafted samples. While numerous works have been proposed to defend against model extraction attacks, existing efforts are accompanied by limitations and low comprehensiveness. In this article, we propose AMAO, a comprehensive defense framework against model extraction attacks. Specifically, AMAO consists of four interlinked successive phases: adversarial training is first exploited to weaken the effectiveness of model extraction attacks. Then, malicious query detection is used to detect malicious queries and mark malicious users. After that, we develop a label-flipping poisoning attack to instruct the adaptive query responses to malicious users. Besides, the image pHash algorithm is employed to ensure the indistinguishability of the query responses. Finally, the perturbed results are served as a backdoor to verify the ownership of any suspicious model. Extensive experiments demonstrate that AMAO outperforms existing defenses in defending against model extraction attacks and is also robust against the adaptive adversary who is aware of the defense.}
}


@article{DBLP:journals/tdsc/KhanKB24,
	author = {Shahid Khan and
                  Joost{-}Pieter Katoen and
                  Marc Bouissou},
	title = {A Compositional Semantics of Boolean-Logic Driven Markov Processes},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {701--716},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3261270},
	doi = {10.1109/TDSC.2023.3261270},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/KhanKB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Boolean-logic driven Markov processes (BDMPs) is a prominent dynamic extension of static fault trees to model repairable and complex dynamic systems. While BDMPs are intensively used in an industrial context for dependability analysis of energy systems, its formal semantics has not been systematically treated. To date, BDMPs are defined as a library of the domain-specific dependability-modelling language Figaro, which is neither open source nor publicly available. A rigorous semantic underpinning of BDMPs is indispensable for (1) developing BDMP analysis tools and (2) comparing its expressive power to other related reliability modelling languages. This paper presents a formal semantics to BDMPs using Markov automata (MA), an extension of continuous-time Markov chains (CTMCs) with action transitions to compose complex MA from smaller MA. This enables us to provide a compositional semantics. That is, we express the semantics of each individual BDMP element as an MA and obtain the MA for the entire BDMP by combining the MA of its elements. This makes the semantics comprehensible, for those familiar with automata theory, and easily extensible with new BDMP elements, e.g., to model security aspects. After considering the entire BDMP, the actions in its MA that were used to “glue” the MA of BDMP elements are ignored. This results in a CTMC amenable to exact numerical analysis by, e.g., efficient probabilistic model-checking techniques. We report on a prototypical implementation of our semantics and empirically show that our semantics yields dependability metrics that correspond to the interpretation by the Figaro knowledge base of BDMPs.}
}


@article{DBLP:journals/tdsc/ZhangLLXL24,
	author = {Di Zhang and
                  Junqing Le and
                  Xinyu Lei and
                  Tao Xiang and
                  Xiaofeng Liao},
	title = {Secure Redactable Blockchain With Dynamic Support},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {717--731},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3261343},
	doi = {10.1109/TDSC.2023.3261343},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangLLXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain is extensively applied to many fields as an immutable distributed ledger. However, the immutability contradicts regulations such as the GDPR ruling “the right to be forgotten” of data. Besides, numerous emerging blockchain-based applications call for elastic data management. To erase some data, redactable blockchains are proposed for breaking the immutability in a controlled way. Unfortunately, the prior solutions may suffer from poor security and centralized control of the redaction privilege. They cannot support dynamic nodes, where the departure of participators will result in a single point of failure. This article proposes a novel dynamic and decentralized attribute-based chameleon hash (DACH) to make blockchain history mutable, achieving a securely and dynamically redactable blockchain (SDR-chain) in a decentralized setting. We first propose the formal definition, security models, and concrete construction of our DACH. Meanwhile, we design a delegation algorithm of DACH to support a dynamically changing committee, where participators can freely and securely leave and join the network. Then, the transactions of the SDR-chain are redacted by computing DACH collisions. The security is analyzed in the random oracle model. Finally, theoretical analysis and experimental evaluation demonstrate that our SDR-chain is superior to the prior solutions in terms of security and functionality.}
}


@article{DBLP:journals/tdsc/LeeL24,
	author = {Insup Lee and
                  Wonjun Lee},
	title = {UniQGAN: Towards Improved Modulation Classification With Adversarial
                  Robustness Using Scalable Generator Design},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {732--745},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3261983},
	doi = {10.1109/TDSC.2023.3261983},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LeeL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automatic modulation classification (AMC) has been envisioned as a significant element for security issues at the physical layer due to its indispensable role in accurate communications. Recent attention to deep learning has impacted the AMC, which exhibits exceptional performance without manual feature engineering. To guarantee the accuracy and robustness of deep learning-based AMC, data augmentation is a critical issue. While existing studies have used several deep generative models to handle the data insufficiency, these studies face three challenges including low scalability, lengthy training time, and limited accuracy improvement. To this end, this paper presents UniQGAN, a novel unified generative architecture that models I/Q constellation diagrams from various signal-to-noise ratios (SNRs) using a single model. The proposed method enables the generation of high-quality data with a scalable generator, while requiring reduced training time. At the core of UniQGAN are multi-conditions embedding and multi-domains classification techniques that leverage both SNR and modulation type during the optimization process to enable unified modeling. Using abundant high-quality training data, UniQGAN accelerates the enhanced AMC with high performance and adversarial robustness. Experimental results demonstrate that the data generation by UniQGAN achieves superiority in terms of scalability, training time, and accuracy.}
}


@article{DBLP:journals/tdsc/GuoLTCL24,
	author = {Cheng Guo and
                  Wenfeng Li and
                  Xinyu Tang and
                  Kim{-}Kwang Raymond Choo and
                  Yining Liu},
	title = {Forward Private Verifiable Dynamic Searchable Symmetric Encryption
                  With Efficient Conjunctive Query},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {746--763},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3262060},
	doi = {10.1109/TDSC.2023.3262060},
	timestamp = {Fri, 21 Feb 2025 14:30:14 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/GuoLTCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic searchable symmetric encryption (DSSE) allows efficient searches over encrypted databases and also supports clients in their updating of the data, such as those stored in a remote cloud server. However, recent attacks suggest the risk of leakage during such updates, which consequently impacts on the privacy of the queries. In addition, existing DSSE schemes that support forward privacy generally rely on the honest-but-curious server and support only single-keyword retrieval, which limits the application scenarios. In this paper, we present the design of a verifiable DSSE protocol, which supports efficient conjunctive query with forward privacy. In our scheme, the forward index is constructed by a novel form, i.e., t-puncturable PRFs, and the authentication tag is designed by symmetric cryptography. During conjunctive queries, we narrow the scope by an inverted index, and then we determine the results of the final query through the forward index. Meanwhile, we can use verification tag to check the correctness and completeness of the result. In addition, we present an extension to support backward privacy, and our experimental evaluations show that our proposed approach achieves better performance on both conjunctive queries and updates than other competing solutions and ensures efficient verification.}
}


@article{DBLP:journals/tdsc/GuiZZX24,
	author = {Linqing Gui and
                  Weihao Zhou and
                  Pinchang Zhang and
                  Fu Xiao},
	title = {Cooperative Jamming-Aided Secure Communication in Wireless Powered
                  Sensor Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {764--774},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3262040},
	doi = {10.1109/TDSC.2023.3262040},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GuiZZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cooperative jamming (CJ) is a promising technique for enhancing the physical-layer security in wireless powered sensor networks. The secrecy performance of CJ-aided wireless powered sensor networks is affected by three issues including disguised eavesdropper as cooperative node, estimation error of the channel between sink node and each sensor node, and distance-related limitation on the transmit power of cooperative nodes. To address the above issues, this paper proposes a CJ-aided secure communication scheme for wireless powered sensor networks with disguised eavesdropper and imperfect channel estimation. Since each cooperative node could be the disguised eavesdropper, the proposed scheme incorporates all possible cases of the eavesdropper disguising itself as unfixed cooperative jamming node. The maximization of secrecy rate over all possible cases is formulated for designing secrecy optimization problem. The imperfect channel estimation and distance-related jamming power limitation are both integrated as constraints into the secrecy rate maximization problem. Since the original optimization problem is complex and non-convex, a two-level optimization algorithm is proposed to solve it. Simulation results show that the proposed scheme achieves significant secrecy rate improvement over typical existing schemes.}
}


@article{DBLP:journals/tdsc/ZhangLLYZKG24,
	author = {Zijian Zhang and
                  Xuyang Liu and
                  Meng Li and
                  Hao Yin and
                  Liehuang Zhu and
                  Bakh Khoussainov and
                  Keke Gai},
	title = {{HCA:} Hashchain-Based Consensus Acceleration Via Re-Voting},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {775--788},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3262283},
	doi = {10.1109/TDSC.2023.3262283},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangLLYZKG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the context of consortium blockchain, consensus protocols set permission mechanisms to maintain a relatively fixed group of participants. They can easily use distributed consistent algorithms for achieving deterministic and efficient consensus and generate incessant blocks as the ledger. However, most of the existing consensus protocols do not sufficiently leverage the chain structure of blocks, and therefore leaving room for performance improvement. In this paper, we first propose a Hashchain-based Consensus Acceleration (HCA) protocol. The HCA protocol enables a leader to generate blocks that contain a quorum of votes on the previous block, and allow voters to re-vote for accelerating the block generation to Byzantine Fault Tolerance (BFT) consensus protocols. Then, we present a rolling-based leader selection (RLS) scheme to further optimize the HCA protocol. In the RLS scheme, the leader is changed in a round-robin fashion. Finally, theoretical analysis proves the safety, liveness and responsiveness of the optimized HCA protocol, while experimental evaluation shows that the optimized HCA protocol outperforms the existing BFT consensus protocols, from the viewpoint of efficiency.}
}


@article{DBLP:journals/tdsc/ZhengZWHJYW24,
	author = {Yifeng Zheng and
                  Menglun Zhou and
                  Songlei Wang and
                  Hejiao Huang and
                  Xiaohua Jia and
                  Xun Yi and
                  Cong Wang},
	title = {SecDR: Enabling Secure, Efficient, and Accurate Data Recovery for
                  Mobile Crowdsensing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {789--803},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3262268},
	doi = {10.1109/TDSC.2023.3262268},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhengZWHJYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile crowdsensing (MCS) has rapidly emerged as a popular paradigm for sensory data collection and benefited various location-based services and applications like road monitoring, smart transportation, and environmental monitoring. In practice, there often exist data-missing regions in the target sensing area, due to factors like limited budget, large area size, and scarcity of participants. This poses a demand for data recovery, which is commonly done based on the compressive sensing (CS) technique. However, CS-based data recovery requires access to sensory data tagged with locations, raising critical concerns on participants’ location privacy. While a plethora of location privacy techniques exist, most of them breach the data correlation inherently required by CS-based data recovery. Meanwhile, existing works mostly focus on protecting locations and overlook sensory data which may also indirectly lead to location leakages. In this paper, we propose SecDR, a new system design supporting secure, efficient, and accurate data recovery for location-based MCS applications. SecDR protects both locations and sensory data, and is built from a delicate synergy of CS-based data recovery and lightweight cryptography techniques. Extensive evaluations demonstrate that SecDR achieves promising performance and, even with stronger security guarantees, outperforms the state-of-the-art, with accuracy close to the plaintext domain.}
}


@article{DBLP:journals/tdsc/PietrantuonoFP24,
	author = {Roberto Pietrantuono and
                  Massimo Ficco and
                  Francesco Palmieri},
	title = {Testing the Resilience of MEC-Based IoT Applications Against Resource
                  Exhaustion Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {804--818},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3263137},
	doi = {10.1109/TDSC.2023.3263137},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/PietrantuonoFP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-access Edge Computing (MEC) is an emerging computing model that provides the necessary on-demand resources and services to the edge of the network, ensuring powerful computing, storage capacity, mobility, location, and context awareness support to emerging Internet of Things (IoT) applications. Nonetheless, its complex hierarchical model introduces new architectural interdependencies, which can influence the resilience of IoT applications against cyber attacks. Although application resilience has been investigated in the context of cloud computing, existing studies are not directly applicable to such an extended edge-cloud paradigm. The use of different enabling technologies at the edge of the network, such as various wireless access technologies and virtualization, implies several threats and challenges that make the analysis and deployment of resilience mechanisms a technically challenging problem. In this article, we first present an overview of the threat model, describing the threats for the different layers of this paradigm. We then study the impact of resource-exhausting attacks – a particularly relevant class for this paradigm - on three different IoT applications exploiting the services offered by the MEC-based architecture. We adopt a testing-based methodology conceived to characterize the resilience of such applications under attack. A set of most important resilience-related indicators are also identified. The characterization's results are useful to support the analyst in planning proper protection means at individual architectural layers.}
}


@article{DBLP:journals/tdsc/SiaJSB24,
	author = {Jayson Sia and
                  Edmond A. Jonckheere and
                  Laith Shalalfeh and
                  Paul Bogdan},
	title = {Phasor Measurement Unit Change-Point Detection of Frequency Hurst
                  Exponent Anomaly With Time-to-Event},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {819--827},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3262825},
	doi = {10.1109/TDSC.2023.3262825},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SiaJSB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The objective of this article is real-time detection of a change-point in the baseline distribution of the frequency signal generated by Phasor Measurement Units (PMUs) that could indicate potential for voltage collapse, false data injection, or other security threats. The alarm flags an anomaly event when the cumulative sum (CUSUM) of the log-likelihood departures of the Hurst exponent of the frequency from its baseline statistic exceeds a threshold set up as a compromise between the conflicting objectives of minimum detection delay and acceptable False Alarm Rate. As main theoretical contribution, an extra protection layer is developed that provides an estimate of the time to the alarm event, giving the Transmission System Operator (TSO) or an autonomous agent more time to deploy proactive measures to avoid large catastrophic system states. The proposed method is illustrated by a retrospective analysis of the 2012 Indian blackout that reveals that 10-12 minutes before the voltage collapse, a significant increase in the Hurst exponent of the frequency could have been detected. Conceptually, this shows that PMUs provide significant value towards ensuring autonomous cognition in the power grid by enabling the abnormal events to be fault-detected in an unsupervised fashion.}
}


@article{DBLP:journals/tdsc/OzbayL24,
	author = {Cavit {\"{O}}zbay and
                  Albert Levi},
	title = {Blacklisting Based Anonymous Authentication Scheme for Sharing Economy},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {828--846},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3263742},
	doi = {10.1109/TDSC.2023.3263742},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/OzbayL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Authentication and blacklisting mechanisms have a key role for service providers to deliver the service to correct users through digital channels. Nevertheless, there always have been concerns about privacy of the users against such mechanisms. The conditional anonymity concept is proposed as a remedy to these concerns. A recent approach in the literature for conditional anonymity is blacklistable anonymous credentials, which allows service providers to blacklist users for an authentication session without identifying the user. In this paper, we improve user anonymity in conditionally anonymous schemes using two complementary mechanisms. First, we define whitelisting property for blacklistable anonymous credentials and give a construction of this scheme. The whitelisting property can be used to unlink an honestly behaved authentication session from the user. Second, we propose an extension of this scheme for a particular use case, sharing economy services. This scheme allows a service provider to blacklist a user only if the user have not returned the shared asset in due time. We benchmark the performance of our schemes by comparing them with the rival schemes. Our experiments show that both of our scheme have comparable performance to previous works.}
}


@article{DBLP:journals/tdsc/HanYWW24,
	author = {Xiao Han and
                  Yuncong Yang and
                  Leye Wang and
                  Junjie Wu},
	title = {Privacy-Preserving Network Embedding Against Private Link Inference
                  Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {847--859},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3264110},
	doi = {10.1109/TDSC.2023.3264110},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HanYWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network embedding represents network nodes by a low-dimensional informative vector. While it is generally effective for various downstream tasks, it may leak some private information of networks, such as hidden private links. In this work, we address a novel problem of privacy-preserving network embedding against private link inference attacks. Basically, we propose to perturb the original network by adding or removing links, and expect the embedding generated on the perturbed network can leak little information about private links but hold high utility for various downstream tasks. Towards this goal, we first propose general measurements to quantify privacy gain and utility loss incurred by candidate network perturbations; we then design a Privacy-Preserving Network Embedding (i.e., PPNE) framework to identify the optimal perturbation solution with the best privacy-utility trade-off in an iterative way. Furthermore, we propose many techniques to accelerate PPNE and ensure its scalability. For instance, as the skip-gram embedding methods including DeepWalk and LINE can be seen as matrix factorization with closed-form embedding results, we devise efficient privacy gain and utility loss approximation methods to avoid the repetitive time-consuming embedding training for every candidate network perturbation in each iteration. Experiments on real-life network datasets (with up to millions of nodes) verify that PPNE outperforms baselines by sacrificing less utility and obtaining higher privacy protection.}
}


@article{DBLP:journals/tdsc/ZhuZHLFS24,
	author = {Dan Zhu and
                  Hui Zhu and
                  Cheng Huang and
                  Rongxing Lu and
                  Dengguo Feng and
                  Xuemin Shen},
	title = {Efficient and Accurate Cloud-Assisted Medical Pre-Diagnosis With Privacy
                  Preservation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {860--875},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3263974},
	doi = {10.1109/TDSC.2023.3263974},
	timestamp = {Wed, 12 Feb 2025 20:32:58 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhuZHLFS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of cloud computing enables various healthcare institutions to outsource pre-diagnostic models and provide timely and convenient services for patients. However, healthcare institutions and patients have serious concerns about potential privacy leakage as cloud servers cannot be fully trusted. In this paper, a privacy-preserving cloud-assisted medical pre-diagnosis scheme, named NAIAD, is proposed, where patients can securely query the outsourced model and obtain their pre-diagnostic results. Specifically, the pre-diagnostic model is constructed on k-Nearest Neighbor (kNN), and Mahalanobis Distance (MD) is chosen as the similarity metric to achieve high accuracy. Accordingly, a secure MD-based comparison method (SMDC) is designed based on a matrix encryption technique. The method is a basic module of NAIAD that enables cloud servers to compare encrypted medical records and achieve privacy-preserving kNN-based pre-diagnosis with linear complexity. To further improve the computational efficiency, medical records are first clustered and encrypted to construct a hierarchical index tree, then patients can query the tree to speed up the query process. Detailed security analysis indicates NAIAD can resist closeness-same-pattern chosen-plaintext attack, and extensive experiments on real-world and synthetic databases demonstrate NAIAD has high query efficiency and pre-diagnosis accuracy.}
}


@article{DBLP:journals/tdsc/YangXCWZ24,
	author = {Jungang Yang and
                  Liyao Xiang and
                  Pengzhi Chu and
                  Xinbing Wang and
                  Chenghu Zhou},
	title = {Certified Distributional Robustness on Smoothed Classifiers},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {876--888},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3264850},
	doi = {10.1109/TDSC.2023.3264850},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YangXCWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The robustness of deep neural networks (DNNs) against adversarial example attacks has raised wide attention. For smoothed classifiers, we propose the worst-case adversarial loss over input distributions as a robustness certificate. Compared with previous certificates, our certificate better describes the empirical performance of the smoothed classifiers. By exploiting duality and the smoothness property, we provide an easy-to-compute upper bound as a surrogate for the certificate. We adopt a noisy adversarial learning procedure to minimize the surrogate loss to improve model robustness. We show that our training method provides a theoretically tighter bound over the distributional robust base classifiers. Experiments on a variety of datasets further demonstrate superior robustness performance of our method over the state-of-the-art certified or heuristic methods.}
}


@article{DBLP:journals/tdsc/DongWLLLCY24,
	author = {Caiqin Dong and
                  Jian Weng and
                  Ming Li and
                  Jia{-}Nan Liu and
                  Zhiquan Liu and
                  Yudan Cheng and
                  Shui Yu},
	title = {Privacy-Preserving and Byzantine-Robust Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {889--904},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3264697},
	doi = {10.1109/TDSC.2023.3264697},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DongWLLLCY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) trains a model over multiple datasets by collecting the local models rather than raw data, which can help facilitate distributed data analysis in many real-world applications. Since the model parameters can leak information about the training datasets, it is necessary to preserve the privacy of the FL participants’ local models. Furthermore, FL is vulnerable to poisoning attacks which can significantly decrease the model utility. To settle the above issues, we propose a privacy-preserving and Byzantine-robust FL scheme\nΠ\nP2Brofl\nthat maintains robustness in the presence of poisoning attacks and preserves the privacy of local models simultaneously. Specifically,\nΠ\nP2Brofl\nleverages three-party computation (3 PC) to securely achieve a Byzantine-robust aggregation method. To improve the efficiency of privacy-preserving local model selection and aggregation, we propose a maliciously secure top-\nk\nprotocol\nΠ\ntop−k\nthat has low communication overhead. Moreover, we present an efficient maliciously secure shuffling protocol\nΠ\nshuffle\nsince secure shuffling is necessary for our secure top-\nk\nprotocol. The security proof of the scheme is given and experiments on real-world datasets are conducted in this paper. When the proportion of Byzantine participants is 50%, the error rate of the model only increases by 1.05% while it increases by 23.78% without using our protection.}
}


@article{DBLP:journals/tdsc/HeWZWZLY24,
	author = {Yongzhong He and
                  Yiming Wang and
                  Sencun Zhu and
                  Wei Wang and
                  Yunjia Zhang and
                  Qiang Li and
                  Aimin Yu},
	title = {Automatically Identifying {CVE} Affected Versions With Patches and
                  Developer Logs},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {905--919},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3264567},
	doi = {10.1109/TDSC.2023.3264567},
	timestamp = {Thu, 06 Jun 2024 16:56:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HeWZWZLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While vulnerability databases are important sources of information for software security, it is known that information in these databases is inconsistent. How to rectify these incorrect data is a challenging issue. In this article, we employ developer logs and patches to automatically identify vulnerable source code versions that each CVE really affects. Our tool organizes all versions of a piece of software into a version tree, and identifies the first vulnerable version, and the last vulnerable versions in the version tree trunk and branches. For evaluation, we took Linux Kernel as the case study and quantified the error rate of the vulnerable versions reported by the NVD. The total number of vulnerable Linux Kernel versions reported by the NVD was 43,727 (as of September 2020), of which the total number of false positives reached 2,497 and the total number of false negatives reached 9,330, accounting for 5.7% and 21.34%, respectively. In addition, we compare our tool with two vulnerability detection tools and show that our tool could achieve high detection accuracy.}
}


@article{DBLP:journals/tdsc/LiCLXXX24,
	author = {Deqiang Li and
                  Shicheng Cui and
                  Yun Li and
                  Jia Xu and
                  Fu Xiao and
                  Shouhuai Xu},
	title = {{PAD:} Towards Principled Adversarial Malware Detection Against Evasion
                  Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {920--936},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3265665},
	doi = {10.1109/TDSC.2023.3265665},
	timestamp = {Mon, 01 Apr 2024 11:15:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiCLXXX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) techniques can facilitate the automation of malicious software (malware for short) detection, but suffer from evasion attacks. Many studies counter such attacks in heuristic manners, lacking theoretical guarantees and defense effectiveness. In this article, we propose a new adversarial training framework, termed Principled Adversarial Malware Detection (PAD), which offers convergence guarantees for robust optimization methods. PAD lays on a learnable convex measurement that quantifies distribution-wise discrete perturbations to protect malware detectors from adversaries, whereby for smooth detectors, adversarial training can be performed with theoretical treatments. To promote defense effectiveness, we propose a new mixture of attacks to instantiate PAD to enhance deep neural network-based measurements and malware detectors. Experimental results on two Android malware datasets demonstrate: (i) the proposed method significantly outperforms the state-of-the-art defenses; (ii) it can harden ML-based malware detection against 27 evasion attacks with detection accuracies greater than 83.45%, at the price of suffering an accuracy decrease smaller than 2.16% in the absence of attacks; (iii) it matches or outperforms many anti-malware scanners in VirusTotal against realistic adversarial malware.}
}


@article{DBLP:journals/tdsc/GeLSFW24,
	author = {Chunpeng Ge and
                  Zhe Liu and
                  Willy Susilo and
                  Liming Fang and
                  Hao Wang},
	title = {Attribute-Based Encryption With Reliable Outsourced Decryption in
                  Cloud Computing Using Smart Contract},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {937--948},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3265932},
	doi = {10.1109/TDSC.2023.3265932},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/GeLSFW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outsourcing the heavy decryption computation to a cloud service provider has been a promising solution for a resource-constrained mobile device to deploy an attribute-based encryption scheme. However, the current attribute based encryption with outsourced decryption schemes only enable the mobile device to verify whether the cloud service provider has returned a correct decryption result, they lack a mechanism to enable the cloud service provider to escape from a mobile device's wrong claim if it has returned a correct decryption result. This article, for the first time, proposes an attribute based encryption with reliable outsourced decryption scheme using the blockchain smart contract. In the proposed scheme, not only can the mobile device verify whether the cloud service provider has returned a correct decryption result, but also the cloud service provider can escape from a wrong claim if the returned decryption result is correct. Moreover, our system achieves the fairness property, which means the cloud service provider can get the reward from the mobile device if and only if it has returned a correct decryption result. Finally, we conduct an implementation to demonstrate that the proposed scheme is practical and efficient.}
}


@article{DBLP:journals/tdsc/GeSLBLF24,
	author = {Chunpeng Ge and
                  Willy Susilo and
                  Zhe Liu and
                  Joonsang Baek and
                  Xiapu Luo and
                  Liming Fang},
	title = {Attribute-Based Proxy Re-Encryption With Direct Revocation Mechanism
                  for Data Sharing in Clouds},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {949--960},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3265979},
	doi = {10.1109/TDSC.2023.3265979},
	timestamp = {Sun, 19 Jan 2025 13:48:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/GeSLBLF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud computing, which provides adequate storage and computation capability, has been a prevalent information infrastructure. Secure data sharing is a basic demand when data was outsourced to a cloud server. Attribute-based proxy re-encryption has been a promising approach that allows secure encrypted data sharing on clouds. With attribute-based proxy re-encryption, a delegator can designate a set of shared users through issuing a re-encryption key which will be used by the cloud server to transform the delegator's encrypted data to the shared users’. However, the existing attribute-based proxy re-encryption schemes lack a mechanism of revoking users from the sharing set which is critical for data sharing systems. Therefore, in this article, we propose a concrete attribute-based proxy re-encryption with direct revocation mechanism (ABPRE-DR) for encrypted data sharing that enables the cloud server to directly revoke users from the original sharing set involved in the re-encryption key. We implemented the new schemes and evaluated its performance. The experimental results show that the proposed ABPRE-DR scheme is efficient and practical.}
}


@article{DBLP:journals/tdsc/YangWTLWZY24,
	author = {Yaxi Yang and
                  Jian Weng and
                  Yao Tong and
                  Jia{-}Nan Liu and
                  Zhenghao Wu and
                  Leo Yu Zhang and
                  Anjia Yang},
	title = {PriGenX: Privacy-Preserving Query With Anonymous Access Control for
                  Genomic Data},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {961--974},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3266292},
	doi = {10.1109/TDSC.2023.3266292},
	timestamp = {Mon, 01 Apr 2024 11:15:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YangWTLWZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Presently, similar sequence search is a fundamental technique in genomic data research. Patients or researchers, who want to check whether they or their research objects have genetic diseases or potential illnesses, need to query similar sequences with their genes in certain genomic databases. As a consequence, this may raise privacy issues since the genomic data are regarded as an identifier of each individual and contain lots of sensitive information. Up to date, some solutions have been brought up for achieving secure similarity search over genomic data, but they are still defective in searching exact similar sequences, supporting fine-grained access control, preventing side information leakage, and being built on strong security models at the same time. In this paper, aiming at the above challenge, we propose a maliciously secure similar sequence search scheme with fine-grained access control over genomic data, named PriGenX. Based on oblivious transfer and authenticated garbling techniques, our scheme also supports secure access control with anonymity for protecting the identity of each party preventing side information leakage, and implementing a flexible over-threshold similarity search. Experimental results and security analysis indicate that our scheme is scalable and maliciously secure.}
}


@article{DBLP:journals/tdsc/FerreroM24,
	author = {Renato Ferrero and
                  Bartolomeo Montrucchio},
	title = {Banknote Identification Through Unique Fluorescent Properties},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {975--986},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3267166},
	doi = {10.1109/TDSC.2023.3267166},
	timestamp = {Sat, 08 Jun 2024 13:14:27 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/FerreroM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of printed banknotes is widespread despite cashless payment methods: for example, more than 27 billion euro banknotes are currently in circulation, and this amount is constantly increasing. Unfortunately, many false banknotes are in circulation, too. Central banks worlwide are continuously striving to reduce the counterfeiting. To fight against the criminal practice, a range of security features are added to banknotes, such as watermarks, micro-printing, holograms, and embossed characters. Beside these well-known characteristics, the colored fibers inside every banknote have strong potential as a security feature, but have so far been poorly exploited. The mere presence of colored fibers does not guarantee the banknote genuineness, as they can be drawn or printed by counterfeiters. However, their random position can be exploited to uniquely identify the banknote. This article presents a technique for automatically recognizing fibers and efficiently storing their positions, considering realistic application scenarios. The classification accuracy and fault tolerance of the proposed method are theoretically demonstrated, thus showing its applicability regardless of banknote wear or any implementation issue. This is a major advantage with respect to state-of-the-art anti-counterfeit approaches. The proposed security method is strictly topical, as the European Central Bank plans to redesign euro banknotes by 2024.}
}


@article{DBLP:journals/tdsc/MaioranaRSM24,
	author = {Emanuele Maiorana and
                  Chiara Romano and
                  Emiliano Schena and
                  Carlo Massaroni},
	title = {{BIOWISH:} Biometric Recognition Using Wearable Inertial Sensors Detecting
                  Heart Activity},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {2},
	pages = {987--1000},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3268360},
	doi = {10.1109/TDSC.2023.3268360},
	timestamp = {Sat, 08 Jun 2024 13:14:27 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MaioranaRSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wearable devices have been recently proposed to perform biometric recognition, leveraging on the uniqueness of the collectable physiological traits to generate discriminative identifiers. Most of the studies conducted on this topic have exploited heart-related signals, sensing the cardiac activity either through electrical measurements using electrocardiography, or with optical recordings employing photoplethysmography. In this article we instead propose a system performing BIOmetric recognition using Wearable Inertial Sensors detecting Heart activity (BIOWISH). In more detail, we investigate the feasibility of exploiting mechanical measurements obtained through seismocardiography and gyrocardiography to verify the identity of a subject. Several feature extractors and classifiers, including deep learning techniques relying on siamese training, are employed to derive distinctive characteristics from the considered signals, so as to differentiate between legitimate users and impostors. A multi-session database, comprising acquisitions taken from subjects performing different activities, is employed to perform experimental tests. The obtained results testify that identifiers derived from measurements of chest vibrations, collected by wearable inertial sensors, could be employed to guarantee high recognition performance, even when considering short-time recordings. Explainability methods have been also employed to derive some insights about the aspects relevant to perform predictions for both people and activity recognition tasks.}
}


@article{DBLP:journals/tdsc/LiLFHHLRQ24,
	author = {Xiaochen Li and
                  Weiran Liu and
                  Hanwen Feng and
                  Kunzhe Huang and
                  Yuke Hu and
                  Jinfei Liu and
                  Kui Ren and
                  Zhan Qin},
	title = {Privacy Enhancement Via Dummy Points in the Shuffle Model},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1001--1016},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3263162},
	doi = {10.1109/TDSC.2023.3263162},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiLFHHLRQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The shuffle model is recently proposed to address the issue of severe utility loss in Local Differential Privacy (LDP) due to distributed data randomization. In the shuffle model, a shuffler is utilized to break the link between the user identity and the message uploaded to the data analyst. Since less noise needs to be introduced to achieve the same privacy guarantee, following this paradigm, the utility of privacy-preserving data collection is improved. We propose DUMP (DUMmy-Point-based), a framework for privacy-preserving histogram estimation in the shuffle model. The core of DUMP is a new concept of dummy blanket, which enables enhancing privacy by just introducing dummy points on the user side and further improving the utility of the shuffle model. We instantiate DUMP by proposing two protocols: pureDUMP and mixDUMP, and conduct a comprehensive experimental evaluation to compare them with existing protocols. The experimental results show that, under the same privacy guarantee, (1) the proposed protocols have significant improvements in communication efficiency over all existing multi-message protocols, by at least 3 orders of magnitude; (2) they achieve competitive utility, while the only known protocol (Ghazi et al. PMLR 2020) having better utility than ours employs hard-to-exactly-sample distributions which are vulnerable to floating-point attacks (CCS 2012).}
}


@article{DBLP:journals/tdsc/GangulyKB24,
	author = {Ritam Ganguly and
                  Shokufeh Kazemloo and
                  Borzoo Bonakdarpour},
	title = {Crash-Resilient Decentralized Synchronous Runtime Verification},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1017--1031},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3265566},
	doi = {10.1109/TDSC.2023.3265566},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GangulyKB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Runtime verification is a technique, where a monitor process extracts information from a running system in order to evaluate whether system executions violate or satisfy a given correctness specification. In this article, we consider runtime verification of synchronous distributed systems, where a set of decentralized monitors that only have a partial view of the system are subject to crash failures. In this context, it is unavoidable that monitors may have different views of the underlying system, and, therefore, have different opinions about the correctness property. We propose an automata-based synchronous monitoring algorithm that copes with t crash monitor failures. In our proposed approach, local monitors do not communicate their explicit reading of the underlying system. Rather, they emit a symbolic verdict that efficiently encodes their partial views. This significantly reduces the communication overhead. To this end, we also introduce an (offline) SMT-based monitor synthesis algorithm, which results in minimizing the size of monitoring messages. We evaluate our algorithm on a wide range of formulas and observe an average of 2.5 times increase in the number of states of the monitor automaton.}
}


@article{DBLP:journals/tdsc/ZhangZZ24,
	author = {Xiaokuan Zhang and
                  Yang Zhang and
                  Yinqian Zhang},
	title = {VeriTrain: Validating MLaaS Training Efforts via Anomaly Detection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1032--1049},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3266427},
	doi = {10.1109/TDSC.2023.3266427},
	timestamp = {Mon, 07 Oct 2024 08:28:30 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning as a service (MLaaS) offers users the benefit of training state-of-the-art neural network models on fast hardware with low costs. However, it also brings security concerns since the user does not fully trust the cloud. To prove to the user that the ML training results are legitimate, existing approaches mainly adopt cryptographic techniques such as secure multi-party computation, which incur large overheads. In this paper, we model the problem of verifying ML training efforts as an anomaly detection problem. We design a verification system, dubbed VeriTrain, which combines unsupervised anomaly detection approaches and hypothesis testing techniques to verify the legitimacy of training efforts on the MLaaS cloud. VeriTrain is run inside trusted execution environments (TEEs) on the same cloud machine to ensure the integrity of its execution. We consider a threat model where the cloud model trainer is a lazy attacker and tries to fool VeriTrain with minimum training effort. We perform extensive evaluations on multiple neural network models and datasets, which shows that VeriTrain performs well in detecting parameter updates crafted by the attacker. We also implement VeriTrain with Intel SGX and show that it only incurs moderate overheads.}
}


@article{DBLP:journals/tdsc/DingHQLGCC24,
	author = {Zikang Ding and
                  Daojing He and
                  Qi Qiao and
                  Xuru Li and
                  Yun Gao and
                  Sammy Chan and
                  Kim{-}Kwang Raymond Choo},
	title = {A Lightweight and Secure Communication Protocol for the IoT Environment},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1050--1067},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3267979},
	doi = {10.1109/TDSC.2023.3267979},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DingHQLGCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ensuring secure communications for the Internet of Things (IoT) systems remains a challenge. Due to exacting resource limitations of computing, memory, and communication in IoT environments, communication schemes based on asymmetric cryptographic systems can be challenging to deploy. An alternative is to deploy symmetric encryption schemes based on pre-shared keys. However, there are also challenges in designing such schemes and examples include how to achieve an optimal trade-off between security and performance levels while meeting resource consumption requirements, especially when adding some of these devices to the blockchain. Hence, this paper presents a lightweight key synchronization update algorithm, which is then used as a building block in our proposed lightweight secure communication protocol. The security of the protocol is analyzed to show that it can resist common attacks, such as replay attacks, and man-in-the-middle attacks. We then use Tamarin, a widely accepted security protocol verification tool, for formal verification. In addition, we evaluate the randomness and computational performance of the lightweight key synchronization update algorithm and demonstrate that it outperforms other schemes. We also evaluate the performance of the protocol, in terms of computational and communication costs, to demonstrate utility.}
}


@article{DBLP:journals/tdsc/XingWTZLS24,
	author = {Yunlong Xing and
                  Xinda Wang and
                  Sadegh Torabi and
                  Zeyu Zhang and
                  Lingguang Lei and
                  Kun Sun},
	title = {A Hybrid System Call Profiling Approach for Container Protection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1068--1083},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3268124},
	doi = {10.1109/TDSC.2023.3268124},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XingWTZLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over-privileged Linux containers might put the underlying OS at risk by permitting pointless system calls that could be exploited as entry points to the kernel. However, finding such security profiles is a difficult task as it demands examining the implementation/operation of containers in the absence of knowledge regarding its required system calls. In this article, we propose a hybrid approach to limit the system call usage during the execution of containers. Specifically, given an application container, we maintain an initial fine-grained whitelist by dynamic tracking to control the run-time security along with a complementary whitelist extracted via static analysis to maintain container's functionality while addressing the coverage limitation of dynamic analysis. Our method automatically analyzes the container behavior to identify three execution phases and dynamically enforce the corresponding fine-grained system call whitelists. The invoked system call will be compared with both whitelists to decide if it should be killed to guarantee the container security or logged for further analysis. Our evaluation results with 193 Docker images demonstrate the effectiveness of our approach in significantly reducing the required system calls during the applications’ life-cycle. Furthermore, we discuss the reduced attack surface and demonstrate the efficiency of our approach through empirical analysis results.}
}


@article{DBLP:journals/tdsc/VugrinHCGTP24,
	author = {Eric D. Vugrin and
                  Seth Hanson and
                  Jerry Cruz and
                  Casey Glatter and
                  Thomas D. Tarman and
                  Ali Pinar},
	title = {Experimental Validation of a Command and Control Traffic Detection
                  Model},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1084--1097},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3266139},
	doi = {10.1109/TDSC.2023.3266139},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/VugrinHCGTP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network intrusion detection systems (NIDS) are commonly used to detect malware communications, including command-and-control (C2) traffic from botnets. NIDS performance assessments have been studied for decades, but mathematical modeling has rarely been used to explore NIDS performance. This paper details a mathematical model that describes a NIDS performing packet inspection and its detection of malware's C2 traffic. The paper further describes an emulation testbed and a set of cyber experiments that used the testbed to validate the model. These experiments included a commonly used NIDS (Snort) and traffic with contents from a pervasive malware (Emotet). Results are presented for two scenarios: a nominal scenario and a “stressed” scenario in which the NIDS cannot process all incoming packets. Model and experiment results match well, with model estimates mostly falling within 95\\%\nconfidence intervals on the experiment means. Model results were produced 70-3000 times faster than the experimental results. Consequently, the model's predictive capability could potentially be used to support decisions about NIDS configuration and effectiveness that require high confidence results, quantification of uncertainty, and exploration of large parameter spaces. Furthermore, the experiments provide an example for how emulation testbeds can be used to validate cyber models that include stochastic variability.}
}


@article{DBLP:journals/tdsc/ZhengHZG24,
	author = {Jian Zheng and
                  Huawei Huang and
                  Zibin Zheng and
                  Song Guo},
	title = {Adaptive Double-Spending Attacks on PoW-Based Blockchains},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1098--1110},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3268668},
	doi = {10.1109/TDSC.2023.3268668},
	timestamp = {Sun, 19 Jan 2025 13:48:33 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhengHZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Previous state-of-the-art studies have proposed various analytical models to understand the double-spending attacks (DSA) occurred in Proof-of-Work (PoW) based Blockchains. Although many insights behind the double-spending attacks have been disclosed, we still believe that advanced versions of DSA can be developed to create new threats for the PoW-based blockchains such as the Bitcoin blockchain. In this paper, we present two new types of double-spending attacks in the context of the PoW-based blockchain and discuss the insights behind them. By considering more practical network parameters, such as the number of confirmation blocks, the hashpower of the double-spending attacker, the amount of coins in the target transaction, and the network-status parameter, we first analyze the success probability of the conventional double-spending attack, named Naive DSA. Based on Naive DSA, we create two new adaptive DSA, i.e., the Adaptive DSA and the Reinforcement Adaptive DSA (RA-DSA). In our analytical models, a double-spending attack is converted into a Markov Decision Process. We then exploit the Stochastic Dynamic Programming (SDP) approach to obtain the optimal attack strategies under Adaptive DSA and RA-DSA. Numerical simulation results demonstrate the correlations between each critical network parameter and the expected attacker's reward. Through the proposed analytical models, we aim to alert the PoW-based blockchain ecosystem that the threat of double-spending attacks is still at a dangerous level. For example, our findings show that the attacker can launch a successful attack with a small hashpower proportion much lower than 51% under RA-DSA.}
}


@article{DBLP:journals/tdsc/LvWSWQC24,
	author = {Chunyang Lv and
                  Jianfeng Wang and
                  Shifeng Sun and
                  Yunling Wang and
                  Saiyu Qi and
                  Xiaofeng Chen},
	title = {Towards Practical Multi-Client Order-Revealing Encryption: Improvement
                  and Application},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1111--1126},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3268652},
	doi = {10.1109/TDSC.2023.3268652},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LvWSWQC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Order-revealing encryption (ORE) enables the untrusted server to perform greater-than-comparison over ciphertext without compromising data privacy, which allows anyone to evaluate the lexicographic ordering of two arbitrary ciphertexts with a public comparison algorithm. However, most ORE constructions merely support ciphertext comparison for single-user. Recently, a variant of ORE named delegatable ORE has been introduced, which achieves cross-user ciphertext comparison by employing token mutual authorization technique at the cost of weak security, i.e., reveals the most significant differing bit of underlying plaintexts. To tackle this problem, we first present a deterministic property-preserving hash called DPPH with short-size hash value, and then propose a novel multi-client ORE scheme (m-ORE) from DPPH that supports ciphertext comparison among multiple users while hiding the most significant differing bits. Furthermore, we present an enhanced construction dubbed m-H-ORE by introducing a two-phase comparison method, which can achieve supper-efficient comparison in some cases, i.e., two ciphertexts with different bit-length. Finally, we provide formal security proofs of the proposed schemes and run extensive experiments to evaluate their performance on real-world and synthetic datasets. The results demonstrate that both of the proposed schemes can achieve a speedup of 47× and 138× in comparison cost to that of parameter-hiding ORE, respectively.}
}


@article{DBLP:journals/tdsc/VhaduriCD24,
	author = {Sudip Vhaduri and
                  William Cheung and
                  Sayanton V. Dibbo},
	title = {Bag of On-Phone ANNs to Secure IoT Objects Using Wearable and Smartphone
                  Biometrics},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1127--1138},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3269037},
	doi = {10.1109/TDSC.2023.3269037},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/VhaduriCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The introduction of the Internet of Things (IoT) has made several emerging applications, from financial transactions to property access, possible through IoT-connected smart wearables (smartwatches). This creates an immediate need for an authentication system that can validate a user seamlessly, compared to knowledge-based approaches. In this work, we present an implicit authentication system that utilizes a bag of on-phone artificial neural network (ANN) models to validate a user based on the availability of three soft-biometrics (heart rate, gait, and breathing patterns) collected from smartphones and Fitbits. We find that using all three biometrics we can achieve an average accuracy of up to\n.973±.004\n. Next, we implement the bag of models on smartphones using Google's TensorFlow Lite framework-supported TFL Auth application, which requires around 56-65 KB memory and can verify a user in 5 seconds. Finally, we evaluate the system TFL Auth using two cohorts of 25 subjects in total, and we find that the system has average understandability and importance scores of around 4.0 and 4.3 on a 1–5 scale.}
}


@article{DBLP:journals/tdsc/WangLYML24,
	author = {Yuchen Wang and
                  Xiaoguang Li and
                  Li Yang and
                  Jianfeng Ma and
                  Hui Li},
	title = {{ADDITION:} Detecting Adversarial Examples With Image-Dependent Noise
                  Reduction},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1139--1154},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3269012},
	doi = {10.1109/TDSC.2023.3269012},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WangLYML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Notwithstanding the tremendous success of deep neural networks in a range of realms, previous studies have shown that these learning models are exposed to an inherent hazard called adversarial example — images to which an elaborate perturbation is maliciously added could deceive a network, which entails the study of countermeasures urgently. However, existing solutions suffer from some weaknesses, e.g., parameters are usually determined empirically in some processing-based detection methods might result in a sub-optimal effect, and the directly performed processing on images might affect the classification of benign samples, leading to increment of false positive. In this paper, we propose a novel imAge-DepenDent noIse reducTION (ADDITION) model based on deep learning for adversarial detection. The ADDITION model can adaptively convert the adversarial perturbation in each image to approximate Gaussian noise by injecting image-dependent additional noise, then perform noise reduction to eliminate the adversarial perturbation, and finally detect adversarial examples by examining the classification inconsistency between the input image and its denoised version. The ADDITION model is trained end-to-end on benign samples without any prior knowledge of adversarial attacks, and thus avoid time-consuming task of generating adversarial examples in practical use. We generate more than 220,000 adversarial examples based on six attack algorithms for evaluation and present state-of-the-art comparisons on three real-word datasets. Extensive experiments demonstrate that our proposed method achieves improved performance in both detection accuracy rate and false positive rate.}
}


@article{DBLP:journals/tdsc/MaQGZAXFZAA24,
	author = {Hua Ma and
                  Huming Qiu and
                  Yansong Gao and
                  Zhi Zhang and
                  Alsharif Abuadbba and
                  Minhui Xue and
                  Anmin Fu and
                  Jiliang Zhang and
                  Said F. Al{-}Sarawi and
                  Derek Abbott},
	title = {Quantization Backdoors to Deep Learning Commercial Frameworks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1155--1172},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3271956},
	doi = {10.1109/TDSC.2023.3271956},
	timestamp = {Wed, 16 Oct 2024 16:36:24 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MaQGZAXFZAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work reveals that standard quantization toolkits can be abused to activate a backdoor. We demonstrate that a full-precision backdoored model which does not have any backdoor effect in the presence of a trigger—as the backdoor is dormant—can be activated by (i) TensorFlow-Lite (TFLite) quantization, the only product-ready quantization framework to date, and (ii) the beta released PyTorch Mobile framework. In our experiments, we employ three popular model architectures (VGG16, ResNet18, and ResNet50), and train each across three popular datasets: MNIST, CIFAR10 and GTSRB. We ascertain that all trained float-32 backdoored models exhibit no backdoor effect even in the presence of trigger inputs. Particularly, four influential backdoor defenses are evaluated, and they fail to identify a backdoor in the float-32 models. When each of the float-32 models is converted into an int-8 format model through the standard TFLite or PyTorch Mobile framework's post-training quantization, the backdoor is activated in the quantized model, which shows a stable attack success rate close to 100% upon inputs with the trigger, while it usually behaves upon non-trigger inputs. This work highlights that a stealthy security threat occurs when an end-user utilizes the on-device post-training model quantization frameworks, informing security researchers of a cross-platform overhaul of DL models post-quantization even if these models pass security-aware front-end backdoor inspections. Significantly, we have identified Gaussian noise injection into the malicious full-precision model as an easy-to-use preventative defense against the PQ backdoor.}
}


@article{DBLP:journals/tdsc/Pandith24,
	author = {Omais Shafi Pandith},
	title = {SGXFault: An Efficient Page Fault Handling Mechanism for {SGX} Enclaves},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1173--1178},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3268169},
	doi = {10.1109/TDSC.2023.3268169},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Pandith24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trusted Execution Environments (TEEs) such as Intel SGX are becoming a commonplace for the security in server processors. Intel SGX provides the guarantees of confidentiality, integrity and replay attack protection for a specific region of memory. However, the downside of it is the performance bottleneck due to the context switching overhead and the page faults for the larger memory footprint applications. In this article, we propose a scheme SGXFault which ensures for major part of the execution, the pages are available in the secure memory when needed. We do this decision at the last level cache (LLC) by locking the blocks of the frequent pages to the LLC using Cache Lockdown mechanism. In addition to this, we do a page-level prediction based prefetching when there is a miss in the LLC. Using the combination of both the approaches, we are able to outperform baseline Intel SGX and recent competing scheme by around 18.6% and 17.8% respectively.}
}


@article{DBLP:journals/tdsc/LiLQZSM24,
	author = {Teng Li and
                  Ximeng Liu and
                  Wei Qiao and
                  Xiongjie Zhu and
                  Yulong Shen and
                  Jianfeng Ma},
	title = {T-Trace: Constructing the APTs Provenance Graphs Through Multiple
                  Syslogs Correlation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1179--1195},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3273918},
	doi = {10.1109/TDSC.2023.3273918},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiLQZSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced Persistent Threats (APTs) employ sophisticated and covert tactics to infiltrate target systems, leading to increased vulnerability and an elevated risk of exposure. Consequently, it is essential for us to proactively create an extensive and clearly outlined attack chain for APTs in order to effectively combat these threats. Unlike traditional malware or application threats, APTs can sidestep cyber security efforts and cause severe damage to organizations or even state security. Nonetheless, earlier methods struggle to accurately track APTs and may face a dependency explosion issue, as identifying the intricate and complex unknown malicious activities within APTs proves to be challenging. In this paper, we propose and build an approach, T-trace, which constructs the events provenance graphs by analyzing the correlations among logs. The approach precisely finds the log communities with tensor decomposition and calculates significance scores to extract the events. The APTs can be inferred by discovering the event communities and constructing the provenance graph with log correlation. In the experiment, we used DARPA data sets and launched four current practical APTs. Compared with current approaches, the results show that T-trace can efficiently reduce time cost by 90% and achieve a 92% accuracy rate in constructing the provenance graph, which can be practically applied in APTs provenance.}
}


@article{DBLP:journals/tdsc/WeiLDMJP24,
	author = {Kang Wei and
                  Jun Li and
                  Ming Ding and
                  Chuan Ma and
                  Yo{-}Seb Jeon and
                  H. Vincent Poor},
	title = {Covert Model Poisoning Against Federated Learning: Algorithm Design
                  and Optimization},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1196--1209},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3274119},
	doi = {10.1109/TDSC.2023.3274119},
	timestamp = {Thu, 14 Nov 2024 14:45:54 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WeiLDMJP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL), as a type of distributed machine learning, is vulnerable to external attacks during parameter transmissions between learning agents and a model aggregator. In particular, malicious participant clients in FL can purposefully craft their uploaded model parameters to manipulate system outputs, which is know as a model poisoning (MP) attack. In this paper, we propose effective MP algorithms to attack the classical defensive aggregation Krum at the aggregator. The proposed algorithms are designed to evade detection, i.e., covert MP (CMP). Specifically, we first formulate the MP as an optimization problem by minimizing the Euclidean distance between the manipulated model and designated one, constrained by Krum. Then, we develop CMP algorithms against Krum based on the solutions of this optimization problem. Furthermore, to reduce the optimization complexity, we propose low complexity CMP algorithms having only a slight performance degradation. Our experimental results demonstrate that the proposed CMP algorithms are effective and can substantially outperform existing attack mechanisms, such as Arjun's attack and the label flipping attack. More specifically, our original CMP can achieve a high rate of the attacker's accuracy (\\approx 90\\%). For example, in our experiments using the MNIST dataset, the proposed CMP attacking algorithm against Krum can successfully manipulate the aggregated model to incorrectly classify a given digit as a different one (e.g., 9 as 8). Meanwhile, our CMP algorithm with an approximated constraint can achieve a rate of 87% in terms of the attacker's accuracy (attacker-desired results), with a 73% complexity reduction compared to the original CMP.}
}


@article{DBLP:journals/tdsc/TanYLHC24,
	author = {Shuaishuai Tan and
                  Shui Yu and
                  Wenyin Liu and
                  Daojing He and
                  Sammy Chan},
	title = {You Can Glimpse but You Cannot Identify: Protect IoT Devices From
                  Being Fingerprinted},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1210--1223},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3275850},
	doi = {10.1109/TDSC.2023.3275850},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/TanYLHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With pervasive IoT networking, traffic-analysis-based IoT fingerprinting techniques have been well researched. For example, by integrating blockchain technology and device fingerprinting, authentication of devices connected to a network can be achieved. Though the primary motivations are identifying vulnerabilities and implementing access control, the techniques could be exploited to trace IoT users’ privacy. We propose a traffic morphing scheme to protect IoT devices from being identified by fingerprinting models. The scheme mainly consists of a morphing policy learning algorithm, a rewarding model, and a time-series-based feature estimation algorithm. Backed by the timely rewarding model, a learning agent produces an optimal policy that perturbs the target fingerprinting model while preserving the original traffic function. The estimation algorithm predicts the feature vectors of unfinished flows to enable live traffic morphing. The scheme's advantage is that it requires minimal knowledge of the fingerprinting model and supports live morphing. Experimental results show that over 81% of the IoT devices become unidentifiable, and the scheme degrades the average F1 score of mainstream fingerprinting models from 0.996 to 0.526. For certain devices and target models, the scheme even reaches 100% effectiveness.}
}


@article{DBLP:journals/tdsc/LeeSNCC24,
	author = {Younho Lee and
                  Jinyeong Seo and
                  Yujin Nam and
                  Jiseok Chae and
                  Jung Hee Cheon},
	title = {HEaaN-STAT: {A} Privacy-Preserving Statistical Analysis Toolkit for
                  Large-Scale Numerical, Ordinal, and Categorical Data},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1224--1241},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3275649},
	doi = {10.1109/TDSC.2023.3275649},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LeeSNCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Statistical analysis of largescale data is useful as it enables the extraction of a large amount of information, despite its simplicity. Therefore, fusing and analyzing data from different security domains is an attractive and promising approach, unless it jeopardizes the privacy of the data in any security domain. In this study, we proposed the HEaaN-STAT toolkit that can efficiently fuse data from different domains to enable largescale statistical analysis while protecting data privacy. Moreover, we proposed an efficient inverse operation and a table lookup function for Cheon-Kim-Kim-Song (CKKS) encrypted data, as well as a data encoding method for counting encrypted data. Based on this, we proposed a method for generating a contingency table with a large number of cases and k-percentile for largescale data that is hundreds to thousands of times faster than the method proposed by Lu et al. in NDSS’17. The validity of the proposed toolkit was verified through practical use for business applications using real-world data.}
}


@article{DBLP:journals/tdsc/ZhangD24,
	author = {Jianhong Zhang and
                  Chenghe Dong},
	title = {On the Security of Lightweight and Escrow-Free Certificate-Based Data
                  Aggregation for Smart Grid},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1242--1243},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3275972},
	doi = {10.1109/TDSC.2023.3275972},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, to eliminate complex certificate maintenance and key escrow issue, Verma et al. proposed the first certificate-based(CB-based) data aggregation scheme for smart grids, in which a lightweight CB-based signature is proposed to ensure the integrity of the transmitted data. Although they claimed that the proposed certificate-based signature scheme is secure against attacks by a malicious certification authority (CA), unfortunately, by analyzing the security of Verma et al.'s scheme, we show that their scheme is insecure. It can not provide data integrity since a malicious CA can forge a message's signature in the name of any entity. After giving the corresponding attacks, we analyze the reasons for producing such attacks and provide the corresponding suggestions to overcome them.}
}


@article{DBLP:journals/tdsc/Tripathi24,
	author = {Nikhil Tripathi},
	title = {Delays Have Dangerous Ends: Slow {HTTP/2} DoS Attacks Into the Wild
                  and Their Real-Time Detection Using Event Sequence Analysis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1244--1256},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3276062},
	doi = {10.1109/TDSC.2023.3276062},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Tripathi24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Jon Postel's robustness principle states that the communicating entities should be liberal while accepting the data. Several web servers on the Internet do follow this principle as they wait to receive the remaining portion of an incomplete web request. Unfortunately, this behaviour also makes them vulnerable to Slow Rate DoS attacks. A few approaches are known to counter Slow Rate DoS attacks against HTTP/1.1. However, those defence approaches are incompatible with HTTP/2 because of several operation differences between HTTP/1.1 and its successor, HTTP/2. Also, to the best of our knowledge, no defence scheme is known to detect Slow Rate DoS attacks against an HTTP/2 supporting web server in real-time. To bridge this gap, in this article, we propose an event sequence analysis-based scheme to detect Slow HTTP/2 DoS attacks. Using extensive experiments, we show that the scheme can detect attacks in real-time with high accuracy and marginal computational overhead. As an aside, we also present a study on the behaviour of popular HTTP/2 servers on the Internet against Slow HTTP/2 DoS attacks. Surprisingly, we noticed that several of them are vulnerable to these attacks, thereby justifying the requirement for an effective real-time detection strategy.}
}


@article{DBLP:journals/tdsc/ZdunQSSCJJ24,
	author = {Uwe Zdun and
                  Pierre{-}Jean Queval and
                  Georg Simhandl and
                  Riccardo Scandariato and
                  Somik Chakravarty and
                  Marjan Jelic and
                  Aleksandar S. Jovanovic},
	title = {Detection Strategies for Microservice Security Tactics},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1257--1273},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3276487},
	doi = {10.1109/TDSC.2023.3276487},
	timestamp = {Sat, 08 Jun 2024 13:14:27 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZdunQSSCJJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microservice architectures are widely used today to implement distributed systems. Securing microservice architectures is challenging because of their polyglot nature, continuous evolution, and various security concerns relevant to such architectures. This article proposes a novel, model-based approach providing detection strategies to address the automated detection of security tactics (or patterns and best practices) in a given microservice architecture decomposition model. Our novel detection strategies are metrics-based rules that decide conformance to a security recommendation based on a statistical predictor. The proposed approach models this recommendation using Architectural Design Decisions (ADDs). We apply our approach for four different security-related ADDs on access management, traffic control, and avoiding plaintext sensitive data in the context of microservice systems. We then apply our approach to a model data set of 10 open-source microservice systems and 20 variants of those systems. Our results are detection strategies showing a very low bias, a very high correlation, and a low prediction error in our model data set.}
}


@article{DBLP:journals/tdsc/TianZHLZLR24,
	author = {Zhihua Tian and
                  Rui Zhang and
                  Xiaoyang Hou and
                  Lingjuan Lyu and
                  Tianyi Zhang and
                  Jian Liu and
                  Kui Ren},
	title = {{\textdollar}\{{\textbackslash}sf FederBoost\}{\textdollar}: Private
                  Federated Learning for {GBDT}},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1274--1285},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3276365},
	doi = {10.1109/TDSC.2023.3276365},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/TianZHLZLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has been an emerging trend in machine learning and artificial intelligence. It allows multiple participants to collaboratively train a better global model and offers a privacy-aware paradigm for model training since it does not require participants to release their original training data. However, existing FL solutions for vertically partitioned data or decision trees require heavy cryptographic operations. In this article, we propose a framework named \\mathsf {FederBoost}\nfor private federated learning of gradient boosting decision trees (GBDT). It supports running GBDT over both vertically and horizontally partitioned data. Vertical \\mathsf {FederBoost}\ndoes not require any cryptographic operation and horizontal \\mathsf {FederBoost}\nonly requires lightweight secure aggregation. The key observation is that the whole training process of GBDT relies on the ordering of the data instead of the values. We fully implement \\mathsf {FederBoost}\nand evaluate its utility and efficiency through extensive experiments performed on three public datasets. Our experimental results show that both vertical and horizontal \\mathsf {FederBoost}\nachieve the same level of accuracy with centralized training where all data are collected in a central server; and they are 4-5 orders of magnitude faster than the state-of-the-art solutions for federated decision tree training; hence offering practical solutions for industrial applications.}
}


@article{DBLP:journals/tdsc/GeYH24,
	author = {Xinrui Ge and
                  Jia Yu and
                  Rong Hao},
	title = {Privacy-Preserving Graph Matching Query Supporting Quick Subgraph
                  Extraction},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1286--1300},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3276360},
	doi = {10.1109/TDSC.2023.3276360},
	timestamp = {Sat, 31 Aug 2024 20:43:29 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GeYH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph matching, as one of the most fundamental problems in graph database, has a wide range of applications. Due to the large scale of graph database and the hardness of graph matching, graph user tends to outsource the encrypted graphs to the cloud. The complex graph matching is performed by the cloud. Several schemes have been proposed to support graph matching query over encrypted graphs. However, none of them can realize efficient subgraph extraction when the matched subgraph needs to be exactly located at the data graph. The graph user has to perform the complex subgraph isomorphism (NP-complete problem) operation to extract the isomorphic subgraph from the matched data graph in state-of-the-art schemes. In order to solve this problem, we propose a privacy-preserving graph matching query scheme supporting quick subgraph extraction in this paper. In our design, two non-colluding cloud servers are adopted to accomplish the matching operation jointly. Neither of them can infer the plaintexts of graphs. Two cloud servers jointly get a matched matrix to represent the matching relationship between vertices in data graph and query graph. Graph user can directly and quickly extract the subgraph isomorphic to query graph from data graph based on the matched matrix. No subgraph isomorphism operation is involved for graph user. The time complexity of subgraph extraction is\nO(\nm\n2\n)\nin our scheme, where\nm\nis the number of vertices in query graph. The extensive experiments with real-world database demonstrate the efficiency of the proposed privacy-preserving graph matching scheme.}
}


@article{DBLP:journals/tdsc/YanNZLGW24,
	author = {Xingfu Yan and
                  Wing W. Y. Ng and
                  Bowen Zhao and
                  Yuxian Liu and
                  Ying Gao and
                  Xiumin Wang},
	title = {Fog-Enabled Privacy-Preserving Multi-Task Data Aggregation for Mobile
                  Crowdsensing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1301--1316},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3277831},
	doi = {10.1109/TDSC.2023.3277831},
	timestamp = {Mon, 16 Sep 2024 10:52:02 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YanNZLGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving data aggregation in mobile crowdsensing (MCS) focuses on mining information from massive sensing data while protecting users’ privacy. The existence of multiple concurrent tasks is common in urban environments, so privacy-preserving multi-task data aggregation is essential and useful to a large-scale crowdsensing server. However, existing privacy-preserving data aggregation schemes in MCS mainly focus on the single-task data aggregation and the privacy protection of user's data. Little attention is paid to the privacy of user's decision of accepting tasks. Therefore, we propose a privacy-preserving and server-oriented efficient multi-task data aggregation scheme for MCS based fog computing. The proposed scheme can aggregate multiple concurrent tasks from multiple requesters (e.g., for 9 tasks, the proposed scheme completes all tasks in one round as opposed to existing schemes, which finish 9 tasks in nine rounds). Our scheme protects the privacy of user's decision, user's data, and aggregation result of each requester under collusion attacks. Through formal security analyses, our scheme is proved to be secure and privacy-preserving. Both theoretical analyses and experiments show our scheme is efficient.}
}


@article{DBLP:journals/tdsc/BlackS24,
	author = {Conor Black and
                  Sandra Scott{-}Hayward},
	title = {Defeating Data Plane Attacks With Program Obfuscation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1317--1330},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3277939},
	doi = {10.1109/TDSC.2023.3277939},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/BlackS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data plane switches in software-defined networks are increasingly recognised as potential targets for attack, with recent exploits showing their vulnerability to full compromise. The serious consequences of such a breach have prompted the design of compromise detection mechanisms, which monitor switch forwarding behaviour at runtime to ensure that it has not been altered by an attack. However, such defences cannot achieve full coverage in stateful, programmable data planes, creating an opportunity for an attacker to evade detection by carefully editing a switch's forwarding program to mishandle a small subset of packets. To exploit this opportunity and avoid detection, an attacker must analyse and edit the program's behaviour within a narrow time window, which is possible when the data plane is defined by a uBPF program compiled from P4, due to the predictable compilation process. In this work, we aim to invalidate this analysis-guided attack technique with targeted obfuscation of P4-uBPF programs that increases the analysis complexity. We find that, by inserting additional program paths and syntactic dependencies between variables, we can force an attacker to analyse a higher proportion of program instructions and carry out time-consuming SMT solving to find valid program paths, rendering the previous attack technique infeasible. Furthermore, by applying our identified program optimisations, program performance can often be maintained after obfuscation. In evaluating our work, we identify the potential to improve our solution by tailoring obfuscations to individual program paths.}
}


@article{DBLP:journals/tdsc/WuWJPBP24,
	author = {Lichao Wu and
                  Yoo{-}Seung Won and
                  Dirmanto Jap and
                  Guilherme Perin and
                  Shivam Bhasin and
                  Stjepan Picek},
	title = {Ablation Analysis for Multi-Device Deep Learning-Based Physical Side-Channel
                  Analysis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1331--1341},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3278857},
	doi = {10.1109/TDSC.2023.3278857},
	timestamp = {Fri, 31 May 2024 21:06:03 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WuWJPBP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of deep learning-based side-channel analysis is an effective way of performing profiling attacks on power and electromagnetic leakages, even against targets protected with countermeasures. While many research articles have reported successful results, they typically focus on profiling and attacking a single device, assuming that leakages are similar between devices of the same type. However, this assumption is not always realistic due to variations in hardware and measurement setups, creating what is known as the portability problem. Profiling multiple devices has been proposed as a solution, but obtaining access to these devices may pose a challenge for attackers. This article proposes a new approach to overcome the portability problem by introducing a neural network layer assessment methodology based on the ablation paradigm. This methodology evaluates the sensitivity and resilience of each layer, providing valuable knowledge to create a Multiple Device Model from Single Device (MDMSD). Specifically, it involves ablating a specific neural network section and performing recovery training. As a result, the profiling model, trained initially on a single device, can be generalized to leakage traces measured from various devices. By addressing the portability problem through a single device, practical side-channel attacks could be more accessible and effective for attackers.}
}


@article{DBLP:journals/tdsc/DumanBEK24,
	author = {Sevtap Duman and
                  Matthias B{\"{u}}chler and
                  Manuel Egele and
                  Engin Kirda},
	title = {PellucidAttachment: Protecting Users From Attacks via E-Mail Attachments},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1342--1354},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3279032},
	doi = {10.1109/TDSC.2023.3279032},
	timestamp = {Fri, 31 May 2024 21:06:04 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DumanBEK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malicious email attachments are a common and successful attack vector on today's Internet. Sophisticated attackers can craft highly-targeted attachments, using publicly available information about potential victims to create convincing documents that contain hidden malicious payloads. Users who open these attachments using vulnerable applications are at a high risk of infection. Unfortunately, current mitigations are unreliable, relying either on fallible malware detection techniques or user education. In this work, we propose adopting a default policy of isolated attachment rendering. Emails bearing attachments are transparently rewritten (in a sandboxed virtual machine environment) to contain static renderings of the attachments. Users who wish to obtain the original attachment are explicitly warned of the dangers of doing so – akin to TLS warnings as used in web browsers – before being allowed to access the requested documents. We implement this technique in a system we call PellucidAttachment . We further report on an extensive user study that measures the usability and effectiveness of PellucidAttachment in shielding users from attacks. Our evaluation shows that adopting email attachment security indicators and an isolation-by-default policy results in a significant increase in user security, while maintaining the usability of email attachments.}
}


@article{DBLP:journals/tdsc/SharmaLMPGG24,
	author = {Shantanu Sharma and
                  Yin Li and
                  Sharad Mehrotra and
                  Nisha Panwar and
                  Peeyush Gupta and
                  Dhrubajyoti Ghosh},
	title = {Prism: Privacy-Preserving and Verifiable Set Computation Over Multi-Owner
                  Secret Shared Outsourced Databases},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1355--1371},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3279356},
	doi = {10.1109/TDSC.2023.3279356},
	timestamp = {Fri, 31 May 2024 21:06:04 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SharmaLMPGG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private set computation over multi-owner databases is an important problem with many applications — the most well studied of which is private set intersection (PSI). This article proposes Prism, a secret-sharing based approach to compute private set operations (i.e., intersection and union, as well as aggregates such as count, sum, average, maximum, minimum, and median) over outsourced databases belonging to multiple owners. Prism enables data owners to pre-load the data onto non-colluding servers and exploits the additive and multiplicative properties of secret-shares to compute the above-listed operations. Prism takes (at most) two rounds of communication between non-colluding servers (storing the secret-shares) and the querier for executing the above-mentioned operations, resulting in a very efficient implementation. Prism also supports result verification techniques for each operation to detect malicious adversaries. Experimental results show that Prism scales both in terms of the number of data owners and database sizes, to which prior approaches do not scale.}
}


@article{DBLP:journals/tdsc/ZhaoJXTWWLZLWB24,
	author = {Binbin Zhao and
                  Shouling Ji and
                  Jiacheng Xu and
                  Yuan Tian and
                  Qiuyang Wei and
                  Qinying Wang and
                  Chenyang Lyu and
                  Xuhong Zhang and
                  Changting Lin and
                  Jingzheng Wu and
                  Raheem Beyah},
	title = {One Bad Apple Spoils the Barrel: Understanding the Security Risks
                  Introduced by Third-Party Components in IoT Firmware},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1372--1389},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3279846},
	doi = {10.1109/TDSC.2023.3279846},
	timestamp = {Fri, 31 May 2024 21:06:04 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhaoJXTWWLZLWB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Currently, the development of Internet of Things (IoT) firmware heavily depends on third-party components (TPCs) to improve development efficiency. Nevertheless, TPCs are not secure, and the vulnerabilities in TPCs will influence the security of IoT firmware. Existing works pay less attention to the vulnerabilities caused by TPCs, and we still lack a comprehensive understanding of the security impact of TPC vulnerability against firmware. To fill in the knowledge gap, we design and implement FirmSec, which leverages syntactical features and control-flow graph features to detect the TPCs in firmware, and then recognizes the corresponding vulnerabilities. Based on FirmSec, we present the first large-scale analysis of the security risks raised by TPCs on 34,136 firmware images. We successfully detect 584 TPCs and identify 128,757 vulnerabilities caused by 429 CVEs. Our in-depth analysis reveals the diversity of security risks in firmware and discovers some well-known vulnerabilities are still rooted in firmware. Besides, we explore the geographical distribution of vulnerable devices and confirm that the security situation of devices in different regions varies. Our analysis also indicates that vulnerabilities caused by TPCs in firmware keep growing with the boom of the IoT ecosystem. Further analysis shows 2,478 commercial firmware images have potentially violated GPL/AGPL licensing terms.}
}


@article{DBLP:journals/tdsc/BacisVFPRS24,
	author = {Enrico Bacis and
                  Sabrina De Capitani di Vimercati and
                  Sara Foresti and
                  Stefano Paraboschi and
                  Marco Rosa and
                  Pierangela Samarati},
	title = {Mix{\&}Slice for Efficient Access Revocation on Outsourced Data},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1390--1405},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3280590},
	doi = {10.1109/TDSC.2023.3280590},
	timestamp = {Sat, 08 Jun 2024 13:14:27 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/BacisVFPRS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A complex problem when outsourcing data to the cloud is access control management. Encryption, by wrapping data with a self-enforcing protection layer, provides access control enforcement by making resources intelligible only to users holding the necessary key. The real challenge becomes then the efficient revocation of access. We address this challenge and present an approach to effectively and efficiently enforce access revocation on resources stored at external cloud providers. The approach relies on a resource transformation that provides strong mutual inter-dependency in its encrypted representation. To revoke access on a resource, it is then sufficient to update a small portion of it, with the guarantee that the resource as a whole (and any portion of it) will become unintelligible to those from whom access is revoked. Our experimental results show the effectiveness of our approach, and confirm its efficiency, especially when managing large resources with dynamic access policy.}
}


@article{DBLP:journals/tdsc/JiangXLYBGC24,
	author = {Peng Jiang and
                  Jifan Xiao and
                  Ding Li and
                  Hongyi Yu and
                  Yu Bai and
                  Yao Guo and
                  Xiangqun Chen},
	title = {Detecting Malicious Websites From the Perspective of System Provenance
                  Analysis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1406--1423},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3277613},
	doi = {10.1109/TDSC.2023.3277613},
	timestamp = {Fri, 04 Oct 2024 08:55:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/JiangXLYBGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malicious websites are considered one of the top threats to the modern Internet. Thus, it is critical to effectively detect malicious websites for the security of the Internet. Conventional technologies typically rely on URL blacklists, or static and dynamic code analysis, which are known to have limitations. In order to effectively detect malicious websites, in this paper, we study malicious websites from the perspective of system provenance analysis for the first time. We first conduct a systematic feature engineering study on thousands of benign and malicious websites from the perspective of system provenance data. In our study, we discover eight useful features for malicious website detection. Based on these eight features, we propose ProvWeb, a novel non-intrusive system provenance-based tool, for malicious website detection. In our evaluation, ProvWeb can achieve an F1 score of 93.7%\n∼\n99.7% for the four combinations of browsers and OSes (Windows Chrome, Windows Firefox, Linux Chrome, Linux Firefox). This result confirms that the features discovered in provenance graphs are effective in detecting malicious websites.}
}


@article{DBLP:journals/tdsc/LuZR24,
	author = {Tianpei Lu and
                  Bingsheng Zhang and
                  Kui Ren},
	title = {PrivData Network: {A} Privacy-Preserving On-Chain Data Factory and
                  Trading Market},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1424--1436},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3284565},
	doi = {10.1109/TDSC.2023.3284565},
	timestamp = {Fri, 31 May 2024 21:06:04 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LuZR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy concerns often raise when sensitive data are collected, traded, and processed. The data owner typically loses her ultimate control of the data after data-outsourcing. In this work, we present the PrivData Network – a community-controlled privacy-preserving data factory and trading market. It can be viewed as a standalone data ecosystem that enables privacy-preserving data-driven workflows in a controlled environment for orchestrating and automating data movement and data transformation. In particular, we design a data encapsulation mechanism with privacy assurance, which can guarantee data privacy, usage policy compliance and metadata validity. We also design a privacy policy language and utilize a static analysis library that transfers the program to the defined policy language. To ensure the correctness of data processing, we propose a publicly verifiable secure multiparty computation protocol for mixed circuits, which guarantees the output correctness even if all parties are corrupted. Its online efficiency is comparable to conventional semi-honest secret-sharing-based MPC schemes. Finally, we implemented a prototype of our system in C++ and benchmark it on various tasks, such as biometric matching, logistic regression, and decision trees, etc.}
}


@article{DBLP:journals/tdsc/YeLNYSJ24,
	author = {Zipeng Ye and
                  Wenjian Luo and
                  Muhammad Luqman Naseem and
                  Xiangkai Yang and
                  Yuhui Shi and
                  Yan Jia},
	title = {{C2FMI:} Corse-to-Fine Black-Box Model Inversion Attack},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1437--1450},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285071},
	doi = {10.1109/TDSC.2023.3285071},
	timestamp = {Fri, 31 May 2024 21:06:04 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YeLNYSJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving machine learning requires that models do not reveal any private information about their training data. However, model inversion attacks (MIAs), which aim to recover the features of training data, pose a huge threat to the security of AI models. Most existing MIAs assume that the target model is white-box, but most models deployed in reality are black-box, and these models can only be accessed like an oracle. There are a few studies for black-box scenarios, but their performance is limited. In this article, we first formulate the MIA problem completely in Bayesian perspective. Second, we propose a novel two-stage MIA approach, the Coarse-to-Fine Model Inversion Attack (C2FMI), which efficiently addresses the MIA problem in the black-box scenario. In stage I of C2FMI, we design a reverse network that constrains the recovered images (also named attacked images) to fall near the manifold space of the training data. In stage II, we design a black-box oriented strategy which further facilitates the attacked images to approach the training data. Empirically, C2FMI achieves a performance that even surpasses existing white-box attack methods. Furthermore, we design the stability analysis method for analyzing the stability of C2FMI along with existing MIAs. Finally, we explore the potential countermeasures which could defend against our attacks.}
}


@article{DBLP:journals/tdsc/ZhouZYYZ24,
	author = {Shuai Zhou and
                  Tianqing Zhu and
                  Dayong Ye and
                  Xin Yu and
                  Wanlei Zhou},
	title = {Boosting Model Inversion Attacks With Adversarial Examples},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1451--1468},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285015},
	doi = {10.1109/TDSC.2023.3285015},
	timestamp = {Fri, 31 May 2024 21:06:04 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhouZYYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model inversion attacks involve reconstructing the training data of a target model, which raises serious privacy concerns for machine learning models. However, these attacks, especially learning-based methods, are likely to suffer from low attack accuracy, i.e., low classification accuracy of these reconstructed data by machine learning classifiers. Recent studies showed an alternative strategy of model inversion attacks, GAN-based optimization, can improve the attack accuracy effectively. However, these series of GAN-based attacks reconstruct only class-representative training data for a class, whereas learning-based attacks can reconstruct diverse data for different training data in each class. Hence, in this paper, we propose a new training paradigm for a learning-based model inversion attack that can achieve higher attack accuracy in a black-box setting. First, we regularize the training process of the attack model with an added semantic loss function and, second, we inject adversarial examples into the training data to increase the diversity of the class-related parts (i.e., he essential features for classification tasks) in training data. This scheme guides the attack model to pay more attention to the class-related parts of the original data during the data reconstruction process. The experimental results show that our method greatly boosts the performance of existing learning-based model inversion attacks. Even when no extra queries to the target model are allowed, the approach can still improve the attack accuracy of reconstructed data. This new attack shows that the severity of the threat from learning-based model inversion adversaries is underestimated and more robust defenses are required.}
}


@article{DBLP:journals/tdsc/HuangCSYZ24,
	author = {Heqing Huang and
                  Hung{-}Chun Chiu and
                  Qingkai Shi and
                  Peisen Yao and
                  Charles Zhang},
	title = {Balance Seed Scheduling via Monte Carlo Planning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1469--1483},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285293},
	doi = {10.1109/TDSC.2023.3285293},
	timestamp = {Fri, 31 May 2024 21:06:04 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HuangCSYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Scheduling seeds, i.e., selecting seed for mutation from a pool of candidates, significantly impacts the speed of a greybox fuzzer to achieve a target coverage rate. Despite much progress in improving seed scheduling, existing work cannot escape from the high-cost trap or the high-benefit trap: one line of approaches believe high cost implies high benefit and, thus, prefer the seeds that explore infrequently-visited paths; the other line of approaches directly calculate the potential benefits, e.g., the number of blocks able to cover, and prefer high-benefit seeds. Due to the ignorance of the impacts of either the cost or the benefits, they often trap fuzzers into mutating the seeds without increasing coverage. This article presents BeliefFuzz, which transforms fuzzing into a Monte Carlo planning system with a upper confidence bound. The system allows us to dynamically compute both the benefits and the cost during the fuzzing process. The experimental results demonstrated that our approach achieves a significant efficiency improvement, with 2.12x-5.63x speedups and 1.18x-2.77x fewer executions needed, over the state of the art to achieve the same coverage. Moreover, BeliefFuzz detected 31 more previously-unseen bugs in the real-world projects evaluated, with 18 CVEs assigned.}
}


@article{DBLP:journals/tdsc/HaJHCLJ24,
	author = {Guanxiong Ha and
                  Chunfu Jia and
                  Yixuan Huang and
                  Hang Chen and
                  Ruiqi Li and
                  Qiaowen Jia},
	title = {Scalable and Popularity-Based Secure Deduplication Schemes With Fully
                  Random Tags},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {3},
	pages = {1484--1500},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285173},
	doi = {10.1109/TDSC.2023.3285173},
	timestamp = {Sat, 08 Jun 2024 13:14:27 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HaJHCLJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is non-trivial to provide semantic security for user data while achieving deduplication in cloud storage. Some studies deploy a trusted party to store deterministic tags for recording data popularity, then provide different levels of security for data according to popularity. However, deterministic tags are vulnerable to offline brute-force attacks. In this article, we first propose a popularity-based secure deduplication scheme with fully random tags, which avoids the storage of deterministic tags. Our scheme uses homomorphic encryption (HE) to generate comparable random tags to record data popularity and then uses the binary search in the AVL tree to accelerate the tag comparisons. Besides, we find the popularity tamper attacks in existing schemes and design a proof of ownership (PoW) protocol against it. To achieve scalability and updatability, we introduce the multi-key homomorphic proxy re-encryption (MKH-PRE) to design a multi-tenant scheme. Users in different tenants generate tags using different key pairs, and the cross-tenant tags can be compared for equality. Meanwhile, our multi-tenant scheme supports efficient key updates. We give comprehensive security analysis and conduct performance evaluations based on both synthetic and real-world datasets. The results show that our schemes achieve efficient data encryption and key update, and have high storage efficiency.}
}


@article{DBLP:journals/tdsc/CuiWGW24,
	author = {Hui Cui and
                  Zhiguo Wan and
                  Rui Gao and
                  Huaqun Wang},
	title = {Outsourced Privately Verifiable Proofs of Retrievability via Blockchain},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1501--1514},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285218},
	doi = {10.1109/TDSC.2023.3285218},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/CuiWGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outsourced Proofs of Retrievability (OPoR) with private verification enables a third party verifier to periodically check cloud data on behalf of users. However, such a scheme requires the verifier to keep a copy of the user's data and generate tags for the data like the data owner. In other words, in addition to storing the data and tags from the user, the cloud server also needs to store tags uploaded by the verifier. To overcome this limitation, we propose a concrete construction of outsourced privately verifiable PoR (OPVPoR) without requiring the additional tag storage from the verifier. Furthermore, we extend the OPVPoR scheme to the multi-user setting and build a MOPVPoR scheme, where users storing the same data to the cloud server also share the tag information to further reduce the storage cost. Finally, we implement both schemes to evaluate their performance in practice.}
}


@article{DBLP:journals/tdsc/ZhangXJC24,
	author = {Zhao Zhang and
                  Chunxiang Xu and
                  Changsong Jiang and
                  Kefei Chen},
	title = {{TSAPP:} Threshold Single-Sign-On Authentication Preserving Privacy},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1515--1527},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285393},
	doi = {10.1109/TDSC.2023.3285393},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangXJC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Single-sign-on (SSO) authentication enables a user to gain a token from the identity server, with which the user accesses multiple services. To address single-point-of-failure of SSO, threshold SSO, where a group of identity servers issue a user with a token in the threshold manner, is introduced. SSO including threshold schemes suffers from privacy disclosure. One can learn a user's identity and access pattern from her/his token. Recent works focus on privacy preservation of SSO. However, these works merely consider scenarios of one single identity server SSO. No works that address privacy preservation of threshold SSO have emerged. In this work, we propose TSAPP, a threshold SSO authentication scheme preserving privacy. Each identity server issues a user with a partial token which is a signature on the user's pseudonym. With a threshold number of partial tokens, the user constructs a token, blinds the token with random numbers and accesses services with blinded tokens. Such mechanism preserves the user's identity, simultaneously protects the user's access pattern since adversaries cannot link the user's accesses, even if identity servers are corrupted. Security analysis demonstrates that TSAPP satisfies properties of anonymity, unlinkability, unforgeability and password-safety. The performance evaluation demonstrates that TSAPP is efficient in practice.}
}


@article{DBLP:journals/tdsc/ZhouNWLLKHZ24,
	author = {Hao Zhou and
                  Zhiheng Niu and
                  Gang Wang and
                  Xiaoguang Liu and
                  Dongshi Liu and
                  Bingnan Kang and
                  Zheng Hu and
                  Yong Zhang},
	title = {Proactive Drive Failure Prediction for Cloud Storage System Through
                  Semi-Supervised Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1528--1543},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3286093},
	doi = {10.1109/TDSC.2023.3286093},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhouNWLLKHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proactive drive failure prediction can help operators handle the failing drives in advance, enhancing the storage system dependability. SSD and HDD failure prediction techniques are currently evolving towards a semi-supervised approach. In this paper, we are dedicated to enhancing the methodology for semi-supervised drive failure prediction from these aspects: design more powerful, robust yet generic models, mine drive failure modes and make the prediction model interpretable. Specifically, we propose two semi-supervised drive failure prediction models, DFP-VL and DFP-FL, from the perspective of reconstructing SMART data and learning SMART data's probability density, respectively. They capture the pattern of healthy drives, and failing drives can be detected when they deviate from the normal pattern. We mine two failure modes, slow deterioration and dramatic deterioration. Based on that, we design two failure detectors, “ThresholdDetector” and ”HybridDetector”, to determine whether a drive deviates from the normal pattern. We evaluate the proposed methods on both SSD and HDD SMART data. DFP-VL is generic yet effective and can interpret the predicted results. DFP-FL has better performance than DFP-VL, but it cannot interpret the results. ThresholdDetector has low complexity and can detect most failing drives. HybridDetector has high complexity and can further improve the detection performance.}
}


@article{DBLP:journals/tdsc/ZhangMCLDB24,
	author = {Yiwei Zhang and
                  Siqi Ma and
                  Tiancheng Chen and
                  Juanru Li and
                  Robert H. Deng and
                  Elisa Bertino},
	title = {EvilScreen Attack: Smart {TV} Hijacking via Multi-Channel Remote Control
                  Mimicry},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1544--1556},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3286182},
	doi = {10.1109/TDSC.2023.3286182},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangMCLDB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern smart TVs often communicate with their remote controls (including the smartphone simulated ones) using multiple wireless channels (e.g., Infrared, Bluetooth, and Wi-Fi). However, this multi-channel remote control communication introduces a new attack surface. An inherent security flaw is that remote controls of most smart TVs are designed to work in a benign environment rather than an adversarial one, and thus wireless communications between a smart TV and its remote controls are not strongly protected. Attackers can leverage such a flaw to abuse the remote control communication and compromise smart TV systems. In this paper, we propose EvilScreen, a novel attack that exploits ill-protected remote control communications to access protected resources of a smart TV or even control the screen. EvilScreen exploits a multi-channel remote control mimicry vulnerability present in today smart TVs. Unlike other attacks, which compromise the TV system by exploiting code vulnerabilities or malicious third-party apps, EvilScreen directly reuses commands of different remote controls, combines them together to circumvent deployed authentication and isolation policies, and finally accesses or controls TV resources remotely. We evaluated eight mainstream smart TVs and found that they are all vulnerable to EvilScreen attacks, including a\nSamsung\nproduct adopting the ISO/IEC security specification.}
}


@article{DBLP:journals/tdsc/LiYWQZ24,
	author = {Fengyong Li and
                  Zongliang Yu and
                  Kui Wu and
                  Chuan Qin and
                  Xinpeng Zhang},
	title = {Multi-Modality Ensemble Distortion for Spatial Steganography With
                  Dynamic Cost Correction},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1557--1571},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285590},
	doi = {10.1109/TDSC.2023.3285590},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiYWQZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article tackles a recent challenge in designing an efficient steganographic distortion model, whose goal is to accurately measure the modification cost of a pixel and help design steganographic schemes with high undetectability. Existing distortion models mostly assume that different modification directions of a pixel have an identical cost value and that pixel modifications are independent. These assumptions, however, may not lead to good steganography design because the modification direction of neighbouring pixels may affect the cost measurement of the current pixel. To address this problem, we propose a new distortion calculation method using dynamic cost correction and multi-modality distortion ensemble. The proposed scheme first employs a given distortion model to generate the original cost map. The cost of each pixel is then dynamically adjusted with majority voting according to the modification directions of its neighbouring pixels. Furthermore, different distortion calculation models are integrated to make the final decision on the distortion of each pixel. Experimental results show that compared to existing additive distortion-based steganographic schemes and deep learning-based steganographic schemes, steganography using our proposed distortion model performs better when tested against state-of-the-art steganalysis methods.}
}


@article{DBLP:journals/tdsc/WangLHGQLR24,
	author = {Zhibo Wang and
                  Wenxin Liu and
                  Jiahui Hu and
                  Hengchang Guo and
                  Zhan Qin and
                  Jian Liu and
                  Kui Ren},
	title = {Label-Free Poisoning Attack Against Deep Unsupervised Domain Adaptation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1572--1586},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3286608},
	doi = {10.1109/TDSC.2023.3286608},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WangLHGQLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep unsupervised domain adaptation (UDA) has significantly boosted the performance of deep models on different domains by transferring knowledge from a source domain to a target domain. However, its robustness against adversarial attacks has not been explored due to the challenges of highly non-convex deep models and different data distribution. In this article, we give the first attempt to analyze the vulnerability of deep UDA and propose a label-free poisoning attack (LFPA), which injects poisoning data into the training data to mislead adaptation between the two domains without ground truth in target domain. Specifically, we design an unsupervised adversarial loss as the attack goal, in which the pseudo-labels are used to approximate the ground-truth. Since retraining the model will gradually degrade the attack performance, we also add a regularization term to the unsupervised loss, which eliminates negative interactions between the training goal and the attack goal. To accelerate the craft of poisons, we select influential samples as the initial poisons and propose a fast reverse-mode optimization method which updates poisons according to the approximate truncated gradients. Experimental results on multiple state-of-the-art deep UDA methods demonstrate the effectiveness of the proposed LFPA and the high sensitivity of UDA to poisoning attacks.}
}


@article{DBLP:journals/tdsc/WangCZHGZ24,
	author = {Fengqun Wang and
                  Jie Cui and
                  Qingyang Zhang and
                  Debiao He and
                  Chengjie Gu and
                  Hong Zhong},
	title = {Blockchain-Based Lightweight Message Authentication for Edge-Assisted
                  Cross-Domain Industrial Internet of Things},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1587--1604},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285800},
	doi = {10.1109/TDSC.2023.3285800},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WangCZHGZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In edge-assisted cross-domain Industrial Internet of Things (IIoT), blockchain-based authentication is an effective way to build cross-domain trust and secure cross-domain data. However, existing authentication schemes still have serious challenges in terms of efficiency and security. In this article, we propose a blockchain-based lightweight message authentication scheme. First, to address efficiency challenges, we build a blockchain-enabled edge-assisted lightweight authentication framework. This framework uses edge servers to assist smart devices in achieving cross-domain authentication and effectively reduce redundant interactions between entities. Second, to resolve the security challenges, we design a lightweight message authentication algorithm for cross-domain IIoT. The algorithm guarantees message security with low computational overhead and is suitable for multi-receiver cross-domain IIoT. The security proof and analysis demonstrate that the proposed scheme is secure under the random oracle model and can resist various attacks. The performance evaluation shows that our proposed scheme is superior in terms of computation and communication overhead when compared with other related schemes.}
}


@article{DBLP:journals/tdsc/GongCHKWSW24,
	author = {Xueluan Gong and
                  Yanjiao Chen and
                  Huayang Huang and
                  Weihan Kong and
                  Ziyao Wang and
                  Chao Shen and
                  Qian Wang},
	title = {KerbNet: {A} QoE-Aware Kernel-Based Backdoor Attack Framework},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1605--1620},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3286842},
	doi = {10.1109/TDSC.2023.3286842},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GongCHKWSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks are vulnerable to backdoor attacks, where a specially-designed trigger will lead to misclassification of any benign samples. However, existing backdoor attacks usually impose conspicuous patch triggers on images, which are easily detected by humans and defense algorithms. Existing works on invisible triggers, however, either have reduced attack success rate or yield detectable patterns to visual inspections. In this article, we propose KerbNet, a kernel-based backdoor attack framework, which applies kernel operations to clean samples as the trigger to incur misclassification. The kernel-processed samples achieve a high attack success rate while appearing natural with high Quality-of-Experience (QoE). We carefully design the kernel trigger generation algorithm by exploiting the neural network structure to propagate the influence of the trigger to the target misclassification label under the QoE constraint. We conduct extensive experiments on five datasets, i.e., MNIST, GTSRB, CIFAR-10, CelebA, and ImageNette to evaluate the effectiveness and practicality of KerbNet under the impact of various factors, including neuron-residing layer, kernel size, base image, loss function, model structure, and so on. We also show that our proposed attacks can evade state-of-the-art defense strategies and visual inspections. Code will be available after publication.}
}


@article{DBLP:journals/tdsc/YangXZHLD24,
	author = {Yang Yang and
                  Wenyi Xue and
                  Yonghua Zhan and
                  Minming Huang and
                  Yingjiu Li and
                  Robert H. Deng},
	title = {AnoPay: Anonymous Payment for Vehicle Parking With Updatable Credential},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1621--1638},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3287228},
	doi = {10.1109/TDSC.2023.3287228},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YangXZHLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many existing anonymous parking payment schemes lack high efficiency and flexibility. For instance, the calculation and communication costs involved in payment may linearly increase with the payment amount. In this paper, we propose an anonymous payment system (dubbed AnoPay) for vehicle parking, which leverages updatable attribute-based anonymous credentials and efficient zero-knowledge proof (ZKP) to achieve user anonymity and constant overhead for parking fee payment. To further improve the efficiency, we design a secure parking fee aggregation protocol based on linear homomorphic encryption to aggregate parking transactions, where the amount of each parking transaction is hidden and the privacy of the parking lot in terms of its revenue is guaranteed. AnoPay achieves both unlinkability and accountability, malicious payments can be efficiently traced when it is necessary. We provide a security model and rigorous proof for each security property of AnoPay. Extensive experiments and comparisons demonstrate the efficiency and practicality of the system.}
}


@article{DBLP:journals/tdsc/HuangLXLL24,
	author = {Mingfeng Huang and
                  Zhetao Li and
                  Fu Xiao and
                  Saiqin Long and
                  Anfeng Liu},
	title = {Trust Mechanism-Based Multi-Tier Computing System for Service-Oriented
                  Edge-Cloud Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1639--1651},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3285927},
	doi = {10.1109/TDSC.2023.3285927},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HuangLXLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge-cloud networks face security threats during data collection, data routing, and service construction, resulting in data tampering, stealing, and communication interruption. Trust mechanism can predict data quality and cooperation probability of nodes before purchasing data or establishing cooperation, so as to select trusted participants for data perception and interaction. Howe ver, there are some problems with existing trust methods, such as limited evaluation scope, incomplete trust evidence, and inaccurate evaluation results. To address these issues, a Trust mechanism-based Multi-Tier Computing system (TMTC) is proposed in this article. Specifically, we propose a two-tier trust evaluation model. At the data collection layer, it conducts trust evaluation on data reporters based on data submission and communication interactions. At the network layer, it evaluates trust of routers through path backtracking verification, multi-service analysis and coincident path analysis. Then, based on evaluation results, a differentiated trust detection is initiated for normal and abnormal nodes. And high-frequency detection tasks are initiated for malicious nodes to improve accuracy, sparse detection tasks are initiated for normal nodes to reduce costs. Finally, extensive experiments conducted on the synthetic and real-world datasets demonstrate that, TMTC can resist data tampering and good-bad mouth attacks effectively. And whether in a dense or uniform scene, it outperforms two benchmark methods by increasing malicious node detection rate by 13.37%–21.87% and reducing cost by 18.8%–50.32%.}
}


@article{DBLP:journals/tdsc/LiSGWS24,
	author = {Kun{-}Chang Li and
                  Run{-}Hua Shi and
                  Wan{-}Peng Guo and
                  Pengbo Wang and
                  Bo{-}Shen Shao},
	title = {Dynamic Range Query Privacy-Preserving Scheme for Blockchain-Enhanced
                  Smart Grid Based on Lattice},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1652--1664},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3288228},
	doi = {10.1109/TDSC.2023.3288228},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiSGWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain-enhanced Smart Grid has attracted a lot of attention from scholars in recent years, due to its excellent decentralization, anti-collusion and immutability. With the wide deployment of blockchain and the popularity of more accurate intelligent applications, its role in Smart Grid is becoming more and more irreplaceable. However, because of the threat of quantum computer, it still confronts the risk of privacy disclosure. In this article, we propose a novel and dynamic range query privacy-preserving scheme for blockchain-enhanced Smart Grid based on lattice. In this scheme, lattice-based homomorphic encryption algorithm is designed to resist the attack of quantum computer and realizes data aggregation to improve efficiency. In particular, this article designs a dynamic range query method with the aid of consortium blockchain by using proxy re-encryption. This method avoids the communication pressure caused by repeated data collection and improves the query efficiency and user experience. In addition, dynamic ciphertext and users update are considered, which further improves the flexibility and feasibility of the scheme. Last but not least, security analysis, exhaustive performance analysis and experiments show that our proposed scheme meets the requirements of dynamic, privacy, security and low computational cost.}
}


@article{DBLP:journals/tdsc/SantisFFM24,
	author = {Alfredo De Santis and
                  Anna Lisa Ferrara and
                  Manuela Flores and
                  Barbara Masucci},
	title = {Provably-Secure One-Message Unilateral Entity Authentication Schemes},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1665--1679},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3288473},
	doi = {10.1109/TDSC.2023.3288473},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SantisFFM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A one-message unilateral entity authentication scheme allows one party, called the prover, to authenticate himself, i.e., to prove his identity, to another party, called the verifier, by sending a single authentication message. We consider schemes where the prover and the verifier do not share any secret information, such as a password, in advance. We propose the first theoretical characterization for one-message unilateral entity authentication schemes, by formalizing the security requirements for such schemes with respect to different kinds of passive and active adversarial behaviours. In particular, we consider both static and adaptive adversaries for each kind of attack (passive/active). Afterwards, we explore the relationships between the security notions resulting from different adversarial behaviours for one-message unilateral entity authentication schemes. Finally, we propose three different constructions for one-message unilateral entity authentication schemes and we analyze their security with respect to the different definitions introduced in this paper.}
}


@article{DBLP:journals/tdsc/HanCHCL24,
	author = {Jinguang Han and
                  Liqun Chen and
                  Aiqun Hu and
                  Liquan Chen and
                  Jiguo Li},
	title = {Privacy-Preserving Decentralized Functional Encryption for Inner Product},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1680--1694},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3288109},
	doi = {10.1109/TDSC.2023.3288109},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/HanCHCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To support secure data mining and privacy-preserving computation, partial access and selective computation on encrypted data are desirable. Functional encryption (FE) is a new paradigm of public-key encryption and allows authorized users to compute specific functions on encrypted data without knowing the data. However, in some FE schemes, a trusted central authority (CA) is required to generate secret keys for users according to the description of functions. In this paper, to reduce trust on the CA and protect users’ privacy, a privacy-preserving decentralized FE for inner product (PPDFEIP) scheme is proposed where multiple authorities co-exist and work independently without any interaction. Especially, to resist collusion attacks, all secret keys of the same user are tied to his/her global identifier (GID), but authorities cannot know any information of the GID even if they collaborate. We formalize the definition and security model of our PPFEIP scheme, and propose a concrete construction. Furthermore, the proposed scheme is implemented and evaluated. Finally, the security of our PPDFEIP scheme is reduced to well-known complexity assumptions. The novelty is to reduce trust on the CA, protect users’ privacy and enable authorized users to compute inner product on encrypted data without compromising confidentiality.}
}


@article{DBLP:journals/tdsc/HitajPHPM24,
	author = {Dorjan Hitaj and
                  Giulio Pagnotta and
                  Briland Hitaj and
                  Fernando P{\'{e}}rez{-}Cruz and
                  Luigi V. Mancini},
	title = {FedComm: Federated Learning as a Medium for Covert Communication},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1695--1707},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3288215},
	doi = {10.1109/TDSC.2023.3288215},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HitajPHPM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proposed as a solution to mitigate the privacy implications related to the adoption of deep learning, Federated Learning (FL) enables large numbers of participants to successfully train deep neural networks without revealing the actual private training data. To date, a substantial amount of research has investigated the security and privacy properties of FL, resulting in a plethora of innovative attack and defense strategies. This paper thoroughly investigates the communication capabilities of an FL scheme. In particular, we show that a party involved in the FL learning process can use FL as a covert communication medium to send an arbitrary message. We introduce FedComm, a novel covert-communication technique that enables robust sharing and transfer of targeted payloads within the FL framework. Our extensive theoretical and empirical evaluations show that FedComm provides a stealthy communication channel, with minimal disruptions to the training process. Our experiments show that FedComm successfully delivers 100% of a payload in the order of kilobits before the FL procedure converges. Our evaluation also shows that FedComm is independent of the application domain and the neural network architecture used by the underlying FL scheme.}
}


@article{DBLP:journals/tdsc/XuHZXNHLD24,
	author = {Guowen Xu and
                  Xingshuo Han and
                  Tianwei Zhang and
                  Shengmin Xu and
                  Jianting Ning and
                  Xinyi Huang and
                  Hongwei Li and
                  Robert H. Deng},
	title = {{SIMC} 2.0: Improved Secure {ML} Inference Against Malicious Clients},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1708--1723},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3288557},
	doi = {10.1109/TDSC.2023.3288557},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XuHZXNHLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the problem of secure ML inference against a malicious client and a semi-trusted server such that the client only learns the inference output while the server learns nothing. This problem is first formulated by Lehmkuhl et al. with a solution (MUSE, Usenix Security’21), whose performance is then substantially improved by Chandran et al.'s work (SIMC, USENIX Security’22). However, there still exists a nontrivial gap in these efforts towards practicality, giving the challenges of overhead reduction and secure inference acceleration in an all-round way. Based on this, we propose SIMC 2.0, which complies with the underlying structure of SIMC, but significantly optimizes both the linear and non-linear layers of the model. Specifically, (1) we design a new coding method for parallel homomorphic computation between matrices and vectors. (2) We reduce the size of the garbled circuit (GC) (used to calculate non-linear activation functions, e.g., ReLU) in SIMC by about two thirds. Compared with SIMC, our experiments show that SIMC 2.0 achieves a significant speedup by up to 17.4\\times for linear layer computation, and at least 1.3\\times reduction of both the computation and communication overhead in the implementation of non-linear layers under different data dimensions. Meanwhile, SIMC 2.0 demonstrates an encouraging runtime boost by 2.3\\sim 4.3\\times over SIMC on different state-of-the-art ML models.}
}


@article{DBLP:journals/tdsc/BaiFXJ24,
	author = {Jia{-}Ju Bai and
                  Zi{-}Xuan Fu and
                  Kai{-}Tao Xie and
                  Zu{-}Ming Jiang},
	title = {Testing Error Handling Code With Software Fault Injection and Error-Coverage-Guided
                  Fuzzing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1724--1739},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3288876},
	doi = {10.1109/TDSC.2023.3288876},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/BaiFXJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-world programs require error handling code to handle various kinds of possible errors. However, these errors just infrequently occur due to special conditions, so error handling code is difficult to test. Coverage-guided fuzzing and software fault injection (SFI) are two common techniques that can test error handling code, but they still have major limitations. Specifically, existing fuzzing approaches generate program inputs guided by code coverage, but many occasional errors (such as insufficient memory) are unrelated to inputs, and code coverage cannot effectively reflect the execution contexts of these errors; existing SFI approaches often inject single or random faults, without exploring fault space or using program feedback. In this paper, we propose a new fuzzing framework named EH-Fuzz, to effectively test error handling code. EH-Fuzz uses a context-sensitive SFI-based fuzzing approach to explore fault space and perform fault injection, guided by a new metric named error coverage. We evaluate EH-Fuzz on 9 user-level programs and 6 kernel-level modules, and find 45 new real bugs, 31 of which have been confirmed and fixed. We compare EH-Fuzz to existing fuzzing approaches (including AFL, AFL++, Syzkaller, FIZZER and FIFUZZ), and EH-Fuzz finds many real bugs missed by these approaches with higher testing coverage.}
}


@article{DBLP:journals/tdsc/ShenLYLZX24,
	author = {Meng Shen and
                  Changyue Li and
                  Hao Yu and
                  Qi Li and
                  Liehuang Zhu and
                  Ke Xu},
	title = {Decision-Based Query Efficient Adversarial Attack via Adaptive Boundary
                  Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1740--1753},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3289298},
	doi = {10.1109/TDSC.2023.3289298},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ShenLYLZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decision-based adversarial attacks pose a severe threat to real-world applications of Deep Neural Networks (DNNs), as attackers are assumed to have no prior knowledge about target model except hard labels of model outputs. Existing decision-based attacks require a large number of queries on the target model for a successful attack. In this article, we propose DEAL, a decision-based query efficient adversarial attack based on adaptive boundary learning. DEAL relies on a local model initialized through meta-learning mechanism to obtain the ability to fit new decision boundaries. We conduct extensive experiments to evaluate the effectiveness of DEAL, which demonstrates that it outperforms 8 state-of-the-art attacks. Specifically for the evaluation on CIFAR-10 dataset, DEAL achieves similar attack success rates with a maximum query reduction of 51% in untargeted attacks and 14% in targeted attacks, respectively.}
}


@article{DBLP:journals/tdsc/LiBL24,
	author = {Ke Li and
                  Cameron Baird and
                  Dan Lin},
	title = {Defend Data Poisoning Attacks on Voice Authentication},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1754--1769},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3289446},
	doi = {10.1109/TDSC.2023.3289446},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiBL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advances in deep learning, speaker verification has achieved very high accuracy and is gaining popularity as a type of biometric authentication option in many scenes of our daily life, especially the growing market of web services. Compared to traditional passwords, “vocal passwords” are much more convenient as they relieve people from memorizing different passwords. However, new machine learning attacks are putting these voice authentication systems at risk. Without a strong security guarantee, attackers could access legitimate users’ web accounts by fooling the deep neural network (DNN) based voice recognition models. In this article, we demonstrate an easy-to-implement data poisoning attack to the voice authentication system, which cannot be captured effectively by existing defense mechanisms. Thus, we also propose a more robust defense method called Guardian, a convolutional neural network-based discriminator. The Guardian discriminator integrates a series of novel techniques including bias reduction, input augmentation, and ensemble learning. Our approach is able to distinguish about 95% of attacked accounts from normal accounts, which is much more effective than existing approaches with only 60% accuracy.}
}


@article{DBLP:journals/tdsc/LinC24,
	author = {Kuo{-}Chun Lin and
                  Yen{-}Ming Chen},
	title = {A High-security-level Iris Cryptosystem Based on Fuzzy Commitment
                  and Soft Reliability Extraction},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1770--1784},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3289916},
	doi = {10.1109/TDSC.2023.3289916},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LinC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, an error-correction-based iris recognition (EC-IR) scheme that guarantees both secure template storage and high-level recognition accuracy is first constructed for personal authentication. From the analysis of both the soft reliability values for the iris bits and the recovery capability values for the low-density parity-check (LDPC) code bits, a method called template mapping is devised in order to freely adjust the error-correction capability of the EC-IR scheme. The design process for suitable LDPC codes is then investigated so as to provide a stable and high-rate EC-IR scheme. In order to further enhance the security level of the EC-IR scheme, we propose locating the dominating feature points (DFPs), and then using them for iris recognition rather than using the original binary templates acquired from the iris database. The DFP-based EC-IR scheme not only enhances the security level, but also provides a better equal error rate (EER) performance and a faster processing speed during the verification stage. As a result, an iris cryptosystem based on the fuzzy commitment strategy is eventually constructed founded on a comprehensive consideration of both a satisfactory recognition performance combined with a high security level.}
}


@article{DBLP:journals/tdsc/XuHDZXNYL24,
	author = {Guowen Xu and
                  Xingshuo Han and
                  Gelei Deng and
                  Tianwei Zhang and
                  Shengmin Xu and
                  Jianting Ning and
                  Anjia Yang and
                  Hongwei Li},
	title = {VerifyML: Obliviously Checking Model Fairness Resilient to Malicious
                  Model Holder},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1785--1800},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3290562},
	doi = {10.1109/TDSC.2023.3290562},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XuHDZXNYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we present VerifyML, the first secure inference framework to check the fairness degree of a given Machine learning (ML) model. VerifyML is generic and is immune to any obstruction by the malicious model holder during the verification process. We rely on secure two-party computation (2 PC) technology to implement VerifyML, and carefully customize a series of optimization methods to boost its performance for both linear and nonlinear layer execution. Specifically, (1) VerifyML allows the vast majority of overhead to be performed offline, thus meeting the low latency requirements for online inference. (2) To speed up offline preparation, we first design novel homomorphic parallel computing techniques to accelerate the authenticated Beaver's triple (including matrix-vector and convolution triples) generation procedure. It achieves up to 1.7\\times computation speedup and gains at least 10.7\\times less communication overhead compared to state-of-the-art work. (3) We also present a new cryptographic protocol to evaluate the activation functions of non-linear layers, which is 4\\times–42\\times faster and has > 48\\times less communication than the existing 2 PC protocol against malicious parties. In fact, VerifyML even beats the state-of-the-art semi-honest ML secure inference system! We provide a formal theoretical analysis for VerifyML security and demonstrate its performance superiority on mainstream ML models including ResNet-18 and LeNet.}
}


@article{DBLP:journals/tdsc/GambaFBBRTV24,
	author = {Julien Gamba and
                  {\'{A}}lvaro Feal and
                  Eduardo Bl{\'{a}}zquez and
                  Vinuri Bandara and
                  Abbas Razaghpanah and
                  Juan Tapiador and
                  Narseo Vallina{-}Rodriguez},
	title = {Mules and Permission Laundering in Android: Dissecting Custom Permissions
                  in the Wild},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1801--1816},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3288981},
	doi = {10.1109/TDSC.2023.3288981},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/GambaFBBRTV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Android implements a permission system to regulate apps’ access to system resources and sensitive user data. One salient feature of this system is its extensibility: apps can define their own custom permissions to expose features and data to other apps. However, little is known about how widespread the usage of custom permissions is, and what is the impact that these permissions can have on users’ privacy and security. In this paper, we empirically study the usage of custom permissions at large scale, using a dataset of 2.2M pre-installed and app-store-downloaded apps. We find the usage of custom permissions to be widespread, and seemingly growing over time. Despite this prevalence, we find that custom permissions are virtually invisible to end users, and their purpose mostly undocumented. This lack of transparency can lead to serious security and privacy problems: we show that custom permissions can facilitate access to permission-protected system resources to apps that lack those permissions without user awareness. To detect this practice, we design and implement two static analysis tools, and highlight multiple concerning cases spotted in the wild. We conclude this study with a discussion of potential solutions to mitigate the privacy and security risks of custom permissions.}
}


@article{DBLP:journals/tdsc/ZubairAMA24,
	author = {Kazi Abu Zubair and
                  Rahaf Abdullah and
                  David Mohaisen and
                  Amro Awad},
	title = {{RC-NVM:} Recovery-Aware Reliability-Security Co-Design for Non-Volatile
                  Memories},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1817--1830},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3279031},
	doi = {10.1109/TDSC.2023.3279031},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZubairAMA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non-Volatile Memory (NVM) technologies are now available in the form of byte-addressable and fast main memory. Despite their benefits, such memories require secure and reliable memory management to prevent malicious and spontaneous data alteration. However, in NVM security, it is still a major challenge to maintain crash consistency and reliable system recovery. In particular, Message Authentication Codes (MAC) are rarely discussed in recent recovery-aware NVM studies since they are generally not cached. MACs have outstanding sensitivity to memory errors and hence they can be used for reliability enhancement alongside their mainstream use to detect malicious tampering. However, persisting MACs is challenging and requires 2x writes and reads in a conventional secure NVM system. It is possible to cache MACs in a MAC-assisted reliability scheme; however, this brings many challenges related to crash consistency and reliability. In this article, we present the difficulties associated with MAC recovery if they are cached, and solutions to guarantee reliable system recovery. Finally, we propose a novel scheme, Recoverable and Chipkill capable NVM, RC-NVM, which can effectively use a volatile write-back cache for MACs as well as recover them quickly after a system crash. Our scheme reduces 27% of the writes and allows 18.2% performance improvement compared to the state-of-the-art, while preserving the ability to recover from a system crash.}
}


@article{DBLP:journals/tdsc/ZhengZLGZWSL24,
	author = {Yandong Zheng and
                  Hui Zhu and
                  Rongxing Lu and
                  Yunguo Guan and
                  Songnian Zhang and
                  Fengwei Wang and
                  Jun Shao and
                  Hui Li},
	title = {PHRkNN: Efficient and Privacy-Preserving Reverse kNN Query Over High-Dimensional
                  Data in Cloud},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1831--1844},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3291715},
	doi = {10.1109/TDSC.2023.3291715},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhengZLGZWSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Big data and bursting cloud computing technologies have facilitated an increasing trend of outsourcing data-driven services to the cloud, where the reverse kNN (RkNN) query is a popularly outsourced query service. The RkNN query aims to retrieve objects having the query object as kNN and widely applied in the product recommendation. Considering privacy concerns, the outsourced query services are demanded to protect data privacy, and consequently a series of privacy-preserving query solutions have been put forth. Nevertheless, RkNN query over high-dimensional data has not been studied to date. In this work, we design the first efficient and privacy-preserving RkNN query scheme over encrypted high-dimensional data, named PHRkNN. Specifically, we first introduce a pivot filter condition for the RkNN query and utilize it to deliberately design a pivot filter R-tree (PFR-tree) to organize the high-dimensional dataset such that the RkNN query has sublinear query efficiency. Then, we propose our PHRkNN scheme by designing some homomorphic encryption based private algorithms and applying them to privately achieve PFR-tree based RkNN query. After that, we propose an oblivious PHRkNN scheme on the basis of the PHRkNN scheme by designing a private random tree permutation (PRTP) algorithm to protect the access pattern privacy. The security of our PHRkNN scheme and oblivious PHRkNN scheme is proved by the simulation-based security analysis. The performance is verified through computational costs and communication overheads evaluation.}
}


@article{DBLP:journals/tdsc/MiaoLLNLCD24,
	author = {Yinbin Miao and
                  Feng Li and
                  Xinghua Li and
                  Jianting Ning and
                  Hongwei Li and
                  Kim{-}Kwang Raymond Choo and
                  Robert H. Deng},
	title = {Verifiable Outsourced Attribute-Based Encryption Scheme for Cloud-Assisted
                  Mobile E-Health System},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1845--1862},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3292129},
	doi = {10.1109/TDSC.2023.3292129},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/MiaoLLNLCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cloud-assisted mobile electronic health (e-health) system facilitates e-health data sharing between healthcare providers and patients, but also raises the security and privacy concerns of e-health data. Although Ciphertext-Policy Attribute-Based Encryption (CP-ABE) has been a promising technique to achieve fine-grained access control over encrypted e-health data, it still incurs high encryption and decryption burdens on mobile users such as smartphones and sensors. In addition, malicious cloud servers may conduct incorrect operations due to various interest incentives (e.g., leaking sensitive information to illegal users, saving computation and storage costs). To solve the above issues, in this paper we first propose an Outsourced CP-ABE (OABE) with verifiable encryption scheme by splitting secret keys corresponding to an attribute set and using the short signature, which not only reduces the encryption and decryption complexities of mobile users but also guarantees that cloud servers correctly perform encryption operations. Then, we extend OABE to construct outsourced CP-ABE with verifiable decryption (OABE+) by utilizing the verifiable tag mechanism, which guarantees that cloud servers correctly conduct the ciphertext transformation. Formal security analysis proves that our schemes are selectively secure against unauthorized accesses and malicious operations. Extensive experiments using various real-world datasets demonstrate that our schemes are efficient and feasible in real applications.}
}


@article{DBLP:journals/tdsc/ValeroTPP24,
	author = {Jos{\'{e}} Mar{\'{\i}}a Jorquera Valero and
                  Vasileios Theodorou and
                  Manuel Gil P{\'{e}}rez and
                  Gregorio Mart{\'{\i}}nez P{\'{e}}rez},
	title = {SLA-Driven Trust and Reputation Management Framework for 5G Distributed
                  Service Marketplaces},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1863--1875},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3292589},
	doi = {10.1109/TDSC.2023.3292589},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ValeroTPP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fifth generation (5G) of mobile telecommunications is characterized by massive growth in the number of stakeholders, interconnected devices, and available services distributed under different administrative domains. Distributed marketplaces aim at facilitating stakeholders in the quest and hiring of third party resources and services. Establishing trustworthiness in such an open ecosystem is a cornerstone for the final deployment of these marketplaces in 5G networks and beyond. Hence, building trust management systems that ensure the selection of reliable parties or assets in 5G distributed marketplaces is essential. Thus, a reputation-based trust management framework is proposed to analyze stakeholder behavior patterns and predict trust scores to establish trustworthy relationships across domains. Furthermore, an Service Level Agreement (SLA)-driven reward and punishment mechanism is designed and developed on top of the reputation-based trust framework. Such a mechanism enables continuously adapting trust scores by gathering breach predictions, breach detections, and SLA violations in real time. Furthermore, an edge-based use case is presented to contextualize our reputation-based framework in a tangible enforcement scenario. In conclusion, three experiments were conducted on real-life testbeds demonstrating that our framework fairly distinguishes bad-mouthing attacks with 67% accuracy, when 50% recommenders are corrupted, and is resilient to continuous misbehavior bursts.}
}


@article{DBLP:journals/tdsc/LiHCJY24,
	author = {Jiangming Li and
                  Huasen He and
                  Shuangwu Chen and
                  Dong Jin and
                  Jian Yang},
	title = {LogGraph: Log Event Graph Learning Aided Robust Fine-Grained Anomaly
                  Diagnosis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1876--1889},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3293111},
	doi = {10.1109/TDSC.2023.3293111},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiHCJY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomaly diagnosis relying on system logs to record runtime events is essential for improving the service quality of distributed systems and reducing economic losses. However, most existing log-based anomaly detection approaches depend on the assumption of the fixed quantitative or sequential patterns of a normal log event sequence. This assumption is challenged in the context of practical distributed and parallel systems due to the dynamic pattern of the log sequence, log data noise as well as concurrency of multiple anomalies. Against these challenges, this paper aims to perform the robust log-based anomaly diagnosis by capturing the event context information of the log event graph, called LogGraph, instead of straightforwardly employing the fixed quantitative or sequential patterns of the log records, thus reducing its sensitivity to the log flaws and the concurrency of multiple anomalies. Specifically, in order to handle multiple anomalies concurrency, LogGraph invokes the association rule to decouple log sequences. It further reinterprets a log record sequence into a log event graph modeled by event semantic embedding and event adjacency matrix. An attention-based Gated Graph Neural Network (GGNN) model is developed to capture the semantic information of the log graph, which enables the fine-grained and robust anomaly identification of the proposed scheme. We use real log data sets collected from Hadoop systems and network switches to verify the effectiveness of the proposed LogGraph in log data scenarios that contain noise and multiple anomalies concurrency problems. The experimental results show that the proposed LogGraph achieves high performance and strong robustness in anomaly diagnosis.}
}


@article{DBLP:journals/tdsc/ZengHXDVX24,
	author = {Zhen Zeng and
                  Dijiang Huang and
                  Guoliang Xue and
                  Yuli Deng and
                  Neha Vadnere and
                  Liguang Xie},
	title = {{ILLATION:} Improving Vulnerability Risk Prioritization by Learning
                  From Network},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1890--1901},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3294433},
	doi = {10.1109/TDSC.2023.3294433},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZengHXDVX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network administrators face the challenge of efficiently patching overwhelming volumes of vulnerabilities with limited time and resources. To address this issue, they must prioritize vulnerabilities based on the associated risk/severity measurements (i.e., CVSS). Existing solutions struggle to efficiently patch thousands of vulnerabilities on a network. This article presents ILLATION, a proof-of-concept model that provides network-specific vulnerability risk prioritization to support efficient patching. ILLATION integrates AI techniques, such as neural networks and logical programming, to learn risk patterns from adversaries, vulnerability severity, and the network environment. It provides an integrated solution that learns and infers adversaries’ motivation and ability in a network while also learning the constraints that restrict interactions between vulnerabilities and network elements. An evaluation of ILLATION against CVSS base and environmental metrics shows that it reflects changes in vulnerability scores and prioritization ranks as the same pattern as the CVSS model while identifying vulnerabilities with similar risk patterns to given adversaries better. On a simulated network with up to 10 k vulnerable hosts and vulnerabilities, ILLATION can assess 1 k vulnerabilities in about 4.5 minutes total, with an average running time of 0.19 seconds per vulnerability on a general-purpose computer.}
}


@article{DBLP:journals/tdsc/LiWX24,
	author = {Shimin Li and
                  Xin Wang and
                  Rui Xue},
	title = {{\textdollar}{\textbackslash}mathsf \{moKHS\}{\textdollar}moKHS: {A}
                  More Lightweight Model for Multi-Client Delegatable Computation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1902--1917},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3295368},
	doi = {10.1109/TDSC.2023.3295368},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-client delegatable computation over outsourced data is an important research area in the context of cloud computing. The main target of it is to produce a function value taken data owned by different users as input while assuring the correctness of the derived result efficiently verifiable. Multi-key homomorphic signature (MK-HS), which allows for computations over signed data originating from multiple users while providing authenticity for the output value, is considered as an elegant primitive to fulfill the above functionality. However, we figure out several deficiencies in the context of MK-HS: (1) the model of MK-HS inevitably induces the participation of a large set of distinct public keys during the procedures of evaluation and verification, which leads to high communication and computation complexity; (2) current MK-HS schemes based on standard assumptions cannot prevent insider corruption attack; (3) the signature succintness of existing MK-HS constructions is far from optimal. In this work, we aim to seek a more appropriate approach for realizing multi-client delegatable computation. Our main result is the introduction of a new model we call message-oriented key-homomorphic signatures ($\\mathsf {moKHS}$). This model provides more lightweight definitions and inherently resists to insider corruption attacks. Besides, we provide a $\\mathsf {moKHS}$ construction based on standard lattices which supports circuits of bounded polynomial depth, and it achieves weak security and input-independent efficiency (in an amortized sense). Furthermore, we present a transformation to obtain an adaptively-secure one from any weakly-secure $\\mathsf {moKHS}$ scheme. Notably, the signature obtained by our $\\mathsf {moKHS}$ scheme achieves optimal succinctness in the sense that its size is independent of both the number of users involved in the computation and the input size of the program. All these improvements show that $\\mathsf {moKHS}$ is a more preferable candidate for applications of delegating computation involving multiple users.}
}


@article{DBLP:journals/tdsc/XuZDWWJ24,
	author = {Lei Xu and
                  Anxin Zhou and
                  Huayi Duan and
                  Cong Wang and
                  Qian Wang and
                  Xiaohua Jia},
	title = {Toward Full Accounting for Leakage Exploitation and Mitigation in
                  Dynamic Encrypted Databases},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1918--1934},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3296189},
	doi = {10.1109/TDSC.2023.3296189},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XuZDWWJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encrypted databases have garnered considerable attention for their ability to safeguard sensitive data outsourced to third parties. However, recent studies have revealed the vulnerability of encrypted databases to leakage-abuse attacks on their search module, prompting the development of countermeasures to address this issue. While most studies have focused on static databases, limited research has been conducted on dynamic encrypted databases. To bridge this gap, this article focuses on undertaking a comprehensive examination of leakage exploitation in dynamic encrypted databases, with the aim of providing effective mitigations. Our investigation begins with two attacks that can be employed to recover encrypted queries. The first attack, known as an active attack, involves injecting encoded files and utilizing correlated file volume information. The second attack, referred to as a passive attack, identifies unique relational characteristics of queries across database updates, assuming certain background knowledge of the plaintext databases. To mitigate these attacks, a two-layer encrypted database hardening approach is proposed, which obfuscates both search indexes and files in a continuous way. Doing so allows us to eliminate the unique characteristics emerging after data updates constantly. We conduct a series of experiments to confirm the severity of our attacks and the effectiveness of our countermeasures.}
}


@article{DBLP:journals/tdsc/PernprunerCSR24,
	author = {Marco Pernpruner and
                  Roberto Carbone and
                  Giada Sciarretta and
                  Silvio Ranise},
	title = {An Automated Multi-Layered Methodology to Assist the Secure and Risk-Aware
                  Design of Multi-Factor Authentication Protocols},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1935--1950},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3296210},
	doi = {10.1109/TDSC.2023.3296210},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/PernprunerCSR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Authentication protocols represent the entry point to online services, so they must be sturdily designed in order to allow only authorized users to access the underlying data. However, designing authentication protocols is a complex process: security designers should carefully select the technologies to involve and integrate them properly in order to prevent potential vulnerabilities. In addition, these choices are usually restricted by further factors, such as the requirements associated with the scenario, the regulatory framework, the dimensions to balance (e.g., security vs. usability), and the standards to rely on. We come to the rescue by presenting an automated multi-layered methodology we have developed to assist security designers in this phase: by repeatedly evaluating their protocols, they can select the security mitigations to consider until they reach the desired security level, thus enabling a security-by-design approach. For concreteness, we also show how we have applied our methodology to a real use case scenario in the context of a collaboration with the Italian Government Printing Office and Mint.}
}


@article{DBLP:journals/tdsc/LiuLZLL24,
	author = {Chen Liu and
                  Bo Li and
                  Jun Zhao and
                  Xudong Liu and
                  Chunpei Li},
	title = {MalAF : Malware Attack Foretelling From Run-Time Behavior Graph Sequence},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1951--1966},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3298905},
	doi = {10.1109/TDSC.2023.3298905},
	timestamp = {Tue, 23 Jul 2024 08:24:23 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuLZLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Foretelling ongoing malware attacks in real time is challenging due to the stealthy and polymorphic nature of their executive behavior patterns. In this article, we present MalAF, a novel Malware Attack Foretelling framework that utilizes run-time behavior (i.e., sequences of API events) of malware to foretell the attack that has not yet executed. MalAF first samples suspicious API events by assessing the sensitivity of the parameters of each API event and dividing them into multiple attack time slots by calculating the strong correlation. Following that, MalAF employs dynamic heterogeneous graph sequences to incrementally model contextual semantics for each attack time slot, generating malware state sequences in real time. Moreover, MalAF proposes a greedy adaptive dictionary (GAD)-optimized IRL preference learning method to automate the capture of families’ intrinsic attack preferences, which achieves higher performance than the existing inverse reinforcement learning (IRL). Additionally, with the guidance of families’ attack preferences, MalAF trains an LSTM to foretell the future path of the target malware. Finally, MalAF matches the identified APIs’ paths with a malicious capability base and reports the comprehensible attacks to an analyst. The experiments on real-world datasets demonstrate that our proposed MalAF outperforms the state-of-the-art methods, which improves the baseline by 3.01%\n∼\n4.73% of accuracy in terms of path foretell.}
}


@article{DBLP:journals/tdsc/ZhangCJPSX24,
	author = {Youzhi Zhang and
                  Dongkai Chen and
                  Sushil Jajodia and
                  Andrea Pugliese and
                  V. S. Subrahmanian and
                  Yanhai Xiong},
	title = {{GAIT:} {A} Game-Theoretic Defense Against Intellectual Property Theft},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1967--1980},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3299225},
	doi = {10.1109/TDSC.2023.3299225},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangCJPSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Months may pass before the victim of IP theft even knows they have been compromised. During this time, the attacker can exfiltrate large amounts of data. Recent work has proposed the idea of injecting a set of believable fake versions of a real document into a network so that the attacker has to expend time and effort to identify the real document from a sea of similar documents. In this paper, we consider the problem of an attacker who is smart and breaks a technical document down into small, bit-sized “units” and inspects them one by one so as to defeat the fake document defense. If a unit in a document is determined to be fake, the adversary does not need to look further at the same document. He can also immediately identify as fake, any other document that contains the same unit. In this paper, we consider the problem of a smart attacker using this strategy. Our proposed defensive algorithm, called {\\sf GAIT}\n, is shown to be successful in mitigating such attacks. {\\sf GAIT}\ncan work in conjunction with any NLP-based generative method to create fake technical documents.}
}


@article{DBLP:journals/tdsc/ReviriegoSDW24,
	author = {Pedro Reviriego and
                  Alfonso S{\'{a}}nchez{-}Maci{\'{a}}n and
                  Peter C. Dillinger and
                  Stefan Walzer},
	title = {On the Privacy of Multi-Versioned Approximate Membership Check Filters},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1981--1993},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3298967},
	doi = {10.1109/TDSC.2023.3298967},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ReviriegoSDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Approximate membership filters are increasingly used in many computing and networking applications and new filter designs are being continuously presented to improve one or more performance metrics. Therefore, understanding their security and privacy is an important issue. Previous works have considered attackers that only have access to an individual filter in isolation. For applications that generate many related filters, such as a filter for a deny list that evolves over time, that analysis is insufficient. This article considers an attacker with access to several versions of a filter that share most of the same input elements. We find that for typical implementations of Bloom, cuckoo, and quotient filters, the attacker gains little or no advantage with access to multiple versions of a filter. However, typical xor filters do reveal more information about their input elements by querying multiple versions of a filter, and we propose techniques to enhance the privacy of xor filters and others.}
}


@article{DBLP:journals/tdsc/LiuPXJWWPWZ24,
	author = {Qin Liu and
                  Yu Peng and
                  Qian Xu and
                  Hongbo Jiang and
                  Jie Wu and
                  Tian Wang and
                  Tao Peng and
                  Guojun Wang and
                  Shaobo Zhang},
	title = {{\textdollar}{\textbackslash}mathsf\{MARS\}{\textdollar}MARS: Enabling
                  Verifiable Range-Aggregate Queries in Multi-Source Environments},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {1994--2011},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3299337},
	doi = {10.1109/TDSC.2023.3299337},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuPXJWWPWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The huge values created by Big Data and the recent advances in cloud computing have been driving data from different sources into cloud repositories for comprehensive query services. However, cloud-based data fusion makes it challenging to verify if an untrusted server faithfully integrates data and executes queries or not. This is even harder for range-aggregate queries that apply aggregate operations on data within given ranges. In this article, we propose a query authentication scheme, named \\mathsf{MARS}\n, enabling a user to efficiently authenticate range-aggregate queries on multi-source data. Specifically, \\mathsf{MARS}\ncreates a VG-tree by subtly integrating Expressive Set Accumulator into a multi-dimensional G-tree while signing the root digest with a multi-source aggregate signature scheme. Compared with previous solutions, \\mathsf{MARS}\nhas the following merits: (1) Practicality. Instead of treating range and aggregate queries separately, the user can directly verify the statistical result of selected data. (2) Scalability. Instead of authenticating the individual result from each source, the user can perform an aggregative validation on the integrated result from multiple sources. The experimental results demonstrate the effectiveness of MARS. For large-scale data fusion, the user-side verification time increases by only 103 ms as the amount of data sources increases by five times.}
}


@article{DBLP:journals/tdsc/VarshithSVA24,
	author = {H. O. Sai Varshith and
                  Shamik Sural and
                  Jaideep Vaidya and
                  Vijayalakshmi Atluri},
	title = {Efficiently Supporting Attribute-Based Access Control in Linux},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2012--2026},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3299429},
	doi = {10.1109/TDSC.2023.3299429},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/VarshithSVA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Linux is a widely used multi-user operating system with applications ranging from personal desktop to commercial heavy duty web servers. It has built-in security features based on discretionary access control enforced in the form of access control lists, which can be enhanced using the Linux Security Module (LSM) Framework. LSM allows inserting security verification hooks for supporting custom security policies. However, there is no support yet for Attribute-Based Access Control (ABAC) - an access control model gaining popularity due to its dynamic nature and flexibility. In ABAC, access is granted or denied based on attributes of the subject, object and environment. In this work, we propose a method for enhancing Linux's security features by integrating ABAC for file system objects using the LSM framework. We look at various kernel and user space components and how they can be made to work together to enforce ABAC policies. Different algorithms and data structures for efficient access request resolution are also investigated. Finally, we carry out extensive performance evaluation of the ABAC-enabled Linux system and discuss its results.}
}


@article{DBLP:journals/tdsc/ShafeeMBSBA24,
	author = {Ahmed Shafee and
                  Mohamed Mahmoud and
                  Jerry W. Bruce and
                  Gautam Srivastava and
                  Abdullah Balamsh and
                  Abdulah Jeza Aljohani},
	title = {False Data Detector for Electrical Vehicles Temporal-Spatial Charging
                  Coordination Secure Against Evasion and Privacy Adversarial Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2027--2044},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3299522},
	doi = {10.1109/TDSC.2023.3299522},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ShafeeMBSBA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the number of electric vehicles on roads significantly increases, spatial-temporal charging coordination mechanisms have been introduced for balancing charging demand and energy supply. However, electric vehicles could send false data, such as state-of-charge (SoC), to the charging coordination mechanism for gaining high charging priority illegally. Machine Learning models can be used to detect false data. However, in our application the detector is trained on a dataset that contains sensitive information, such as the locations and SoC values of the electric vehicles. Therefore, attackers could launch adversarial attacks against the detector, such as membership inference and model inversion, for revealing sensitive information on the drivers whose data are used to train the detector. Furthermore, attackers could launch evasion attacks against the detector by computing false SoC values that are classified benign by the detector. Addressing the three attacks simultaneously makes the problem more complicated because a countermeasure to one attack may degrade the model's accuracy and unintentionally make the model more susceptible to other attacks. Accordingly, in this article, we propose a deep-learning training approach for false data detector in spatial-temporal charging coordination. Our approach can deal with the tradeoffs and balance the detector's accuracy and robustness against the adversarial attacks. Specifically, our approach combines three techniques, including mimic learning, dropout, and differential privacy, in a certain way that makes the detector highly accurate in detecting false data and also robust against adversarial attacks. To validate our approach, we have conducted a set of experiments and the given results demonstrate the robustness and accuracy of our detector.}
}


@article{DBLP:journals/tdsc/YaoWHW24,
	author = {Lin Yao and
                  Xue Wang and
                  Haibo Hu and
                  Guowei Wu},
	title = {A Utility-Aware Anonymization Model for Multiple Sensitive Attributes
                  Based on Association Concealment},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2045--2056},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3299641},
	doi = {10.1109/TDSC.2023.3299641},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YaoWHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Relational data usually contain multiple Sensitive Attributes (SAs) and Quasi-Identifiers (QIs). Privacy leakage may occur if they are published directly. Therefore, many privacy models have been proposed. However, one of the most challenging issues is the association between attributes, which can cause both identity disclosure and attribute disclosure. Furthermore, these models always prioritize privacy over utility, so a rigorous (but often unnecessary) setting of privacy parameters could cause poor utility or even useless data. In this paper we propose a scheme called MSAAC that addresses both issues. To balance data privacy and utility, MSAAC adopts a utility-aware (\nα,β\n) privacy model. To guide data publishers to set\nα\nand\nβ\nreasonably, MSAAC has built-in measures on privacy gain and utility loss, and quantitatively trades privacy for utility and vice versa. Our second contribution is quantifying the association of SA-SA using lift degree and the association of QI-SA using a chi-square value. Based on them, MSAAC applies suppression and permutation techniques to properly anonymize them. Through both theoretical and experimental results, we show MSAAC can achieve better privacy while retaining higher utility than state-of-the-art solutions.}
}


@article{DBLP:journals/tdsc/ShenCHX24,
	author = {Jun Shen and
                  Xiaofeng Chen and
                  Xinyi Huang and
                  Yang Xiang},
	title = {Public Proofs of Data Replication and Retrievability With User-Friendly
                  Replication},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2057--2067},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3299627},
	doi = {10.1109/TDSC.2023.3299627},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ShenCHX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proofs of Retrievability (PoRs) and Provable Data Possession (PDP) are efficient cryptographic solutions to monitoring the state of storage, enabling integrity verification without the necessity of retrieving data. However, such protocols fail to guarantee data availability, since it is too late for cloud clients to recover the corrupted data when notified. To remedy it, these protocols are extended to verify integrity of both the stored data and their redundant copies in the multi-replica environment. Most of the existing multi-replica PDP protocols not only consume considerable computation and bandwidth resources of clients to generate and upload replicas, but also lead economic losses to service providers due to abused replica discounts. Though the other few considered these problems and proposed some countermeasures, they imposed the linear cost of generating and uploading copy parameters on clients in replication algorithms and fail to realize public verifiability. In this article, we propose a public proofs of data replication and retrievability protocol with user-friendly replication for the first time. One distinguishable property is the simultaneous achievement of user-friendly replication and public verifiability. Specifically, we design a novel replication algorithm, which imposes nearly no computation and a constant-size communication cost on clients. Subsequently, we employ non-interactive succinct proofs to make the verification public. Furthermore, we present a comprehensive analysis and extensive experiments to demonstrate the security and efficiency of the proposed protocol.}
}


@article{DBLP:journals/tdsc/XuCJC24,
	author = {Wenyuan Xu and
                  Yushi Cheng and
                  Xiaoyu Ji and
                  Yi{-}Chao Chen},
	title = {On Tracing Screen Photos - {A} Moir{\'{e}} Pattern-Based Approach},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2068--2084},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3299983},
	doi = {10.1109/TDSC.2023.3299983},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XuCJC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-theft of trade secrets has become a serious business threat. Digital watermarking is a popular technique to help identify the source of the file leakage, whereby a unique watermark for each insider is hidden in sensitive files. However, malicious insiders may use smartphones to photograph the secret file displayed on screens to remove the embedded hidden digital watermarks due to the optical noises introduced during photographing. To identify the leakage source despite such screen-photo-based leakage attacks, we leverage Moiré pattern, an optical phenomenon resulted from the optical interaction between electronic screens and cameras. As such, we present mID, a new watermark-like technique that can create a carefully crafted Moiré pattern on the photo when it is taken towards the screen. We design patterns that appear to be natural yet can be linked to the identity of the leaker. We implemented mID and evaluated it with 7 display devices and 6 smartphones from various manufacturers and models. The results demonstrate that mID can achieve an average bit error rate (BER) of 0.2% and can successfully identify an ID with an average accuracy of 98%, with little influence from the type of display devices, cameras, IDs, and ambient lights.}
}


@article{DBLP:journals/tdsc/ZhouZLDNWX24,
	author = {Lei Zhou and
                  Fengwei Zhang and
                  Kevin Leach and
                  Xuhua Ding and
                  Zhenyu Ning and
                  Guojun Wang and
                  Jidong Xiao},
	title = {Hardware-Assisted Live Kernel Function Updating on Intel Platforms},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2085--2098},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3300101},
	doi = {10.1109/TDSC.2023.3300101},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhouZLDNWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional kernel updates such as perfective maintenance and vulnerability patching requires shutting the system down, disrupting continuous execution of applications. Enterprises and researchers have proposed various live updating techniques to patch the kernel with lower downtime to reduce the loss of useful uptime. However, existing kernel live update techniques either rely on specific support from the target OS, or are deployed in virtualized environments (i.e., systems running in virtual machines). In this article we present KShot, a hardware-assisted live and secure kernel function update mechanism for native operating systems. By leveraging x86 SMM and Intel SGX, KShot runs in hardware-assisted Trusted Execution Environments and updates kernel functions at the binary-level without relying on the underlying OS support. We demonstrate the applicability of KShot by successfully patching critical kernel vulnerabilities, upgrading base kernel functions and drivers nearly instantly and transparently. Our experimental results show that KShot incurs merely 70 microseconds downtime to update a one kilobyte binary and 18 MB memory overhead.}
}


@article{DBLP:journals/tdsc/LiYYXTWZ24,
	author = {Wei Li and
                  Borui Yang and
                  Hangyu Ye and
                  Liyao Xiang and
                  Qingxiao Tao and
                  Xinbing Wang and
                  Chenghu Zhou},
	title = {MiniTracker: Large-Scale Sensitive Information Tracking in Mini Apps},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2099--2114},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3299945},
	doi = {10.1109/TDSC.2023.3299945},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiYYXTWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Running on host mobile applications, mini apps have gained increasing popularity these days for its convenience in installation and usage. However, being easy to use allows mini apps to freely access a large amount of user information, mostly without close inspection of privacy violations. Hence it becomes a crucial issue to automatically track sensitive flows in mini apps. Although flow analysis has been widely studied, unique challenges emerge: the analysis tool should not only handle mini app-specific features such as flows that interweave between rendering and logic, and asynchronous executions, but also deal with problems raised by Javascript development: the performance tradeoff between precision and efficiency, and function aliases. To this end, we propose MiniTracker, an automatic sensitive flow tracking tool which well handles mini app features, constructs assignment flow graphs as common representation across different host apps, searches function aliases, and analyzes the graph by property chains. We show our design choices achieve a sweet spot in the tradeoff between precision and efficiency, with superior performance compared to the state-of-the-art. We also perform a large-scale study on 150 k mini apps, which reveals the common leakage patterns and offers insights into the privacy threats of mini apps.}
}


@article{DBLP:journals/tdsc/PishbinB24,
	author = {Hora Saadaat Pishbin and
                  Amir Jalaly Bidgoly},
	title = {Exploiting Deep Neural Networks as Covert Channels},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2115--2126},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3300072},
	doi = {10.1109/TDSC.2023.3300072},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/PishbinB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing development of deep learning models, the security of these models has become more important. In this work, for the first time, we have investigated the possibility of abusing the deep model as a covert channel. The concept of a covert channel is to use a channel that is not designed for information exchange for transmitting a covert message. This work studies how a deep model can be used by an adversary as a covert channel. The proposed approach is using an end-to-end training deep model called the covert model to produce artificial data which includes some covert messages. This artificial data is the input of the deep model, which is aimed at being exploited as a covert channel, in such a way that the signal will be covered in the output of this model. To achieve indistinguishability of concealment, generative adversarial networks are used. The results show that it is possible to have a covert channel with an acceptable message transmission power in well-known deep models such as the ResNet and InceptionV3 models. Results of case studies indicate the signal-to-noise ratio (SNR) of 12.67, the bit error rate (BER) of 0.08, and the accuracy of the deep model used to hide the signal reaches 92%.}
}


@article{DBLP:journals/tdsc/Guri24,
	author = {Mordechai Guri},
	title = {Air-Gap Electromagnetic Covert Channel},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2127--2144},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3300035},
	doi = {10.1109/TDSC.2023.3300035},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Guri24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Air-gapped systems are isolated from the Internet due to the sensitive information they handle. This article introduces a covert channel attack that leaks sensitive information over the air from highly isolated systems. The information emanates from the air-gapped computer over the air and can be picked up by a nearby insider or spy with a mobile phone or laptop. Malware on an air-gapped computer can generate radio waves by executing crafted code on the target system. The malicious code exploits the dynamic power consumption of modern computers and manipulates the momentary loads on CPU cores. This technique allows the malware to control the computer's internal utilization and generate low-frequency electromagnetic radiation in the 0–60 kHz band. Sensitive information (e.g., files, encryption keys, biometric data, and keylogging) can be modulated over the emanated signals and received by a nearby mobile phone at a max speed of 1,000 bits/sec. We show that a smartphone or laptop with a small {\\$}1 antenna carried by a malicious insider or visitor can be used as a covert receiver. Notably, the attack is highly evasive since it executes from an ordinary user-level process, does not require root privileges, and is effective even within a virtual machine (VM). We discuss the attack model and provide technical details. We implement air-gap transmission of texts and files and present signal generation and data modulation. We test the covert channel and show evaluation results. Finally, we present a set of countermeasures to this air-gap attack.}
}


@article{DBLP:journals/tdsc/HuLLHXH24,
	author = {Chunqiang Hu and
                  Zewei Liu and
                  Ruinian Li and
                  Pengfei Hu and
                  Tao Xiang and
                  Meng Han},
	title = {Smart Contract Assisted Privacy-Preserving Data Aggregation and Management
                  Scheme for Smart Grid},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2145--2161},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3300749},
	doi = {10.1109/TDSC.2023.3300749},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HuLLHXH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data aggregation plays a crucial role in smart grid communication as it enables the collection of data in an energy-efficient manner. However, the widespread deployment of smart meters has raised significant concerns regarding the privacy of users’ personal data. Therefore, in this paper, we present an efficient and privacy-preserving data aggregation and trust management scheme (PATM) for an IoT-enabled smart grid based on smart contract. First, we propose a five-layer architecture for smart grid communication to support secure and efficient data aggregation and management. Under the architecture, the Boneh-Goh-Nissim cryptosystem with blind factor is improved to facilitate privacy protection. In addition, the tamper-evident nature of blockchain is utilized for effective data management. Our designs also enhance the resistance to differential attack and prevent privacy breaches during the aggregation process. Detailed security proof and theoretical analysis confirm that our PATM can satisfies the necessary security and privacy requirements while maintaining the required efficiency for smart grid operations. Furthermore, comparative experiments demonstrate that PATM outperforms other proposed work in terms of storage cost, computational complexity, and utility of differential privacy.}
}


@article{DBLP:journals/tdsc/KurtEAUC24,
	author = {Ahmet Kurt and
                  Enes Erdin and
                  Kemal Akkaya and
                  A. Selcuk Uluagac and
                  Mumin Cebe},
	title = {D-LNBot: {A} Scalable, Cost-Free and Covert Hybrid Botnet on Bitcoin's
                  Lightning Network},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2162--2180},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3300738},
	doi = {10.1109/TDSC.2023.3300738},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/KurtEAUC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While various covert botnets were proposed in the past, they still lack complete anonymization for their servers/botmasters or suffer from slow communication between the botmaster and the bots. In this article, we first propose a new generation hybrid botnet that covertly and efficiently communicates over Bitcoin Lightning Network (LN), called LNBot. Exploiting various anonymity features of LN, we show the feasibility of a scalable two-layer botnet which completely anonymizes the identity of the botmaster. In the first layer, the botmaster anonymously sends the commands to the command and control (C&C) servers through regular LN payments. Specifically, LNBot allows botmaster's commands to be sent in the form of surreptitious multi-hop LN payments, where the commands are either encoded with the payments or attached to the payments to provide covert communications. In the second layer, C&C servers further relay those commands to the bots in their mini-botnets to launch any type of attacks to victim machines. We further improve on this design by introducing D-LNBot; a distributed version of LNBot that generates its C&C servers by infecting users on the Internet and forms the C&C connections by opening channels to the existing nodes on LN. In contrary to the LNBot, the whole botnet formation phase is distributed and the botmaster is never involved in the process. By utilizing Bitcoin's Testnet and the new message attachment feature of LN, we show that D-LNBot can be run for free and commands are propagated faster to all the C&C servers compared to LNBot. We presented proof-of-concept implementations for both LNBot and D-LNBot on the actual LN and extensively analyzed their delay and cost performance. Finally, we also provide and discuss a list of potential countermeasures to detect LNBot and D-LNBot activities and minimize their impacts.}
}


@article{DBLP:journals/tdsc/HoangCF24,
	author = {Anh{-}Tu Hoang and
                  Barbara Carminati and
                  Elena Ferrari},
	title = {Protecting Privacy in Knowledge Graphs With Personalized Anonymization},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2181--2193},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3300360},
	doi = {10.1109/TDSC.2023.3300360},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/HoangCF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge graphs (KGs) are emerging data models allowing data providers to share data. This data sharing might bring new knowledge and collaborations, with evident benefits for providers. However, since KGs might contain sensitive information about users, it is of utmost importance to ensure KG anonymization before publishing. Recently, some proposals have addressed the problem of KGs’ anonymization based on the k-anonymity principle. These techniques propose to anonymize the whole dataset with the same anonymization level. However, in a contest where data are collected from different users, it is crucial to consider also users’ preferences on the anonymization level to adopt for their data. To cope with this requirement, this paper presents the Personalized k-Attribute Degree (p-k-ad) principle. It allows users to specify their anonymity levels (the k values) while preventing adversaries from re-identifying them with a confidence higher than \\frac{1}{k} with their specified k. Moreover, we design the Personalized Cluster-Based Knowledge Graph Anonymization Algorithm (PCKGA) to generate anonymized KGs satisfying p-k-ad. We conduct experiments on four real-life datasets and show that PCKGA greatly improves the quality of anonymized KGs comparing to previous algorithms.}
}


@article{DBLP:journals/tdsc/KietzmannSW24,
	author = {Peter Kietzmann and
                  Thomas C. Schmidt and
                  Matthias W{\"{a}}hlisch},
	title = {{PUF} for the Commons: Enhancing Embedded Security on the {OS} Level},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2194--2210},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3300368},
	doi = {10.1109/TDSC.2023.3300368},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/KietzmannSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Security is essential for the Internet of Things (IoT). Cryptographic operations for authentication and encryption commonly rely on random input of high entropy and secure, tamper-resistant identities, which are difficult to obtain on constrained embedded devices. In this paper, we design and analyze a generic integration of physically unclonable functions (PUFs) into the IoT operating system RIOT that supports about 250 platforms. Our approach leverages uninitialized SRAM to act as the digital fingerprint for heterogeneous devices. We ground our design on an extensive study of PUF performance in the wild, which involves SRAM measurements on more than 700 IoT nodes that aged naturally in the real-world. We quantify static SRAM bias, as well as the aging effects of devices and incorporate the results in our system. This work closes a previously identified gap of missing statistically significant sample sizes for testing the unpredictability of PUFs. Our experiments on COTS devices of 64 kB SRAM indicate that secure random seeds derived from the SRAM PUF provide 256 Bits-, and device unique keys provide more than 128 Bits of security. In a practical security assessment we show that SRAM PUFs resist moderate attack scenarios, which greatly improves the security of low-end IoT devices.}
}


@article{DBLP:journals/tdsc/FengLSR24,
	author = {Yebo Feng and
                  Jun Li and
                  Devkishen Sisodia and
                  Peter L. Reiher},
	title = {On Explainable and Adaptable Detection of Distributed Denial-of-Service
                  Traffic},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2211--2226},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3301293},
	doi = {10.1109/TDSC.2023.3301293},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/FengLSR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Launched from numerous end-hosts throughout the Internet, a distributed denial-of-service (DDoS) attack can exhaust the network bandwidth or other resources of a victim, cripple its service, and make it unavailable to legitimate clients. Recently many learning-based approaches attempt to detect DDoS attacks, but their results are often hardly explainable to users and their models are seldom adaptable to new environments. In this paper, we propose a new learning-based DDoS detection approach. It detects DDoS attacks via an enhanced k-nearest neighbors (KNN) algorithm, which utilizes a k-dimensional (KD) tree to speed up the detection process, and classifies DDoS sources at a fine granularity according to each IP’s risk level. Compared to previous DDoS detection approaches, this approach outputs explanatory information that enables network administrators to easily inspect detection results and make necessary interventions. Moreover, this approach is adaptable in that users do not need to retrain the detection model to have it fit with a new network environment. We evaluated this approach in both simulated environments and the real world, achieving more than 95.6% accuracy in detecting DDoS attacks at line speed. In addition, we carried out a human subject study on its explainability, demonstrating that the outputs can help people better understand the attack and make interventions precisely and promptly.}
}


@article{DBLP:journals/tdsc/AroraA24,
	author = {Shashank Arora and
                  Pradeep K. Atrey},
	title = {SecureC2Edit: {A} Framework for Secure Collaborative and Concurrent
                  Document Editing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2227--2241},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3302810},
	doi = {10.1109/TDSC.2023.3302810},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/AroraA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud-based online document editing services, such as Google Docs and Office 365, provide an inexpensive and efficient means of managing documents. However, storing data on the cloud also raises certain security and privacy concerns, especially when the data is of confidential and sensitive nature. We argue that in online editing environments, user data should never be exposed to the cloud in plaintext form. Significant prior work around secure collaborative editing has several limitations and is not practical. Thus, in this paper, we propose a secure online editing framework, called SecureC2Edit, which is based on structured peer-to-peer architecture, uses hybrid differential synchronization, allows collaborative and concurrent access to the document, yet ensures security and privacy by encrypting the data before storing it on the cloud. The framework is evaluated for security, operability, and performance.}
}


@article{DBLP:journals/tdsc/GaoCHYF24,
	author = {Yuan Gao and
                  Liquan Chen and
                  Jinguang Han and
                  Shui Yu and
                  Huiyu Fang},
	title = {Similarity-Based Secure Deduplication for IIoT Cloud Management System},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2242--2256},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3302891},
	doi = {10.1109/TDSC.2023.3302891},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GaoCHYF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of the Industrial Internet of Things (IIoT), the scale of IIoT data is rapidly increasing, bringing significant challenges to existing data management systems. To tackle this issue, we propose a similarity-based secure deduplication for IIoT cloud management system, which can effectively balance the security and availability of IIoT data and minimize the storage cost. Concretely, we propose a similarity-based secure deduplication algorithm for IIoT (IIoT-SBSD) by designing a similarity-preserving tag (IIoT-Simhash). This algorithm can perform similarity deduplication over ciphertexts, thus reducing storage space while ensuring data security. Besides, we construct a parallelizable edge-based deduplication framework in which similarity comparison and deduplication operations are performed directly by edge nodes, significantly alleviating the transmission pressure. Additionally, we propose similarity-based proofs of ownership, S-PoWs, to mitigate the impact of data deduplication on the user's access to the IIoT data. Experimental results show that our method significantly reduces storage space and transmission bandwidth without increasing the computation burden.}
}


@article{DBLP:journals/tdsc/LinSMHYWS24,
	author = {Chenhao Lin and
                  Tianle Song and
                  Yingmao Miao and
                  Jingyi He and
                  Minghui Yang and
                  Huan Wang and
                  Chao Shen},
	title = {ChildShield: An Implicit and Continuous Child Identification System
                  on Smartphones},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2257--2272},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3302414},
	doi = {10.1109/TDSC.2023.3302414},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LinSMHYWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smartphone addiction among child users is becoming a severe global social problem. Uncontrolled and unsupervised use of smartphones by children has posed a significant threat to the health and property of both children and their parents. Automatic identification of child users on smartphones can be an effective way to alleviate this problem. Unfortunately, existing works usually require additional input devices like cameras for face biometrics or additional applications for users’ specific touch-interaction behavior to identify child users, leading to poor user experience and privacy concerns. This paper develops a novel, implicit and continuous system, named ChildShield, for child identification on smartphones. Specifically, our system providing a built-in data acquisition service can automatically and real-timely collect users’ behavioral data in a non-conscious and privacy-preserving manner. We build a large-scale database by collecting users’ operations in 5 complex and popular mobile game applications on 12 different models of smartphones from 1875 subjects. Based on the feature extracted from multi-finger interaction data in realistic and complex usage scenarios, ChildShield can learn the discriminative behavioral patterns for accurate child identification using the specifically designed deep learning-based classifiers. Then when a child user is identified, the pre-setting subsequent operation like Enable Kids Mode in ChildShield can be executed to provide a protective shield for children. The effectiveness of ChildShield is validated on the created database. Our approach significantly outperforms existing methods, achieves an EER of 4.38% for child identification, and performs an even lower EER of 2.12% for the younger age group.}
}


@article{DBLP:journals/tdsc/SantosoF24,
	author = {Fendy Santoso and
                  Anthony Finn},
	title = {Trusted Operations of a Military Ground Robot in the Face of Man-in-the-Middle
                  Cyberattacks Using Deep Learning Convolutional Neural Networks: Real-Time
                  Experimental Outcomes},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2273--2284},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3302807},
	doi = {10.1109/TDSC.2023.3302807},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/SantosoF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Safe and secure operations of robotic systems are of paramount importance. Aiming for achieving the trusted operations of a military robotic vehicle under contested environments, we introduce a new cyber-physical system based on the concepts of deep learning Convolutional Neural Network (CNN). The proposed algorithm is specifically designed to reduce the cyber vulnerability of the Robot Operating System (ROS), a well-known middleware platform, widely used in both civilian and military domains. To demonstrate the efficacy of the proposed algorithm, we conduct penetration testing (real-time man-in-the-middle cyberattacks) on the GVR-BOT ground vehicle, a replicate of a military ground robot, developed by the United States Army Combat Capabilities Development Command (CCDC), Ground Vehicle Systems Center. The cyberattacks also exploit the vulnerability of the Robot Operating System employed on its onboard computer. We collect experimental data and train our CNN based on two different operating conditions, namely, legitimate and malicious. We normalize and convert the network traffic data in the form of RGB or grayscale images. We introduce two different types of windowing techniques, namely, the independent and overlapping sliding epochs to efficiently feed the network traffic data to our CNN system. Our research indicates the efficacy of the proposed algorithm as our proposed cyber intrusion detection system can achieve reasonably high accuracies \\geq99% and substantially small false-positive rates \\leq2% supported with minimum detection times. In addition, we also compare and demonstrate the relative merits of our proposed algorithm with respect to the performance of some well-known techniques, namely, ‘bag-of-features’ (BoFs) and Support Vector Machine (SVM) algorithms.}
}


@article{DBLP:journals/tdsc/MaZCG24,
	author = {Jiating Ma and
                  Yipeng Zhou and
                  Laizhong Cui and
                  Song Guo},
	title = {An Optimized Sparse Response Mechanism for Differentially Private
                  Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2285--2295},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3302864},
	doi = {10.1109/TDSC.2023.3302864},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MaZCG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) enables geo-distributed clients to collaboratively train a learning model without exposing their private data. By only exposing local model parameters, FL well preserves data privacy of clients. Yet, it remains possible to recover raw samples from over frequently exposed parameters resulting in privacy leakage. Differentially private federated learning (DPFL) has recently been suggested to protect these parameters by introducing information noises. In this way, even if attackers get these parameters, they cannot exactly infer true parameters from these noisy information. Directly incorporating Differentially Private (DP) into FL however can severely affect model utility. In this article, we present an optimized sparse response mechanism (OSRM) that seamlessly incorporates DP into FL to diminish privacy budget consumption and improve model accuracy. Through OSRM, each FL client only exposes a selected set of large gradients, so as not to waste privacy budgets in protecting valueless gradients. We theoretically derive the convergence rate of DPFL with OSRM under non-convex loss. Then, OSRM is optimized by minimizing the loss of the convergence rate. Based on analysis, we present an effective algorithm for optimizing OSRM. Extensive experiments are conducted with public datasets, including MNIST, Fashion-MNIST and CIFAR-10. The results suggest that OSRM can achieve the average improvement of accuracy by 18.42% as compared to state-of-the-art baselines with a fixed privacy budget.}
}


@article{DBLP:journals/tdsc/GeWBZCZZ24,
	author = {Yong{-}Feng Ge and
                  Hua Wang and
                  Elisa Bertino and
                  Zhi{-}Hui Zhan and
                  Jinli Cao and
                  Yanchun Zhang and
                  Jun Zhang},
	title = {Evolutionary Dynamic Database Partitioning Optimization for Privacy
                  and Utility},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2296--2311},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3302284},
	doi = {10.1109/TDSC.2023.3302284},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GeWBZCZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed database system (DDBS) technology has shown its advantages with respect to query processing efficiency, scalability, and reliability. Moreover, by partitioning attributes of sensitive associations into different fragments, DDBSs can be used to protect data privacy. However, it is complex to design a DDBS when one has to optimize privacy and utility in a time-varying environment. This article proposes a distributed prediction-randomness framework for the evolutionary dynamic multiobjective partitioning optimization of databases. In the proposed framework, two sub-populations contain individuals representing database partitioning solutions. One sub-population utilizes a Markov chain-based predictor to predict discrete-domain solutions for database partitioning when the environment changes, and the other sub-population utilizes the random initialization operator to maintain population diversity. In addition, a knee-driven migration operator is utilized to exchange information between two sub-populations. Experimental results show that the proposed algorithm outperforms the competing solutions with respect to accuracy, convergence speed, and scalability.}
}


@article{DBLP:journals/tdsc/MirSM24,
	author = {Omid Mir and
                  Daniel Slamanig and
                  Ren{\'{e}} Mayrhofer},
	title = {Threshold Delegatable Anonymous Credentials With Controlled and Fine-Grained
                  Delegation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2312--2326},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3303834},
	doi = {10.1109/TDSC.2023.3303834},
	timestamp = {Fri, 02 Aug 2024 21:41:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MirSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymous credential systems allow users to obtain a credential on multiple attributes from an organization and then present it to verifiers in a way that no information beyond what attributes are required to be shown is revealed. Moreover, multiple uses of the credential cannot be linked. Thus they represent an attractive tool to realize fine-grained privacy-friendly authentication and access control. In order to avoid a single point of trust and failure, decentralized AC systems have been proposed. They eliminate the need for a trusted credential issuer, e.g., by relying on a set of credential issuers that issue credentials in a threshold manner (e.g., t\nout of n\nf). In this article, we present a novel AC system with such a threshold issuance that additionally provides credential delegation. It represents the first decentralized and delegatable AC system. We provide a rigorous formal framework for such threshold delegatable anonymous credentials (\\mathsf {TDAC}\n’s). Our concrete approach departs from previous delegatable ACs and is inspired by the concept of functional credentials. More precisely, we propose a threshold delegatable subset predicate encryption (\\mathsf {TDSPE}\n) scheme and use \\mathsf {TDSPE}\nto construct a \\mathsf {TDAC}\nscheme and present a comparison with previous work and performance benchmarks based on a prototype implementation.}
}


@article{DBLP:journals/tdsc/GaoXGLLH24,
	author = {Ming Gao and
                  Fu Xiao and
                  Wentao Guo and
                  Zixin Lin and
                  Weiran Liu and
                  Jinsong Han},
	title = {Practical {EMI} Attacks on Smartphones With Users' Commands Cancelled},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2327--2343},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3303503},
	doi = {10.1109/TDSC.2023.3303503},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GaoXGLLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human-machine interactions (HMIs), e.g., touchscreens, are essential for users to interact with mobile devices. They are also beneficial in resisting emerging active attacks, which aim at maliciously controlling mobile devices, e.g., smartphones and tablets. With touchscreen-like HMIs, users can notice and interrupt malicious actions conducted by the attackers timely and perform necessary countermeasures, e.g., tapping the ‘Quit’ button on the touchscreen. However, the effect of HMI-oriented active attacks has not been investigated yet. In this paper, we present a practical attack towards touch-based devices, namely Expelliarmus. It reveals a new attack surface of active attacks for hijacking users’ operations and thus taking full control over victim devices. Expelliarmus neutralizes users’ touch commands by producing a reverse current via electromagnetic interference (EMI). Since the reverse current offsets the current change caused by a touch, the touchscreen detects no current change and thus ignores users’ commands. Besides this basic denial-of-service attack, we also realize a target cancellation attack, which can neutralize target commands, e.g., ‘Quit’ without interference in irrelevant operations. Thus, the active attack can be completely performed without interruption from users, even if they are alerted by the abnormal events. Extensive evaluations demonstrate the effectiveness of Expelliarmus on 29 off-the-shelf devices.}
}


@article{DBLP:journals/tdsc/FuHY24,
	author = {Yongquan Fu and
                  Weihong Han and
                  Dong Yuan},
	title = {Disentangled Orchestration on Cyber Ranges},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2344--2360},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3303888},
	doi = {10.1109/TDSC.2023.3303888},
	timestamp = {Fri, 21 Feb 2025 21:47:09 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/FuHY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber ranges require networked applications to test cyberspace events effectively. As testing becomes more advanced, it involves multiple real-world applications with flexible execution orders. However, it is increasingly challenging to orchestrate large-scale, chained, and heterogeneous Internet applications. State-of-the-art orchestration techniques face scalability issues due to inefficient representation models and entangled scheduling of events and applications. To address these issues, we present Wukong, a disentangled orchestration system in cyber ranges that disaggregates the scheduling and execution of workflows and their applications in a decentralized coordination approach. First, we overcome the heterogeneity of events with a workflow model that encodes event chains with compositional Directed Acyclic Graphs (DAGs) and unified event triggers. Second, Wukong disaggregates the execution of DAGs and applications with push-pull decentralized coordination over distributed agents. Our evaluation of Wukong on a real-world cyber range demonstrates its expressive, scalable, and efficient abilities for automatically emulating diverse event chains. The storage footprint of compositional modeling is up to 57 times smaller than that of baseline models. Wukong's response delay is 1.52 to 2.74 times shorter than state-of-the-art orchestration engines, and the scheduling delay is up to 2.16 times smaller than the baseline approach.}
}


@article{DBLP:journals/tdsc/MiaoLLLLCD24,
	author = {Yinbin Miao and
                  Ziteng Liu and
                  Xinghua Li and
                  Meng Li and
                  Hongwei Li and
                  Kim{-}Kwang Raymond Choo and
                  Robert H. Deng},
	title = {Robust Asynchronous Federated Learning With Time-Weighted and Stale
                  Model Aggregation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2361--2375},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3304788},
	doi = {10.1109/TDSC.2023.3304788},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MiaoLLLLCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) ensures collaborative learning among multiple clients while maintaining data locally. However, the traditional synchronous FL solutions have lower accuracy and require more communication time in scenarios where most devices drop out during learning. Therefore, we propose an Asynchronous Federated Learning (AsyFL) scheme using time-weighted and stale model aggregation, which effectively solves the problem of poor model performance due to the heterogeneity of devices. Then, we integrate Symmetric Homomorphic Encryption (SHE) into AsyFL to propose Asynchronous Privacy-Preserving Federated Learning (Asy-PPFL), which protects the privacy of clients and achieves lightweight computing. Privacy analysis shows that Asy-PPFL is indistinguishable under Known Plaintext Attack (KPA) and convergence analysis proves the effectiveness of our schemes. A large number of experiments show that AsyFL and Asy-PPFL can achieve the highest accuracy of 58.40% and 58.26% on Cifar-10 dataset when most clients (i.e., 80%) are offline or delayed, respectively.}
}


@article{DBLP:journals/tdsc/SunZLJZ24,
	author = {Hui Sun and
                  Tianqing Zhu and
                  Jie Li and
                  Shouling Ji and
                  Wanlei Zhou},
	title = {Attribute-Based Membership Inference Attacks and Defenses on GANs},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2376--2393},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3305591},
	doi = {10.1109/TDSC.2023.3305591},
	timestamp = {Fri, 02 Aug 2024 08:05:15 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SunZLJZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With breakthroughs in high-resolution image generation, applications for disentangled generative adversarial networks (GANs) have attracted much attention. At the same time, the privacy issues associated with GAN models have been raising many concerns. Membership inference attacks (MIAs), where an adversary attempts to determine whether or not a sample has been used to train the victim model, are a major risk with GANs. In prior research, scholars have shown that successful MIAs can be mounted by leveraging overfit images. However, high-resolution images make the existing MIAs fail due to their complexity. And the nature of disentangled GANs is such that the attributes are overfitting, which means that, for an MIA to be successful, it must likely be based on overfitting attributes. Furthermore, given the empirical difficulties with obtaining independent and identically distributed (IID) candidate samples, choosing the non-trivial attributes of candidate samples as the target for exploring overfitting would be a more preferable choice. Hence, in this article, we propose a series of attribute-based MIAs that considers both black-box and white-box settings. The attacks are performed on the generator, and the inferences are derived by overfitting the non-trivial attributes. Additionally, we put forward a novel perspective on model generalization and a possible defense by evaluating the overfitting status of each individual attribute. A series of empirical evaluations in both settings demonstrate that the attacks remain stable and successful when using non-IID candidate samples. Further experiments illustrate that each attribute exhibits a distinct overfitting status. Moreover, manually generalizing highly overfitting attributes significantly reduces the risk of privacy leaks.}
}


@article{DBLP:journals/tdsc/ButoraPB24,
	author = {Jan Butora and
                  Pauline Puteaux and
                  Patrick Bas},
	title = {Errorless Robust {JPEG} Steganography Using Outputs of {JPEG} Coders},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2394--2406},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3306379},
	doi = {10.1109/TDSC.2023.3306379},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ButoraPB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robust steganography is a technique of hiding secret messages in images so that the message can be recovered after additional image processing. One of the most popular processing operations is JPEG recompression. Unfortunately, most of today's steganographic methods addressing this issue only provide a probabilistic guarantee of recovering the secret and are consequently not errorless. That is unacceptable since even a single unexpected change can make the whole message unreadable if it is encrypted. We propose to create a robust set of DCT coefficients by inspecting their behavior during recompression, which requires access to the targeted JPEG compressor. This is done by dividing the DCT coefficients into 64 non-overlapping lattices because one embedding change can potentially affect many other coefficients from the same DCT block during recompression. The robustness is then combined with standard steganographic costs creating a lattice embedding scheme robust against JPEG recompression. Through experiments, we show that the size of the robust set and the scheme's security depends on the ordering of lattices during embedding. We verify the validity of the proposed method with three typical JPEG compressors and the Slack instant messaging application. We benchmark its security for various embedding payloads, three different ways of ordering the lattices, and a range of Quality Factors. Finally, this method is errorless by construction, meaning the embedded message will always be readable.}
}


@article{DBLP:journals/tdsc/TianCZTYT24,
	author = {Zhiyi Tian and
                  Lei Cui and
                  Chenhan Zhang and
                  Shuaishuai Tan and
                  Shui Yu and
                  Yonghong Tian},
	title = {The Role of Class Information in Model Inversion Attacks Against Image
                  Deep Learning Classifiers},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2407--2420},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3306748},
	doi = {10.1109/TDSC.2023.3306748},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/TianCZTYT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model inversion attacks can reconstruct the training samples of victim deep learning models. The existing efforts heavily rely on auxiliary information of the target samples (prior target information) to achieve their adversarial goals. However, prior target information is hard to obtain in practice. In this article, we explore the effect of class information in model inversion attacks to reduce the reliance of prior target information. Our contributions on class information exploitation are two-fold. First, we propose a supervised inversion model, Supervised Model Inversion (SMI). The proposed inversion model learns pixel-level features and data-to-class features from the rounded-outputs of the victim model and labeled auxiliary dataset. Second, we leverage victim model's rounded-outputs to guide the optimization of reconstructing inversion samples after trained inversion model. Our experimental results show that inversion samples reconstructed by SMI are more visually plausible with more details, comparing to the three representative model inversion attacks. We further perform an extensive study on various auxiliary dataset settings. It is found that the class combination in the auxiliary dataset rather than the number of classes that determines the quality of inversion samples. The ground-truth labels can improve the qualities of inversion samples but not essential to inversion attacks.}
}


@article{DBLP:journals/tdsc/ChenWLHCGX24,
	author = {Libo Chen and
                  Yanhao Wang and
                  Jiaqi Linghu and
                  Qinsheng Hou and
                  Quanpu Cai and
                  Shanqing Guo and
                  Zhi Xue},
	title = {SaTC: Shared-Keyword Aware Taint Checking for Detecting Bugs in Embedded
                  Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2421--2433},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3307430},
	doi = {10.1109/TDSC.2023.3307430},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ChenWLHCGX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices have brought invaluable convenience to our daily life. However, their pervasiveness also amplifies the impact of security vulnerabilities. Many widespread vulnerabilities of embedded systems reside in their vulnerable border services. Unfortunately, existing vulnerability detection methods can neither effectively nor efficiently analyze such border services: they either introduce heavy execution overheads or have many false positives and negatives. In this article, we propose a novel static taint checking solution, SaTC, to effectively detect security vulnerabilities in border services provided by embedded devices. Our key insight is that string literals on border interfaces are commonly shared between front-end files and back-end binaries to encode user input. Thus, we extract common keywords from the front-end and use them to locate reference points in the back-end, which indicate the input entry. Then, we apply targeted data-flow analysis to detect dangerous uses of the untrusted user input accurately. We implemented a prototype of SaTC and evaluated it on 39 firmware samples from six popular vendors. SaTC discovered 36 unknown bugs, of which CVE/CNVD/PSV confirms 33. Compared to the state-of-the-art tool KARONTE, SaTC found significantly more bugs in the test set. It shows that SaTC is effective in discovering bugs in embedded systems.}
}


@article{DBLP:journals/tdsc/LiLLSZL24,
	author = {Shengyu Li and
                  Songfan Li and
                  Qingqing Liu and
                  Yihang Song and
                  Chong Zhang and
                  Li Lu},
	title = {Watch Out Your Thumb Drive: Covert Data Theft From Portable Data Storage
                  via Backscatter},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2434--2447},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3305607},
	doi = {10.1109/TDSC.2023.3305607},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiLLSZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {USB flash drives are widely employed for data storage including sensitive personal or business data. Current defense strategies to protect those data mainly focus on preventing data theft when a USB drive plugs into a host computer that is infected with malware. This paper reveals a threat - attackers can produce spy USB flash drives that are able to leak the stored data via covert wireless communication without triggering security defenses on host computers. In this paper, we present SpyUSB, a USB flash drive implanted with a backscatter-based data theft hardware to demonstrate the threat of covert data theft. SpyUSB collects data from the physical layer of the communication between the host computer and SpyUSB device, which is transparent to the security mechanisms on the host computer. SpyUSB leverages backscatter communication to create a covert wireless channel. Furthermore, we explore the opportunity of covert data theft when the SpyUSB device is disconnected from the host computer using a tiny energy reservoir. Our experiment shows that SpyUSB can achieve a transmission bandwidth of up to 1,600 kbps. After unplugged from a computer, it can maintain standby for over 6 hours or continuously transmit data for 1.9 hours.}
}


@article{DBLP:journals/tdsc/LiangTZYZ24,
	author = {Xiaoping Liang and
                  Zhenjun Tang and
                  Xianquan Zhang and
                  Mengzhu Yu and
                  Xinpeng Zhang},
	title = {Robust Hashing With Local Tangent Space Alignment for Image Copy Detection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2448--2460},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3307403},
	doi = {10.1109/TDSC.2023.3307403},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiangTZYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robust hashing is a useful technique for the image applications of watermarking, authentication, quality assessment and copy detection. This article proposes a new robust hashing for image copy detection by using local tangent space alignment (LTSA). A key contribution is the weighted visual map computation based on the difference of Gaussian (DOG) and visual attention model. The weighted visual map can provide the proposed method with good robustness. Another contribution is the feature learning via LTSA from the feature matrix of the weighted visual map in discrete cosine transform domain. As it can maintain the local geometric relationships within image, the learned features can make the proposed method discriminative. Extensive experiments on public databases are conducted to validate the proposed robust hashing method. Compared with some famous robust hashing methods, the proposed robust hashing method demonstrates preferable classification performance in terms of discrimination and robustness. Copy detection performance is tested and the result verifies effectiveness of the proposed robust hashing method.}
}


@article{DBLP:journals/tdsc/ManiKBADP24,
	author = {Ganapathy Mani and
                  Myeongsu Kim and
                  Bharat K. Bhargava and
                  Pelin Angin and
                  Ay{\c{c}}a Deniz and
                  Vikram Pasumarti},
	title = {Malware Speaks! Deep Learning Based Assembly Code Processing for Detecting
                  Evasive Cryptojacking},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2461--2477},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3307445},
	doi = {10.1109/TDSC.2023.3307445},
	timestamp = {Fri, 02 Aug 2024 21:41:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ManiKBADP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing prevalence of blockchain-based cryptocurrencies as a payment instrument in the past decade and the rewards earned by the cryptominers has resulted in a new class of cyber attacks, cryptojacking, which involves unauthorized mining of cryptocurrencies on someone's system. Spotting cryptojacking is difficult in many cases, since the relevant software tries to disguise its presence to evade detection, by mimicking benign software such as compression applications by performing similar bitwise, cryptographic, and encryption operations. In this paper, we propose the processing of assembly code—a fundamental and platform-independent programming language—as a natural language using deep learning for profiling applications, which we call Deep Code Profiler (DeCode Pro). Our proposed solution leverages the immutable step of any cyber attack: the deployment of instructions in system memory to carry out the attack. Through extensive experimentation with different neural network architectures in the profiling stage, we show that DeCode Pro is highly effective in the detection of evasive cryptojacking attacks and achieves low false positive and false negative rates. We also show that the model achieves high classification accuracy even with limited training data, which can considerably reduce the computing resources required for training and retraining the deep learning model.}
}


@article{DBLP:journals/tdsc/JalalzaiNFG24,
	author = {Mohammad M. Jalalzai and
                  Jianyu Niu and
                  Chen Feng and
                  Fangyu Gai},
	title = {Fast-HotStuff: {A} Fast and Robust {BFT} Protocol for Blockchains},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2478--2493},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3308848},
	doi = {10.1109/TDSC.2023.3308848},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/JalalzaiNFG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The HotStuff protocol is a recent breakthrough in Byzantine Fault Tolerant (BFT) consensus that enjoys both responsiveness and linear view change by creatively adding a round to classic two-round BFT protocols like PBFT. Despite its great advantages, HotStuff has a few limitations. First, the additional round of communication during normal cases results in higher latency. Second, HotStuff is vulnerable to certain performance attacks, which can significantly deteriorate its throughput and latency. To address these limitations, we propose a new two-round BFT protocol called Fast-HotStuff, which enjoys responsiveness and efficient view change that is comparable to the linear view-change in terms of performance. Our Fast-HotStuff has lower latency and is more robust against the performance attacks that HotStuff is susceptible to.}
}


@article{DBLP:journals/tdsc/TongNHLZ24,
	author = {Wei Tong and
                  Jiacheng Niu and
                  Jingyu Hua and
                  Qun Li and
                  Sheng Zhong},
	title = {Scalable Differentially Private Model Publishing Via Private Iterative
                  Sample Selection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2494--2506},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3309089},
	doi = {10.1109/TDSC.2023.3309089},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/TongNHLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model publishing and deployment are essential for artificial intelligence applications. A major challenge in model publishing is efficiently distributing the models in a scalable way without violating the privacy of sensitive data. With the wide adoption of machine learning techniques, the privacy concern has also drawn much attraction. Differential privacy has become an important notion for privacy protection and is popular in private learning. However, it may bring much accuracy loss to fulfill data privacy. In addition, the private models are also hard to train in terms of convergence, which makes the existing approaches not scalable for private model publishing. This paper proposes a model publishing framework that provides a novel way to train privacy-preserving machine learning models with fast convergence and a lower privacy budget. By incorporating the concept of iterative machine teaching and the techniques in differential privacy, we have explored a way to privately select more suitable examples in the training process for achieving good accuracy with fewer iterations. Our analysis shows the privacy and convergence performance of the proposed method, and extensive experiments have been performed on real-world datasets to demonstrate its effectiveness.}
}


@article{DBLP:journals/tdsc/ZhangFYSZC24,
	author = {Quanjun Zhang and
                  Chunrong Fang and
                  Bowen Yu and
                  Weisong Sun and
                  Tongke Zhang and
                  Zhenyu Chen},
	title = {Pre-Trained Model-Based Automated Software Vulnerability Repair: How
                  Far are We?},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2507--2525},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3308897},
	doi = {10.1109/TDSC.2023.3308897},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangFYSZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Various approaches are proposed to help under-resourced security researchers to detect and analyze software vulnerabilities. It is still incredibly time-consuming and labor-intensive for security researchers to fix such reported vulnerabilities due to the increasing size and complexity of modern software systems. The time lag between the reporting and fixing of a security vulnerability causes software systems to suffer from significant exposure to possible attacks. Very recently, some techniques propose to apply pre-trained models to fix security vulnerabilities and have proved their success in improving repair accuracy. However, the effectiveness of existing pre-trained models has not been systematically compared and little is known about their advantages and disadvantages. To bridge this gap, we perform the first extensive study on applying various pre-trained models to automated vulnerability repair. The experimental results on two vulnerability datasets show that all studied pre-trained models consistently outperform the state-of-the-art technique VRepair with a prediction accuracy of 32.94%$\\sim$44.96%. We also investigate the impact of three major phases (i.e., data pre-processing, model training and repair inference) in the vulnerability repair workflow. Inspired by the findings, we construct a simplistic vulnerability repair approach that adopts the transfer learning from bug fixing. Surprisingly, such a simplistic approach can further improve the prediction accuracy of pre-trained models by 9.40% on average. Besides, we provide additional discussion from different aspects (e.g., code representation and a preliminary study with ChatGPT) to illustrate the capacity and limitation of pre-trained model-based techniques. Finally, we further pinpoint various practical guidelines (e.g., the improvement of fine-tuning) for advanced pre-trained model-based vulnerability repair in the near future. Our study highlights the promising future of adopting pre-trained models to patch real-world security vulnerabilities and reduce the manual debugging effort of security experts in practice.}
}


@article{DBLP:journals/tdsc/CastiglioneL24,
	author = {Luca Maria Castiglione and
                  Emil C. Lupu},
	title = {Which Attacks Lead to Hazards? Combining Safety and Security Analysis
                  for Cyber-Physical Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2526--2540},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3309778},
	doi = {10.1109/TDSC.2023.3309778},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/CastiglioneL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-Physical Systems (CPS) are exposed to a plethora of attacks and their attack surface is only increasing. However, whilst many attack paths are possible, only some can threaten the system's safety and potentially lead to loss of life. Identifying them is of essence. We propose a methodology and develop a tool-chain to systematically analyse and enumerate the attacks leading to safety violations. This is achieved by lazily combining threat modelling and safety analysis with formal verification and with attack graph analysis. We also identify the minimum sets of privileges that must be protected to preserve safety. We demonstrate the effectiveness of our methodology to discover threat scenarios by applying it to a Communication Based Train Control System. Our design choices emphasise compatibility with existing safety and security frameworks, whilst remaining agnostic to specific tools or attack graphs representations.}
}


@article{DBLP:journals/tdsc/DengDQG24,
	author = {Shuhua Deng and
                  Wenjie Dai and
                  Xian Qing and
                  Xieping Gao},
	title = {Vulnerabilities in {SDN} Topology Discovery Mechanism: Novel Attacks
                  and Countermeasures},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2541--2551},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3314111},
	doi = {10.1109/TDSC.2023.3314111},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DengDQG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software-defined networking (SDN) has significantly enriched network functions by separating the control plane from the data plane. Meanwhile, the unique architecture of SDN brings new security challenges. Recent studies show that attackers can fabricate inter-switch links to hijack the traffic or interfere with network services. In this paper, we uncover two new vulnerabilities that can tamper with the topology view of the SDN controller. Then, we present two novel attacks named Cluster Splitting and Cluster Amnesia according to such flaws. We split or forget partial network topology by establishing a broadcast domain port or external link. As a result, it affects the module responsible for computing topology instances and disrupts the routing calculations. To defend against such attacks, we design a two-stage algorithm to verify the switch port and link in real-time. With the principle of saving the limited control channel resources and not extending the LLDP protocol, we propose LldpChecker. As a lightweight extension for SDN controllers, it can filter malicious broadcast domain ports and external links. We conduct a series of experiments to evaluate the effectiveness and efficiency of LldpChecker. The results show that LldpChecker can effectively mitigate these two novel attacks with negligible overhead.}
}


@article{DBLP:journals/tdsc/LiLLLLZ24,
	author = {Yuanfei Li and
                  Xiong Li and
                  Xiangyang Luo and
                  Zhetao Li and
                  Hongwei Li and
                  Xiaosong Zhang},
	title = {AnotherMe: {A} Location Privacy Protection System Based on Online
                  Virtual Trajectory Generation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2552--2567},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3314200},
	doi = {10.1109/TDSC.2023.3314200},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiLLLLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, location-based services (LBS) are becoming increasingly important and popular. However, many LBSs are probable to collect the location information of users, which leads to the leakage of location privacy. To address this problem, dummy-based schemes have been proposed by researchers. Nevertheless, most of them only consider semantic information instead of points of interest (POIs), so the virtual trajectories may be detected by advanced data mining techniques. Besides, some of them are offline or non-local, which are not suitable for online LBS scenarios. In this article, we design AnotherMe, an online and local location privacy-preserving system based on virtual trajectory generation, and develop the system on Android and iOS platforms. The AnotherMe system has two main functions. One is to generate virtual users located in different cities by imitating the real user's moving pattern and mapping the real user's POIs, and the other is to generate virtual trajectories that are indistinguishable from real trajectories with the help of Amap API. Therefore, the AnotherMe system can preserve continuous location privacy, and even advanced data mining techniques are difficult to distinguish between the real trajectory and the corresponding virtual trajectory. Due to low response time and battery consumption, the AnotherMe system is practical for location privacy protection. Furthermore, experimental results show that the virtual trajectories generated by our solution are more indistinguishable from real trajectories than similar solutions, and the average recognition rate of virtual trajectories is 53.8%, which is close to random guessing (50%).}
}


@article{DBLP:journals/tdsc/HuLXX24,
	author = {Aoting Hu and
                  Zhigang Lu and
                  Renjie Xie and
                  Minhui Xue},
	title = {{\textdollar}\{{\textbackslash}sf VeriDIP\}{\textdollar}VeriDIP: Verifying
                  Ownership of Deep Neural Networks Through Privacy Leakage Fingerprints},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2568--2584},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3313577},
	doi = {10.1109/TDSC.2023.3313577},
	timestamp = {Wed, 16 Oct 2024 16:36:24 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HuLXX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deploying Machine Learning as a Service gives rise to model plagiarism, leading to copyright infringement. Ownership testing techniques are designed to identify model fingerprints for verifying plagiarism. However, previous works often rely on overfitting or robustness features as fingerprints, lacking theoretical guarantees and exhibiting under-performance on generalized models. In this article, we propose a novel ownership testing method called VeriDIP, which verifies a DNN model's intellectual property. VeriDIP makes two major contributions. 1) It utilizes membership inference attacks to estimate the lower bound of privacy leakage, which reflects the fingerprint of a given model. The privacy leakage fingerprints highlight the unique patterns through which the models memorize sensitive training datasets. 2) We introduce a novel approach using less private samples to enhance the performance of ownership testing. Extensive experimental results confirm that VeriDIP is effective and efficient in validating the ownership of deep learning models trained on both image and tabular datasets. VeriDIP achieves comparable performance to state-of-the-art methods on image datasets while significantly reducing computation and communication costs. Enhanced VeriDIP demonstrates superior verification performance on generalized deep learning models, particularly on table-trained models. Additionally, VeriDIP exhibits similar effectiveness on utility-preserving differentially private models compared to non-differentially private baselines.}
}


@article{DBLP:journals/tdsc/ShiYLFSPD24,
	author = {Rui Shi and
                  Yang Yang and
                  Yingjiu Li and
                  Huamin Feng and
                  Guozhen Shi and
                  HweeHwa Pang and
                  Robert H. Deng},
	title = {Double Issuer-Hiding Attribute-Based Credentials From Tag-Based Aggregatable
                  Mercurial Signatures},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2585--2602},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3314019},
	doi = {10.1109/TDSC.2023.3314019},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ShiYLFSPD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attribute-based anonymous credentials offer users fine-grained access control in a privacy-preserving manner. However, in such schemes obtaining a user's credentials requires knowledge of the issuer's public key, which obviously reveals the issuer's identity that must be hidden from users in certain scenarios. Moreover, verifying a user's credentials also requires the knowledge of issuer's public key, which may infer the user's private information from their choice of issuer. In this article, we introduce the notion of double issuer-hiding attribute-based credentials (\nDIHAC\n) to tackle these two problems. In our model, a central authority can issue public-key credentials for a group of issuers, and users can obtain attribute-based credentials from one of the issuers without knowing which one it is. Then, a user can prove that their credential was issued by one of the authenticated issuers without revealing which one to a verifier. We provide a generic construction, as well as a concrete instantiation for\nDIHAC\nbased on structure-preserving signatures on equivalence classes (JOC's 19) and a novel primitive which we call\ntag\n-\nbased\naggregatable\nmercurial\nsignatures\n. Our construction is efficient without relying on zero-knowledge proofs. We provide rigorous evaluations on personal laptop and smartphone platforms, respectively, to demonstrate its practicability.}
}


@article{DBLP:journals/tdsc/LiuXTLCGWS24,
	author = {Yizhong Liu and
                  Xinxin Xing and
                  Ziheng Tong and
                  Xun Lin and
                  Jing Chen and
                  Zhenyu Guan and
                  Qianhong Wu and
                  Willy Susilo},
	title = {Secure and Scalable Cross-Domain Data Sharing in Zero-Trust Cloud-Edge-End
                  Environment Based on Sharding Blockchain},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2603--2618},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3313799},
	doi = {10.1109/TDSC.2023.3313799},
	timestamp = {Fri, 19 Jul 2024 23:17:20 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuXTLCGWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cloud-edge-end architecture is suitable for many essential scenarios, such as 5G, the Internet of Things (IoT), and mobile edge computing. Under this architecture, cross-domain and cross-layer data sharing is commonly in need. Considering cross-domain data sharing under the zero-trust model, where each entity does not trust the others, existing solutions have certain problems regarding security, fairness, scalability, and efficiency. Aiming at solving these issues, we conduct the following research. First, a new plaintext checkable encryption scheme is constructed, which can be used on lightweight IoT devices to verify the ciphertext validity sent by a data owner. Second, we propose a new multi-domain cloud-edge-end architecture based on sharding blockchains and design a cross-domain data sharing scheme under the partial trust model to achieve security, scalability, and high performance. Third, a cross-domain data sharing scheme under the zero trust model is further designed, which can ensure the fairness of both parties in data sharing. Fourth, we give a formal security definition and analysis of cross-domain data sharing. Fifth, we conduct a detailed theoretical analysis of the protocol and give an in-depth functional test and performance test, including the throughput and latency of data sharing policy registration and execution.}
}


@article{DBLP:journals/tdsc/QinLDLXC24,
	author = {Junren Qin and
                  Shanxiang Lyu and
                  Jiarui Deng and
                  Xingyuan Liang and
                  Shijun Xiang and
                  Hao Chen},
	title = {A Lattice-Based Embedding Method for Reversible Audio Watermarking},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2619--2630},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3314612},
	doi = {10.1109/TDSC.2023.3314612},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/QinLDLXC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing reversible audio watermarking (RAW) techniques are often vulnerable to intentional or even unintentional attacks on the cover object. This article proposes a robust RAW scheme based on lattices, which is referred to as Meet-in-the-Middle Embedding (MME). In MME, the lattice quantization errors are properly scaled and added back to the quantized host signals such that the receiver can estimate the cover. Scaling factor serves as a key factor to the reversibility of MME, whose feasible range is rigorously justified. Both theoretically and experimentally, we demonstrate the superiority of MME to improved quantization index modulation (IQIM) in terms of signal-to-watermark ratio (SWR) and generalized signal-to-noise ratio (GSNR). Moreover, simulations show that MME also outperforms other state-of-the-arts in SWR, objective difference grade (ODG), and bit error rate (BER).}
}


@article{DBLP:journals/tdsc/OliveiraGBGMR24,
	author = {Daniel Oliveira and
                  Edoardo Giusto and
                  Betis Baheri and
                  Qiang Guan and
                  Bartolomeo Montrucchio and
                  Paolo Rech},
	title = {A Systematic Methodology to Compute the Quantum Vulnerability Factors
                  for Quantum Circuits},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2631--2644},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3313934},
	doi = {10.1109/TDSC.2023.3313934},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/OliveiraGBGMR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum computing is one of the most promising technology advances of the latest years. Qubits are highly sensitive to noise, which can make the output useless. Lately, it has been shown that superconducting qubits are extremely susceptible to external sources of faults, such as ionizing radiation. When adopted in large scale, radiation-induced errors are expected to become a serious challenge for qubits reliability. We propose an evaluation of the impact of transient faults in the execution of quantum circuits on superconducting chips. Inspired by the Architectural and Program Vulnerability Factors, widely used for classical computation, we propose the Quantum Vulnerability Factor (QVF) to measure the impact of qubit corruption on the circuit output. We model faults, and design a fault injector, based on the latest studies on real machines and radiation experiments. We report the finding of more than 388,000,000 fault injections, considering single and double faults, on three algorithms, identifying the faults and qubits that are more likely to impact the output. We give guidelines on how to map the qubits in real devices to reduce the output error and to reduce the probability of having a radiation-induced corruption modifying the output. Finally, we compare simulations with experiments on physical quantum computers.}
}


@article{DBLP:journals/tdsc/YaoLHLQR24,
	author = {Hongwei Yao and
                  Zheng Li and
                  Kunzhe Huang and
                  Jian Lou and
                  Zhan Qin and
                  Kui Ren},
	title = {RemovalNet: {DNN} Fingerprint Removal Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2645--2658},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3315064},
	doi = {10.1109/TDSC.2023.3315064},
	timestamp = {Wed, 24 Jul 2024 07:50:48 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YaoLHLQR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the performance of deep neural networks (DNNs) remarkably improving, DNNs have been widely used in many areas. Consequently, the DNN model has become a valuable asset, and its intellectual property is safeguarded by ownership verification techniques (e.g., DNN fingerprinting). However, the feasibility of the DNN fingerprint removal attack and its potential influence remains an open problem. In this article, we perform the first comprehensive investigation of DNN fingerprint removal attacks. Generally, the knowledge contained in a DNN model can be categorized into general semantic and fingerprint-specific knowledge. To this end, we propose a min-max bilevel optimization-based DNN fingerprint removal attack named RemovalNet, to evade model ownership verification. The lower-level optimization is designed to remove fingerprint-specific knowledge. While in the upper-level optimization, we distill the victim model's general semantic knowledge to maintain the surrogate model's performance. We conduct extensive experiments to evaluate the fidelity, effectiveness, and efficiency of the RemovalNet against four advanced defense methods on six metrics. The empirical results demonstrate that (1) the RemovalNet is effective. After our DNN fingerprint removal attack, the model distance between the target and surrogate models is \\times 100\ntimes higher than that of the baseline attacks, (2) the RemovalNet is efficient. It uses only 0.2% (400 samples) of the substitute dataset and 1,000 iterations to conduct our attack. Besides, compared with advanced model stealing attacks, the RemovalNet saves nearly 85% of computational resources at most, (3) the RemovalNet achieves high fidelity that the created surrogate model maintains high accuracy after the DNN fingerprint removal process.}
}


@article{DBLP:journals/tdsc/SmetSB24,
	author = {Ruben de Smet and
                  Kris Steenhaut and
                  An Braeken},
	title = {Private Electronic Road Pricing Using Bulletproofs With Vector Commitments},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2659--2671},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3314867},
	doi = {10.1109/TDSC.2023.3314867},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SmetSB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a novel approach to privacy preserving electronic road pricing (ERP) based on on-board units (OBUs) and zero-knowledge proofs (ZKPs), and without any need for tamper-proof elements. Since our approach is software-only and protocol-enforced, it can be rapidly deployed on off-the-shelve or even pre-existing hardware, such as a smartphone or the on-board computer of a car. In addition, communication complexity is only logarithmic in function of route length, such that even for short routes the communication cost of the protocol is lower than the cost of naively transmitting the clear text route. Our implementation proves the construction to be computationally practical, especially for the verifier. Since the scheme is based on ZKPs, no unnecessary information gets leaked. At the basis of the scheme lies Bulletproofs, which is modified to provide native support for Pedersen vector commitments with logarithmic impact on proof size.}
}


@article{DBLP:journals/tdsc/GongFLWCW24,
	author = {Xueluan Gong and
                  Zheng Fang and
                  Bowen Li and
                  Tao Wang and
                  Yanjiao Chen and
                  Qian Wang},
	title = {Palette: Physically-Realizable Backdoor Attacks Against Video Recognition
                  Models},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2672--2685},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3314792},
	doi = {10.1109/TDSC.2023.3314792},
	timestamp = {Wed, 24 Jul 2024 21:43:19 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GongFLWCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Backdoor attacks have been widely studied for image classification tasks, but rarely investigated for video recognition tasks. In this paper, we explore the possibility of physically-realizable backdoor attacks against video recognition models. Different from existing works that directly apply image backdoor attacks to videos, i.e., patch a visible trigger to each frame of a video, we carefully take into consideration the temporal interactions among frames in a video. Our proposed video backdoor attack, named Palette, features two special design choices. The first is to utilize natural-light-alike RGB offset as triggers rather than traditional patch triggers. Such triggers may be applied in the physical world through lighting without the need to modify video files. The second is to make the backdoored model more robust to temporal asynchronization between the trigger and the video samples by performing rolling operations during sample poisoning. Extensive experiments show that Palette outperforms existing video backdoor attacks, especially in the physical world. It is shown that Palette is also resistant to backdoor defense methods. We will open-source our codes upon publication.}
}


@article{DBLP:journals/tdsc/RyuKH24,
	author = {Dohyun Ryu and
                  Yerim Kim and
                  Junbeom Hur},
	title = {{\textdollar}{\textbackslash}gamma{\textdollar}{\(\gamma\)}-Knife:
                  Extracting Neural Network Architecture Through Software-Based Power
                  Side-Channel},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2686--2703},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3314710},
	doi = {10.1109/TDSC.2023.3314710},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/RyuKH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Several side-channel attacks exploiting timing, cache, or power side channels have recently been proposed to obtain private information of a neural network. However, the hardware-based attacks require physical access to the system, using high-precision equipment to measure physical system behaviors such as power consumption or electromagnetic emanations, to exploit them as side channels. Whereas, the previous software-based side-channel attacks on neural networks can extract their model information only when the target architecture is known. In this article, we propose the \\gamma\nγ-Knife attack, a software-based power side-channel attack on a neural network, which can extract its architecture without any physical access or high-precision measuring equipment. Our work demonstrates that side-channels can be formed that leak architecture of neural networks by utilizing statistical metrics without high-resolution power data. The \\gamma\n-Knife attack can reduce the search space of candidate architectures by obtaining private information such as filter size, depth of convolutional layer, and activation functions in the target architecture, as accurately as hardware-based power side-channel attacks even when the target neural network is totally unknown. We demonstrated the efficacy of the \\gamma\n-Knife attack by implementing the attack on the well-known neural networks VGGNet, ResNet, GoogleNet, and MobileNet, using the Pytorch library on Intel CPUs and AMD CPUs. The \\gamma\n-Knife attack could identify the target neural network architecture with an accuracy of approximately 90%, and efficiently extract its private information, by significantly reducing the search space of the target architecture.}
}


@article{DBLP:journals/tdsc/LuXLXL24,
	author = {Ruiqi Lu and
                  Guoqi Xie and
                  Renfa Li and
                  Wei Xu and
                  Jianmei Lei},
	title = {TrinitySec: Trinity-Enabled and Lightweight Security Framework for
                  {CAN-FD} Communication},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2704--2719},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3314908},
	doi = {10.1109/TDSC.2023.3314908},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LuXLXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Controller Area Network with Flexible Data-rate (CAN-FD) is a promising industrial embedded network because of its high bandwidth and long data field length. However, CAN-FD does not deploy any security protection mechanisms, leaving it vulnerable to network attacks. In recent years, authentication and authorization frameworks have often been deployed in industrial embedded networks (e.g., automotive networks) to provide secure CAN/CAN-FD communication. However, these frameworks cannot simultaneously enhance confidentiality, integrity, and availability; moreover, these frameworks are mainly based on a distributed security management mechanism, resulting in large computation, communication,and memory overhead. This article proposes a trinity-enabled and lightweight security framework called TrinitySec based on cryptographic algorithms for CAN-FD communication. TrinitySec ensures the availability of ECU and CAN-FD messages through authentication and authorization, as well as the confidentiality and integrity of CAN-FD messages through a symmetric-key algorithm and Hash-based Message Authentication Code (HMAC) function. TrinitySec proposes a low-overhead centralized security management mechanism instead of the existing distributed management mechanism. We formally verify the security of TrinitySec using the ProVerif tool. We implement TrinitySec on STM32H743IIT Micro Controller Units (MCUs) with ARM Cortex M7 core and evaluate that TrinitySec outperforms other state-of-the-art security frameworks in terms of computation, communication, memory, and storage overhead.}
}


@article{DBLP:journals/tdsc/HeBHPGR24,
	author = {Anxiao He and
                  Kai Bu and
                  Jiongrui Huang and
                  Yifei Pang and
                  Qianping Gu and
                  Kui Ren},
	title = {SwiftParade: Anti-Burst Multipath Validation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2720--2734},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3315457},
	doi = {10.1109/TDSC.2023.3315457},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HeBHPGR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Path validation promises a necessary security add-on for future Internet architectures. It authenticates not only source identities but also the exact path where a packet forwards through. This offers users more flexibility and reliability in network services. Most existing solutions focus on single-path validation that pre-correlates a packet to a specific forwarding path. However, parallel transmissions in multipath routing tend to induce bursty traffic that is hardly validated in time by existing solutions. In this paper, we present SwiftParade as the first attempt toward anti-burst multipath validation. It proposes a composite validation technique that can simultaneously validate a group of packets likely from multiple different paths. This helps to amortize the validation overhead across packets of the entire group instead of imposing the validation overhead equally on every packet. To implement composite validation, SwiftParade further explores a noncommutative homomorphic asymmetric encryption scheme. We prove effectiveness and security of SwiftParade through theoretical analysis. We also conduct extensive experiments to evaluate SwiftParade performance. The results show that SwiftParade offers high efficiency and applicability to multipath validation with complex routing topologies. In comparison with the state-of-the-art multipath validation solution—Atlas, SwiftParade speeds up packet processing by 2.5\\times \\,\\sim 8.3\\times and increases communication throughput by 2.8\\times \\,\\sim 10.2\\times.}
}


@article{DBLP:journals/tdsc/RathorAS24,
	author = {Mahendra Rathor and
                  Aditya Anshul and
                  Anirban Sengupta},
	title = {Securing Reusable {IP} Cores Using Voice Biometric Based Watermark},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2735--2749},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3315780},
	doi = {10.1109/TDSC.2023.3315780},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/RathorAS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reusable third-party intellectual property (3PIP) cores within the supply chain are vulnerable to hardware threats such as IP piracy and false claim of ownership. Securing the reusable IP cores is vital to protect the original vendor from a substantial revenue loss and his/her brand value. This paper presents a novel hardware IP core watermarking methodology based on voice biometric signature to enable detective control against IP piracy and resolve IP ownership claim. To the best of our knowledge, this is the first voice biometric-based hardware IP protection technique. This paper proposes a novel methodology for generating a unique voice signature template using distinct voice features, viz. jitter and shimmer, along with pitch and intensity values at different timestamps. We present a high-level synthesis (HLS) design methodology of embedding a voice signature digital template during the register allocation phase to generate secured IP cores. Results and analysis imply that the proposed approach can significantly improve security in terms of stronger authorship proof and higher tamper tolerance compared to the existing IP watermarking approaches. Additionally, we also analyze the uniqueness of a voice signature and its security against forgery attack. We achieve higher security at negligible design cost overhead.}
}


@article{DBLP:journals/tdsc/GuanLZZSW24,
	author = {Yunguo Guan and
                  Rongxing Lu and
                  Songnian Zhang and
                  Yandong Zheng and
                  Jun Shao and
                  Guiyi Wei},
	title = {{\textdollar}k{\textdollar}kTCQ: Achieving Privacy-Preserving {\textdollar}k{\textdollar}k-Truss
                  Community Queries Over Outsourced Data},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2750--2765},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3317401},
	doi = {10.1109/TDSC.2023.3317401},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GuanLZZSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search over graphs, which is believed as a powerful tool for locating subgraphs of closely related vertices, has received considerable attention in recent years, and k-truss is such a popular community search metric to obtain subgraphs in which every edge forms (k-2) triangles. In this paper, we particularly consider k-truss community query services, which will return all k-truss communities containing a given query vertex. As is known, when the size of graph grows, for achieving better performance, it is natural for a service provider to outsource the services to a powerful cloud. However, this stresses the need for privacy-preserving k-truss community query services, as the cloud server is not fully trustable. Over the past years, many schemes focusing on privacy-preserving graph computation have been put forth, but none of them can well support privacy-preserving k-truss community queries. Aiming at this challenge, we first propose a privacy-preserving k-truss community query scheme (kTCQ) by constructing boolean circuits with homomorphic encryption technique and a table-based index. After that, we also design an efficiency-enhanced version (kTCQ+) based on a stream cipher scheme to reduce the encrypted index's size and improve the query efficiency. Detailed security analysis shows that both kTCQ and kTCQ+ can well preserve data privacy and access pattern privacy, and extensive experimental results also demonstrate that kTCQ+ can observably reduce the size of encrypted index and the query time by 12\\times and 5.9\\times, respectively.}
}


@article{DBLP:journals/tdsc/FanKW24,
	author = {Chun{-}I Fan and
                  Arijit Karati and
                  Shou{-}Li Wu},
	title = {A Privacy-Aware Provably Secure Smart Card Authentication Protocol
                  Based on Physically Unclonable Functions},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2766--2778},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3317675},
	doi = {10.1109/TDSC.2023.3317675},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/FanKW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For many industrial applications, the smart card is a necessary safety component in user authentication. Smart cards provided to the users are used in open and public places, making them susceptible to physical and cloning attacks. Thus, the opponent can break the authentication process without the smart card if the information is exposed. In addition, many existing authentication systems employ challenge-response pairs (CRPs) to identify users by creating large numbers of data on the server and spending much time looking for and comparing responses. To address these concerns, we propose a lightweight privacy-preserving authentication protocol in which the physically unclonable function is considered a necessary tool. The suggested technique avoids creating a significant number of CRPs on the server to identify users uniquely. Under formal security models, the proposed protocol is resistant to user impersonation attacks and session key disclosure attacks and achieves robust mutual authentication. Nonetheless, it is immune to other essential security vulnerabilities. Empirical performance analysis demonstrates its viability in comparison to prior works.}
}


@article{DBLP:journals/tdsc/FuXWRZB24,
	author = {Junsong Fu and
                  Shuai Xiong and
                  Na Wang and
                  Ruiping Ren and
                  Ang Zhou and
                  Bharat K. Bhargava},
	title = {A Framework of High-Speed Network Protocol Fuzzing Based on Shared
                  Memory},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2779--2798},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3318571},
	doi = {10.1109/TDSC.2023.3318571},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/FuXWRZB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, security test of network protocols based on fuzzing has been attracting more and more attentions. This is very challenging compared with the stateless software fuzzing and most early network protocol fuzzers are of low speed and poor test effect. Since the first greybox and stateful fuzzer named AFLNET was proposed, several new schemes have been designed to improve its performance from different aspects. During the research, a great challenge is how to greatly improve the fuzzing efficiency. Based on the basic analysis in SNPSFuzzer, this article provides a more thorough analysis about the time consumption in a fuzzing iteration for 13 network protocols and then we design a High-speed Network Protocol Fuzzer named HNPFuzzer. In HNPFuzzer, the test cases and response messages between the client and server are transmitted through the shared memory, guided by a precise synchronizer, rather than the socket interfaces. This greatly shorten the period of an iteration. Moreover, we design a persistent mode attempting to fuzz the service instances in the memory more than one time based on analyzing the side effect information. This mode further improves the speed of fuzzing. Experiment results illustrate that our scheme can improve the fuzzing throughput by about 39.66 times in average and triggers a large number of crashes including 2 new vulnerabilities which cannot discovered by existing fuzzers. Note that, the existing network protocol fuzzing schemes proposed in different directions do not compete with each other and on the contrary, they can collaborate with each other to improve the overall fuzzing effect and efficiency. Consequently, more existing tools can be integrated into our framework to get better network protocol fuzzing effect.}
}


@article{DBLP:journals/tdsc/OqailyKMJZPWD24,
	author = {Momen Oqaily and
                  Mohammad Ekramul Kabir and
                  Suryadipta Majumdar and
                  Yosr Jarraya and
                  Mengyuan Zhang and
                  Makan Pourzandi and
                  Lingyu Wang and
                  Mourad Debbabi},
	title = {iCAT+: An Interactive Customizable Anonymization Tool Using Automated
                  Translation Through Deep Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2799--2817},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3317806},
	doi = {10.1109/TDSC.2023.3317806},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/OqailyKMJZPWD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data anonymization is a viable solution for data owners to mitigate their privacy concerns. However, existing data anonymization tools are inflexible to support various privacy and utility requirements of both data owners and data users. In most cases, this limitation is due to a lack of understanding of those requirements as well as the non-customizability of the existing tools. To address this limitation, we propose iCAT+, which is an interactive and customizable anonymization approach. More specifically, we first automate the interpretation of data owners’ and data users’ textual requirements by deploying a Convolutional Neural Network (CNN) model for Natural Language Processing (NLP). Second, we introduce the concept of the anonymization space to model possible combinations of per-attribute anonymization primitives based on the level of privacy and utility that each primitive provides. Third, we design an ontology model that maps the translated requirements into their appropriate anonymization primitives in the defined anonymization space corresponding to the plain data. Fourth, we evaluate the efficiency and effectiveness of iCAT+ based on both real and synthetic network data. Finally, we assess its usability through a real user study involving participants from industry and research laboratories. Our experiments show the effectiveness and efficiency of our solution (e.g., requirement translation accuracy of 99% at the data owner side and 98% at the data user side, with a computational time of around one minute for the Google cluster dataset).}
}


@article{DBLP:journals/tdsc/BenzaidTSH24,
	author = {Chafika Benza{\"{\i}}d and
                  Tarik Taleb and
                  Ashkan Sami and
                  Othmane Hireche},
	title = {FortisEDoS: {A} Deep Transfer Learning-Empowered Economical Denial
                  of Sustainability Detection Framework for Cloud-Native Network Slicing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2818--2835},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3318606},
	doi = {10.1109/TDSC.2023.3318606},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/BenzaidTSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network slicing is envisaged as the key to unlocking revenue growth in 5G and beyond (B5G) networks. However, the dynamic nature of network slicing and the growing sophistication of DDoS attacks rises the menace of reshaping a stealthy DDoS into an Economical Denial of Sustainability (EDoS) attack. EDoS aims at incurring economic damages to service provider due to the increased elastic use of resources. Motivated by the limitations of existing defense solutions, we propose FortisEDoS, a novel framework that aims at enabling elastic B5G services that are impervious to EDoS attacks. FortisEDoS integrates a new deep learning-powered DDoS anomaly detection model, dubbed CG-GRU, that capitalizes on the capabilities of emerging graph and recurrent neural networks in capturing spatio-temporal correlations to accurately discriminate malicious behavior. Furthermore, FortisEDoS leverages transfer learning to effectively defeat EDoS attacks in newly deployed slices by exploiting the knowledge learned in a previously deployed slice. The experimental results demonstrate the superiority of CG-GRU in achieving higher detection performance of more than 92% with lower computation complexity. They show also that transfer learning can yield an attack detection sensitivity of above 91%, while accelerating the training process by at least 61%. Further analysis shows that FortisEDoS exhibits intuitive explainability of its decisions, fostering trust in deep learning-assisted systems.}
}


@article{DBLP:journals/tdsc/TianZH24,
	author = {Xianhao Tian and
                  Peijia Zheng and
                  Jiwu Huang},
	title = {Secure Deep Learning Framework for Moving Object Detection in Compressed
                  Video},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2836--2851},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3318975},
	doi = {10.1109/TDSC.2023.3318975},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/TianZH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the cloud, there is an urgent need to implement intelligent video surveillance in a privacy-preserving way. Moving object detection is an important task in the intelligent surveillance system. In this article, we propose a privacy-preserving deep learning framework to detect moving objects on compressed videos. We encrypt video bitstreams using selective video encryption to protect the private video content. We propose encrypted domain motion information (EDMI) without decryption and decompression to design three motion feature maps. Due to the sparsity of the EDMI distribution, existing convolutional backbones designed for RGB images have difficulty providing satisfactory performance. We design a novel convolutional backbone using a “subtraction” strategy to reduce model complexity. Our backbone employs residual blocks and skipping connections to reuse the EDMI at deeper layers. We evaluate our model on two large high-definition surveillance video datasets, i.e., VIRAT and Duke-MTMC. The experimental results show that the proposed framework achieves state-of-the-art detection performance compared with the most recent works. Our approach achieves an excellent privacy-utility tradeoff. Compared to previous solutions, it performs more robustly in crowded scenarios with challenges like occlusion. To our best knowledge, this is the first reported deep learning framework for moving object detection in encrypted-compressed video.}
}


@article{DBLP:journals/tdsc/YaoHLWLL24,
	author = {Yuan Yao and
                  Junjiang He and
                  Tao Li and
                  Yunpeng Wang and
                  Xiaolong Lan and
                  Yuan Li},
	title = {An Automatic {XSS} Attack Vector Generation Method Based on the Improved
                  Dueling {DDQN} Algorithm},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2852--2868},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3319352},
	doi = {10.1109/TDSC.2023.3319352},
	timestamp = {Fri, 26 Jul 2024 07:35:34 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YaoHLWLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional XSS (Cross Site Scripting) scanners typically rely on attack vectors based on expert knowledge and manual testing, which not only incur high costs and long processing times but also result in a significant number of false positives. In this paper, we build an automatic XSS attack vector generation method based on the improved Dueling DDQN algorithm. First, we model the XSS attack vector generation process as a Markov decision process, mapping the initial attack vector mutation points and mutation strategies to the state space and action space of the model, respectively. Second, we propose an improved Dueling DDQN algorithm by introducing a priority experience replay mechanism to improve algorithm performance and the speed of attack vector generation. Third, we establish a feedback mechanism based on the edit distance algorithm to define the role of the reward function, preventing the model from getting stuck in local optima and achieving better mutation effects. Finally, we propose an automatic XSS attack verification method based on static semantic analysis to validate the effectiveness of our generated attack vectors. Based on the mentioned approach, we have developed a prototype tool for automatic XSS scanning. The experimental results demonstrate that the improved Dueling DDQN algorithm outperforms other value-based reinforcement learning algorithms in terms of convergence speed, learning efficiency, and stability. The adaptive attack vector generation model can generate attack vectors that adapt to program context semantics and bypass defense mechanisms.}
}


@article{DBLP:journals/tdsc/RotGPS24,
	author = {Peter Rot and
                  Klemen Grm and
                  Peter Peer and
                  Vitomir Struc},
	title = {PrivacyProber: Assessment and Detection of Soft-Biometric Privacy-Enhancing
                  Techniques},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2869--2887},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3319500},
	doi = {10.1109/TDSC.2023.3319500},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/RotGPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Soft–biometric privacy-enhancing techniques represent machine learning methods that aim to: i) mitigate privacy concerns associated with face recognition by suppressing soft-biometric attributes in facial images (e.g., gender, age, ethnicity) and ii) make unsolicited extraction of sensitive personal information infeasible. Because such techniques are increasingly used in real-world applications, it is imperative to understand to what extent the privacy enhancement can be inverted and how much attribute information can be recovered from the privacy-enhanced images. While these aspects are critical, they have not been investigated in the literature so far. In this paper, we therefore study the robustness of state-of-the-art soft-biometric privacy-enhancing techniques to attribute recovery attempts. We propose PrivacyProber, a high-level framework for restoring soft-biometrics from privacy-enhanced images and apply it for attribute recovery in comprehensive experiments on three public face datasets (LFW, MUCT, and Adience). Our experiments show the proposed framework is able to restore a considerable amount of suppressed information, regardless of the privacy-enhancing technique used (e.g., adversarial perturbations, conditional synthesis, etc.), and that there are significant differences between the considered privacy models. These results point to the need for novel mechanisms to improve the robustness of existing techniques and secure them against adversaries trying to restore suppressed information. We also demonstrate that PrivacyProber can be used to detect privacy enhancement (under black-box assumptions) with high accuracy.}
}


@article{DBLP:journals/tdsc/XiMLWLH24,
	author = {Liang Xi and
                  Dehua Miao and
                  Menghan Li and
                  Ruidong Wang and
                  Han Liu and
                  Xunhua Huang},
	title = {Adaptive-Correlation-Aware Unsupervised Deep Learning for Anomaly
                  Detection in Cyber-Physical Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2888--2899},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3319701},
	doi = {10.1109/TDSC.2023.3319701},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XiMLWLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-Physical System needs high security to ensure the safe operation. Anomaly detection is one of the mainstream security technologies, the core of which is data analysis and learning. Unsupervised Deep-Learning-based Anomaly Detection Methods can be used in the scenarios that collects large amounts of unlabeled data and are more in line with the actual needs of CPS. However, the correlation among data did not attract enough attention to exploring their implicit relationship, and the adaptive training was deficient. Therefore, we propose an Adaptive-Correlation-aware Unsupervised Deep Learning (ACUDL) for anomaly detection in CPS. It constructs a directed graph structure to represent the implicit correlation among data and adaptively updates with dynamic graph; then, designs a dual-autoencoder to extract the original non-correlation, correlation, and reconstruction features, and builds an estimation network using the Gaussian mixture model (GMM) to estimate the anomaly energy. Experimental results on several CPS data scenarios show that ACUDL can be well adapted to many application scenarios with different data characteristics and achieves better overall results than some up-to-date DL-ADMs.}
}


@article{DBLP:journals/tdsc/MengLZTC24,
	author = {Yan Meng and
                  Jiachun Li and
                  Haojin Zhu and
                  Yuan Tian and
                  Jiming Chen},
	title = {Privacy-Preserving Liveness Detection for Securing Smart Voice Interfaces},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2900--2916},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3319833},
	doi = {10.1109/TDSC.2023.3319833},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MengLZTC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart speakers are widely used as the primary user interface in intelligent systems, including smart homes and industrial IoT. However, they are vulnerable to voice spoofing attacks which result in malicious command execution or privacy information leakage. Passive liveness detection, which thwarts voice spoofing via analyzing the collected audio rather than deploying sensors to distinguish between live-human and spoofing voices, has drawn increasing attention. But existing schemes either face performance degradation under environmental factor changes or require the user to keep fixed gestures, which limit their deployment in real-world scenarios. Besides, the space distributed property of smart speakers causes building a universal classifier for all involved users to be cumbersome and increases privacy leakage issues. To address the challenges mentioned above, we propose LiveArray, an efficient, lightweight, and privacy-preserving passive liveness detection system. LiveArray exploits a novel liveness feature, array fingerprint, which utilizes the microphone array inherently adopted by the smart speaker to improve the accuracy of liveness detection. LiveArray's further employs the federated learning-based architecture to reduce the dataset collection overhead during classifier building and eliminate the potential privacy leakage during data transmission. Experimental results show that LiveArray achieves an accuracy of 99.16%, which is superior to existing passive schemes.}
}


@article{DBLP:journals/tdsc/AbbasSSH24,
	author = {Haider Abbas and
                  Muhammad Shahzad and
                  Maliha Safdar and
                  Ahmed Hemani},
	title = {{DUDE:} Decryption, Unpacking, Deobfuscation, and Endian Conversion
                  Framework for Embedded Devices Firmware},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2917--2929},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3320675},
	doi = {10.1109/TDSC.2023.3320675},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/AbbasSSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Commercial-Off-The-Shelf (COTS) embedded devices rely on vendor-specific firmware to perform essential tasks. These firmware have been under active analysis by researchers to check security features and identify possible vendor backdoors. However, consistently unpacking newly created filesystem formats has been exceptionally challenging. To thwart attempts at unpacking, vendors frequently use encryption and obfuscation methods. On the other hand, when handling encrypted, obfuscated, big endian cramfs, or custom filesystem formats found in firmware under test, the available literature and tools are insufficient. This study introduces DUDE, an automated framework that provides novel functionalities, outperforming cutting-edge tools in the decryption, unpacking, deobfuscation, and endian conversion of firmware. For big endian compressed romfs filesystem formats, DUDE supports endian conversion. It also supports deobfuscating obfuscated signatures for successful unpacking. Moreover, decryption support for encrypted binaries from the D-Link and MOXA series has also been added, allowing for easier analysis and access to the contents of these firmware files. Additionally, the framework offers unpacking assistance by supporting the extraction of special filesystem formats commonly found in firmware samples from various vendors. A remarkable 78% (1424 out of 1814) firmware binaries from different vendors were successfully unpacked using the suggested framework. This performance surpasses the capabilities of commercially available tools combined on a single platform.}
}


@article{DBLP:journals/tdsc/RanaweeraYLJ24,
	author = {Pasika Ranaweera and
                  Awaneesh Kumar Yadav and
                  Madhusanka Liyanage and
                  Anca Delia Jurcut},
	title = {A Novel Authentication Protocol for 5G gNodeBs in Service Migration
                  Scenarios of {MEC}},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2930--2948},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3320647},
	doi = {10.1109/TDSC.2023.3320647},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/RanaweeraYLJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing paradigms were an expedient innovation for elevating the contemporary standards of mobile and Internet networks. As specified in Multi-Access Edge Computing (MEC) standardization, edge computing serviceable infrastructures are running on virtualization technologies to provide dynamic and flexible service instances. Since the inception and operation of the services are executing at the edge level gNodeBs (gNBs), migration of services between gNBs is an imminent occurrence in edge computing that is contriving challenges to its feasible deployment. Security and service level latency requirements are vital parameters for such service migration operations conducted through gNB to gNB (g2g) connecting channels. In this paper, our focus is to ensure identity verification among the parties involved in a service migration through authentication and to secure the migrating content through a robust g2g channel establishment. Our proposed authentication protocol was designed in accordance with the MEC architectural standardization. We have verified the proposed protocol employing four different formal verification techniques: Scyther and AVISPA verification tools, GNY and ROR logical approaches. Further, we have developed the proposed protocol in a test-bed environment emulating the MEC system with an integrated 5G Core network.}
}


@article{DBLP:journals/tdsc/WalterMNK24,
	author = {Kane Walter and
                  Meisam Mohammady and
                  Surya Nepal and
                  Salil S. Kanhere},
	title = {Optimally Mitigating Backdoor Attacks in Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2949--2963},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3320694},
	doi = {10.1109/TDSC.2023.3320694},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WalterMNK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is a distributed, privacy-preserving learning paradigm where a joint model is trained on private data stored on client devices. Data owners (clients) train models locally and then submit them to an aggregation server for incorporation into the joint model. Malicious clients can apply training time attacks, e.g., backdoor attacks, by submitting maliciously trained models. Prior work has shown that Differential Privacy (DP) can provide certified robustness to backdoor attacks; however, there are limited studies regarding DP parameter selection as a function of the model architecture. In this work, we show empirically that larger models (i.e., with more parameters) require stronger DP parameter settings to mitigate backdoor attacks. Furthermore, we present a framework that alters the FL training algorithm to preserve certified accuracy round-by-round and show empirically that it is superior to a model trainer selecting DP parameters ahead of time before training begins and with incomplete information about the attacker. Although tools from DP are used in our proposed framework, it is focused on backdoor attack mitigation and does not provide privacy guarantees.}
}


@article{DBLP:journals/tdsc/ThirunavukkarasuZMJPW24,
	author = {Sudershan Lakshmanan Thirunavukkarasu and
                  Mengyuan Zhang and
                  Suryadipta Majumdar and
                  Yosr Jarraya and
                  Makan Pourzandi and
                  Lingyu Wang},
	title = {Caught-in-Translation (CiT): Detecting Cross-Level Inconsistency Attacks
                  in Network Functions Virtualization {(NFV)}},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2964--2981},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3320811},
	doi = {10.1109/TDSC.2023.3320811},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ThirunavukkarasuZMJPW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As one of the main technology pillars of 5 G networks, Network Functions Virtualization (NFV) enables agile and cost-effective deployment of network services. However, the multi-level, multi-actor design of NFV may also allow for inconsistency between the different abstraction levels to be mistakenly or intentionally introduced, as shown in recent studies. Serious security issues, such as man-in-the-middle, network sniffing, and DoS, may arise at one abstraction level without being noticed by the victims at another level. Most existing solutions are either limited to one abstraction level of NFV or reliant on direct access to lower-level data which could become inaccessible when managed by different providers. In this paper, by drawing an analogy between cross-level NFV event sequences and natural languages, we propose a Neural Machine Translation-based approach, namely, Caught-in-Translation (CiT), to detect cross-level inconsistency attacks in NFV at runtime. Specifically, we first extract event sequences from different abstraction levels of an NFV stack. We then leverage Long Short-Term Memory (LSTM) to translate the event sequences from one level to another. Finally, we apply both a similarity metric and a Siamese neural network to compare the translated event sequences with the original ones to detect attacks. We integrate CiT into OpenStack/Tacker, a popular open-source NFV implementation, and evaluate its performance using both real and synthetic data. Experimental results show the benefit of leveraging NMT as CiT achieves AUC \\geq\n96.03%, which significantly outperforms traditional SVM-based anomaly detection. We also evaluate CiT in terms of its efficiency, scalability, and robustness for detecting inconsistency attacks in NFV platforms.}
}


@article{DBLP:journals/tdsc/ShiLLAL24,
	author = {Yang Shi and
                  Tianyuan Luo and
                  Jingwen Liang and
                  Man Ho Au and
                  Xiapu Luo},
	title = {Obfuscating Verifiable Random Functions for Proof-of-Stake Blockchains},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2982--2996},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3321051},
	doi = {10.1109/TDSC.2023.3321051},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ShiLLAL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain systems enable new applications, such as cryptocurrencies and smart contracts, using decentralized consensus without trusted authorities. A number of blockchain systems based on proof-of-stake techniques have been proposed, many of which use verifiable random functions (VRFs) as fundamental building blocks, such as Ouroboros, Algorand, and Dfinity, etc. The secret key of a VRF scheme is critical to the security of a VRF and the entire blockchain system built on it. To protect the secret keys of VRFs and maintain the efficiency of the proof-of-stake protocol, we extend the objective of cryptographic program obfuscation to VRFs and propose an obfuscatable VRF scheme. In particular, we propose an obfuscator that can transform the implementation of the scheme's random string generation algorithm and the given secret key into an unintelligible form. Obfuscated implementations of the random string generation algorithm are deployed on peers of a blockchain for supporting normal routines of the proof-of-stake protocol. Even if a hacker has controlled a peer's host, the owner's secret key will not be compromised because the key has been hardwired into the obfuscated implementation in an “encrypted manner”. We formally prove the correctness and the security of the proposed VRF and obfuscator. Since the proposed scheme supports the general semantics of verifiable random functions, it can be used as a building block for all blockchain systems that adopt proof-of-stake protocols based on VRFs. The experimental result indicated that the scheme performs well on various platforms, such as cloud servers, workstations, smartphones, and embedded devices.}
}


@article{DBLP:journals/tdsc/HuangWSWGDSTV24,
	author = {Hao Huang and
                  Patrick Wlazlo and
                  Abhijeet Sahu and
                  Adele Walker and
                  Ana E. Goulart and
                  Katherine R. Davis and
                  Laura P. Swiler and
                  Thomas D. Tarman and
                  Eric D. Vugrin},
	title = {Validating an Emulation-Based Cybersecurity Model With a Physical
                  Testbed},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {2997--3011},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3321176},
	doi = {10.1109/TDSC.2023.3321176},
	timestamp = {Tue, 23 Jul 2024 08:24:22 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HuangWSWGDSTV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For researchers studying cyber-physical system security, working with realistic datasets is essential. To produce the datasets, the existing methodology is to emulate the cyber network. A challenge is that the industrial control systems (ICS) network consists of not just computers and communication equipment, but also field devices that collect data and execute controls. These devices play a significant role in the operation and the security of the system. However, in comparison to the cyber network, the research reproducibility and realism of the cyber-physical system emulation and its data has received far less attention. This article thus develops an approach to answer, ”How well can emulated devices replicate the behavior of physical intelligent electronics devices (IEDs) in a realistic cyber attack and defense environment?” To study this, we perform a comparison study based on an emulation experiment using the minimega testbed environment that is entirely virtual and a hardware-in-the-loop experiment using the Resilient Energy Systems Lab (RESLab) cyber-physical testbed featuring real industrial controllers and communications devices. Results show that under different reconnaissance attack scenarios, RESLab generates realistic datasets that validate the emulation-based cybersecurity model in minimega. The approach is generalizable toward validating the realism of other types of ICS devices in security studies.}
}


@article{DBLP:journals/tdsc/HuZSSCD24,
	author = {Hongsheng Hu and
                  Xuyun Zhang and
                  Zoran Salcic and
                  Lichao Sun and
                  Kim{-}Kwang Raymond Choo and
                  Gillian Dobbie},
	title = {Source Inference Attacks: Beyond Membership Inference Attacks in Federated
                  Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3012--3029},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3321565},
	doi = {10.1109/TDSC.2023.3321565},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HuZSSCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is a popular approach to facilitate privacy-aware machine learning since it allows multiple clients to collaboratively train a global model without granting others access to their private data. It is, however, known that FL can be vulnerable to membership inference attacks (MIAs), where the training records of the global model can be distinguished from the testing records. Surprisingly, research focusing on the investigation of the source inference problem appears to be lacking. We also observe that identifying a training record's source client can result in privacy breaches extending beyond MIAs. Seeking to contribute to the literature gap, we take the first step to investigate source privacy in FL. Specifically, we propose a new inference attack (hereafter referred to as source inference attack–SIA), designed to facilitate an honest-but-curious server to identify the training record's source client. The proposed SIAs leverage the Bayesian theorem to implement the attack in a non-intrusive manner without deviating from the defined FL protocol. We then evaluate SIAs in three different FL frameworks to show that in existing FL frameworks, the clients sharing gradients, model parameters, or predictions on a public dataset will leak such source information to the server. The experimental results validate the efficacy of the proposed SIAs, e.g., an attack success rate of 67.1% (baseline 10%) can be achieved when the clients share model parameters with the server. Comprehensive ablation studies demonstrate that the success of an SIA is directly related to the overfitting of the local models.}
}


@article{DBLP:journals/tdsc/SalmanGPBAJC24,
	author = {Tara Salman and
                  Ali Ghubaish and
                  Roberto Di Pietro and
                  Mohamed Baza and
                  Hani Alshahrani and
                  Raj Jain and
                  Kim{-}Kwang Raymond Choo},
	title = {CrowdFAB: Intelligent Crowd-Forecasting Using Blockchains and its
                  Use in Security},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3030--3047},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3322038},
	doi = {10.1109/TDSC.2023.3322038},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SalmanGPBAJC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourcing applications, such as Uber for ride-sharing, enable distributed problem-solving. A subset of these applications is intelligent crowd-forecasting applications, e.g., Virustotal, for malware detection. In crowd-forecasting applications, multiple agents respond with predictions about potential future event outcome(s). These responses are then combined to assess the events collaboratively and act accordingly. Unlike conventional crowdsourcing applications that only communicate information, crowd-forecasting applications need to additionally process information to achieve a collaborative assessment. Hence, they require knowledge-based systems instead of simple storage-based ones for crowdsourcing applications. Most existing crowd-forecasting systems are centralized, leading to the inherent single point of failure and inefficient collaborative assessment. This paper presents CrowdFAB, Crowdsourced Forecasting Applications using Blockchains. We deploy a knowledge-based blockchain paradigm that transforms blockchains from simple storage to knowledge-based systems, thereby achieving crowd-forecasting requirements without centralization. In addition, we formulate a novel reputation scheme that assigns reputations to agents based on their performance. We then use this scheme when making assessments. We implement and analyze CrowdFAB in terms of overhead and security features. Further, we evaluate CrowdFAB for a collaborative malware detection use case, where multiple detectors are involved for crowd forecasting. Results demonstrate CrowdFAB's superior accuracy and other metrics performance compared to other works with the same settings.}
}


@article{DBLP:journals/tdsc/YuCWW24,
	author = {Chuan Yu and
                  Shuhui Chen and
                  Ziling Wei and
                  Fei Wang},
	title = {Toward a Truly Secure Telecom Network: Analyzing and Exploiting Vulnerable
                  Security Configurations/ Implementations in Commercial {LTE/IMS} Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3048--3064},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3322267},
	doi = {10.1109/TDSC.2023.3322267},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YuCWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Authentication and data protection (both integrity and confidentiality) between the network and cellular devices are two fundamental security features in 4G/Long Term Evolution (LTE) and IP Multimedia Subsystem (IMS) networks. The first is implemented via authentication and key agreement mechanisms and can be compromised by relaying authentication parameters. The second security feature builds on the first one and is activated through corresponding security setup procedures. This work intends to investigate whether these basic security procedures are securely implemented and deployed in commercial networks. We analyzed the de facto situation of these security features in three major operators in China and found several new and previously disclosed configuration and implementation flaws that do not conform to specifications. These vulnerabilities allow attackers to disable LTE and IMS data protection mechanisms. We further propose novel proof-of-concept attacks to exploit the identified vulnerabilities including IMEI and Phone Number Catching, SMS and Call Impersonation and Interception attacks. To show the urgency of addressing these security issues and thus secure the real-world telecom networks, we successfully demonstrated these attacks in practice using open-source SDR tools as they have serious implications. For instance, the interception attacks undermine the widely-used SMS verification code security mechanism. We also discuss countermeasures to resist the proposed attacks.}
}


@article{DBLP:journals/tdsc/LinWLLSBLXR24,
	author = {Feng Lin and
                  Chao Wang and
                  Tiantian Liu and
                  Ziwei Liu and
                  Yijie Shen and
                  Zhongjie Ba and
                  Li Lu and
                  Wenyao Xu and
                  Kui Ren},
	title = {High-Quality Speech Recovery Through Soundproof Protections via mmWave
                  Sensing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3065--3081},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3322295},
	doi = {10.1109/TDSC.2023.3322295},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LinWLLSBLXR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online voice communications are widely used nowadays. To protect speech from leakage, people tend to initiate the talk in sound-isolated environments. In this artcle, we reveal a novel attack that recovers high-quality speech from outside soundproof zones. The rationale of the attack is to leverage sound-sensitive characteristics of piezoelectric materials, i.e., a piezo film that can change the phase of reflected mmWaves when placed in a sound field. If the attacker transmits mmWaves and analyzes reflected signals from the piezo film, the speech information can be compromised. More importantly, the piezo film is paper-like and works without a power supply. We propose a new speech recovery methodology to transform sound waves into wireless signals and build an end-to-end eavesdropping system working as a through-wall “microphone” to recover high-quality speech stealthily. To combat signal attenuation and improve speech quality, we develop a speech-enhancement scheme based on generative adversarial networks and propose to use multi-antenna information for intelligible speech reconstruction. We conduct extensive experiments to evaluate the system. The results indicate that the system achieves over 98% accuracy for digit recognition and works well over 5 m away through the wall. We also test the system under complex scenarios and give countermeasures.}
}


@article{DBLP:journals/tdsc/VasiliadisKSPIK24,
	author = {Giorgos Vasiliadis and
                  Apostolos Karampelas and
                  Alexandros Shevtsov and
                  Panagiotis Papadopoulos and
                  Sotiris Ioannidis and
                  Alexandros Kapravelos},
	title = {{WRIT:} Web Request Integrity and Attestation Against Malicious Browser
                  Extensions},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3082--3095},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3322516},
	doi = {10.1109/TDSC.2023.3322516},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/VasiliadisKSPIK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The powerful capabilities of modern browsers have pushed the web application logic to the user side, in order to minimize latency, increase scalability of the service and improve users’ quality of experience. What is more, browsers provide a rich toolchest for browser extensions to provide additional functionality, but at the same time enable them to become a powerful vehicle for malicious actors. Such actors may spy, phish or fraud users, thus making the user's browser untrusted for the web servers. In this article, we present WRIT, a practical framework that enables websites to protect critical functionality from abuse in the presence of malicious extensions. In WRIT, the integrity of outgoing web requests is attested and verified to ensure they were triggered by a user's action and not automatically generated by a malicious browser extension. WRIT is immediately applicable by leveraging existing HTML5 and other native browser features and does not require any modification of the browser. Performance results of our prototype show that it adds a negligible 7.29 ms latency to sensitive user-triggered actions (e.g., post message).}
}


@article{DBLP:journals/tdsc/JangirKKPGS24,
	author = {Pranav Jangir and
                  Nishat Koti and
                  Varsha Bhat Kukkala and
                  Arpita Patra and
                  Bhavish Raj Gopal and
                  Somya Sangal},
	title = {Vogue: Faster Computation of Private Heavy Hitters},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3096--3108},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3322511},
	doi = {10.1109/TDSC.2023.3322511},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/JangirKKPGS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Consider the problem of securely identifying \\tau-heavy hitters, where given a set of client inputs, the goal is to identify those inputs which are held by at least \\tau clients in a privacy-preserving manner. Towards this, we design a novel system \\mathsf {Vogue}, whose key highlight in comparison to prior works, is that it ensures complete privacy and does not leak any information other than the heavy hitters. In doing so, \\mathsf {Vogue} aims to achieve as efficient a solution as possible. To showcase these efficiency improvements, we benchmark our solution and observe that it requires around 14 minutes to compute the heavy hitters for \\tau = 100 on 256-bit inputs when considering 400K clients. This is in contrast to the state of the art solution that requires over an hour for the same. In addition to the static input setting described above, \\mathsf {Vogue} also accounts for streaming inputs and provides a protocol that outperforms the state-of-the-art therein. The efficiency improvements witnessed while computing heavy hitters in both, the static and streaming input settings, are attributed to our new secure stable compaction protocol, whose round complexity is independent of the size of the input array to be compacted.}
}


@article{DBLP:journals/tdsc/LuZR24a,
	author = {Yibiao Lu and
                  Bingsheng Zhang and
                  Kui Ren},
	title = {Maliciously Secure {MPC} From Semi-Honest 2PC in the Server-Aided
                  Model},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3109--3125},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3322397},
	doi = {10.1109/TDSC.2023.3322397},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LuZR24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure multi-party computation (MPC) provides provable security guarantees for many privacy critical applications. The semi-honest MPC protocols are secure against semi-honest adversaries who can only observe the protocol execution, while the maliciously secure MPC protocols are secure against malicious adversaries who can deviate from the protocol description arbitrarily. Many security sensitive applications tend to use semi-honest MPC protocols because malicious security comes with huge communication and/or computation costs. In this work, we show how to efficiently transform generic semi-honest two-party protocols into maliciously secure multi-party protocol in the server-aided setting. We further propose an optimized constant-round server-aided MPC protocol. The proposed protocols are secure when all but one parties are maliciously corrupted, while the remaining party and the server are corrupted by semi-honest and non-colluding adversaries. We implement and evaluate our constant-round protocol. For the 2-party case, our protocol is only 1.11× slower than the semi-honest Yao's Garbled Circuits protocol, and it is 9.16× faster than the maliciously secure authenticated garbling protocol and 4.96× faster than the state-of-the-art maliciously secure server-aided protocol of Wu et al. For the 8-party case, our protocol is 103.29× faster than the authenticated garbling protocol and 17.03× faster than the protocol of Wu et al.}
}


@article{DBLP:journals/tdsc/ZhangLRLMLD24,
	author = {Man Zhang and
                  Xinghua Li and
                  Yanbing Ren and
                  Bin Luo and
                  Yinbin Miao and
                  Ximeng Liu and
                  Robert H. Deng},
	title = {Privacy-Preserved Data Trading Via Verifiable Data Disturbance},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3126--3140},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3323669},
	doi = {10.1109/TDSC.2023.3323669},
	timestamp = {Fri, 14 Feb 2025 20:58:22 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangLRLMLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To motivate data owner (DO) to trade data, the existing data trading allows DO to sell the disturbed data to the data consumer (DC), where the disturbance parameter and the data price are negotiated by them, and DO independently adds the disturbance noise to data (usually continuous type) following the negotiation result. However, DOs may violate the negotiated parameter and add more noise to data while obtaining the negotiated price, which damages DC's disturbed data availability. This deficiency is rooted in the absence of supervision and verifiability on DOs’ independent disturbances. Aiming at the above problem, we devise a privacy-preserved data trading via verifiable data disturbance. Specifically, the honest-but-curious disturbance server (DS) is introduced to generate encrypted verifiable disturbance noises, and secretly distribute noises to DOs referring to the method of private information retrieval. Using homomorphic encryption, DOs finish data disturbance without knowing noises’ specific sizes. Subsequently, DC selects DOs to verify with our proposed anti-forgery verification, where the anti-forgery on both disturbance noise and original data guarantees verification correctness. Theoretical analysis proves that DOs’ original data is preserved in data trading. Extensive experiments using the real-world dataset demonstrate that our scheme can detect more than 80% of malicious DOs and decrease their utilities to punish malicious disturbance compared with existing works.}
}


@article{DBLP:journals/tdsc/ShepherdKSM24,
	author = {Carlton Shepherd and
                  Jan Kalbantner and
                  Benjamin Semal and
                  Konstantinos Markantonakis},
	title = {A Side-Channel Analysis of Sensor Multiplexing for Covert Channels
                  and Application Profiling on Mobile Devices},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3141--3152},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3323732},
	doi = {10.1109/TDSC.2023.3323732},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ShepherdKSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile devices often distribute measurements from physical sensors to multiple applications using software multiplexing. On Android devices, the highest requested sampling frequency is returned to all applications, even if others request measurements at lower frequencies. In this article, we comprehensively demonstrate that this design choice exposes practically exploitable side-channels using frequency-key shifting. By carefully modulating sensor sampling frequencies in software, we show how unprivileged malicious applications can construct reliable spectral covert channels that bypass existing security mechanisms. Additionally, we present a novel variant that allows an unprivileged malicious application to profile other active, sensor-enabled applications at a coarse-grained level. Both methods do not impose any special assumptions beyond accessing standard mobile services available to developers. As such, our work reports side-channel vulnerabilities that exploit subtle yet insecure design choices in Android sensor stacks.}
}


@article{DBLP:journals/tdsc/PereiraDAB24,
	author = {Mayana Pereira and
                  Rahul Dodhia and
                  Hyrum S. Anderson and
                  Richard Brown},
	title = {Metadata-Based Detection of Child Sexual Abuse Material},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3153--3164},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3324275},
	doi = {10.1109/TDSC.2023.3324275},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/PereiraDAB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Child Sexual Abuse Media (CSAM) is any visual record of a sexually explicit activity involving minors. Machine learning-based solutions can help law enforcement identify CSAM and block distribution. Yet, collecting CSAM imagery to train machine learning models has ethical and legal constraints. CSAM detection systems based on file metadata offer several opportunities. Metadata is not a record of a crime and, therefore, clear of legal restrictions. This article proposes a CSAM detection framework consisting of machine learning models trained on file paths extracted from a real-world data set of over 1 million file paths obtained in criminal investigations. Our framework includes guidelines for model evaluation that account for data changes caused by adversarial data modification and variations in data distribution caused by limited access to training data, as well as an assessment of false positive rates against file paths from common crawl data. We achieve accuracies as high as 0.97 while presenting stable behavior under adversarial attacks previously used in natural language tasks. When evaluating the model on publicly available file paths from common crawl data, we observed a false positive rate of 0.002, showing that the model operating in distinct data distributions maintains low false positive rates.}
}


@article{DBLP:journals/tdsc/ShuY24,
	author = {Zhan Shu and
                  Guanhua Yan},
	title = {{EAGLE:} Evasion Attacks Guided by Local Explanations Against Android
                  Malware Classification},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3165--3182},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3324265},
	doi = {10.1109/TDSC.2023.3324265},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ShuY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With machine learning techniques widely used to automate Android malware detection, it is important to investigate the robustness of these methods against evasion attacks. A recent work has proposed a novel problem-space attack on Android malware classifiers, where adversarial examples are generated by transforming Android malware samples while satisfying practical constraints. Aimed to address its limitations, we propose a new attack called EAGLE (Evasion Attacks Guided by Local Explanations), whose key idea is to leverage local explanations to guide the search for adversarial examples. We present a generic algorithmic framework for EAGLE attacks, which can be customized with specific feature increase and decrease operations to evade Android malware classifiers trained on different types of count features. We overcome practical challenges in implementing these operations for four different types of Android malware classifiers. Using two Android malware datasets, our results show that EAGLE attacks can be highly effective at finding functionable adversarial examples. We study the attack transferrability of malware variants created by EAGLE attacks across classifiers built with different classification models or trained on different types of count features. Our research further demonstrates that ensemble classifiers trained from multiple types of count features are not immune to EAGLE attacks. We also discuss possible defense mechanisms against EAGLE attacks.}
}


@article{DBLP:journals/tdsc/DasAM24,
	author = {Dola Das and
                  Kazi Md. Rokibul Alam and
                  Yasuhiko Morimoto},
	title = {An Anonymity Retaining Framework for Multi-party Skyline Queries Based
                  on Unique Tags},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3183--3195},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3323961},
	doi = {10.1109/TDSC.2023.3323961},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DasAM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While finding out dominant objects over multiple competing parties’ sensitive datasets via multi-party skyline queries (MSQs), upholding ample data privacy with integrity, data and data owners’ (i.e., parties) anonymity, verifiable deeds of entities, the robustness of framework, etc., is crucial. The existing works consider these criteria trivially or partially and may sacrifice data integrity due to malleable cipher data. This article proposes a framework for MSQs that incorporates these requirements together and eventually makes a ranking of parties’ data-objects. To enrich data privacy, it allocates separate decryption keys among mutual entities. To confirm data integrity, it unites encrypted unique tags (UTs) to parties’ encrypted datasets individually. To assure data and parties’ anonymity, it re-encrypts and shuffles encrypted datasets, and uses anonymous credentials, respectively. These qualities and publicly exposed data reinforce the framework and assure the correct deeds of entities. Finally, evaluation results, analyses, comparisons with state-of-the-art works, etc., prove the efficacy of the proposed framework.}
}


@article{DBLP:journals/tdsc/YuanYXCSLZJ24,
	author = {Bin Yuan and
                  Maogen Yang and
                  Zheng Xu and
                  Qunjinming Chen and
                  Zhanxiang Song and
                  Zhen Li and
                  Deqing Zou and
                  Hai Jin},
	title = {Leakage of Authorization-Data in IoT Device Sharing: New Attacks and
                  Countermeasure},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3196--3210},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3323713},
	doi = {10.1109/TDSC.2023.3323713},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/YuanYXCSLZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device sharing among users is a common functionality in today's IoT clouds. Supporting device sharing are the delegation methods proposed by different IoT clouds, which we find are heterogeneous and ad-hoc — IoT clouds use various data (e.g., device ID, product ID, and access token) as authorization certificates. In this paper, we report the first systematic study on how the authorization-data are managed in IoT device sharing. Our study brought to light the security risks in today's IoT authorization-data management, identifying 6 authorization-data leakage flaws. To mitigate such flaws, we propose an approach to hide the authorization-data from the delegatee (a.k.a., the user authorized to access the devices) without disrupting the device sharing services. We propose SecHARE, an automated tool to patch the vulnerable IoT clouds. We applied SecHARE to 3 popular open-source IoT clouds. Results have shown the compatibility, effectiveness, and efficiency of SecHARE. We have made SecHARE publicly available.}
}


@article{DBLP:journals/tdsc/GaoZZ24,
	author = {Jiacheng Gao and
                  Yuan Zhang and
                  Sheng Zhong},
	title = {Revisiting Privacy-Preserving Min and k-th Min Protocols for Mobile
                  Sensing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3211--3226},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3324802},
	doi = {10.1109/TDSC.2023.3324802},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/GaoZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Exploiting participants’ data without knowing them is the center topic of secure mobile sensing data aggregation. In this article, we study how to improve existing protocols for computing the minimum or\nk\n-th minimum of all participants’ data in a privacy-preserving manner. Existing protocols for these two computations require relatively high communication cost or frequent interactions, which leads to unbearable time consumption when the network delay is high. We improve the min computation protocol proposed by Zhang et al. 2017, cutting down on its need for interactions and thus making it perform better in terms of efficiency. We also propose a new protocol as a secure substitute of the Bit-choosing Algorithm designed by Yu et al. 2018. It helps participants generate a secret permutation, which will be further used in the\nk\n-th min computation protocol to achieve higher accuracy and efficiency. Theoretical analyses are done to help predict and understand our new protocols’ performances, and later evaluations show that both these new protocols perform notably better in comparison to the existing ones.}
}


@article{DBLP:journals/tdsc/LuHYSC24,
	author = {Ning Lu and
                  Ruxiao Huang and
                  Mingliang Yao and
                  Wenbo Shi and
                  Kim{-}Kwang Raymond Choo},
	title = {V-Digger: An Efficient and Secure Vulnerability Assessment for Large-Scale
                  {ISP} Network},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3227--3246},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3324646},
	doi = {10.1109/TDSC.2023.3324646},
	timestamp = {Sun, 08 Sep 2024 16:07:51 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LuHYSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vulnerability assessment allows cyber security professionals to discover vulnerable end devices. Generally, in such a process one extracts the default Service Banner (SB) from the application layer message of each device, prior to matching the SB with each Common Vulnerabilities and Exposures (CVE) in the public National Vulnerability Database (NVD). However, such an approach is not practical in large-scale ISP networks due to the efforts involved (e.g., collecting of SBs, and CVE matching) and potential vulnerability information leakage. In this paper, we propose V-Digger, an efficient and secure vulnerability assessment approach. Specifically, we adopt a flexible distributed architecture based on Local Area Network (LAN), which allows each LAN of the respective ISP network to participate in vulnerability assessment and share vulnerability data as per demand. To obtain more SBs, we design a system parameter evaluation method, which ensures that the collection task is performed under light network load. To expedite CVE matching, we devise an efficient SB-to-CPE transformer and a fast CVE searching algorithm. To prevent vulnerability leakage, we also design a secure vulnerability sharing protocol. We then undertake extensive theoretical analysis and real-world experiments to prove the effectiveness and efficiency of V-Digger. The results show that the assessment accuracy can achieve almost 85%, and its assessment rate is about 330 seconds per 1,000 devices.}
}


@article{DBLP:journals/tdsc/MiaoLJWLCD24,
	author = {Yinbin Miao and
                  Feng Li and
                  Xiaohua Jia and
                  Huaxiong Wang and
                  Ximeng Liu and
                  Kim{-}Kwang Raymond Choo and
                  Robert H. Deng},
	title = {{REKS:} Role-Based Encrypted Keyword Search With Enhanced Access Control
                  for Outsourced Cloud Data},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3247--3261},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3324640},
	doi = {10.1109/TDSC.2023.3324640},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MiaoLJWLCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Keyword-based search over encrypted data is an important technique to achieve both data confidentiality and utilization in cloud outsourcing services. While commonly used access control mechanisms, such as identity-based encryption and attribute-based encryption, do not generally scale well for hierarchical access permissions. To solve this problem, we propose a Role-based Encrypted Keyword Search (REKS) scheme by using the role-based access control and broadcast encryption. Specifically, REKS allows owners to deploy hierarchical access control by allowing users with parent roles to have access permissions from child roles. Using REKS, we further facilitate token generation preprocessing and efficient user management, thereby significantly reducing the users’ final token generation and index update overheads, respectively. Formal security analysis proves that REKS is secure against chosen keyword and internal keyword guessing attacks, and findings from the empirical evaluations demonstrate that REKS is efficient and practical.}
}


@article{DBLP:journals/tdsc/ShadabZGAL24,
	author = {Rakin Muhammad Shadab and
                  Yu Zou and
                  Sanjay Gandham and
                  Amro Awad and
                  Mingjie Lin},
	title = {A Secure Computing System With Hardware-Efficient Lazy Bonsai Merkle
                  Tree for FPGA-Attached Embedded Memory},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3262--3279},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3324935},
	doi = {10.1109/TDSC.2023.3324935},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ShadabZGAL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With high-impact cyber-attacks on the rise, provisioning cybersecurity to the emerging Internet of Things (IoT) systems typically comprising of modern embedded computing platforms becomes significantly more challenging to achieve. Contemporary secure-memory computing stipulates both content encryption and integrity protection that can seriously impede the computing performance and consume excessive amount of hardware resources. In this paper, we focus on hardware-efficient verification of the memory integrity in the mission-critical computing tasks executing on an FPGA-based secure embedded system, effectively mitigating adversarial attacks such as memory buffer replay. We proposed an innovative partitioned parallel cache structure that leverages the unique reconfigurable capability of modern FPGA devices and successfully circumvents the hardware implementation challenges due to the recursiveness that inherently exists in Merkle tree updating schemes. We designed and implemented a new Bonsai Merkle tree (BMT) lazy update controller specifically designed for FPGA to efficiently exploit the parallelism offered by its reconfigurable fabric. Our experimental results for the new system show up to 95x and 149x latency overhead reduction respectively for write and read and up to 17% better throughput in standard benchmarks compared to software-based approach. Critical system performance is also improved with the lowering of average evictions by up to 8%.}
}


@article{DBLP:journals/tdsc/ZhouWLWYW24,
	author = {Yipeng Zhou and
                  Runze Wang and
                  Jiahao Liu and
                  Di Wu and
                  Shui Yu and
                  Yonggang Wen},
	title = {Exploring the Practicality of Differentially Private Federated Learning:
                  {A} Local Iteration Tuning Approach},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3280--3294},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3325889},
	doi = {10.1109/TDSC.2023.3325889},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhouWLWYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although Federated Learning (FL) prevents the exposure of original data samples when collaboratively training machine learning models among decentralized clients, it has been revealed that vanilla FL is still susceptible to adversarial attacks if model parameters are leaked to malicious attackers. To enhance the protection level of FL, Differential Private Federated Learning (DPFL) has been proposed in recent years. DPFL injects zero-mean noises randomly generated by differential private (DP) mechanisms on local model parameters before they are disclosed. Nevertheless, DP noises can significantly deteriorate model utility jeopardizing the practicality of DPFL. In this article, we are among the first to explore how to improve the model utility of DPFL by tuning the number of local iterations (LIs) on DPFL clients. Our work shows that such a local iteration tuning approach can well mitigate the adverse influence of DP noises on the final model utility. Formally, we derive the sensitivity (a measure of the maximum change of the output given two adjacent inputs) with respect to the number of LIs conducted on DPFL clients for the Laplace mechanism, and the aggregated variances of Laplace noises at the server side. We further conduct convergence rate analysis to quantify the influence of the Laplace noises on the final model accuracy and determine how to optimally set the number of LIs. Finally, to verify our theoretical findings, we perform extensive experiments using three real-world datasets, namely, Lending Club, MNIST and Fashion-MNIST. The results not only corroborate our analysis, but also demonstrate that our approach significantly improves the practicality of DPFL.}
}


@article{DBLP:journals/tdsc/JiangJZJJX24,
	author = {Yan Jiang and
                  Xiaoyu Ji and
                  Juchuan Zhang and
                  Yancheng Jiang and
                  Shui Jiang and
                  Wenyuan Xu},
	title = {CapSpeaker: Injecting Commands to Voice Assistants Via Capacitors},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3295--3308},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3326184},
	doi = {10.1109/TDSC.2023.3326184},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/JiangJZJJX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have exposed that voice assistants can be manipulated by various voice commands without being noticed, however, existing attacks require a nearby speaker to play the attack commands. In this paper, we demonstrate that even without a speaker, we can use capacitors inside electronic devices to produce malicious voice commands, i.e., we convert capacitors into speakers and call it CapSpeaker. The underlying principle of CapSpeaker is the inverse piezoelectric effect, i.e., varying the voltage across a capacitor to make it vibrate and thus emit acoustic noises. Forcing capacitors to emit target voice commands is challenging because (1) capacitors’ response frequency is out of the range of audible voices. (2) We can not directly control the voltage across capacitors to manipulate their emit sounds. To overcome these challenges, we propose a PWM-based modulation scheme to embed the malicious audio onto a high-frequency carrier, e.g., above 20 kHz, and we create malware to induce the designed voltage across the capacitors such that CapSpeaker plays the chosen malicious commands. Our evaluation of 7 commercial devices demonstrates that CapSpeaker is feasible to inject voice commands, e.g., ”open the door”, at a distance of up to 10.5cm.}
}


@article{DBLP:journals/tdsc/JiangJWYMSX24,
	author = {Yan Jiang and
                  Xiaoyu Ji and
                  Kai Wang and
                  Chen Yan and
                  Richard Mitev and
                  Ahmad{-}Reza Sadeghi and
                  Wenyuan Xu},
	title = {Marionette: Manipulate Your Touchscreen via a Charging Cable},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3309--3323},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3326181},
	doi = {10.1109/TDSC.2023.3326181},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/JiangJWYMSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The security of capacitive touchscreens is crucial since they have become the primary human-machine interface on smart devices. This paper presents Marionette, the first wired attack that creates ghost touches on capacitive touchscreens via charging cables and can manipulate the victim's devices with undesired consequences, e.g., establishing malicious Bluetooth connections. Our study provides a new threat vector against touchscreens that only requires connecting to a malicious charging port, which could be a public charging station, and is effective across various USB data blockers and power adapters. Despite the fact that smartphones employ abundant noise reduction and voltage management techniques, we manage to inject carefully crafted signals that can induce ghost touches within a chosen range. The underlying principle is to inject common-mode noises over the power line to avoid being effectively filtered yet affecting the touch measurement mechanism and synchronize the malicious noise with the screen measurement scanning cycles to place the ghost touches at target locations. We achieve three types of attacks, i.e., injection, alteration, and Denial-of-Service, and the evaluation of 12 commercial electronics, 6 power adapters, and 13 charging cables demonstrate the feasibility of Marionette.}
}


@article{DBLP:journals/tdsc/TangCWLGX24,
	author = {Lihong Tang and
                  Xiao Chen and
                  Sheng Wen and
                  Li Li and
                  Marthie Grobler and
                  Yang Xiang},
	title = {Demystifying the Evolution of Android Malware Variants},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3324--3341},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3325912},
	doi = {10.1109/TDSC.2023.3325912},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/TangCWLGX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is important to understand the evolution of Android malware as this facilitates the development of defence techniques by proactively capturing malware features. So far, researchers mainly rely on dendrogram or family-tree analysis for malware's evolutionary development. However, our research finds that these techniques cannot support comprehensive malware evolution modelling, which provides a detailed explanation for why Android malware samples evolve in specific ways. This shortcoming is mainly caused by the coarse-grained clustering and analysis of malware samples. For example, because these works do not divide malware samples of a family into variant sets and explore the evolution principles among those sets, they usually fail to capture new variants that have been empowered by the feature ‘drifting’ in evolution. To address this problem, we propose a fine-grained and in-depth analysis of Android malware. Our experimental work systematically reveals the phylogenetic relationships among the variant sets for a deeper malware evolution analysis. We introduce five metrics: silhouette coefficient, creation date, variant labels, the presentativeness of the variant set formula, and the correctness of the linked edges to evaluate the correctness of our analysis. The results show that our variant clustering achieved a high silhouette value at a small sample distance (0.3), a small standard deviation (three months and 16 days) date based on when the malware samples are lastly modified, a high label consistency (91.4%), a high representativeness (93.1%) of the variant set formula. All the linked variant sets are connected based on our PhyloNet construction rules. We further analyse the coding details of Android malware for each variant set and summarise models of their evolutionary development. In this work, we successfully expose two major models of malware evolution: active evolution and passive evolution. We also disclose four technical explanations on the incentives of the two evolution models (two for each model respectively). These findings are valuable for proactive defence against newly emerged malware samples.}
}


@article{DBLP:journals/tdsc/YehHS24,
	author = {Lo{-}Yao Yeh and
                  Wan{-}Hsin Hsu and
                  Chih{-}Ya Shen},
	title = {GDPR-Compliant Personal Health Record Sharing Mechanism With Redactable
                  Blockchain and Revocable {IPFS}},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3342--3356},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3325907},
	doi = {10.1109/TDSC.2023.3325907},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YehHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of IoT technology in collecting personal health records (PHR) within the eHealth environment is a growing trend. However, data integrity is a concern as cloud service providers (CSPs) often cannot guarantee it. Blockchain technology offers a solution to guarantee data integrity and traceability. However, the immutability of traditional blockchain conflicts with GDPR's requirements. To address scalability and privacy concerns, we have designed a comprehensive scheme that integrates the redactable blockchain with the existing revocable IPFS mechanism. Our scheme overcomes the disadvantage of residual downloading information in the traditional blockchain. Additionally, we have developed an enhanced proxy re-encryption scheme that simplifies access control for physicians without the need for complex group key management. Unlike traditional blockchains and P2P file sharing systems, our PHR platform allows for selective removal of records and files while maintaining auditable logs. Evaluation results demonstrate that our proposed scheme effectively enhances the exclusive revocation feature with acceptable overheads. To the best of our knowledge, this is the first work to provide the merit of fully complete record and file revocation on a blockchain-based system.}
}


@article{DBLP:journals/tdsc/AlsadiCDDRSSTWW24,
	author = {Mohammed Alsadi and
                  Matthew Casey and
                  Constantin Catalin Dragan and
                  Fran{\c{c}}ois Dupressoir and
                  Luke Riley and
                  Muntadher Sallal and
                  Steve Schneider and
                  Helen Treharne and
                  Joe Wadsworth and
                  Phil Wright},
	title = {Towards End-to-End Verifiable Online Voting: Adding Verifiability
                  to Established Voting Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3357--3374},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3327859},
	doi = {10.1109/TDSC.2023.3327859},
	timestamp = {Mon, 04 Nov 2024 07:42:46 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/AlsadiCDDRSSTWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online voting for independent elections is generally supported by trusted election providers. Typically these providers do not offer any way in which a voter can verify their vote, and hence the providers are trusted with ballot privacy and in ensuring correctness. Despite the desire to offer online voting for political elections, this lack of transparency and verifiability is often seen as a significant barrier to the large-scale adoption of online elections. Adding verifiability to an online election increases transparency and integrity, as well as allowing voters to verify that the vote they cast has been recorded correctly and included in the tally. However, replacing existing online systems with those that provide verifiable voting requires new algorithms and code to be deployed, and this presents a significant business risk to commercial election providers, as well as the societal risk for official elections selecting for public office. In this paper we present the first step in an incremental approach which minimises the business risk but demonstrates the advantages of verifiability, by developing an implementation of key elements of a Selene-based verifiability layer and adding it to an operational online voting system. Selene is a verifiable voting protocol that publishes votes in plaintext alongside a voter's tracker. These trackers enable voters to confirm that their votes have been captured correctly by the system, such that the election provider does not know which tracker has been allocated to which voter. This results in a system where even a “dishonest but cautious” election authority running the system cannot be sure of changing the result in an undetectable way, and hence gives stronger guarantees on the integrity of the election than were previously present. We explore the challenges presented by adding a verifiability layer to an operational system. The system was used in two initial trials conducted within real contested elections. We conclude by outlining the further steps in the road-map towards the deployment of a fully trustworthy online voting system.}
}


@article{DBLP:journals/tdsc/YinXLZ24,
	author = {Lingyuan Yin and
                  Jing Xu and
                  Kaitai Liang and
                  Zhenfeng Zhang},
	title = {Sidechains With Optimally Succinct Proof},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3375--3389},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3328430},
	doi = {10.1109/TDSC.2023.3328430},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YinXLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sidechains have been widely used to improve the interoperability and scalability of blockchain systems. Despite several interesting sidechain constructions have been proposed in the literature, they suffer from the following downsides: 1) their designs do not easily support pluggable consensus mechanisms, and 2) their communication and storage costs for cross-chain operations are not yet optimized. In this work, we first propose Ge-Co, a generic sidechain construction to realize secure asset transfers between blockchains, supporting different consensus algorithms, such as Proof-of-Stake (PoS) and Proof-of-Work (PoW). Our design is built on top of the proposed voting committee selection approach and threshold signature schemes (TSS) and meanwhile, it achieves optimally succinct and constant proof size, only yielding lightweight communication and storage costs. Ge-Co works in the semi-adaptive corruption model. To provide stronger security, we further propose PoS-Co, a PoS-based sidechain construction in the fully-adaptive corruption model. PoS-Co is based on the proposed anonymous committee selection approach, and preserves optimally succinct proof. We also formally prove that Ge-Co can achieve the security properties of atomicity and timeliness. Finally, we develop a proof-of-concept (PoC) implementation for Ge-Co, and the results demonstrate that the design is efficient and practical.}
}


@article{DBLP:journals/tdsc/CaoWFDZQR24,
	author = {Guodong Cao and
                  Zhibo Wang and
                  Yunhe Feng and
                  Xiaowei Dong and
                  Zhifei Zhang and
                  Zhan Qin and
                  Kui Ren},
	title = {Task-Free Fairness-Aware Bias Mitigation for Black-Box Deployed Models},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3390--3405},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3328663},
	doi = {10.1109/TDSC.2023.3328663},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/CaoWFDZQR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With AI systems widely deployed in societal applications, the fairness of these models is of increasing concern, for instance, hiring systems should recommend applicants impartially from different demographic groups, and risk assessment systems must eliminate racial inequity in the criminal justice system. Therefore, ensuring fairness in these models is crucial. In this paper, we propose Task-Free Fairness-Aware Adversarial Perturbation (TF-FAAP), a flexible approach for improving the fairness of black-box deployed models by adding perturbations on input samples that blind their fairness-related attribute information without modifying the model's parameters or structures. The proposed TF-FAAP consists of a discriminator and a generator to create universal fairness-aware perturbations for a variety of tasks. The former aims to distinguish fairnessrelated attributes, and the latter generates perturbations to make the discriminator's prediction distribution of fairness-related attributes uniform. To preserve the utility of perturbed samples, we maximize the mutual information between their representations and corresponding original samples, retaining more original samples' information. In addition, the perturbation generated by TF-FAAP has a high transferability, i.e., the perturbations learned on one dataset can also alleviate the unfairness of a model trained on a different dataset. The extensive experimental evaluation demonstrated the effectiveness and superior performance of our method.}
}


@article{DBLP:journals/tdsc/ChenWHCHZTCLR24,
	author = {Zhuo Chen and
                  Lei Wu and
                  Yubo Hu and
                  Jing Cheng and
                  Yufeng Hu and
                  Yajin Zhou and
                  Zhushou Tang and
                  Yexuan Chen and
                  Jinku Li and
                  Kui Ren},
	title = {Lifting the Grey Curtain: Analyzing the Ecosystem of Android Scam
                  Apps},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3406--3421},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3329205},
	doi = {10.1109/TDSC.2023.3329205},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ChenWHCHZTCLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile applications (apps) are extensively involved in online scams. Previous studies mainly target malicious apps that either compromise victims’ devices (e.g., malware and ransomware), or lead to privacy leakage and abuse (e.g., creepware). Recently, an emerging kind of app makes profits by providing scam services rather than compromising devices or abusing privacy. We name these apps as scamware due to their deceptive behavior, which poses a new threat to (mobile) users. However, the characteristics and the ecosystem of scamware remain mysterious. This article takes the first step toward systematically studying scamware. In total, 1,262 ground-truth scamware are collected from December 1, 2020, to May 1, 2022. Specifically, we first investigate the social tricks used by scamware, and then analyze the participants and their relationships to demystify the ecosystem behind scamware. Finally, we reveal the scamware development features to facilitate the detection of scamware. Our study also gives some interesting findings, e.g., 1) the crowd-sourcing strategy is adopted to develop scamware, i.e., the scammers are the core members, while other participants are hired as peripherals; and 2) the online app generators have been abused to facilitate development; and 3) the money mule based payment is prevalent, and the case study shows the money flow is around\n$\n2,593,346 per day. We believe that our findings will facilitate the community and law enforcement agencies to mitigate this threat, and we will release the source code of our tools to engage the community.}
}


@article{DBLP:journals/tdsc/HouLHZSSY24,
	author = {Jiahui Hou and
                  Dongxiao Liu and
                  Cheng Huang and
                  Weihua Zhuang and
                  Xuemin Shen and
                  Rob Sun and
                  Bidi Ying},
	title = {Data Protection: Privacy-Preserving Data Collection With Validation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3422--3438},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3326299},
	doi = {10.1109/TDSC.2023.3326299},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HouLHZSSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ubiquitous data collection has raised potential risks of leaking physical and private attribute information associated with individuals in a collected dataset. A data collector who wants to collect data for provisioning its machine learning (ML)-based services requires establishing a privacy-preserving data collection protocol for data owners. In this work, we design, implement, and evaluate a novel privacy-preserving data collection protocol. Specifically, we validate the functionality of the data collection protocol on behalf of data owners. First, the ML-based services are not always predefined, it is challenging for a data collector to combat inference of private attributes and user identity from the collected data while maintaining the utility of data. To address the challenge, we reconstruct the data by designing a data transformation model based on the autoencoder and clustering. Second, it is necessary to ensure that the reconstructed data satisfy certain privacy-preserving properties as untrusted data collectors can provide the data transformation models. Therefore, we utilize detection models and design an efficient enclave-based mechanism to validate that the reconstructed data's private attribute estimation probability is bounded by the predefined thresholds. Extensive experiments demonstrate our protocol's effectiveness, such as significantly reducing the accuracy of private attribute detection.}
}


@article{DBLP:journals/tdsc/ZhangZLFZG24,
	author = {Chuan Zhang and
                  Mingyang Zhao and
                  Jinwen Liang and
                  Qing Fan and
                  Liehuang Zhu and
                  Song Guo},
	title = {{NANO:} Cryptographic Enforcement of Readability and Editability Governance
                  in Blockchain Databases},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3439--3452},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3330171},
	doi = {10.1109/TDSC.2023.3330171},
	timestamp = {Fri, 07 Feb 2025 10:18:47 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangZLFZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, increasing personal data has been stored in blockchain databases, ensuring data integrity by consensus. Although transparent and immutable blockchains are mainly adopted, the need to deploy preferences on which users can read and edit the data is growing in importance. Based on chameleon hashes, recent blockchains support editability governance but can hardly prevent data breaches because the data is readable to all participants in plaintexts. This motivates us to propose NANO, the first permissioned blockchain database that provides downward compatible readability and editability governance (i.e., users who can edit the data can also read the data). Two challenges are protecting policy privacy and efficiently revoking malicious users (e.g., users who abuse their editability privileges). The punchline is leveraging Newton's interpolation formula-based secret sharing to hide policies into polynomial parameters and govern the distribution of data decryption keys and chameleon hash trapdoors. Inspired by proxy re-encryption, NANO integrates unique user symbols into user keys, achieving linear user revocation overhead. Security analysis proves that NANO provides comprehensive privacy preservation under the chosen-ciphertext attack. Experiments on the FISCO blockchain platform demonstrate that compared with state-of-the-art related solutions, NANO achieves a 7× improvement on average regarding computational costs, gas consumption, and communication overhead.}
}


@article{DBLP:journals/tdsc/YinGXMZZ24,
	author = {Tingting Yin and
                  Zicong Gao and
                  Zhenghang Xiao and
                  Zheyu Ma and
                  Min Zheng and
                  Chao Zhang},
	title = {KextFuzz: {A} Practical Fuzzer for macOS Kernel EXTensions on Apple
                  Silicon},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3453--3468},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3330852},
	doi = {10.1109/TDSC.2023.3330852},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YinGXMZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {macOS drivers, i.e., Kernel EXTensions (kexts), are attractive attack targets for adversaries. However, automatically discovering vulnerabilities in kexts is extremely challenging because kexts are mostly closed-source, and the latest macOS running on customized Apple Silicon has limited tool-chain support. Most existing static analysis and dynamic testing solutions cannot be applied to the latest macOS. In this paper, we present the first end-to-end fuzzing solution KextFuzz to detect bugs in the latest macOS kexts running on Apple Silicon. Unlike existing driver fuzzing solutions, KextFuzz does not require source code, execution traces, hypervisors, or hardware features (e.g., coverage tracing) and thus is universal and practical. We note that macOS has deployed many mitigations, including pointer authentication, code signature, and userspace kernel layer wrappers, to thwart potential attacks. These mitigations can provide extra knowledge and resources for us to enable kernel fuzzing. KextFuzz exploits these mitigation schemes to instrument the binary for coverage tracking, infer the type and semantic information of kext interfaces, and generate multi-dimension inputs. KextFuzz has found 49 unique kernel bugs in the macOS kexts and got five CVEs. Some bugs could cause severe consequences like running arbitrary code with kernel privilege.}
}


@article{DBLP:journals/tdsc/LiuHCWL24,
	author = {Chun Liu and
                  Xuexian Hu and
                  Xiaofeng Chen and
                  Jianghong Wei and
                  Wenfen Liu},
	title = {{SDIM:} {A} Subtly Designed Invertible Matrix for Enhanced Privacy-Preserving
                  Outsourcing Matrix Multiplication and Related Tasks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3469--3486},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3333256},
	doi = {10.1109/TDSC.2023.3333256},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuHCWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Matrix multiplication computation (MMC) is a fundamental operation with various applications, including linear regression, k-nearest neighbor classification and biometric identification. However, performing these tasks with large-scale datasets surpasses the computation capabilities of resource-constrained clients. As outsourcing intensive tasks to cloud server has become a promising method, many matrix-transformation-based privacy-protected schemes have been presented for certain outsourcing tasks, such as Lei et al.'s scheme addresses MMC outsourcing, and Zhao et al.'s scheme focuses on matrix determinant computation. Nevertheless, Lei et al.'s scheme exhibits inherent security flaws, leaking statistical information about zero elements in the original data. Additionally, Zhao et al.'s scheme is task-specific, limiting its application to universal scenarios such as MMC, where clients must compute the inverse matrix of the secret key. Therefore, designing an invertible matrix presents a challenge that affects privacy security, efficiency, and universality of matrix-transformation-based privacy-protected outsourcing computing schemes. To address this issue, we propose a subtly designed invertible matrix (SDIM) and a privacy-protected outsourcing MMC scheme based on SDIM, remedying the security flaws of Lei et al.'s scheme. We also propose an optimized matrix-chain multiplication method to ensure high efficiency of the SDIM-based privacy-protected scheme. This optimization also allows SDIM to be universally applied not only to MMC but also to other related outsourced tasks such as linear regression. Theoretical analyses and experiments have demonstrated that our methods provide enhanced data privacy security while maintaining efficiency comparable to the state-of-the-art scheme based on matrix transformation, i.e., achieving a well-balanced trade-off between security, efficiency, and universality.}
}


@article{DBLP:journals/tdsc/LiLRSGWHL24,
	author = {Dawei Li and
                  Di Liu and
                  Yangkun Ren and
                  Yu Sun and
                  Zhenyu Guan and
                  Qianhong Wu and
                  Jiankun Hu and
                  Jianwei Liu},
	title = {{CPAKA:} Mutual Authentication and Key Agreement Scheme Based on Conditional
                  {PUF} in Space-Air-Ground Integrated Network},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3487--3500},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3333549},
	doi = {10.1109/TDSC.2023.3333549},
	timestamp = {Tue, 27 Aug 2024 15:50:37 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiLRSGWHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The space-air-ground integrated network (SAGIN) has a stringent demand on the efficiency of authentication protocols deployed in the devices that have been launched into the air and space. In this article, we define the concept of the security model of conditional physical unclonable function (CPUF) that guarantees the security of the protocol while allowing the use of PUFs that can be modeled. We then propose a CPUF-based authentication and key agreement (AKA) scheme, named CPAKA, that addresses the challenges of device key leakage and inefficient authentication in resource-asymmetric environments. The CPAKA scheme embeds PUFs in weak nodes and deploys prediction models corresponding to the PUFs in strong nodes, eliminating the need to store challenge-response pairs or perform complex calculations. We formally prove the protocol's security under the decisional uniqueness assumption of CPUF and the universal composability framework, and we analyze its secrecy and authentication properties using the Tamarin prover. We also implement an Arbiter PUF on the ZYNQ-7020 FPGA, verify its accuracy through experiments, and show that CPAKA is secure, efficient, and suitable for SAGIN. Our CPAKA scheme greatly reduces computing and storage costs while improving authentication efficiency compared to traditional schemes.}
}


@article{DBLP:journals/tdsc/WangJCZWHWL24,
	author = {Dingding Wang and
                  Muhui Jiang and
                  Rui Chang and
                  Yajin Zhou and
                  Hexiang Wang and
                  Baolei Hou and
                  Lei Wu and
                  Xiapu Luo},
	title = {An Empirical Study on the Insecurity of End-of-Life (EoL) IoT Devices},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3501--3514},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334017},
	doi = {10.1109/TDSC.2023.3334017},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WangJCZWHWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Researchers actively work on the security of Internet of Things (IoT) devices when IoT devices become popular. However, previous works ignore the insecurity about a special category of devices, i.e., the end-of-life (EoL) devices. Once a product becomes EoL, vendors no longer maintain its firmware, which makes it susceptible to attacks. In this article, we conduct the first empirical study to shed light on the (in)security of EoL devices. Our study performs two types of analysis, including the liveness analysis and the vulnerability analysis. The first one aims to detect the scale of EoL devices that are still alive in the wild in the long term. The second one is to evaluate the vulnerabilities existing in (active) EoL devices. We analyzed 894 EoL models from three vendors (i.e., D-Link, Tp-Link, and Netgear) for more than two years. Our study reveals some worrisome facts that were unknown by the community. There exist more than three million active EoL devices, while more than one million of them have been alive for more than five years. Furthermore, more than half of the vulnerabilities are discovered after the EoL date. Although vendors may release security patches after the EoL date, the process is ad hoc and incomplete, with limited functionality. In summary, more than three million active EoL devices are vulnerable, and nearly half of them are threatened by high-risk vulnerabilities. By compromising EoL devices, attackers can achieve a minimum of 8.67 Tbps DDoS attack.}
}


@article{DBLP:journals/tdsc/ZhangCQZY24,
	author = {Jiansong Zhang and
                  Kejiang Chen and
                  Chuan Qin and
                  Weiming Zhang and
                  Nenghai Yu},
	title = {{AAS:} Automatic Virtual Data Augmentation for Deep Image Steganalysis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3515--3527},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3333913},
	doi = {10.1109/TDSC.2023.3333913},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangCQZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, steganalysis based on deep learning has evolved rapidly. However, training deep learning models is data-consuming. The models are prone to overfitting when data is limited. Data augmentation is an effective method to mitigate overfitting. Existing data augmentation methods in steganalysis can be categorized into cover enrichment and virtual augmentation. They are used in different stages. Cover enrichment refers to introducing additional cover-stego pairs in some ways, which is performed prior to training. In contrast, virtual augmentation augments data during training. Existing virtual augmentation methods are designed heuristically and rely on expert knowledge. In this paper, we propose the first automatic virtual data augmentation method for steganalysis. Specifically, we design an augmentation network that augments cover and stego images by intelligently adding noises. The augmentation network is trained adversarially with the steganalyzer to generate diverse data. Meanwhile, a “class-invariant” module prevents the augmentation network from changing the original data distribution too much. A “stabilizer” loss function is designed that keeps the adversarial training stable by constraining the number of noises. The experimental results show that the proposed method outperforms existing virtual augmentation methods. Moreover, combining the proposed method and cover enrichment can further boost performance.}
}


@article{DBLP:journals/tdsc/JiangYCSWM24,
	author = {Tao Jiang and
                  Xu Yuan and
                  Qiong Cheng and
                  Yulong Shen and
                  Liangmin Wang and
                  Jianfeng Ma},
	title = {FairECom: Towards Proof of E-Commerce Fairness Against Price Discrimination},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3528--3544},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334197},
	doi = {10.1109/TDSC.2023.3334197},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/JiangYCSWM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Price discrimination has been empirically exposed where e-commercial platforms aim to gain additional profits by charging customers with different prices for the same product/service. This situation becomes even worse in nowadays’ Big Data era, giving the chance for service providers to leverage artificial intelligence technologies to have the deep analysis of personalized patterns, urgently calling for solutions to prevent such discriminated behaviors to protect customers’ rights. This article aims to defend against price discrimination by developing a secure and privacy-preserving solution, provable for e-commerce fairness. Using a newly designed cryptographic accumulator and public bulletin board, our system, called FairECom, allows an auditor (i.e., a customer or third-party auditor) to verify if customers are experiencing price discrimination. In particular, FairECom enables a customer to check if his payment to a product/service is identical to other customers through a privacy-preserving challenge-response protocol, for implementing the price transparency against discrimination. We implement a prototype using an Ethereum-based public bulletin board to conduct the system evaluation. Our evaluation indicates that FairECom can integrate with existing APIs provided by Ethereum and incur acceptable costs when deploying to the e-commercial systems.}
}


@article{DBLP:journals/tdsc/SongHZXJ24,
	author = {Mingyang Song and
                  Zhongyun Hua and
                  Yifeng Zheng and
                  Tao Xiang and
                  Xiaohua Jia},
	title = {Enabling Transparent Deduplication and Auditing for Encrypted Data
                  in Cloud},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3545--3561},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334475},
	doi = {10.1109/TDSC.2023.3334475},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SongHZXJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In cloud storage systems, secure deduplication plays a critical role in saving storage costs for the cloud server and ensuring data confidentiality for cloud users. Traditional secure deduplication schemes require users to encrypt their outsourced files using specific encryption algorithms that cannot provide semantic security. However, users are unable to directly benefit from the storage savings, as the relation between the actual storage cost and the offered prices remains not transparent. As a result, users may be unwilling to cooperate with the cloud by encrypting their data using semantically secure algorithms. Moreover, data integrity is a significant concern for cloud storage users. To address these issues, this paper proposes a novel transparent and secure deduplication scheme that supports integrity auditing. Compared to previous works, our design can verify the number of file owners and the integrity through one-time proof verification. It also protects the private contents of files and the privacy of file ownership from malicious users. Moreover, our scheme includes a batch auditing method to simultaneously verify the numbers of file owners and the integrity of multiple files. Theoretical analysis confirms the correctness and security of our scheme. Comparison results demonstrate its competing performance over previous solutions.}
}


@article{DBLP:journals/tdsc/MenetreyPFSMHV24,
	author = {J{\"{a}}mes M{\'{e}}n{\'{e}}trey and
                  Marcelo Pasin and
                  Pascal Felber and
                  Valerio Schiavoni and
                  Giovanni Mazzeo and
                  Arne Hollum and
                  Darshan Vaydia},
	title = {A Comprehensive Trusted Runtime for WebAssembly With Intel {SGX}},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3562--3579},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334516},
	doi = {10.1109/TDSC.2023.3334516},
	timestamp = {Sun, 19 Jan 2025 13:48:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/MenetreyPFSMHV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In real-world scenarios, trusted execution environments (TEEs) frequently host applications that lack the trust of the infrastructure provider, as well as data owners who have specifically outsourced their data for remote processing. We present Twine, a trusted runtime for running WebAssembly-compiled applications within TEEs, establishing a two-way sandbox. Twine leverages memory safety guarantees of WebAssembly (Wasm) and abstracts the complexity of TEEs, empowering the execution of legacy and language-agnostic applications. It extends the standard WebAssembly system interface (WASI), providing controlled OS services, focusing on I/O. Additionally, through built-in TEE mechanisms, Twine delivers attestation capabilities to ensure the integrity of the runtime and the OS services supplied to the application. We evaluate its performance using general-purpose benchmarks and real-world applications, showing it compares on par with state-of-the-art solutions. A case study involving fintech company Credora reveals that Twine can be deployed in production with reasonable performance trade-offs, ranging from a 0.7× slowdown to a 1.17× speedup compared to native run time. Finally, we identify performance improvement through library optimisation, showcasing one such adjustment that leads up to 4.1× speedup.Twine is open-source and has been upstreamed into the original Wasm runtime, WAMR.}
}


@article{DBLP:journals/tdsc/WangTZJ24,
	author = {Cheng Wang and
                  Hao Tang and
                  Hangyu Zhu and
                  Changjun Jiang},
	title = {Collaborative Prediction in Anti-Fraud System Over Multiple Credit
                  Loan Platforms},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3580--3596},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334281},
	doi = {10.1109/TDSC.2023.3334281},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WangTZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anti-fraud engineering for online credit loan (OCL) platforms is getting more challenging due to the developing specialization of gang fraud. Associations are critical features referring to assessing the credibility of loan applications for OCL fraud prediction. State-of-the-art solutions employ graph-based methods to mine hidden associations among loan applications effectively. They perform well based on the information asymmetry which is guaranteed by the huge advantage of platforms over fraudsters in terms of data quantity and quality at their disposal. The inherent difficulty that can be foreseen is the data isolation caused by mistrust between multiple platforms and data control legislations for privacy preservation. To maintain the advantage owned by the platforms, we design a privacy-preserving distributed graph learning framework that ensures critical association repairs by merging parameter sharing and data sharing. Specially, we propose the association reconstruction mechanism (ARM) that consists of the devised exploration, processing, transmission and utilization schemes to realize data sharing. For parameter sharing, we design a hybrid encryption technique to protect privacy during collaboratively learning graph neural network (GNN) models among different financial client platforms. We conduct the experiments over real-life data from large financial platforms. The results demonstrate the effectiveness and efficiency of our proposed methods.}
}


@article{DBLP:journals/tdsc/LiuXYZHLW24,
	author = {Feng Liu and
                  Kaiping Xue and
                  Jinjiang Yang and
                  Jing Zhang and
                  Zixuan Huang and
                  Jian Li and
                  David S. L. Wei},
	title = {Volume-Hiding Range Searchable Symmetric Encryption for Large-Scale
                  Datasets},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3597--3609},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3335304},
	doi = {10.1109/TDSC.2023.3335304},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuXYZHLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searchable Symmetric Encryption (SSE) is a valuable cryptographic tool that allows a client to retrieve its outsourced data from an untrusted server via keyword search. Initially, SSE research primarily focused on the efficiency-security trade-off. However, in recent years, attention has shifted towards range queries instead of exact keyword searches, resulting in significant developments in the SSE field. Despite the advancements in SSE schemes supporting range queries, many are susceptible to leakage-abuse attacks due to volumetric profile leakage. Although several schemes exist to prevent volume leakage, these solutions prove inefficient when dealing with large-scale datasets. In this article, we highlight the efficiency-security trade-off for range queries in SSE. Subsequently, we propose a volume-hiding range SSE scheme that ensures efficient operations on extensive datasets. Leveraging the order-weighted inverted index and bitmap structure, our scheme achieves high search efficiency while maintaining the confidentiality of the volumetric profile. To facilitate searching within large-scale datasets, we introduce a partitioning strategy that divides a broad range into disjoint partitions and stores the information in a local binary tree. Through an analysis of the leakage function, we demonstrate the security of our proposed scheme within the ideal/real model simulation paradigm. Our experimental results further validate the practicality of our scheme with real-life large-scale datasets.}
}


@article{DBLP:journals/tdsc/YangJCDZ24,
	author = {Zheng Yang and
                  Chenglu Jin and
                  Xuelian Cao and
                  Marten van Dijk and
                  Jianying Zhou},
	title = {Optimizing Proof of Aliveness in Cyber-Physical Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3610--3628},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3335188},
	doi = {10.1109/TDSC.2023.3335188},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YangJCDZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {At ACSAC 2019, we introduced a new cryptographic primitive called proof of aliveness (PoA), allowing us to remotely and automatically track the running status (aliveness) of devices in the fields in cyber-physical systems. We proposed to use a one-way function (OWF) chain structure to build an efficient proof of aliveness, such that the prover sends every node on the OWF chain in a reverse order periodically. However, the finite nodes in OWF chains limited its practicality. We enhance our first PoA construction by linking multiple OWF chains together using a pseudo-random generator chain in our second PoA scheme. This enhancement allows us to integrate one-time signature (OTS) schemes into the structure of the second construction to realize the auto-replenishment of the aliveness proofs for continuous use without interruption for reinitialization. In this work, our primary motivation is to further improve our secondary PoA and auto-replenishment schemes. Instead of storing the tail nodes of multiple OWF chains on the verifier side, we use a Bloom Filter to compress them, reducing the storage cost by\n4.7\ntimes. Moreover, the OTS-based auto-replenishment solution cannot be applied to our first scheme, and it is not so efficient despite its standard model security. To overcome these limitations, we design a new auto-replenishment scheme from a hash-based commitment under the random oracle model in this work, which is much faster and can be used by both PoA schemes. Considering the implementation on a storage/memory-constrained device, we particularly study the strategies for efficiently generating proofs.}
}


@article{DBLP:journals/tdsc/MinZDLXPH24,
	author = {Minghui Min and
                  Haopeng Zhu and
                  Jiahao Ding and
                  Shiyin Li and
                  Liang Xiao and
                  Miao Pan and
                  Zhu Han},
	title = {Personalized 3D Location Privacy Protection With Differential and
                  Distortion Geo-Perturbation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3629--3643},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3335374},
	doi = {10.1109/TDSC.2023.3335374},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MinZDLXPH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of indoor location-based services (LBS) has raised concerns about location privacy protection in the 3-dimensional (3D) space. The existing 2-dimensional (2D) location privacy protection mechanisms (LPPMs) cannot effectively resist attacks in 3D environments. Furthermore, users may have various sensitive attributes at different locations and times. In this article, we first formally study the relationship between two complementary notions of geo-indistinguishability and distortion privacy (i.e., expected inference error) in the 3D space and develop a two-phase personalized 3D LPPM (P3DLPPM). In Phase I, we search for neighboring locations to formulate a protection location set (PLS) for hiding the actual location based on the above-mentioned relationship. To realize this, we develop a 3D Hilbert curve-based minimum distance searching algorithm to find the PLS with minimum diameter for each location while guaranteeing differential privacy. In Phase II, we put forth a novel Permute-and-Flip mechanism for location perturbation, which maps its initial application in data publishing privacy protection to a location perturbation mechanism. It generates fake locations with smaller perturbation distances while improving the balance between privacy and quality of service (QoS). Simulation results show that the proposed P3DLPPM can significantly improve personalized privacy protection while meeting the user's QoS needs.}
}


@article{DBLP:journals/tdsc/DengFWHL24,
	author = {Lunzhi Deng and
                  Shuai Feng and
                  Tao Wang and
                  Zhenyu Hu and
                  Siwei Li},
	title = {Identity-Based Data Auditing Scheme With Provable Security in the
                  Standard Model Suitable for Cloud Storage},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3644--3655},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3336994},
	doi = {10.1109/TDSC.2023.3336994},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DengFWHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In a data auditing scheme, the data owner authorizes a third-party auditor (TPA) to check whether the data stored in the cloud remains intact. Researchers have given many data auditing schemes. However, there are still three significant shortcomings in these schemes. First of all, the security proofs of these schemes are completed in the random oracle model (ROM). As we all know, a scheme with provably security in ROM may be insecure in practical applications. Second, TPA in most known schemes is set to be completely reliable. However, TPA in reality may attempt to extract the data owner's data. These schemes cannot resist the malicious behavior of TPA. Third, most known schemes require hash-to-point operations and enjoy high computation cost, so they are not suitable for computing-constrained environments. In this article, we first presented the system model and security demands for an identity-based data auditing (IBDA) scheme. We then came up with a new IBDA scheme and showed the security proofs in the standard model (SM). Finally, we made an analysis on performance for seven data auditing schemes. In our scheme, the computation cost required by TPA is a constant, independent of the number of data blocks participating in the challenge. Therefore, our scheme requires low computation cost and is suitable for computing-constrained environments.}
}


@article{DBLP:journals/tdsc/ZhangLLCP24,
	author = {Zongyang Zhang and
                  Weihan Li and
                  Ximeng Liu and
                  Xin Chen and
                  Qihang Peng},
	title = {Ligerolight: Optimized IOP-Based Zero-Knowledge Argument for Blockchain
                  Scalability},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3656--3670},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3336717},
	doi = {10.1109/TDSC.2023.3336717},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangLLCP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Zero-knowledge scalable transparent arguments of knowledge (zk-STARKs) are a promising approach to solving the blockchain scalability problem while maintaining security, decentralization and privacy. However, compared with zero-knowledge proofs with trusted setups deployed in existing scalability solutions, zk-STARKs are usually less efficient. In this paper, we introduce Ligerolight, an optimized zk-STARK for the arithmetic circuit satisfiability problem following the framework of Ligero (ACM CCS 2017) and Aurora (Eurocrypt 2019) based on interactive oracle proof, which could be used for blockchain scalability. Evaluations show that Ligerolight has performance advantages compared with existing zk-STARKs. The prover time is 30% faster than Aurora to generate proof for computing an authentication path of a Merkle tree with 32 leaves. The proof size is about 131 KB, one-tenth of Ligero and 50% smaller than Aurora. The verifier time is 2 times as fast as Aurora. Underlying Ligerolight is a new batch zero-knowledge inner product argument, allowing to prove multiple inner product relations once. Using this argument, we build a batch multivariate polynomial commitment with poly-logarithmic communication complexity and verification. This polynomial commitment is particularly efficient when opening multiple points in multiple polynomials at one time, and may be of independent interest in constructing scalability solutions.}
}


@article{DBLP:journals/tdsc/0020024,
	author = {Liang Zhao and
                  Liqun Chen},
	title = {Privacy-Preserving Transformation Used in Verifiable (Outsourced)
                  Computation, Revisited},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3671--3687},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334890},
	doi = {10.1109/TDSC.2023.3334890},
	timestamp = {Tue, 22 Oct 2024 21:09:43 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/0020024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, a privacy-preserving technique called Privacy-Preserving Matrix Transformation (PPMT) is widely used to construct efficient privacy-preserving Verifiable (outsourced) Computation (VC) protocols for specific functions. This technique is first proposed and formalized by Salinas et al. in 2015, and it enjoys provable privacy and high efficiency. Although it seems that Salinas et al.'s PPMT scheme and the further modified scheme are elegant, we still need to take a step back and precisely discuss whether the PPMT schemes are suitable choices for VC protocols. Since Salinas et al. gave two concrete PPMT schemes to achieve the matrix-related VC in data protection and proved that their schemes are private (in terms of indistinguishability), and Zhou et al. devised a new type of PPMT scheme for the same purpose, we focus on exploring privacy of these three types of PPMT schemes. In this article, to achieve our object, we first propose the concept of a linear distinguisher and two constructions of the linear distinguisher algorithms. In particular, the linear distinguisher is a polynomial-time algorithm employed by an adversary to explore the privacy property of a cryptographic primitive. Then, we take these three PPMT schemes (including Salinas et al.'s original work, Yu et al.'s generalization and Zhou et al.'s variant) as targets and analyze their privacy property by letting an adversary make use of our linear distinguisher algorithms. The analysis results show that all these three types of transformations do not hold privacy even against passive eavesdropping (i.e., a ciphertext-only attack), and subsequently, the privacy-preserving VC protocols, based on any of these PPMT schemes, also do not hold the same privacy.}
}


@article{DBLP:journals/tdsc/MiaoGZCV24,
	author = {Ying Miao and
                  Keke Gai and
                  Liehuang Zhu and
                  Kim{-}Kwang Raymond Choo and
                  Jaideep Vaidya},
	title = {Blockchain-Based Shared Data Integrity Auditing and Deduplication},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3688--3703},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3335413},
	doi = {10.1109/TDSC.2023.3335413},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MiaoGZCV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data deduplication and integrity auditing based blockchain plays an important role in guaranteeing secure and efficient cloud storage services. However, existing data deduplication schemes support auditing either with the assistance of a trust center (key server or third-party auditor) or bear the waste of computation and storage resources caused by repetitive authenticators storage and key storage. In this paper, we propose a blockchain-based shared data integrity auditing and deduplication scheme. Specifically, we propose a deduplication protocol based on ID-based broadcast encryption without key servers and achieve key deduplication on the user side. Next, we propose a data integrity auditing protocol by using the characteristic of convergent encryption to achieve authenticator deduplication on the cloud service provider side. Besides, we achieve decentralized data integrity auditing based blockchain without relying on a single trusted third-party auditor and improve the credibility of the auditing result. On this basis, we propose two bath auditing protocols for different scenarios to improve efficiency. Security and performance analysis demonstrates that the authenticators’ storage cost on the cloud storage provider side can be reduced from {\\mathcal {O}}({\\mathcal {F}}) to {\\mathcal {O}}(1) and the key storage cost on the user side can be reduced from {\\mathcal {O}}({\\mathcal {F}}) to {\\mathcal {O}}(1) as well.}
}


@article{DBLP:journals/tdsc/XieLWW24,
	author = {Yadong Xie and
                  Fan Li and
                  Yue Wu and
                  Yu Wang},
	title = {User Authentication on Earable Devices via Bone-Conducted Occlusion
                  Sounds},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3704--3718},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3335368},
	doi = {10.1109/TDSC.2023.3335368},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XieLWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of mobile devices and the fast increase of sensitive data, secure and convenient mobile authentication technologies are desired. Except for traditional passwords, many mobile devices have biometric-based authentication methods (e.g., fingerprint, voiceprint, and face recognition), but they are vulnerable to spoofing attacks. To solve this problem, we study new biometric features which are based on the dental occlusion and find that the bone-conducted sound of dental occlusion collected in binaural canals contains unique features of individual bones and teeth. Motivated by this, we propose a novel authentication system, TeethPass\n+\n, which uses earbuds to collect occlusal sounds in binaural canals to achieve authentication. First, we design an event detection method based on spectrum variance to detect bone-conducted sounds. Then, we analyze the time-frequency domain of the sounds to filter out motion noises and extract unique features of users from four aspects: teeth structure, bone structure, occlusal location, and occlusal sound. Finally, we train a Triplet network to construct the user template, which is used to complete authentication. Through extensive experiments including 53 volunteers, the performance of TeethPass\n+\nin different environments is verified. TeethPass\n+\nachieves an accuracy of 98.6% and resists 99.7% of spoofing attacks.}
}


@article{DBLP:journals/tdsc/HussainGLP24,
	author = {Sajid Hussain and
                  Hui Guo and
                  Tuo Li and
                  Sri Parameswaran},
	title = {{MP-ORAM:} {A} Novel {ORAM} Design for Multicore Processor Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3719--3733},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3337114},
	doi = {10.1109/TDSC.2023.3337114},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HussainGLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Security becomes increasingly critical in today's ubiquitous computing. One vulnerable part of a computing system is the bus between the processor chip and the external off-chip memory, where data transferred on the bus can be snooped. To protect data confidentiality, encryption is commonly used. However, encryption alone is not sufficient since the adversary can still find out useful information using the memory address trace. Oblivious RAM (ORAM) is a strong security measure to prevent such information leak. ORAM hides a true memory access in a round of random (dummy) accesses to the memory such that the data and addresses transferred over the memory buses look oblivious to the adversary. However, the existing ORAM designs often incur a hefty performance overhead, which greatly slows down the processor execution, especially for the multicore processor system where the potentially high memory access frequency from the multiple cores could make the impact of the performance overhead even more critical. To address this issue, we, for the first time, propose to process multiple memory access requests in a single round of dummy memory accesses. As such, we develop a novel ORAM design, called MP-ORAM, that targets the multicore system and is able to simultaneously handle a dynamic number of memory access requests to mitigate the performance overhead without compromising the obliviousness of the off-chip memory access trace. We have built a prototype for MP-ORAM and successfully integrated it into a RISCV-based multicore processor system. The whole system has also been implemented on a Xilinx Ultrascale+ ZCU102 FPGA board, with which we can effectively evaluate the performance of our design. Our evaluation, based on the SPLASH-2 benchmark suit, shows that MP-ORAM improves performance by 51–157% while only consuming up to 22% extra FPGA resources as compared to the baseline design. Furthermore, from the NIST randomness tests on the memory access traces generated by MP-ORAM, we have demonstrated that this performance improvement does not affect the obliviousness of the memory access trace. Most importantly, MP-ORAM is the first ORAM design of its kind that has been fully implemented and evaluated on a real multicore processor system with OS support.}
}


@article{DBLP:journals/tdsc/ChengJZZFX24,
	author = {Yushi Cheng and
                  Xiaoyu Ji and
                  Wenjun Zhu and
                  Shibo Zhang and
                  Kevin Fu and
                  Wenyuan Xu},
	title = {Adversarial Computer Vision via Acoustic Manipulation of Camera Sensors},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3734--3750},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334618},
	doi = {10.1109/TDSC.2023.3334618},
	timestamp = {Fri, 19 Jul 2024 23:17:21 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ChengJZZFX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous vehicles increasingly rely on camera-based computer vision systems to perceive environments and make critical driving decisions. To improve image quality, image stabilizers with inertial sensors are added to reduce image blurring caused by camera jitters. However, this trend creates a new attack surface. This paper identifies a system-level vulnerability resulting from the combination of emerging image stabilizer hardware susceptible to acoustic manipulation and computer vision algorithms subject to adversarial examples. By emitting deliberately designed acoustic signals, an adversary can control the output of an inertial sensor, which triggers unnecessary motion compensation and results in a blurred image, even when the camera is stable. These blurred images can induce object misclassification, affecting safety-critical decision-making. We model the feasibility of such acoustic manipulation and design an attack framework that can accomplish three types of attacks: hiding, creating, and altering objects. Evaluation results demonstrate the effectiveness of our attacks against five object detectors (YOLO V3/V4/V5, Faster R-CNN, and Apollo) and two lane detectors (UFLD and LaneAF). We further introduce the concept of AMpLe attacks, a new class of system-level security vulnerabilities resulting from a combination of adversarial machine learning and physics-based injection of information-carrying signals into hardware.}
}


@article{DBLP:journals/tdsc/Zhao00M024,
	author = {Guichuan Zhao and
                  Qi Jiang and
                  Ding Wang and
                  Xindi Ma and
                  Xinghua Li},
	title = {Deep Hashing Based Cancelable Multi-Biometric Template Protection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3751--3767},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3335961},
	doi = {10.1109/TDSC.2023.3335961},
	timestamp = {Tue, 22 Oct 2024 21:09:43 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Zhao00M024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing use of multi-biometric authentication has raised concerns about the security of biometric templates. Many template protection methods based on convolutional neural network have been presented, but most involve a trade-off between authentication accuracy and template security. In this paper, we present a cancelable multi-biometric template protection scheme that combines deep hashing with cancelable distance-preserving encryption (CDPE), which provides high template security without degrading the authentication performance. Specifically, a deep hashing based architecture that minimizes the quantization loss is designed to map face and iris traits to binary codes. Next, CDPE is proposed to generate a protected template given the face binary code and a user-specific key obtained from the iris binary code, which preserves the distance between original templates in the protected domain to ensure authentication performance equivalent to unprotected systems. Digital lockers instead of the key are stored to further enhance the security, which can be unlocked with genuine biometric traits to get the correct key during authentication. Theoretical and experimental results on real face and iris datasets show that our scheme can achieve equal error rate of 0.23% and genuine accept rate of 97.54%, while guaranteeing irreversibility, revocability and unlinkability of protected templates.}
}


@article{DBLP:journals/tdsc/YangTSZCZ24,
	author = {Yutian Yang and
                  Jinjiang Tu and
                  Wenbo Shen and
                  Songbo Zhu and
                  Rui Chang and
                  Yajin Zhou},
	title = {kCPA: Towards Sensitive Pointer Full Life Cycle Authentication for
                  {OS} Kernels},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3768--3784},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334268},
	doi = {10.1109/TDSC.2023.3334268},
	timestamp = {Tue, 22 Oct 2024 21:09:43 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YangTSZCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, code reuse attacks impose a substantial threat to the security of operating system kernels. Control-flow graph-based CFI techniques, while effective, bring considerable performance overhead, thus limiting their practical adoption in real-world products. As an alternative approach, recent research suggests safeguarding the integrity of sensitive pointers as a countermeasure against manipulation attempts. Unfortunately, existing pointer integrity protection schemes only protect sensitive pointers partially and ignore assembly code, leaving protection gaps. To fill up these protection gaps, we propose a novel security concept named full life-cycle integrity, which enforces the integrity of a sensitive pointer at every step on its value flow chain. To realize full life-cycle integrity, we propose three novel techniques, including assembly-aware sensitivity for analyzing assembly code, Merkle PAC tree for protecting interrupt context securely and efficiently, and pointer-grained authentication for defeating spatial substitution attacks. We have developed a practical implementation of comprehensive life-cycle integrity for the Linux kernel, called ”kernel Code Pointer Authentication” (kCPA), which leverages the ARM Pointer Authentication (PAuth) mechanism. This implementation has been extended to the Apple M1 architecture for real-world evaluation on PAuth hardware. Our assessment demonstrates that kCPA effectively mitigates a range of real-world attacks while incurring a minimal 2.5% performance overhead for the Phoronix Test Suite and nearly negligible performance impact for SPEC2017 benchmarks.}
}


@article{DBLP:journals/tdsc/SongLWL24,
	author = {Jinke Song and
                  Qiang Li and
                  Haining Wang and
                  Jiqiang Liu},
	title = {{PKVIC:} Supplement Missing Software Package Information in Security
                  Vulnerability Reports},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3785--3800},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334762},
	doi = {10.1109/TDSC.2023.3334762},
	timestamp = {Thu, 18 Jul 2024 16:38:02 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SongLWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays security vulnerability reports contain commercial vendor-centric information but fail to include accurate information of open-source software packages. Open-source ecosystems use package managers, such as Maven, NuGet, NPM, and Gem, to cover hundreds of thousands of free code packages. However, we uncover that vulnerability reports frequently miss the vulnerable software package information when the software package comes from open-source ecosystems. To fill in this gap, we propose a framework called PKVIC (software package vulnerability information calibration), as the first tool to automatically associate security vulnerability reports with affected software packages from different open-source ecosystems. Specifically, PKVIC designs an ecosystem classifier to determine which ecosystem a vulnerability report belongs to. From the reports written in natural language, PKVIC extracts the entities closely related to software names in ecosystems. To efficiently and accurately locate the affected software packages from millions of packages, we propose a recursive traversal method to generate the package identifier based on the naming scheme and candidate named entities. We implemented the prototype of PKVIC and conducted comprehensive experiments to validate its efficacy. In particular, we ran PKVIC over 421,808 vulnerability reports from 20 well-known sources of security vulnerabilities and identified 11,279 unique vulnerability reports that affected 2,703 open-source software packages. PKVIC successfully found the accurate reference URLs for these 2,703 software packages across 6 open-source ecosystems, including Pypi, Gem, NPM, Packagist, Nuget, and Maven.}
}


@article{DBLP:journals/tdsc/WangDNL0YH0Z24,
	author = {Chenxu Wang and
                  Yunjie Deng and
                  Zhenyu Ning and
                  Kevin Leach and
                  Jin Li and
                  Shoumeng Yan and
                  Zhengyu He and
                  Jiannong Cao and
                  Fengwei Zhang},
	title = {Building a Lightweight Trusted Execution Environment for Arm GPUs},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3801--3816},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3334277},
	doi = {10.1109/TDSC.2023.3334277},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WangDNL0YH0Z24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A wide range of Arm endpoints leverage integrated and discrete GPUs to accelerate computation. However, Arm GPU security has not been explored by the community. Existing work has used Trusted Execution Environments (TEEs) to address GPU security concerns on Intel-based platforms, but there are numerous architectural differences that lead to novel technical challenges in deploying TEEs for Arm GPUs. There is a need for generalizable and efficient Arm-based GPU security mechanisms. To address these problems, we present StrongBox, the first GPU TEE for secured general computation on Arm endpoints. StrongBox provides an isolated execution environment by ensuring exclusive access to GPU. Our approach is based in part on a dynamic, fine-grained memory protection policy as Arm-based GPUs typically share a unified memory with the CPU. Furthermore, StrongBox reduces runtime overhead from the redundant security introspection operations. We also design an effective defense mechanism within secure world to protect the confidential GPU computation. Our design leverages the widely-deployed Arm TrustZone and generic Arm features, without hardware modification or architectural changes. We prototype StrongBox using an off-the-shelf Arm Mali GPU and perform an extensive evaluation. Results show that StrongBox successfully ensures GPU computation security with a low (4.70%–15.26%) overhead.}
}


@article{DBLP:journals/tdsc/CaiDX0LW24,
	author = {Yuxuan Cai and
                  Wenxiu Ding and
                  Yuxuan Xiao and
                  Zheng Yan and
                  Ximeng Liu and
                  Zhiguo Wan},
	title = {SecFed: {A} Secure and Efficient Federated Learning Based on Multi-Key
                  Homomorphic Encryption},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3817--3833},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3336977},
	doi = {10.1109/TDSC.2023.3336977},
	timestamp = {Tue, 24 Dec 2024 22:38:13 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/CaiDX0LW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is widely used in various industries because it effectively addresses the predicament of isolated data island. However, eavesdroppers is capable of inferring user privacy from the gradients or models transmitted in FL. Homomorphic Encryption (HE) can be applied in FL to protect sensitive data owing to its computability over ciphertexts. However, traditional HE as a single-key system cannot prevent dishonest users from intercepting and decrypting the ciphertexts from cooperative users in FL. Guaranteeing privacy and efficiency in this multi-user scenario is still a challenging target. In this article, we propose a secure and efficient Federated Learning scheme (SecFed) based on multi-key HE to preserve user privacy and delegate some operations to TEE to improve efficiency while ensuring security. Specifically, we design the first TEE-based multi-key HE cryptosystem (EMK-BFV) to support privacy-preserving FL and optimize operation efficiency. Furthermore, we provide an offline protection mechanism to ensure the normal operation of system with disconnected participants. Finally, we give their security proofs and show their efficiency and superiority through comprehensive simulations and comparisons with existing schemes. SecFed offers a 3x performance improvement over TEE-based scheme and a 2x performance improvement over HE-based solution.}
}


@article{DBLP:journals/tdsc/SolimanSSRM24,
	author = {Hazem M. Soliman and
                  Dusan Sovilj and
                  Geoff Salmon and
                  Mohan Rao and
                  Niranjan Mayya},
	title = {{RANK:} AI-Assisted End-to-End Architecture for Detecting Persistent
                  Attacks in Enterprise Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3834--3850},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3338136},
	doi = {10.1109/TDSC.2023.3338136},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SolimanSSRM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern government and enterprise networks are the target of sophisticated multi-step attacks called Advanced Persistent Threats (APTs), designed and carried out by expert adversaries. The prolonged nature of APTs results in overwhelming the analyst with an increasingly impractical number of alerts. As a result, the challenge of APT detection is ideal for automation through artificial intelligence (AI). In this paper, we propose the first, up to our knowledge, end-to-end AI-assisted architecture for detecting APTs – RANK. We propose advanced algorithms and solutions for four consecutive sub-problems: 1) alert templating and merging, 2) alert graph construction, 3) alert graph partitioning into incidents, and 4) incident scoring and prioritization. Additionally, we discuss the necessary optimizations and techniques enabling the system to operate in a real-time fashion. We evaluate our architecture against the 2000 DARPA, Mordor, as well as a large number of real-world datasets from enterprise networks. Extensive results are provided showing four orders-of-magnitude reduction in the amount of data to be reviewed, innovative extraction and security-aware scoring of incidents. The extracted incidents can be further used for downstream tasks. In our experiments where we have access to a portion of alert labels, we are able achieve 87% balanced accuracy.}
}


@article{DBLP:journals/tdsc/Quincozes00M24,
	author = {Silvio Ereno Quincozes and
                  C{\'{e}}lio Albuquerque and
                  Diego G. Passos and
                  Daniel Moss{\'{e}}},
	title = {{ERENO:} {A} Framework for Generating Realistic {IEC-61850} Intrusion
                  Detection Datasets for Smart Grids},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3851--3865},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3336857},
	doi = {10.1109/TDSC.2023.3336857},
	timestamp = {Tue, 15 Oct 2024 20:58:06 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Quincozes00M24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Connected and digital electricity substations based on IEC–61850 standards enable novel applications. On the other hand, such connectivity also creates an extended attack surface. Therefore, Intrusion Detection Systems (IDSs) have become an essential component of safeguarding substations from malicious activities. However, in contrast to traditional information technology systems, there is a serious lack of realistic data for training, testing, and evaluating IDSs in smart grid scenarios. Many existing substation IDSs rely on datasets from other contexts or on proprietary datasets that do not allow reproducibility, validation, or performance comparison with competing algorithms. To address this issue, we propose the Efficacious Reproducer Engine for Network Operations (ERENO) synthetic traffic generation framework based on the IEC–61850 standard specifications. As an additional contribution, and as a proof-of-concept, we create and make available a suite of realistic IEC–61850 datasets that model 8 use cases, namely traffic for seven common attacks and one for normal network traffic. Based on those datasets, we further evaluate how enriched features combining raw data from the substation can significantly improve intrusion detection performance. Our results suggest that it can improve F1-Score up to 47.22% for masquerade attacks.}
}


@article{DBLP:journals/tdsc/00020LLK24,
	author = {Bo Feng and
                  Meng Luo and
                  Changming Liu and
                  Long Lu and
                  Engin Kirda},
	title = {{AIM:} Automatic Interrupt Modeling for Dynamic Firmware Analysis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3866--3882},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3339569},
	doi = {10.1109/TDSC.2023.3339569},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/00020LLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The security of microcontrollers, which drive modern IoT and embedded devices, continues to raise major concerns. Within a microcontroller (MCU), the firmware is a monolithic piece of software that contains the whole software stack, whereas a variety of peripherals represent the hardware. As MCU firmware contains vulnerabilities, it is ideal to test firmware with off-the-shelf software testing techniques, such as dynamic symbolic execution and fuzzing. Nevertheless, no emulator can emulate the diverse MCU peripherals or execute/test the firmware. Specifically, the interrupt interface, among all I/O interfaces used by MCU peripherals, is extremely challenging to emulate. In this article, we present AIM—a generic, scalable, and hardware-independent dynamic firmware analysis framework that supports unemulated MCU peripherals by a novel interrupt modeling mechanism. AIM effectively and efficiently covers interrupt-dependent code in firmware by a novel, firmware-guided, Just-in-Time Interrupt Firing technique. We implemented our framework in angr and performed dynamic symbolic execution for eight real-world MCU firmware. According to testing results, our framework covered up to 11.2 times more interrupt-dependent code than state-of-the-art approaches while accomplishing several challenging goals not feasible previously. Finally, a comparison with a state-of-the-art firmware fuzzer demonstrates dynamic symbolic execution and fuzzing together can achieve better firmware testing coverage.}
}


@article{DBLP:journals/tdsc/Hu00L0024,
	author = {Shun Hu and
                  Ming Li and
                  Jiasi Weng and
                  Jia{-}Nan Liu and
                  Jian Weng and
                  Zhi Li},
	title = {IvyRedaction: Enabling Atomic, Consistent and Accountable Cross-Chain
                  Rewriting},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3883--3900},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3339675},
	doi = {10.1109/TDSC.2023.3339675},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Hu00L0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain rewriting has become widely explored for addressing data deletion requirements, such as error data deletion, space-saving, and compliance with the “right-to-be-forgotten” rule. However, existing approaches are inadequate for handling cross-chain redaction issues, in facing with the increasing need for inter-chain communication. In particular, transaction rewriting on a blockchain might have relevant effects on the states of other blockchains. The cross-chain interoperability results in inter-chain transactions with more complex dependency relations. The issues pose new challenges to achieve rewriting consistency, for example, ensuring the rewriting of related transactions when a transaction is being modified, and achieve atomic rewriting, whereby two cross-chain transactions must either all, or neither, be processed. This article introduces a cross-chain solution IvyRedaction, with an emphasis on customizing a decentralized intermediary for generating and maintaining global cross-chain redaction states and transaction dependencies. The article proposes a novel cross-chain state mapping method with rollback rules, as well as customized block structures and verification algorithms, to address the aforementioned issues. Proof-of-concept experiments are conducted to demonstrate the feasibility of the proposed framework.}
}


@article{DBLP:journals/tdsc/0002GZ0HJY024,
	author = {Hao Peng and
                  Shixin Guo and
                  Dandan Zhao and
                  Xuhong Zhang and
                  Jianmin Han and
                  Shouling Ji and
                  Xing Yang and
                  Ming Zhong},
	title = {TextCheater: {A} Query-Efficient Textual Adversarial Attack in the
                  Hard-Label Setting},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3901--3916},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3339802},
	doi = {10.1109/TDSC.2023.3339802},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/0002GZ0HJY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Designing a query-efficient attack strategy to generate high-quality adversarial examples under the hard-label black-box setting is a fundamental yet challenging problem, especially in natural language processing (NLP). The process of searching for adversarial examples has many uncertainties (e.g., an unknown impact on the target model's prediction of the added perturbation) when confidence scores cannot be accessed, which must be compensated for with a large number of queries. To address this issue, we propose TextCheater, a decision-based metaheuristic search method that performs a query-efficient textual adversarial attack task by prohibiting invalid searches. The strategies of multiple initialization points and Tabu search are also introduced to keep the search process from falling into a local optimum. We apply our approach to three state-of-the-art language models (i.e., BERT, wordLSTM, and wordCNN) across six benchmark datasets and eight real-world commercial sentiment analysis platforms/models. Furthermore, we evaluate the Robustly optimized BERT pretraining Approach (RoBERTa) and models that enhance their robustness by adversarial training on toxicity detection and text classification tasks. The results demonstrate that our method minimizes the number of queries required for crafting plausible adversarial text while outperforming existing attack methods in the attack success rate, fluency of output sentences, and similarity between the original text and its adversary.}
}


@article{DBLP:journals/tdsc/TianWMGS024,
	author = {Guohua Tian and
                  Jianghong Wei and
                  Meixia Miao and
                  Fuchun Guo and
                  Willy Susilo and
                  Xiaofeng Chen},
	title = {Blockchain-Based Compact Verifiable Data Streaming With Self-Auditing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3917--3930},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3340208},
	doi = {10.1109/TDSC.2023.3340208},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/TianWMGS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The primitive of verifiable data streaming (VDS) provides a secure data outsourcing solution for resource-constrained users, that is, they can stream their continuously-generated data items to untrusted servers while enabling publicly verifiable query and update. However, existing VDS schemes either require the server to store the authentication tags of all data items to support data query and auditing, or bind all data items into a constant-size tag to achieve optimal storage on the server side, but cannot achieve public auditing. To close this gap, in this article, we first design a novel authentication data structure, dubbed retrievable homomorphic verifiable tags (RHVTs), which allows users to aggregate the authentication tags of all data items into a constant-size tag, and enables them to retrieve the original tags from the aggregated tag when necessary. Based on this, we propose a compact verifiable and auditable data streaming (CVADS) scheme, which adopts a single-level authentication mechanism to achieve more efficient data append and update, as well as optimal storage and public auditing. For better robustness and performance, we introduce a nested dual-level authentication mechanism and propose a blockchain-based CVADS (BCVADS) scheme to achieve a distributed CVADS with self-auditing. Finally, we prove the security of our schemes in the random oracle model and demonstrate their practicality through a visual performance evaluation.}
}


@article{DBLP:journals/tdsc/DuanLLCS00W24,
	author = {Chenxin Duan and
                  Sainan Li and
                  Hai Lin and
                  Wenqi Chen and
                  Guanglei Song and
                  Chenglong Li and
                  Jiahai Yang and
                  Zhiliang Wang},
	title = {IoTa: Fine-Grained Traffic Monitoring for IoT Devices via Fully Packet-Level
                  Models},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3931--3947},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3340563},
	doi = {10.1109/TDSC.2023.3340563},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/DuanLLCS00W24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With Internet-of-Things (IoT) devices gaining popularity, dedicated monitoring systems which accurately detect intrusion traffic for them are in high demand. Existing methods mainly use statistical spatial-temporal traffic features and machine learning models. Their practicality has been limited due to the lack of detection ability for stealthy and tricky attacks, diagnostic utility and long-term performance. To address these problems and motivated by the simplicity of mini IoT devices, we propose to construct fully packet-level models to profile traffic patterns for IoT devices by constructing automaton for short flow and long flow, where the length and direction of each packet are the representative features. We apply these fine-grained models to design and develop a traffic monitoring system, namely IoTa, to detect intrusion traffic for IoT devices. IoTa matches the ongoing traffic with patterns extracted from normal traffic traces. With visible and interactive traffic profiles, IoTa can generate interpretable alerts and is available for long-term use under reasonable human efforts. Evaluations on dozens of common IoT devices show that IoTa can achieve excellent detection accuracy (nearly perfect recalls and always over 0.999 precisions) for various intrusion traffic covering the complete kill chains. Incorrect detection results can be compensated for by error recovery mechanisms and the understandable alert context can be used by the operator to enhance the system. The diagnostic utility and little alert weariness are recognized by the experienced operators.}
}


@article{DBLP:journals/tdsc/HutzelmannMPP24,
	author = {Thomas Hutzelmann and
                  Dominik Mauksch and
                  Ana Petrovska and
                  Alexander Pretschner},
	title = {Generation of Tailored and Confined Datasets for {IDS} Evaluation
                  in Cyber-Physical Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3948--3962},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3341211},
	doi = {10.1109/TDSC.2023.3341211},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/HutzelmannMPP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The state-of-the-art evaluation of an Intrusion Detection System (IDS) relies on benchmark datasets composed of the regular system's and potential attackers’ behavior. The datasets are collected once and independently of the IDS under analysis. This paper questions this practice by introducing a methodology to elicit particularly challenging samples to benchmark a given IDS. In detail, we propose (1) six fitness functions quantifying the suitability of individual samples, particularly tailored for safety-critical cyber-physical systems, (2) a scenario-based methodology for attacks on networks to systematically deduce optimal samples in addition to previous datasets, and (3) a respective extension of the standard IDS evaluation methodology. We applied our methodology to two network-based IDSs defending an advanced driver assistance system. Our results indicate that different IDSs show strongly differing characteristics in their edge case classifications and that the original datasets used for evaluation do not include such challenging behavior. In the worst case, this causes a critical undetected attack, as we document for one IDS. Our findings highlight the need to tailor benchmark datasets to the individual IDS in a final evaluation step. Especially the manual investigation of selected samples from edge case classifications by domain experts is vital for assessing the IDSs.}
}


@article{DBLP:journals/tdsc/AbdukhamidovAWC24,
	author = {Eldor Abdukhamidov and
                  Mohammed Abuhamad and
                  Simon S. Woo and
                  Eric Chan{-}Tin and
                  Tamer Abuhmed},
	title = {Hardening Interpretable Deep Learning Systems: Investigating Adversarial
                  Threats and Defenses},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3963--3976},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3341090},
	doi = {10.1109/TDSC.2023.3341090},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/AbdukhamidovAWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning methods have gained increasing attention in various applications due to their outstanding performance. For exploring how this high performance relates to the proper use of data artifacts and the accurate problem formulation of a given task, interpretation models have become a crucial component in developing deep learning-based systems. Interpretation models enable the understanding of the inner workings of deep learning models and offer a sense of security in detecting the misuse of artifacts in the input data. Similar to prediction models, interpretation models are also susceptible to adversarial inputs. This work introduces two attacks, AdvEdge and AdvEdge^{+}\n, which deceive both the target deep learning model and the coupled interpretation model. We assess the effectiveness of proposed attacks against four deep learning model architectures coupled with four interpretation models that represent different categories of interpretation models. Our experiments include the implementation of attacks using various attack frameworks. We also explore the attack resilience against three general defense mechanisms and potential countermeasures. Our analysis shows the effectiveness of our attacks in terms of deceiving the deep learning models and their interpreters, and highlights insights to improve and circumvent the attacks.}
}


@article{DBLP:journals/tdsc/0004LZ0GH24,
	author = {Jie Cui and
                  Yatao Li and
                  Qingyang Zhang and
                  Hong Zhong and
                  Chengjie Gu and
                  Debiao He},
	title = {DSChain: {A} Blockchain System for Complete Lifecycle Security of
                  Data in Internet of Things},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3977--3993},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3337093},
	doi = {10.1109/TDSC.2023.3337093},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/0004LZ0GH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There is a growing concern about the complete lifecycle security of data in Internet of Things (IoT). This may cause privacy and trust problems for users regarding data sources, data storage, and access control for data sharing. Blockchain is a valuable solution to the above problems through distributed ledger technology, and it has been widely applied in various fields such as public services, finance, and IoT. However, the data in IoT are characterized by a large quantity, large capacity, and timely response, and existing blockchain systems only partially resolve them for data security and performance. We propose DSChain for IoT data security to address the challenges mentioned above. Our system uses a certificateless signature to ensure a trusted data source and public auditing to ensure the integrity of stored data while using ciphertext-policy attribute-based encryption to control access to shared data. Moreover, we propose a packaging mechanism based on the Merkle Hash Tree that effectively improves system performance. We implement the DSChain and provide a detailed analysis of performance and security. The experimental results indicate that DSChain can achieve approximately 1035 transactions per second on a single peer and is scalable.}
}


@article{DBLP:journals/tdsc/ZhangCL0Y24,
	author = {Jiansong Zhang and
                  Kejiang Chen and
                  Weixiang Li and
                  Weiming Zhang and
                  Nenghai Yu},
	title = {Steganography With Generated Images: Leveraging Volatility to Enhance
                  Security},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {3994--4005},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3341427},
	doi = {10.1109/TDSC.2023.3341427},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangCL0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of generative AI applications has revolutionized the data environment for steganography, providing a new source of steganographic cover. However, existing generative data-based steganography methods typically require white-box access, rendering them unsuitable for black-box generative models. To overcome this limitation, we propose a novel steganography method for generated images, which leverages the volatility of generative models and is applicable in black-box scenarios. The volatility of generative models refers to the ability to generate a series of images with slight variations by fine-tuning the input parameters of the model. These generated images exhibit varying degrees of volatility in different areas. To resist steganalysis, we mask steganographic modifications by confusing them with the inherent volatility of the model. Specifically, by modeling distributions of generated pixels and estimating the parameters of the distributions, the occurrence probabilities of generated pixels can be obtained, which serve as an effective measure for steganographic modification probabilities to render stego images as indistinguishable as possible from the images producible by the model. Moreover, we further combine it with existing costs to develop a more comprehensive steganographic algorithm. Experimental results show that the proposed method significantly outperforms baseline and comparative methods in resisting both feature-based and CNN-based steganalyzers.}
}


@article{DBLP:journals/tdsc/SongL0F0024,
	author = {Fuyuan Song and
                  Jinwen Liang and
                  Chuan Zhang and
                  Zhangjie Fu and
                  Zheng Qin and
                  Song Guo},
	title = {Achieving Efficient and Privacy-Preserving Location-Based Task Recommendation
                  in Spatial Crowdsourcing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4006--4023},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3342239},
	doi = {10.1109/TDSC.2023.3342239},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SongL0F0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In spatial crowdsourcing, location-based task recommendation schemes are widely used to match appropriate workers in desired geographic areas with relevant tasks from data requesters. To ensure data confidentiality, various privacy-preserving location-based task recommendation schemes have been proposed, as cloud servers behave semi-honestly. However, existing schemes reveal access patterns, and the dimension of the geographic query increases significantly when additional information beyond locations is used to filter appropriate workers. To address the above challenges, this article proposes two efficient and privacy-preserving location-based task recommendation (EPTR) schemes that support high-dimensional queries and access pattern privacy protection. First, we propose a basic EPTR scheme (EPTR-I) that utilizes randomizable matrix multiplication and public position intersection test (PPIT) to achieve linear search complexity and full access pattern privacy protection. Then, we explore the trade-off between efficiency and security and develop a tree-based EPTR scheme (EPTR-II) to achieve sub-linear search complexity. Security analysis demonstrates that both schemes protect the confidentiality of worker locations, requester queries, and query results and achieve different security properties on access pattern assurance. Extensive performance evaluation shows that both EPTR schemes are efficient in terms of computational cost, with EPTR-II being\n10\n3\n×\nfaster than the state-of-the-art scheme in task recommendation.}
}


@article{DBLP:journals/tdsc/Rafiee24,
	author = {Mojtaba Rafiee},
	title = {Multi-Adjustable Join Schemes With Adaptive Indistinguishably Security},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4024--4034},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3343872},
	doi = {10.1109/TDSC.2023.3343872},
	timestamp = {Tue, 15 Oct 2024 20:58:06 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Rafiee24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A multi-adjustable join (\\text{M-Adjoin}) scheme [Khazaei-Rafiee, IEEE TDSC 2020], a generalization of \\text{Adjoin} scheme [Popa-Zeldovich, MIT CSAIL TR 2012], is a symmetric-key primitive that enables a user to securely outsource his database to an external server, and later to issue join queries for a list of columns. In [Rafiee-Khazaei, IEEE TDSC 2021], based on the previously defined security notions for \\text{Adjoin} [Mironov-Segev-Shahaf, TCC 2017], several security notions for \\text{M-Adjoin} were proposed and their relationships were investigated. Constructing an \\text{M-Adjoin} with indistinguishability security against adaptive adversary has remained a challenging problem so far. In this paper, we introduce two \\text{M-Adjoin} constructions to achieve this strong security notion in the random oracle model. We prove the security of our constructions under Decisional Diffie-Hellman assumption in \\mathbb {G}_{1} (DDH1) in the bilinear groups. Compared with previous constructions, despite having a higher security level, the computation and storage overheads do not increase.}
}


@article{DBLP:journals/tdsc/ZhangGF024,
	author = {Zhenxiao Zhang and
                  Yuanxiong Guo and
                  Yuguang Fang and
                  Yanmin Gong},
	title = {Communication and Energy Efficient Wireless Federated Learning With
                  Intrinsic Privacy},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4035--4047},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3341788},
	doi = {10.1109/TDSC.2023.3341788},
	timestamp = {Tue, 22 Oct 2024 21:09:44 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangGF024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is a collaborative learning framework that enables edge devices to collaboratively learn a global model while keeping raw data locally. Although FL avoids leaking direct information from local datasets, sensitive information can still be inferred from the shared models. To address the privacy issue in FL, differential privacy (DP) mechanisms are leveraged to provide formal privacy guarantee. However, when deploying FL at the wireless edge with over-the-air computation, ensuring client-level DP faces significant challenges. In this paper, we propose a novel wireless FL scheme called private federated edge learning with sparsification (PFELS) to provide client-level DP guarantee with intrinsic channel noise while reducing communication and energy overhead and improving model accuracy. The key idea of PFELS is for each device to first compress its model update and then adaptively design the transmit power of the compressed model update according to the wireless channel status without any artificial noise addition. We provide a privacy analysis for PFELS and prove the convergence of PFELS under general non-convex and non-IID settings. Experimental results show that compared with prior work, PFELS can improve the accuracy with the same DP guarantee and save communication and energy costs simultaneously.}
}


@article{DBLP:journals/tdsc/FarrellB00DDS0M24,
	author = {Marie Farrell and
                  Matthew Bradbury and
                  Rafael C. Cardoso and
                  Michael Fisher and
                  Louise A. Dennis and
                  Clare Dixon and
                  Al Tariq Sheik and
                  Hu Yuan and
                  Carsten Maple},
	title = {Security-Minded Verification of Cooperative Awareness Messages},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4048--4065},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3345543},
	doi = {10.1109/TDSC.2023.3345543},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/FarrellB00DDS0M24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous robotic systems systems are both safety- and security-critical, since a breach in system security may impact safety. In such critical systems, formal verification is used to model the system and verify that it obeys specific functional and safety properties. Independently, threat modeling is used to analyse and manage the cyber security threats that such systems may encounter. Both verification and threat analysis serve the purpose of ensuring that the system will be reliable, albeit from differing perspectives. In prior work, we argued that these analyses should be used to inform one another and, in this paper, we extend our previously defined methodology for security-minded verification by incorporating runtime verification. To illustrate our approach, we analyse an algorithm for sending Cooperative Awareness Messages between autonomous vehicles. Our analysis centres on identifying STRIDE security threats. We show how these can be formalised, and subsequently verified, using a combination of formal tools for static aspects, namely Promela/SPIN and Dafny, and generate runtime monitors for dynamic verification. Our approach allows us to focus our verification effort on those security properties that are particularly important and to consider safety and security in tandem, both statically and at runtime.}
}


@article{DBLP:journals/tdsc/BaeeSBFP24,
	author = {Mir Ali Rezazadeh Baee and
                  Leonie Simpson and
                  Xavier Boyen and
                  Ernest Foo and
                  Josef Pieprzyk},
	title = {A Provably Secure and Efficient Cryptographic-Key Update Protocol
                  for Connected Vehicles},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4066--4083},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3345406},
	doi = {10.1109/TDSC.2023.3345406},
	timestamp = {Sun, 19 Jan 2025 13:48:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/BaeeSBFP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless broadcast transmission technology enables vehicles to communicate with other nearby vehicles and with nearby fixed equipment. Vehicles and equipment within transmission range establish a self-organizing network called Vehicular Ad-hoc Network (VANET). The communication in VANETs is vulnerable to message manipulation attacks. Thus, mechanisms should be applied to ensure both the authenticity and integrity of the data broadcast. Any cryptographic technique employed for authentication requires the use of a cryptographic key, and mechanisms to restore the system quickly when either long-term and short-term cryptographic keying material are leaked or expired. Such mechanisms must be carefully designed to satisfy both perfect-forward-secrecy and security against known-key attacks. To achieve this, there should be no direct dependencies among keying material. Unfortunately, many existing proposals for authentication are not fully effective in VANETs, since many of them do not take a key-management mechanism into consideration or they fail to satisfy the requirements for secure key-update. In this paper, we first present a case study demonstrating that dependency among keying material is an exploitable vulnerability that violates perfect-forward-secrecy, and results in known-key attacks and message forgery attacks. Second, we propose a new cryptographic-key update protocol that consists of two sub-protocols: a long-term-key update protocol (for updating the long-term cryptographic keying material) and a short-term-key update protocol (for session-key establishment). Our scheme is accompanied by both security and efficiency analysis: we provide a formal security proof and demonstrate efficiency by conducting extensive performance analysis. This is compared with the security and efficiency of existing schemes in public literature.}
}


@article{DBLP:journals/tdsc/RonSZBM24,
	author = {Javier Ron and
                  C{\'{e}}sar Soto{-}Valero and
                  Long Zhang and
                  Benoit Baudry and
                  Martin Monperrus},
	title = {Highly Available Blockchain Nodes With N-Version Design},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4084--4097},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3346195},
	doi = {10.1109/TDSC.2023.3346195},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/RonSZBM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As all software, blockchain nodes are exposed to faults in their underlying execution stack. Unstable execution environments can disrupt the availability of blockchain nodes’ interfaces, resulting in downtime for users. This article introduces the concept of N-Version Blockchain nodes. This new type of node relies on simultaneous execution of different implementations of the same blockchain protocol, in the line of Avizienis’ N-Version programming vision. We design and implement an N-Version blockchain node prototype in the context of Ethereum, called N-ETH. We show that N-ETH is able to mitigate the effects of unstable execution environments and significantly enhance availability under environment faults. To simulate unstable execution environments, we perform fault injection at the system-call level. Our results show that existing Ethereum node implementations behave asymmetrically under identical instability scenarios. N-ETH leverages this asymmetric behavior available in the diverse implementations of Ethereum nodes to provide increased availability, even under our most aggressive fault-injection strategies. We are the first to validate the relevance of N-Version design in the domain of blockchain infrastructure. From an industrial perspective, our results are of utmost importance for businesses operating blockchain nodes, including Google, ConsenSys, and many other major blockchain companies.}
}


@article{DBLP:journals/tdsc/KangYKD0L24,
	author = {Xiangping Kang and
                  Guoxian Yu and
                  Lanju Kong and
                  Carlotta Domeniconi and
                  Xiangliang Zhang and
                  Qingzhong Li},
	title = {FedTA: Federated Worthy Task Assignment for Crowd Workers},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4098--4109},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3346183},
	doi = {10.1109/TDSC.2023.3346183},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/KangYKD0L24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourcing is a promising computing paradigm for processing computer-hard tasks by harnessing human intelligence. How to protect online workers’ privacy is a hindrance for deploying crowdsourcing in the real world. Attempts have been made to address this issue by injecting noise or encrypting sensitive data, which cause quality loss and/or heavy computation and communication load. In this paper, we propose an approach, called FedTA (Federated Worthy Task Assignment for Crowd Workers), to protect a crowd worker's private data while ensuring quality. FedTA trains a client model based on the private data and annotations owned by a worker and uploads client models to aggregate the server model, without leaking the privacy of task data. To account for the varying task distributions (i.e., non-i.i.d.) and error-prone annotations of tasks, it leverages the feature similarity and semantic similarity separately derived from client and server models on local tasks, to quantify the quality of annotations and clients. Based on those, it further introduces a task assignment strategy to notify the clients which tasks are worthy and suitable for annotations. This strategy can incrementally improve the performance of client and server models. At the same time, it disregards the unworthy tasks to save the budget and to avoid their negative impact. Experimental results show that FedTA can complete secure crowdsourcing projects with high quality and low budget.}
}


@article{DBLP:journals/tdsc/LeeR24,
	author = {Hong Joo Lee and
                  Yong Man Ro},
	title = {Defending Video Recognition Model Against Adversarial Perturbations
                  via Defense Patterns},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4110--4121},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3346064},
	doi = {10.1109/TDSC.2023.3346064},
	timestamp = {Fri, 15 Nov 2024 11:23:31 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LeeR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Neural Networks (DNNs) have been widely successful in various domains, but they are vulnerable to adversarial attacks. Recent studies have also demonstrated that video recognition models are susceptible to adversarial perturbations, but the existing defense strategies in the image domain do not transfer well to the video domain due to the lack of considering temporal development and require a high computational cost for training video recognition models. This article, first, investigates the temporal vulnerability of video recognition models by quantifying the effect of temporal perturbations on the model's performance. Based on these investigations, we propose Defense Patterns (DPs) that can effectively protect video recognition models by adding them to the input video frames. The DPs are generated on top of a pre-trained model, eliminating the need for retraining or fine-tuning, which significantly reduces the computational cost. Experimental results on two benchmark datasets and various action recognition models demonstrate the effectiveness of the proposed method in enhancing the robustness of video recognition models.}
}


@article{DBLP:journals/tdsc/ZhengL24,
	author = {Tianhang Zheng and
                  Baochun Li},
	title = {{CMI:} Client-Targeted Membership Inference in Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4122--4132},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3346692},
	doi = {10.1109/TDSC.2023.3346692},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhengL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Membership inference is a popular benchmark attack to evaluate the privacy risk of a machine learning model or a learning scheme. However, in federated learning, membership inference is still under-explored due to several issues. For instance, some assumptions in prior works may not be practical in federated learning. Most existing membership inference methods stand on those impractical assumptions or lack generalization ability, which may misestimate the privacy risk. To address these issues, we propose CMI, an attack framework armed by a targeted poisoning method, to conduct a critical evaluation of client-targeted membership inference in federated learning. Under CMI, we consider a strong adversary, refine the prior impractical assumptions, and apply simple but generalizable attack methods. The evaluation results on multiple datasets demonstrate the efficacy of CMI under identically independently distributed (i.i.d.) and non-i.i.d. settings. In terms of the defenses, although differetially private stochatic gradient descent (DP-SGD) is effective under the i.i.d. setting, it does not provide satisfactory protection under label-biased non-i.i.d. settings. Thus, we propose RR-Label, a modified random response algorithm, to defend against membership inference. Compared to DP-SGD and Random Response Top-k (RRTop-k), RR-Label enables a better trade-off between model utility and defensive performance under label-biased non-i.i.d. settings.}
}


@article{DBLP:journals/tdsc/SandbornSWFDWL24,
	author = {Michael Sandborn and
                  Zach Stoebner and
                  Westley Weimer and
                  Stephanie Forrest and
                  Ryan E. Dougherty and
                  Jules White and
                  Kevin Leach},
	title = {Reducing Malware Analysis Overhead With Coverings},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4133--4146},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3346328},
	doi = {10.1109/TDSC.2023.3346328},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/SandbornSWFDWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There is a substantial and growing body of malware samples that evade automated analysis and detection tools. Malware may measure fingerprints (“artifacts”) of the underlying analysis tool or environment, and change their behavior when such artifacts are detected. While analysis tools can mitigate artifacts to reduce exposure, such concealment is expensive and limits scalable automated malware analysis. However, not every sample checks for every type of artifact—analysis efficiency can be improved by mitigating only those artifacts most likely to be used by a sample. Using that insight, we propose Mimosa, a system that identifies a small set of “covering” configurations that collectively and efficiently defeat most malware samples in a corpus. Mimosa identifies a set of configurations that maximize analysis throughput and detection accuracy while minimizing manual effort, enabling scalable automation for analyzing stealthy malware. We evaluate our approach against a benchmark of 1535 meticulously labeled stealthy malware samples. We further test our approach on an additional set of 1221 stealthy malware samples and successfully analyze nearly 99% of them using only 2 VM backends. Mimosa provides a practical, tunable method for efficiently deploying malware analysis resources.}
}


@article{DBLP:journals/tdsc/Wu0WZ00Y24,
	author = {Siwei Wu and
                  Zhou Yu and
                  Dabao Wang and
                  Yajin Zhou and
                  Lei Wu and
                  Haoyu Wang and
                  Xingliang Yuan},
	title = {DeFiRanger: Detecting DeFi Price Manipulation Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4147--4161},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3346888},
	doi = {10.1109/TDSC.2023.3346888},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Wu0WZ00Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid growth of Decentralized Finance (DeFi) boosts the blockchain ecosystem. At the same time, attacks on DeFi applications (apps) are increasing. However, to the best of our knowledge, existing smart contract vulnerability detection tools cannot directly detect DeFi attacks. That's because they lack the capability to recover and understand high-level DeFi semantics, e.g., a user trades a token pair X and Y in a Decentralized EXchange (DEX). In this work, we focus on the detection of two new types of price manipulation attacks. To this end, we propose a platform-independent method to identify high-level DeFi semantics. Specifically, we first construct the Cash Flow Tree (CFT) from a raw transaction and then lifting the low-level semantics to high-level ones, including five advanced DeFi actions. Finally, we use patterns expressed with the recovered DeFi semantics to detect price manipulation attacks. We implemented a prototype named DeFiRanger that detected 14 zero-day security incidents. These findings were reported to affected parties or/and the community for the first time. Furthermore, the backtest experiment discovered 15 unknown historical security incidents. We further performed an attack analysis to shed light on the root causes of vulnerabilities incurring price manipulation attacks.}
}


@article{DBLP:journals/tdsc/0005LSLC24,
	author = {Ning Lu and
                  Mingxi Liu and
                  Wenbo Shi and
                  Ximeng Liu and
                  Kim{-}Kwang Raymond Choo},
	title = {SG-Audit: An Efficient and Robust Cloud Auditing Scheme for Smart
                  Grid},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4162--4179},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3347001},
	doi = {10.1109/TDSC.2023.3347001},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/0005LSLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud auditing allows users to leverage digital signature evidences to undertake remote data verification and consequently determine the integrity of their data stored in the cloud. While there are many cloud auditing schemes proposed for cloud services, deployments on large scale smart grid (SG) are known to be challenging in practice, for example in terms of inefficiency and lack of robustness. In this article, we propose an efficient and robust cloud auditing scheme for SG (hereafter referred to as SG-Audit). Specifically, we utilize mobile edge computing (served as proxy signer) to offload the signature computation loads incurred by smart meters (SMs), as well as devising an efficient proxy signer recommendation strategy to ensure each SM obtains high quality service, a scalable index structure to reduce the signature evidence access time during data verification, and a deduplication and sampling based challenge data index generation strategy to narrow down the verification scope. Moreover, we also define three strategic threat scenarios supported by SG-Audit, and further devise a secure cloud auditing protocol to improve robustness. Through rigorous mathematical analysis and extensive experiments, we demonstrate that SG-Audit achieves increased auditing efficiency (by about 42% on average) in comparison to prior work.}
}


@article{DBLP:journals/tdsc/AlexJP24,
	author = {Sona Alex and
                  Dhanaraj Kakkanattu Jagalchandran and
                  Deepthi P. Pattathil},
	title = {Privacy-Preserving and Energy-Saving Random Forest-Based Disease Detection
                  Framework for Green Internet of Things in Mobile Healthcare Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4180--4192},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3347342},
	doi = {10.1109/TDSC.2023.3347342},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/AlexJP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The privacy of medical data and resource restrictions in the Internet of Things (IoT) nodes prohibit medical users from utilizing disease detection (DD) services offered by the health cloud in the mobile healthcare network (MHN). Also, health clouds may need the DD procedures to be private. Therefore, the essential requirements for MHN DD services are (i) performing accurate and fast DD without jeopardizing the privacy of health clouds and medical users and (ii) reducing the computational and transmission overhead (energy-consumption) of the green IoT devices while performing privacy-preserving DD. The outsourced privacy-preserving DD is available in the literature based on popular tree-based machine learning schemes such as a random forest. However, these schemes utilize energy-hungry public-key encryption schemes in IoT nodes at medical users for privacy preservation. This work proposes an energy-efficient, fully homomorphic modified Rivest scheme (FHMRS) for the proposed privacy-preserving random forest classification (PRFC). A secure integer comparison protocol is also developed for reducing processing time and energy consumption for users while performing outsourced PRFC. The implementation results and security analysis show that the proposed schemes guarantee better energy efficiency for MHN green IoT devices without compromising privacy than the existing tree-based schemes.}
}


@article{DBLP:journals/tdsc/YeLZZSJ24,
	author = {Zipeng Ye and
                  Wenjian Luo and
                  Ruizhuo Zhang and
                  Hongwei Zhang and
                  Yuhui Shi and
                  Yan Jia},
	title = {An Evolutionary Attack for Revealing Training Data of DNNs With Higher
                  Feature Fidelity},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4193--4205},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3347225},
	doi = {10.1109/TDSC.2023.3347225},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YeLZZSJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model inversion attacks aim to reveal information about sensitive training data of AI models, which may lead to serious privacy leakage. However, existing attack methods have limitations in reconstructing training data with higher feature fidelity. In this article, we propose an evolutionary model inversion attack approach (EvoMI) and empirically demonstrate that combined with the systematic search in the multi-degree-of-freedom latent space of the generative model, the simple use of an evolutionary algorithm can effectively improve the attack performance. Concretely, at first, we search for latent vectors which can generate images close to the attack target in the latent space with low-degree of freedom. Generally, the low-freedom constraint will reduce the probability of getting a local optima compared to existing methods that directly search for latent vectors in the high-freedom space. Consequently, we introduce a mutation operation to expand the search domain, thus further reduce the possibility of obtaining a local optima. Finally, we treat the searched latent vectors as the initial values of the post-processing and relax the constraint to further optimize the latent vectors in a higher-freedom space. Our proposed method is conceptually simple and easy to implement, yet it achieves substantial improvements and outperforms the state-of-the-art methods significantly.}
}


@article{DBLP:journals/tdsc/WeiMMQ00B024,
	author = {Yang Wei and
                  Zhuo Ma and
                  Zhuoran Ma and
                  Zhan Qin and
                  Yang Liu and
                  Bin Xiao and
                  Xiuli Bi and
                  Jianfeng Ma},
	title = {Effectively Improving Data Diversity of Substitute Training for Data-Free
                  Black-Box Attack},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4206--4219},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3347753},
	doi = {10.1109/TDSC.2023.3347753},
	timestamp = {Thu, 13 Feb 2025 09:22:27 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WeiMMQ00B024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent substitute training methods have utilized the concept of Generative Adversarial Networks (GANs) to implement data-free black-box attacks. Specifically, in designing the generators, the substitute training methods use a similar structure to the generators in GANs. However, this design approach ignores the potential situation that the generators in GANs operate under real data supervision, while the generators in substitute training methods lack such supervision. This difference in data-supervised conditions constrain the diversity of data generated by the substitute training methods, resulting in inadequate data to support effective training of the substitute model. This impacts the substitute model's ability to attack the target model further. Consequently, to solve the above issues, we propose three strategies to improve the attack success rates. For the generator, we first propose a dense projection space that projects the input noise into various latent feature spaces to diversify feature information. Then, we introduce a novel disguised natural color mode. This mode improves information exchange between the generator's output layer and previous layers, allowing for more diverse generated data. Besides, we present a regularization method for the substitute model, called noise-based balanced learning, to prevent the potential risk of overfitting due to the lack of diversity of the generated data. In the experimental analysis, extensive experiments are conducted to validate the effectiveness of these proposed strategies.}
}


@article{DBLP:journals/tdsc/001000024,
	author = {Xiaoyu Zhang and
                  Shen Lin and
                  Chao Chen and
                  Xiaofeng Chen},
	title = {{MODA:} Model Ownership Deprivation Attack in Asynchronous Federated
                  Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4220--4235},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3348204},
	doi = {10.1109/TDSC.2023.3348204},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/001000024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Training a deep learning model from scratch requires a great deal of available labeled data, computation resources, and expert knowledge. Thus, the time-consuming and complicated learning procedure catapulted the trained model to valuable intellectual property (IP), spurring interest from attackers in model copyright infringement and stealing. Recently, a new defense approach leverages watermarking techniques to inject watermarks into the training procedure and verify model ownership when necessary. To our best knowledge, there is no research work on model ownership stealing attacks in federated learning, and the existing defense or mitigation methods can not be directly used for federated learning scenarios. In this article, we introduce watermarking neural networks in asynchronous federated learning and propose a novel model privacy attack, dubbed model ownership deprivation attack (MODA). MODA is launched by an inside adversarial participant, targeting occupying and depriving the remaining participants’ (victims) copyright to achieve his maximum profit. The extensive experimental results on five benchmark datasets (MNIST, Fashion-MNIST, GTSRB, SVHN, CIFAR10) show that MODA is highly effective in a two-participant learning scenario with a minor impact on model's performance. When extending MODA into multiple participants scenario, MODA still maintains high attack success rate and classification accuracy. Compared to the state-of-the-art works, MODA has a higher attack success rate than the black-box solution and comparable efficacy with the approach in the white-box scenario.}
}


@article{DBLP:journals/tdsc/XuBW024,
	author = {Yuan Xu and
                  Yungang Bao and
                  Sa Wang and
                  Tianwei Zhang},
	title = {Function Interaction Risks in Robot Apps: Analysis and Policy-Based
                  Solution},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4236--4253},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3348772},
	doi = {10.1109/TDSC.2023.3348772},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XuBW024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robot apps are becoming more automated, complex and diverse. An app usually consists of many functions, interacting with each other and the environment. This allows robots to conduct various tasks. However, it also opens a new door for cyber attacks: adversaries can leverage these interactions to threaten the safety of robot operations. Unfortunately, this issue is rarely explored in past works. We present the first systematic investigation about the function interactions in common robot apps. First, we disclose the potential risks and damages caused by malicious interactions. We introduce a comprehensive graph to model the function interactions in robot apps by analyzing 3,100 packages from the Robot Operating System (ROS) platform. From this graph, we identify and categorize three types of interaction risks. Second, we propose novel methodologies to detect and mitigate these risks and protect the operations of robot apps. We introduce security policies for each type of risks, and design coordination nodes to enforce the policies and regulate the interactions. We conduct extensive experiments on 110 robot apps from the ROS platform and two complex apps (Baidu Apollo and Autoware) widely adopted in industry. Evaluation results showed our methodologies can correctly identify and mitigate all potential risks.}
}


@article{DBLP:journals/tdsc/LeeKKO24,
	author = {Seunghwa Lee and
                  Hankyung Ko and
                  Jihye Kim and
                  Hyunok Oh},
	title = {vCNN: Verifiable Convolutional Neural Network Based on zk-SNARKs},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4254--4270},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3348760},
	doi = {10.1109/TDSC.2023.3348760},
	timestamp = {Thu, 12 Dec 2024 08:59:05 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LeeKKO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is becoming important for the client to be able to check whether the AI inference services have been correctly calculated. Since the weight values in a CNN model are assets of service providers, the client should be able to check the correctness of the result without them. The Zero-knowledge Succinct Non-interactive Argument of Knowledge (zk-SNARK) allows verifying the result without input and weight values. However, the proving time in zk-SNARK is too slow to be applied to real AI applications. This article proposes a new efficient verifiable convolutional neural network (vCNN) framework that greatly accelerates the proving performance. We introduce a new efficient relation representation for convolution equations, reducing the proving complexity of convolution from O(ln) to O(l+n) compared to existing zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) approaches, where l and n denote the size of the kernel and the data in CNNs. Experimental results show that the proposed vCNN improves proving performance by 20-fold for a simple MNIST and 18,000-fold for VGG16. The security of the proposed scheme is formally proven.}
}


@article{DBLP:journals/tdsc/0008LC0SL24,
	author = {Ziming Zhao and
                  Zhuotao Liu and
                  Huan Chen and
                  Fan Zhang and
                  Zhuoxue Song and
                  Zhaoxuan Li},
	title = {Effective DDoS Mitigation via ML-Driven In-Network Traffic Shaping},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4271--4289},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3349180},
	doi = {10.1109/TDSC.2023.3349180},
	timestamp = {Wed, 06 Nov 2024 22:19:02 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/0008LC0SL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Defending against Distributed Denial of Service (DDoS) attacks is a fundamental problem in the Internet. Over the past few decades, the research and industry communities have proposed a variety of solutions, from adding incremental capabilities to the existing Internet routing stack, to clean-slate future Internet architectures, and to widely deployed commercial DDoS prevention services. Yet a recent interview with over 100 security practitioners in multiple sectors reveals that existing solutions are still insufficient against, due to either unenforceable protocol deployment or non-comprehensive traffic filters. This seemingly endless arms race with attackers probably means that we need a fundamental paradigm shift. In this paper, we propose a new DDoS prevention paradigm named preference-driven and in-network enforced traffic shaping, aiming to explore the novel DDoS prevention norms that focus on delivering victim-preferred traffic rather than consistently chasing after the DDoS attacks. Towards this end, we propose\nDFNet\n, a novel DDoS prevention system that provides reliable delivery of victim-preferred traffic without full knowledge of DDoS attacks. At a very high level, the core innovative design of\nDFNet\nembraces the advances in Machine Learning (ML) and new network dataplane primitives, by encoding the victim’s traffic preference (in the form of complex ML models) into dataplane packet scheduling algorithms such that the victim-preferred traffic is forwarded with priority at line-speed, regardless of the attacker strategy. We implement a prototype of\nDFNet\nin 11,560 lines of code, and extensively evaluate it on our testbed. The results show that a single instance of\nDFNet\nDFNet can forward 99.93% of victim-desired traffic when facing previously unseen attacks, while imposing less than 0.1% forwarding overhead on a dataplane with 80 Gbps upstream links and a 40 Gbps bottleneck.}
}


@article{DBLP:journals/tdsc/Pichler0VP24,
	author = {Georg Pichler and
                  Marco Romanelli and
                  Leonardo Rey Vega and
                  Pablo Piantanida},
	title = {Perfectly Accurate Membership Inference by a Dishonest Central Server
                  in Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4290--4296},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3326230},
	doi = {10.1109/TDSC.2023.3326230},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/Pichler0VP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning is expected to provide strong privacy guarantees, as only gradients or model parameters but no plain text training data is ever exchanged either between the clients or between the clients and the central server. In this paper, we challenge this claim by introducing a simple but still very effective membership inference attack algorithm, which relies only on a single training step. In contrast to the popular honest-but-curious model, we investigate a framework with a dishonest central server. Our strategy is applicable to models with ReLU activations and uses the properties of this activation function to achieve perfect accuracy. Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets show that our method provides perfect accuracy in identifying one sample in a training set with thousands of samples. Occasional failures of our method lead us to discover duplicate images in the CIFAR100 and CelebA datasets.}
}


@article{DBLP:journals/tdsc/Xu0ZZ00024,
	author = {Yanxin Xu and
                  Hua Zhang and
                  Shaohua Zhao and
                  Xin Zhang and
                  Wenmin Li and
                  Fei Gao and
                  Kaixuan Li},
	title = {Comments on "VERSA: Verifiable Secure Aggregation for Cross-Device
                  Federated Learning"},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4297--4298},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3272338},
	doi = {10.1109/TDSC.2023.3272338},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Xu0ZZ00024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, in IEEE Transactions on Dependable and Secure Computing (TDSC), the VERSA scheme proposed by Hahn et al. uses a double aggregation method for verifying the correctness of results returned from the server. The authors proposed that the correctness of the model aggregation can be verified with lower verification overhead by utilizing only a lightweight pseudorandom generator. To support verifiability of results returned from the server, a method of sharing a pair of vectors (a,b)\nby all clients is proposed, which is one of the most important work in VERSA. Unfortunately, in this paper, we show that the method is incorrect, which leads clients to consistently conclude that the aggregated results are incorrect. Furthermore, the model training process in federated learning is forced to abort. Finally, we demonstrate our view through theory analysis and instantiation verification.}
}


@article{DBLP:journals/tdsc/ZhaoYZC24,
	author = {Liang Zhao and
                  Jie Yu and
                  Yiheng Zhang and
                  Liqun Chen},
	title = {On the Privacy of Elementary Matrices Masking-Based Verifiable (Outsourced)
                  Computation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4299--4301},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3277285},
	doi = {10.1109/TDSC.2023.3277285},
	timestamp = {Thu, 24 Oct 2024 08:17:55 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhaoYZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving Verifiable (outsourced) Computation (PVC) for face recognition is a significant research topic in the information security community. Recently, an efficient elementary matrices masking-based PVC protocol for face recognition has been published in IEEE Transactions on Dependable and Secure Computing (Ren et al. 2023). In this article, we analyze the privacy property of this protocol, and demonstrate that the output distribution of the problem generation algorithm in this protocol is not computationally indistinguishable from the uniform distribution over a matrix set, which breaks the original consequence (see Theorem 1). We introduce a formal definition of a privacy model for a PVC protocol and prove that the targeted PVC protocol does not hold privacy under this model. We then present experimental results to support our theoretical analyses.}
}


@article{DBLP:journals/tdsc/DongZ24,
	author = {Chenghe Dong and
                  Jianhong Zhang},
	title = {On the Security of Multi-Receiver Certificateless Generalized Signcryption
                  Scheme for WBANs},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4302--4303},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3318296},
	doi = {10.1109/TDSC.2023.3318296},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DongZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Wireless body area networks (WBANs), the physiological parameters monitored by wearable devices are sensitive data of patients. To ensure the privacy of such data, Shen et al. proposed a multi-receiver certificateless generalized signcryption scheme to support multidisciplinary team treatment. Although they claim that their scheme can resist Type I attacks and provide the unlinkability of ciphertext, our analysis found that their scheme is insecure. Specifically, it is neither resistant to public key replacement in Type I attacks, nor does it satisfy the claimed unlinkability of ciphertext. After giving the corresponding attacks, we analyze the reasons underlying these attacks and provide the corresponding suggestions to overcome them.}
}


@article{DBLP:journals/tdsc/Cao24,
	author = {Zhengjun Cao},
	title = {Corrections to "Efficient Provably-Secure Dynamic ID-Based Authenticated
                  Key Agreement Scheme With Enhanced Security Provision"},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4304--4305},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3302300},
	doi = {10.1109/TDSC.2023.3302300},
	timestamp = {Tue, 22 Oct 2024 21:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Cao24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We show that the key agreement scheme [IEEE TDSC, 2022, 19(2): 1227–1238] is vulnerable to offline password guessing attack, not as claimed. We also reiterate the signification of an identifier which has often been neglected by some researchers.}
}


@article{DBLP:journals/tdsc/Li0SW24,
	author = {Cong Li and
                  Xinyu Feng and
                  Qingni Shen and
                  Zhonghai Wu},
	title = {On the Security of Secure Keyword Search and Data Sharing Mechanism
                  for Cloud Computing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {4},
	pages = {4306--4308},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2023.3346795},
	doi = {10.1109/TDSC.2023.3346795},
	timestamp = {Tue, 15 Oct 2024 20:58:06 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/Li0SW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nearly all of the previous attribute-based proxy re-encryption (ABPRE) schemes cannot support keyword search and keyword updating without the aid of private key generator (PKG) simultaneously. To resolve this problem, recently in IEEE Transactions on Dependable and Secure Computing (doi: 10.1109/TDSC.2020.2963978), Ge et al. proposed a ciphertext-policy ABPRE scheme with keyword search, dubbed CPAB-KSDS, which supports keyword updating without communicating with PKG. It also achieves indistinguishability against chosen-ciphertext attack (IND-CCA) security and indistinguishability against chosen-keyword attack (IND-CKA) security in the random oracle model. In this paper, we carefully analyze the security of Ge et al.’s CPAB-KSDS scheme and find that they did not give a correct reduction from IND-CKA security of theirs to the underlying cryptographic assumption. Furthermore, we also give a concrete attack on IND-CKA security of the CPAB-KSDS scheme. Therefore, it fails to achieve IND-CKA security they claimed, which is an essential security requirement for the encryption scheme with keyword search.}
}


@article{DBLP:journals/tdsc/XuLLJML24,
	author = {Runhua Xu and
                  Bo Li and
                  Chao Li and
                  James B. D. Joshi and
                  Shuai Ma and
                  Jianxin Li},
	title = {TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated
                  Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4309--4323},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3350206},
	doi = {10.1109/TDSC.2024.3350206},
	timestamp = {Fri, 27 Sep 2024 16:24:56 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XuLLJML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning is a computing paradigm that enhances privacy by enabling multiple parties to collaboratively train a machine learning model without revealing personal data. However, current research indicates that traditional federated learning platforms are unable to ensure privacy due to privacy leaks caused by the interchange of gradients. To achieve privacy-preserving federated learning, integrating secure aggregation mechanisms is essential. Unfortunately, existing solutions are vulnerable to recently demonstrated inference attacks such as the disaggregation attack. This article proposes TAPFed, an approach for achieving privacy-preserving federated learning in the context of multiple decentralized aggregators with malicious actors. TAPFed uses a proposed threshold functional encryption scheme and allows for a certain number of malicious aggregators while maintaining security and privacy. We provide formal security and privacy analyses of TAPFed and compare it to various baselines through experimental evaluation. Our results show that TAPFed offers equivalent performance in terms of model quality compared to state-of-the-art approaches while reducing transmission overhead by 29%–45% across different model training scenarios. Most importantly, TAPFed can defend against recently demonstrated inference attacks caused by curious aggregators, which the majority of existing approaches are susceptible to.}
}


@article{DBLP:journals/tdsc/WuZ24,
	author = {Jiahui Wu and
                  Weizhe Zhang},
	title = {On the Security of Verifiable and Oblivious Secure Aggregation for
                  Privacy-Preserving Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4324--4326},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3352170},
	doi = {10.1109/TDSC.2024.3352170},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WuZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, to resist privacy leakage and aggregation result forgery in federated learning (FL), Wang et al. proposed a verifiable and oblivious secure aggregation protocol for FL, called VOSA. They claimed that VOSA was aggregate unforgeable and verifiable under a malicious aggregation server and gave detailed security proof. In this article, we show that VOSA is insecure, in which local gradients/aggregation results and their corresponding authentication tags/proofs can be tampered with without being detected by the verifiers. After presenting specific attacks, we analyze the reason for this security issue and give a suggestion to prevent it.}
}


@article{DBLP:journals/tdsc/YuCLYSK24,
	author = {Zitong Yu and
                  Rizhao Cai and
                  Zhi Li and
                  Wenhan Yang and
                  Jingang Shi and
                  Alex C. Kot},
	title = {Benchmarking Joint Face Spoofing and Forgery Detection With Visual
                  and Physiological Cues},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4327--4342},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3352049},
	doi = {10.1109/TDSC.2024.3352049},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YuCLYSK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face anti-spoofing (FAS) and face forgery detection play vital roles in securing face biometric systems from presentation attacks (PAs) and vicious digital manipulation (e.g., deepfakes). Despite satisfactory performance upon large-scale data and powerful deep models, recent advances in face spoofing and forgery detection approaches usually focus on 1) unimodal visual appearance or physiological (i.e., remote photoplethysmography (rPPG)) cues; and 2) separated feature representation for FAS or face forgery detection. On one side, unimodal appearance and rPPG features are respectively vulnerable to high-fidelity face 3D mask and video replay attacks, inspiring us to design reliable multi-modal fusion mechanisms for generalized FAS. On the other side, there are rich common features across FAS and face forgery detection tasks (e.g., periodic rPPG rhythms and vanilla appearance for bonafides), providing solid evidence to design a joint FAS and face forgery detection system in a multi-task learning fashion. In this paper, we establish the first joint face spoofing and forgery detection benchmark using both visual appearance and physiological rPPG cues. To enhance the rPPG periodicity discrimination, we design a two-branch physiological network using both facial spatio-temporal rPPG signal map and its continuous wavelet transformed counterpart as inputs. To mitigate the modality bias and improve the fusion efficacy, we conduct a weighted batch and layer normalization for both appearance and rPPG features before multi-modal fusion. We also investigate prevalent deep models, feature fusion strategies and multi-task learning configurations for joint face spoofing and forgery detection. We find that the generalization capacities of both unimodal (appearance or rPPG) and multi-modal (appearance+rPPG) models can be obviously improved via joint training on these two tasks. We hope this new benchmark will facilitate the future research of both FAS and deepfake detection communities.}
}


@article{DBLP:journals/tdsc/HanXSWZLL24,
	author = {Xiao Han and
                  Junjie Xiong and
                  Wenbo Shen and
                  Mingkui Wei and
                  Shangqing Zhao and
                  Zhuo Lu and
                  Yao Liu},
	title = {The Perils of Wi-Fi Spoofing Attack Via Geolocation {API} and Its
                  Defense},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4343--4359},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3352981},
	doi = {10.1109/TDSC.2024.3352981},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/HanXSWZLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Location spoofing attack deceiving a Wi-Fi positioning system has been studied for over a decade. However, it has been challenging to construct a practical spoofing attack in urban areas with dense coverage of legitimate Wi-Fi APs. This paper identifies the vulnerability of the Google Geolocation API, which returns the location of a mobile device based on the information of the Wi-Fi access points that the device can detect. We show that this vulnerability can be exploited by the attacker to reveal the black-box localization algorithms adopted by the Google Wi-Fi positioning system and easily launch the location spoofing attack in dense urban areas with a high success rate. Furthermore, we find that this vulnerability can also lead to severe consequences that hurt user privacy, including the leakage of sensitive information like precise locations, daily activities, and demographics. Ultimately, we discuss the potential countermeasures that may be used to mitigate this vulnerability and location spoofing attack.}
}


@article{DBLP:journals/tdsc/WangMYJSX24,
	author = {Kai Wang and
                  Richard Mitev and
                  Chen Yan and
                  Xiaoyu Ji and
                  Ahmad{-}Reza Sadeghi and
                  Wenyuan Xu},
	title = {Analyzing and Defending GhostTouch Attack Against Capacitive Touchscreens},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4360--4375},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3352593},
	doi = {10.1109/TDSC.2024.3352593},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/WangMYJSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Capacitive touchscreens have become the primary human-machine interface for personal devices such as smartphones and tablets. In this article, we present GhostTouch, the first active contactless attack against capacitive touchscreens. GhostTouch uses electromagnetic interference (EMI) to inject fake touch points into a touchscreen without the requirement to physically touch it. By tuning the parameters of the electromagnetic signal and adjusting the antenna, we can inject two types of basic touch events, taps and swipes, into targeted locations of the touchscreen and control them to manipulate the underlying device. We successfully launch theGhostTouch attacks on nine smartphone models. We can inject targeted taps continuously with a standard deviation of as low as\n14.6×19.2\npixels from the target area, and a distance of up to\n40mm\n. We show the real-world impact of the GhostTouch attacks in a few proof-of-concept scenarios, including pressing the button, answering an eavesdropping phone call, and swiping up to unlock. Finally, we propose touchscreen reinforcement and attack detection mechanisms to mitigate the threat of GhostTouch attack.}
}


@article{DBLP:journals/tdsc/XieLS24,
	author = {Yuhao Xie and
                  Xiong Luo and
                  Jiankun Sun},
	title = {Toward Enhancing Sequence-Optimized Malware Representation With Context-Separated
                  Bi-Directional Long Short-Term Memory and Proximal Policy Optimization},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4376--4387},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3352604},
	doi = {10.1109/TDSC.2024.3352604},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/XieLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware proliferation is a major threat to computer systems, and malware classification techniques are effective for analyzing and identifying malware. Recent intelligent malware classifiers intend to integrate natural language processing techniques for better identification performance, however, representation learning presents a fundamental challenge in this new paradigm. Currently, representation models either rely on predetermined structures or ignore structure. Thus, we propose a malware vector representation model utilizing an improved context-separated bi-directional long short-term memory (CS-Bi-LSTM) network with reinforcement learning (RL) to discover optimized structures for learning sentence representations. Our model filters out irrelevant representations and captures long-term dependencies. To generate word vectors, we use the CS-Bi-LSTM network, which employs two unique unidirectional long short-term memory (LSTM) cells for each context. Following that, we develop a proximal policy optimization (PPO)-based RL structure to capture relevant representations with feedback from a quality estimator. Through intrinsic and extrinsic evaluations on two malware datasets, our proposed model demonstrates better performance by filtering redundant information and achieving an acceptable vector representation. Then, our proposed method achieves the highest predictive performance with a classification accuracy of 98.54%.}
}


@article{DBLP:journals/tdsc/WangMS24,
	author = {Dongxia Wang and
                  Tim Muller and
                  Jun Sun},
	title = {Provably Secure Decisions Based on Potentially Malicious Information},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4388--4403},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353295},
	doi = {10.1109/TDSC.2024.3353295},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WangMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There are various security-critical decisions routinely made, based on information provided by peers: routing messages, user reports, sensor data, navigational information, blockchain updates, etc. Jury theorems were proposed in sociology to make decisions based on information from peers, which assume peers may be mistaken with some probability. We focus on attackers in a system, which manifest as peers that strategically report fake information to manipulate decision-making. We define the property of robustness: a lower bound probability of deciding correctly, regardless of what information attackers provide. When peers are independently selected, we propose an optimal, robust decision mechanism called Most Probable Realisation (MPR). When peer collusion affects source selection, we prove that generally, it is NP-hard to find an optimal decision scheme. We propose multiple heuristic decision schemes that can achieve optimality for some collusion scenarios.}
}


@article{DBLP:journals/tdsc/XieY24,
	author = {Haomeng Xie and
                  Zheng Yan},
	title = {{SPCEX:} Secure and Privacy-Preserving Cryptocurrency Exchange},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4404--4417},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353541},
	doi = {10.1109/TDSC.2024.3353541},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/XieY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The prosperity of blockchain technique has spawned numerous types of cryptocurrencies. However, a secure and privacy-preserving cryptocurrency exchange protocol that can support atomicity and unlinkability, and effectively resist various attacks is still missed in the literature. This article proposes SPCEX, a secure and privacy-preserving cryptocurrency exchange protocol, which supports atomicity and unlinkability, as well as resists collusion attacks, front-running attacks and Sybil attacks without relying on any trust execution environments (TEEs). SPCEX employs a mixing protocol to conceal trader involvement and preserve their identity privacy. It applies a privacy-preserving comparison algorithm based on an improved homomorphic re-encryption scheme to match buy and sell orders secretly, thus resisting front-running attacks. In addition, we construct atomic transactions with smart contracts to protect tokens of honest traders. A collateral deposit mechanism is employed to deter collusive parties and penalize abnormal behaviors, which discourages collusion attacks and Sybil attacks. We analyze the security and privacy of SPCEX, and formally prove the security of the improved homomorphic re-encryption scheme. Through proof-of-concept implementation, we demonstrate its validity and reliability, and show its advanced performance by comparing it with a cutting-edge scheme.}
}


@article{DBLP:journals/tdsc/TianSWXZLL24,
	author = {Jiwei Tian and
                  Chao Shen and
                  Buhong Wang and
                  Xiaofang Xia and
                  Meng Zhang and
                  Chenhao Lin and
                  Qian Li},
	title = {{LESSON:} Multi-Label Adversarial False Data Injection Attack for
                  Deep Learning Locational Detection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4418--4432},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353302},
	doi = {10.1109/TDSC.2024.3353302},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/TianSWXZLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning methods can not only detect false data injection attacks (FDIA) but also locate attacks of FDIA. Although adversarial false data injection attacks (AFDIA) based on deep learning vulnerabilities have been studied in the field of single-label FDIA detection, the adversarial attack and defense against multi-label FDIA locational detection are still not involved. To bridge this gap, this paper first explores the multi-label adversarial example attacks against multi-label FDIA locational detectors and proposes a general multi-label adversarial attack framework, namely muLti-labEl adverSarial falSe data injectiON attack (LESSON). The proposed LESSON attack framework includes three key designs, namely Perturbing State Variables, Tailored Loss Function Design, and Change of Variables, which can help find suitable multi-label adversarial perturbations within the physical constraints to circumvent both Bad Data Detection (BDD) and Neural Attack Location (NAL). Four typical LESSON attacks based on the proposed framework and two dimensions of attack objectives are examined, and the experimental results demonstrate the effectiveness of the proposed attack framework, posing serious and pressing security concerns in smart grids.}
}


@article{DBLP:journals/tdsc/WangYLBP24,
	author = {Jie Wang and
                  Zheng Yan and
                  Jiahe Lan and
                  Elisa Bertino and
                  Witold Pedrycz},
	title = {TrustGuard: GNN-Based Robust and Explainable Trust Evaluation With
                  Dynamicity Support},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4433--4450},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353548},
	doi = {10.1109/TDSC.2024.3353548},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WangYLBP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trust evaluation assesses trust relationships between entities and facilitates decision-making. Machine Learning (ML) shows great potential for trust evaluation owing to its learning capabilities. In recent years, Graph Neural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in dealing with graph data. This has motivated researchers to explore their use in trust evaluation, as trust relationships among entities can be modeled as a graph. However, current trust evaluation methods that employ GNNs fail to fully satisfy the dynamic nature of trust, overlook the adverse effects of trust-related attacks, and cannot provide convincing explanations on evaluation results. To address these problems, we propose TrustGuard, a GNN-based accurate trust evaluation model that supports trust dynamicity, is robust against typical attacks, and provides explanations through visualization. Specifically, TrustGuard is designed with a layered architecture that contains a snapshot input layer, a spatial aggregation layer, a temporal aggregation layer, and a prediction layer. Among them, the spatial aggregation layer adopts a defense mechanism to robustly aggregate local trust, and the temporal aggregation layer applies an attention mechanism for effective learning of temporal patterns. Extensive experiments on two real-world datasets show that TrustGuard outperforms state-of-the-art GNN-based trust evaluation models with respect to trust prediction across single-timeslot and multi-timeslot, even in the presence of attacks. In addition, TrustGuard can explain its evaluation results by visualizing both spatial and temporal views.}
}


@article{DBLP:journals/tdsc/LamLZWWG24,
	author = {Kwok{-}Yan Lam and
                  Xianhui Lu and
                  Linru Zhang and
                  Xiangning Wang and
                  Huaxiong Wang and
                  Si Qi Goh},
	title = {Efficient FHE-Based Privacy-Enhanced Neural Network for Trustworthy
                  AI-as-a-Service},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4451--4468},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353536},
	doi = {10.1109/TDSC.2024.3353536},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LamLZWWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {AI-as-a-Service has emerged as an important trend for supporting the growth of the digital economy. Digital service providers make use of their vast amount of customer data to train AI models (such as image recognition, financial modelling and pandemic modelling etc) and offer them as a service on the cloud. While there are convincing advantages for using such third-party models, the fact that model users are required to upload their data to the cloud is bound to raise serious privacy concerns, especially in the face of increasingly stringent privacy regulations and legislation. To promote the adoption of AI-as-a-Service while addressing privacy issues, we propose a practical approach for constructing privacy-enhanced neural networks by designing an efficient implementation of fully homomorphic encryption. With this approach, an existing neural network can be converted to process FHE-encrypted data and produce encrypted output which are only accessible by the model users, and more importantly, within an operationally acceptable time (e.g., within 1 s for facial recognition in typical border control systems). Experimental results show that in many practical tasks such as facial recognition, text classification and so on, we obtained the state-of-the-art inference accuracy in less than one second on a 16 cores CPU.}
}


@article{DBLP:journals/tdsc/ZhangCZL24,
	author = {Pei Zhang and
                  Qingfeng Cheng and
                  Mingliang Zhang and
                  Xiangyang Luo},
	title = {A Blockchain-Based Secure Covert Communication Method via Shamir Threshold
                  and {STC} Mapping},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4469--4480},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353570},
	doi = {10.1109/TDSC.2024.3353570},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangCZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Covert communication is a crucial technology that hides information in the redundant structure of the file and transmission through public channel to achieve the secure delivery of information. The existing covert communication methods face certain challenges based on blockchain, such as the lack of a secure channel for transferring the master key, low embedding capacity, and weak detection resistance. In view of this, this paper proposes a covert communication method based on Shamir threshold and STC mapping, which is suitable for public chain networks. The proposed method first decomposes the master key into sub-keys by introducing Shamir scheme, and the sub-keys are shared with the help of transaction amounts on a blockchain. Then, a mapping relation is established to ensure that the transaction amounts carrying the secret are evenly distributed. Finally, secret information is hidden in the mapping relationship and the transaction amount is interwoven, which is published to the blockchain through transactions to complete covert communication. The introduction of Shamir threshold breaks the limitation that master key cannot be safely transmitted due to the lack of a secure channel in the research of covert communication based on blockchain, thereby enhances the security of the method. A series of experimental results illustrate that the proposed method is more resistant to detection, and the embedding efficiency is enhanced by up to 27.56 times compared with existing public chain-based covert communication methods, effectively reducing the number of transactions and saving resource consumption.}
}


@article{DBLP:journals/tdsc/KasyapT24,
	author = {Harsh Kasyap and
                  Somanath Tripathy},
	title = {Sine: Similarity is Not Enough for Mitigating Local Model Poisoning
                  Attacks in Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4481--4494},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353317},
	doi = {10.1109/TDSC.2024.3353317},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/KasyapT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning is a collaborative machine learning paradigm that brings the model to the edge for training over the participants’ local data under the orchestration of a trusted server. Though this paradigm protects data privacy, the aggregator has no control over the local data or model at the edge. So, malicious participants could perturb their locally held data or model to post an insidious update, degrading global model accuracy. Recent Byzantine-robust aggregation rules could defend against data poisoning attacks. Also, model poisoning attacks have become more ingenious and adaptive to the existing defenses. But these attacks are crafted against specific aggregation rules. This work presents a generic model poisoning attack framework named Sine (Similarity is not enough), which harnesses vulnerabilities in cosine similarity to increase the impact of poisoning attacks by 20–30%. Sine makes convergence unachievable by maintaining the persistence of the attack. Further, we propose an effective defense technique called FLTC (FL Trusted Coordinates) to avoid such issues. FLTC selects the trusted coordinates and aggregates them based on the change in their direction and magnitude with respect to a trusted base model update. FLTC could successfully defend against poisoning attacks, including adaptive model poisoning attacks, by restricting the attack impact to 2–4%.}
}


@article{DBLP:journals/tdsc/RoyC24,
	author = {Krishna Chandra Roy and
                  Guenevere Chen},
	title = {GraphCH: {A} Deep Framework for Assessing Cyber-Human Aspects in Insider
                  Threat Detection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4495--4509},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353929},
	doi = {10.1109/TDSC.2024.3353929},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/RoyC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Insider threat is one of the most damaging cyber attacks that could cause the loss of intellectual property and enterprise data security breaches. Action sequence data such as host logs are used to investigate such threats and develop anomaly-based AI detectors. However, insider threat actions are similar to legitimate user activities, causing AI detectors to fail and suffer from high false alarm rates. Therefore, user cyber activity logs are inadequate to fully unfold insider threats. In this study, we adopt human psychological principles of risk-taking and impulsiveness along with host data to assess the influence and usefulness of human behavioral aspects in insider threat detection. We hypothesize that individuals’ impulsive and risk-taking behavior correlates with cyberspace activities. To validate our hypothesis, we conducted an IRB-approved study recruiting 35 participants who work in a large U.S. university and collected their cyber and psychological data for 90 days. Host and human-behavioral data analysis and mapping indicate that impulsive and risk-taking users trigger more system errors causing (un)intentional insider threats and are susceptible to attackers’ social engineering and cognitive hacking. Utilizing cyber-human aspects, we introduce a Cyber-Human Graph Neural Network (GNN) based framework GraphCH to identify abnormal user behaviors and detect insider threats.}
}


@article{DBLP:journals/tdsc/ChenLCWYZZS24,
	author = {Dajiang Chen and
                  Zeyu Liao and
                  Ruidong Chen and
                  Hao Wang and
                  Chong Yu and
                  Kuan Zhang and
                  Ning Zhang and
                  Xuemin Shen},
	title = {Privacy-Preserving Anomaly Detection of Encrypted Smart Contract for
                  Blockchain-Based Data Trading},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4510--4525},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353827},
	doi = {10.1109/TDSC.2024.3353827},
	timestamp = {Sun, 19 Jan 2025 13:48:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ChenLCWYZZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In a blockchain-based data trading platform, data users can purchase data sets and computing power through encrypted smart contracts. The security of smart contracts is important as it relates to that of the data platform. However, due to the inability to apply to detection rules with complex structures and the inefficiency of detection, existing malicious code detection methods are not suitable for the encrypted smart contracts in blockchain-based data trading platforms with high transaction rate requirements. In this article, a practical and privacy-preserving malicious code detection method is proposed for encrypted smart contract in blockchain-based data trading platform. Specifically, we design two kinds of miners to act as the malicious rule processor and the detector respectively for inspecting the encrypted smart contract. The rule processor generates an obfuscated map with the original open-source malicious rule set. The detector performs a malicious inspection algorithm by inputting the obfuscated map and the randomized tokens, where the latter is generated from smart contract. Then, we theoretically analyze the security syntax of the proposed method. The analysis results demonstrate the proposed scheme can achieve \\mathcal {L}\n-secure against adaptive attacks. Extensive experiments are carried out through the open-source real rule sets, which show that the proposed scheme can reduce communication time and communication overhead.}
}


@article{DBLP:journals/tdsc/LiCWXW24,
	author = {Cui Li and
                  Rongmao Chen and
                  Yi Wang and
                  Qianqian Xing and
                  Baosheng Wang},
	title = {{REEDS:} An Efficient Revocable End-to-End Encrypted Message Distribution
                  System for IoT},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4526--4542},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353811},
	doi = {10.1109/TDSC.2024.3353811},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiCWXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To address the confidentiality concerns of malicious adversaries that fully compromise the message broker in pub/sub based IoT systems, several researchers use proxy re-encryption (PRE) to realize end-to-end encrypted message distribution (from publisher to subscriber). However, the all-or-nothing share feature of PRE poses a problem that the share cannot be efficiently revoked. The only way for publishers to revoke the access rights of subscribers is to pick a new public-private key pair and re-generate the re-encryption keys for all the remaining subscribers, which hampers the scalability in practice. To realize efficient user revocation, we present REEDS, an efficient revocable end-to-end encrypted message distribution system for IoT. The core of REEDS is a novel proxy-aided identity-based conditional proxy re-encryption (PIB-CPRE) scheme. Essentially, we use a binary-tree structure to organize re-encryption keys, so that the update of re-encryption keys is reduced from linear to logarithmic in the number of subscribers. We show that REEDS satisfies confidentiality, efficient immediate revocation, decentralized authorization, and maintains low overhead for publishers and subscribers. The prototype system is implemented and its performance is evaluated. The results show that REEDS is not only easy to deploy over existing message brokers but also highly efficient.}
}


@article{DBLP:journals/tdsc/WahrstatterTS24,
	author = {Anton Wahrst{\"{a}}tter and
                  Alfred Taudes and
                  Davor Svetinovic},
	title = {Reducing Privacy of CoinJoin Transactions: Quantitative Bitcoin Network
                  Analysis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4543--4558},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353803},
	doi = {10.1109/TDSC.2024.3353803},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WahrstatterTS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy within the Bitcoin ecosystem has been critical for the operation and propagation of the system since its very first release. While various entities have sought to deanonymize and reveal user identities, the default semi-anonymous approach to privacy was judged as insufficient and the community developed a number of advanced privacy-preservation mechanisms. In this study, we propose an improved variant of the multiple-input clustering approach that incorporates advanced privacy-enhancing techniques. We examine the CoinJoin-adjusted user graph of Bitcoin through quantitative network analysis and draw conclusions on the effectiveness of our proposed clustering method compared to naive multiple-input clustering. Our findings indicate that CoinJoin transactions can significantly distort commonly applied address clustering approaches. Moreover, we demonstrate that Bitcoin's user graph has become less dense in recent years, concurrent with the collapse of several independent user clusters. Our results contribute to a more comprehensive understanding of privacy aspects in the Bitcoin transaction network and lay the groundwork for developing enhanced measures to prevent money laundering and terrorism financing.}
}


@article{DBLP:journals/tdsc/ZhangZGMZSC24,
	author = {Jiale Zhang and
                  Chengcheng Zhu and
                  Chunpeng Ge and
                  Chuan Ma and
                  Yanchao Zhao and
                  Xiaobing Sun and
                  Bing Chen},
	title = {BadCleaner: Defending Backdoor Attacks in Federated Learning via Attention-Based
                  Multi-Teacher Distillation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4559--4573},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3354049},
	doi = {10.1109/TDSC.2024.3354049},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangZGMZSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a privacy-preserving distributed learning paradigm, federated learning (FL) has been proven to be vulnerable to various attacks, among which backdoor attack is one of the toughest. In this attack, malicious users attempt to embed backdoor triggers into local models, resulting in the crafted inputs being misclassified as the targeted labels. To address such attack, several defense mechanisms are proposed, but may lose the effectiveness due to the following drawbacks. First, current methods heavily rely on massive labeled clean data, which is an impractical setting in FL. Moreover, an in-avoidable performance degradation usually occurs in the defensive procedure. To alleviate such concerns, we propose BadCleaner, a lossless and efficient backdoor defense scheme via attention-based federated multi-teacher distillation. First, BadCleaner can effectively tune the backdoored joint model without performance degradation, by distilling the in-depth knowledge from multiple teachers with only a small part of unlabeled clean data. Second, to fully eliminate the hidden backdoor patterns, we present an attention transfer method to alleviate the attention of models to the trigger regions. The extensive evaluation demonstrates that BadCleaner can reduce the success rates of state-of-the-art backdoor attacks without compromising the model performance.}
}


@article{DBLP:journals/tdsc/LiBMR24,
	author = {Mengming Li and
                  Kai Bu and
                  Chenlu Miao and
                  Kui Ren},
	title = {TreasureCache: Hiding Cache Evictions Against Side-Channel Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4574--4588},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3354991},
	doi = {10.1109/TDSC.2024.3354991},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiBMR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cache side-channel attacks remain a stubborn source of cross-core secret leakage. Such attacks exploit the timing difference between cache hits and misses. Most defenses thus choose to prevent cache evictions. Given that two possible types of evictions—flush-based and conflict-based—use different architectural features, these defenses have to integrate hybrid defense strategies, incur OS modification, and sacrifice performance to completely throttle cache side-channel attacks. In this article, we present TreasureCache against cache side-channel attacks without modifying OS or sacrificing performance. Instead of preventing cache evictions with various costs, we advocate to allow cache evictions as is and hide exploitable evictions in our specialized small eviction-hidden buffer. The buffer guarantees a fast hit time comparative to LLC hits. This instantly closes the timing gap between accessing exploitable blocks when they are in and out of the LLC. Moreover, with the help of our buffer, we no longer have to disable flush instructions or shared memory. A lightweight constant-time flush instruction can help TreasureCache to prevent both flush-based and conflict-based side-channel attacks. We validate TreasureCache security and performance through extensive experiments. With a hardware overhead of less than 0.5%, TreasureCache reduces the secret-leakage resolution by about 1,000 times without introducing any performance slowdown.}
}


@article{DBLP:journals/tdsc/BakerLJZTZ24,
	author = {Thar Baker and
                  Tong Li and
                  Jingyu Jia and
                  Baolei Zhang and
                  Chang Tan and
                  Albert Y. Zomaya},
	title = {Poison-Tolerant Collaborative Filtering Against Poisoning Attacks
                  on Recommender Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4589--4599},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3354462},
	doi = {10.1109/TDSC.2024.3354462},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/BakerLJZTZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized recommendation is deemed ubiquitous. Indeed, it has been applied to several online services (e.g., E-commerce, advertising, and social media applications, to name a few). Learning unknown user preferences from user-provided data lies at the core of modern collaborative filtering recommender systems. However, there is an incentive for malicious attackers to manipulate the learned preferences, which could affect business decision making, by injecting poisoned data. In the face of such a poisoning attack, while previous works have proposed a number of defense methods succeeding in other machine learning (ML) tasks, little is effective for collaborative filtering (CF). Thereof, we present a new defense scheme called poison-tolerant collaborative filtering (PTCF), which is highly robust against poisoning attacks on collaborative filtering. Different from the defenses that remove outliers or search a min-loss subset, the PTCF scheme enables collaborative filtering on an attacked training dataset while guarantees system's availability and integrity. We evaluate extensively the PTCF scheme on a public dataset (Jester) and two real-world datasets (Movie and E-Shopping), and demonstrate that the PTCF scheme is significantly effective in providing robustness.}
}


@article{DBLP:journals/tdsc/LiLWMW24,
	author = {Zongjie Li and
                  Zhibo Liu and
                  Wai Kin Wong and
                  Pingchuan Ma and
                  Shuai Wang},
	title = {Evaluating {C/C++} Vulnerability Detectability of Query-Based Static
                  Application Security Testing Tools},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4600--4618},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3354789},
	doi = {10.1109/TDSC.2024.3354789},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiLWMW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, query-based static application security testing(Q-SAST) tools such as CodeQL have gained popularity due to their ability to codify vulnerability knowledge into SQL-like queries and search for vulnerabilities in the database derived from the software. The industry has made considerable progress in building Q-SAST tools, facilitating their integration into the continuous integration (CI) pipeline, and sustaining an active community. However, we do not have a systematic understanding of their vulnerability detection capability in comparison to conventional SAST tools. We conduct the first in-depth study of Q-SAST to demystify their C/C++ vulnerability detectability. Our study is conducted from three complementary aspects. We first use a synthetic CWE test suite and a real-world CVE test suite, totaling almost 30 K programs with known CWE/CVE, to assess popular (commercial) Q-SAST and industry-leading SAST (requiring no queries). Then, we gather defect-fixing pull requests (PRs) since the release dates of three popular Q-SAST tools, characterizing historically-fixed defects and comparing them to pitfalls exposed in our CWE/CVE study. To enhance vulnerability detection, we design SAST-MT, a metamorphic testing framework to detect false positives (FPs) and false negatives (FNs) of Q-SAST. Findings of SAST-MT can be used to easily expose the root causes of Q-SAST's FPs and FNs. We summarize lessons from our study that can benefit both users and developers of Q-SAST.}
}


@article{DBLP:journals/tdsc/MiaoXLLCD24,
	author = {Yinbin Miao and
                  Rongpeng Xie and
                  Xinghua Li and
                  Zhiquan Liu and
                  Kim{-}Kwang Raymond Choo and
                  Robert H. Deng},
	title = {Efficient and Secure Federated Learning Against Backdoor Attacks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4619--4636},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3354736},
	doi = {10.1109/TDSC.2024.3354736},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/MiaoXLLCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the powerful representation ability and superior performance of Deep Neural Networks (DNN), Federated Learning (FL) based on DNN has attracted much attention from both academic and industrial fields. However, its transmitted plaintext data causes privacy disclosure. FL based on Local Differential Privacy (LDP) solutions can provide privacy protection to a certain extent, but these solutions still cannot achieve adaptive perturbation in DNN model. In addition, this kind of schemes cause high communication overheads due to the curse of dimensionality of DNN, and are naturally vulnerable to backdoor attacks due to the inherent distributed characteristic. To solve these issues, we propose an Efficient and Secure Federated Learning scheme (ESFL) against backdoor attacks by using adaptive LDP and compressive sensing. Formal security analysis proves that ESFL satisfies\nϵ\n-LDP security. Extensive experiments using three datasets demonstrate that ESFL can solve the problems of traditional LDP-based FL schemes without a loss of model accuracy and efficiently resist the backdoor attacks.}
}


@article{DBLP:journals/tdsc/LiLLXWL24,
	author = {Dong Li and
                  Qingguo L{\"{u}} and
                  Xiaofeng Liao and
                  Tao Xiang and
                  Jiahui Wu and
                  Junqing Le},
	title = {{AVPMIR:} Adaptive Verifiable Privacy-Preserving Medical Image Retrieval},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4637--4651},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3355223},
	doi = {10.1109/TDSC.2024.3355223},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiLLXWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing privacy concerns associated with cloud-assisted image retrieval have captured the attention of researchers. However, a significant number of current research endeavors encounter limitations, including suboptimal accuracy, inefficient retrieval, and a lack of effective result verification mechanisms. To address these limitations, we propose an adaptive verifiable privacy-preserving medical image retrieval (AVPMIR) scheme in the outsourced cloud. Specifically, we utilize the convolutional neural network (CNN) ResNet50 model to extract the feature of each medical image within the dataset of the medical institution, aiming to enhance retrieval accuracy. To enhance retrieval efficiency, we build an encryption searchable index based on a mini-batch\nk\n-means clustering algorithm. Furthermore, we present an index merging method in which multi-data owners build a different index tree according to different standards. To check the correctness of the returned results from the cloud server, we construct an adaptive verification framework for the obtained results based on chameleon hash and BLS signature. To provide strong security for the medical image datasets, we design an improved logistic chaotic mapping algorithm. The security analysis demonstrates that AVPMIR can defend various threat models. The experiment analysis further indicates that the AVPMIR can improve retrieval efficiency and demonstrate its practicability.}
}


@article{DBLP:journals/tdsc/PingWFGBX24,
	author = {Ping Ping and
                  Pan Wei and
                  Deyin Fu and
                  Bobiao Guo and
                  Olano Teah Bloh and
                  Feng Xu},
	title = {{IMIH:} Imperceptible Medical Image Hiding for Secure Healthcare},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4652--4667},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3355165},
	doi = {10.1109/TDSC.2024.3355165},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/PingWFGBX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medical images play a crucial role in doctors’ clinical diagnosis and treatment. However, the transmission and sharing of such private information raises security concerns. To address this issue, image hiding is used as an effective technique to protect images. To achieve large hiding capacity, lossless recovery and anti-steganalysis, we propose a novel two-stage medical image-hiding method in this article. In the first stage, a QR code for the patient diagnosis information (PDI) is generated and embedded into a secret medical image using reversible data hiding. In the second stage, the secret medical image containing PDI is hidden in a natural target image. A kind of lossless compression technique named soft compression is innovatively introduced in two hiding stages, to ensure that the reconstructed secret medical image and PDI are exactly identical to the original ones. Moreover, an adaptive n-LSB model is proposed to improve the stego image quality. Extensive experimental results show that our method achieves a PSNR of over 40 dB for the stego image at 2 BPP while recovering the PDI and secret medical image with 100% accuracy on the DIV2K, COCO and ImageNet datasets. It outperforms other state-of-the-art methods in terms of hiding invisibility, recovery accuracy and security.}
}


@article{DBLP:journals/tdsc/ZhangLLAYYZLLK24,
	author = {Zijian Zhang and
                  Xin Lu and
                  Meng Li and
                  Jincheng An and
                  Yang Yu and
                  Hao Yin and
                  Liehuang Zhu and
                  Yong Liu and
                  Jiamou Liu and
                  Bakh Khoussainov},
	title = {A Blockchain-Based Privacy-Preserving Scheme for Sealed-Bid Auction},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4668--4683},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3353540},
	doi = {10.1109/TDSC.2024.3353540},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangLLAYYZLLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The sealed-bid auction enables bidders to secretly send their bids to the auctioneer, which compares all bids and publishes the winning one on the bid-opening day. This type of auction is friendly for protecting the bid privacy, and sufficiently fair for all bidders if the auctioneer acts faithfully. Unfortunately, the auctioneer may not always be trustworthy. The auctioneer has the ability to deliberately leak any bid information to a part of bidders for raising the final winning price based on the investigation. Meanwhile, the auctioneer can appoint any bidder as the winner, as long as the bidder accepts a higher winning price than the current highest bid. Since bidders cannot obtain any bid information from others, to the best of our knowledge, it is difficult to prevent bid leakage from the auctioneer, and support bidders to verify the bid comparison results without disclosing the winning bid, simultaneously. To alleviate these problems, we first construct a homomorphic encryption(HE)-based bid comparison circuit. All bidders can directly compute a cipher of the winning bid by using this circuit; hence, the winning bid does not need to be exposed to all bidders. Then, we propose a blockchain-based sealed-bid scheme (BSS) by integrating the circuit with commitment and zero-knowledge proof. The auctioneer only obtains the commitments of bids before the bid-opening day, and he has to prove that the winner's bid is the same as the plaintext of the bidders’ computed cipher. Thus, the auctioneer can neither leak the bid information nor publish a higher winning price during in the auction. Detailed performance analysis shows that the computational complexity of BSS is linear with the binary length of bids.}
}


@article{DBLP:journals/tdsc/MaoDWZZ24,
	author = {Yunlong Mao and
                  Ziqin Dang and
                  Heng Wang and
                  Yuan Zhang and
                  Sheng Zhong},
	title = {Solution Probing Attack Against Coin Mixing Based Privacy-Preserving
                  Crowdsourcing Platforms},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4684--4698},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3355453},
	doi = {10.1109/TDSC.2024.3355453},
	timestamp = {Fri, 27 Sep 2024 16:24:56 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MaoDWZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conventional crowdsourcing platforms primarily rely on a central server as the broker for information exchange. Although many efforts have been made, centralized platforms are still vulnerable to underlying security issues, such as an untrusted central server and single-point failure. Fortunately, blockchain has emerged as an alternative infrastructure for building crowdsourcing platforms. Many excellent designs of blockchain-based decentralized crowdsourcing (BDCS) solutions have been proposed. Benefiting from blockchain, BDCS can provide fascinating features, like tampering resistance and anonymity. However, a new attack surface appears in BDCS. Recently, a new attack against BDCS named solution probing attack has been identified. The solution-probing adversary can take advantage of the anonymity of BDCS to probe valid solutions using a generative model. Due to the transparency of blockchain transactions, the probing attack is effective even if solutions are encrypted. Nevertheless, we find transaction-mixing techniques effective in defending against probing attacks. In this article, we introduce the solution probing attack and an improved variant, which can attack coin mixing-based BDCS. We evaluate probing attacks on large-scale crowdsourcing tasks. Experimental results show that the adversary is capable of deceiving BDCS with a limited number of probing, even if the BDCS is protected by solution encryption and coin mixing techniques.}
}


@article{DBLP:journals/tdsc/AkhtarBSRAVS24,
	author = {Ahmed Akhtar and
                  Masoud Barati and
                  Basit Shafiq and
                  Omer F. Rana and
                  Ayesha Afzal and
                  Jaideep Vaidya and
                  Shafay Shamail},
	title = {Blockchain Based Auditable Access Control for Business Processes With
                  Event Driven Policies},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4699--4716},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3356811},
	doi = {10.1109/TDSC.2024.3356811},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/AkhtarBSRAVS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of blockchain technology has been proposed to provide auditable access control for individual resources. Unlike the case where all resources are owned by a single organization, this work focuses on distributed applications such as business processes and distributed workflows. These applications are often composed of multiple resources/services that are subject to the security and access control policies of different organizational domains. Here, blockchains provide an attractive decentralized solution to provide auditability. However, the underlying access control policies may have event-driven constraints and can be overlapping in terms of the component conditions/rules as well as events. Existing work cannot handle event-driven constraints and does not sufficiently account for overlaps leading to significant overhead in terms of cost and computation time for evaluating authorizations over the blockchain. In this work, we propose an automata-theoretic approach for generating a cost-efficient composite access control policy. We reduce this composite policy generation problem to the standard weighted set cover problem. We show that the composite policy correctly captures all the local access control policies and reduces the policy evaluation cost over the blockchain. We have implemented the initial prototype of our approach using Ethereum as the underlying blockchain and empirically validated the effectiveness and efficiency of our approach. Ablation studies were conducted to determine the impact of changes in individual service policies on the overall cost.}
}


@article{DBLP:journals/tdsc/BuccafurriAL24,
	author = {Francesco Buccafurri and
                  Vincenzo De Angelis and
                  Sara Lazzaro},
	title = {{MQTT-I:} Achieving End-to-End Data Flow Integrity in {MQTT}},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4717--4734},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3358630},
	doi = {10.1109/TDSC.2024.3358630},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/BuccafurriAL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {MQTT has become the de facto standard in the IoT. Although standard MQTT lacks built-in security features, several proposals have been made to address this gap. Unfortunately, no existing proposal aims to offer end-to-end data flow integrity in the threat model of untrusted broker. Consider that, the broker has a privileged role, since it is in the middle of communication between publishers and subscribers. Our paper attempts to bridge this gap by introducing a new protocol called MQTT-I, which achieves end-to-end data flow integrity. Our solution is inspired by approaches based on Merkle Hash Trees, commonly used in the context of outsourced data to guarantee data integrity. Our solution aligns with the specific nature of MQTT, in which: (1) publishers and subscribers dynamically join and leave the system, (2) the decoupling principle holds, meaning that publishers and subscribers do not establish any form of agreement, and (3) data, whose integrity should be protected, are multi-topic streams. Moreover, the proposed solution allows us to find the right balance between performance and security. We perform both theoretical and experimental analysis to demonstrate that the introduced security features come with an acceptable overhead in terms of computational and energy cost.}
}


@article{DBLP:journals/tdsc/AlecciSLBK24,
	author = {Marco Alecci and
                  Jordan Samhi and
                  Li Li and
                  Tegawend{\'{e}} F. Bissyand{\'{e}} and
                  Jacques Klein},
	title = {Improving Logic Bomb Identification in Android Apps via Context-Aware
                  Anomaly Detection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4735--4753},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3358979},
	doi = {10.1109/TDSC.2024.3358979},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/AlecciSLBK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One prominent tactic used to keep malicious behavior from being detected during dynamic test campaigns is logic bombs, where malicious operations are triggered only when specific conditions are satisfied. Defusing logic bombs remains an unsolved problem in the literature. In this work, we propose to investigate Suspicious Hidden Sensitive Operations (SHSOs) as a step toward triaging logic bombs. To that end, we develop a novel hybrid approach that combines static analysis and context-aware anomaly detection techniques to uncover SHSOs, which we predict as likely implementations of logic bombs. Concretely, Difuzer++ identifies SHSO entry-points using an instrumentation engine and conducting an inter-procedural data-flow analysis. Subsequently, it extracts trigger-specific features to characterize SHSOs. To detect abnormal triggers, we utilize multiple One-Class SVM models, each trained on distinct sets of similar apps to more effectively capture normal behavior patterns. To assess the added value of the context-aware analysis, we compare Difuzer++ against a baseline approach with no context (that we name Difuzer). We show that the context-aware analysis leads to a significant improvement in both the precision and F1 score. Furthermore, the probability of successfully triaging logic bombs among SHSOs increases from 29.7% to 58.8%. All our artifacts are released to the community.}
}


@article{DBLP:journals/tdsc/AslRAT24,
	author = {Javad Rafiei Asl and
                  Mohammad Hossein Rafiei and
                  Manar Alohaly and
                  Daniel Takabi},
	title = {A Semantic, Syntactic, and Context-Aware Natural Language Adversarial
                  Example Generator},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4754--4769},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3359817},
	doi = {10.1109/TDSC.2024.3359817},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/AslRAT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning models are vulnerable to maliciously crafted Adversarial Examples (AEs). Training a machine learning model with AEs improves its robustness and stability against adversarial attacks. It is essential to develop models that produce high-quality AEs. Developing such models has been much slower in natural language processing (NLP) than in areas such as computer vision. This paper introduces a practical and efficient adversarial attack model called SSCAE for Semantic, Syntactic, and Context-aware natural language AEs generator. SSCAE identifies important words and uses a masked language model to generate an early set of substitutions. Next, two well-known language models are employed to evaluate the initial set in terms of semantic and syntactic characteristics. We introduce (1) a dynamic threshold to capture more efficient perturbations and (2) a local greedy search to generate high-quality AEs. As a black-box method, SSCAE generates humanly imperceptible and context-aware AEs that preserve semantic consistency and the source language's syntactical and grammatical requirements. The effectiveness and superiority of the proposed SSCAE model are illustrated with fifteen comparative experiments and extensive sensitivity analysis for parameter optimization. SSCAE outperforms the existing models in all experiments while maintaining a higher semantic consistency with a lower query number and a comparable perturbation rate.}
}


@article{DBLP:journals/tdsc/LiuLZR24,
	author = {Jian Liu and
                  Peilun Li and
                  Fan Zhang and
                  Kui Ren},
	title = {{\textdollar}{\textbackslash}mathsf \{monoCash\}{\textdollar}monoCash:
                  {A} Channel-Free Payment Network via Trusted Monotonic Counters},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4770--4783},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3354927},
	doi = {10.1109/TDSC.2024.3354927},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuLZR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptocurrencies such as Bitcoin and Ethereum are gaining popularity thanks to their prominent advantages compared to legacy financial transaction systems. However, they require all participants to reach a consensus on the order of transactions, which fundamentally limits their performance in terms of confirmation latency and throughput, thus hindering their further deployment. Off-chain payment network is the state-of-the-art approach of solving this performance issue. Unfortunately, all existing payment networks are based on payment channels, which bring extra overhead, cost and vulnerabilities. In this paper, by leveraging trusted monotonic counters, we propose \\mathsf {monoCash}\n, the first off-chain payment network that is channel-free, thereby it is one-hop, routing-free, concurrency-friendly, rebalancing-free and wormhole-resilient. We implement and deploy \\mathsf {monoCash}\non a wide area network of 3 000 nodes. The benchmark shows that it provides a throughput up to 30 000 transactions per second (higher than credit card systems, e.g., VISA).}
}


@article{DBLP:journals/tdsc/LiuLWXL24,
	author = {Gao Liu and
                  Hao Li and
                  Ning Wang and
                  Tao Xiang and
                  Yi{-}Ning Liu},
	title = {DeGKM: Decentralized Group Key Management for Content Push in Integrated
                  Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4784--4800},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3359240},
	doi = {10.1109/TDSC.2024.3359240},
	timestamp = {Sun, 19 Jan 2025 13:48:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuLWXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Group-based content push can be widely applied in integrated networks, where group key management is crucial for the push's security. Existing group key management methods mainly include symmetric group key agreement, broadcast encryption, asymmetric group key agreement, and attribute-based encryption. However, most of them do not consider user equipment (UE) identity privacy and unlinkability, cannot support flexibility and efficiency due to each UE maintaining group keys, and lack the trustworthiness of UE and group key management, which hinders the widespread adoption of group-based content push in trustless environments like integrated networks. In this paper, we investigate a novel decentralized group key management (DeGKM) scheme for group-based content push in integrated networks, where different operators manage pseudonyms and group keys across domains in a decentralized manner. In particular, our scheme adopts verifiable shuffling to establish a unified and trustworthy inter-domain pseudonym management approach that can preserve UE identity privacy and pseudonym unlinkability without relying on a trusted third party, and introduces a unified inter-domain group key management method based on Chinese remainder theorem and blockchain that significantly guarantees the flexibility, efficiency and trustworthiness. We formally prove the security of DeGKM and show its efficiency through simulations and comparisons with related works.}
}


@article{DBLP:journals/tdsc/ZhaoGWZ24,
	author = {Yiru Zhao and
                  Long Gao and
                  Qiang Wei and
                  Lei Zhao},
	title = {Towards Tightly-Coupled Hybrid Fuzzing via Excavating Input Specifications},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4801--4814},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3361008},
	doi = {10.1109/TDSC.2024.3361008},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhaoGWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hybrid fuzzing, which combines fuzzing and concolic execution based on the observation that these two types of techniques are complementary, has recently become a research focus. Several hybrid fuzzing studies have shown that concolic execution can assist fuzzing in exploring deeper program states and discovering more vulnerabilities. Despite advances in hybrid fuzzing, most existing techniques employ a result-oriented scheme in which fuzzing and concolic execution cooperate by synchronizing generated test cases. Such cooperation underestimates the sophisticated analysis of concolic execution on the program. Based on the observation that concolic execution can generate abundant program states, which are desirable to be investigated for improving the performance of hybrid fuzzing, we propose a tightly-coupled hybrid fuzzing technique by excavating input specifications from concolic execution. Specifically, we define and excavate three input specification types: critical region, critical value, and type inference. We further design new fuzzing mutation algorithms to leverage them to guide the exploration of the program states. We implement three prototypes, Gear-Driller, Gear-DigFuzz and Gear-QSYM, on top of Driller, DigFuzz and QSYM, respectively. Experimental results show that Gear-Driller, Gear-DigFuzz and Gear-QSYM outperform Driller, DigFuzz and QSYM with larger code coverage, more discovered vulnerabilities, and higher efficiency in finding vulnerabilities.}
}


@article{DBLP:journals/tdsc/TianGXLX24,
	author = {Wenlong Tian and
                  Jian Guo and
                  Zhiyong Xu and
                  Ruixuan Li and
                  Weijun Xiao},
	title = {PEO-Store: Delegation-Proof Based Oblivious Storage With Secure Redundancy
                  Elimination},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4815--4826},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3361450},
	doi = {10.1109/TDSC.2024.3361450},
	timestamp = {Sun, 19 Jan 2025 13:48:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/TianGXLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, Oblivious Storage has been proposed to prevent privacy leakage from user access patterns, which obfuscates and makes it computationally indistinguishable from the random sequences by fake accesses and probabilistic encryption. The same data exhibits distinct ciphertexts. Thus, it seriously impedes cloud providers’ efforts to improve storage utilization to remove user redundancy, which has been widely used in the existing cloud storage scenario. Inspired by the successful adoption of removing duplicate data in cloud storage, we attempt to integrate obliviousness, remove redundancy, and propose a practical oblivious storage, PEO-Store. Instead of fake accesses, introducing delegates breaks the mapping link between a valid access pattern and a specific client. The cloud interacts only with randomly authorized delegates. This design leverages non-interactive zero-knowledge-based redundancy detection, discrete logarithm problem-based key sharing, and secure time-based delivery proof. These components collectively protect access pattern privacy, accurately eliminate redundancy, and prove the data delivery among delegates and the cloud. Theoretical proof demonstrates that, in our design, the probability of identifying the valid access pattern with a specific client is negligible. Experimental results show that PEO-Store outperforms state-of-the-art methods, achieving an average throughput of up to 3 times faster and saving 74% of storage space.}
}


@article{DBLP:journals/tdsc/ChenliTLJ24,
	author = {Changhao Chenli and
                  Wenyi Tang and
                  Hyeonbum Lee and
                  Taeho Jung},
	title = {Fair{\textdollar}{\^{}}\{2\}{\textdollar}2Trade: Digital Trading Platform
                  Ensuring Exchange and Distribution Fairness},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4827--4842},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3362196},
	doi = {10.1109/TDSC.2024.3362196},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ChenliTLJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online data trading is increasingly prevalent as data are becoming valuable assets. In most common conventional data trading scenarios, three parties (seller, broker, and buyer) exist, and fairness in trading is essential. This article discusses and solves the fairness problem in two aspects. First, we consider exchange fairness, which requires payments and data exchanged correctly between buyers and the broker. In existing solutions, keys of encrypted data are traded. However, these solutions failed to provide a complete and secure design for validating keys’ correctness unless they used generic theoretical but expensive methods, e.g., zk-SNARK. We address this security issue by designing a new key verification mechanism. We also present a novel atomic exchange protocol based on Hashed Timelock Contracts on Ethereum, reducing gas consumption compared to the existing approach. Second, we consider distribution fairness, which requires correctly splitting income between the broker and sellers. Straightforward solutions are impractical, i.e., sellers participating in every transaction or traversing the blockchain. Therefore, we design a verifiable statement protocol for sellers to verify the income split efficiently. Further, analysis and experimental results indicate that extra fairness properties are securely achieved, and our protocol reduces users’ on-chain participation compared to state-of-the-art protocols.}
}


@article{DBLP:journals/tdsc/GuoWSHMJXG24,
	author = {Hanxi Guo and
                  Hao Wang and
                  Tao Song and
                  Yang Hua and
                  Ruhui Ma and
                  Xiulang Jin and
                  Zhengui Xue and
                  Haibing Guan},
	title = {Siren{\textdollar}{\^{}}+{\textdollar}+: Robust Federated Learning
                  With Proactive Alarming and Differential Privacy},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4843--4860},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3362534},
	doi = {10.1109/TDSC.2024.3362534},
	timestamp = {Wed, 12 Feb 2025 14:31:22 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/GuoWSHMJXG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL), an emerging machine learning paradigm that trains a global model across distributed clients without violating data privacy, has recently attracted significant attention. However, FL's distributed nature and iterative training extensively increase the attacking surface for Byzantine and inference attacks. Existing FL defense methods can hardly protect FL from both Byzantine and inference attacks due to their fundamental conflicts. The noise injected to defend against inference attacks interferes with model weights and training data, obscuring model analysis that Byzantine-robust methods utilize to detect attacks. Besides, the practicability of existing Byzantine-robust methods is limited since they heavily rely on model analysis. In this article, we present Siren^+\n, a new robust FL system that defends against a wide spectrum of Byzantine attacks and inference attacks by jointly utilizing a proactive alarming mechanism and local differential privacy (LDP). The proactive alarming mechanism orchestrates clients and the FL server to collaboratively detect attacks using distributed alarms, which are free from the noise interference injected by LDP. Compared with the state-of-the-art defense methods, Siren^+\ncan protect FL from Byzantine and inference attacks from a higher proportion of malicious clients in the system while keeping the global model performing normally. Extensive experiments with diverse settings and attacks on real-world datasets show that Siren^+\noutperforms existing defense methods when attacked by Byzantine and inference attacks.}
}


@article{DBLP:journals/tdsc/ZhengLHLLS24,
	author = {Zhirun Zheng and
                  Zhetao Li and
                  Cheng Huang and
                  Saiqin Long and
                  Mushu Li and
                  Xuemin Shen},
	title = {Data Poisoning Attacks and Defenses to LDP-Based Privacy-Preserving
                  Crowdsensing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4861--4878},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3363507},
	doi = {10.1109/TDSC.2024.3363507},
	timestamp = {Mon, 30 Sep 2024 07:53:49 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhengLHLLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we explore data poisoning attacks and their defenses in local differential privacy (LDP)-based crowdsensing systems. First, we construct data poisoning attacks launched by corrupted workers to subvert crowdsensing results by tampering information reported. Specifically, the attacks are formulated as a bi-level optimization problem where attackers strive to conceal their malicious behavior by delicately exploiting noise perturbation introduced by LDP protocols. In this way, the attacks can not be detected, even with the weight-based truth discovery methods. Due to the NP-hard nature of the bi-level problem, we decompose it into upper-level and lower-level sub-problems and employ the augmented Lagrangian method to iteratively solve them, ultimately identifying optimal attack strategies. Second, we propose corresponding countermeasures to defend against the attacks. The countermeasures are formulated as a minimization problem, with the objective of minimizing disruptions caused by attacks through the identification and removal of corrupted workers from crowdsensing systems. To solve the problem, we utilize a differential evolution algorithm instead of gradient-based methods since the objective function of the problem is not differentiable. Extensive experiments on real-world datasets are conducted to evaluate the performance of the proposed attacks and defenses. The evaluation results demonstrate that LDP perturbation indeed facilitates the success of data poisoning attacks, and the proposed defenses can accurately distinguish malicious behaviors disguised.}
}


@article{DBLP:journals/tdsc/CaiLYLW24,
	author = {Jianping Cai and
                  Ximeng Liu and
                  Qingqing Ye and
                  Yang Liu and
                  Yuyang Wang},
	title = {A Federated Learning Framework Based on Differentially Private Continuous
                  Data Release},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4879--4894},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3364060},
	doi = {10.1109/TDSC.2024.3364060},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/CaiLYLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) provides a learning framework without participants sharing local raw data, but individual privacy is still at risk of disclosure through attacking the trained models. Due to the strong privacy guarantee, differential privacy (DP) is widely applied to FL to avoid privacy leakage. Traditional private learning adds noise directly to the gradients. The continuous accumulated noise on parameter models severely impairs learning effectiveness. To solve this problem, we introduce the idea of differentially private continuous data release (DPCR) into FL and propose an FL framework based on DPCR (FL-DPCR). Meanwhile, our proposed Equivalent Aggregation Theorem demonstrates that DPCR effectively reduces the overall error added to parameter models and improves FL's accuracy. To improve FL-DPCR's learning effectiveness, we introduce Matrix Mechanism to construct a release strategy and design a binary-indexed-tree (BIT) based DPCR model for Gaussian mechanism (BCRG). By solving a complex nonlinear programming problem with negative exponents, BCRG achieves optimal release accuracy efficiently. Besides, we exploit the residual privacy budget to boost the accuracy further and propose an advanced BCRG version (ABCRG). Our experiments show that, compared to traditional FL with DP, our achievements improve the accuracy with gains ranging from 3.4% on FMNIST to 65.7% on PAMAP2.}
}


@article{DBLP:journals/tdsc/YangSDZLZ24,
	author = {Hao Yang and
                  Shiyu Shen and
                  Wangchen Dai and
                  Lu Zhou and
                  Zhe Liu and
                  Yunlei Zhao},
	title = {Phantom: {A} CUDA-Accelerated Word-Wise Homomorphic Encryption Library},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4895--4906},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3363900},
	doi = {10.1109/TDSC.2024.3363900},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/YangSDZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Homomorphic encryption (HE) is a promising technique for privacy-preserving computations, especially the word-wise HE schemes that allow batching. However, the high computational overhead hinders the deployment of HE in real-word applications. GPUs are often used to accelerate execution, but a comprehensive performance comparison of different schemes on the same platform is still missing. In this work, we fill this gap by implementing three word-wise HE schemes BGV, BFV, and CKKS on GPU, with both theoretical and engineering optimizations. We enhance the hybrid key-switching technique, significantly reducing the computational and memory overhead. We explore several kernel fusing strategies to reuse data, resulting in reduced memory access and IO latency, and enhancing the overall performance. By comparing with the state-of-the-art works, we demonstrate the effectiveness of our implementation. Meanwhile, we introduce a unified framework that finely integrates our implementation of the three schemes, covering almost all scheme functions and homomorphic operations. We optimize the management of pre-computation, RNS bases, and memory in the framework, to provide efficient and low-latency data access and transfer. Based on this framework, we provide a thorough benchmark of the three schemes, which can serve as a reference for scheme selection and implementation in constructing privacy-preserving applications.}
}


@article{DBLP:journals/tdsc/CuiTZMNS24,
	author = {Qi Cui and
                  Weixuan Tang and
                  Zhili Zhou and
                  Ruohan Meng and
                  Guoshun Nan and
                  Yun{-}Qing Shi},
	title = {Meta Security Metric Learning for Secure Deep Image Hiding},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4907--4920},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3363692},
	doi = {10.1109/TDSC.2024.3363692},
	timestamp = {Sun, 19 Jan 2025 13:48:34 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/CuiTZMNS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Image Hiding (DIH) aims to imperceptibly hide images within image. To improve its security performance, some DIH methods design Security Metrics (SMs) to guide the learning of their hiding networks. However, these methods focus on optimizing their anti-steganalysis ability on specific SMs, resulting in inferior generalization ability. To overcome these limitations, in this paper, we introduce meta-learning into DIH and propose Meta Security Metric-based DIH (MSM-DIH). In the MSM-DIH, the Invertible Neural Network (INN)-based hiding network is learned under the guidance of a learnable meta SM generalized from multiple fixed source SMs, and each SM is composed of a metric network and a contrastive loss function. Specifically, MSM-DIH is trained with bi-level optimization. In the outer optimization, a meta SM is learned to assign higher security scores for more advanced stego images. Besides, the domain knowledge of steganalysis is transferred from the multiple pre-trained source metric networks to the meta metric network, so as to enhance the generalization ability of the meta SM. In the inner optimization, the hiding network is learned to generate more secure stego images according to the learned meta SM. Experimental results show that our MSM-DIH has achieved the best security performance in most cases.}
}


@article{DBLP:journals/tdsc/ChenCYLH24,
	author = {Hongyang Chen and
                  Pengfei Chen and
                  Guangba Yu and
                  Xiaoyun Li and
                  Zilong He},
	title = {MicroFI: Non-Intrusive and Prioritized Request-Level Fault Injection
                  for Microservice Applications},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4921--4938},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3363902},
	doi = {10.1109/TDSC.2024.3363902},
	timestamp = {Sun, 19 Jan 2025 13:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ChenCYLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microservice is a widely-adopted architecture for constructing cloud-native applications. To test application resiliency, chaos engineering is widely used to inject faults proactively in applications. However, the searching space formed by possible injection locations is huge due to the scale and complexity of the application. Although some methods are proposed to effectively explore injection space, they cannot prioritize high-impact injection solutions. Additionally, the blast radius of faults injected by existing methods is typically full of uncertainty, causing faults of multiple application functions. Although some tools are designed to conduct request-level injection, they require instrumentation on application code. To tackle these problems, this paper presents MicroFI, a non-intrusive fault injection framework, aiming to efficiently test different application functions with request-level injection. Request-level injection limits the blast radius to specified requests without any source code modification. Additionally, MicroFI leverages historical injection results and parallel technique to accelerate the searching. Moreover, An enhanced PageRank is used to measure the impact of faults and prioritize high-impact faults that fail more functions. Evaluations on three microservice applications show that MicroFI precisely injects faults and reduces up to 91% redundant faults on average. Additionally, by employing prioritization, MicroFI reduces an average of 47.3% injection budgets to cover all high-impact faults.}
}


@article{DBLP:journals/tdsc/FengLYXW24,
	author = {Xia Feng and
                  Haiyang Liu and
                  Haowei Yang and
                  Qingqing Xie and
                  Liangmin Wang},
	title = {Batch-Aggregate: Efficient Aggregation for Private Federated Learning
                  in VANETs},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4939--4952},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3364371},
	doi = {10.1109/TDSC.2024.3364371},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/FengLYXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) in Vehicular Ad-hoc Networks (VANETs) enables vehicles to collaboratively train machine learning models by aggregating local gradients without revealing the training data. To ensure no gradient is revealed during aggregation, proposals are using a secret sharing-based strategy. A major bottleneck for applying these proposals in VANETs is the overhead of model aggregation across high-mobility vehicles. Particularly, the communication overhead grows exponentially due to the dynamic of VANETs. In the paper, we propose Batch-Aggregate, an efficient aggregation scheme for FL coping with high mobility and unstable connections of VANETs. By encoding the linear encryption into a short group signature, we combine authentication into aggregation protocol. When a registered vehicle trains its local model and sends the masked gradients to the nearby Road-side Unit (RSU), the RSU can independently check the gradients for validity and aggregate the parameters in a batch way. Thus, the computation time of the aggregator will be reduced to \\mathcal {O}(n) while the gradients can be aggregated in one communication round per training iteration. Moreover, our scheme provides privacy properties such as anonymity and unlinkability. The simulations show that the computation overhead of Batch-Aggregate grows linearly under the batch-enabled scheme, which reduces up to 50% over the existing schemes.}
}


@article{DBLP:journals/tdsc/YuKMBL24,
	author = {Alian Yu and
                  Jian Kang and
                  Joshua Morris and
                  Elisa Bertino and
                  Dan Lin},
	title = {Fight Malware Like Malware: {A} New Defense Method Against Crypto
                  Ransomware},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4953--4966},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3364209},
	doi = {10.1109/TDSC.2024.3364209},
	timestamp = {Sun, 19 Jan 2025 13:48:33 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/YuKMBL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ransomware attacks have become widespread in the last few years and have affected many critical industries and infrastructures. Unfortunately, there are no recovery tools that can effectively defend against all types of ransomware. Approaches, such as frequent data backups, have several drawbacks. They are expensive in terms of resources and trained technical staff. Therefore, it is much more challenging and cost-consuming for average users and small business owners to survive ransomware attacks. To provide an easy-to-use tool for a broader population of users and businesses, we propose a novel ransomware defense mechanism that can be conveniently deployed in modern Windows systems which have over 76% market share as of 2022. The uniqueness of our approach is to fight malware like malware. We leverage Alternate Data Streams, which are sometimes used by malicious applications, to design and implement a data protection method that misleads the ransomware into attacking only file “shells” instead of the actual file content. We have evaluated our approach against different cryptographic ransomware. The results show that our approach is usable, efficient, and effective.}
}


@article{DBLP:journals/tdsc/ChenZLLCZJ24,
	author = {Jinyin Chen and
                  Haibin Zheng and
                  Tao Liu and
                  Jiawei Liu and
                  Yao Cheng and
                  Xuhong Zhang and
                  Shouling Ji},
	title = {EdgePro: Edge Deep Learning Model Protection via Neuron Authorization},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4967--4981},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3365730},
	doi = {10.1109/TDSC.2024.3365730},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/ChenZLLCZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of deep learning processors and accelerators, deep learning models have been widely deployed on edge devices as part of the Internet of Things. Edge device models are generally considered as valuable intellectual properties that are worth for careful protection. Unfortunately, these models have a great risk of being stolen or illegally copied. The existing model protections using encryption algorithms are suffered from high computation overhead which is not practical due to the limited computing capacity on edge devices. In this work, we propose a light-weight, practical, and general Edge device model Protection method at neuron level, denoted as EdgePro. Specifically, we select several neurons as authorization neurons and set their activation values to locking values and scale the neuron outputs during training, where the authorization neurons, locking value, and scale factor together form the “passwords”. Then, we design lock training to implement model property protection through alternately locking and releasing, which correspond to model performance preservation and encryption, respectively. EdgePro protects the model by ensuring it can only work correctly when the “passwords” are met, at the cost of encrypting and storing the information of the “passwords” instead of the whole model. Extensive experimental results indicate that EdgePro can work well on the task of protecting models on different datasets. The inference time increase of EdgePro is only 60% of state-of-the-art methods, and the accuracy loss is less than 1%. Additionally, EdgePro is robust against adaptive attacks including fine-tuning, reverse engineering, and pruning, which makes it more practical in real-world applications.}
}


@article{DBLP:journals/tdsc/YangCZ24,
	author = {Qiang Yang and
                  Kaiyan Cui and
                  Yuanqing Zheng},
	title = {Room-Scale Voice Liveness Detection for Smart Devices},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4982--4996},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3367269},
	doi = {10.1109/TDSC.2024.3367269},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YangCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Voice assistants are widely integrated into a variety of mobile devices, enabling users to easily complete daily tasks and even critical operations like online transactions with voice commands. Thus, once attackers replay a secretly-recorded voice command by loudspeakers to compromise users’ voice assistants, this operation will cause serious consequences, such as information leakage and property loss. Unfortunately, most voice liveness detection approaches against replay attacks mainly rely on detecting lip motions or subtle physiological features in speech, which are limited within a very short range. In this article, we propose VoShield to check whether a voice command is from a genuine user or a loudspeaker imposter. VoShield measures sound field dynamics, a feature that changes fast as the human mouths dynamically open and close. In contrast, it would remain rather stable for loudspeakers due to the fixed size. This feature enables VoShield to largely extend the working distance and remain resilient to user locations. Besides, sound field dynamics are extracted from the difference between multiple microphone channels, making this feature robust to voice volume. To evaluate VoShield, we conducted comprehensive experiments with various settings in different working scenarios. The results show that VoShield can achieve a detection accuracy of 98.2% and an Equal Error Rate of 2.0%, which serves as a promising complement to current voice authentication systems for smart mobile devices.}
}


@article{DBLP:journals/tdsc/MaSXWX24,
	author = {Wanlun Ma and
                  Yiliao Song and
                  Minhui Xue and
                  Sheng Wen and
                  Yang Xiang},
	title = {The "Code" of Ethics: {A} Holistic Audit of {AI} Code Generators},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {4997--5013},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3367737},
	doi = {10.1109/TDSC.2024.3367737},
	timestamp = {Wed, 16 Oct 2024 16:36:24 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/MaSXWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {AI-powered programming language generation (PLG) models have gained increasing attention due to their ability to generate source code of programs in a few seconds with a plain program description. Despite their remarkable performance, many concerns are raised over the potential risks of their development and deployment, such as legal issues of copyright infringement induced by training usage of licensed code, and malicious consequences due to the unregulated use of these models. In this article, we present the first-of-its-kind study to systematically investigate the accountability of PLG models from the perspectives of both model development and deployment. In particular, we develop a holistic framework not only to audit the training data usage of PLG models, but also to identify neural code generated by PLG models as well as determine its attribution to a source model. To this end, we propose using membership inference to audit whether a code snippet used is in the PLG model's training data. In addition, we propose a learning-based method to distinguish between human-written code and neural code. In neural code attribution, through both empirical and theoretical analysis, we show that it is impossible to reliably attribute the generation of one code snippet to one model. We then propose two feasible alternative methods: one is to attribute one neural code snippet to one of the candidate PLG models, and the other is to verify whether a set of neural code snippets can be attributed to a given PLG model. The proposed framework thoroughly examines the accountability of PLG models which are verified by extensive experiments. The implementations of our proposed framework are also encapsulated into a new artifact, named CodeForensic, to foster further research.}
}


@article{DBLP:journals/tdsc/DuanZWWHG24,
	author = {Junke Duan and
                  Shihui Zheng and
                  Wei Wang and
                  Licheng Wang and
                  Xiaoya Hu and
                  Lize Gu},
	title = {Concise RingCT Protocol Based on Linkable Threshold Ring Signature},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {5014--5028},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3367888},
	doi = {10.1109/TDSC.2024.3367888},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DuanZWWHG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ring Confidential Transactions (RingCT) is a typical privacy-preserving protocol for blockchain, which is used for the most popular anonymous cryptocurrency Monero in recent years. RingCT provides the user's identity anonymity based on the linkable ring signature. At the cost of that, the transaction size is increased linearly to the involved users. In this article, we aim to overcome this inefficient aspect of RingCT by introducing the linkable threshold ring signature (LTRS). We first propose a construction of threshold ring signatures for homomorphic cryptosystems, and present an efficient instantiation based on the intractability assumption of the discrete logarithm problem. Based on this framework, an efficient LTRS scheme and a novel construction of the RingCT protocol are presented. Our proposed RingCT protocol enables multiple payers to co-construct an anonymous transaction without revealing their secret account keys, and it is more concise under multiple input accounts. For a transaction with a ring size of 100 and the input accounts number of 64, the communication overhead is about 4% of the original RingCT protocol.}
}


@article{DBLP:journals/tdsc/YuZDYWXJC24,
	author = {Chuer Yu and
                  Xuhong Zhang and
                  Yuxuan Duan and
                  Senbo Yan and
                  Zonghui Wang and
                  Yang Xiang and
                  Shouling Ji and
                  Wenzhi Chen},
	title = {Diff-ID: An Explainable Identity Difference Quantification Framework
                  for DeepFake Detection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {5029--5045},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3364679},
	doi = {10.1109/TDSC.2024.3364679},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/YuZDYWXJC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, DeepFake technologies have seen widespread adoption in various domains, including entertainment and film production. However, they have also been maliciously employed for disseminating false information and engaging in video fraud. Existing detection methods often experience significant performance degradation when confronted with unknown forgeries or exhibit limitations when dealing with low-quality images. To address this challenge, we introduce Diff-ID, a novel approach designed to elucidate and quantify the identity loss induced by facial manipulations. When assessing the authenticity of an image, Diff-ID leverages a genuine image of the same individual as a reference and processes two images jointly. It aligns the reference image and the test image into the same identity-insensitive attribute feature space using a face-swapping generator. This alignment allows us to observe the identity disparities between the two images through the differences in the aligned generation pairs. Subsequently, we have developed a custom metric designed to quantify the identity loss relative to the reference image in the test image. This metric effectively distinguishes forgery images from the real ones. Extensive experiments have demonstrated the exceptional performance of our approach. It achieves a high level of detection accuracy on DeepFake images and showcases state-of-the-art generalization capabilities when confronted with previously unknown forgery methods. Moreover, it exhibits robustness even in the presence of image distortions.}
}


@article{DBLP:journals/tdsc/DuanPXHL24,
	author = {Haohua Duan and
                  Zedong Peng and
                  Liyao Xiang and
                  Yuncong Hu and
                  Bo Li},
	title = {A Verifiable and Privacy-Preserving Federated Learning Training Framework},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {5},
	pages = {5046--5058},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3369658},
	doi = {10.1109/TDSC.2024.3369658},
	timestamp = {Fri, 20 Sep 2024 14:01:59 +0200},
	biburl = {https://dblp.org/rec/journals/tdsc/DuanPXHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning allows multiple clients to collaboratively train a global model without revealing their private data. Despite its success in many applications, it remains a challenge to prevent malicious clients to corrupt the global model through uploading incorrect model updates. Hence, one critical issue arises in how to validate the training is truly conducted on legitimate neural networks. To address the issue, we propose VPNNT, a zero-knowledge proof scheme for neural network backpropagation. VPNNT enables each client to prove to others that the model updates (gradients) are indeed calculated on the global model of the previous round, without leaking any information about the client's private training data. Our proof scheme is generally applicable to any type of neural network. Different from conventional verification schemes constructing neural network operations by gate-level circuits, we improve verification efficiency by formulating the training process using custom gates — matrix operations, and apply an optimized linear time zero knowledge protocol for verification. Thanks to the recursive structure of neural network backward propagation, common custom gates are combined in verification thereby reducing prover and verifier costs over conventional zero knowledge proofs. Experimental results show that VPNNT is a lightweighted verification scheme for neural network backpropagation with an improved prove time, verification time and proof size.}
}


@article{DBLP:journals/tdsc/WangHMXS24,
	author = {Wansen Wang and
                  Wenchao Huang and
                  Zhaoyi Meng and
                  Yan Xiong and
                  Cheng Su},
	title = {Advancing the Automation Capability of Verifying Security Protocols},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5059--5070},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3368131},
	doi = {10.1109/TDSC.2024.3368131},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WangHMXS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current formal approaches have been successfully used to find design flaws in many security protocols. However, it is still challenging to automatically analyze protocols due to their large or infinite state spaces. In this paper, we propose SmartVerif, a novel and general framework that pushes the limit of automation capability of Tamarin, a state-of-the-art protocol verifier. The primary technical contribution is the dynamic strategy inside SmartVerif, which can be used to smartly search proof trees. Different from the existing static strategies, our dynamic strategy can automatically optimize itself according to the security protocols without any human intervention. We implement the strategy by modifying Tamarin and introducing a reinforcement learning algorithm to avoid non-terminating paths in the proof tree. Besides, to improve SmartVerif, we add multiple extracted information for training the reinforcement learning network and design a submodule of Non-termination Estimation to collect training data precisely and rapidly. Experimental results show that SmartVerif can automatically verify all security protocols studied in this paper. The case study validates the efficiency of our dynamic strategy. The experimental results also demonstrate the effectiveness of our extracted information, and the accuracy of the submodule of Non-termination Estimation.}
}


@article{DBLP:journals/tdsc/TongZWCNH24,
	author = {Fei Tong and
                  Yuanhang Zhou and
                  Kaiming Wang and
                  Guang Cheng and
                  Jianyu Niu and
                  Shibo He},
	title = {A Privacy-Preserving Incentive Mechanism for Mobile Crowdsensing Based
                  on Blockchain},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5071--5085},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3368655},
	doi = {10.1109/TDSC.2024.3368655},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/TongZWCNH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile crowdsensing (MCS) is an efficient approach for large-scale sensing data collection by leveraging the mobility and capability of mobile devices. To avoid the weaknesses of traditional centralized crowdsensing systems, blockchain has been introduced to secure the process of MCS. This article studies a location-aware scenario, where privacy of users are protected in a blockchain- based MCS system, and formulates an optimization problem to maximize the coverage given a budget based on reverse auction. An incentive mechanism named MMCB is further proposed and implemented as smart contracts in blockchain to solve the problem. We demonstrate that the mechanism achieves a set of desirable properties, including computation efficiency, individual rationality, truthfulness, budget feasibility, approximation, and privacy preservation. To protect the identity privacy of workers and obtain anonymity, a linkable ring signature is employed in smart contracts. In addition, a Pedersen commitment is utilized for protecting workers’ bid profile and the submitted sensing data is encrypted and only accessible to the requester. We implement a prototype system based on the Hyperledger Fabric platform, and the evaluation results show that our privacy-preserving incentive mechanism architecture improves 36.2% coverage and reduces 53.1% payment with better security level compared to the state-of-the-art schemes.}
}


@article{DBLP:journals/tdsc/ZhaoDLLY24,
	author = {Liangrong Zhao and
                  J{\'{e}}r{\'{e}}mie Decouchant and
                  Joseph K. Liu and
                  Qinghua Lu and
                  Jiangshan Yu},
	title = {Trusted Hardware-Assisted Leaderless Byzantine Fault Tolerance Consensus},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5086--5097},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3357521},
	doi = {10.1109/TDSC.2024.3357521},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhaoDLLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Byzantine Fault Tolerance (BFT) Consensus protocols with trusted hardware assistance have been extensively explored for their improved resilience to tolerate more faulty processes. Nonetheless, the potential of trust hardware has been scarcely investigated in leaderless BFT protocols. RedBelly is assumed to be the first blockchain network whose consensus is based on a truly leaderless BFT algorithm. This paper proposes a trusted hardware-assisted leaderless BFT consensus protocol by offering a hybrid solution for the set BFT problem defined in the RedBelly blockchain. Drawing on previous studies, we present two crucial trusted services: the counter and the collector. Based on these two services, we introduce two primitives to formulate our leaderless BFT protocol: a hybrid verified broadcast (VRB) protocol and a hybrid binary agreement. The hybrid VRB protocol enhances the hybrid reliable broadcast protocol by integrating a verification function. This addition ensures that a broadcast message is verified not only for authentication but also for the correctness of its content. Our hybrid BFT consensus is integrated with these broadcast protocols to deliver binary decisions on all proposals. We prove the correctness of the proposed hybrid protocol and demonstrate its enhanced performance in comparison to the prior trusted BFT protocol.}
}


@article{DBLP:journals/tdsc/YaoZGTPZZC24,
	author = {Zeming Yao and
                  Hangtao Zhang and
                  Yicheng Guo and
                  Xin Tian and
                  Wei Peng and
                  Yi Zou and
                  Leo Yu Zhang and
                  Chao Chen},
	title = {Reverse Backdoor Distillation: Towards Online Backdoor Attack Detection
                  for Deep Neural Network Models},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5098--5111},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3369751},
	doi = {10.1109/TDSC.2024.3369751},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/YaoZGTPZZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The backdoor attack on deep neural network models implants malicious data patterns in a model to induce attacker-desirable behaviors. Existing defense methods fall into the online and offline categories, in which the offline models achieve state-of-the-art detection rates but are restricted by heavy computation overhead. In contrast, their more deployable online counterparts lack the means to detect source-specific backdoors with large sizes. This work proposes a new online backdoor detection method—Reverse Backdoor Distillation (RBD) to handle issues associated with source-specific and source-agnostic backdoor attacks. RBD, designed with the novel perspective of distilling instead of erasing backdoor knowledge, is a complementary backdoor detection methodology that can be used in conjunction with other online backdoor defenses. Considering the fact that trigger data will cause overwhelming neuron activation while clean data will not, RBD distills backdoor attack pattern knowledge from a suspicious model to create a shadow model, which is subsequently deployed online along with the original model in scope to predict a backdoor attack. We extensively evaluate RBD on several datasets (MNIST, GTSRB, CIFAR-10) with diverse model architectures and trigger patterns. RBD outperforms online benchmarks in all experimental settings. Notably, RBD demonstrates superior capability in detecting source-specific attacks, where comparison methods fail, underscoring the effectiveness of our proposed technique. Moreover, RBD achieves a computational savings of at least 97%.}
}


@article{DBLP:journals/tdsc/DengLHSWLL24,
	author = {Jingyi Deng and
                  Chenhao Lin and
                  Pengbin Hu and
                  Chao Shen and
                  Qian Wang and
                  Qi Li and
                  Qiming Li},
	title = {Towards Benchmarking and Evaluating Deepfake Detection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5112--5127},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3369711},
	doi = {10.1109/TDSC.2024.3369711},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/DengLHSWLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deepfake detection automatically recognizes the manipulated media by analyzing whether it contains forgeries generated through deep learning. It is natural to ask which among the existing deepfake detection approaches stand out as top performers. This question is pivotal for identifying promising research directions and offering practical guidance. Unfortunately, conducting a sound benchmark comparison of popular detection approaches based on literature results is challenging due to inconsistent evaluation conditions across studies. In this paper, our objective is to achieve a sound comparison between detection approaches by establishing a comprehensive and consistent benchmark, developing a repeatable evaluation procedure, and performing extensive performance evaluation. Accordingly, a challenging dataset consisting of the manipulated samples generated by more than 12 different methods is collected. Subsequently, we implement and evaluate 13 prominent detection approaches (comprising 11 algorithms) from existing literature, utilizing five fair-minded and practical evaluation metrics. Finally, we provide up to 882 comprehensive evaluations by training 117 detection models. The results, along with the shared data and evaluation methodology, constitute a benchmark for comparing deepfake detection approaches and measuring progress.}
}


@article{DBLP:journals/tdsc/MozipoA24,
	author = {Aurelien T. Mozipo and
                  John M. Acken},
	title = {Analysis of Countermeasures Against Remote and Local Power Side Channel
                  Attacks using Correlation Power Analysis},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5128--5142},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3370711},
	doi = {10.1109/TDSC.2024.3370711},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/MozipoA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Countermeasures and deterrents to power side-channel attacks targeting the alteration or scrambling of the power delivery network have been shown to be effective against local attacks where the malicious agent has physical access to the target system. However, remote attacks that capture the leaked information from within the IC power grid are shown herein to be nonetheless effective at uncovering the secret key in the presence of these countermeasures/deterrents. Theoretical studies and experimental analysis are carried out to define and quantify the impact of integrated voltage regulators, voltage noise injection, and integration of on-package decoupling capacitors for both remote and local attacks. An outcome yielded by the studies is that the use of an integrated voltage regulator as a countermeasure is effective for a local attack. However, remote attacks are still effective and hence break the integrated voltage regulator countermeasure. From the experimental analysis, it is observed that within the range of designs' practical values, the adoption of on-package decoupling capacitors provides only a 1.3x increase in the minimum number of traces required to discover the secret key. However, the injection of noise in the IC power delivery network yields a 37x increase in the minimum number of traces to discover. Thus, increasing the number of on-package decoupling capacitors or the impedance between locally measured power and the IC power grid should not be relied on as countermeasures to power side-channel attacks, for remote attack schemes. Noise injection should be considered as it is more effective at scrambling the leaked signal to eliminate sensitive identifying information.}
}


@article{DBLP:journals/tdsc/LuDLY24,
	author = {Siqi Lu and
                  Hanjie Dong and
                  Zhaoxuan Li and
                  Laurence T. Yang},
	title = {Not Just Summing: The Identifier Leakage of Private-Join-and-Compute
                  and its Improvement},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5143--5155},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3371569},
	doi = {10.1109/TDSC.2024.3371569},
	timestamp = {Sun, 12 Jan 2025 00:08:23 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LuDLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we focus on the Private Intersection-Sum (PIS) with cardinality problem: two parties hold datasets containing user identifiers, and the second party additionally has an integer value associated with each user identifier. Both parties want to learn the number of users they have in common, and the sum of the integer values associated with a user, without revealing anything more. To this end, Google proposed a PIS protocol and released the open-source library Private-Join-and-Compute. And the security of the protocol has been proven in the honest-but-curious model. However, this study found a potential shortcoming in the Private-Join-and-Compute library: the user identifier stealing attack against the PIS protocol based on a special input data structure. An improved PIS protocol is proposed based on differential privacy technology, and the Private-Join-and-Compute open-source library is optimized. Through a security proof and formal analysis based on the Tamarin tool, we show that the improved PIS protocol successfully resists the discovered attack without obvious additional overhead.}
}


@article{DBLP:journals/tdsc/LinggaJYK24,
	author = {Patrick Lingga and
                  Jaehoon Jeong and
                  Jinhyuk Yang and
                  Jeonghyeon Kim},
	title = {{SPT:} Security Policy Translator for Network Security Functions in
                  Cloud-Based Security Services},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5156--5169},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3371788},
	doi = {10.1109/TDSC.2024.3371788},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LinggaJYK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interface to Network Security Functions (I2NSF) Working Group within Internet Engineering Task Force (IETF) has developed a framework and its interfaces with YANG data models for configuring Network Security Functions (NSF). These models include a high-level security policy (i.e., an overview of configuration) and a low-level security policy (i.e., a detailed and specific configuration) to facilitate the configuration of NSFs. In this paper, a Security Policy Translator (SPT) is proposed to translate high-level security policies created by users into the corresponding low-level security policies. It leverages the design of I2NSF YANG data models to accurately translate security policies. The SPT performs a translation by extracting the high-level security principles using Deterministic Finite Automaton (DFA) construction from the high-level YANG data model. It converts the extracted information to a low-level form by utilizing a mapping model created by comparing the two YANG data models, such as the Consumer-Facing Interface (CFI) and NSF-Facing Interface (NFI) YANG data models. It selects the optimal NSFs based on the security policies to provide maximum security performance. It generates low-level security policies for the NSFs to deploy the security services. The proposed approach allows security policy translation for the I2NSF framework with high accuracy and speed.}
}


@article{DBLP:journals/tdsc/ZengHZLX24,
	author = {Man Zeng and
                  Xiaohong Huang and
                  Pei Zhang and
                  Dandan Li and
                  Kun Xie},
	title = {Improving Prefix Hijacking Defense of {RPKI} From an Evolutionary
                  Game Perspective},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5170--5184},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3371644},
	doi = {10.1109/TDSC.2024.3371644},
	timestamp = {Sat, 30 Nov 2024 21:09:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZengHZLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Resource Public Key Infrastructure (RPKI) defends against BGP prefix hijacking by signing Route Origin Authorizations (ROAs) and filtering malicious BGP routes with ROAs. However, RPKI's low deployment weakens its defense against prefix hijacking. In the absence of a large fraction of Autonomous Systems (ASes) signing ROAs, the incentive to use filtering to eliminate hijacked prefixes commensurately decreases. There is a cyclic dependency here because reduced filtering in turn lessens the incentive for non-adoptees to become adoptees. Previous studies on RPKI deployment are mainly from the measurement perspective or focus on the deployment of large Internet Service Providers (ISPs). The above circular dependency problem inside the RPKI has not been fully studied. To improve RPKI's defense, this paper studies the circular dependency problem from an evolutionary game theory perspective. We model the strategy evolution of ASes choosing to deploy signing alone, deploy filtering alone, or deploy both signing and filtering. The results show that when the deployment rates of signing and filtering reach a certain range, the evolution can reach an ideal deployment state at a faster speed. Therefore, to increase the probability of evolution reaching the ideal deployment state, we propose RPKIN to widen this interval and reduce the minimum deployment rate required for signing and filtering.}
}


@article{DBLP:journals/tdsc/FanMZLXT24,
	author = {Yongkai Fan and
                  Kaile Ma and
                  Linlin Zhang and
                  Xia Lei and
                  Guangquan Xu and
                  Gang Tan},
	title = {ValidCNN: {A} Large-Scale {CNN} Predictive Integrity Verification
                  Scheme Based on zk-SNARK},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5185--5195},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3371643},
	doi = {10.1109/TDSC.2024.3371643},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/FanMZLXT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The integrity of cloud-based convolutional neural network (CNN) prediction services can be jeopardized by a malicious cloud server. Although zero-knowledge proof approaches can be used to verify integrity, they are difficult to use for larger CNN models like LeNet-5 and VGG16, due to the large cost (in terms of time and storage) of generating a proof. This paper proposes ValidCNN, which can efficiently generate integrity proofs based on zk-SNARK. At the heart of ValidCNN, it is a novel usage of Freivald's concepts for circuit construction, and a more efficient way for verifying matrix multiplication. Our experimental results demonstrate that ValidCNN significantly outperforms the state of the art approaches that are based on zk-SNARK. For example, compared with ZEN, ValidCNN achieves a 12-fold improvement in time and a 31-fold improvement in storage. Compared with vCNN, ValidCNN achieves a 195-fold and 279-fold improvement in time and storage respectively.}
}


@article{DBLP:journals/tdsc/SuZSHZ24,
	author = {Zhaopin Su and
                  Guofu Zhang and
                  Zhiyuan Shi and
                  Donghui Hu and
                  Weiming Zhang},
	title = {Message-Driven Generative Music Steganography Using {MIDI-GAN}},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5196--5207},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3372139},
	doi = {10.1109/TDSC.2024.3372139},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/SuZSHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generative steganography has become a popular research topic in the field of generative AI, including generative image and synthetic speech steganography. However, music files have different statistical properties and knowledge representation compared to image and speech files, and the reversible transform between secret message and music is also challenging. Therefore, the existing generative steganographic methods that are effective for image/speech may not be directly effective for music. In this article, we propose a generative music steganography method, named MIDI-GAN, to generate a secret message as an artificial stego MIDI file using generative adversarial networks (GANs). The created stego MIDI file is small in size, has sweet melodies, and is undetectable to deep learning-based steganalyzers. Unlike the previous generative image/speech steganography, the stego MIDI can also be presented as a sequence of chord numbers, making it difficult for anyone to detect and see grounds for suspicion. Moreover, these chord numbers can be transmitted as any other digital or physical medium to evade detection. Specifically, MIDI-GAN comprises a generator, a discriminator, and an extractor. The generator synthesizes a stego MIDI file from the secret message, while the discriminator ensures that the stego MIDI file approaches the authentic rather than the synthetic MIDI file as much as possible in statistical distribution. The extractor recovers the secret message from the stego MIDI file or chord sequence. Experimental results demonstrate that MIDI-GAN has high concealment and security, as the stego MIDI generated by our method is closely similar to the authentic MIDI files and maintains excellent anti-detection ability against deep learning-based steganalysis.}
}


@article{DBLP:journals/tdsc/AvizhehNS24,
	author = {Sepideh Avizheh and
                  Mahmudun Nabi and
                  Reihaneh Safavi{-}Naini},
	title = {Refereed Delegation of Computation Using Smart Contracts},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5208--5227},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3372848},
	doi = {10.1109/TDSC.2024.3372848},
	timestamp = {Sat, 30 Nov 2024 21:09:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/AvizhehNS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outsourcing computation enables a weak client to expand its computational power as the need arises. A basic requirement of outsourcing computation is the guarantee that the computation result is correct. Cryptographic solutions that provide verifiability for the computation result when the computation is outsourced to a single server, are complex and fragile. We consider the intuitive approach of verifiable computation, called verifiable computation by replication, when the computation is replicated on multiple servers, and a referee decides the result of the final computation using the outputs of all servers. We consider the case when a smart contact is used as the referee. We propose a security model in the Universal Composability (UC) framework of Canetti, and design a 2-server and an n-server protocol with proved security in our model. Our protocols build on the Refereed Delegation of Computation (RDoC) framework of Canetti, Riva, and Rothblum, underline the challenges of using a smart contract as a referee, and address those challenges in the designed protocols. We give the efficiency analysis of the protocols, provide a proof of concept implementation for our protocols using Ethereum smart contact, and give concrete cost values for an example computation.}
}


@article{DBLP:journals/tdsc/ZhangZSLK24,
	author = {Zhixiang Zhang and
                  Hanlin Zhang and
                  Xiangfu Song and
                  Jie Lin and
                  Fanyu Kong},
	title = {Secure Outsourcing Evaluation for Sparse Decision Trees},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5228--5241},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3372505},
	doi = {10.1109/TDSC.2024.3372505},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangZSLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decision tree classifiers are pervasively applied in a wide range of areas, such as healthcare, credit-risk assessment, spam detection, and many more. To ensure effectiveness and efficiency, clients usually choose to adopt classification services that are offered by model providers. However, the required data interactions in the evaluation process raise privacy concerns for both the provider and the client, indicating an imminent need for private decision tree evaluation (PDTE). Recently, some works, e.g., Zheng et al. (2019) (ESORICS’19) and Ma et al. (2021) (NDSS’21), try to achieve PDTE by secure outsourcing computation. However, to hide the decision tree structure, Zheng et al. (2019) and Ma et al. (2021) require non-complete decision trees to be made complete by padding dummy nodes, which lead to exponential (provider-side and cloud-side) computation and communication complexity in the depth of the decision tree. This is especially impractical for deep but sparse decision trees. In this paper, we propose a secure and efficient outsourced PDTE protocol with a focus on sparse trees. We avoid padding dummy nodes by vector dot products in outsourcing settings. Through experiments, we show the competitive performance of our design. Compared with Ma et al. (2021) on Spambase dataset in the cloud-side, we are 486× more communication efficient in offline phase and 15× more communication efficient in online phase.}
}


@article{DBLP:journals/tdsc/ZhangXBWHLQR24,
	author = {Xinyu Zhang and
                  Huiyu Xu and
                  Zhongjie Ba and
                  Zhibo Wang and
                  Yuan Hong and
                  Jian Liu and
                  Zhan Qin and
                  Kui Ren},
	title = {PrivacyAsst: Safeguarding User Privacy in Tool-Using Large Language
                  Model Agents},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5242--5258},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3372777},
	doi = {10.1109/TDSC.2024.3372777},
	timestamp = {Fri, 21 Feb 2025 08:48:13 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangXBWHLQR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Swift advancements in large language model (LLM) technologies lead to widespread research and applications, particularly in integrating LLMs with auxiliary tools, known as tool-using LLM agents. However, amid user interactions, the transmission of private information to both LLMs and tools poses considerable privacy risks to users. In this paper, we delve into current privacy-preserving solutions for LLMs and outline three pivotal challenges for tool-using LLM agents: generalization to both open-source and closed-source LLMs and tools, compliance with privacy requirements, and applicability to unrestricted tasks. To tackle these challenges, we present PrivacyAsst, the first privacy-preserving framework tailored for tool-using LLM agents, encompassing two solutions for different application scenarios. First, we incorporate a homomorphic encryption scheme to ensure computational security guarantees for users as a safeguard against both open-source and closed-source LLMs and tools. Moreover, we propose a shuffling-based solution to broaden the framework's applicability to unrestricted tasks. This solution employs an attribute-based forgery generative model and an attribute shuffling mechanism to craft privacy-preserving requests, effectively concealing individual inputs. In addition, we introduce an innovative privacy concept,\nt\n-closeness in image data, for privacy compliance within this solution. Finally, we implement PrivacyAsst, accompanied by two case studies, demonstrating its effectiveness in advancing privacy-preserving artificial intelligence.}
}


@article{DBLP:journals/tdsc/MuCSLCZM24,
	author = {Xutong Mu and
                  Ke Cheng and
                  Yulong Shen and
                  Xiaoxiao Li and
                  Zhao Chang and
                  Tao Zhang and
                  Xindi Ma},
	title = {FedDMC: Efficient and Robust Federated Learning via Detecting Malicious
                  Clients},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5259--5274},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3372634},
	doi = {10.1109/TDSC.2024.3372634},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/MuCSLCZM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has gained popularity in the field of machine learning, which allows multiple participants to collaboratively learn a highly-accurate global model without exposing their sensitive data. However, FL is susceptible to poisoning attacks, in which malicious clients manipulate local model parameters to corrupt the global model. Existing FL frameworks based on detecting malicious clients suffer from unreasonable assumptions (e.g., clean validation datasets) or fail to balance robustness and efficiency. To address these deficiencies, we propose FedDMC, which implements robust federated learning by efficiently and precisely detecting malicious clients. Specifically, FedDMC first applies principal component analysis to reduce the dimensionality of the model parameters, which retains the primary parameter feature and reduces the computational overhead for subsequent clustering. Then, a binary tree-based clustering method with noise is designed to eliminate the effect of noisy points in the clustering process, facilitating accurate and efficient malicious client detection. Finally, we design a self-ensemble detection correction module that utilizes historical results via exponential moving averages to improve the robustness of malicious client detection. Extensive experiments conducted on three benchmark datasets demonstrate that FedDMC outperforms state-of-the-art methods in terms of detection precision, global model accuracy, and computational complexity.}
}


@article{DBLP:journals/tdsc/ZhangLLXDLC24,
	author = {Fenglu Zhang and
                  Baojun Liu and
                  Chaoyi Lu and
                  Yunpeng Xing and
                  Haixin Duan and
                  Ying Liu and
                  Liyuan Chang},
	title = {Investigating Deployment Issues of {DNS} Root Server Instances From
                  a China-Wide View},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5275--5292},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3373530},
	doi = {10.1109/TDSC.2024.3373530},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangLLXDLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DNS root servers are the starting point of most DNS queries. To ensure their security and stability, multiple anycast instances are operated worldwide, and new root instances have been rapidly deployed in recent years. Apart from authorized instances managed by Root Server System, some networks equip unauthorized instances to hijack queries from clients. Despite various root instances handling queries within their residing networks, few studies have focused on the deployment issues of these instances. In this article, we provide the first study to reveal the deployment issues of root instances from a nationwide view. With the support of 7,860 vantage points, we utilized a suite of methodologies to identify the deployment of unauthorized instances. 54 vantage points witnessed the evidence of unauthorized instances, and 70.4% of them further observed security issues of unauthorized instances, including DoS, unavailability of DNSSEC validation, and vulnerable DNS software. Additionally, we utilized the side-channel information of censorship mechanisms to measure the catchment area of authorized instances. We found that most authorized instances in the Chinese mainland serve with limited catchment areas due to restricted BGP policies. Through discussions with ISPs and network operators, we make recommendations to improve the deployment status of different root instances.}
}


@article{DBLP:journals/tdsc/WuLZZBZR24,
	author = {Sifan Wu and
                  Zhenguang Liu and
                  Beibei Zhang and
                  Roger Zimmermann and
                  Zhongjie Ba and
                  Xiaosong Zhang and
                  Kui Ren},
	title = {Do as {I} Do: Pose Guided Human Motion Copy},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5293--5307},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3371530},
	doi = {10.1109/TDSC.2024.3371530},
	timestamp = {Sat, 30 Nov 2024 21:09:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/WuLZZBZR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human motion copy is an intriguing yet challenging task in artificial intelligence and computer vision, which strives to generate a fake video of a target person performing the motion of a source person. The problem is inherently challenging due to the subtle human-body texture details to be generated and the temporal consistency to be considered. Existing approaches typically adopt a conventional GAN with an L1 or L2 loss to produce the target fake video, which intrinsically necessitates a large number of training samples that are challenging to acquire. Meanwhile, current methods still have difficulties in attaining realistic image details and temporal consistency, which unfortunately can be easily perceived by human observers. Motivated by this, we try to tackle the issues from three aspects. (1) We constrain pose-to-appearance generation with a perceptual loss and a theoretically motivated Gromov-Wasserstein loss to bridge the gap between pose and appearance. (2) We present an episodic memory module in the pose-to-appearance generation to propel continuous learning that helps the model learn from its past poor generations. We also utilize geometrical cues of the face to optimize facial details and refine each key body part with a dedicated local GAN. (3) We advocate generating the foreground in a sequence-to-sequence manner rather than a single-frame manner, explicitly enforcing temporal inconsistency. Empirical results on five datasets, iPER, ComplexMotion, SoloDance, Fish, and Mouse datasets, demonstrate that our method is capable of generating realistic target videos while precisely copying motion from a source video. Our method significantly outperforms state-of-the-art approaches and gains 7.2% and 12.4% improvements in PSNR and FID respectively.}
}


@article{DBLP:journals/tdsc/LiuMWZL24,
	author = {Hang Liu and
                  Yang Ming and
                  Chenhao Wang and
                  Yi Zhao and
                  Yabin Li},
	title = {Comments on "Enabling Verifiable Privacy-Preserving Multi-Type
                  Data Aggregation in Smart Grids"},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5308--5310},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3374955},
	doi = {10.1109/TDSC.2024.3374955},
	timestamp = {Mon, 10 Feb 2025 08:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuMWZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most recently, Zhang et al. (2022) presented a verifiable data aggregation scheme for smart grids in IEEE Transactions on Dependable and Secure Computing. The authors claim that the privacy of the user's electricity data is preserved, and the control center can check whether the aggregator honestly computes the aggregated ciphertext. However, we indicate that Zhang et al.'s scheme fails to provide the properties of data privacy and aggregate correctness guarantee. Specifically, by offering concrete attacks, we illustrate that the adversary who has the ability to obtain the decryption key of control center can decrypt any user's ciphertext to get the detailed electricity data, and a misbehaved aggregator will not be detected when it does have some malicious behavior.}
}


@article{DBLP:journals/tdsc/NguyenSXGCSY24,
	author = {Dinh Duc Nha Nguyen and
                  Keshav Sood and
                  Yong Xiang and
                  Longxiang Gao and
                  Lianhua Chi and
                  Gurpreet Singh and
                  Shui Yu},
	title = {Design and Robust Evaluation of Next Generation Node Authentication
                  Approach},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5311--5323},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3373778},
	doi = {10.1109/TDSC.2024.3373778},
	timestamp = {Sun, 22 Dec 2024 15:49:22 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/NguyenSXGCSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The flexibility of 5G-NGNs makes them an ideal infrastructure for supporting mission-critical IoT applications that require low latency and high bandwidth. However, due to the rapid proliferation and the integration of IoTs with 5G, the threat surface has considerably expanded. Hence the security of IoT devices is a big concern. Unfortunately, IoT devices have limited resources, and the traditional security approaches (authentication and intrusion detection approaches) of cryptography do not work effectively on 5G-IoT ecosystems. Motivated from this, we leverage the distinctive RF (Radio Frequency) fingerprinting signatures of IoT devices and used them to train a Deep learning model, Mahalanobis Distance theory in addition to the Chi-square distribution theory, to authenticate the IoT nodes. Under robust scenarios we have tested the approach shows detection accuracy (99.35%) as well as significant amount of reduction in model's training time as these two metrics are one of the primary key performance indicators (KPIs). In order to evaluate the effectiveness of the proposed method in real-time scenarios, we tested the proposed solution with a real RF dataset and the OSM-MANO 5G platform. The model underwent formal verification using the Tamarin Prover tool, and the proposal was also compared with recent research works.}
}


@article{DBLP:journals/tdsc/FuCCS24,
	author = {Jiaxuan Fu and
                  Ke Cheng and
                  Zhao Chang and
                  Yulong Shen},
	title = {{PPA-DBSCAN:} Privacy-Preserving {\textdollar}{\textbackslash}rho{\textdollar}{\(\rho\)}-Approximate
                  Density-Based Clustering},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5324--5340},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3375347},
	doi = {10.1109/TDSC.2024.3375347},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/FuCCS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clustering is widely used for data analysis that partitions a set of data into multiple clusters, where objects in the same cluster have similar properties. Data for clustering analysis often comes from different data sources, which makes it important to maintain data privacy. However, existing privacy-preserving clustering schemes either require the support of prior knowledge or are just applicable for small datasets due to impractical costs. To solve this issue, we follow a classical approximate DBSCAN clustering algorithm and adapt it to the privacy-preserving context. Concretely, to construct our secure approximate clustering algorithm, we propose a series of basic secure computation protocols among additively secret-shared values. In addition, we design a crypto-friendly grid partitioning method based on which an efficient and privacy-preserving approximation DBSCAN scheme is derived. Theoretical analysis and experimental results show that our scheme achieves almost the same cluster quality compared to the plain-text exact DBSCAN. Our extensive experiments on different datasets demonstrate that our scheme is accurate and efficient.}
}


@article{DBLP:journals/tdsc/HuZZZZZCR24,
	author = {Jilin Hu and
                  Fanlang Zeng and
                  Yongwang Zhao and
                  Zhuoruo Zhang and
                  Leping Zhang and
                  Jianhong Zhao and
                  Rui Chang and
                  Kui Ren},
	title = {ProveriT: {A} Parameterized, Composable, and Verified Model of {TEE}
                  Protection Profile},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5341--5358},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3375311},
	doi = {10.1109/TDSC.2024.3375311},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/HuZZZZZCR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Trusted Execution Environment (TEE) plays a crucial role in modern computer systems and the compromise of TEE can result in enormous losses. Although numerous TEE products have been proposed, most of them lack robust security guarantees. To address this concern, GlobalPlatform (GP) defines the TEE security standard, Protection Profile (PP), which has gained widespread adoption in the TEE development and Common Criteria (CC) evaluation. However, despite its importance, GPTEE PP has never been formally specified and verified. In this article, we present ProveriT, a parameterized, composable, and formally verified model of GPTEE PP. First, we propose the first formal specification of GPTEE PP in a parameterized manner, encompassing the definition of security problems, security objectives, and security functional requirements. Second, we provide a compositional framework, utilizing horizontal calculus and vertical calculus, to flexibly combine specific security functional requirements for TEE developers and reduce proof efforts for verification. ProveriT is extensible and reusable for the verification and CC evaluation of specific TEE products. Third, we conduct a comprehensive formal verification of rationales in the model to ensure the correctness of GPTEE PP. During the verification, 8 issues are discovered and we provide suggestions to resolve them. Finally, we demonstrate the extensibility and effectiveness of ProveriT by applying it to the verification of a commercial TEE. All the specifications and verification are carried out in the Isabelle/HOL theorem prover.}
}


@article{DBLP:journals/tdsc/LiSXHGW24,
	author = {Wenchao Li and
                  Willy Susilo and
                  Chunhe Xia and
                  Luqi Huang and
                  Fuchun Guo and
                  Tianbo Wang},
	title = {Secure Data Integrity Check Based on Verified Public Key Encryption
                  With Equality Test for Multi-Cloud Storage},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5359--5373},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3375369},
	doi = {10.1109/TDSC.2024.3375369},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiSXHGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud computing eliminates the need for local hardware, addressing the challenge of high computing expenses. However, entrusting data to the cloud may pose the risk of unintentional data loss. Using multiple copies and multi-cloud servers is promising because even if the data on one cloud storage server is compromised, the data proprietor can retrieve the information from alternate cloud storage servers. To protect data security, data needs to be encrypted before uploading to the cloud. However, users cannot directly confirm whether their encrypted documents and copies are stored securely and with integrity on cloud servers. To verify data copies on remote servers without downloading and decrypting, we propose Public Verification Public Key Encryption with Equality Test (PVPKEET). Under PVPKEET, users upload encrypted data to cloud servers, and then the test result and proof will be provided by the cloud server without decryption. The publicly verified proof can be examined by all users, allowing everyone to witness the copies stored correctly. Our approach is resistant to chosen-plaintext attacks and is verifiable. A comparison with prior research demonstrates the efficiency and feasibility of our design.}
}


@article{DBLP:journals/tdsc/OrbinatoFCN24,
	author = {Vittorio Orbinato and
                  Marco Carlo Feliciano and
                  Domenico Cotroneo and
                  Roberto Natella},
	title = {Laccolith: Hypervisor-Based Adversary Emulation With Anti-Detection},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5374--5387},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3376129},
	doi = {10.1109/TDSC.2024.3376129},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/OrbinatoFCN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced Persistent Threats (APTs) represent the most threatening form of attack nowadays since they can stay undetected for a long time. Adversary emulation is a proactive approach for preparing against these attacks. However, adversary emulation tools lack the anti-detection abilities of APTs. We introduce Laccolith, a hypervisor-based solution for adversary emulation with anti-detection to fill this gap. We also present an experimental study to compare Laccolith with MITRE CALDERA, a state-of-the-art solution for adversary emulation, against five popular anti-virus products. We found that CALDERA cannot evade detection, limiting the realism of emulated attacks, even when combined with a state-of-the-art anti-detection framework. Our experiments show that Laccolith can hide its activities from all the tested anti-virus products, thus making it suitable for realistic emulations. prova}
}


@article{DBLP:journals/tdsc/XuGDGZLZZ24,
	author = {Chenhao Xu and
                  Jiaqi Ge and
                  Yao Deng and
                  Longxiang Gao and
                  Mengshi Zhang and
                  Yong Li and
                  Wanlei Zhou and
                  Xi Zheng},
	title = {{BASS:} {A} Blockchain-Based Asynchronous SignSGD Architecture for
                  Efficient and Secure Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5388--5402},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3374809},
	doi = {10.1109/TDSC.2024.3374809},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/XuGDGZLZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is a distributed framework for machine learning that enables collaborative training of a shared model across data silos while preserving data privacy. However, the FL aggregation server faces a challenge in waiting for a large volume of model parameters from selected nodes before generating a global model, which leads to inefficient communication and aggregation. Although transmitting only the signs of stochastic gradient descent (SignSGD) reduces the transmission load, it decreases model accuracy, and the time waiting for local model collection remains substantial. Moreover, the security of FL is severely compromised by prevalent poisoning, backdoor, and DDoS attacks, causing ineffective and inaccurate model training. To overcome these challenges, this paper proposes a Blockchain-based Asynchronous SignSGD (BASS) architecture for efficient and secure federated learning. By integrating a blockchain-based semi-asynchronous aggregation scheme with sign-based gradient compression, BASS considerably improves communication and aggregation efficiency, while providing resistance against attacks. Besides, a novel node-summarized sign aggregation algorithm is developed for the blockchain leaders to ensure the convergence and accuracy of the global model. An open-source prototype is developed, on top of which extensive experiments are conducted. The results validate the superiority of BASS in terms of efficiency, model accuracy, and security.}
}


@article{DBLP:journals/tdsc/ChenWL24,
	author = {Yijing Chen and
                  Hongxia Wang and
                  Wanjie Li},
	title = {Constructing Immune-Cover for Improving Holistic Security of Spatial
                  Adaptive Steganography},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5403--5419},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3376815},
	doi = {10.1109/TDSC.2024.3376815},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ChenWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cover image with strong resistance against embedding distortion has promise for improving the holistic security of steganography. However, existing methods use the vulnerability of Convolutional Neural Network (CNN) to construct the enhanced cover which can only deceive the target CNN-based steganalyzer, but is not more suitable for steganography. When resisting steganalysis outside the target steganalyzer, its performance drops significantly. In this paper, we propose an immune-cover construction scheme via Artificial Immune System (AIS). By the association between the steganography and immune theory, we regard the cover as the organism, the distortion introduced by steganography as the pathogenic factor, and the immunoprocessing for optimizing the original cover as the antibody. Based on AIS, the optimal immunoprocessing is dynamically searched and performed on the original cover to construct an immune-cover which is most suitable for steganography. Besides, the proposed method carefully selects the immunoprocessing region to prevent artifacts, and guarantees the visual quality of the immune-cover through the constraint of the immunoprocessing intensity. Extensive experimental results demonstrate that the proposed immune-cover has much stronger resistance against embedding distortion compared with the related methods, thus significantly improving the holistic security of the adaptive steganography evaluated on both traditional and CNN-based steganalyzers.}
}


@article{DBLP:journals/tdsc/YanLZCWLL24,
	author = {Haonan Yan and
                  Xiaoguang Li and
                  Wenjing Zhang and
                  Qian Chen and
                  Bin Wang and
                  Hui Li and
                  Xiaodong Lin},
	title = {{CODER:} Protecting Privacy in Image Retrieval With Differential Privacy},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5420--5430},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3376532},
	doi = {10.1109/TDSC.2024.3376532},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/YanLZCWLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image retrieval techniques can be easily abused to violate personal privacy with images containing individuals’ sensitive information. For example, people's identity information can be inferred from their face photos. Therefore, images should be sanitized before being shared or transmitted. However, previous works on image privacy protection suffer from either no provable privacy protection or poor utility with privacy guarantee. In this work, we propose CODER, a privacy protection mechanism in image retrieval, with provable privacy guarantee as well as improved utility. In particular, CODER achieves metric differential privacy and adopts a newly proposed distortion metric definition which measures the distance more precisely to improve utility. The novel distortion metric can be applied to an arbitrary k-dimensional metric space with stronger image privacy protection. We theoretically analyze the privacy guarantee and rigorous utility bound of CODER. We also experimentally compare its performance with two state-of-the-art works on two widely used face datasets. The results show that CODER significantly improves the utility of the protected images and demonstrates its superiority in terms of the privacy-utility trade-off over the compared works. Finally, we perform reliability verification on both discriminative and generative models to demonstrate the practicality of CODER.}
}


@article{DBLP:journals/tdsc/ShiJPZZYZYW24,
	author = {Chenghui Shi and
                  Shouling Ji and
                  Xudong Pan and
                  Xuhong Zhang and
                  Mi Zhang and
                  Min Yang and
                  Jun Zhou and
                  Jianwei Yin and
                  Ting Wang},
	title = {Towards Practical Backdoor Attacks on Federated Learning Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5431--5447},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3376790},
	doi = {10.1109/TDSC.2024.3376790},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ShiJPZZYZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is nowadays one of the most promising paradigms for privacy-preserving distributed learning. Without revealing its local private data to outsiders, a client in FL systems collaborates to build a global Deep Neural Network (DNN) by submitting its local model parameter update to a central server for iterative aggregation. With secure multi-party computation protocols, the submitted update of any client is also by design invisible to the server. Seemingly, this standard design is a win-win for client privacy and service provider utility. Ironically, any attacker may also use manipulated or impersonated client to submit almost any attack payloads under the umbrella of the FL protocol itself. In this work, we craft a practical backdoor attack on FL systems that is proved to be simultaneously effective and stealthy on diverse use cases of FL systems and leading commercial FL platforms in the real world. Basically, we first identify a small number of redundant neurons which tend to be rarely or slightly updated in the model, and then inject backdoor into these redundant neurons instead of the whole model. In this way, our backdoor attack can achieve a high attack success rate with a minor impact on the accuracy of the original task. As countermeasures, we further consider several common technical choices including robust aggregation mechanisms, differential privacy mechanism,s and network pruning. However, none of the defenses show desirable defense capability against our backdoor attack. Our results strongly highlight the vulnerability of existing FL systems against backdoor attacks and the urgent need to develop more effective defense mechanisms.}
}


@article{DBLP:journals/tdsc/SaadM24,
	author = {Muhammad Saad and
                  David Mohaisen},
	title = {Analyzing In-Browser Cryptojacking},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5448--5460},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3377533},
	doi = {10.1109/TDSC.2024.3377533},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/SaadM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptojacking is the permissionless use of a target device to covertly mine cryptocurrencies. With cryptojacking, attackers use malicious JavaScript codes to force web browsers into solving proof-of-work puzzles, thus making money by exploiting the resources of the website visitors. We systematically analyze the static, dynamic, and economic aspects of in-browser cryptojacking to understand and counter such attacks. For static analysis, we perform currency-based and code-based categorization of cryptojacking samples to 1) measure their distribution across websites, 2) highlight their platform affinities, and 3) study their code complexities. We apply machine learning techniques to distinguish cryptojacking scripts from benign and malicious JavaScript samples with 100% accuracy. For dynamic analysis, we analyze the effect of cryptojacking on critical system resources, such as CPU and battery usage. We also perform web browser fingerprinting to analyze the information exchange between the victim node and the dropzone cryptojacking server. We also build an analytical model to empirically evaluate the feasibility of cryptojacking as an alternative to online advertisement. Our results show a sizeable negative profit and loss gap, indicating that the model is economically infeasible. Finally, leveraging insights from our analyses, we build countermeasures for in-browser cryptojacking that improve the existing remedies.}
}


@article{DBLP:journals/tdsc/GhoshZJS24,
	author = {Sagarika Ghosh and
                  Marzia Zaman and
                  Rohit Joshi and
                  Srinivas Sampalli},
	title = {Multi-Phase Quantum Resistant Framework for Secure Communication in
                  {SCADA} Systems},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5461--5478},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3378474},
	doi = {10.1109/TDSC.2024.3378474},
	timestamp = {Mon, 09 Dec 2024 22:46:25 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/GhoshZJS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Supervisory Control and Data Acquisition (SCADA) systems are vulnerable to traditional cyber-attacks, such as man-in-the-middle, denial of service, eavesdropping, and masquerade attacks, as well as future attacks based on Grover's and Shor's algorithm implemented in quantum hardware. This article proposes a quantum-robust scheme based on entanglement and supersingular isogeny-based cryptography. The scheme employs a modified Supersingular Isogeny Key Encapsulation (SIKE) to generate shared secret keys, also authenticating BBM92, a quantum key distribution protocol to generate a symmetric key. The article uses ASCON-128 and SHA-3 to encrypt and authenticate messages, and provides a comparative analysis of two entanglement-based quantum key distribution protocols. The proposed scheme is compared to the current SCADA standard, AGA-12, and is shown to provide confidentiality, integrity, intrusion resistance, message authentication, and scalability. The randomness of key pairs generated by our algorithm and RSA key pairs is 87.5% and 84.37%, respectively, addressing confidentiality and integrity. Using the BBM92 protocol, our proposed algorithm detects the presence of an adversary by generating an average error rate of 26.07% and information leakage of 76.01%. AGA-12 relies on SHA-1 hash function that Google has cracked recently. However, our algorithm includes SHA-3, a collision and quantum-resistant hash that provides message authentication.}
}


@article{DBLP:journals/tdsc/ZhengLZSZ24,
	author = {Yandong Zheng and
                  Rongxing Lu and
                  Songnian Zhang and
                  Jun Shao and
                  Hui Zhu},
	title = {Achieving Practical and Privacy-Preserving kNN Query Over Encrypted
                  Data},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5479--5492},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3376084},
	doi = {10.1109/TDSC.2024.3376084},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhengLZSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As one of the most popular queries in Big Data era, the k\nnearest neighbors (k\nNN) query plays a significant role in various applications, such as medical diagnosis, signal processing, and recommendation systems. Meanwhile, driven by the advancement of the cloud service, an emerging trend among applications is to outsource the dataset and the corresponding k\nNN query services to the cloud. However, as the cloud is not fully trusted, those applications will face vital privacy concerns, and thus they usually encrypt data before outsourcing them to the cloud. Because encrypted data are outsourced to cloud, the k\nNN query over encrypted data has become increasingly attractive, and many solutions have been put forth in recent years. However, existing solutions cannot fully satisfy the objects of returning exact query results, protecting database privacy and query privacy, achieving high query efficiency, and imposing low computational costs at the user side. To address these issues, in this paper, we propose a new practical and privacy-preserving k\nNN query scheme. Specifically, we first refine the general security requirements for the matrix encryption by systematically analyzing existing algorithms. Then, we design a novel asymmetric matrix encryption (AME) to securely achieve Euclidean distance computation and two distances comparison in a single-party and non-interactive way. Then, based on the AME scheme, we propose a privacy-preserving k\nNN query scheme, in which a max-heap of size k\nis used to accelerate query efficiency. Detailed security analysis shows that our proposed scheme is really privacy-preserving. In addition, extensive performance evaluations are conducted, and the results demonstrate that our proposed scheme is also highly efficient.}
}


@article{DBLP:journals/tdsc/ChenMEHY24,
	author = {Xiao Chen and
                  Tiejun Ma and
                  Btissam Er{-}Rahmadi and
                  Jane Hillston and
                  Guanxu Yuan},
	title = {Parallel Byzantine Consensus Based on Hierarchical Architecture and
                  Trusted Hardware},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5493--5508},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3375925},
	doi = {10.1109/TDSC.2024.3375925},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ChenMEHY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Byzantine fault-tolerant (BFT) state machine replication (SMR) is adopted to support blockchain consensus by tolerating arbitrarily faulty behaviours. However, the inherent complexity of BFT protocols makes existing BFT protocols hard to adapt to large-scale applications that require high scalability and performance. In this article, we propose a BFT parallelism protocol designed to enhance its scalability by using a hierarchical multi-committee architecture. It also encompasses a cross-layer consensus operation flow to improve safety, and support trusted execution environments (TEEs). Our proposed approach allows the lower bound on the number of peers to be reduced to 2f+1\n. We show the value of our proposed protocol in comparison to other state-of-the-art BFT protocols through experiments and performance evaluations on a testbed built on a cloud platform. The proposed protocol demonstrates a remarkable level of scalability, capable of accommodating a growing number of peers. Additionally, it exhibits improved performance when contrasted with HotStuff and FastBFT, with approximately 100% and 200% enhancements, respectively.}
}


@article{DBLP:journals/tdsc/FeiLHWX24,
	author = {Gaolei Fei and
                  Yang Liu and
                  Guangmin Hu and
                  Sheng Wen and
                  Yang Xiang},
	title = {Online Social Network User Home Location Inference Based on Heterogeneous
                  Networks},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5509--5525},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3376372},
	doi = {10.1109/TDSC.2024.3376372},
	timestamp = {Sat, 30 Nov 2024 21:09:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/FeiLHWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inferring the home locations of online social network (OSN) users from their corresponding account data is an important process for many applications, such as personal privacy protection and business advertising applications. The existing methods typically use a supervised learning method to infer a user's home location according to a single or partial aspect of their OSN information. However, the home location of a user may be represented in a biased way if only a single or partial aspect of the information is used, and the performances of the supervised learning-based methods are also very sensitive to the quality of the training set utilized. To address these problems, this article presents a novel unsupervised method for inferring the home locations of the OSN users. The method first builds a heterogeneous network model to comprehensively represent the complex location information in the OSN data and then recursively infers users’ home locations by fusing the direct and indirect location information of the users. Experiments that compared our method with five existing typical Twitter user home location inference methods on a Twitter dataset demonstrate that the proposed method can significantly improve the accuracy and reliability of user home location inference.}
}


@article{DBLP:journals/tdsc/MaWCWFX24,
	author = {Wanlun Ma and
                  Derui Wang and
                  Chao Chen and
                  Sheng Wen and
                  Gaolei Fei and
                  Yang Xiang},
	title = {LocGuard: {A} Location Privacy Defender for Image Sharing},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5526--5537},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3376929},
	doi = {10.1109/TDSC.2024.3376929},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/MaWCWFX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The privacy of social media users is a major concern when the users share their content to the public. Sensitive information such as the location of the users can be inferred from relevant content without arising the awareness of the users. With blooming services provided by social media platforms, the users have more freedom to share information via diverse data formats. The multi-modality of the shared information may, in return, worsen the private information leakage caused by inference attacks. In this article, we first examine the problem of location inference on multi-modal data comprised of textual information and visual content. It is observed that the visual content, such as photos shared by social media users, can significantly boost the success rate of location inference. To thwart adversaries who are driven by visual-related data, we propose a defence that mitigates the threat of location privacy breach under an imperceptible utility loss. Our defence, namely LocGuard, perturbs the photos in a one-off manner before sharing them. The perturbations, along with a simple but effective bipartite perturbation strategy, ensure that LocGuard is resistant to adaptive adversaries who can perform adversarial training based on the perturbed photos. Moreover, LocGuard remains effective against open-set adversaries whose data categories in the training dataset are hidden from the defender. In the evaluation, we conduct extensive experiments based on real-world datasets and compare our work with previous methods. The results show that LocGuard significantly outperforms the existing defences. In particular, LocGuard not only achieves better privacy protection and utility preservation for image sharing, but also can effectively defend against adversarial-training-capable attackers.}
}


@article{DBLP:journals/tdsc/JiangSLXLLT24,
	author = {Mengxi Jiang and
                  Yulei Sui and
                  Yunqi Lei and
                  Xiaofei Xie and
                  Cuihua Li and
                  Yang Liu and
                  Ivor W. Tsang},
	title = {Adversarial Learning for Coordinate Regression Through {\textdollar}k{\textdollar}k-Layer
                  Penetrating Representation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5538--5552},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3376437},
	doi = {10.1109/TDSC.2024.3376437},
	timestamp = {Mon, 02 Dec 2024 08:14:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/JiangSLXLLT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial attack is a crucial step when evaluating the reliability and robustness of deep neural networks (DNNs) models. Most existing attack approaches apply an end-to-end gradient update strategy to generate adversarial examples for a classification or regression problem. However, few of them consider the non-differentiable DNN models (e.g., coordinate regression model) that prevent end-to-end backpropagation resulting in the failure of gradient calculation. In this article, we present a new adversarial example generation approach for both untargeted and targeted attacks on coordinate regression models with non-differentiable operations. The novelty of our approach lies in a k-layer penetrating representation, on which we perturb the hidden feature distribution of the kth layer through relational guidance to influence the final output, in which end-to-end backpropagation is not required. Rather than modifying a large portion of the pixels in an image, the proposed approach only modifies a very small set of the input pixels. These pixels are carefully and precisely selected by three correlations between the input pixels and hidden features of the kth layer of a DNN, thus significantly reducing the adversarial perturbation on a clean image. We successfully apply the proposed approach to two different tasks (i.e., 2D and 3D human pose estimation) which are typical applications of the coordinate regression learning. The comprehensive experiments demonstrate that our approach achieves better performance while using much less adversarial perturbation on clean images.}
}


@article{DBLP:journals/tdsc/GaoJPS24,
	author = {Chongyang Gao and
                  Sushil Jajodia and
                  Andrea Pugliese and
                  V. S. Subrahmanian},
	title = {{\textdollar}\{{\textbackslash}sf FakeDB\}{\textdollar}FakeDB: Generating
                  Fake Synthetic Databases},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5553--5564},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3379434},
	doi = {10.1109/TDSC.2024.3379434},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/GaoJPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Health care providers may wish to share limited information with researchers. Manufacturing companies may want to share some but not all data with regulators or partners. Since the emergence of generative adversarial networks (GANs), efforts have been made to generate synthetic data that preserves semantic properties on the one hand and distributions on the other hand. However, all past efforts focus on a single table at a time. We propose {\\sf FakeDB}, a general framework to generate synthetic data that preserves a a wide variety of semantic integrity constraints as well as a broad set of statistical properties, across an entire relational database. We compare {\\sf FakeDB} with natural extensions of prior work on 8 well known relational databases as well as on a synthetically generated dataset, and show that {\\sf FakeDB} outperforms them. We also show that {\\sf FakeDB} runs in reasonable amounts of time, making it a practical solution to the problem of generating synthetic data.}
}


@article{DBLP:journals/tdsc/ChuG24,
	author = {Kai{-}Fung Chu and
                  Weisi Guo},
	title = {Multi-Agent Reinforcement Learning-Based Passenger Spoofing Attack
                  on Mobility-as-a-Service},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5565--5581},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3379283},
	doi = {10.1109/TDSC.2024.3379283},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ChuG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-physical systems, such as smart transportation, face security threats from both digital and physical realms. Recently, Mobility-as-a-Service (MaaS) has emerged as a novel transportation concept, offering passengers access to diverse mobility services via a unified platform. Central to this system is the smart MaaS coordinator, tasked with tailoring services to passengers based on their profiles and behaviors. However, the coordination of heterogeneous passengers introduces vulnerabilities, enabling malicious entities to exploit the system by impersonating priority passengers with falsified information. Effective detection mechanisms require a deep understanding of the spoofing process. This paper investigates threats to the smart MaaS coordinator, unveiling a new reinforcement learning-based attack named the passenger spoofing attack, which aims to mitigate the risk of inadvertently exposing MaaS vulnerabilities post-deployment. This attack leverages feedback from actions and experiences to manipulate system profitability and passenger satisfaction by generating false passenger information. Furthermore, our research reveals that multi-agent reinforcement learning, accounting for spatial distribution among malicious agents and passengers, strengthens the attack. Through simulations based on datasets from New York City and synthetic sources, we demonstrate that the attack can significantly reduce 70% of profit and 50% of passenger satisfaction. Spatial analysis indicates an effective distance of approximately two nodes from the origin or destination. This study enriches our comprehension of the vulnerabilities inherent in smart coordinators within MaaS, enabling the development of robust countermeasures against malicious actors.}
}


@article{DBLP:journals/tdsc/HeCZLJX24,
	author = {Ruiwen He and
                  Yushi Cheng and
                  Junning Ze and
                  Xinfeng Li and
                  Xiaoyu Ji and
                  Wenyuan Xu},
	title = {Scoring Metrics of Assessing Voiceprint Distinctiveness Based on Speech
                  Content and Rate},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5582--5599},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3380603},
	doi = {10.1109/TDSC.2024.3380603},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/HeCZLJX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A voiceprint is the distinctive pattern of human voices widely used for authentication in voice assistants. This article investigates the impact of speech contents and speech rates on the distinctiveness of voiceprint, and has obtained answers to three questions by studying 2457 speakers and 21,500,000 test samples: 1) What are the influential factors that users can control to affect the distinctiveness of voiceprints? 2) How to quantify the distinctiveness for given speeches, e.g., the speech of wake-up words when activating voice assistants? 3) How to help users select wake-up words and adjust the speech rate to improve distinctiveness levels? To answer those questions, we break down speeches into phones, and experimentally obtain the correlation between false recognition rates and the richness, order, length, and elements of the phones. Then, we define the PROLE Score that can reflect the voice distinctiveness, and evaluate 30 wake-up words of 19 commercial voice assistant products to provide recommendations on selecting secure voiceprint words. We also measure the correlation between false recognition rates and speech rates, and define the TER Score that reveals the distance of distinctiveness from the secure voiceprint, and it guides users to adjust their speech rate to a secure value.}
}


@article{DBLP:journals/tdsc/ZhuGZQ24,
	author = {Yin Zhu and
                  Junqing Gong and
                  Kai Zhang and
                  Haifeng Qian},
	title = {Malicious-Resistant Non-Interactive Verifiable Aggregation for Federated
                  Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5600--5616},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3380669},
	doi = {10.1109/TDSC.2024.3380669},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhuGZQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In cross-device federated learning, verifiable secure aggregation enables clients to aggregate their locally trained model parameters through a malicious server to obtain a global model. To prevent the malicious server from tampering with the results, solutions have been proposed to ensure verifiability during this aggregation process. However, previous solutions either failed to achieve non-interactivity, which is critical in the cross-device setting, or failed to achieve malicious server resistance due to their underlying approach. Thus in this paper, we propose a lightweight non-interactive multi-client verifiable computation scheme (lwMVC) and then construct the malicious-resistant non-interactive verifiable aggregation (MRNIVA) for cross-device federated learning by the newly introduced underlying approach lwMVC. By combining Half Gates and non-iterative proxy oblivious-transfer, lwMVC meets both the non-interactivity and malicious resistance properties. Then, after solving the user dropout and efficiency problem, we construct the MRNIVA by lwMVC. Since we focus on the cross-device scenario, we conduct experiments on a Single Board Computer. The experiment result demonstrates that MRNIVA remains efficient compared to previous works after achieving both non-interactive and malicious resistance properties. As far as we know, we are the first to carry out verifiable aggregation experiments using such resource-constrained devices.}
}


@article{DBLP:journals/tdsc/XuSLSTS24,
	author = {Yang Xu and
                  Jianbo Shao and
                  Jia Liu and
                  Yulong Shen and
                  Tarik Taleb and
                  Norio Shiratori},
	title = {{BWKA:} {A} Blockchain-Based Wide-Area Knowledge Acquisition Ecosystem},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5617--5634},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3382031},
	doi = {10.1109/TDSC.2024.3382031},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/XuSLSTS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Benefiting from the booming of Big Data and artificial intelligence (AI) technologies, data-as-a-service is gradually transforming into knowledge-as-a-service. Extracting knowledge from massive raw data is becoming a popular paradigm to save network resources and improve efficiency, and establishing knowledge markets is receiving increasing attention from academia and industry. In this paper, we propose a one-stop knowledge acquisition ecosystem termed BWKA that covers the whole process from upper-layer knowledge trading to underlying knowledge generation. In the knowledge trading process, the knowledge-as-a-service platform (KSP) is the buyer and publishes knowledge demands to multiple local knowledge sellers (LKSs). In the knowledge generation process, each LKS aggregates data from its sensors and then trains data into knowledge according to the KSP's requirements. We resort to blockchain technology and provide a series of tailored operating rules and functions to protect the truthfulness of data gathering and the fairness of knowledge trading. In addition, we introduce incentive mechanisms to stimulate selfish and rational entities in the BWKA ecosystem to participate in knowledge acquisition. To analyze the strategic interactions among entities theoretically, we develop a nested hierarchical game model, where the upper-layer knowledge trading is evaluated based on the Contract Theory, and the lower-layer knowledge generation is formulated as a two-stage Stackelberg game. By solving the nested hierarchical game in a backward inductive way, we identify the optimal strategy for each entity in closed form. Experiments on the Ethereum blockchain and simulation results demonstrate the practical operability and outstanding performance of the BWKA ecosystem.}
}


@article{DBLP:journals/tdsc/PengLNZZ24,
	author = {Wei Peng and
                  Xiang Li and
                  Jianyu Niu and
                  Xiaokuan Zhang and
                  Yinqian Zhang},
	title = {Ensuring State Continuity for Confidential Computing: {A} Blockchain-Based
                  Approach},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5635--5649},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3381973},
	doi = {10.1109/TDSC.2024.3381973},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/PengLNZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Public cloud platforms have employed Trusted Execution Environment (TEE) technology to provide confidential computing services. However, applications running on cloud TEEs are susceptible to rollback or forking attacks. Their states can be rolled back to an outdated version or split into multiple conflicting versions, violating state continuity. Existing solutions against these attacks either rely on centralized trust assumption (e.g., trusted server) or have limited performance (e.g., tens of state updates per second). In this article, we introduce Narrator-Pro (an upgrade to the original Narrator), a secure and practical distributed system that utilizes blockchain technology and TEEs to provide high-performance state continuity protection for TEE applications in the cloud. Specifically, we use the blockchain to initialize the system, which lays down the decentralized trust base with minimal interaction overhead. Meanwhile, we leverage the distributed system composed of TEEs to provide fast and unlimited state updates. We have implemented a proof-of-concept of Narrator-Pro in Intel SGX and conducted extensive evaluations in both the WAN and the LAN. Our results show that in a LAN environment with 5 nodes, Narrator-Pro can support around 8 k state updates per second with a latency of 3.58 ms. This performance is 30x higher than ROTE and 70x higher than using a TPM counter.}
}


@article{DBLP:journals/tdsc/KongZLWRL24,
	author = {Chenqi Kong and
                  Kexin Zheng and
                  Yibing Liu and
                  Shiqi Wang and
                  Anderson Rocha and
                  Haoliang Li},
	title = {M{\textdollar}{\^{}}\{3\}{\textdollar}3FAS: An Accurate and Robust
                  MultiModal Mobile Face Anti-Spoofing System},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5650--5666},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3381598},
	doi = {10.1109/TDSC.2024.3381598},
	timestamp = {Sat, 30 Nov 2024 21:09:36 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/KongZLWRL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face presentation attacks (FPA), also known as face spoofing, have brought increasing concerns to the public through various malicious applications, such as financial fraud and privacy leakage. Therefore, safeguarding face recognition systems against FPA is of utmost importance. Although existing learning-based face anti-spoofing (FAS) models can achieve outstanding detection performance, they lack generalization capability and suffer significant performance drops in unforeseen environments. Many methodologies seek to use auxiliary modality data (e.g., depth and infrared maps) during the presentation attack detection (PAD) to address this limitation. However, these methods can be limited since (1) they require specific sensors such as depth and infrared cameras for data capture, which are rarely available on commodity mobile devices, and (2) they cannot work properly in practical scenarios when either modality is missing or of poor quality. In this article, we devise an accurate and robust MultiModal Mobile Face Anti-Spoofing system named M\n3\n3FAS to overcome the issues above. The primary innovation of this work lies in the following aspects: (1) To achieve robust PAD, our system combines visual and auditory modalities using three commonly available sensors: camera, speaker, and microphone; (2) We design a novel two-branch neural network with three hierarchical feature aggregation modules to perform cross-modal feature fusion; (3). We propose a multi-head training strategy, allowing the model to output predictions from the vision, acoustic, and fusion heads, resulting in a more flexible PAD. Extensive experiments have demonstrated the accuracy, robustness, and flexibility of M\n3\nFAS under various challenging experimental settings.}
}


@article{DBLP:journals/tdsc/ZhangLY24,
	author = {Lei Zhang and
                  Jiangtao Li and
                  Yafang Yang},
	title = {Message Linkable Group Signature With Information Binding and Efficient
                  Revocation for Privacy- Preserving Announcement in VANETs},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5667--5680},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3381436},
	doi = {10.1109/TDSC.2024.3381436},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In vehicular ad hoc networks (VANETs), the broadcasting of fake announcement messages by malicious vehicles can potentially misguide nearby vehicles. Ensuring the trustworthiness of announcement messages while preserving the privacy of vehicles is a significant challenge in the design of an announcement scheme for VANETs. To address this challenge, we propose a privacy-preserving announcement scheme with strong trustworthiness based on a new security tool called message linkable group signature with information binding and efficient revocation. Compared with the existing privacy-preserving announcement schemes, our proposed scheme not only achieves the traditional trustworthiness requirement of an announcement message but also provides strong trustworthiness, which makes it resistant to sybil and collusive attacks. To the best of our knowledge, our scheme realizes strong trustworthiness for the first time. Simulations were also performed to show the practicability of the scheme.}
}


@article{DBLP:journals/tdsc/HanXJC24,
	author = {Yunxia Han and
                  Chunxiang Xu and
                  Changsong Jiang and
                  Kefei Chen},
	title = {A Secure Two-Factor Authentication Key Exchange Scheme},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5681--5693},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3382359},
	doi = {10.1109/TDSC.2024.3382359},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/HanXJC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Two-factor authentication key exchange (AKE) is an effective way to strengthen the security of password-authenticated key exchange. Most two-factor AKE schemes using smart cards as the second factor require users to have the second factor with them any time, which causes users inconveniences. Biometrics provide a user-friendly manner to achieve two-factor AKE since they need not be carried. However, biometrics may have less entropy than expected and would suffer from offline guessing attacks. In this article, we propose a secure two-factor authentication key exchange scheme TAKE that resists offline guessing attacks against biometrics and passwords. In TAKE, a user generates a combined factor of his/her biometrics and password. To protect the combined factor, the user and the server leverages secure two-party computation to blind it with a key which is protected in a trusted execution environment. Thus, TAKE prevents an adversary from eavesdropping on the combined factor, and simultaneously guarantees that he cannot recover the combined factor from blinded one to undertake offline guessing attacks even if he compromises the server and obtains the blinded combined factor. We provide the formal security proof of TAKE. The experiments show that TAKE is efficient in terms of storage, computation, and communication overhead.}
}


@article{DBLP:journals/tdsc/SahaKGCB24,
	author = {Rahul Saha and
                  Gulshan Kumar and
                  G. Geetha and
                  Mauro Conti and
                  William J. Buchanan},
	title = {Application of Randomness for Security and Privacy in Multi-Party
                  Computation},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5694--5705},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3381959},
	doi = {10.1109/TDSC.2024.3381959},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/SahaKGCB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A secure Multi-Party Computation (MPC) is one of the distributed computational methods, where it computes a function over the inputs given by more than one party jointly and keeps those inputs private from the parties involved in the process. Randomization in secret sharing leading to MPC is a requirement for privacy enhancements; however, most of the available MPC models use the trust assumptions of sharing and combining values. Thus, randomization in secret sharing and MPC modules is neglected. As a result, the available MPC models are prone to information leakage problems, where the models can reveal the partial values of the sharing secrets. In this paper, we propose the first model of utilizing a random function generator as an MPC primitive. More specifically, we analyze our previous development of the Symmetric Random Function Generator (SRFG) for information-theoretic security, where the system is considered to have unconditional security if it is secure against adversaries with unlimited computing resources and time. Further, we apply SRFG to eradicate the problem of information leakage in the general MPC model. Through a set of experiments, we show that SRFG is a function generator that can generate the combined functions (combination of logic GATEs) with n/2\n-private to n\n-private norms. As the main goal of MPC is privacy preservation of the inputs, we analyze the applicability of SRFG properties in secret sharing and MPC and observe that SRFG is eligible to be a cryptographic primitive in MPCdevelopments. We also measure the performance of our proposed SRFG-based MPC framework with the other randomness generation-based MPC frameworks and analyze the comparative attributes with the state-of-the-art models. We observe that our posed SRFG-based MPC is \\approx 30\\%\nbetter in terms of throughput and also shows 100% privacy attainment.}
}


@article{DBLP:journals/tdsc/LiuGD24,
	author = {Jianqing Liu and
                  Na Gong and
                  Hritom Das},
	title = {Two Birds With One Stone: Differential Privacy by Low-Power {SRAM}
                  Memory},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5706--5719},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3382630},
	doi = {10.1109/TDSC.2024.3382630},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuGD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The software-based implementation of differential privacy mechanisms has been shown to be neither friendly for lightweight devices nor secure against side-channel attacks. In this work, we aim to develop a hardware-based technique to achieve differential privacy by design. In contrary to the conventional software-based noise generation and injection process, our design realizes local differential privacy (LDP) by harnessing the inherent hardware noise into controlled LDP noise when data is stored in the memory. Specifically, the noise is tamed through a novel memory design and power downscaling technique, which leads to double-faceted gains in privacy and power efficiency. A well-round study that consists of theoretical design and analysis and chip implementation and experiments is presented. The results confirm that the developed technique is differentially private, saves 88.58% system power, speeds up software-based DP mechanisms by more than 10^{6} times, while only incurring 2.46% chip overhead and 7.81% estimation errors in data recovery.}
}


@article{DBLP:journals/tdsc/GaoMWSLJCC24,
	author = {Xiangshan Gao and
                  Xingjun Ma and
                  Jingyi Wang and
                  Youcheng Sun and
                  Bo Li and
                  Shouling Ji and
                  Peng Cheng and
                  Jiming Chen},
	title = {VeriFi: Towards Verifiable Federated Unlearning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5720--5736},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3382321},
	doi = {10.1109/TDSC.2024.3382321},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/GaoMWSLJCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has emerged as a privacy-aware collaborative learning paradigm where participants jointly train a powerful model without sharing their private data. One desirable property for FL is the implementation of the right to be forgotten (RTBF), i.e., a leaving participant has the right to request the deletion of its private data from the global model. However, unlearning itself may not be enough to implement RTBF unless the unlearning effect can be independently verified, an important aspect that has been overlooked in the current literature. Unlearning verification is particularly challenging in FL as the unlearning effect on one participant's data could be canceled by the contribution of other participants. In this work, we prompt the concept of verifiable federated unlearning and propose VeriFi, a unified framework that allows systematic analysis of federated unlearning and quantification of its effect, with different combinations of various unlearning and verification methods. In VeriFi, the leaving participant is granted the right to verify (RTV) to actively verify the unlearning effect in the next few rounds immediately after notifying the server of its intention to leave, along with local verification done through two steps: 1) marking that fingerprints the leaving participant by specially-designed markers and 2) checking that examines the global model's performance change on the markers. Based on VeriFi, we have conducted so far the most systematic study on verifiable federated unlearning, covering six unlearning methods and five verification methods. Our study sheds light on the existing drawbacks and potential alternatives for both unlearning and verification methods. During the study, we also propose a more efficient and FL-friendly unlearning method $^{u}$S2U, and two more effective and robust non-invasive (without training controllability, external data, white-box model access nor introducing new security risks) verification methods $^{v}$FM and $^{v}$EM. While the proposed methods may not be a panacea for all the challenges, they address several key drawbacks of existing methods and represent a promising step toward effective, efficient, robust, and more importantly, non-invasive federated unlearning and verification. We extensively evaluate VeriFi on seven datasets, including natural/facial/medical images and audios, and four types of deep learning models, including both Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). We hope, such an extensive and holistic experimental evaluation, although admittedly complex and challenging, could help establish important empirical understandings, evidence, and insights for trustworthy federated unlearning.}
}


@article{DBLP:journals/tdsc/FengZHZW24,
	author = {Yuming Feng and
                  Yu Zhang and
                  Hui He and
                  Weizhe Zhang and
                  Desheng Wang},
	title = {An IoT Device Identification Method Using Extracted Fingerprint From
                  Sequence of Traffic Grayscale Images},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5737--5754},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3383159},
	doi = {10.1109/TDSC.2024.3383159},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/FengZHZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread deployment and application of various types of IoT devices, preventing illegal intrusion and impersonation attacks of IoT devices has become an important security challenge. Device identification helps to limit the behavior of suspicious devices and enhances the security of the device access process. In this paper, we propose a novel deep learning-based automatic fingerprint extraction model that addresses low efficiency and complexity of traditional feature engineering process, which are often rely on expert experience. The proposed model integrates advanced modules such as Depthwise Separable Convolution (DSC) and Gated Recurrent Unit (GRU), as well as architectures of inverted residuals and linear bottlenecks to enhance the performance of fingerprint extraction. After converting the raw device traffic into the sequence of traffic grayscale images, the model can analyze spatial and temporal features from them to generate highly distinguishable device fingerprints automatically. Additionally, we also achieve fast fingerprint search based on Hierarchical Navigable Small World (HNSW) to support device identification. Our proposed method can not only indicate deviations in device behavior from expected specifications, but also identify unknown and unreliable IoT devices. The experimental results show that our method has excellent performance and more comprehensive identification capabilities in multiple dimensions.}
}


@article{DBLP:journals/tdsc/AldeenZCFL24,
	author = {Mohammed Shujaa Aldeen and
                  Chuan Zhao and
                  Zhenxiang Chen and
                  Liming Fang and
                  Zhe Liu},
	title = {Privacy-Preserving Collaborative Learning for Genome Analysis via
                  Secure XGBoost},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5755--5765},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3384244},
	doi = {10.1109/TDSC.2024.3384244},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/AldeenZCFL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Genomic data is usually stored in a decentralized manner among data providers, who cannot share them publicly due to privacy concerns. A significant technical challenge is to combine machine learning and cryptography techniques to build secure machine learning models over distributed datasets without violating privacy. Therefore, data providers in collaborative machine learning want to maintain the privacy of their genomic data, and the researcher who owns the training model wants to keep the model and training methods confidential. This paper proposes a framework that supports secure collaborative learning tasks without disclosing the participants’ genomic data and training model information simultaneously. With the help of a cluster of Intel SGX enclaves, our work performs fast distributed training over these enclaves, and a dedicated enclave is solely used for updating the global model. Also, Secure XGBoost was implemented over these hardware enclaves for fast learning and to enhance the enclaves’ security with unique data-oblivious algorithms that eliminate side-channel attacks. From the experimental results, our scheme achieves fast and efficient results in collaborative learning systems without an increase in communication overhead, making it practical for large genomic data.}
}


@article{DBLP:journals/tdsc/LiuWZ24,
	author = {Yong Liu and
                  Hanzhou Wu and
                  Xinpeng Zhang},
	title = {Robust and Imperceptible Black-Box {DNN} Watermarking Based on Fourier
                  Perturbation Analysis and Frequency Sensitivity Clustering},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5766--5780},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3384416},
	doi = {10.1109/TDSC.2024.3384416},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/LiuWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, more and more attention has been focused on the intellectual property protection of deep neural networks (DNNs), promoting DNN watermarking to become a hot research topic. Compared with embedding watermarks directly into DNN parameters, inserting trigger-set watermarks enables us to verify the ownership without knowing the internal details of the DNN, which is more suitable for application scenarios. The cost is we have to carefully craft the trigger samples. Mainstream methods construct the trigger samples by inserting a noticeable pattern to the clean samples in the spatial domain, which does not consider sample imperceptibility, sample robustness and model robustness, and therefore has limited the watermarking performance and the model generalization. It has motivated the authors in this paper to propose a novel DNN watermarking method based on Fourier perturbation analysis and frequency sensitivity clustering. First, we analyze the perturbation impact of different frequency components of the input sample on the task functionality of the DNN by applying random perturbation. Then, by K-means clustering, we determine the frequency components that result in superior watermarking performance for crafting the trigger samples. Our experiments show that the proposed work not only maintains the performance of the DNN on its original task, but also provides better watermarking performance compared with related works.}
}


@article{DBLP:journals/tdsc/QianLHXWF24,
	author = {Xinyuan Qian and
                  Hongwei Li and
                  Meng Hao and
                  Guowen Xu and
                  Haoyong Wang and
                  Yuguang Fang},
	title = {Decentralized Multi-Client Functional Encryption for Inner Product
                  With Applications to Federated Learning},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5781--5796},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3386357},
	doi = {10.1109/TDSC.2024.3386357},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/QianLHXWF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized multi-client functional encryption for inner product (DMCFE-IP) enables efficient joint functional computation of private inputs in a secure manner without a trusted third party, which has found successful applications, including distributed statistical analysis and machine learning. However, existing DMCFE-IP schemes suffer several drawbacks, such as lack of support for client dropout, requiring cross-client communication for key generation, and poor efficiency and scalability. To address these issues, we propose an efficient and scalable DMCFE-IP, which supports client dropout and non-interactive decentralized partial decryption key generation. Our scheme mainly exploits appropriate underlying cryptographic primitives, including multi-client functional encryption, digital signature, key agreement, secret sharing, and symmetric encryption, with careful integration to achieve the aforementioned two functionalities. We then extend this scheme to enable privacy-preserving federated learning (PPFL) for the cross-silo scenrio. We provide formal security proof for our scheme and evaluate our DMCFE-IP-based PPFL on several real-world datasets. Compared with the state-of-the-art methods, our approach achieves a speedup of 6.12\\sim\n43.36× in running time.}
}


@article{DBLP:journals/tdsc/ZhangFCHZ24,
	author = {Qingyang Zhang and
                  Yujie Fu and
                  Jie Cui and
                  Debiao He and
                  Hong Zhong},
	title = {Efficient Fine-Grained Data Sharing Based on Proxy Re-Encryption in
                  IIoT},
	journal = {{IEEE} Trans. Dependable Secur. Comput.},
	volume = {21},
	number = {6},
	pages = {5797--5809},
	year = {2024},
	url = {https://doi.org/10.1109/TDSC.2024.3386690},
	doi = {10.1109/TDSC.2024.3386690},
	timestamp = {Sat, 30 Nov 2024 21:09:37 +0100},
	biburl = {https://dblp.org/rec/journals/tdsc/ZhangFCHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of the industrial Internet of Things (IIoT), the amount of data generated by industrial manufacturing equipment will increase. To reduce the cost of data management while achieving secure data sharing, data owners generally upload the resulting ciphertexts to a cloud server after encrypting their data. Attribute-based encryption (ABE) is a valuable technology that implements fine-grained access control over shared information; however, its computational complexity is not suitable for resource-constrained IIoT devices, making it difficult to apply directly to an IIoT environment. To address this problem, we design a fine-grained data sharing scheme based on proxy re-encryption in IIoT. In the proposed scheme, data files are encrypted through an identity-based encryption and a data owner can authorize a semi-trusted proxy server to transform the ciphertext into an ABE ciphertext. This realizes fine-grained access control and decreases a data owner's computational cost in data sharing. In addition, the computational burden is outsourced to a cloud server, and users only need to perform simple computing operations. A formal security proof indicates the proposed scheme's selective chosen-plaintext attack security. Theoretical and experimental analyses illustrate that our construction is more efficient than previous schemes.}
}
