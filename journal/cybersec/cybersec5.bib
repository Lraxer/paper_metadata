@article{DBLP:journals/cybersec/DishaW22,
	author = {Raisa Abedin Disha and
                  Sajjad Waheed},
	title = {Performance analysis of machine learning models for intrusion detection
                  system using Gini Impurity-based Weighted Random Forest {(GIWRF)}
                  feature selection technique},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {1},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-021-00103-8},
	doi = {10.1186/S42400-021-00103-8},
	timestamp = {Fri, 21 Jan 2022 22:00:48 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/DishaW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To protect the network, resources, and sensitive data, the intrusion detection system (IDS) has become a fundamental component of organizations that prevents cybercriminal activities. Several approaches have been introduced and implemented to thwart malicious activities so far. Due to the effectiveness of machine learning (ML) methods, the proposed approach applied several ML models for the intrusion detection system. In order to evaluate the performance of models, UNSW-NB 15 and Network TON_IoT datasets were used for offline analysis. Both datasets are comparatively newer than the NSL-KDD dataset to represent modern-day attacks. However, the performance analysis was carried out by training and testing the Decision Tree (DT), Gradient Boosting Tree\xa0(GBT), Multilayer Perceptron\xa0(MLP), AdaBoost, Long-Short Term Memory\xa0(LSTM), and Gated Recurrent Unit\xa0(GRU) for the binary classification task. As the performance of IDS deteriorates with a high dimensional feature vector, an optimum set of features was selected through a Gini Impurity-based Weighted Random Forest (GIWRF) model as the embedded feature selection technique. This technique employed Gini impurity as the splitting criterion of trees and adjusted the weights for two different classes of the imbalanced data to make the learning algorithm understand the class distribution. Based upon the importance score, 20 features were selected from UNSW-NB 15 and 10 features from the Network TON_IoT dataset. The experimental result revealed that DT performed well with the feature selection technique than other trained models of this experiment. Moreover, the proposed GIWRF-DT outperformed other existing methods surveyed in the literature in terms of the F1 score.}
}


@article{DBLP:journals/cybersec/RajmohanNF22,
	author = {Tanusan Rajmohan and
                  Phu Hong Nguyen and
                  Nicolas Ferry},
	title = {A decade of research on patterns and architectures for IoT security},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {2},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-021-00104-7},
	doi = {10.1186/S42400-021-00104-7},
	timestamp = {Fri, 21 Jan 2022 22:00:48 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/RajmohanNF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Security of the Internet of Things (IoT)-based Smart Systems involving sensors, actuators and distributed control loop is of paramount importance but very difficult to address. Security patterns consist of domain-independent time-proven security knowledge and expertise. How are they useful for developing secure IoT-based smart systems? Are there architectures that support IoT security? We aim to systematically review the research work published on patterns and architectures for IoT security (and privacy). Then, we want to provide an analysis on that research landscape to answer our research questions. We follow the well-known guidelines for conducting systematic literature reviews. From thousands of candidate papers initially found in our search process, we have systematically distinguished and analyzed thirty-six (36) papers that have been peer-reviewed and published around patterns and architectures for IoT security and privacy in the last decade (January 2010–December 2020). Our analysis shows that there is a rise in the number of publications tending to patterns and architectures for IoT security in the last three years. We have not seen any approach of applying systematically architectures and patterns together that can address security (and privacy) concerns not only at the architectural level, but also at the network or IoT devices level. We also explored how the research contributions in the primary studies handle the different issues from the OWASP Internet of Things (IoT) top ten vulnerabilities list. Finally, we discuss the current gaps in this research area and how to fill in the gaps for promoting the utilization of patterns for IoT security and privacy by design.}
}


@article{DBLP:journals/cybersec/YouJJYLFWL22,
	author = {Yizhe You and
                  Jun Jiang and
                  Zhengwei Jiang and
                  Peian Yang and
                  Baoxu Liu and
                  Huamin Feng and
                  Xuren Wang and
                  Ning Li},
	title = {{TIM:} threat context-enhanced {TTP} intelligence mining on unstructured
                  threat data},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {3},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-021-00106-5},
	doi = {10.1186/S42400-021-00106-5},
	timestamp = {Wed, 23 Feb 2022 11:16:27 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/YouJJYLFWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {TTPs (Tactics, Techniques, and Procedures), which represent an attacker’s goals and methods, are the long period and essential feature of the attacker. Defenders can use TTP intelligence to perform the penetration test and compensate for defense deficiency. However, most TTP intelligence is described in unstructured threat data, such as APT analysis reports. Manually converting natural language TTPs descriptions to standard TTP names, such as ATT&CK TTP names and IDs, is time-consuming and requires deep expertise. In this paper, we define the TTP classification task as a sentence classification task. We annotate a new sentence-level TTP dataset with 6 categories and 6061 TTP descriptions from 10761 security analysis reports. We construct a threat context-enhanced TTP intelligence mining (TIM) framework to mine TTP intelligence from unstructured threat data. The TIM framework uses TCENet (Threat Context Enhanced Network) to find and classify TTP descriptions, which we define as three continuous sentences, from textual data. Meanwhile, we use the element features of TTP in the descriptions to enhance the TTPs classification accuracy of TCENet. The evaluation result shows that the average classification accuracy of our proposed method on the 6 TTP categories reaches 0.941. The evaluation results also show that adding TTP element features can improve our classification accuracy compared to using only text features. TCENet also achieved the best results compared to the previous document-level TTP classification works and other popular text classification methods, even in the case of few-shot training samples. Finally, the TIM framework organizes TTP descriptions and TTP elements into STIX 2.1 format as final TTP intelligence for sharing the long-period and essential attack behavior characteristics of attackers. In addition, we transform TTP intelligence into sigma detection rules for attack behavior detection. Such TTP intelligence and rules can help defenders deploy long-term effective threat detection and perform more realistic attack simulations to strengthen defense.}
}


@article{DBLP:journals/cybersec/LiuXW22,
	author = {Pengrui Liu and
                  Xiangrui Xu and
                  Wei Wang},
	title = {Threats, attacks and defenses to federated learning: issues, taxonomy
                  and perspectives},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {4},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-021-00105-6},
	doi = {10.1186/S42400-021-00105-6},
	timestamp = {Fri, 17 Nov 2023 16:26:53 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/LiuXW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Empirical attacks on Federated Learning (FL) systems\xa0indicate that FL is fraught with numerous attack surfaces throughout the FL execution. These attacks can not only cause models to fail in specific tasks, but also infer private information. While previous surveys have identified the risks, listed the attack methods available in the literature or provided a basic taxonomy to classify them, they mainly focused on the risks in the training phase of FL. In this work, we survey the threats, attacks and defenses to FL throughout the whole process of FL in three phases, including Data and Behavior Auditing Phase, Training Phase and Predicting Phase. We further provide a comprehensive analysis of these threats, attacks and defenses, and summarize their issues and taxonomy. Our work\xa0considers security and privacy of FL based on the viewpoint of the execution process of FL. We highlight that establishing a trusted FL requires adequate measures to mitigate security and privacy threats at each phase. Finally, we discuss the limitations of current attacks and defense approaches and provide an outlook on promising future research directions\xa0in FL.}
}


@article{DBLP:journals/cybersec/YanZLWLL22,
	author = {Chuyi Yan and
                  Chen Zhang and
                  Zhigang Lu and
                  Zehui Wang and
                  Yuling Liu and
                  Baoxu Liu},
	title = {Blockchain abnormal behavior awareness methods: a survey},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {5},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-021-00107-4},
	doi = {10.1186/S42400-021-00107-4},
	timestamp = {Wed, 28 Feb 2024 14:47:44 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/YanZLWLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the wide application and development of blockchain technology in various fields such as finance, government affairs and medical care, security incidents occur frequently on it, which brings great threats to users’ assets and information. Many researchers have worked on blockchain abnormal behavior awareness in respond to these threats. We summarize respectively the existing public blockchain and consortium blockchain abnormal behavior awareness methods and ideas in detail as the difference between the two types of blockchain. At the same time, we summarize and analyze the existing data sets related to mainstream blockchain security, and finally discuss possible future research directions. Therefore, this work can provide a reference for blockchain security awareness research.}
}


@article{DBLP:journals/cybersec/ParkinsonK22,
	author = {Simon Parkinson and
                  Saad Khan},
	title = {Identifying high-risk over-entitlement in access control policies
                  using fuzzy logic},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {6},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00112-1},
	doi = {10.1186/S42400-022-00112-1},
	timestamp = {Fri, 13 May 2022 19:52:50 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/ParkinsonK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analysing access control policies is an essential process for ensuring over-prescribed permissions are identified and removed. This is a time-consuming and knowledge-intensive process, largely because there is a wealth of policy information that needs to be manually examined. Furthermore, there is no standard definition of what constitutes an over-entitled permission within an organisation’s access control policy, making it not possible to develop automated rule-based approaches. It is often the case that over-entitled permissions are subjective to an organisation’s role-based structure, where access is be divided and managed based on different employee needs. In this context, an irregular permission could be one where an employee has frequently changed roles, thus accumulating a wide-ranging set of permissions. There is no one size fits all approach to identifying permissions where an employee is receiving more permission than is necessary, and it is necessary to examine them in the context of the organisation to establish their individual risk. Risk is not a binary measure and, in this work, an approach is built using Fuzzy Logic to determine an overall risk rating, which can then be used to make a more informed decision as to whether a user is over-entitled and presenting risk to the organisation. This requires the exploratory use of establishing resource sensitivity and user trust as measures to determine a risk rating. The paper presents a generic solution, which has been implemented to perform experimental analysis on Microsoft’s New Technology File System to show how this works in practice. A simulation using expert knowledge for comparison is then performed to demonstrate how effective it is at helping the user identify potential irregular permissions.}
}


@article{DBLP:journals/cybersec/FernandezYWY22,
	author = {Eduardo B. Fern{\'{a}}ndez and
                  Nobukazu Yoshioka and
                  Hironori Washizaki and
                  Joseph W. Yoder},
	title = {Abstract security patterns and the design of secure systems},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {7},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00109-w},
	doi = {10.1186/S42400-022-00109-W},
	timestamp = {Fri, 29 Apr 2022 14:50:29 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/FernandezYWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {During the initial stages of software development, the primary goal is to define precise and detailed requirements without concern for software realizations. Security constraints should be introduced then and must be based on the semantic aspects of applications, not on their software architectures, as it is the case in most secure development methodologies. In these stages, we need to identify threats as attacker goals and indicate what conceptual security defenses are needed to thwart these goals, without consideration of implementation details. We can consider the effects of threats on the application assets and try to find ways to stop them. These threats should be controlled with abstract security mechanisms that can be realized by abstract security patterns (ASPs), that include only the core functions of these mechanisms, which must be present in every implementation of them. An abstract security pattern describes a conceptual security mechanism that includes functions able to stop or mitigate a threat or comply with a regulation or institutional policy. We describe here the properties of ASPs and present a detailed example. We relate ASPs to each other and to Security Solution Frames, which describe families of related patterns. We show how to include ASPs to secure an application, as well as how to derive concrete patterns from them. Finally, we discuss their practical value, including their use in “security by design” and IoT systems design.}
}


@article{DBLP:journals/cybersec/LiuYJHWJYL22,
	author = {Jian Liu and
                  Junjie Yan and
                  Jun Jiang and
                  Yitong He and
                  Xuren Wang and
                  Zhengwei Jiang and
                  Peian Yang and
                  Ning Li},
	title = {TriCTI: an actionable cyber threat intelligence discovery system via
                  trigger-enhanced neural network},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {8},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00110-3},
	doi = {10.1186/S42400-022-00110-3},
	timestamp = {Sun, 05 Mar 2023 01:38:20 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/LiuYJHWJYL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cybersecurity report provides unstructured actionable cyber threat intelligence (CTI) with detailed threat attack procedures and indicators of compromise (IOCs), e.g., malware hash or URL (uniform resource locator) of command and control server. The actionable CTI, integrated into intrusion detection systems, can not only prioritize the most urgent threats based on the campaign stages of attack vectors (i.e., IOCs) but also take appropriate mitigation measures based on contextual information of the alerts. However, the dramatic growth in the number of cybersecurity reports makes it nearly impossible for security professionals to find an efficient way to use these massive amounts of threat intelligence. In this paper, we propose a trigger-enhanced actionable CTI discovery system (TriCTI) to portray a relationship between IOCs and campaign stages and generate actionable CTI from cybersecurity reports through natural language processing (NLP) technology. Specifically, we introduce the “campaign trigger” for an effective explanation of the campaign stages to improve the performance of the classification model. The campaign trigger phrases are the keywords in the sentence that imply the campaign stage. The trained final trigger vectors have similar space representations with the keywords in the unseen sentence and will help correct classification by increasing the weight of the keywords. We also meticulously devise a data augmentation specifically for cybersecurity training sets to cope with the challenge of the scarcity of annotation data sets. Compared with state-of-the-art text classification models, such as BERT, the trigger-enhanced classification model has better performance with accuracy (86.99%) and F1 score (87.02%). We run TriCTI on more than 29k cybersecurity reports, from which we automatically and efficiently collect 113,543 actionable CTI. In particular, we verify the actionability of discovered CTI by using large-scale field data from VirusTotal (VT). The results demonstrate that the threat intelligence provided by VT lacks a part of the threat context for IOCs, such as the Actions on Objectives campaign stage. As a comparison, our proposed method can completely identify the actionable CTI in all campaign stages. Accordingly, cyber threats can be identified and resisted at any campaign stage with the discovered actionable CTI.}
}


@article{DBLP:journals/cybersec/PintoGDT22,
	author = {Rui Pinto and
                  Gil Gon{\c{c}}alves and
                  Jerker Delsing and
                  Eduardo Tovar},
	title = {Enabling data-driven anomaly detection by design in cyber-physical
                  production systems},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {9},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00114-z},
	doi = {10.1186/S42400-022-00114-Z},
	timestamp = {Tue, 07 May 2024 20:27:33 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/PintoGDT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Designing and developing distributed cyber-physical production systems (CPPS) is a time-consuming, complex, and error-prone process. These systems are typically heterogeneous, i.e., they consist of multiple components implemented with different languages and development tools. One of the main problems nowadays in CPPS implementation is enabling security mechanisms by design while reducing the complexity and increasing the system’s maintainability. Adopting the IEC 61499 standard is an excellent approach to tackle these challenges by enabling the design, deployment, and management of CPPS in a model-based engineering methodology. We propose a method for CPPS design based on the IEC 61499 standard. The method allows designers to embed a bio-inspired anomaly-based host intrusion detection system (A-HIDS) in Edge devices. This A-HIDS is based on the incremental Dendritic Cell Algorithm\xa0(iDCA) and can analyze OPC UA network data exchanged between the Edge devices and detect attacks that target the CPPS’ Edge layer. This study’s findings have practical implications on the industrial security community by making novel contributions to the intrusion detection problem in CPPS considering immune-inspired solutions, and cost-effective security by design system implementation. According to the experimental data, the proposed solution can dramatically reduce design and code complexity while improving application maintainability and successfully detecting network attacks without negatively impacting the performance of the CPPS Edge devices.}
}


@article{DBLP:journals/cybersec/SunZJZT22,
	author = {Shuo Sun and
                  Yongbin Zhou and
                  Yunfeng Ji and
                  Rui Zhang and
                  Yang Tao},
	title = {Generic, efficient and isochronous Gaussian sampling over the integers},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {10},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00113-0},
	doi = {10.1186/S42400-022-00113-0},
	timestamp = {Thu, 12 May 2022 16:54:00 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/SunZJZT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gaussian sampling over the integers is one of the fundamental building blocks of lattice-based cryptography. Among the extensively used trapdoor sampling algorithms, it is ineluctable until now. Under the influence of numerous side-channel attacks, it is still challenging to construct a Gaussian sampler that is generic, efficient, and resistant to timing attacks. In this paper, our contribution is three-fold. First, we propose a secure, efficient exponential Bernoulli sampling algorithm. It can be applied to Gaussian samplers based on rejection samplings. We apply it to FALCON, a candidate of round 3 of the NIST post-quantum cryptography standardization project, and reduce its signature generation time by 13–14%. Second, we develop an isochronous Gaussian sampler based on rejection sampling. Our Algorithm can securely sample from Gaussian distributions with different standard deviations and arbitrary centers. We apply it to PALISADE (S&P 2018), an open-source lattice-based cryptography library. During the online phase of trapdoor sampling, the running time of the G-lattice sampling algorithm is reduced by 44.12% while resisting timing attacks. Third, we improve the efficiency of the COSAC sampler (PQC 2020). The new COSAC sampler is 1.46x–1.63x faster than the original and has the lowest expected number of trials among all Gaussian samplers based on rejection samplings. But it needs a more efficient algorithm sampling from the normal distribution to improve its performance.}
}


@article{DBLP:journals/cybersec/YangHDTX22,
	author = {Fengyu Yang and
                  Yanni Han and
                  Ying Ding and
                  Qian Tan and
                  Zhen Xu},
	title = {A flexible approach for cyber threat hunting based on kernel audit
                  records},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {11},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00111-2},
	doi = {10.1186/S42400-022-00111-2},
	timestamp = {Wed, 10 Jan 2024 22:27:37 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/YangHDTX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hunting the advanced threats hidden in the enterprise networks has always been a complex and difficult task. Due to the variety of attacking means, it is difficult for traditional security systems to detect threats. Most existing methods analyze log records, but the amount of log records generated every day is very large. How to find the information related to the attack events quickly and effectively from massive data streams is an important problem. Considering that the knowledge graph can be used for automatic relation calculation and complex relation analysis, and can get relatively fast feedback, our work proposes to construct the knowledge graph based on kernel audit records, which fully considers the global correlation among entities observed in audit logs. We design the construction and application process of knowledge graph, which can be applied to actual threat hunting activities. Then we explore different ways to use the constructed knowledge graph for hunting actual threats in detail. Finally, we implement a LAN-wide hunting system which is convenient and flexible for security analysts. Evaluations based on the adversarial engagement designed by DARPA prove that our platform can effectively hunt sophisticated threats, quickly restore the attack path or assess the impact of attack.}
}


@article{DBLP:journals/cybersec/LuLLL22,
	author = {Xiaojuan Lu and
                  Bohan Li and
                  Meicheng Liu and
                  Dongdai Lin},
	title = {Improved conditional differential attacks on lightweight hash family
                  {QUARK}},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {12},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-021-00108-3},
	doi = {10.1186/S42400-021-00108-3},
	timestamp = {Thu, 18 Aug 2022 11:54:59 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/LuLLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nonlinear feedback shift register (NFSR) is one of the most important cryptographic primitives in lightweight cryptography. At ASIACRYPT 2010, Knellwolf et al. proposed conditional differential attack to perform a cryptanalysis on NFSR-based cryptosystems. The main idea of conditional differential attack is to restrain the propagation of the difference and obtain a detectable bias of the difference of the output bit. QUARK is a lightweight hash function family which is designed by Aumasson et al. at CHES 2010. Then the extended version of QUARK was published in Journal of Cryptology 2013. In this paper, we propose an improved conditional differential attack on QUARK. One improvement is that we propose a method to select the input difference. We could obtain a set of good input differences by this method. Another improvement is that we propose an automatic condition imposing algorithm to deal with the complicated conditions efficiently and easily. It is shown that with the improved conditional differential attack on QUARK, we can detect the bias of output difference at a higher round of QUARK. Compared to the current literature, we find a distinguisher of U-QUARK/D-QUARK/S-QUARK/C-QUARK up to 157/171/292/460 rounds with increasing 2/5/33/8 rounds respectively. We have performed the attacks on each instance of QUARK on a 3.30 GHz Intel Core i5 CPU, and all these attacks take practical complexities which have been fully verified by our experiments. As far as we know, all of these results have been the best thus far.}
}


@article{DBLP:journals/cybersec/LiLW22,
	author = {Lingyun Li and
                  Xianhui Lu and
                  Kunpeng Wang},
	title = {Hash-based signature revisited},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {13},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00117-w},
	doi = {10.1186/S42400-022-00117-W},
	timestamp = {Mon, 08 Aug 2022 21:23:34 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/LiLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The current development toward quantum attack has shocked our confidence on classical digital signature schemes. As one of the mainstreams of post quantum cryptography primitives, hash-based signature has attracted more and more concern in both cryptographic research and application in recent years. The goal of this paper is to present, classify and discuss different solutions for hash-based signature. Firstly, this paper discusses the research progress in the component of hash-based signature, i.e., one-time signature and few-time signature; then classifies the tree-based public key authentication schemes of hash-based signature into limited number and stateful schemes, unlimited number and stateful schemes and unlimited number and stateless schemes. The above discussion aims to analyze the overall design idea of different categories of hash-based signatures, as well as the construction, security reduction and performance efficiency of specific schemes. Finally, the perspectives and possible development directions of hash-based signature are briefly discussed.}
}


@article{DBLP:journals/cybersec/LiYLHM22,
	author = {Ruishi Li and
                  Yunfei Yang and
                  Jinghua Liu and
                  Peiwei Hu and
                  Guozhu Meng},
	title = {The inconsistency of documentation: a study of online {C} standard
                  library documents},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {14},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00118-9},
	doi = {10.1186/S42400-022-00118-9},
	timestamp = {Mon, 08 Aug 2022 21:23:34 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/LiYLHM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The C standard libraries are basic function libraries standardized by the C language. Programmers usually refer to their API documentation provided by third-party websites. Unfortunately, these documents are not necessarily complete or accurate, especially for constraint sentences of API usage, which are called Security Specifications (SSs). SS issues can prevent programmers from following obligatory constraints, which results in API misuse vulnerabilities. Previous work studying SS issues could only find certain types of inaccurate SSs through checking the compliance between API usage and existing SSs. Therefore, we propose a novel approach SSeeker for quickly discovering missing and inaccurate SSs through the inconsistency of semantically similar SSs. More specifically, SSeeker first completes broken sentences and discovers SSs from them by judging their constraint sentiment. Then SSeeker puts semantically similar SSs from different sources into a group, which can be used to discover missing or inaccurate SSs. With the help of SSeeker, we investigated 4 popular online third-party C standard library documents, studied their conformity with the C99 standard, analyzed their APIs and SSs, and discovered 92 prototype issues, 15 web page issues, and 96 SS issues.}
}


@article{DBLP:journals/cybersec/BiLLWZ22,
	author = {Lei Bi and
                  Xianhui Lu and
                  Junjie Luo and
                  Kunpeng Wang and
                  Zhenfei Zhang},
	title = {Hybrid dual attack on {LWE} with arbitrary secrets},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {15},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00115-y},
	doi = {10.1186/S42400-022-00115-Y},
	timestamp = {Thu, 25 Aug 2022 08:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/BiLLWZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the hybrid dual attack over learning with errors (LWE) problems for any secret distribution. Prior to our work, hybrid attacks are only considered for sparse and/or small secrets. A new and interesting result from our analysis shows that for most cryptographic use cases a hybrid dual attack outperforms a standalone dual attack, regardless of the secret distribution. We formulate our results into a framework of predicting the performance of the hybrid dual attacks. We also present a few tricks that further improve our attack. To illustrate the effectiveness of our result, we re-evaluate the security of all LWE related proposals in round 3 of NIST’s post-quantum cryptography process, and improve the state-of-the-art cryptanalysis results by 2-15 bits, under the BKZ-core-SVP model.}
}


@article{DBLP:journals/cybersec/KoushkiARZGH22,
	author = {Masoud Mehrabi Koushki and
                  Ibrahim Y. Abualhaol and
                  Anandharaju Durai Raju and
                  Yang Zhou and
                  Ronnie Salvador Giagone and
                  Shengqiang Huang},
	title = {On building machine learning pipelines for Android malware detection:
                  a procedural survey of practices, challenges and opportunities},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {16},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00119-8},
	doi = {10.1186/S42400-022-00119-8},
	timestamp = {Mon, 15 Aug 2022 15:04:54 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/KoushkiARZGH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the smartphone market leader, Android has been a prominent target for malware attacks. The number of malicious applications (apps) identified for it has increased continually over the past decade, creating an immense challenge for all parties involved. For market holders and researchers, in particular, the large number of samples has made manual malware detection unfeasible, leading to an influx of research that investigate Machine Learning (ML) approaches to automate this process. However, while some of the proposed approaches achieve high performance, rapidly evolving Android malware has made them unable to maintain their accuracy over time. This has created a need in the community to conduct further research, and build more flexible ML pipelines. Doing so, however, is currently hindered by a lack of systematic overview of the existing literature, to learn from and improve upon the existing solutions. Existing survey papers often focus only on parts of the ML process (e.g., data collection or model deployment), while omitting other important stages, such as model evaluation and explanation. In this paper, we address this problem with a review of 42 highly-cited papers, spanning a decade of research (from 2011 to 2021). We introduce a novel procedural taxonomy of the published literature, covering how they have used ML algorithms, what features they have engineered, which dimensionality reduction techniques they have employed, what datasets they have employed for training, and what their evaluation and explanation strategies are. Drawing from this taxonomy, we also identify gaps in knowledge and provide ideas for improvement and future work.}
}


@article{DBLP:journals/cybersec/ShiZZTZPH22,
	author = {Ji Shi and
                  Wei Zou and
                  Chao Zhang and
                  Lingxiao Tan and
                  Yanyan Zou and
                  Yue Peng and
                  Wei Huo},
	title = {CAMFuzz: Explainable Fuzzing with Local Interpretation},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {17},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00116-x},
	doi = {10.1186/S42400-022-00116-X},
	timestamp = {Mon, 24 Oct 2022 20:51:30 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/ShiZZTZPH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Grey-box fuzzing techniques have been widely used in software bug finding. In general, there are many decisions to make in the fuzzing process, including which code block in the target program should be explored first, which bytes of an input seed should be mutated to reach the target code block, and how to mutate the chosen input bytes. However, existing solutions usually rely on random exploration or certain heuristics to choose where and how to fuzz, which limits the efficiency of fuzzing. In this paper, we propose a novel solution CAMFuzz to guide the fuzzing process with explainable decisions in explainable artificial intelligence (XAI). First, we propose a dynamic weight adjustment algorithm, which considers both the difficulty of reaching a block and the number of unvisited blocks nearby, to find code blocks worthy to explore first. Second, we utilize a widely used local interpretation technique, i.e., class activation mapping (CAM), to recognize which part of an input seed should be mutated to reach a given target code block. Therefore, CAMFuzz can distinguish which part of code in the program is more important and which positions in the input file should be mutated first, in order to achieve a better code coverage and bug finding efficiency. Third, to further help the fuzzer increase fuzzing efficiency, we leverage a lightweight static program analysis to help the fuzzer identify magic values. We implement a prototype of CAMFuzz and evaluate it on 13 real-world programs (including 11 open source targets, 2 closed-source commercial products including a Microsoft component and Hancom Office) Results show that CAMFuzz outperforms state-of-the-art fuzzers in both code coverage and bug finding. To detail, CAMFuzz on average achieves 2.07\\(\\times\\) more bugs and 1.17\\(\\times\\) coverage improvements. In total, it found 19 previously unknown vulnerabilities, of which 6 have been assigned by CVE so far.}
}


@article{DBLP:journals/cybersec/EiseleMSHB22,
	author = {Max Eisele and
                  Marcello Maugeri and
                  Rachna Shriwas and
                  Christopher Huth and
                  Giampaolo Bella},
	title = {Embedded fuzzing: a review of challenges, tools, and solutions},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {18},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00123-y},
	doi = {10.1186/S42400-022-00123-Y},
	timestamp = {Sat, 30 Sep 2023 10:11:26 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/EiseleMSHB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fuzzing has become one of the best-established methods to uncover software bugs. Meanwhile, the market of embedded systems, which binds the software execution tightly to the very hardware architecture, has grown at a steady pace, and that pace is anticipated to become yet more sustained in the near future. Embedded systems also benefit from fuzzing, but the innumerable existing architectures and hardware peripherals complicate the development of general and usable approaches, hence a plethora of tools have recently appeared. Here comes a stringent need for a systematic review in the area of fuzzing approaches for embedded systems, which we term “embedded fuzzing” for brevity. The inclusion criteria chosen in this article are semi-objective in their coverage of the most relevant publication venues as well as of our personal judgement. The review rests on a formal definition we develop to represent the realm of embedded fuzzing. It continues by discussing the approaches that satisfy the inclusion criteria, then defines the relevant elements of comparison and groups the approaches according to how the execution environment is served to the system under test. The resulting review produces a table with 42 entries, which in turn supports discussion suggesting vast room for future research due to the limitations noted.}
}


@article{DBLP:journals/cybersec/FanWJLCLL22,
	author = {Zhaoshan Fan and
                  Qing Wang and
                  Haoran Jiao and
                  Junrong Liu and
                  Zelin Cui and
                  Song Liu and
                  Yuling Liu},
	title = {{PUMD:} a {PU} learning-based malicious domain detection framework},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {19},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00124-x},
	doi = {10.1186/S42400-022-00124-X},
	timestamp = {Mon, 28 Aug 2023 21:41:15 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/FanWJLCLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain name system (DNS), as one of the most critical internet infrastructure, has been abused by various cyber attacks. Current malicious domain detection capabilities are limited by insufficient credible label information, severe class imbalance, and incompact distribution of domain samples in different malicious activities. This paper proposes a malicious domain detection framework named PUMD, which innovatively introduces Positive and Unlabeled (PU) learning solution to solve the problem of insufficient label information, adopts customized sample weight to improve the impact of class imbalance, and effectively constructs evidence features based on resource overlapping to reduce the intra-class distance of malicious samples. Besides, a feature selection strategy based on permutation importance and binning is proposed to screen the most informative detection features. Finally, we conduct experiments on the open source real DNS traffic dataset provided by QI-ANXIN Technology Group to evaluate the PUMD framework’s ability to capture potential command and control (C&C) domains for malicious activities. The experimental results prove that PUMD can achieve the best detection performance under different label frequencies and class imbalance ratios.}
}


@article{DBLP:journals/cybersec/ZhangZYZJXSLH22,
	author = {Yu Zhang and
                  Nanyu Zhong and
                  Wei You and
                  Yanyan Zou and
                  Kunpeng Jian and
                  Jiahuan Xu and
                  Jian Sun and
                  Baoxu Liu and
                  Wei Huo},
	title = {NDFuzz: a non-intrusive coverage-guided fuzzing framework for virtualized
                  network devices},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {21},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00120-1},
	doi = {10.1186/S42400-022-00120-1},
	timestamp = {Mon, 05 Dec 2022 13:35:25 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/ZhangZYZJXSLH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network function virtualization provides programmable in-network middlewares by leveraging virtualization technologies and commodity hardware and has gained popularity among all mainstream network device manufacturers. Yet it is challenging to apply coverage-guided fuzzing, one of the state-of-the-art vulnerability discovery approaches, to those virtualized network devices, due to inevitable integrity protection adopted by those devices. In this paper, we propose a coverage-guided fuzzing framework NDFuzz for virtualized network devices with a novel integrity protection bypassing method, which is able to distinguish processes of virtualized network devices from hypervisors with a carefully designed non-intrusive page global directory inference technique. We implement NDFuzz atop of two black-box fuzzers and evaluate NDFuzz with three representative network protocols, SNMP , DHCP and NTP , on nine popular virtualized network devices. NDFuzz obtains an average 36% coverage improvement in comparison with its black-box counterparts. NDFuzz discovers 2 0-Day vulnerabilities and 1 1-Day vulnerability with coverage guidance while the black-box fuzzer can find only one of them. All discovered vulnerabilities are confirmed by corresponding vendors.}
}


@article{DBLP:journals/cybersec/AwasthiG22,
	author = {Anjaneya Awasthi and
                  Noopur Goel},
	title = {Phishing website prediction using base and ensemble classifier techniques
                  with cross-validation},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {22},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00126-9},
	doi = {10.1186/S42400-022-00126-9},
	timestamp = {Mon, 05 Dec 2022 13:35:25 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/AwasthiG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet or public internetwork has become a vulnerable place nowadays as there are so many threats available for the novice or careless users because there exist many types of tools and techniques being used by notorious people on it to victimize people somehow and gain access to their precious and personal data resulting in sometimes smaller. However, these victims suffer considerable losses in many instances due to their entrapment in such traps as hacking, cracking, data diddling, Trojan attacks, web jacking, salami attacks, and phishing. Therefore, despite the web users and the software and application developer's continuous effort to make and keep the IT infrastructure safe and secure using many techniques, including encryption, digital signatures, digital certificates, etc. this paper focuses on the problem of phishing to detect and predict phishing websites URLs, primary machine learning classifiers and new ensemble-based techniques are used on 2 distinct datasets. Again on a merged dataset, this study is conducted in 3 phases. First, they include classification using base classifiers, Ensemble classifiers, and then ensemble classifiers are tested with and without cross-validation. Finally, their performance is analyzed, and the results are presented at last to help others use this study for their upcoming research.}
}


@article{DBLP:journals/cybersec/ZhangXXX22,
	author = {Weiwei Zhang and
                  Zhengzi Xu and
                  Yang Xiao and
                  Yinxing Xue},
	title = {Unleashing the power of pseudo-code for binary code similarity analysis},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {23},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00121-0},
	doi = {10.1186/S42400-022-00121-0},
	timestamp = {Wed, 17 Jul 2024 07:49:04 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/ZhangXXX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Code similarity analysis has become more popular due to its significant applicantions, including vulnerability detection, malware detection, and patch analysis. Since the source code of the software is difficult to obtain under most circumstances, binary-level code similarity analysis (BCSA) has been paid much attention to. In recent years, many BCSA studies incorporating AI techniques focus on deriving semantic information from binary functions with code representations such as assembly code, intermediate representations, and control flow graphs to measure the similarity. However, due to the impacts of different compilers, architectures, and obfuscations, binaries compiled from the same source code may vary considerably, which becomes the major obstacle for these works to obtain robust features. In this paper, we propose a solution, named UPPC (Unleashing the Power of Pseudo-code), which leverages the pseudo-code of binary function as input, to address the binary code similarity analysis challenge, since pseudo-code has higher abstraction and is platform-independent compared to binary instructions. UPPC selectively inlines the functions to capture the full function semantics across different compiler optimization levels and uses a deep pyramidal convolutional neural network to obtain the semantic embedding of the function. We evaluated UPPC on a data set containing vulnerabilities and a data set including different architectures (X86, ARM), different optimization options (O0-O3), different compilers (GCC, Clang), and four obfuscation strategies. The experimental results show that the accuracy of UPPC in function search is 33.2% higher than that of existing methods.}
}


@article{DBLP:journals/cybersec/Wang0F0Y22,
	author = {Feng Wang and
                  Hang Zhou and
                  Han Fang and
                  Weiming Zhang and
                  Nenghai Yu},
	title = {Deep 3D mesh watermarking with self-adaptive robustness},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {24},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00125-w},
	doi = {10.1186/S42400-022-00125-W},
	timestamp = {Thu, 05 Jan 2023 17:09:24 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/Wang0F0Y22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robust 3D mesh watermarking is a traditional research topic in computer graphics, which provides an efficient solution to the copyright protection for 3D meshes. Traditionally, researchers need manually design watermarking algorithms to achieve sufficient robustness for the actual application scenarios. In this paper, we propose the first deep learning-based 3D mesh watermarking network, which can provide a more general framework for this problem. In detail, we propose an end-to-end network, consisting of a watermark embedding sub-network, a watermark extracting sub-network and attack layers. We employ the topology-agnostic graph convolutional network (GCN) as the basic convolution operation, therefore our network is not limited by registered meshes (which share a fixed topology). For the specific application scenario, we can integrate the corresponding attack layers to guarantee adaptive robustness against possible attacks. To ensure the visual quality of watermarked 3D meshes, we design the curvature consistency loss function to constrain the local geometry smoothness of watermarked meshes. Experimental results show that the proposed method can achieve more universal robustness while guaranteeing comparable visual quality.}
}


@article{DBLP:journals/cybersec/HeinoHV22,
	author = {Jenny Heino and
                  Antti Hakkala and
                  Seppo Virtanen},
	title = {Study of methods for endpoint aware inspection in a next generation
                  firewall},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {25},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00127-8},
	doi = {10.1186/S42400-022-00127-8},
	timestamp = {Mon, 24 Oct 2022 20:51:30 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/HeinoHV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the global increase in remote work with the COVID-19 pandemic and deperimeterization due to cloud deployment of next generation firewalls, the concept of a next generation firewall is at a breaking point. It is becoming more difficult to define the barrier between the good and the bad. To provide the best security for an endpoint with minimal false positives or false negatives it is often necessary to identify the communicating endpoint application. In this study, we present an analysis of key research and methods for providing endpoint aware protection in the context of a next generation firewall. We examine both academic research as well as state-of-the-art of the existing next generation firewall implementations. We divide endpoint application identification into passive and active methods. For passive endpoint application identification, we study several traffic fingerprinting methods for different protocols. For active methods we consider active scanning, endpoint metadata analysis and content injection and reference existing implementations. We conclude that there are several open areas for future research, and that none of the considered methods is a silver bullet solution for endpoint aware inspection in the context of a next generation firewall. To our best knowledge, this is the first study to examine current research and existing implementations of endpoint aware inspection.}
}


@article{DBLP:journals/cybersec/XiaoWC22,
	author = {Haiyan Xiao and
                  Lifang Wang and
                  Jinyong Chang},
	title = {The differential fault analysis on block cipher FeW},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {28},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00130-z},
	doi = {10.1186/S42400-022-00130-Z},
	timestamp = {Mon, 28 Aug 2023 21:41:15 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/XiaoWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Feather weight (FeW) cipher is a lightweight block cipher proposed by Kumar et al. in 2019, which takes 64 bits plaintext as input and produces 64 bits ciphertext. As Kumar et al. said, FeW is a software oriented design with the aim of achieving high efficiency in software based environments. It seems that FeW is immune to many cryptographic attacks, like linear, impossible differential, differential and zero correlation attacks. However, in recent work, Xie et al. reassessed the security of FeW. More precisely, they proved that under the differential fault analysis (DFA) on the encryption states, an attacker can completely recover the master secret key. In this paper, we revisit the block cipher FeW and consider the DFA on its key schedule algorithm, which is rather popular cryptanalysis for kinds of block ciphers. In particular, by respectively injected faults into the 30th and 29th round subkeys, one can recover about 55/80\xa0≈\xa069% bits of master key. Then the brute force searching remaining bits, one can obtain the full master secret key. The simulations and experiment results show that our analysis is practical.}
}


@article{DBLP:journals/cybersec/YangYCM22,
	author = {Ruipeng Yang and
                  Aimin Yu and
                  Lijun Cai and
                  Dan Meng},
	title = {Subspace clustering via graph auto-encoder network for unknown encrypted
                  traffic recognition},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	pages = {29},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00131-y},
	doi = {10.1186/S42400-022-00131-Y},
	timestamp = {Thu, 05 Jan 2023 17:09:24 +0100},
	biburl = {https://dblp.org/rec/journals/cybersec/YangYCM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The traffic encryption brings new challenges to the identification of unknown encrypted traffic. Currently, machine learning is the most commonly used encrypted traffic recognization technology, but this method relies on expensive prior label information. Therefore, we propose a subspace clustering via graph auto-encoder network (SCGAE) to recognize unknown applications without prior label information. The SCGAE adopts a graph encoder-decoder structure, which can comprehensively utilize the feature and structure information to extract discriminative embedding representation. Additionally, the self-supervised module is introduced, which use the clustering labels acts as a supervisor to guide the learning of the graph encoder-decoder module. Finally, we obtain the self-expression coefficient matrix through the self-expression module and map it to the subspace for clustering. The results show that SCGAE has better performance than all benchmark models in unknown encrypted traffic recognization.}
}


@article{DBLP:journals/cybersec/LiaoHC22,
	author = {Zhijian Liao and
                  Qiong Huang and
                  Xinjian Chen},
	title = {A fully dynamic forward-secure group signature from lattice},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00122-z},
	doi = {10.1186/S42400-022-00122-Z},
	timestamp = {Wed, 20 Sep 2023 13:32:40 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/LiaoHC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A forward-secure group signature (FSGS) ensures the unforgeability of signatures in the past time period despite signing secret key is leaked in the current time period. As we know, traditional FSGS schemes are mostly relying on number-theoretic assumptions unable to resist quantum attacks. Therefore, we present an efficient lattice-based fully dynamic (i.e. users can flexibly join or quit the group) forward-secure group signature (DFSGS) by combining an improved version of FSGS scheme proposed by Ling. Based on an efficient zero-knowledge argument, we construct argument of knowledge of the committed value and the plaintext that help with privacy protection. Our DFSGS scheme is proved to be anonymous and forward-secure traceable relying on short integer solution and learning with errors assumptions in random oracle model. Moreover, the lengths of group public key and signature of our DFSGS scheme have been improved, and the length of user secret key has no connection with the quantity of group members.}
}


@article{DBLP:journals/cybersec/RenganathanYAY22,
	author = {Vishnu Renganathan and
                  Ekim Yurtsever and
                  Qadeer Ahmed and
                  Aylin Yener},
	title = {Valet attack on privacy: a cybersecurity threat in automotive Bluetooth
                  infotainment systems},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00132-x},
	doi = {10.1186/S42400-022-00132-X},
	timestamp = {Wed, 17 May 2023 21:57:19 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/RenganathanYAY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern automobiles are equipped with connectivity features to enhance the user’s comfort. Bluetooth is one such communication technology that is used to pair a personal device with an automotive infotainment unit. Upon pairing, the user could access the personal information on the phone through the automotive head unit with minimum distraction while driving. However, such connectivity introduces a possibility for privacy attacks. Hence, performing an in-depth analysis of the system with privacy constraints is extremely important to prevent unauthorized access to personal information. In this work, we perform a systematic analysis of the Bluetooth network of an automotive infotainment unit to exploit security and privacy-related vulnerabilities. We model the identified threat with respect to privacy constraints of the system, emphasize the severity of attacks through a standardized rating metric and then provide potential countermeasures to prevent the attack. We perform System Theoretic Process Analysis for Privacy as a part of the systematic analysis and use the Common Vulnerability Scoring System to derive attack severity. The identified vulnerabilities are due to design flaws and assumptions on Bluetooth protocol implementation on automotive infotainment systems. We then elicit the vulnerability by performing a privacy attack on the Automotive system in an actual vehicle. We use Android Open-Source Project to report our findings and propose defense strategies.}
}


@article{DBLP:journals/cybersec/VarmaCS22,
	author = {Gatha Varma and
                  Ritu Chauhan and
                  Dhananjay Singh},
	title = {Sarve: synthetic data and local differential privacy for private frequency
                  estimation},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00129-6},
	doi = {10.1186/S42400-022-00129-6},
	timestamp = {Mon, 28 Aug 2023 21:41:15 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/VarmaCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The collection of user attributes by service providers is a double-edged sword. They are instrumental in driving statistical analysis to train more accurate predictive models like recommenders. The analysis of the collected user data includes frequency estimation for categorical attributes. Nonetheless, the users deserve privacy guarantees against inadvertent identity disclosures. Therefore algorithms called frequency oracles were developed to randomize or perturb user attributes and estimate the frequencies of their values. We propose Sarve, a frequency oracle that used Randomized Aggregatable Privacy-Preserving Ordinal Response (RAPPOR) and Hadamard Response (HR) for randomization in combination with fake data. The design of a service-oriented architecture must consider two types of complexities, namely computational and communication. The functions of such systems aim to minimize the two complexities and therefore, the choice of privacy-enhancing methods must be a calculated decision. The variant of RAPPOR we had used was realized through bloom filters. A bloom filter is a memory-efficient data structure that offers time complexity of O(1). On the other hand, HR has been proven to give the best communication costs of the order of log(b) for b-bits communication. Therefore, Sarve is a step towards frequency oracles that exhibit how privacy provisions of existing methods can be combined with those of fake data to achieve statistical results comparable to the original data. Sarve also implemented an adaptive solution enhanced from the work of Arcolezi et al. The use of RAPPOR was found to provide better privacy-utility tradeoffs for specific privacy budgets in both high and general privacy regimes.}
}


@article{DBLP:journals/cybersec/JiaLLWLL22,
	author = {Kun Jia and
                  Chaoge Liu and
                  Qixu Liu and
                  Junnan Wang and
                  Jiazhi Liu and
                  Feng Liu},
	title = {A lightweight DDoS detection scheme under {SDN} context},
	journal = {Cybersecur.},
	volume = {5},
	number = {1},
	year = {2022},
	url = {https://doi.org/10.1186/s42400-022-00128-7},
	doi = {10.1186/S42400-022-00128-7},
	timestamp = {Wed, 17 May 2023 21:57:19 +0200},
	biburl = {https://dblp.org/rec/journals/cybersec/JiaLLWLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software-defined networking (SDN), a novel network paradigm, separates the control plane and data plane into different network equipment to realize the flexible control of network traffic. Its excellent programmability and global view present many new opportunities. DDoS detection under the SDN context is an important and challenging research field. Some previous works attempted to collect and analyze statistics related to flows, usually recorded in switches, to address DDoS threats. In contrast, other works applied machine learning-based solutions to identify DDoS and achieved promising results. Generally, most previous works need to periodically request flow rules or packets to obtain flow statistics or features to detect stealthy exceptions. Nevertheless, the request for flow rules is very time-consuming and CPU-consuming; moreover may congest the communication channel between the controller and the switches. Therefore, we present FORT, a lightweight DDoS detection scheme, which spreads the rule-based detection algorithm at edge switches and determines whether to start it by periodically retrieving the ports state. A time-series algorithm, ARIMA, is utilized to determine the port statistics adaptively, and an SVM algorithm is applied to detect whether a DDoS attack does occur. Representative experiments demonstrate that FORT can significantly reduce the controller load and provide a reliable detection accuracy. Referring to the false alarm rate of 1.24% in the comparison scheme, the false alarm rate of this scheme is only 0.039%, which significantly reduces the probability of false alarm. Besides, by introducing the alarm mechanism, this scheme can reduce the load of the southbound channel by more than 60% in the normal state.}
}
