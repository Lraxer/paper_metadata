@article{DBLP:journals/tissec/ZhaoAKTY20,
	author = {Benjamin Zi Hao Zhao and
                  Hassan Jameel Asghar and
                  Mohamed Ali K{\^{a}}afar and
                  Francesca Trevisan and
                  Haiyue Yuan},
	title = {Exploiting Behavioral Side Channels in Observation Resilient Cognitive
                  Authentication Schemes},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {1},
	pages = {1:1--1:33},
	year = {2020},
	url = {https://doi.org/10.1145/3414844},
	doi = {10.1145/3414844},
	timestamp = {Sat, 08 Jan 2022 02:22:54 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/ZhaoAKTY20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Observation Resilient Authentication Schemes (ORAS) are a class of shared secret challenge–response identification schemes where a user mentally computes the response via a cognitive function to authenticate herself such that eavesdroppers cannot readily extract the secret. Security evaluation of ORAS generally involves quantifying information leaked via observed challenge–response pairs. However, little work has evaluated information leaked via human behavior while interacting with these schemes. A common way to achieve observation resilience is by including a modulus operation in the cognitive function. This minimizes the information leaked about the secret due to the many-to-one map from the set of possible secrets to a given response. In this work, we show that user behavior can be used as a side channel to obtain the secret in such ORAS. Specifically, the user’s eye-movement patterns and associated timing information can deduce whether a modulus operation was performed (a fundamental design element) to leak information about the secret. We further show that the secret can still be retrieved if the deduction is erroneous, a more likely case in practice. We treat the vulnerability analytically and propose a generic attack algorithm that iteratively obtains the secret despite the “faulty” modulus information. We demonstrate the attack on five ORAS and show that the secret can be retrieved with considerably less challenge–response pairs than non-side-channel attacks (e.g., algebraic/statistical attacks). In particular, our attack is applicable on Mod10, a one-time-pad-based scheme, for which no non-side-channel attack exists. We field test our attack with a small-scale eye-tracking user study.}
}


@article{DBLP:journals/tissec/AhmedMO20,
	author = {Chuadhry Mujeeb Ahmed and
                  Aditya P. Mathur and
                  Mart{\'{\i}}n Ochoa},
	title = {\emph{NoiSense Print}: Detecting Data Integrity Attacks on Sensor
                  Measurements Using Hardware-based Fingerprints},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {1},
	pages = {2:1--2:35},
	year = {2020},
	url = {https://doi.org/10.1145/3410447},
	doi = {10.1145/3410447},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/AhmedMO20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fingerprinting of various physical and logical devices has been proposed for uniquely identifying users or devices of mainstream IT systems such as PCs, laptops, and smart phones. However, the application of such techniques in Industrial Control Systems (ICS) is less explored for reasons such as a lack of direct access to such systems and the cost of faithfully reproducing realistic threat scenarios. This work addresses the feasibility of using fingerprinting techniques in the context of realistic ICS related to water treatment and distribution systems. A model-free sensor fingerprinting scheme (NoiSense) and a model-based sensor fingerprinting scheme (NoisePrint) are proposed. Using extensive experimentation with sensors, it is shown that noise patterns due to microscopic imperfections in hardware manufacturing can uniquely identify sensors with accuracy as high as 97%. The proposed technique can be used to detect physical attacks, such as the replacement of legitimate sensors by faulty or manipulated sensors. For NoisePrint, a combined fingerprint for sensor and process noise is created. The difference (called residual), between expected and observed values, i.e., noise, is used to derive a model of the system. It was found that in steady state the residual vector is a function of process and sensor noise. Data from experiments reveals that a multitude of sensors can be uniquely identified with a minimum accuracy of 90% based on NoisePrint. Also proposed is a novel challenge-response protocol that exposes more powerful cyber-attacks, including replay attacks.}
}


@article{DBLP:journals/tissec/AlexopoulosHSM20,
	author = {Nikolaos Alexopoulos and
                  Sheikh Mahbub Habib and
                  Steffen Schulz and
                  Max M{\"{u}}hlh{\"{a}}user},
	title = {The Tip of the Iceberg: On the Merits of Finding Security Bugs},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {1},
	pages = {3:1--3:33},
	year = {2020},
	url = {https://doi.org/10.1145/3406112},
	doi = {10.1145/3406112},
	timestamp = {Mon, 05 Feb 2024 20:25:07 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/AlexopoulosHSM20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we investigate a fundamental question regarding software security: Is the security of SW releases increasing over time? We approach this question with a detailed analysis of the large body of open-source software packaged in the popular Debian GNU/Linux distribution. Contrary to common intuition, we find no clear evidence that the vulnerability rate of widely used software decreases over time: Even in popular and “stable” releases, the fixing of bugs does not seem to reduce the rate of newly identified vulnerabilities. The intuitive conclusion is worrisome: Commonly employed development and validation procedures do not seem to scale with the increase of features and complexity—they are only chopping pieces off the top of an iceberg of vulnerabilities. To the best of our knowledge, this is the first investigation into the problem that studies a complete distribution of software, spanning multiple versions. Although we can not give a definitive answer, we show that several popular beliefs also cannot be confirmed given our dataset. We publish our Debian Vulnerability Analysis Framework (DVAF), an automated dataset creation and analysis process, to enable reproduction and further analysis of our results. Overall, we hope our contributions provide important insights into the vulnerability discovery process and help in identifying effective techniques for vulnerability analysis and prevention.}
}


@article{DBLP:journals/tissec/MeylanCCHBH20,
	author = {Alexandre Meylan and
                  Mauro Cherubini and
                  Bertil Chapuis and
                  Mathias Humbert and
                  Igor Bilogrevic and
                  K{\'{e}}vin Huguenin},
	title = {A Study on the Use of Checksums for Integrity Verification of Web
                  Downloads},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {1},
	pages = {4:1--4:36},
	year = {2020},
	url = {https://doi.org/10.1145/3410154},
	doi = {10.1145/3410154},
	timestamp = {Sat, 08 Jan 2022 02:22:55 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/MeylanCCHBH20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {App stores provide access to millions of different programs that users can download on their computers. Developers can also make their programs available for download on their websites and host the program files either directly on their website or on third-party platforms, such as mirrors. In the latter case, as users download the software without any vetting from the developers, they should take the necessary precautions to ensure that it is authentic. One way to accomplish this is to check that the published file’s integrity verification code—the checksum—matches that (if provided) of the downloaded file. To date, however, there is little evidence to suggest that such a process is effective. Even worse, very few usability studies about it exist. In this article, we provide the first comprehensive study that assesses the usability and effectiveness of the manual checksum verification process. First, by means of an in-situ experiment with 40 participants and eye-tracking technology, we show that the process is cumbersome and error-prone. Second, after a 4-month-long in-the-wild experiment with 134 participants, we demonstrate how our proposed solution—a Chrome extension that verifies checksums automatically—significantly reduces human errors, improves coverage, and has only limited impact on usability. It also confirms that, sadly, only a tiny minority of websites that link to executable files in our sample provide checksums (0.01%), which is a strong call to action for web standards bodies, service providers, and content creators to increase the use of file integrity verification on their properties.}
}


@article{DBLP:journals/tissec/ShreeveHEAFR20,
	author = {Benjamin Shreeve and
                  Joseph Hallett and
                  Matthew Edwards and
                  Pauline Anthonysamy and
                  Sylvain Frey and
                  Awais Rashid},
	title = {"So if Mr Blue Head here clicks the link..." Risk Thinking in Cyber
                  Security Decision Making},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {1},
	pages = {5:1--5:29},
	year = {2020},
	url = {https://doi.org/10.1145/3419101},
	doi = {10.1145/3419101},
	timestamp = {Fri, 09 Apr 2021 18:26:45 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/ShreeveHEAFR20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber security decision making is inherently complicated, with nearly every decision having knock-on consequences for an organisation’s vulnerability and exposure. This is further compounded by the fact that decision-making actors are rarely security experts and may have an incomplete understanding of the security that the organisation currently has in place. They must contend with a multitude of possible security options that they may only partially understand. This challenge is met by decision makers’ risk thinking—their strategies for identifying risks, assessing their severity, and prioritising responses. We study the risk thinking strategies employed by teams of participants in an existing dataset derived from a tabletop cyber-physical systems security game.\xa0 Our analysis identifies four structural patterns of risk thinking and two reasoning strategies: risk-first and opportunity-first. Our work highlights that risk-first approaches (as prescribed by the likes of NIST-800-53\xa0and ISO 27001)\xa0are followed neither substantially nor exclusively when it comes to decision making. Instead, our analysis finds that decision making is affected by the plasticity of teams—that is, the ability to readily switch between ideas and practising both risk-first and opportunity-first reasoning.}
}


@article{DBLP:journals/tissec/HuZL20,
	author = {Zhisheng Hu and
                  Minghui Zhu and
                  Peng Liu},
	title = {Adaptive Cyber Defense Against Multi-Stage Attacks Using Learning-Based
                  {POMDP}},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {1},
	pages = {6:1--6:25},
	year = {2020},
	url = {https://doi.org/10.1145/3418897},
	doi = {10.1145/3418897},
	timestamp = {Sat, 08 Jan 2022 02:22:54 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/HuZL20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Growing multi-stage attacks in computer networks impose significant security risks and necessitate the development of effective defense schemes that are able to autonomously respond to intrusions during vulnerability windows. However, the defender faces several real-world challenges, e.g., unknown likelihoods and unknown impacts of successful exploits. In this article, we leverage reinforcement learning to develop an innovative adaptive cyber defense to maximize the cost-effectiveness subject to the aforementioned challenges. In particular, we use Bayesian attack graphs to model the interactions between the attacker and networks. Then we formulate the defense problem of interest as a partially observable Markov decision process problem where the defender maintains belief states to estimate system states, leverages Thompson sampling to estimate transition probabilities, and utilizes reinforcement learning to choose optimal defense actions using measured utility values. The algorithm performance is verified via numerical simulations based on real-world attacks.}
}


@article{DBLP:journals/tissec/PapaevripidesA21,
	author = {Michalis Papaevripides and
                  Elias Athanasopoulos},
	title = {Exploiting Mixed Binaries},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {2},
	pages = {7:1--7:29},
	year = {2021},
	url = {https://doi.org/10.1145/3418898},
	doi = {10.1145/3418898},
	timestamp = {Tue, 09 Mar 2021 08:38:53 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/PapaevripidesA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsafe programming systems are still very popular, despite the shortcomings due to several published memory-corruption vulnerabilities. Toward defending memory corruption, compilers have started to employ advanced software hardening such as Control-flow Integrity (CFI) and SafeStack. However, there is a broad interest for realizing compilers that impose memory safety with no heavy runtime support (e.g., garbage collection). Representative examples of this category are Rust and Go, which enforce memory safety primarily statically at compile time. Software hardening and Rust/Go are promising directions for defending memory corruption, albeit combining the two is questionable. In this article, we consider hardened mixed binaries, i.e., machine code that has been produced from different compilers and, in particular, from hardened C/C++ and Rust/Go (e.g., Mozilla Firefox, Dropbox, npm, and Docker). Our analysis is focused on Mozilla Firefox, which outsources significant code to Rust and is open source with known public vulnerabilities (with assigned CVE). Furthermore, we extend our analysis in mixed binaries that leverage Go, and we derive similar results. The attacks explored in this article do not exploit Rust or Go binaries that depend on some legacy (vulnerable) C/C++ code. In contrast, we explore how Rust/Go compiled code can stand as a vehicle for bypassing hardening in C/C++ code. In particular, we discuss CFI and SafeStack, which are available in the latest Clang. Our assessment concludes that CFI can be completely nullified through Rust or Go code by constructing much simpler attacks than state-of-the-art CFI bypasses.}
}


@article{DBLP:journals/tissec/CorderoVWMN21,
	author = {Carlos Garcia Cordero and
                  Emmanouil Vasilomanolakis and
                  Aidmar Wainakh and
                  Max M{\"{u}}hlh{\"{a}}user and
                  Simin Nadjm{-}Tehrani},
	title = {On Generating Network Traffic Datasets with Synthetic Attacks for
                  Intrusion Detection},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {2},
	pages = {8:1--8:39},
	year = {2021},
	url = {https://doi.org/10.1145/3424155},
	doi = {10.1145/3424155},
	timestamp = {Fri, 09 Apr 2021 18:26:45 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/CorderoVWMN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most research in the field of network intrusion detection heavily relies on datasets. Datasets in this field, however, are scarce and difficult to reproduce. To compare, evaluate, and test related work, researchers usually need the same datasets or at least datasets with similar characteristics as the ones used in related work. In this work, we present concepts and the Intrusion Detection Dataset Toolkit (ID2T) to alleviate the problem of reproducing datasets with desired characteristics to enable an accurate replication of scientific results. Intrusion Detection Dataset Toolkit (ID2T) facilitates the creation of labeled datasets by injecting synthetic attacks into background traffic. The injected synthetic attacks created by ID2T blend with the background traffic by mimicking the background traffic’s properties. This article has three core contributions. First, we present a comprehensive survey on intrusion detection datasets. In the survey, we propose a classification to group the negative qualities found in the datasets. Second, the architecture of ID2T is revised, improved, and expanded in comparison to previous work. The architectural changes enable ID2T to inject recent and advanced attacks, such as the EternalBlue exploit or a peer-to-peer botnet. ID2T’s functionality provides a set of tests, known as TIDED, that helps identify potential defects in the background traffic into which attacks are injected. Third, we illustrate how ID2T is used in different use-case scenarios to replicate scientific results with the help of reproducible datasets. ID2T is open source software and is made available to the community to expand its arsenal of attacks and capabilities.}
}


@article{DBLP:journals/tissec/BhattacharjeeMS21,
	author = {Shameek Bhattacharjee and
                  Venkata Praveen Kumar Madhavarapu and
                  Simone Silvestri and
                  Sajal K. Das},
	title = {Attack Context Embedded Data Driven Trust Diagnostics in Smart Metering
                  Infrastructure},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {2},
	pages = {9:1--9:36},
	year = {2021},
	url = {https://doi.org/10.1145/3426739},
	doi = {10.1145/3426739},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/BhattacharjeeMS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spurious power consumption data reported from compromised meters controlled by organized adversaries in the Advanced Metering Infrastructure (AMI) may have drastic consequences on a smart grid’s operations. While existing research on data falsification in smart grids mostly defends against isolated electricity theft, we introduce a taxonomy of various data falsification attack types, when smart meters are compromised by organized or strategic rivals. To counter these attacks, we first propose a coarse-grained and a fine-grained anomaly-based security event detection technique that uses indicators such as deviation and directional change in the time series of the proposed anomaly detection metrics to indicate: (i) occurrence, (ii) type of attack, and (iii) attack strategy used, collectively known asattack context. Leveraging the attack context information, we propose three attack response metrics to the inferred attack context: (a) an unbiased mean indicating a robust location parameter; (b) a median absolute deviation indicating a robust scale parameter; and (c) an attack probability time ratio metric indicating the active time horizon of attacks. Subsequently, we propose a trust scoring model based on Kullback-Leibler (KL) divergence, that embeds the appropriate unbiased mean, the median absolute deviation, and the attack probability ratio metric at runtime to produce trust scores for each smart meter. These trust scores help classify compromised smart meters from the non-compromised ones. The embedding of the attack context, into the trust scoring model, facilitates accurate and rapid classification of compromised meters, even under large fractions of compromised meters, generalize across various attack strategies and margins of false data. Using real datasets collected from two different AMIs, experimental results show that our proposed framework has a high true positive detection rate, while the average false alarm and missed detection rates are much lesser than 10% for most attack combinations for two different real AMI micro-grid datasets. Finally, we also establish fundamental theoretical limits of the proposed method, which will help assess the applicability of our method to other domains.}
}


@article{DBLP:journals/tissec/ArceriM21,
	author = {Vincenzo Arceri and
                  Isabella Mastroeni},
	title = {Analyzing Dynamic Code: {A} Sound Abstract Interpreter for \emph{Evil}
                  Eval},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {2},
	pages = {10:1--10:38},
	year = {2021},
	url = {https://doi.org/10.1145/3426470},
	doi = {10.1145/3426470},
	timestamp = {Sat, 08 Jan 2022 02:22:54 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/ArceriM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic languages, such as JavaScript, employ string-to-code primitives to turn dynamically generated text into executable code at run-time. These features make standard static analysis extremely hard if not impossible, because its essential data structures, i.e., the control-flow graph and the system of recursive equations associated with the program to analyze, are themselves dynamically mutating objects. Nevertheless, assembling code at run-time by manipulating strings, such as by eval in JavaScript, has been always strongly discouraged, since it is often recognized that “eval is evil,” leading static analyzers to not consider such statements or ignoring their effects. Unfortunately, the lack of formal approaches to analyze string-to-code statements pose a perfect habitat for malicious code, that is surely evil and do not respect good practice rules, allowing them to hide malicious intents as strings to be converted to code and making static analyses blind to the real malicious aim of the code. Hence, the need to handle string-to-code statements approximating what they can execute, and therefore allowing the analysis to continue (even in the presence of dynamically generated program statements) with an acceptable degree of precision, should be clear. To reach this goal, we propose a static analysis allowing us to collect string values and to soundly over-approximate and analyze the code potentially executed by a string-to-code statement.}
}


@article{DBLP:journals/tissec/BotacinAOKVOGG21,
	author = {Marcus Botacin and
                  Hojjat Aghakhani and
                  Stefano Ortolani and
                  Christopher Kruegel and
                  Giovanni Vigna and
                  Daniela Oliveira and
                  Paulo L{\'{\i}}cio de Geus and
                  Andr{\'{e}} Gr{\'{e}}gio},
	title = {One Size Does Not Fit All: {A} Longitudinal Analysis of Brazilian
                  Financial Malware},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {2},
	pages = {11:1--11:31},
	year = {2021},
	url = {https://doi.org/10.1145/3429741},
	doi = {10.1145/3429741},
	timestamp = {Sat, 09 Apr 2022 12:26:32 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/BotacinAOKVOGG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware analysis is an essential task to understand infection campaigns, the behavior of malicious codes, and possible ways to mitigate threats. Malware analysis also allows better assessment of attackers’ capabilities, techniques, and processes. Although a substantial amount of previous work provided a comprehensive analysis of the international malware ecosystem, research on regionalized, country-, and population-specific malware campaigns have been scarce. Moving towards addressing this gap, we conducted a longitudinal (2012-2020) and comprehensive (encompassing an entire population of online banking users) study of MS Windows desktop malware that actually infected Brazilian banks’ users. We found that the Brazilian financial desktop malware has been evolving quickly: it started to make use of a variety of file formats instead of typical PE binaries, relied on native system resources, and abused obfuscation techniques to bypass detection mechanisms. Our study on the threats targeting a significant population on the ecosystem of the largest and most populous country in Latin America can provide invaluable insights that may be applied to other countries’ user populations, especially those in the developing world that might face cultural peculiarities similar to Brazil’s. With this evaluation, we expect to motivate the security community/industry to seriously consider a deeper level of customization during the development of next-generation anti-malware solutions, as well as to raise awareness towards regionalized and targeted Internet threats.}
}


@article{DBLP:journals/tissec/WagnerY21,
	author = {Isabel Wagner and
                  Iryna Yevseyeva},
	title = {Designing Strong Privacy Metrics Suites Using Evolutionary Optimization},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {2},
	pages = {12:1--12:35},
	year = {2021},
	url = {https://doi.org/10.1145/3439405},
	doi = {10.1145/3439405},
	timestamp = {Sat, 08 Jan 2022 02:22:54 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/WagnerY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ability to measure privacy accurately and consistently is key in the development of new privacy protections. However, recent studies have uncovered weaknesses in existing privacy metrics, as well as weaknesses caused by the use of only a single privacy metric. Metrics suites, or combinations of privacy metrics, are a promising mechanism to alleviate these weaknesses, if we can solve two open problems: which metrics should be combined and how. In this article, we tackle the first problem, i.e., the selection of metrics for strong metrics suites, by formulating it as a knapsack optimization problem with both single and multiple objectives. Because solving this problem exactly is difficult due to the large number of combinations and many qualities/objectives that need to be evaluated for each metrics suite, we apply 16 existing evolutionary and metaheuristic optimization algorithms. We solve the optimization problem for three privacy application domains: genomic privacy, graph privacy, and vehicular communications privacy. We find that the resulting metrics suites have better properties, i.e., higher monotonicity, diversity, evenness, and shared value range, than previously proposed metrics suites.}
}


@article{DBLP:journals/tissec/JacommeK21,
	author = {Charlie Jacomme and
                  Steve Kremer},
	title = {An Extensive Formal Analysis of Multi-factor Authentication Protocols},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {2},
	pages = {13:1--13:34},
	year = {2021},
	url = {https://doi.org/10.1145/3440712},
	doi = {10.1145/3440712},
	timestamp = {Tue, 09 Mar 2021 08:38:53 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/JacommeK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Passwords are still the most widespread means for authenticating users, even though they have been shown to create huge security problems. This motivated the use of additional authentication mechanisms in so-called multi-factor authentication protocols. In this article, we define a detailed threat model for this kind of protocol: While in classical protocol analysis attackers control the communication network, we take into account that many communications are performed over TLS channels, that computers may be infected by different kinds of malware, that attackers could perform phishing, and that humans may omit some actions. We formalize this model in the applied pi calculus and perform an extensive analysis and comparison of several widely used protocols—variants of Google 2-step and FIDO’s U2F (Yubico’s Security Key token). The analysis is completely automated, generating systematically all combinations of threat scenarios for each of the protocols and using the PROVERIF tool for automated protocol analysis. To validate our model and attacks, we demonstrate their feasibility in practice, even though our experiments are run in a laboratory environment. Our analysis highlights weaknesses and strengths of the different protocols. It allows us to suggest several small modifications of the existing protocols that are easy to implement, as well as an extension of Google 2-step that improves security in several threat scenarios.}
}


@article{DBLP:journals/tissec/MohammadyOWHLPD21,
	author = {Meisam Mohammady and
                  Momen Oqaily and
                  Lingyu Wang and
                  Yuan Hong and
                  Habib Louafi and
                  Makan Pourzandi and
                  Mourad Debbabi},
	title = {A Multi-view Approach to Preserve Privacy and Utility in Network Trace
                  Anonymization},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {14:1--14:36},
	year = {2021},
	url = {https://doi.org/10.1145/3439732},
	doi = {10.1145/3439732},
	timestamp = {Tue, 07 May 2024 20:26:12 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/MohammadyOWHLPD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As network security monitoring grows more sophisticated, there is an increasing need for outsourcing such tasks to third-party analysts. However, organizations are usually reluctant to share their network traces due to privacy concerns over sensitive information, e.g., network and system configuration, which may potentially be exploited for attacks. In cases where data owners are convinced to share their network traces, the data are typically subjected to certain anonymization techniques, e.g., CryptoPAn, which replaces real IP addresses with prefix-preserving pseudonyms. However, most such techniques either are vulnerable to adversaries with prior knowledge about some network flows in the traces or require heavy data sanitization or perturbation, which may result in a significant loss of data utility. In this article, we aim to preserve both privacy and utility through shifting the trade-off from between privacy and utility to between privacy and computational cost. The key idea is for the analysts to generate and analyze multiple anonymized views of the original network traces: Those views are designed to be sufficiently indistinguishable even to adversaries armed with prior knowledge, which preserves the privacy, whereas one of the views will yield true analysis results privately retrieved by the data owner, which preserves the utility. We formally analyze the privacy of our solution and experimentally evaluate it using real network traces provided by a major ISP. The experimental results show that our approach can significantly reduce the level of information leakage (e.g., less than 1% of the information leaked by CryptoPAn) with comparable utility.}
}


@article{DBLP:journals/tissec/AmiKMNP21,
	author = {Amit Seal Ami and
                  Kaushal Kafle and
                  Kevin Moran and
                  Adwait Nadkarni and
                  Denys Poshyvanyk},
	title = {Systematic Mutation-Based Evaluation of the Soundness of Security-Focused
                  Android Static Analysis Techniques},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {15:1--15:37},
	year = {2021},
	url = {https://doi.org/10.1145/3439802},
	doi = {10.1145/3439802},
	timestamp = {Tue, 21 Mar 2023 21:08:56 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/AmiKMNP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile application security has been a major area of focus for security research over the course of the last decade. Numerous application analysis tools have been proposed in response to malicious, curious, or vulnerable apps. However, existing tools, and specifically, static analysis tools, trade soundness of the analysis for precision and performance and are hence soundy. Unfortunately, the specific unsound choices or flaws in the design of these tools is often not known or well documented, leading to misplaced confidence among researchers, developers, and users. This article describes the Mutation-Based Soundness Evaluation (μSE) framework, which systematically evaluates Android static analysis tools to discover, document, and fix flaws, by leveraging the well-founded practice of mutation analysis. We implemented μSE and applied it to a set of prominent Android static analysis tools that detect private data leaks in apps. In a study conducted previously, we used μSE to discover 13 previously undocumented flaws in FlowDroid, one of the most prominent data leak detectors for Android apps. Moreover, we discovered that flaws also propagated to other tools that build upon the design or implementation of FlowDroid or its components. This article substantially extends our μSE framework and offers a new in-depth analysis of two more major tools in our 2020 study; we find 12 new, undocumented flaws and demonstrate that all 25 flaws are found in more than one tool, regardless of any inheritance-relation among the tools. Our results motivate the need for systematic discovery and documentation of unsound choices in soundy tools and demonstrate the opportunities in leveraging mutation testing in achieving this goal.}
}


@article{DBLP:journals/tissec/BalliuMPS21,
	author = {Musard Balliu and
                  Massimo Merro and
                  Michele Pasqua and
                  Mikhail Shcherbakov},
	title = {Friendly Fire: Cross-app Interactions in IoT Platforms},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {16:1--16:40},
	year = {2021},
	url = {https://doi.org/10.1145/3444963},
	doi = {10.1145/3444963},
	timestamp = {Sat, 30 Sep 2023 10:28:53 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/BalliuMPS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT platforms enable users to connect various smart devices and online services via reactive apps running on the cloud. These apps, often developed by third-parties, perform simple computations on data triggered by external information sources and actuate the results of computations on external information sinks. Recent research shows that unintended or malicious interactions between the different (even benign) apps of a user can cause severe security and safety risks. These works leverage program analysis techniques to build tools for unveiling unexpected interference across apps for specific use cases. Despite these initial efforts, we are still lacking a semantic framework for understanding interactions between IoT apps. The question of what security policy cross-app interference embodies remains largely unexplored. This article proposes a semantic framework capturing the essence of cross-app interactions in IoT platforms. The framework generalizes and connects syntactic enforcement mechanisms to bisimulation-based notions of security, thus providing a baseline for formulating soundness criteria of these enforcement mechanisms. Specifically, we present a calculus that models the behavioral semantics of a system of apps executing concurrently, and use it to define desirable semantic policies targeting the security and safety of IoT apps. To demonstrate the usefulness of our framework, we define and implement static analyses for enforcing cross-app security and safety, and prove them sound with respect to our semantic conditions. We also leverage real-world apps to validate the practical benefits of our tools based on the proposed enforcement mechanisms.}
}


@article{DBLP:journals/tissec/JareckiJKSS21,
	author = {Stanislaw Jarecki and
                  Mohammed Jubur and
                  Hugo Krawczyk and
                  Nitesh Saxena and
                  Maliheh Shirvanian},
	title = {Two-factor Password-authenticated Key Exchange with End-to-end Security},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {17:1--17:37},
	year = {2021},
	url = {https://doi.org/10.1145/3446807},
	doi = {10.1145/3446807},
	timestamp = {Sat, 30 Sep 2023 10:28:53 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/JareckiJKSS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a secure two-factor authentication (TFA) scheme based on the user’s possession of a password and a crypto-capable device. Security is “end-to-end” in the sense that the attacker can attack all parts of the system, including all communication links and any subset of parties (servers, devices, client terminals), can learn users’ passwords, and perform active and passive attacks, online and offline. In all cases the scheme provides the highest attainable security bounds given the set of compromised components. Our solution builds a TFA scheme using any Device-enhanced Password-authenticated Key Exchange (PAKE), defined by Jarecki et\xa0al., and any Short Authenticated String (SAS) Message Authentication, defined by Vaudenay. We show an efficient instantiation of this modular construction, which utilizes any password-based client-server authentication method, with or without reliance on public-key infrastructure. The security of the proposed scheme is proven in a formal model that we formulate as an extension of the traditional PAKE model. We also report on a prototype implementation of our schemes, including TLS-based and PKI-free variants, as well as several instantiations of the SAS mechanism, all demonstrating the practicality of our approach. Finally, we present a usability study evaluating the viability of our protocol contrasted with the traditional PIN-based TFA approach in terms of efficiency, potential for errors, user experience, and security perception of the underlying manual process.1}
}


@article{DBLP:journals/tissec/CuiSAGR21,
	author = {Shujie Cui and
                  Xiangfu Song and
                  Muhammad Rizwan Asghar and
                  Steven D. Galbraith and
                  Giovanni Russello},
	title = {Privacy-preserving Dynamic Symmetric Searchable Encryption with Controllable
                  Leakage},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {18:1--18:35},
	year = {2021},
	url = {https://doi.org/10.1145/3446920},
	doi = {10.1145/3446920},
	timestamp = {Mon, 05 Feb 2024 20:25:07 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/CuiSAGR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searchable Encryption (SE) is a technique that allows Cloud Service Providers to search over encrypted datasets without learning the content of queries and records. In recent years, many SE schemes have been proposed to protect outsourced data. However, most of them leak sensitive information, from which attackers could still infer the content of queries and records by mounting leakage-based inference attacks, such as the count attack and file-injection attack. In this work, first we define the leakage in searchable encrypted databases and analyse how the leakage is leveraged in existing leakage-based attacks. Second, we propose a <underline>P</underline>rivacy-preserving <underline>M</underline>ulti-<underline>c</underline>loud based dynamic symmetric SE scheme for relational <underline>D</underline>ata<underline>b</underline>ase (P-McDb). P-McDb has minimal leakage, which not only ensures confidentiality of queries and records but also protects the search, intersection, and size patterns. Moreover, P-McDb ensures both forward and backward privacy of the database. Thus, P-McDb could resist existing leakage-based attacks, e.g., active file/record-injection attacks. We give security definition and analysis to show how P-McDb hides the aforementioned patterns. Finally, we implemented a prototype of P-McDb and tested it using the TPC-H benchmark dataset. Our evaluation results show that users can get the required records in 2.16 s when searching over 4.1 million records.}
}


@article{DBLP:journals/tissec/MayrhoferSBK21,
	author = {Ren{\'{e}} Mayrhofer and
                  Jeffrey Vander Stoep and
                  Chad Brubaker and
                  Nick Kralevich},
	title = {The Android Platform Security Model},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {19:1--19:35},
	year = {2021},
	url = {https://doi.org/10.1145/3448609},
	doi = {10.1145/3448609},
	timestamp = {Fri, 14 May 2021 15:36:58 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/MayrhoferSBK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Android is the most widely deployed end-user focused operating system. With its growing set of use cases encompassing communication, navigation, media consumption, entertainment, finance, health, and access to sensors, actuators, cameras, or microphones, its underlying security model needs to address a host of practical threats in a wide variety of scenarios while being useful to non-security experts. The model needs to strike a difficult balance between security, privacy, and usability for end users, assurances for app developers, and system performance under tight hardware constraints. While many of the underlying design principles have implicitly informed the overall system architecture, access control mechanisms, and mitigation techniques, the Android security model has previously not been formally published. This article aims to both document the abstract model and discuss its implications. Based on a definition of the threat model and Android ecosystem context in which it operates, we analyze how the different security measures in past and current Android implementations work together to mitigate these threats. There are some special cases in applying the security model, and we discuss such deliberate deviations from the abstract model.}
}


@article{DBLP:journals/tissec/VerasCT21,
	author = {Rafael Veras and
                  Christopher Collins and
                  Julie Thorpe},
	title = {A Large-Scale Analysis of the Semantic Password Model and Linguistic
                  Patterns in Passwords},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {20:1--20:21},
	year = {2021},
	url = {https://doi.org/10.1145/3448608},
	doi = {10.1145/3448608},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/VerasCT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we present a thorough evaluation of semantic password grammars. We report multifactorial experiments that test the impact of sample size, probability smoothing, and linguistic information on password cracking. The semantic grammars are compared with state-of-the-art probabilistic context-free grammar (PCFG) and neural network models, and tested in cross-validation and A vs. B scenarios. We present results that reveal the contributions of part-of-speech (syntactic) and semantic patterns, and suggest that the former are more consequential to the security of passwords. Our results show that in many cases PCFGs are still competitive models compared to their latest neural network counterparts. In addition, we show that there is little performance gain in training PCFGs with more than 1 million passwords. We present qualitative analyses of four password leaks (Mate1, 000webhost, Comcast, and RockYou) based on trained semantic grammars, and derive graphical models that capture high-level dependencies between token classes. Finally, we confirm the similarity inferences from our qualitative analysis by examining the effectiveness of grammars trained and tested on all pairs of leaks.}
}


@article{DBLP:journals/tissec/CramptonGM21,
	author = {Jason Crampton and
                  Gregory Z. Gutin and
                  Diptapriyo Majumdar},
	title = {Towards Better Understanding of User Authorization Query Problem via
                  Multi-variable Complexity Analysis},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {21:1--21:22},
	year = {2021},
	url = {https://doi.org/10.1145/3450768},
	doi = {10.1145/3450768},
	timestamp = {Thu, 18 Aug 2022 13:37:50 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/CramptonGM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User authorization queries in the context of role-based access control have attracted considerable interest in the past 15 years. Such queries are used to determine whether it is possible to allocate a set of roles to a user that enables the user to complete a task, in the sense that all the permissions required to complete the task are assigned to the roles in that set. Answering such a query, in general, must take into account a number of factors, including, but not limited to, the roles to which the user is assigned and constraints on the sets of roles that can be activated. Answering such a query is known to be NP-hard. The presence of multiple parameters and the need to find efficient and exact solutions to the problem suggest that a multi-variate approach will enable us to better understand the complexity of the user authorization query problem (UAQ). In this article, we establish a number of complexity results for UAQ. Specifically, we show the problem remains hard even when quite restrictive conditions are imposed on the structure of the problem. Our fixed-parameter tractable (FPT) results show that we have to use either a parameter with potentially quite large values or quite a restricted version of UAQ. Moreover, our second FPT algorithm is complex and requires sophisticated, state-of-the-art techniques. In short, our results show that it is unlikely that all variants of UAQ that arise in practice can be solved reasonably quickly in general.}
}


@article{DBLP:journals/tissec/ChaddadCEK21,
	author = {Louma Chaddad and
                  Ali Chehab and
                  Imad H. Elhajj and
                  Ayman I. Kayssi},
	title = {Optimal Packet Camouflage Against Traffic Analysis},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {3},
	pages = {22:1--22:23},
	year = {2021},
	url = {https://doi.org/10.1145/3442697},
	doi = {10.1145/3442697},
	timestamp = {Tue, 21 Mar 2023 21:08:56 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/ChaddadCEK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Research has proved that supposedly secure encrypted network traffic is actually threatened by privacy and security violations from many aspects. This is mainly due to flow features leaking evidence about user activity and data content. Currently, adversaries can use statistical traffic analysis to create classifiers for network applications and infer users’ sensitive data. In this article, we propose a system that optimally prevents traffic feature leaks. In our first algorithm, we model the packet length probability distribution of the source app to be protected and that of the target app that the source app will resemble. We define a model that mutates the packet lengths of a source app to those lengths from the target app having similar bin probability. This would confuse a classifier by identifying a mutated source app as the target app. In our second obfuscation algorithm, we present an optimized scheme resulting in a trade-off between privacy and complexity overhead. For this reason, we propose a mathematical model for network obfuscation. We formulate analytically the problem of selecting the target app and the length from the target app to mutate to. Then, we propose an algorithm to solve it dynamically. Extensive evaluation of the proposed models, on real app traffic traces, shows significant obfuscation efficiency with relatively acceptable overhead. We were able to reduce a classification accuracy from 91.1% to 0.22% using the first algorithm, with 11.86% padding overhead. The same classification accuracy was reduced to 1.76% with only 0.73% overhead using the second algorithm.}
}


@article{DBLP:journals/tissec/AbuhamadAMN21,
	author = {Mohammed Abuhamad and
                  Tamer AbuHmed and
                  David Mohaisen and
                  Daehun Nyang},
	title = {Large-scale and Robust Code Authorship Identification with Deep Feature
                  Learning},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {23:1--23:35},
	year = {2021},
	url = {https://doi.org/10.1145/3461666},
	doi = {10.1145/3461666},
	timestamp = {Sun, 02 Oct 2022 15:51:13 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/AbuhamadAMN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Successful software authorship de-anonymization has both software forensics applications and privacy implications. However, the process requires an efficient extraction of authorship attributes. The extraction of such attributes is very challenging, due to various software code formats from executable binaries with different toolchain provenance to source code with different programming languages. Moreover, the quality of attributes is bounded by the availability of software samples to a certain number of samples per author and a specific size for software samples. To this end, this work proposes a deep Learning-based approach for software authorship attribution, that facilitates large-scale, format-independent, language-oblivious, and obfuscation-resilient software authorship identification. This proposed approach incorporates the process of learning deep authorship attribution using a recurrent neural network, and ensemble random forest classifier for scalability to de-anonymize programmers. Comprehensive experiments are conducted to evaluate the proposed approach over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1,987 public repositories on GitHub. The results of our work show high accuracy despite requiring a smaller number of samples per author. Experimenting with source-code, our approach allows us to identify 8,903 GCJ authors, the largest-scale dataset used by far, with an accuracy of 92.3%. Using the real-world dataset, we achieved an identification accuracy of 94.38% for 745 C programmers on GitHub. Moreover, the proposed approach is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g., C, C++, Java, and Python), and authors writing in mixed languages (e.g., Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g., using C Tigress) with an accuracy of 93.42% for a set of 120 authors. Experimenting with executable binaries, our approach achieves 95.74% for identifying 1,500 programmers of software binaries. Similar results were obtained when software binaries are generated with different compilation options, optimization levels, and removing of symbol information. Moreover, our approach achieves 93.86% for identifying 1,500 programmers of obfuscated binaries using all features adopted in Obfuscator-LLVM tool.}
}


@article{DBLP:journals/tissec/AcarAKKAAU21,
	author = {Abbas Acar and
                  Shoukat Ali and
                  Koray Karabina and
                  Cengiz Kaygusuz and
                  Hidayet Aksu and
                  Kemal Akkaya and
                  Arif Selcuk Uluagac},
	title = {A Lightweight Privacy-Aware Continuous Authentication Protocol-PACA},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {24:1--24:28},
	year = {2021},
	url = {https://doi.org/10.1145/3464690},
	doi = {10.1145/3464690},
	timestamp = {Mon, 18 Oct 2021 08:37:21 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/AcarAKKAAU21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As many vulnerabilities of one-time authentication systems have already been uncovered, there is a growing need and trend to adopt continuous authentication systems. Biometrics provides an excellent means for periodic verification of the authenticated users without breaking the continuity of a session. Nevertheless, as attacks to computing systems increase, biometric systems demand more user information in their operations, yielding privacy issues for users in biometric-based continuous authentication systems. However, the current state-of-the-art privacy technologies are not viable or costly for the continuous authentication systems, which require periodic real-time verification. In this article, we introduce a novel, lightweight, <underline>p</underline>rivacy-<underline>a</underline>ware, and secure <underline>c</underline>ontinuous <underline>a</underline>uthentication protocol called PACA. PACA is initiated through a password-based key exchange (PAKE) mechanism, and it continuously authenticates users based on their biometrics in a privacy-aware manner. Then, we design an actual continuous user authentication system under the proposed protocol. In this concrete system, we utilize a privacy-aware template matching technique and a wearable-assisted keystroke dynamics-based continuous authentication method. This provides privacy guarantees without relying on any trusted third party while allowing the comparison of noisy user inputs (due to biometric data) and yielding an efficient and lightweight protocol. Finally, we implement our system on an Apple smartwatch and perform experiments with real user data to evaluate the accuracy and resource consumption of our concrete system.}
}


@article{DBLP:journals/tissec/SalemBP21,
	author = {Aleieldin Salem and
                  Sebastian Banescu and
                  Alexander Pretschner},
	title = {Maat: Automatically Analyzing VirusTotal for Accurate Labeling and
                  Effective Malware Detection},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {25:1--25:35},
	year = {2021},
	url = {https://doi.org/10.1145/3465361},
	doi = {10.1145/3465361},
	timestamp = {Sat, 09 Apr 2022 12:26:32 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/SalemBP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The malware analysis and detection research community relies on the online platform VirusTotal to label Android apps based on the scan results of around 60 antiviral scanners. Unfortunately, there are no standards on how to best interpret the scan results acquired from VirusTotal, which leads to the utilization of different threshold-based labeling strategies (e.g., if 10 or more scanners deem an app malicious, it is considered malicious). While some of the utilized thresholds may be able to accurately approximate the ground truths of apps, the fact that VirusTotal changes the set and versions of the scanners it uses makes such thresholds unsustainable over time. We implemented a method, Maat, that tackles these issues of standardization and sustainability by automatically generating a Machine Learning (ML)-based labeling scheme, which outperforms threshold-based labeling strategies. Using the VirusTotal scan reports of 53K Android apps that span 1 year, we evaluated the applicability of Maat’s Machine Learning (ML)-based labeling strategies by comparing their performance against threshold-based strategies. We found that such ML-based strategies (a) can accurately and consistently label apps based on their VirusTotal scan reports, and (b) contribute to training ML-based detection methods that are more effective at classifying out-of-sample apps than their threshold-based counterparts.}
}


@article{DBLP:journals/tissec/ChengALNCJAY21,
	author = {Long Cheng and
                  Salman Ahmed and
                  Hans Liljestrand and
                  Thomas Nyman and
                  Haipeng Cai and
                  Trent Jaeger and
                  N. Asokan and
                  Danfeng (Daphne) Yao},
	title = {Exploitation Techniques for Data-oriented Attacks with Existing and
                  Potential Defense Approaches},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {26:1--26:36},
	year = {2021},
	url = {https://doi.org/10.1145/3462699},
	doi = {10.1145/3462699},
	timestamp = {Sun, 02 Oct 2022 15:51:13 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/ChengALNCJAY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data-oriented attacks manipulate non-control data to alter a program’s benign behavior without violating its control-flow integrity. It has been shown that such attacks can cause significant damage even in the presence of control-flow defense mechanisms. However, these threats have not been adequately addressed. In this survey article, we first map data-oriented exploits, including Data-Oriented Programming (DOP) and Block-Oriented Programming (BOP) attacks, to their assumptions/requirements and attack capabilities. Then, we compare known defenses against these attacks, in terms of approach, detection capabilities, overhead, and compatibility. It is generally believed that control flows may not be useful for data-oriented security. However, data-oriented attacks (especially DOP attacks) may generate side effects on control-flow behaviors in multiple dimensions (i.e., incompatible branch behaviors and frequency anomalies). We also characterize control-flow anomalies caused by data-oriented attacks. In the end, we discuss challenges for building deployable data-oriented defenses and open research questions.}
}


@article{DBLP:journals/tissec/DemetrioCBLAR21,
	author = {Luca Demetrio and
                  Scott E. Coull and
                  Battista Biggio and
                  Giovanni Lagorio and
                  Alessandro Armando and
                  Fabio Roli},
	title = {Adversarial EXEmples: {A} Survey and Experimental Evaluation of Practical
                  Attacks on Machine Learning for Windows Malware Detection},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {27:1--27:31},
	year = {2021},
	url = {https://doi.org/10.1145/3473039},
	doi = {10.1145/3473039},
	timestamp = {Sat, 09 Apr 2022 12:26:32 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/DemetrioCBLAR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent work has shown that adversarial Windows malware samples—referred to as adversarial EXEmples in this article—can bypass machine learning-based detection relying on static code analysis by perturbing relatively few input bytes. To preserve malicious functionality, previous attacks either add bytes to existing non-functional areas of the file, potentially limiting their effectiveness, or require running computationally demanding validation steps to discard malware variants that do not correctly execute in sandbox environments. In this work, we overcome these limitations by developing a unifying framework that does not only encompass and generalize previous attacks against machine-learning models, but also includes three novel attacks based on practical, functionality-preserving manipulations to the Windows Portable Executable file format. These attacks, named Full DOS, Extend, and Shift, inject the adversarial payload by respectively manipulating the DOS header, extending it, and shifting the content of the first section. Our experimental results show that these attacks outperform existing ones in both white-box and black-box scenarios, achieving a better tradeoff in terms of evasion rate and size of the injected payload, while also enabling evasion of models that have been shown to be robust to previous attacks. To facilitate reproducibility of our findings, we open source our framework and all the corresponding attack implementations as part of the secml-malware Python library. We conclude this work by discussing the limitations of current machine learning-based malware detectors, along with potential mitigation strategies based on embedding domain knowledge coming from subject-matter experts directly into the learning process.}
}


@article{DBLP:journals/tissec/MaqsoodC21,
	author = {Sana Maqsood and
                  Sonia Chiasson},
	title = {Design, Development, and Evaluation of a Cybersecurity, Privacy, and
                  Digital Literacy Game for Tweens},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {28:1--28:37},
	year = {2021},
	url = {https://doi.org/10.1145/3469821},
	doi = {10.1145/3469821},
	timestamp = {Tue, 16 Aug 2022 23:09:26 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/MaqsoodC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tweens are avid users of digital media, which exposes them to various online threats. Teachers are primarily expected to teach children safe online behaviours, despite not necessarily having the required training or classroom tools to support this education. Using the theory of procedural rhetoric and established game design principles, we designed a classroom-based cybersecurity, privacy, and digital literacy game for tweens that has since been deployed to over 300 Canadian elementary schools. The game, A Day in the Life of the JOs, teaches children about 25 cybersecurity, privacy, and digital literacy topics and allows them to practice what they have learned in a simulated environment. We employed a user-centered design process to create the game, iteratively testing its design and effectiveness with children and teachers through five user studies (with a total of 63 child participants and 21 teachers). Our summative evaluation with children showed that the game improved their cybersecurity, privacy, and digital literacy knowledge and behavioural intent and was positively received by them. Our summative evaluation with teachers also showed positive results. Teachers liked that the game represented the authentic experiences of children on digital media and that it aligned with their curriculum requirements; they were interested in using it in their classrooms. In this article, we discuss our process and experience of designing a production quality game for children and provide evidence of its effectiveness with both children and teachers.}
}


@article{DBLP:journals/tissec/HelbleKLRRA21,
	author = {Sarah C. Helble and
                  Ian D. Kretz and
                  Peter A. Loscocco and
                  John D. Ramsdell and
                  Paul D. Rowe and
                  Perry Alexander},
	title = {Flexible Mechanisms for Remote Attestation},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {29:1--29:23},
	year = {2021},
	url = {https://doi.org/10.1145/3470535},
	doi = {10.1145/3470535},
	timestamp = {Sat, 30 Sep 2023 10:28:53 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/HelbleKLRRA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote attestation consists of generating evidence of a system’s integrity via measurements and reporting the evidence to a remote party for appraisal in a form that can be trusted. The parties that exchange information must agree on formats and protocols. We assert there is a large variety of patterns of interactions among appraisers and attesters of interest. Therefore, it is important to standardize on flexible mechanisms for remote attestation. We make our case by describing scenarios that require the exchange of evidence among multiple parties using a variety of message passing patterns. We show cases in which changes in the order of evidence collection result in important differences to what can be inferred by an appraiser. We argue that adding the ability to negotiate the appropriate kind of attestation allows for remote attestations that better adapt to a dynamically changing environment. Finally, we suggest a language-based solution to taming the complexity of specifying and negotiating attestation procedures.}
}


@article{DBLP:journals/tissec/MarkertBGDA21,
	author = {Philipp Markert and
                  Daniel V. Bailey and
                  Maximilian Golla and
                  Markus D{\"{u}}rmuth and
                  Adam J. Aviv},
	title = {On the Security of Smartphone Unlock PINs},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {30:1--30:36},
	year = {2021},
	url = {https://doi.org/10.1145/3473040},
	doi = {10.1145/3473040},
	timestamp = {Sun, 02 Oct 2022 15:51:13 +0200},
	biburl = {https://dblp.org/rec/journals/tissec/MarkertBGDA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we provide the first comprehensive study of user-chosen four- and six-digit PINs (n=1705) collected on smartphones with participants being explicitly primed for device unlocking. We find that against a throttled attacker (with 10, 30, or 100 guesses, matching the smartphone unlock setting), using six-digit PINs instead of four-digit PINs provides little to no increase in security and surprisingly may even decrease security. We also study the effects of blocklists, where a set of “easy to guess” PINs is disallowed during selection. Two such blocklists are in use today by iOS, for four digits (274 PINs) as well as six digits (2,910 PINs). We extracted both blocklists and compared them with six other blocklists, three for each PIN length. In each case, we had a small (four-digit: 27 PINs; six-digit: 29 PINs), a large (four-digit: 2,740 PINs; six-digit: 291,000 PINs), and a placebo blocklist that always excluded the first-choice PIN. For four-digit PINs, we find that the relatively small blocklist in use today by iOS offers little to no benefit against a throttled guessing attack. Security gains are only observed when the blocklist is much larger. In the six-digit case, we were able to reach a similar security level with a smaller blocklist. As the user frustration increases with the blocklists size, developers should employ a blocklist that is as small as possible while ensuring the desired security. Based on our analysis, we recommend that for four-digit PINs a blocklist should contain the 1,000 most popular PINs to provide the best balance between usability and security and for six-digit PINs the 2,000 most popular PINs should be blocked.}
}


@article{DBLP:journals/tissec/BirnbachBEM21,
	author = {Simon Birnbach and
                  Richard Baker and
                  Simon Eberz and
                  Ivan Martinovic},
	title = {{\#}PrettyFlyForAWiFi: Real-world Detection of Privacy Invasion Attacks
                  by Drones},
	journal = {{ACM} Trans. Priv. Secur.},
	volume = {24},
	number = {4},
	pages = {31:1--31:34},
	year = {2021},
	url = {https://doi.org/10.1145/3473672},
	doi = {10.1145/3473672},
	timestamp = {Sat, 08 Jan 2022 02:22:54 +0100},
	biburl = {https://dblp.org/rec/journals/tissec/BirnbachBEM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Drones are becoming increasingly popular for hobbyists and recreational use. But with this surge in popularity comes increased risk to privacy as the technology makes it easy to spy on people in otherwise-private environments, such as an individual’s home. An attacker can fly a drone over fences and walls to observe the inside of a house, without having physical access. Existing drone detection systems require specialist hardware and expensive deployment efforts, making them inaccessible to the general public. In this work, we present a drone detection system that requires minimal prior configuration and uses inexpensive commercial off-the-shelf hardware to detect drones that are carrying out privacy invasion attacks. We use a model of the attack structure to derive statistical metrics for movement and proximity that are then applied to received communications between a drone and its controller. We test our system in real-world experiments with two popular consumer drone models mounting privacy invasion attacks using a range of flight patterns. We are able both to detect the presence of a drone and to identify which phase of the privacy attack was in progress while being resistant to false positives from other mobile transmitters. For line-of-sight approaches using our kurtosis-based method, we are able to detect all drones at a distance of 6 m, with the majority of approaches detected at 25 m or farther from the target window without suffering false positives for stationary or mobile non-drone transmitters.}
}
