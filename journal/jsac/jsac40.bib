@article{DBLP:journals/jsac/LiSOKQHHGE22,
	author = {Geoffrey Ye Li and
                  Walid Saad and
                  Ayfer {\"{O}}zg{\"{u}}r and
                  Peter Kairouz and
                  Zhijin Qin and
                  Jakob Hoydis and
                  Zhu Han and
                  Deniz G{\"{u}}nd{\"{u}}z and
                  Jaafar Mohamed Hashim Elmirghani},
	title = {Series Editorial The Fourth Issue of the Series on Machine Learning
                  in Communications and Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {1--4},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126188},
	doi = {10.1109/JSAC.2021.3126188},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiSOKQHHGE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The third call for papers of the Series on Machine Learning in Communications and Networks has continued to receive a great number of high-quality papers covering various aspects of intelligent communications, from which we have included 26 original contributions in this issue. In the following, we provide a brief review of key contributions of papers in this issue according to their topics.}
}


@article{DBLP:journals/jsac/LetaiefSLL22,
	author = {Khaled B. Letaief and
                  Yuanming Shi and
                  Jianmin Lu and
                  Jianhua Lu},
	title = {Edge Artificial Intelligence for 6G: Vision, Enabling Technologies,
                  and Applications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {5--36},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126076},
	doi = {10.1109/JSAC.2021.3126076},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LetaiefSLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from “connected things” to “connected intelligence”. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods, as well as a holistic end-to-end system architecture to support edge AI will be described. Standardization, software and hardware platforms, and application scenarios are also discussed to facilitate the industrialization and commercialization of edge AI systems.}
}


@article{DBLP:journals/jsac/HussainM22,
	author = {Muddassar Hussain and
                  Nicol{\`{o}} Michelusi},
	title = {Learning and Adaptation for Millimeter-Wave Beam Tracking and Training:
                  {A} Dual Timescale Variational Framework},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {37--53},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126086},
	doi = {10.1109/JSAC.2021.3126086},
	timestamp = {Fri, 21 Jan 2022 22:02:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HussainM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Millimeter-wave vehicular networks incur enormous beam-training overhead to enable narrow-beam communications. This paper proposes a learning and adaptation framework in which the dynamics of the communication beams are learned and then exploited to design adaptive beam-tracking and training with low overhead: on a long-timescale, a deep recurrent variational autoencoder (DR-VAE) uses noisy beam-training feedback to learn a probabilistic model of beam dynamics and enable predictive beam-tracking; on a short-timescale, an adaptive beam-training procedure is formulated as a partially observable (PO-) Markov decision process (MDP) and optimized via point-based value iteration (PBVI) by leveraging beam-training feedback and a probabilistic prediction of the strongest beam pair provided by the DR-VAE. In turn, beam-training feedback is used to refine the DR-VAE via stochastic gradient ascent in a continuous process of learning and adaptation. The proposed DR-VAE learning framework learns accurate beam dynamics: it reduces the Kullback-Leibler divergence between the ground truth and the learned model of beam dynamics by ~95% over the Baum-Welch algorithm and a naive learning approach that neglects feedback errors. Numerical results on a line-of-sight scenario with multipath and 3D beamforming reveal that the proposed dual timescale approach yields near-optimal spectral efficiency, and improves it by 130% over a policy that scans exhaustively over the dominant beam pairs, and by 20% over a state-of-the-art POMDP policy. Finally, a low-complexity policy is proposed by reducing the POMDP to an error-robust MDP, and is shown to perform well in regimes with infrequent feedback errors.}
}


@article{DBLP:journals/jsac/WuGAW22,
	author = {Yibo Wu and
                  Ulf Gustavsson and
                  Alexandre Graell i Amat and
                  Henk Wymeersch},
	title = {Low Complexity Joint Impairment Mitigation of {I/Q} Modulator and
                  {PA} Using Neural Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {54--64},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126024},
	doi = {10.1109/JSAC.2021.3126024},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WuGAW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {neural networks (NNs) for multiple hardware impairments mitigation of a realistic direct conversion transmitter are impractical due to high computational complexity. We propose two methods to reduce the complexity without significant performance penalty. First, propose a novel NN with shortcut connections, referred to as shortcut real-valued time-delay neural network (SVDEN), where trainable neuron-wise shortcut connections are added between the input and output layers. Second, we implement a NN pruning algorithm that gradually removes connections corresponding to minimal weight magnitudes in each layer. Simulation and experimental results show that SVDEN with pruning achieves better performance for compensating frequency-dependent quadrature imbalance and power amplifier nonlinearity than other NN-based and Volterra-based models, while requiring less or similar complexity.}
}


@article{DBLP:journals/jsac/ZhangWJ22,
	author = {Jing Zhang and
                  Chao{-}Kai Wen and
                  Shi Jin},
	title = {Adaptive {MIMO} Detector Based on Hypernetwork: Design, Simulation,
                  and Experimental Test},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {65--81},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126064},
	doi = {10.1109/JSAC.2021.3126064},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangWJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Algorithm unfolding, which provides a systematic connection between conventional model-based algorithms and modern data-based deep learning, has exhibited great empirical success for efficiently balancing the performance and complexity of multiple-input and multiple-output (MIMO) detectors. However, existing unfolding-based MIMO detectors have difficulties adapting to the high discrepancy in channel and noise conditions. In this study, we present a novel unfolding-based framework for MIMO detectors, which can automatically determine internal parameters of an unfolding-based MIMO detector to adapt to the varying conditions. A key part of our approach is to develop a hypernetwork that can effectively learn to generate the internal parameters in the sophisticated expectation propagation-based MIMO detector. In particular, we design long short-term memory-based hypernetwork to ensure the flexibility of the layers of the unfolded algorithm. The proposed framework is also extended to a coded MIMO turbo receiver to adapt to the different feedback beliefs from the decoder. Numerical results demonstrate that the proposed MIMO detectors have excellent adaptation capability to different channel environments and noise levels. Compared with the existing unfolded algorithm that is an optimal reference, the proposed framework avoids frequent retraining and presents the nearly optimal performance in uncoded and coded MIMO systems. An over-the-air platform is presented as well to demonstrate the significant robustness of the proposed receivers in practical deployment.}
}


@article{DBLP:journals/jsac/HannaDC22,
	author = {Samer S. Hanna and
                  Chris Dick and
                  Danijela Cabric},
	title = {Signal Processing-Based Deep Learning for Blind Symbol Decoding and
                  Modulation Classification},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {82--96},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126088},
	doi = {10.1109/JSAC.2021.3126088},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HannaDC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blindly decoding a signal requires estimating its unknown transmit parameters, compensating for the wireless channel impairments, and identifying the modulation type. While deep learning can solve complex problems, digital signal processing (DSP) is interpretable and can be more computationally efficient. To combine both, we propose the dual path network (DPN). It consists of a signal path of DSP operations that recover the signal, and a feature path of neural networks that estimate the unknown transmit parameters. By interconnecting the paths over several recovery stages, later stages benefit from the recovered signals and reuse all the previously extracted features. The proposed design is demonstrated to provide 5% improvement in modulation classification compared to alternative designs lacking either feature sharing or access to recovered signals. The estimation results of DPN along with its blind decoding performance are shown to outperform a blind signal processing algorithm for BPSK and QPSK on a simulated dataset. An over-the-air software-defined-radio capture was used to verify DPN results at high SNRs. DPN design can process variable length inputs and is shown to outperform relying on fixed length inputs with prediction averaging on longer signals by up to 15% in modulation classification.}
}


@article{DBLP:journals/jsac/ZhangYLZC22,
	author = {Lin Zhang and
                  Xiaoling Yang and
                  Heng Liu and
                  Haotian Zhang and
                  Julian Cheng},
	title = {Efficient Residual Shrinkage {CNN} Denoiser Design for Intelligent
                  Signal Processing: Modulation Recognition, Detection, and Decoding},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {97--111},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126074},
	doi = {10.1109/JSAC.2021.3126074},
	timestamp = {Thu, 23 Jun 2022 20:01:47 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangYLZC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The noises embedded in signals will degrade the signal processing quality. Traditional denoising algorithms might not work in practical systems since the statistical characteristics of noises might not be learned. To address this issue, we propose an efficient residual shrinkage convolutional neural network (RSCNN) aided denoiser based on the principle of the domain transformation, shrinking and inverse transforming operations conducted by the traditional denoiser. The proposed RSCNN is composed by the batch normalization layer, domain transformation layers, the shrinkage module and inverse transformation layers, wherein transformation layers consist of convolutional layers and the nonlinear activation function. Moreover, we propose a thresholds learning subnetwork to automatically determine the thresholds, so as to enhance noise suppressing performances. Furthermore, we compose the data set by preprocessing the received signals, and design the loss function according to different denoising requirements. To validate the efficiency and universality of the RSCNN aided denoiser, we apply the proposed RSCNN denoiser to three different application scenarios, including the modulation recognition, detection and decoding. After the offline training, at the online deployment stage, we utilize the RSCNN denoiser to reduce the noise power and improve the signal to noise ratios. Simulation results demonstrate that the proposed intelligent denoiser can efficiently improve the signal processing capabilities to achieve higher modulation recognition accuracy, better detection and decoding performances with lower complexity than benchmark schemes.}
}


@article{DBLP:journals/jsac/BaiCAZW22,
	author = {Yanna Bai and
                  Wei Chen and
                  Bo Ai and
                  Zhangdui Zhong and
                  Ian J. Wassell},
	title = {Prior Information Aided Deep Learning Method for Grant-Free {NOMA}
                  in mMTC},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {112--126},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126071},
	doi = {10.1109/JSAC.2021.3126071},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/BaiCAZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In massive machine-type communications (mMTC), the conflict between millions of potential access devices and limited channel freedom leads to a sharp decrease in spectrum efficiency. The nature of sporadic activity in mMTC provides a solution to enhance spectrum efficiency by employing compressive sensing (CS) to perform multiuser detection (MUD). However, CS-MUD suffers from high computation complexity and fails to meet the strict latency requirement in some critical applications. To address this problem, in this paper, we propose a novel deep learning (DL) based framework for grant-free non-orthogonal multiple access (GF-NOMA), where we utilize the information distilled from the initial data recovery phase to further enhance channel estimation, which in turn improves data recovery performance. Besides, we design an interpretable and structured Model-driven Prior Information Aided Network (M-PIAN) and provide theoretical analysis that demonstrates the proposed M-PIAN can converge faster and support more users. Experiments show that the proposed method outperforms existing CS algorithms and DL methods in both computation complexity and reconstruction accuracy.}
}


@article{DBLP:journals/jsac/FoziSB22,
	author = {Mahdi Fozi and
                  Ahmad R. Sharafat and
                  Mehdi Bennis},
	title = {Fast {MIMO} Beamforming via Deep Reinforcement Learning for High Mobility
                  mmWave Connectivity},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {127--142},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126056},
	doi = {10.1109/JSAC.2021.3126056},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/FoziSB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future 5G/6G wireless networks will be increasingly using millimeter waves (mmWaves), where fast and efficient beamforming is vital for providing continuous service to highly mobile devices in the presence of interference and signal attenuation, manifested by blockage. In this paper, we propose a novel and efficient method for mmWave beamforming in massive multiple-input multiple-output (MIMO) systems to achieve the aforementioned goals with low complexity in such scenarios. In doing so, we utilize deep reinforcement learning (DRL) to maximize the network’s energy efficiency subject to the quality of service (QoS) constraint for each user equipment (UE) and obtain its hybrid beamforming matrices. In doing so, we assume each UE is simultaneously associated with multiple access points (APs), i.e., simultaneous beamforming to/from multiple APs (coordinated multipoints) is needed for each UE. We also propose a low-complexity training algorithm, based on approximate message passing, which is well suited for the network edge. Besides, we develop a distributed scheme to reduce communications overhead via federated DRL. Extensive simulations show significant performance improvement over existing methods.}
}


@article{DBLP:journals/jsac/HuangHL22,
	author = {Yan Huang and
                  Y. Thomas Hou and
                  Wenjing Lou},
	title = {{DELUXE:} {A} DL-Based Link Adaptation for URLLC/eMBB Multiplexing
                  in 5G {NR}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {143--162},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126084},
	doi = {10.1109/JSAC.2021.3126084},
	timestamp = {Thu, 11 May 2023 21:27:17 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuangHL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ultra-Reliable and Low Latency Communications (URLLC) is an important use case in 5G NR that targets at 1-ms level delay sensitive applications. For fast transmission of URLLC traffic, a promising mechanism is to multiplex URLLC traffic into a channel occupied by enhanced Mobile BroadBand (eMBB) service through preemptive puncturing. Although preemptive puncturing can offer transmission resource to URLLC on demand, it will adversely affect throughput and link reliability performance of eMBB service. To mitigate such an adverse impact, a possible approach is to employ link adaptation (LA) through modulation and coding scheme (MCS) selection for eMBB users. In this paper, we study the problem of maximizing eMBB throughput through MCS selection while ensuring link reliability requirement for eMBB users. We present DELUXE – the first successful design and implementation based on deep learning to address this problem. DELUXE involves a novel mapping method to compress high-dimensional eMBB transmission information into a low-dimensional representation with minimal information loss, a learning method to learn and predict the block-error rate (BLER) under each MCS, and a fast calibration method to compensate errors in BLER predictions. For proof of concept, we implemented DELUXE through a link-level 5G NR simulator with GPU and MathWorks 5G toolbox. Through extensive experiments, we show that DELUXE can successfully choose MCS for eMBB transmissions to maintain the desired link reliability while striving for spectral efficiency. In addition, our implementation can meet the real-time requirement (\n<125μs\n) in 5G NR.}
}


@article{DBLP:journals/jsac/HuCKYHE22,
	author = {Qiyu Hu and
                  Yunlong Cai and
                  Kai Kang and
                  Guanding Yu and
                  Jakob Hoydis and
                  Yonina C. Eldar},
	title = {Two-Timescale End-to-End Learning for Channel Acquisition and Hybrid
                  Precoding},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {163--181},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126050},
	doi = {10.1109/JSAC.2021.3126050},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HuCKYHE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose an end-to-end deep learning-based joint transceiver design algorithm for millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems, which consists of deep neural network (DNN)-aided pilot training, channel feedback, and hybrid analog-digital (HAD) precoding. Specifically, we develop a DNN architecture that maps the received pilots into feedback bits at the receiver, and then further maps the feedback bits into the hybrid precoder at the transmitter. To reduce the signaling overhead and channel state information (CSI) mismatch caused by the transmission delay, a two-timescale DNN composed of a long-term DNN and a short-term DNN is developed. The analog precoders are designed by the long-term DNN based on the CSI statistics and updated once in a frame consisting of a number of time slots. In contrast, the digital precoders are optimized by the short-term DNN at each time slot based on the estimated low-dimensional equivalent CSI matrices. A two-timescale training method is also developed for the proposed DNN with a binary layer. We then analyze the generalization ability and signaling overhead for the proposed DNN based algorithm. Simulation results show that our proposed technique significantly outperforms conventional schemes in terms of bit-error rate performance with reduced signaling overhead and shorter pilot sequences.}
}


@article{DBLP:journals/jsac/ZhongLMCS22,
	author = {Ruikang Zhong and
                  Yuanwei Liu and
                  Xidong Mu and
                  Yue Chen and
                  Lingyang Song},
	title = {{AI} Empowered RIS-Assisted {NOMA} Networks: Deep Learning or Reinforcement
                  Learning?},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {182--196},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126068},
	doi = {10.1109/JSAC.2021.3126068},
	timestamp = {Sat, 08 Jan 2022 02:24:14 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhongLMCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A reconfigurable intelligent surface (RIS)-assisted multi-user downlink communication system over fading channels is investigated, where both non-orthogonal multiple access (NOMA) and orthogonal multiple access (OMA) schemes are employed. In particular, the time overhead for configuring the RIS reflective elements at the beginning of each fading channel is considered. The optimization goal is maximizing the effective throughput of the entire transmission period by jointly optimizing the phase shift of the RIS and the power allocation of the AP for each channel block. In an effort to solve the formulated problem and fill the research vacancy of the performance comparison between different machine learning tools in wireless networks, a deep learning (DL) approach and a reinforcement learning (RL) approach are proposed and their representative superiority and inferiority are investigated. The DL approach can locate the optimal phase shifts with the deep neural network fitting as well as the corresponding power allocation for each user. From the perspective of long-term reward, the phase shift control with configuration overhead can be regarded as a Markov decision process and the RL algorithm is proficient in solving such problems with the assistance of the Bellman equation. The numerical results indicate that: 1) From the perspective of the wireless network, NOMA can achieve a throughput gain of about 42% compared with OMA; 2) The well-trained RL and DL agents are able to achieve the same performance in Rician channel, while RL is superior in the Rayleigh channel; 3) The DL approach has lower complexity and faster convergence, while the RL approach has preferable strategy flexibility.}
}


@article{DBLP:journals/jsac/ShaoMZ22,
	author = {Jiawei Shao and
                  Yuyi Mao and
                  Jun Zhang},
	title = {Learning Task-Oriented Communication for Edge Inference: An Information
                  Bottleneck Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {197--211},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126087},
	doi = {10.1109/JSAC.2021.3126087},
	timestamp = {Sun, 02 Oct 2022 15:42:34 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ShaoMZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates task-oriented communication for edge inference, where a low-end edge device transmits the extracted feature vector of a local data sample to a powerful edge server for processing. It is critical to encode the data into an informative and compact representation for low-latency inference given the limited bandwidth. We propose a learning-based communication scheme that jointly optimizes feature extraction, source coding, and channel coding in a task-oriented manner, i.e., targeting the downstream inference task rather than data reconstruction. Specifically, we leverage an information bottleneck (IB) framework to formalize a rate-distortion tradeoff between the informativeness of the encoded feature and the inference performance. As the IB optimization is computationally prohibitive for the high-dimensional data, we adopt a variational approximation, namely the variational information bottleneck (VIB), to build a tractable upper bound. To reduce the communication overhead, we leverage a sparsity-inducing distribution as the variational prior for the VIB framework to sparsify the encoded feature vector. Furthermore, considering dynamic channel conditions in practical communication systems, we propose a variable-length feature encoding scheme based on dynamic neural networks to adaptively adjust the activated dimensions of the encoded feature to different channel conditions. Extensive experiments evidence that the proposed task-oriented communication system achieves a better rate-distortion tradeoff than baseline methods and significantly reduces the feature transmission latency in dynamic channel conditions.}
}


@article{DBLP:journals/jsac/LuongZXHXPH22,
	author = {Thien Van Luong and
                  Xiaoyu Zhang and
                  Luping Xiang and
                  Tiep Minh Hoang and
                  Chao Xu and
                  Periklis Petropoulos and
                  Lajos Hanzo},
	title = {Deep Learning-Aided Optical {IM/DD} {OFDM} Approaches the Throughput
                  of {RF-OFDM}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {212--226},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126080},
	doi = {10.1109/JSAC.2021.3126080},
	timestamp = {Sat, 09 Apr 2022 12:32:42 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LuongZXHXPH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-aided optical orthogonal frequency division multiplexing (O-OFDM) is proposed for intensity modulated direct detection transmissions, which is termed as O-OFDMNet. In particular, O-OFDMNet employs deep neural networks (DNNs) for converting a complex-valued signal into a non-negative signal in the time-domain at the transmitter and vice versa at the receiver. The associated frequency-domain signal processing remains the same as in conventional radio frequency (RF) OFDM. As a result, our scheme achieves the same spectral efficiency as the RF scheme, which has never been attained by the existing O-OFDM schemes, because they have relied on the Hermitian symmetry of the spectral-domain signal to guarantee that the time-domain signal becomes real-valued. We show that O-OFDMNet can be viewed as an autoencoder architecture, which can be trained in an end-to-end manner in order to simultaneously improve both the bit error ratio (BER) and the peak-to-average power ratio (PAPR) for transmission over both additive white Gaussian noise and frequency-selective channels. Furthermore, we intrinsically integrate a soft-decision aided channel decoder with our O-OFDMNet and investigate its coded performance relying on both convolutional and polar codes. The simulation results show that our scheme improves both the uncoded and coded BER as well as a reducing the PAPR compared to the benchmarks at the cost of a moderate additional DNN complexity. Furthermore, our scheme is capable of approaching the throughput of RF-OFDM, which is notably higher than that of conventional O-OFDM. Finally, our complexity analysis shows that O-OFDMNet is suitable for real-time operation.}
}


@article{DBLP:journals/jsac/SunZNG22,
	author = {Yuxuan Sun and
                  Sheng Zhou and
                  Zhisheng Niu and
                  Deniz G{\"{u}}nd{\"{u}}z},
	title = {Dynamic Scheduling for Over-the-Air Federated Edge Learning With Energy
                  Constraints},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {227--242},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126078},
	doi = {10.1109/JSAC.2021.3126078},
	timestamp = {Fri, 21 Jan 2022 22:02:27 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SunZNG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning and wireless communication technologies are jointly facilitating an intelligent edge, where federated edge learning (FEEL) is emerging as a promising training framework. As wireless devices involved in FEEL are resource limited in terms of communication bandwidth, computing power and battery capacity, it is important to carefully schedule them to optimize the training performance. In this work, we consider an over-the-air FEEL system with analog gradient aggregation, and propose an energy-aware dynamic device scheduling algorithm to optimize the training performance within the energy constraints of devices, where both communication energy for gradient aggregation and computation energy for local training are considered. The consideration of computation energy makes dynamic scheduling challenging, as devices are scheduled before local training, but the communication energy for over-the-air aggregation depends on the\nl\n2\n-norm of local gradient, which is known only after local training. We thus incorporate estimation methods into scheduling to predict the gradient norm. Taking the estimation error into account, we characterize the performance gap between the proposed algorithm and its offline counterpart. Experimental results show that, under a highly unbalanced local data distribution, the proposed algorithm can increase the accuracy by 4.9% on CIFAR-10 dataset compared with the myopic benchmark, while satisfying the energy constraints.}
}


@article{DBLP:journals/jsac/ChenWCLZBLJ22,
	author = {Xianfu Chen and
                  Celimuge Wu and
                  Tao Chen and
                  Zhi Liu and
                  Honggang Zhang and
                  Mehdi Bennis and
                  Hang Liu and
                  Yusheng Ji},
	title = {Information Freshness-Aware Task Offloading in Air-Ground Integrated
                  Edge Computing Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {243--258},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126075},
	doi = {10.1109/JSAC.2021.3126075},
	timestamp = {Sat, 08 Jan 2022 02:24:14 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenWCLZBLJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates an air-ground integrated multi-access edge computing system, which is deployed by an infrastructure provider (InP). Under a business agreement with the InP, a third-party service provider provides computing services to the subscribed mobile users (MUs). MUs compete for the shared spectrum and computing resources over time to achieve their distinctive goals. From the perspective of an MU, we deliberately define the age of update to capture the staleness of information from refreshing computation outcomes. Given the system dynamics, we model the interactions among MUs as a stochastic game. In the Nash equilibrium without cooperation, each MU behaves in accordance with the local system states and conjectures. We can hence transform the stochastic game into a single-agent Markov decision process. As another major contribution, we develop an online deep reinforcement learning (RL) scheme that adopts two separate double deep Q-networks to approximate the Q-factor and the post-decision Q-factor, respectively. The deep RL scheme allows each MU to optimize the behaviours with unknown dynamic statistics. Numerical experiments show that our proposed scheme outperforms the baselines in terms of the average utility under various system conditions.}
}


@article{DBLP:journals/jsac/XuCMLJ22,
	author = {Xiaoxia Xu and
                  Qimei Chen and
                  Xidong Mu and
                  Yuanwei Liu and
                  Hao Jiang},
	title = {Graph-Embedded Multi-Agent Learning for Smart Reconfigurable THz {MIMO-NOMA}
                  Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {259--275},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126079},
	doi = {10.1109/JSAC.2021.3126079},
	timestamp = {Sat, 30 Sep 2023 10:20:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XuCMLJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the accelerated development of immersive applications and the explosive increment of internet-of-things (IoT) terminals, 6G would introduce terahertz (THz) massive multiple-input multiple-output non-orthogonal multiple access (MIMO-NOMA) technologies to meet the ultra-high-speed data rate and massive connectivity requirements. Nevertheless, the unreliability of THz transmissions and the extreme heterogeneity of device requirements pose critical challenges for practical applications. To address these challenges, we propose a novel smart reconfigurable THz MIMO-NOMA framework, which can realize customizable and intelligent communications by flexibly and coordinately reconfiguring hybrid beams through the cooperation between access points (APs) and reconfigurable intelligent surfaces (RISs). The optimization problem is formulated as a decentralized partially-observable Markov decision process (Dec-POMDP) to maximize the network energy efficiency, while guaranteeing the diversified users’ performance, via a joint RIS element selection, coordinated discrete phase-shift control, and power allocation strategy. To solve the above non-convex, strongly coupled, and highly complex mixed integer nonlinear programming (MINLP) problem, we propose a novel multi-agent deep reinforcement learning (MADRL) algorithm, namely graph-embedded value-decomposition actor-critic (GE-VDAC) , that embeds the interaction information of agents, and learns a locally optimal solution through a distributed policy. Numerical results demonstrate that the proposed algorithm achieves highly customized communications and outperforms traditional MADRL algorithms.}
}


@article{DBLP:journals/jsac/TangHKKYH22,
	author = {Fengxiao Tang and
                  Hans Hofner and
                  Nei Kato and
                  Kazuma Kaneko and
                  Yasutaka Yamashita and
                  Masatake Hangai},
	title = {A Deep Reinforcement Learning-Based Dynamic Traffic Offloading in
                  Space-Air-Ground Integrated Networks {(SAGIN)}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {276--289},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126073},
	doi = {10.1109/JSAC.2021.3126073},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/TangHKKYH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Space-Air-Ground Integrated Networks (SAGIN) is considered as the key structure of the next generation network. The space satellites and air nodes are the potential candidates to assist and offload the terrain transmissions. However, due to the high mobility of space and air nodes as well as the high dynamic of network traffic, the conventional traffic offloading strategy is not applicable for the high dynamic SAGIN. In this paper, we propose a reinforcement learning based traffic offloading for SAGIN by considering the high mobility of nodes as well as frequent changing network traffic and link state. In the proposal, a double Q-learning algorithm with improved delay-sensitive replay memory algorithm (DSRPM) is proposed to train the node to decide offloading strategy based on the local and neighboring historical information. Furthermore, a joint information collection with hello package and offline training mechanism is proposed to assist the proposed offloading algorithm. The simulation shows that the proposal outperforms conventional offloading algorithms in terms of signaling overhead, dynamic adaptivity, packet drop rate and transmission delay.}
}


@article{DBLP:journals/jsac/WeiLMDCJHP22,
	author = {Kang Wei and
                  Jun Li and
                  Chuan Ma and
                  Ming Ding and
                  Cailian Chen and
                  Shi Jin and
                  Zhu Han and
                  H. Vincent Poor},
	title = {Low-Latency Federated Learning Over Wireless Channels With Differential
                  Privacy},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {290--307},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126052},
	doi = {10.1109/JSAC.2021.3126052},
	timestamp = {Mon, 10 Jan 2022 15:47:05 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WeiLMDCJHP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In federated learning (FL), model training is distributed over clients and local models are aggregated by a central server. The performance of uploaded models in such situations can vary widely due to imbalanced data distributions, potential demands on privacy protections, and quality of transmissions. In this paper, we aim to minimize FL training delay over wireless channels, constrained by overall training performance as well as each client’s differential privacy (DP) requirement. We solve this problem in a multi-agent multi-armed bandit (MAMAB) framework to deal with the situation where there are multiple clients confronting different unknown transmission environments, e.g., channel fading and interference. Specifically, we first transform long-term constraints on both training performance and each client’s DP into a virtual queue based on the Lyapunov drift technique. Then, we convert the MAMAB to a max-min bipartite matching problem at each communication round, by estimating rewards with the upper confidence bound (UCB) approach. More importantly, we propose two efficient solutions to this matching problem, i.e., a modified Hungarian algorithm and greedy matching with a better alternative (GMBA), of which the former can achieve the optimal solution with high complexity while the latter approaches a better trade-off by enabling verified low-complexity with little performance loss. In addition, we develop an upper bound on the expected regret of this MAMAB based FL framework, which shows a linear growth over the logarithm of communication rounds, justifying its theoretical feasibility. Extensive experimental results are conducted to validate the effectiveness of our proposed algorithms, and the impacts of various parameters on the FL performance over wireless edge networks are also discussed.}
}


@article{DBLP:journals/jsac/WangBZ22,
	author = {Shuoyao Wang and
                  Suzhi Bi and
                  Ying{-}Jun Angela Zhang},
	title = {Deep Reinforcement Learning With Communication Transformer for Adaptive
                  Live Streaming in Wireless Edge Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {308--322},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126062},
	doi = {10.1109/JSAC.2021.3126062},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangBZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emerging mobile edge computing (MEC) technology has been recently applied to improve the Quality of Experience (QoE) of network services, such as live video streaming. In this paper, we study an energy-aware adaptive live streaming scheme in wireless edge networks. In particular, we aim to design a joint uplink transmission and edge transcoding algorithm maximizing the video followers’ QoE, while minimizing the energy consumption of the video streamer. We formulate the problem as a Markov decision process (MDP), and propose a deep reinforcement learning (DRL) based framework, named SACCT, to determine the streamer’s encoding bitrate, the uploading power as well as the edge transcoding bitrates and frequency. We decompose the MDP problem into inter-frame and intra-frame problems to address the key design challenges that arise from continuous-discrete hybrid action space, time-varying state and action spaces, and unknown network variation. By doing so, SACCT integrates model-based optimization and model-free DRL to determine the intra-frame continuous resource allocation decisions and the inter-frame discrete bitrate adaptation decisions, respectively. To integrate both the numerical features (e.g., channel gain) and the categorical features (e.g., bitrate), we propose a communication Transformer (CT) as a backbone of SACCT by representing network states as communication tokens and running Transformers to model multi-scale dependencies. Extensive simulations manifest that compared with state-of-the-art approaches, SACCT can provide 128.23% (on average) extra reward. As such, by leveraging joint uplink adaption and edge transcoding, the proposed scheme enables an intelligent wireless network edge with QoE-assured and energy-aware live streaming services.}
}


@article{DBLP:journals/jsac/WangXSC22,
	author = {Yanmeng Wang and
                  Yanqing Xu and
                  Qingjiang Shi and
                  Tsung{-}Hui Chang},
	title = {Quantized Federated Learning Under Transmission Delay and Outage Constraints},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {323--341},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126081},
	doi = {10.1109/JSAC.2021.3126081},
	timestamp = {Thu, 23 Jun 2022 20:01:47 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangXSC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has been recognized as a viable distributed learning paradigm which trains a machine learning model collaboratively with massive mobile devices in the wireless edge while protecting user privacy. Although various communication schemes have been proposed to expedite the FL process, most of them have assumed ideal wireless channels which provide reliable and lossless communication links between the server and mobile clients. Unfortunately, in practical systems with limited radio resources such as constraint on the training latency and constraints on the transmission power and bandwidth, transmission of a large number of model parameters inevitably suffers from quantization errors (QE) and transmission outage (TO). In this paper, we consider such non-ideal wireless channels, and carry out the first analysis showing that the FL convergence can be severely jeopardized by TO and QE, but intriguingly can be alleviated if the clients have uniform outage probabilities. These insightful results motivate us to propose a robust FL scheme, named FedTOE , which performs joint allocation of wireless resources and quantization bits across the clients to minimize the QE while making the clients have the same TO probability. Extensive experimental results are presented to show the superior performance of FedTOE for deep learning-based classification tasks with transmission latency constraints.}
}


@article{DBLP:journals/jsac/CaoZXWC22,
	author = {Xiaowen Cao and
                  Guangxu Zhu and
                  Jie Xu and
                  Zhiqin Wang and
                  Shuguang Cui},
	title = {Optimized Power Control Design for Over-the-Air Federated Edge Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {342--358},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126060},
	doi = {10.1109/JSAC.2021.3126060},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/CaoZXWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over-the-air federated edge learning (Air-FEEL) has emerged as a communication-efficient solution to enable distributed machine learning over edge devices by using their data locally to preserve the privacy. By exploiting the waveform superposition property of wireless channels, Air-FEEL allows the “one-shot” over-the-air aggregation of gradient-updates to enhance the communication efficiency, but at the cost of a compromised learning performance due to the aggregation errors caused by channel fading and noise. This paper investigates the transmission power control to combat against such aggregation errors in Air-FEEL. Different from conventional power control designs (e.g., to minimize the individual mean squared error (MSE) of the over-the-air aggregation at each round), we consider a new power control design aiming at directly maximizing the convergence speed. Towards this end, we first analyze the convergence behavior of Air-FEEL (in terms of the optimality gap) subject to aggregation errors at different communication rounds. It is revealed that if the aggregation estimates are unbiased, then the training algorithm would converge exactly to the optimal point with mild conditions; while if they are biased, then the algorithm would converge with an error floor determined by the accumulated estimate bias over communication rounds. Next, building upon the convergence results, we optimize the power control to directly minimize the derived optimality gaps under the cases without and with unbiased aggregation constraints, subject to a set of average and maximum power constraints at individual edge devices. We transform both problems into convex forms, and obtain their structured optimal solutions, both appearing in a form of regularized channel inversion, by using the Lagrangian duality method. Finally, numerical results show that the proposed power control policies achieve significantly faster convergence for Air-FEEL, as compared with benchmark policies with fixed power transmission or conventional MSE minimization.}
}


@article{DBLP:journals/jsac/NgLXCNLK22,
	author = {Jer Shyuan Ng and
                  Wei Yang Bryan Lim and
                  Zehui Xiong and
                  Xianbin Cao and
                  Dusit Niyato and
                  Cyril Leung and
                  Dong In Kim},
	title = {A Hierarchical Incentive Design Toward Motivating Participation in
                  Coded Federated Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {359--375},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126057},
	doi = {10.1109/JSAC.2021.3126057},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/NgLXCNLK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is a privacy-preserving collaborative learning approach that trains artificial intelligence (AI) models without revealing local datasets of the FL workers. While FL ensures the privacy of the FL workers, its performance is limited by several bottlenecks, which become significant given the increasing amounts of data generated and the size of the FL network. One of the main challenges is the straggler effects where the significant computation delays are caused by the slow FL workers. As such, Coded Federated Learning (CFL), which leverages coding techniques to introduce redundant computations to the FL server, has been proposed to reduce the computation latency. In CFL, the FL server helps to compute a subset of the partial gradients based on the composite parity data and aggregates the computed partial gradients with those received from the FL workers. In order to implement the coding schemes over the FL network, incentive mechanisms are important to allocate the resources of the FL workers and data owners efficiently in order to complete the CFL training tasks. In this paper, we consider a two-level incentive mechanism design problem. In the lower level, the data owners are allowed to support the FL training tasks of the FL workers by contributing their data. To model the dynamics of the selection of FL workers by the data owners, an evolutionary game is adopted to achieve an equilibrium solution. In the upper level, a deep learning based auction is proposed to model the competition among the model owners.}
}


@article{DBLP:journals/jsac/ZhengLZCDXW22,
	author = {Ying Zheng and
                  Lixiang Lin and
                  Tianqi Zhang and
                  Haoyu Chen and
                  Qingyang Duan and
                  Yuedong Xu and
                  Xin Wang},
	title = {Enabling Robust DRL-Driven Networking Systems via Teacher-Student
                  Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {376--392},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126085},
	doi = {10.1109/JSAC.2021.3126085},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengLZCDXW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The past few years have witnessed a surge of interest towards deep reinforcement learning (DRL) in computer networks. With extraordinary ability of feature extraction, DRL has the potential to re-engineer the fundamental resource allocation problems in networking without relying on pre-programmed models or assumptions about dynamic environments. However, such black-box systems suffer from poor robustness, showing high performance variance and poor tail performance. In this work, we propose a unified Teacher-Student learning framework that harnesses rich domain knowledge to improve robustness. The domain-specific algorithms, less performant but more trustable than DRL, play the role of teachers providing advice at critical states; the student neural network is steered to maximize the expected reward as usual and mimic the teacher’s advice meanwhile. The Teacher-Student method comprises of three modules where the confidence check module locates wrong decisions and risky decisions, the reward shaping module designs a new updating function to stimulate the learning of student network, and the prioritized experience replay module to effectively utilize the advised actions. We further implement our Teacher-Student framework in existing video streaming (Pensieve), load balancing (DeepLB), and TCP congestion control (Aurora). Experimental results manifest that the proposed approach reduces the performance standard deviation of DeepLB by 37%; it improves the 90th, 95th, and 99th tail performance of Pensieve by 7.6%, 8.8%, and 10.7% respectively; and it accelerates the growth rate of Aurora by 2x at the initial stage, and achieves a more stable performance in dynamic environments.}
}


@article{DBLP:journals/jsac/MouGLW22,
	author = {Zhiyu Mou and
                  Feifei Gao and
                  Jun Liu and
                  Qihui Wu},
	title = {Resilient {UAV} Swarm Communications With Graph Convolutional Neural
                  Network},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {393--411},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126047},
	doi = {10.1109/JSAC.2021.3126047},
	timestamp = {Sat, 08 Jan 2022 02:24:13 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MouGLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the self-healing problem of unmanned aerial vehicle (UAV) swarm network (USNET) that is required to quickly rebuild the communication connectivity under unpredictable external destructions (UEDs). Firstly, to cope with the one-off UEDs , we propose a graph convolutional neural network (GCN) that can find the recovery topology of the USNET in an on-line manner. Secondly, to cope with general UEDs , we develop a GCN based trajectory planning algorithm that can make UAVs rebuild the communication connectivity during the self-healing process. We also design a meta learning scheme to facilitate the on-line executions of the GCN. Numerical results show that the proposed algorithms can rebuild the communication connectivity of the USNET more quickly than the existing algorithms under both one-off UEDs and general UEDs. The simulation results also show that the meta learning scheme can not only enhance the performance of the GCN but also reduce the time complexity of the on-line executions.}
}


@article{DBLP:journals/jsac/WangJFJTGW22,
	author = {Xiong Wang and
                  Riheng Jia and
                  Luoyi Fu and
                  Haiming Jin and
                  Xiaohua Tian and
                  Xiaoying Gan and
                  Xinbing Wang},
	title = {Online Spatial Crowdsensing With Expertise-Aware Truth Inference and
                  Task Allocation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {412--427},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126045},
	doi = {10.1109/JSAC.2021.3126045},
	timestamp = {Sat, 08 Jan 2022 02:24:14 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangJFJTGW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging crowdsensing paradigm enables a large number of sensing applications, where much attention is drawn to the fundamental problems of data collection and truth inference. Existing works have devised manifold techniques to discover truth from collected noisy data, but they frequently ignore various expertise of workers and dynamic information of crowdsensing system, thus leading to error-prone estimated truth and unqualified sensing data. In this paper, we design an online location-aware crowdsensing system to accurately estimate truth and efficiently assign tasks. Specifically, we unify diverse types of numerical and categorical tasks based on probabilistic graphical model, and then propose unsupervised learning methods which can dynamically infer ground truth and various worker expertise at the same time. Furthermore, we develop online task allocation schemes to gradually gather high quality data considering location awareness and inferred worker expertise. In particular, we convert the complicated task allocation into the additive form of probability improvement and entropy reduction, thereby solving the allocation problem via linearly selecting worker-task pair with low computation complexity. We finally carry out extensive evaluations using two datasets collected by our smartphones, where results demonstrate the superiority of our algorithms over the state-of-the-art approaches.}
}


@article{DBLP:journals/jsac/TangYZCQ22,
	author = {Dan Tang and
                  Yudong Yan and
                  Siqi Zhang and
                  Jingwen Chen and
                  Zheng Qin},
	title = {Performance and Features: Mitigating the Low-Rate TCP-Targeted DoS
                  Attack via {SDN}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {1},
	pages = {428--444},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3126053},
	doi = {10.1109/JSAC.2021.3126053},
	timestamp = {Wed, 27 Apr 2022 16:59:07 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TangYZCQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software-Defined Networking (SDN) is an emerging network architecture. The decoupled data and control plane provides programmability for efficient network management. However, the centralized control mode of SDN also exposes unique vulnerabilities. Low-rate Denial of Service (LDoS) has a lower attack rate than ordinary DDoS attacks with the characteristics of periodicity and concealment, which is among one of the severe threats to SDN. In this paper, we propose a lightweight, real-time framework Performance and Features (P&F) to detect and mitigate LDoS attacks with SDN. We implement LDoS attacks in SDN, extract traffic features with OpenFlow, and classify the features into two categories. By analyzing the performance (P) of normal traffic under attack state, P&F determines whether LDoS attacks take effect based on machine learning. Meanwhile, P&F tries to locate attack sources and victims according to flow features (F) of LDoS attacks based on time-frequency analysis. According to detection and locating results, P&F sets corresponding mitigation schemes. Experimental results show that P&F has a high detection rate and low false positive rate for detecting LDoS attacks. P&F can deploy on controllers to achieve real-time attack detection and mitigation with low system cost, which can defend against LDoS attacks effectively.}
}


@article{DBLP:journals/jsac/ChenGHSBFP22,
	author = {Mingzhe Chen and
                  Deniz G{\"{u}}nd{\"{u}}z and
                  Kaibin Huang and
                  Walid Saad and
                  Mehdi Bennis and
                  Aneta Vulgarakis Feljan and
                  H. Vincent Poor},
	title = {Guest Editorial Special Issue on Distributed Learning Over Wireless
                  Edge Networks - Part {II}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {445--448},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118515},
	doi = {10.1109/JSAC.2021.3118515},
	timestamp = {Tue, 08 Feb 2022 10:43:27 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenGHSBFP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This is Part II of a double-part special issue on distributed learning over wireless edge networks. This two-part special issue features papers dealing with two main research challenges: optimization of wireless network performance for efficient implementation of distributed learning in wireless networks, and distributed learning for solving communication problems and optimizing network performance. The accepted papers in this special issue have been grouped into three topics: 1) network optimization for federated learning (FL), 2) network optimization for other distributed learning methods, and 3) distributed reinforcement learning (RL) for wireless network optimization. In Part I (vol. 39, no. 12, Dec. 2021), the focus is on the first cluster (network optimization for FL). The focus of Part II is on the second and third clusters (network optimization for other distributed learning methods and RL for wireless network optimization). The readers are referred to Part I for an overview paper [A1] by the team of guest editors where a comprehensive study of how distributed learning can be efficiently deployed over wireless edge networks is provided. The contributions made by the papers in Part II are summarized as follows.}
}


@article{DBLP:journals/jsac/SahaRRG22,
	author = {Rajarshi Saha and
                  Stefano Rini and
                  Milind Rao and
                  Andrea J. Goldsmith},
	title = {Decentralized Optimization Over Noisy, Rate-Constrained Networks:
                  Achieving Consensus by Communicating Differences},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {449--467},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118428},
	doi = {10.1109/JSAC.2021.3118428},
	timestamp = {Fri, 21 Jan 2022 22:02:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SahaRRG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In decentralized optimization, multiple nodes in a network collaborate to minimize the sum of their local loss functions. The information exchange between nodes required for this task, is often limited by network connectivity. We consider a setting in which communication between nodes is hindered by both (i) a finite rate-constraint on the signal transmitted by any node, and (ii) additive noise corrupting the signal received by any node. We propose a novel algorithm for this scenario: Decentralized Lazy Mirror Descent with Differential Exchanges (DLMD-DiffEx), which guarantees convergence of the local estimates to the optimal solution under the given communication constraints. A salient feature of DLMD-DiffEx is the introduction of additional proxy variables that are maintained by the nodes to account for the disagreement in their estimates due to channel noise and rate-constraints. Convergence to the optimal solution is attained by having nodes iteratively exchange these disagreement terms until consensus is achieved. In order to prevent noise accumulation during this exchange, DLMD-DiffEx relies on two sequences: one controlling the power of the transmitted signal, and the other determining the consensus rate. We provide insights on the design of these two sequences which highlights the interplay between consensus rate and noise amplification. We investigate the performance of DLMD-DiffEx both from a theoretical perspective as well as through numerical evaluations on synthetic data and MNIST. MATLAB and Python implementations can be found at https://github.com/rajarshisaha95/DLMD-DiffEx.}
}


@article{DBLP:journals/jsac/TeginHRD22,
	author = {Busra Tegin and
                  Eduin E. Hernandez and
                  Stefano Rini and
                  Tolga M. Duman},
	title = {Straggler Mitigation Through Unequal Error Protection for Distributed
                  Approximate Matrix Multiplication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {468--483},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118350},
	doi = {10.1109/JSAC.2021.3118350},
	timestamp = {Mon, 28 Aug 2023 21:38:10 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TeginHRD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large-scale machine learning and data mining methods routinely distribute computations across multiple agents to parallelize processing. The time required for the computations at the agents is affected by the availability of local resources and/or poor channel conditions, thus giving rise to the “straggler problem.” In this paper, we address this problem for distributed approximate matrix multiplication. In particular, we employ Unequal Error Protection (UEP) codes to obtain an approximation of the matrix product to provide higher protection for the blocks with a higher effect on the multiplication outcome. We characterize the performance of the proposed approach from a theoretical perspective by bounding the expected reconstruction error for matrices with uncorrelated entries. We also apply the proposed coding strategy to the computation of the back-propagation step in the training of a Deep Neural Network (DNN) for an image classification task in the evaluation of the gradients. Our numerical experiments show that it is indeed possible to obtain significant improvements in the overall time required to achieve DNN training convergence by producing approximation of matrix products using UEP codes in the presence of stragglers.}
}


@article{DBLP:journals/jsac/HuynhHND22,
	author = {Nguyen Van Huynh and
                  Dinh Thai Hoang and
                  Diep N. Nguyen and
                  Eryk Dutkiewicz},
	title = {Joint Coding and Scheduling Optimization for Distributed Learning
                  Over Wireless Edge Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {484--498},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118432},
	doi = {10.1109/JSAC.2021.3118432},
	timestamp = {Fri, 21 Jan 2022 22:02:27 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HuynhHND22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unlike theoretical analysis of distributed learning (DL) in the literature, DL over wireless edge networks faces the inherent dynamics/uncertainty of wireless connections and edge nodes, making DL less efficient or even inapplicable under the highly dynamic wireless edge networks. This article addresses these problems by leveraging recent advances in coded computing and the deep dueling neural network architecture. By introducing coded structures/redundancy, a distributed learning task can be completed without waiting for straggling nodes. Unlike conventional coded computing that only optimizes the code structure, coded distributed learning over the wireless edge also requires to optimize the selection/scheduling of wireless edge nodes with heterogeneous connections, computing capability, and straggling effects. However, even neglecting the aforementioned dynamics/uncertainty, the resulting joint optimization of coding and scheduling to minimize the distributed learning time turns out to be NP-hard. To tackle this and to account for the dynamics and uncertainty of wireless connections and edge nodes, we reformulate the problem as a Markov Decision Process and design a novel deep reinforcement learning algorithm that employs the deep dueling neural network architecture to find the jointly optimal coding scheme and the best set of edge nodes for different learning tasks without explicit information about the wireless environment and edge nodes’ straggling parameters. Simulations show that the proposed framework reduces the average learning delay in wireless edge computing up to 66% compared with other DL approaches. The jointly optimal framework in this article is also applicable to any distributed learning scheme with heterogeneous and uncertain computing nodes.}
}


@article{DBLP:journals/jsac/NingSFYQWLH22,
	author = {Wanyi Ning and
                  Haifeng Sun and
                  Xiaoyuan Fu and
                  Xiang Yang and
                  Qi Qi and
                  Jingyu Wang and
                  Jianxin Liao and
                  Zhu Han},
	title = {Following the Correct Direction: Renovating Sparsified {SGD} Towards
                  Global Optimization in Distributed Edge Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {499--514},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118396},
	doi = {10.1109/JSAC.2021.3118396},
	timestamp = {Wed, 14 Sep 2022 14:07:26 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/NingSFYQWLH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed edge learning collaborates powerful edge devices to train a shared global model. Since the frequent communication between the server and workers is very expensive, it is desired to accelerate the learning process. The gradient sparsification is an efficient method that only uploads a small subset of gradient elements. However, most existing works neglect the distributed nature of local datasets, and consequently the local gradients uploaded by edge devices cannot follow the global correct optimization direction well, which results in the loss of accuracy. In this paper, we propose a new gradient sparsification with a renovating mechanism, called Global Renovating Stochastic Gradient Descent (GRSGD). GRSGD utilizes the previous-round global gradient to estimate the current global one and renovates the current zero-sparsified local gradients. It mitigates the communication overhead while making the convergence direction of training closer to the global optimization, accelerating the distributed edge learning process. We provide a theoretical convergence guarantee for our algorithm based on the non-convex assumption, which better fits most deep learning problems. With extensive experiments in PyTorch, we show that GRSGD effectively accelerates the learning process with a smaller communication cost and a faster convergence rate on most training tasks. For example, on ImageNet MnasNet, GRSGD cuts down the gradient size from 8.47MB to 2.13MB while achieving 9.6%+ higher accuracy.}
}


@article{DBLP:journals/jsac/XuCMXWQ22,
	author = {Hongli Xu and
                  Min Chen and
                  Zeyu Meng and
                  Yang Xu and
                  Lun Wang and
                  Chunming Qiao},
	title = {Decentralized Machine Learning Through Experience-Driven Method in
                  Edge Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {515--531},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118424},
	doi = {10.1109/JSAC.2021.3118424},
	timestamp = {Tue, 29 Nov 2022 22:51:44 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XuCMXWQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data generated at the network edge can be processed locally by leveraging the paradigm of edge computing. To fully utilize the widely distributed data, we concentrate on a wireless edge computing system that conducts model training using decentralized peer-to-peer (P2P) methods. However, there are two major challenges on the way towards efficient P2P model training: limited resources (e.g., network bandwidth and battery life of mobile devices) and time-varying network connectivity due to device mobility or wireless channel dynamics, which receives less attention in recent years. To address these two challenges, this paper studies the impact of topology construction on the P2P training performance. Specifically, we dynamically construct an efficient P2P topology, where model aggregation occurs at the edge. In a nutshell, we first formulate the topology construction for P2P learning (TCPL) problem with resource constraints as an integer programming problem. Then a learning-driven method is proposed to adaptively construct a topology at each training epoch. We evaluate the performance of our proposed algorithm through extensive simulations and physical platform. Evaluation results show that our method can improve the model training efficiency by about 11% with resource constraints, reduce the communication cost by 30% and the network traffic consumption by about 60% under the same accuracy requirement compared to the benchmarks.}
}


@article{DBLP:journals/jsac/PaulFC22,
	author = {Raz Paul and
                  Yuval Friedman and
                  Kobi Cohen},
	title = {Accelerated Gradient Descent Learning Over Multiple Access Fading
                  Channels},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {532--547},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118410},
	doi = {10.1109/JSAC.2021.3118410},
	timestamp = {Fri, 21 Jan 2022 22:02:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/PaulFC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a distributed learning problem in a wireless network, consisting of N\ndistributed edge devices and a parameter server (PS). The objective function is a sum of the edge devices’ local loss functions, who aim to train a shared model by communicating with the PS over multiple access channels (MAC). This problem has attracted a growing interest in distributed sensing systems, and more recently in federated learning, known as over-the-air computation. In this paper, we develop a novel Accelerated Gradient-descent Multiple Access (AGMA) algorithm that uses momentum-based gradient signals over noisy fading MAC to improve the convergence rate as compared to existing methods. Furthermore, AGMA does not require power control or beamforming to cancel the fading effect, which simplifies the implementation complexity. We analyze AGMA theoretically, and establish a finite-sample bound of the error for both convex and strongly convex loss functions with Lipschitz gradient. For the strongly convex case, we show that AGMA approaches the best-known linear convergence rate as the network increases. For the convex case, we show that AGMA significantly improves the sub-linear convergence rate as compared to existing methods. Finally, we present simulation results using real datasets that demonstrate better performance by AGMA.}
}


@article{DBLP:journals/jsac/LeeBO22,
	author = {Chuan{-}Zheng Lee and
                  Leighton Pate Barnes and
                  Ayfer {\"{O}}zg{\"{u}}r},
	title = {Over-the-Air Statistical Estimation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {548--561},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118412},
	doi = {10.1109/JSAC.2021.3118412},
	timestamp = {Fri, 21 Jan 2022 22:02:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LeeBO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study schemes and lower bounds for distributed minimax statistical estimation over a Gaussian multiple-access channel (MAC) under squared error loss. Our framework combines statistical estimation and wireless communication. First, we develop “analog” joint estimation-communication schemes that exploit the superposition property of the Gaussian MAC. We characterize their risk in terms of the number of nodes and dimension of the parameter space. Then, we derive information-theoretic lower bounds on the minimax risk of any estimation scheme that is restricted to communicate the samples over a given number of uses of the channel. This shows that the risk achieved by our proposed schemes is within a logarithmic factor of these lower bounds. We compare both achievability and lower bound results to previous “digital” lower bounds, where nodes transmit errorless bits at the Shannon capacity of the MAC. Our key finding is that analog estimation schemes that leverage the physical layer offer a drastic reduction in estimation error over digital schemes relying on a physical-layer abstraction.}
}


@article{DBLP:journals/jsac/LiuS22,
	author = {Dongzhu Liu and
                  Osvaldo Simeone},
	title = {Channel-Driven Monte Carlo Sampling for Bayesian Distributed Learning
                  in Wireless Data Centers},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {562--577},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118406},
	doi = {10.1109/JSAC.2021.3118406},
	timestamp = {Fri, 21 Jan 2022 22:02:27 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conventional frequentist learning, as assumed by existing federated learning protocols, is limited in its ability to quantify uncertainty, incorporate prior knowledge, guide active learning, and enable continual learning. Bayesian learning provides a principled approach to address all these limitations, at the cost of an increase in computational complexity. This paper studies distributed Bayesian learning in a wireless data center setting encompassing a central server and multiple distributed workers. Prior work on wireless distributed learning has focused exclusively on frequentist learning, and has introduced the idea of leveraging uncoded transmission to enable “over-the-air” computing. Unlike frequentist learning, Bayesian learning aims at evaluating approximations or samples from a global posterior distribution in the model parameter space. This work investigates for the first time the design of distributed one-shot, or “embarrassingly parallel”, Bayesian learning protocols in wireless data centers via consensus Monte Carlo (CMC). Uncoded transmission is introduced not only as a way to implement “over-the-air” computing, but also as a mechanism to deploy channel-driven MC sampling: Rather than treating channel noise as a nuisance to be mitigated, channel-driven sampling utilizes channel noise as an integral part of the MC sampling process. A simple wireless CMC scheme is first proposed that is asymptotically optimal under Gaussian local posteriors. Then, for arbitrary local posteriors, a variational optimization strategy is introduced. Simulation results demonstrate that, if properly accounted for, channel noise can indeed contribute to MC sampling and does not necessarily decrease the accuracy level.}
}


@article{DBLP:journals/jsac/PuYXCZX22,
	author = {Lingjun Pu and
                  Xinjing Yuan and
                  Xiaohang Xu and
                  Xu Chen and
                  Pan Zhou and
                  Jingdong Xu},
	title = {Cost-Efficient and Skew-Aware Data Scheduling for Incremental Learning
                  in 5G Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {578--595},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118430},
	doi = {10.1109/JSAC.2021.3118430},
	timestamp = {Thu, 20 Jun 2024 15:06:43 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/PuYXCZX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To facilitate the emerging applications in 5G networks, mobile network operators will provide many network functions in terms of control and prediction. Recently, they have recognized the power of machine learning (ML) and started to explore its potential to facilitate those network functions. Nevertheless, the current ML models for network functions are often derived in an offline manner, which is inefficient due to the excessive overhead for transmitting a huge volume of dataset to remote ML training clouds and failing to provide the incremental learning capability for the continuous model updating. As an alternative solution, we propose Cocktail, an incremental learning framework within a reference 5G network architecture. To achieve cost efficiency while increasing trained model accuracy, an efficient online data scheduling policy is essential. To this end, we formulate an online data scheduling problem to optimize the framework cost while alleviating the data skew issue caused by the capacity heterogeneity of training workers from the long-term perspective. We exploit the stochastic gradient descent to devise an online asymptotically optimal algorithm, including two optimal policies based on novel graph constructions for skew-aware data collection and data training. Small-scale testbed and large-scale simulations validate the superior performance of our proposed framework.}
}


@article{DBLP:journals/jsac/ShiHWZH22,
	author = {Siping Shi and
                  Chuang Hu and
                  Dan Wang and
                  Yifei Zhu and
                  Zhu Han},
	title = {Federated Anomaly Analytics for Local Model Poisoning Attack},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {596--610},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118347},
	doi = {10.1109/JSAC.2021.3118347},
	timestamp = {Sat, 30 Sep 2023 10:20:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ShiHWZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The local model poisoning attack is an attack to manipulate the shared local models during the process of distributed learning. Existing defense methods are passive in the sense that they try to mitigate the negative impact of the poisoned local models instead of eliminating them. In this paper, we leverage the new federated analytics paradigm, to develop a proactive defense method. More specifically, federated analytics is to collectively carry out analytics tasks without disclosing local data of the edge devices. We propose a Federated Anomaly Analytics enhanced Distributed Learning (FAA-DL) framework, where the clients and the server collaboratively analyze the anomalies. FAA-DL firstly detects all the uploaded local models and splits out the potential malicious ones. Then, it verifies each potential malicious local model with functional encryption. Finally, it removes the verified anomalies and aggregates the remaining to produce the global model. We analyze the FAA-DL framework and show that it is accurate, robust, and efficient. We evaluate FAA-DL by training classifiers on MNIST and Fashion-MNIST under various local model poisoning attacks. Our experiment results show FAA-DL improves the accuracy of the learned global model under strong attacks up to 6.90 times and outperforms the state-of-the-art defense methods with a robustness guarantee.}
}


@article{DBLP:journals/jsac/CaiWWLXZV22,
	author = {Shangming Cai and
                  Dongsheng Wang and
                  Haixia Wang and
                  Yongqiang Lyu and
                  Guangquan Xu and
                  Xi Zheng and
                  Athanasios V. Vasilakos},
	title = {DynaComm: Accelerating Distributed {CNN} Training Between Edges and
                  Clouds Through Dynamic Communication Scheduling},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {611--625},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118419},
	doi = {10.1109/JSAC.2021.3118419},
	timestamp = {Wed, 07 Feb 2024 17:24:23 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/CaiWWLXZV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To reduce uploading bandwidth and address privacy concerns, deep learning at the network edge has been an emerging topic. Typically, edge devices collaboratively train a shared model using real-time generated data through the Parameter Server framework. Although all the edge devices can share the computing workloads, the distributed training processes over edge networks are still time-consuming due to the parameters and gradients transmission procedures between parameter servers and edge devices. Focusing on accelerating distributed Convolutional Neural Networks (CNNs) training at the network edge, we present DynaComm, a novel scheduler that dynamically decomposes each transmission procedure into several segments to achieve optimal layer-wise communications and computations overlapping during run-time. Through experiments, we verify that DynaComm manages to achieve optimal layer-wise scheduling for all cases compared to competing strategies while the model accuracy remains untouched.}
}


@article{DBLP:journals/jsac/WangZUM22,
	author = {Song Wang and
                  Xinyu Zhang and
                  Hiromasa Uchiyama and
                  Hiroki Matsuda},
	title = {HiveMind: Towards Cellular Native Machine Learning Model Splitting},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {626--640},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118403},
	doi = {10.1109/JSAC.2021.3118403},
	timestamp = {Mon, 28 Aug 2023 21:38:11 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangZUM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing processing load of today’s mobile machine learning (ML) application challenges the stringent computation budget of mobile user equipment (UE). With the wide deployment of 5G edge-cloud, a new ML offloading scheme called split ML is provisioned to enable computation-intensive mobile ML applications by splitting an ML model across mobile UE, edge, and cloud. However, the complex split assignment problems pose new challenges for split ML system design. In this paper, we introduce HiveMind, the first practical multi-split ML system tailored for 5G cellular networks. HiveMind reformulates the complicated multi-split problem to a min-cost graph search and optimizes the distributed algorithm to drastically reduce the signaling overhead. Benefit from its low overhead property, HiveMind makes the optimal split decision on multiple computing nodes in real-time and adapts the split decisions to the instantaneous network dynamics. HiveMind also incorporates a multi-objective mechanism that accommodates heterogeneous objectives for a single ML task. HiveMind adapts to a wide range of ML frameworks, including non-linear models like Recurrent Neural Network (RNN), Federated Learning (FL), and Multi-agent Reinforcement Learning (MARL). We evaluate HiveMind on 5G MEC network simulators with realistic traffic patterns and real-life MEC computation/communication profiles. Our experiments demonstrate that HiveMind achieves the optimal efficiency comparing to state-of-art split ML designs.}
}


@article{DBLP:journals/jsac/WuLQ22,
	author = {Yi{-}Chen Wu and
                  Che Lin and
                  Tony Q. S. Quek},
	title = {A Robust Distributed Hierarchical Online Learning Approach for Dynamic
                  {MEC} Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {641--656},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118342},
	doi = {10.1109/JSAC.2021.3118342},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WuLQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a resource allocation and offloading decision-making problem in a mobile edge computing (MEC) network. Since the locations of user equipments (UEs) vary over time in practice, we consider a dynamic network, where the UEs could leave or join the network coverage at any location. Since the joint offloading decision that minimizes the network cost also varies with the topology, the expected best offloading decision for the previous topology would not match the new topology. Consequently, the system suffers from recurring cost peaks due to the topology change. Thus, we propose a robust distributed hierarchical online learning approach to enhance the algorithm’s robustness and reduce the cost peaks. Specifically, the UEs learn the utility of each offloading decision via deep Q networks (DQNs) from their interaction with the MEC network. Meanwhile, the computational access points (CAPs) train their deep neural networks (DNNs) online with the real-time data collected from the UEs to predict their corresponding Q-value vectors. Therefore, the UEs and CAPs form a hierarchical collaborative-learning structure. When the topology changes, each UE downloads its Q-value vector as the Q-bias vector and learns its difference from the actual Q-value vector via its DQN. With different agents learning distributedly, both the peak and sum costs are reduced as the joint offloading decision could start from a near-local-optimal point. In simulations, our robust approach successfully reduces the peak cost and sum cost by up to 50% and 30%, respectively. This demonstrates the need for a robust learning algorithm design in a practical dynamic MEC network.}
}


@article{DBLP:journals/jsac/LiuGPCOH22,
	author = {Yongnan Liu and
                  Xin Guan and
                  Yu Peng and
                  Hongyang Chen and
                  Tomoaki Ohtsuki and
                  Zhu Han},
	title = {Blockchain-Based Task Offloading for Edge Computing on Low-Quality
                  Data via Distributed Learning in the Internet of Energy},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {657--676},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118417},
	doi = {10.1109/JSAC.2021.3118417},
	timestamp = {Fri, 21 Jan 2022 22:02:27 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuGPCOH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of the Internet of energy, more and more participants share data by different types of edge devices. However, such multi-source heterogenous data typically contain low-quality data, e.g., missing values, which may result in potential risks. Besides, resource-constrained devices incur large latency in edge computing networks. To alleviate such latency, distributed task offloading schemes are designed to share the computation burden between edge nodes and nearby servers. However, there are three main drawbacks of such schemes. First, low-quality data are not carefully evaluated by constraints under scenarios, which may result in slow convergence in distributed computation. Second, multi-source data including sensitive information are computed and shared among edge nodes without privacy protection. Third, distributed tasks on low-quality data may result in low-quality results even with an optimal offloading scheme. To address the problems above, a task offloading framework for edge computing based on consortium blockchain and distributed reinforcement learning is proposed in this paper, which can provide high-quality task offloading policies with data privacy protected. This framework consists of three key components: data quality evaluation (DQ) with multiple data quality dimensions, data repairing (DR) with a repairing algorithm based on a novel repairing consensus mechanism and distributed reinforcement learning for task arrangement (DELTA) with a distributed reinforcement learning algorithm based on a novel low-quality data distributing strategy. Numeric results are presented to illustrate the effectiveness and efficiency of the proposed task offloading framework for edge computing on low-quality data in the IoE.}
}


@article{DBLP:journals/jsac/ZhangXLGFL22,
	author = {Ruichen Zhang and
                  Ke Xiong and
                  Yang Lu and
                  Bo Gao and
                  Pingyi Fan and
                  Khaled Ben Letaief},
	title = {Joint Coordinated Beamforming and Power Splitting Ratio Optimization
                  in {MU-MISO} SWIPT-Enabled HetNets: {A} Multi-Agent DDQN-Based Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {677--693},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118397},
	doi = {10.1109/JSAC.2021.3118397},
	timestamp = {Fri, 21 Jan 2022 22:02:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangXLGFL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a multi-agent double deep Q network (DDQN)-based approach to jointly optimize the beamforming vectors and power splitting (PS) ratio in multi-user multiple-input single-output (MU-MISO) simultaneous wireless information and power transfer (SWIPT)-enabled heterogeneous networks (HetNets), where a macro base station (MBS) and several femto base stations (FBSs) serve multiple macro user equipments (MUEs) and femto user equipments (FUEs). The PS receiver architecture is deployed at FUEs. An optimization problem is formulated to maximize the achievable sum information rate of FUEs under the constraints of the achievable information rate requirements of MUEs and FUEs and the energy harvesting (EH) requirements of FUEs. Since the optimization problem is challenging to handle due to the high dimension and time-varying environment, an efficient multi-agent DDQN-based algorithm is presented, which is trained in a centralized manner and runs in a distributed manner, where two sets of deep neural network parameters are jointly updated and trained to tackle the problem and avoid overestimation. To facilitate the presented multi-agent DDQN-based algorithm, the action space, the state space and the reward function are designed, where the codebook matrix is employed to deal with the complex transmit beamforming vectors. Simulation results validate the proposed algorithm. Notable performance gains are achieved by the proposed algorithm due to considering the beam directions in the action space and the adaptability to the Doppler frequency shifts. Besides, the proposed algorithm is shown to be superior to other benchmark ones numerically.}
}


@article{DBLP:journals/jsac/ZhangLLHTWY22,
	author = {Ran Zhang and
                  Jiang Liu and
                  Fangqi Liu and
                  Tao Huang and
                  Qinqin Tang and
                  Shangguang Wang and
                  F. Richard Yu},
	title = {Buffer-Aware Virtual Reality Video Streaming With Personalized and
                  Private Viewport Prediction},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {694--709},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3119144},
	doi = {10.1109/JSAC.2021.3119144},
	timestamp = {Fri, 21 Jan 2022 22:02:27 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangLLHTWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Viewport prediction and prefetch have an important influence on VR video streaming performance. This work proposes a novel federated learning-based viewport prediction model training algorithm, ComPer-FedAvg. The proposed algorithm leverages a VR video’s common viewing pattern and users’ personal viewing patterns to train the prediction model in a distributed and privacy-preserving manner. Further, considering the VR video viewport prediction accuracy, a stochastic game is formulated to solve the VR streaming network’s communication resource allocation problem, where limited communication resource blocks are auctioned to users to achieve the optimal overall VR viewing experience. For each user, the auction is decomposed into two disjoint subproblems, namely, the optimal number of data rate requesting and true value claiming (bidding). The optimal true value claiming has been analytically proved to be equal to the VR viewing reward with given data rate. Due to the lack of global information when users request data rate, we reformulate users’ data rate requesting problem as a POMDP problem. A novel deep reinforcement learning algorithm is adopted to solve the problem. Evaluation and simulation results show the proposed viewport prediction and VR streaming schemes outperform conventional solutions in terms of prediction accuracy and VR viewing experience.}
}


@article{DBLP:journals/jsac/LiuDHR22,
	author = {Xiaonan Liu and
                  Yansha Deng and
                  Chong Han and
                  Marco Di Renzo},
	title = {Learning-Based Prediction, Rendering and Transmission for Interactive
                  Virtual Reality in RIS-Assisted Terahertz Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {2},
	pages = {710--724},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3118405},
	doi = {10.1109/JSAC.2021.3118405},
	timestamp = {Fri, 21 Jan 2022 22:02:27 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuDHR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The quality of experience (QoE) requirements of wireless virtual reality (VR) can only be satisfied with high data rate, high reliability, and low VR interaction latency. This high data rate over short transmission distances may be achieved via the abundant bandwidth in the terahertz (THz) band. However, THz waves experience severe signal attenuation, which may be compensated by the reconfigurable intelligent surface (RIS) technology with programmable reflecting elements. Meanwhile, the low VR interaction latency can be achieved with the mobile edge computing (MEC) network architecture due to its computation capabilities. Motivated by these considerations, in this paper, we propose an MEC-enabled and RIS-assisted THz VR network in an indoor scenario, by taking into account the uplink viewpoint prediction and position transmission, the MEC rendering, and the downlink transmission. We propose two methods, which are referred to as centralized online gated recurrent unit (GRU) and distributed federated averaging (FedAvg), to predict the viewpoints of the VR users. In the uplink, an algorithm that integrates online long-short term memory (LSTM) and convolutional neural networks (CNN) is deployed to predict the locations and the line-of-sight and non-line-of-sight statuses of the VR users over time. In the downlink, we develop a constrained deep reinforcement learning algorithm to select the optimal phase shifts of the RIS under latency constraints. Simulation results show that our proposed learning architecture achieves near-optimal QoE as that of the genie-aided benchmark algorithm, and about two times improvement in QoE compared to the random phase shift selection scheme.}
}


@article{DBLP:journals/jsac/UlukusAGJTT22,
	author = {Sennur Ulukus and
                  Salman Avestimehr and
                  Michael Gastpar and
                  Syed Ali Jafar and
                  Ravi Tandon and
                  Chao Tian},
	title = {Privacy in Retrieval, Computing, and Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {725--728},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142570},
	doi = {10.1109/JSAC.2022.3142570},
	timestamp = {Tue, 15 Mar 2022 10:21:37 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/UlukusAGJTT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing prevalence of massive datasets makes the outsourcing of storage and computation tasks to distributed servers a necessity. This raises a number of concerns regarding the security and integrity of stored information, the privacy of accessing desired information, the communication overhead of distributed systems, the latency, reliability, and complexity of distributed computing, and privacy in distributed training and learning systems. Recent breakthroughs from coding, communication, and information-theoretic perspectives have opened up exciting new research avenues for these topics. There are many theoretical and practical open problems. This Special Issue is dedicated to communication theory, coding theory, information theory, signal processing, and networking aspects of privacy in information retrieval, privacy in coded computing over distributed servers, and privacy in distributed learning.}
}


@article{DBLP:journals/jsac/UlukusAGJTT22a,
	author = {Sennur Ulukus and
                  Salman Avestimehr and
                  Michael Gastpar and
                  Syed Ali Jafar and
                  Ravi Tandon and
                  Chao Tian},
	title = {Private Retrieval, Computing, and Learning: Recent Progress and Future
                  Challenges},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {729--748},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142358},
	doi = {10.1109/JSAC.2022.3142358},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/UlukusAGJTT22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most of our lives are conducted in the cyberspace. The human notion of privacy translates into a cyber notion of privacy on many functions that take place in the cyberspace. This article focuses on three such functions: how to privately retrieve information from cyberspace (privacy in information retrieval), how to privately leverage large-scale distributed/parallel processing (privacy in distributed computing), and how to learn/train machine learning models from private data spread across multiple users (privacy in distributed (federated) learning). The article motivates each privacy setting, describes the problem formulation, summarizes breakthrough results in the history of each problem, and gives recent results and discusses some of the major ideas that emerged in each field. In addition, the cross-cutting techniques and interconnections between the three topics are discussed along with a set of open problems and challenges.}
}


@article{DBLP:journals/jsac/LiuZHQ22,
	author = {Shengheng Liu and
                  Chong Zheng and
                  Yongming Huang and
                  Tony Q. S. Quek},
	title = {Distributed Reinforcement Learning for Privacy-Preserving Dynamic
                  Edge Caching},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {749--760},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142348},
	doi = {10.1109/JSAC.2022.3142348},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuZHQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing (MEC) is a prominent computing paradigm which expands the application fields of wireless communication. Due to the limitation of the capacities of user equipments and MEC servers, edge caching (EC) optimization is crucial to the effective utilization of the caching resources in MEC-enabled wireless networks. However, the dynamics and complexities of content popularities over space and time as well as the privacy preservation of users pose significant challenges to EC optimization. In this paper, a privacy-preserving distributed deep deterministic policy gradient (P2D3PG) algorithm is proposed to maximize the cache hit rates of devices in the MEC networks. Specifically, we consider the fact that content popularities are dynamic, complicated and unobservable, and formulate the maximization of cache hit rates on devices as distributed problems under the constraints of privacy preservation. In particular, we convert the distributed optimizations into distributed model-free Markov decision process problems and then introduce a privacy-preserving federated learning method for popularity prediction. Subsequently, a P2D3PG algorithm is developed based on distributed reinforcement learning to solve the distributed problems. Simulation results demonstrate the superiority of the proposed approach in improving EC hit rate over the baseline methods while preserving user privacy.}
}


@article{DBLP:journals/jsac/SasidharanT22,
	author = {Birenjith Sasidharan and
                  Anoop Thomas},
	title = {Coded Gradient Aggregation: {A} Tradeoff Between Communication Costs
                  at Edge Nodes and at Helper Nodes},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {761--772},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142356},
	doi = {10.1109/JSAC.2022.3142356},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SasidharanT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increasing amount of data generated at edge nodes and quest for privacy have resulted in learning at the edge. Computations are performed at edge devices and outputs are communicated to a central node for updating the model. The edge nodes are available intermittently and are connected via low-bandwidth links. The edge nodes communicate local gradients to helper nodes, and these helpers forward messages to the central node after possible aggregation. Recently, schemes using repetition codes and maximum-distance-separable (MDS) codes, respectively known as aligned repetition coding (ARC) and aligned MDS coding (AMC) schemes, were proposed. It was observed that the communication cost at edge nodes becomes optimal in the AMC scheme, at the expense of an increased cost of communication incurred by helpers. An upper bound on the communication cost at helpers for the AMC scheme was known in literature. In this paper, a tradeoff between communication costs at edge nodes and at helper nodes is established with the help of newly proposed pyramid scheme. The scheme makes use of well-known class of pyramid codes, thus expanding the realm of application of locally repairable codes to distributed learning. The communication costs both at helper nodes and at edge nodes are exactly characterized. Using the developed technique, the exact communication cost at helper nodes can be computed for the AMC scheme as well. Next, we come up with a technique to improve the aggregation strategy of both pyramid and AMC schemes, that yields significant reduction in communication cost at helpers without changing parameters of the code used by edges. Finally, we present a greedy algorithm to improve the aggregation strategy of the ARC scheme, achieving significantly reduced communication cost at helpers.}
}


@article{DBLP:journals/jsac/LiS22,
	author = {Tan Li and
                  Linqi Song},
	title = {Privacy-Preserving Communication-Efficient Federated Multi-Armed Bandits},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {773--787},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142374},
	doi = {10.1109/JSAC.2022.3142374},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Communication bottleneck and data privacy are two critical concerns in federated multi-armed bandit (MAB) problems, such as situations in decision-making and recommendations of connected vehicles via wireless. In this paper, we design the privacy-preserving communication-efficient algorithm in such problems and study the interactions among privacy, communication and learning performance in terms of the regret. To be specific, we design privacy-preserving learning algorithms and communication protocols and derive the learning regret when networked private agents are performing online bandit learning in a master-worker, a decentralized and a hybrid structure. Our bandit learning algorithms are based on epoch-wise sub-optimal arm eliminations at each agent and agents exchange learning knowledge with the server/each other at the end of each epoch. Furthermore, we adopt the differential privacy (DP) approach to protect the data privacy at each agent when exchanging information; and we curtail communication costs by making less frequent communications with fewer agents participation. By analyzing the regret of our proposed algorithmic framework in the master-worker, decentralized and hybrid structures, we theoretically show trade-offs between regret and communication costs/privacy. Finally, we empirically show these trade-offs which are consistent with our theoretical analysis.}
}


@article{DBLP:journals/jsac/SchlegelKRA22,
	author = {Reent Schlegel and
                  Siddhartha Kumar and
                  Eirik Rosnes and
                  Alexandre Graell i Amat},
	title = {Privacy-Preserving Coded Mobile Edge Computing for Low-Latency Distributed
                  Inference},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {788--799},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142295},
	doi = {10.1109/JSAC.2022.3142295},
	timestamp = {Tue, 15 Mar 2022 10:21:37 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SchlegelKRA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a mobile edge computing scenario where a number of devices want to perform a linear inference\nWx\non some local data\nx\ngiven a network-side matrix\nW\n. The computation is performed at the network edge over a number of edge servers. We propose a coding scheme that provides information-theoretic privacy against\nz\ncolluding (honest-but-curious) edge servers, while minimizing the overall latency—comprising upload, computation, download, and decoding latency—in the presence of straggling servers. The proposed scheme exploits Shamir’s secret sharing to yield data privacy and straggler mitigation, combined with replication to provide spatial diversity for the download. We also propose two variants of the scheme that further reduce latency. For a considered scenario with 9 edge servers, the proposed scheme reduces the latency by 8% compared to the nonprivate scheme recently introduced by Zhang and Simeone, while providing privacy against an honest-but-curious edge server.}
}


@article{DBLP:journals/jsac/NaimDR22,
	author = {Carolina Naim and
                  Rafael G. L. D'Oliveira and
                  Salim El Rouayheb},
	title = {Private Multi-Group Aggregation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {800--814},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142357},
	doi = {10.1109/JSAC.2022.3142357},
	timestamp = {Tue, 15 Mar 2022 10:21:37 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/NaimDR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the differentially private multi-group aggregation (PMGA) problem. This setting involves a single server and\nn\nusers. Each user belongs to one of\nk\ndistinct groups and holds a discrete value. The goal is to design schemes that allow the server to find the aggregate (sum) of the values in each group (with high accuracy) under communication and local differential privacy constraints. The privacy constraint guarantees that the user’s group remains private. This is motivated by applications where a user’s group can reveal sensitive information, such as his religious and political beliefs, health condition, or race. We propose a novel scheme, dubbed Query and Aggregate (Q&A) for PMGA. The novelty of Q&A is that it is an interactive aggregation scheme. In Q&A, each user is assigned a random query matrix, to which he sends the server an answer based on his group and value. We characterize the Q&A scheme’s performance in terms of accuracy (MSE), privacy, and communication. We compare Q&A to the Randomized Group (RG) scheme, which is non-interactive and adapts existing randomized response schemes to the PMGA setting. We observe that typically Q&A outperforms RG, in terms of privacy vs. utility, in the high privacy regime.}
}


@article{DBLP:journals/jsac/ZhuYT22,
	author = {Jinbao Zhu and
                  Qifa Yan and
                  Xiaohu Tang},
	title = {Multi-User Blind Symmetric Private Information Retrieval From Coded
                  Servers},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {815--831},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142352},
	doi = {10.1109/JSAC.2022.3142352},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhuYT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of Multi-user Blind\nX\n-secure\nT\n-colluding Symmetric Private Information Retrieval from Maximum Distance Separable (MDS) coded storage system with\nB\nByzantine and\nU\nunresponsive servers (U-B-MDS-MB-XTSPIR) is studied in this paper. Specifically, a database consisting of multiple files, each labeled by\nM\nindices, is stored at the distributed system with\nN\nservers according to\n(N,K+X)\nMDS codes over\nF\nq\nsuch that any group of up to\nX\ncolluding servers learn nothing about the data files. There are\nM\nusers, in which each user\nm,m=1,…,M\nprivately selects an index\nθ\nm\nand wishes to jointly retrieve the file specified by the\nM\nusers’ indices\n(\nθ\n1\n,…,\nθ\nM\n)\nfrom the storage system, while keeping its index\nθ\nm\nprivate from any\nT\nm\ncolluding servers, where there exists\nB\nByzantine servers that can send arbitrary responses maliciously to confuse the users retrieving the desired file and\nU\nunresponsive servers that will not respond any message at all. In addition, each user must not learn information about the other users’ indices and the database more than the desired file. An U-B-MDS-MB-XTSPIR scheme is constructed based on Lagrange encoding. The scheme achieves a retrieval rate of\n1−\nK+X+\nT\n1\n+…+\nT\nM\n+2B−1\nN−U\nwith secrecy rate\nK+X+\nT\n1\n+…+\nT\nM\n−1\nN−(K+X+\nT\n1\n+…+\nT\nM\n+2B+U−1)\non the finite field of size\nq≥N+max{K,N−(K+X+\nT\n1\n+…+\nT\nM\n+2B+U−1)}\nfor any number of files.}
}


@article{DBLP:journals/jsac/YakimenkaLRK22,
	author = {Yauhen Yakimenka and
                  Hsuan{-}Yin Lin and
                  Eirik Rosnes and
                  J{\"{o}}rg Kliewer},
	title = {Optimal Rate-Distortion-Leakage Tradeoff for Single-Server Information
                  Retrieval},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {832--846},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142296},
	doi = {10.1109/JSAC.2022.3142296},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YakimenkaLRK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private information retrieval protocols guarantee that a user can privately and losslessly retrieve a single file from a database stored across multiple servers. In this work, we propose to simultaneously relax the conditions of perfect retrievability and privacy in order to obtain improved download rates when all files are stored uncoded on a single server. Information leakage is measured in terms of the average success probability for the server of correctly guessing the identity of the desired file. The main findings are: i) The derivation of the optimal tradeoff between download rate, distortion, and information leakage when the file size is infinite . Closed-form expressions of the optimal tradeoff for the special cases of “no-leakage” and “no-privacy” are also given. ii) A novel approach based on linear programming (LP) to construct schemes for a finite file size and an arbitrary number of files. The proposed LP approach can be leveraged to find provably optimal schemes with corresponding closed-form expressions for the rate-distortion-leakage tradeoff when the database contains at most four bits. Finally, for a database that contains 320 bits, we compare two construction methods based on the LP approach with a nonconstructive scheme downloading subsets of files using a finite-length lossy compressor based on random coding.}
}


@article{DBLP:journals/jsac/ObeadLRK22,
	author = {Sarah A. Obead and
                  Hsuan{-}Yin Lin and
                  Eirik Rosnes and
                  J{\"{o}}rg Kliewer},
	title = {Private Linear Computation for Noncolluding Coded Databases},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {847--861},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142362},
	doi = {10.1109/JSAC.2022.3142362},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ObeadLRK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private computation in a distributed storage system (DSS) is a generalization of the private information retrieval (PIR) problem. In such a setting, a user wishes to compute a function of\nf\nmessages stored in\nn\nnoncolluding coded databases, i.e., databases storing data encoded with an\n[n,k]\nlinear storage code, while revealing no information about the desired function to the databases. We consider the problem of private linear computation (PLC) for coded databases. In PLC, a user wishes to compute a linear combination over the\nf\nmessages while keeping the coefficients of the desired linear combination hidden from the databases. For a DSS setup where data is stored using a code from a particular family of linear storage codes, we derive an outer bound on the PLC rate, which is defined as the ratio of the desired amount of information and the total amount of downloaded information. In particular, the proposed converse is valid for any number of messages and linear combinations, and depends on the rank of the coefficient matrix obtained from all linear combinations. Further, we present a PLC scheme with rate equal to the outer bound and hence settle the PLC capacity for the considered class of linear storage codes. Interestingly, the PLC capacity matches the maximum distance separable coded capacity of PIR for the considered class of linear storage codes.}
}


@article{DBLP:journals/jsac/BudkuleyJMY22,
	author = {Amitalok J. Budkuley and
                  Pranav Joshi and
                  Manideep Mamindlapally and
                  Anuj Kumar Yadav},
	title = {On Reverse Elastic Channels and the Asymmetry of Commitment Capacity
                  Under Channel Elasticity},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {862--870},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142304},
	doi = {10.1109/JSAC.2022.3142304},
	timestamp = {Sat, 30 Sep 2023 10:20:13 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/BudkuleyJMY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Commitment is an important cryptographic primitive. It is well known that noisy channels are a promising resource to realize commitment in an information-theoretically secure manner. However, oftentimes, channel behaviour may be poorly characterized thereby limiting the commitment throughput and/or degrading the security guarantees; a particularly problematic situation arises when a dishonest party, unbeknown to the honest one, maliciously alters the channel characteristics. Reverse elastic channels (RECs) are an interesting class of such unreliable channels where only a dishonest committer , say Alice, can maliciously alter the channel. RECs have attracted recent interest in the study of several cryptographic primitives. Our principal contribution is the REC commitment capacity characterization; this proves a recent related conjecture. A key result is our tight converse which analyses a specific cheating strategy by Alice. Along with elastic channels (ECs), where only a dishonest receiver Bob can alter the channel, RECs are also closely related to the classic unfair noisy channels (UNCs). In stark contrast to UNCs, both RECs and ECs always exhibit positive commitment throughput for all non-trivial channel parameters. Interestingly, our results show that channels with exclusive one-sided elasticity for dishonest parties, exhibit a fundamental asymmetry where, a committer with one-sided elasticity has a significantly more debilitating effect on the commitment throughput than a similarly capable receiver.}
}


@article{DBLP:journals/jsac/LiMHG22,
	author = {Jie Li and
                  Okko Makkonen and
                  Camilla Hollanti and
                  Oliver W. Gnilke},
	title = {Efficient Recovery of a Shared Secret via Cooperation: Applications
                  to {SDMM} and {PIR}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {871--884},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142366},
	doi = {10.1109/JSAC.2022.3142366},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiMHG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work considers the problem of privately outsourcing the computation of a matrix product over a finite field {\\mathbb {F}}_{q}\nto N\nhelper servers. These servers are considered to be honest but curious, i.e. , they behave according to the protocol but will try to deduce information about the user’s data. Furthermore, any set of up to X\nservers is allowed to share their data. Previous works considered this collusion a hindrance and the download cost of the schemes increases with growing X\n. We propose to utilize such linkage between servers to the user’s advantage by allowing servers to cooperate in the computational task. This leads to a significant gain in the download cost for the proposed schemes. The gain naturally comes at the cost of increased communication load between the servers. Hence, the proposed cooperative schemes can be understood as outsourcing both computational cost and communication cost. Both information–theoretically secure and computationally secure schemes are considered, showing that allowing information leakage that is computationally hard to utilize will lead to further gains. The proposed server cooperation is then exemplified for specific secure distributed matrix multiplication (SDMM) schemes and linear private information retrieval (PIR). Similar ideas naturally apply to many other use cases as well, but not necessarily always with lowered costs.}
}


@article{DBLP:journals/jsac/AllaixSHPHH22,
	author = {Matteo Allaix and
                  Seunghoan Song and
                  Lukas Holzbaur and
                  Tefjol Pllaha and
                  Masahito Hayashi and
                  Camilla Hollanti},
	title = {On the Capacity of Quantum Private Information Retrieval From MDS-Coded
                  and Colluding Servers},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {885--898},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142363},
	doi = {10.1109/JSAC.2022.3142363},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/AllaixSHPHH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In quantum private information retrieval (QPIR), a user retrieves a classical file from multiple servers by downloading quantum systems without revealing the identity of the file. The QPIR capacity is the maximal achievable ratio of the retrieved file size to the total download size. In this paper, the capacity of QPIR from MDS-coded and colluding servers is studied for the first time. Two general classes of QPIR, called stabilizer QPIR and dimension-squared QPIR induced from classical strongly linear PIR are defined, and the related QPIR capacities are derived. For the non-colluding case, the general QPIR capacity is derived when the number of files goes to infinity. A general statement on the converse bound for QPIR with coded and colluding servers is derived showing that the capacities of stabilizer QPIR and dimension-squared QPIR induced from any class of PIR are upper bounded by twice the classical capacity of the respective PIR class. The proposed capacity-achieving scheme combines the star-product scheme by Freij-Hollanti et al. and the stabilizer QPIR scheme by Song et al. by employing (weakly) self-dual Reed–Solomon codes.}
}


@article{DBLP:journals/jsac/HeidarzadehES22,
	author = {Anoosheh Heidarzadeh and
                  Nahid Esmati and
                  Alex Sprintson},
	title = {Single-Server Private Linear Transformation: The Joint Privacy Case},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {899--911},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142293},
	doi = {10.1109/JSAC.2022.3142293},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HeidarzadehES22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces the problem of Private Linear Transformation (PLT) which generalizes the problems of private information retrieval and private linear computation. The PLT problem includes one or more remote server(s) storing (identical copies of)\nK\nmessages and a user who wants to compute\nL\nindependent linear combinations of a\nD\n-subset of messages. The objective of the user is to perform the computation by downloading minimum possible amount of information from the server(s), while protecting the identities of the\nD\nmessages required for the computation. In this work, we focus on the single-server setting of the PLT problem when the identities of the\nD\nmessages required for the computation must be protected jointly. We consider two different models, depending on whether the coefficient matrix of the required\nL\nlinear combinations generates a Maximum Distance Separable (MDS) code. We prove that the capacity for both models is given by\nL/(K−D+L)\n, where the capacity is defined as the supremum of all achievable download rates. Our converse proofs are based on linear-algebraic and information-theoretic arguments. For each model, we also present an achievability scheme that relies on MDS codes.}
}


@article{DBLP:journals/jsac/WanSJC22,
	author = {Kai Wan and
                  Hua Sun and
                  Mingyue Ji and
                  Giuseppe Caire},
	title = {On Secure Distributed Linearly Separable Computation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {912--926},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142373},
	doi = {10.1109/JSAC.2022.3142373},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WanSJC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed linearly separable computation, where a user asks some distributed servers to compute a linearly separable function, was recently formulated by the same authors and aims to alleviate the bottlenecks of stragglers and communication cost in distributed computation. The data center assigns a subset of input datasets to each server in an uncoded manner, and each server computes some coded packets on the assigned datasets, which are then sent to the user. The user should recover the task function from the answers of a subset of servers, such that the effect of stragglers could be tolerated. In this paper, we formulate a novel secure framework for this distributed linearly separable computation, where we aim to let the user only retrieve the desired task function without obtaining any other information about the input datasets, even if it receives the answers of all servers. In order to preserve the security of the input datasets, some common randomness variable independent of the datasets should be introduced into the transmission. We show that any non-secure linear-coding based computing scheme for the original distributed linearly separable computation problem, can be made secure without increasing the communication cost (number of symbols the user should receive). Then we focus on the case where the computation cost of each server (number of datasets assigned to each server) is minimum and aim to minimize the size of the randomness variable (i.e., randomness size) introduced in the system while achieving the optimal communication cost. We first propose an information theoretic converse bound on the randomness size. We then propose secure computing schemes based on two well-known data assignments, namely fractional repetition assignment and cyclic assignment . These schemes are optimal subject to using these assignments. Motivated by the observation of the general limitation of these two schemes on the randomness size, we propose a computing scheme with novel assignment, which strictly outperforms the above two schemes. Some additional optimality results are also obtained.}
}


@article{DBLP:journals/jsac/YeR22,
	author = {Fangwei Ye and
                  Salim El Rouayheb},
	title = {Intermittent Private Information Retrieval With Application to Location
                  Privacy},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {927--939},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142301},
	doi = {10.1109/JSAC.2022.3142301},
	timestamp = {Tue, 15 Mar 2022 10:21:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/YeR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of intermittent private information retrieval with multiple servers, in which a user consecutively requests one of K\nmessages from N\nreplicated databases such that part of requests need to be protected while others do not need privacy. Motivated by the location privacy application, the correlation between requests is modeled by a Markov chain. We propose an intermittent private information retrieval scheme that concatenates an obfuscation scheme and a private information retrieval scheme for the time period when privacy is not needed, to prevent leakage incurred by the correlation over time. In the end, we illustrate how the proposed scheme for the problem of intermittent private information retrieval with Markov structure correlation can be applied to design a location privacy protection mechanism in the location privacy problem.}
}


@article{DBLP:journals/jsac/ShariatnasabSE22,
	author = {Mahshad Shariatnasab and
                  Farhad Shirani and
                  Elza Erkip},
	title = {Fundamental Privacy Limits in Bipartite Networks Under Active Attacks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {940--954},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142299},
	doi = {10.1109/JSAC.2022.3142299},
	timestamp = {Tue, 15 Mar 2022 10:21:37 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ShariatnasabSE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work considers active deanonymization of bipartite networks. The scenario arises naturally in evaluating privacy in various applications such as social networks, mobility networks, and medical databases. For instance, in active deanonymization of social networks, an anonymous victim is targeted by an attacker (e.g. the victim visits the attacker’s website), and the attacker queries her group memberships (e.g. by querying the browser history) to deanonymize her. In this work, the fundamental limits of privacy, in terms of the minimum number of queries necessary for deanonymization, is investigated. A stochastic model is considered, where 1) the bipartite network of group memberships is generated randomly; 2) the attacker has partial prior knowledge of the group memberships; and 3) it receives noisy responses to its real-time queries. The bipartite network is generated based on linear and sublinear preferential attachment, and the stochastic block model. The victim’s identity is chosen randomly based on a distribution modeling the users’ risk of being the victim (e.g. probability of visiting the website). An attack algorithm is proposed which builds upon techniques from communication with feedback, and its performance, in terms of expected number of queries, is analyzed. Simulation results are provided to verify the theoretical derivations.}
}


@article{DBLP:journals/jsac/HasirciogluGG22,
	author = {Burak Hasircioglu and
                  Jes{\'{u}}s G{\'{o}}mez{-}Vilardeb{\'{o}} and
                  Deniz G{\"{u}}nd{\"{u}}z},
	title = {Bivariate Polynomial Codes for Secure Distributed Matrix Multiplication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {955--967},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142355},
	doi = {10.1109/JSAC.2022.3142355},
	timestamp = {Mon, 28 Aug 2023 21:38:10 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HasirciogluGG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the problem of secure distributed matrix multiplication (SDMM). Coded computation has been shown to be an effective solution in distributed matrix multiplication, both providing privacy against workers and boosting the computation speed by efficiently mitigating stragglers. In this work, we present a non-direct secure extension of the recently introduced bivariate polynomial codes. Bivariate polynomial codes have been shown to be able to further speed up distributed matrix multiplication by exploiting the partial work done by the stragglers rather than completely ignoring them while reducing the upload communication cost and/or the workers’ storage’s capacity needs. We show that, especially for upload communication or storage constrained settings, the proposed approach reduces the average computation time of SDMM compared to its competitors in the literature.}
}


@article{DBLP:journals/jsac/YanT22,
	author = {Qifa Yan and
                  Daniela Tuninetti},
	title = {Robust, Private and Secure Cache-Aided Scalar Linear Function Retrieval
                  From Coded Servers},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {968--981},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142360},
	doi = {10.1109/JSAC.2022.3142360},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YanT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work investigates a system where each user aims to retrieve a scalar linear function of the files of a library, which are Maximum Distance Separable coded and stored at multiple distributed servers. The system needs to guarantee robust decoding in the sense that each user must decode its demanded function with signals received from any subset of servers whose cardinality exceeds a threshold. In addition, (a) the content of the library must be kept secure from a wiretapper who obtains all the signals from the servers; (b) any subset of users together can not obtain any information about the demands of the remaining users; and (c) the users’ demands must be kept private against all the servers even if they collude. Achievable schemes are derived by modifying existing Placement Delivery Array (PDA) constructions, originally proposed for single-server single-file retrieval coded caching systems without any privacy or security or robustness constraints. It is shown that the PDAs describing the original Maddah-Ali and Niesen’s coded caching scheme result in a load-memory tradeoff that is optimal to within a constant multiplicative gap, except for the small memory regime when the number of file is smaller than the number of users. As by-products, improved order optimality results are derived for three less restrictive systems in all parameter regimes.}
}


@article{DBLP:journals/jsac/KurtYWM22,
	author = {Mehmet Necip Kurt and
                  Yasin Yilmaz and
                  Xiaodong Wang and
                  Pieter J. Mosterman},
	title = {Online Privacy-Preserving Data-Driven Network Anomaly Detection},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {982--998},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142302},
	doi = {10.1109/JSAC.2022.3142302},
	timestamp = {Mon, 28 Aug 2023 21:38:11 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KurtYWM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study online privacy-preserving anomaly detection in a setting in which the data are distributed over a network and locally sensitive to each node, and a probabilistic data model is unknown. We design and analyze a data-driven solution scheme where each node observes a high-dimensional data stream for which it computes a local outlierness score. This score is then perturbed, encrypted, and sent to a network operator. The network operator then decrypts an aggregate statistic over the network and performs online network anomaly detection via the proposed generalized cumulative sum (CUSUM) algorithm. We derive an asymptotic lower bound and an asymptotic approximation for the average false alarm period of the proposed algorithm. Additionally, we derive an asymptotic upper bound and asymptotic approximation for the average detection delay of the proposed algorithm under a certain anomaly. We show the analytical tradeoff between the anomaly detection performance and the differential privacy level, controlled via the local perturbation noise. Experiments illustrate that the proposed algorithm offers a good tradeoff between privacy and quick anomaly detection against the UDP flooding and spam attacks in a real Internet of Things (IoT) network.}
}


@article{DBLP:journals/jsac/SongH22,
	author = {Seunghoan Song and
                  Masahito Hayashi},
	title = {Equivalence of Non-Perfect Secret Sharing and Symmetric Private Information
                  Retrieval With General Access Structure},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {999--1012},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142375},
	doi = {10.1109/JSAC.2022.3142375},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/SongH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the equivalence between non-perfect secret sharing (NSS) and symmetric private information retrieval (SPIR) with arbitrary response and collusion patterns. NSS and SPIR are defined with an access structure, which corresponds to the authorized/forbidden sets for NSS and the response/collusion patterns for SPIR. We prove the equivalence between NSS and SPIR in the following two senses. 1) Given any SPIR protocol with an access structure, an NSS protocol is constructed with the same access structure and the same rate. 2) Given any linear NSS protocol with an access structure, a linear SPIR protocol is constructed with the same access structure and the same rate. We prove the first relation even if the SPIR protocol has imperfect correctness and secrecy. From the first relation, we derive an upper bound of the SPIR capacity for arbitrary response and collusion patterns. For the special case of\nn\n-server SPIR with\nr\nresponsive and\nt\ncolluding servers, this upper bound proves that the SPIR capacity is\n(r−t)/n\n. From the second relation, we prove that a SPIR protocol exists for any response and collusion patterns.}
}


@article{DBLP:journals/jsac/HongYL22,
	author = {Sangwoo Hong and
                  Heecheol Yang and
                  Jungwoo Lee},
	title = {Hierarchical Group Testing for Byzantine Attack Identification in
                  Distributed Matrix Multiplication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {3},
	pages = {1013--1029},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3142364},
	doi = {10.1109/JSAC.2022.3142364},
	timestamp = {Mon, 28 Aug 2023 21:38:10 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HongYL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Coded computing has proved its efficiency in handling a straggler issue in distributed computing framework. It uses error correcting codes to mitigate the effect of the stragglers. However, in a coded distributed computing framework, there may exist Byzantine workers who send the wrong computation results to a master in order to contaminate the overall computation output. Therefore, it is essential to identify Byzantine workers from their computation results in coded computing. In this paper, we consider Byzantine attack identification problem in coded computing for distributed matrix multiplication tasks. We propose a new coding scheme which facilitates the efficient Byzantine attack identification, namely locally testable codes. We also suggest a hierarchical group testing method for Byzantine attack identification. We claim the required number of tests for group testing in our scheme, and show that it requires smaller number of tests than the conventional group testing method for the existing coded computing schemes.}
}


@article{DBLP:journals/jsac/LiuZDSAHS22,
	author = {Yuanwei Liu and
                  Shuowen Zhang and
                  Zhiguo Ding and
                  Robert Schober and
                  Naofal Al{-}Dhahir and
                  Ekram Hossain and
                  Xuemin Shen},
	title = {Special Issue on Next Generation Multiple Access - Part {I}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1031--1036},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3139485},
	doi = {10.1109/JSAC.2021.3139485},
	timestamp = {Tue, 23 Aug 2022 09:19:57 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuZDSAHS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the long-term evolution (LTE) system is reaching maturity and the fifth-generation (5G) systems are being commercially deployed, researchers have turned their attention to the development of next-generation wireless networks. Compared to current wireless networks, on the one hand, next-generation wireless networks are expected to achieve significantly higher capacity, extremely low latency, ultra-high reliability, as well as massive and ubiquitous connectivity for supporting diverse disruptive applications (e.g., virtual reality (VR), augmented reality (AR), and industry 4.0). On the other hand, the evolution toward next-generation wireless networks requires a paradigm shift from the communication-oriented design to a multi-functional design, including communication, sensing, imaging, computing, and localization. Looking back at the history of wireless communication systems, multiple access (MA) techniques have been key enablers. From the first generation (1G) to the fifth generation (5G), orthogonal multiple access (OMA) schemes are mainly employed, where multiple users are allotted in orthogonal frequency/time/code resources, and the uplink transmission of the code code-division multiple-access (CDMA) uses non-orthogonal code resources. However, given the enormous challenges and diverse services of next-generation wireless networks, which significantly differ from that in current and previous wireless networks, existing MA schemes may not be applicable. As a result, a fundamental issue is the design of next-generation multiple access (NGMA) techniques. The key concept of NGMA is to enable a very large number of users/devices to be efficiently, flexibly, and intelligently connected with the network over the given wireless radio resources to not only satisfy stringent communication requirements but also realize heterogeneous functions. The investigation of NGMA is still in the infancy stage, and extensive research efforts have to be devoted to areas, including but not limited to 1) the development of new MA schemes, such as non-orthogonal multiple access (NOMA) and space division multiple access (SDMA), which are capable of achieving higher bandwidth efficiency and higher connectivity compared with conventional MA schemes; 2) the development of innovative techniques, such as reconfigurable metasurfaces, random access, advanced modulation, and channel coding, which are beneficial to the overall design of NGMA; and 3) the exploitation of advanced machine learning (ML) tools and big data techniques for providing effective solutions to address newly emerging NGMA problems.}
}


@article{DBLP:journals/jsac/LiuZMDSAHS22,
	author = {Yuanwei Liu and
                  Shuowen Zhang and
                  Xidong Mu and
                  Zhiguo Ding and
                  Robert Schober and
                  Naofal Al{-}Dhahir and
                  Ekram Hossain and
                  Xuemin Shen},
	title = {Evolution of {NOMA} Toward Next Generation Multiple Access {(NGMA)}
                  for 6G},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1037--1071},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3145234},
	doi = {10.1109/JSAC.2022.3145234},
	timestamp = {Tue, 23 Aug 2022 09:19:57 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuZMDSAHS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the explosive growth in the number of wireless devices and diverse wireless services, such as virtual/augmented reality and Internet-of-Everything, next generation wireless networks face unprecedented challenges caused by heterogeneous data traffic, massive connectivity, and ultra-high bandwidth efficiency and ultra-low latency requirements. To address these challenges, advanced multiple access schemes are expected to be developed, namely next generation multiple access (NGMA), which are capable of supporting massive numbers of users in a more resource- and complexity-efficient manner than existing multiple access schemes. As the research on NGMA is in a very early stage, in this paper, we explore the evolution of NGMA with a particular focus on non-orthogonal multiple access (NOMA), i.e., the transition from NOMA to NGMA. In particular, we first review the fundamental capacity limits of NOMA, elaborate on the new requirements for NGMA, and discuss several possible candidate techniques. Moreover, given the high compatibility and flexibility of NOMA, we provide an overview of current research efforts on multi-antenna techniques for NOMA, promising future application scenarios of NOMA, and the interplay between NOMA and other emerging physical layer techniques. Furthermore, we discuss advanced mathematical tools for facilitating the design of NOMA communication systems, including conventional optimization approaches and new machine learning techniques. Next, we propose a unified framework for NGMA based on multiple antennas and NOMA, where both downlink and uplink transmissions are considered, thus setting the foundation for this emerging research area. Finally, several practical implementation challenges for NGMA are highlighted as motivation for future work.}
}


@article{DBLP:journals/jsac/PeiCWYPP22,
	author = {Xinyue Pei and
                  Yingyang Chen and
                  Miaowen Wen and
                  Hua Yu and
                  Erdal Panayirci and
                  H. Vincent Poor},
	title = {Next-Generation Multiple Access Based on {NOMA} With Power Level Modulation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1072--1083},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143240},
	doi = {10.1109/JSAC.2022.3143240},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/PeiCWYPP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To cope with the explosive traffic growth expected in next-generation wireless networks, it is necessary to design next-generation multiple access techniques that can provide higher spectral efficiency as well as larger-scale connectivity. As a promising candidate, power-domain non-orthogonal multiple access (NOMA) has been widely studied. In conventional power-domain NOMA, multiple users are multiplexed in the same time and frequency band with different preset power levels, which, however, may limit the spectral efficiency under practical finite alphabet inputs. Inspired by the concept of spatial modulation, we propose to solve this problem by encoding extra information bits into the power levels, and exploiting different signal constellations to help the receiver distinguish between them. To convey this idea, termed power selection (PS)-NOMA, clearly, we consider a simple downlink two-user NOMA system with finite input constellations. Assuming maximum-likelihood detection, we derive closed-form approximate bit error rate (BER) expressions for both users. Moreover, the two-user achievable rate region is also characterized. Simulation results verify the analysis and show that the proposed PS-NOMA can outperform conventional NOMA in terms of BER and achievable rate.}
}


@article{DBLP:journals/jsac/WangWWY22,
	author = {Yuan Wang and
                  Jiaheng Wang and
                  Vincent W. S. Wong and
                  Xiaohu You},
	title = {Effective Throughput Maximization of {NOMA} With Practical Modulations},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1084--1100},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143244},
	doi = {10.1109/JSAC.2022.3143244},
	timestamp = {Fri, 30 Jun 2023 15:15:58 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangWWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non-orthogonal multiple access (NOMA) has been considered as a promising technology for future wireless communications. In most of the existing NOMA schemes, the ideal information rate based on Shannon capacity is used as the performance metric, assuming perfect successive interference cancellation (SIC) and Gaussian transmit signals without considering practical modulations. The implicit assumptions and the resulting schemes may lead to suboptimal performance in practical NOMA systems. In this paper, we consider multi-user multi-channel NOMA systems using practical quadrature amplitude modulation (QAM) with imperfect SIC. We aim to maximize a more practical performance metric, namely the effective throughput , which takes into account the data rate and error performance. To achieve this goal, we derive both the exact and approximate expressions of the effective throughput. We also formulate a joint resource optimization problem of the power allocation, channel assignment, and modulation selection to maximize the effective throughput. We develop an efficient power allocation solution by proposing a closed-form power allocation within channels and a waterfilling-form power budget allocation among channels. We also develop efficient channel assignment and modulation selection methods with the aid of matching theory and machine learning, respectively. Consequently, we provide an efficient joint resource allocation algorithm via iterative optimization to maximize the effective throughput. Numerical results are presented to verify the superiority of the proposed NOMA scheme over orthogonal multiple access (OMA) and other NOMA schemes.}
}


@article{DBLP:journals/jsac/WangJK22,
	author = {Jiawei Wang and
                  Chunxiao Jiang and
                  Linling Kuang},
	title = {Iterative {NOMA} Detection for Multiple Access in Satellite High-Mobility
                  Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1101--1113},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143254},
	doi = {10.1109/JSAC.2022.3143254},
	timestamp = {Mon, 26 Jun 2023 17:07:13 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangJK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non-orthogonal multiple access (NOMA) is a promising technology for next generation multiple access (NGMA). However, traditional NOMA detection methods cannot cope with challenges of NGMA in satellite high-mobility communications. On the one hand, due to the high mobility and heterogeneity of terminals in terms of the velocity and acceleration, time-varying Doppler shifts caused by high-mobility terminals are relatively higher and different for each user, which degrades the demodulation performance seriously and makes multi-user interference cancellation become the bottleneck. On the other hand, owning to wide distribution of high-mobility terminals, the arriving time of users’ signals is different at the receiver, which further incurs more difficulties for NOMA detection. To solve such a problem in satellite high-mobility communications, we propose a novel multi-user detection method based on the new three-dimensional (3D) factor graph for high-mobility environments, named the turbo iterative detection (TID) algorithm. Specially, the proposed algorithm consists of the interference cancellation loop, the Doppler elimination loop and the decoding loop. By means of message passing along edges in the proposed 3D factor graph, these three iterative loops can interact with each other to effectively eliminate time-varying Doppler shifts of heterogeneous high-mobility terminals and interference among multiple users. Simulation results show that the proposed algorithm improves the bit error ratio (BER) performance more than 0.9 dB with less computational complexity compared with traditional algorithms, which demonstrates the superiority of this algorithm in terms of the BER performance and computational complexity.}
}


@article{DBLP:journals/jsac/HanBZLCZ22,
	author = {Rui Han and
                  Lin Bai and
                  Weizheng Zhang and
                  Jianwei Liu and
                  Jinho Choi and
                  Wei Zhang},
	title = {Variational Inference Based Sparse Signal Detection for Next Generation
                  Multiple Access},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1114--1127},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143234},
	doi = {10.1109/JSAC.2022.3143234},
	timestamp = {Wed, 06 Jul 2022 10:42:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HanBZLCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The next generation multiple access (NGMA) schemes are considered to support massive access for a large number of devices, which motivates us to develop a low-complexity approach for next generation systems. Since the generalized spatial modulation (SM) can be adopted to the system, a number of compressive sensing (CS) reconstruction algorithms are deployed for the detection of sparse signals, while the complexity of CS-based approaches is proportional to the number of antennas. In order to decrease the complexity, we propose a two-stage approach to detect sparse signals, where the received signals are divided into groups. Then, the activity variables of aggregated signals are decided and the sparse signal detection is carried out at the signals belonging to active groups. During the activity variable detection, the variational inference algorithm is applied to determine the activity variables. Moreover, in order to analyze the performance of activity variable detection, the\nJ\n-divergence is proposed to measure the distance between the distributions, while the approximate expression of\nJ\n-divergence is derived. Simulation results show that the proposed approach is able to provide good detection performance with low complexity. In addition, the\nJ\n-divergence is confirmed to be useful as an evaluation metric to measure the detection performance.}
}


@article{DBLP:journals/jsac/LiWYYBNH22,
	author = {Shuangyang Li and
                  Zhiqiang Wei and
                  Weijie Yuan and
                  Jinhong Yuan and
                  Baoming Bai and
                  Derrick Wing Kwan Ng and
                  Lajos Hanzo},
	title = {Faster-Than-Nyquist Asynchronous {NOMA} Outperforms Synchronous {NOMA}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1128--1145},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143245},
	doi = {10.1109/JSAC.2022.3143245},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiWYYBNH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Faster-than-Nyquist (FTN) signaling aided non-orthogonal multiple access (NOMA) is conceived and its achievable rate is quantified in the presence of random link delays of the different users. We reveal that exploiting the link delays may potentially lead to a signal-to-interference-plus-noise ratio (SINR) gain, while transmitting the data symbols at FTN rates has the potential of increasing the degree-of-freedom (DoF). We then unveil the fundamental trade-off between the SINR and DoF. In particular, at a sufficiently high symbol rate, the SINR gain vanishes while the DoF gain achieves its maximum, where the achievable rate is almost (1+\\beta)\ntimes higher than that of the conventional synchronous NOMA transmission in the high signal-to-noise ratio (SNR) regime, with \\beta\nbeing the roll-off factor of the signaling pulse. Our simulation results verify our analysis and demonstrate considerable rate improvements over the conventional power-domain NOMA scheme.}
}


@article{DBLP:journals/jsac/CheZYCZN22,
	author = {Jingze Che and
                  Zhaoyang Zhang and
                  Zhaohui Yang and
                  Xiaoming Chen and
                  Caijun Zhong and
                  Derrick Wing Kwan Ng},
	title = {Unsourced Random Massive Access With Beam-Space Tree Decoding},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1146--1161},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143241},
	doi = {10.1109/JSAC.2022.3143241},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/CheZYCZN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The core requirement of massive Machine-Type Communication (mMTC) is to support reliable and fast access for an enormous number of machine-type devices (MTDs). In many practical applications, the base station (BS) only concerns the list of received messages instead of the source information, introducing the emerging concept of unsourced random access (URA). Although some massive multiple-input multiple-output (MIMO) URA schemes have been proposed recently, the unique propagation properties of millimeter-wave (mmWave) massive MIMO systems are not fully exploited in conventional URA schemes. In grant-free random access, the BS cannot perform receive beamforming independently as the identities of active users are unknown to the BS. Therefore, only the intrinsic beam division property can be exploited to improve the decoding performance. In this paper, a URA scheme based on beam-space tree decoding is proposed for mmWave massive MIMO system. Specifically, two beam-space tree decoders are designed based on hard decision and soft decision, respectively, to utilize the beam division property. They both leverage the beam division property to assist in discriminating the sub-blocks transmitted from different users. Besides, the first decoder can reduce the searching space, enjoying a low complexity. The second decoder exploits the advantage of list decoding to recover the miss-detected packets. Simulation results verify the superiority of the proposed URA schemes compared to the conventional URA schemes in terms of error probability.}
}


@article{DBLP:journals/jsac/RezvaniJJY22,
	author = {Sepehr Rezvani and
                  Eduard A. Jorswieck and
                  Roghayeh Joda and
                  Halim Yanikomeroglu},
	title = {Optimal Power Allocation in Downlink Multicarrier {NOMA} Systems:
                  Theory and Fast Algorithms},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1162--1189},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143237},
	doi = {10.1109/JSAC.2022.3143237},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/RezvaniJJY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we propose globally optimal power allocation strategies to maximize the users sum-rate (SR), and system energy efficiency (EE) in the downlink of single-cell multicarrier non-orthogonal multiple access (MC-NOMA) systems. Each NOMA cluster includes a set of users in which the well-known superposition coding (SC) combined with successive interference cancellation (SIC) technique is applied among them. By obtaining the closed-form expression of intra-cluster power allocation, we show that MC-NOMA can be equivalently transformed to a virtual orthogonal multiple access (OMA) system, where the effective channel gain of these virtual OMA users is obtained in closed-form. Then, the SR and EE maximization problems are solved by using very fast water-filling and Dinkelbach algorithms, respectively. The equivalent transformation of MC-NOMA to the virtual OMA system brings new theoretical insights, which are discussed throughout the paper. The extensions of our analyses to other scenarios, such as considering users rate fairness, admission control, long-term performance, and a number of future next-generation multiple access (NGMA) schemes enabling recent advanced technologies, e.g., reconfigurable intelligent surfaces are discussed. Extensive numerical results are provided to demonstrate the performance gaps among single-carrier NOMA (SC-NOMA), OMA-NOMA, and OMA.}
}


@article{DBLP:journals/jsac/ZhuHK22,
	author = {Yazhou Zhu and
                  Christian A. Hofmann and
                  Andreas Knopp},
	title = {Distributed Resource Optimization for {NOMA} Transmission in Beamforming
                  {SATCOM}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1190--1209},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143215},
	doi = {10.1109/JSAC.2022.3143215},
	timestamp = {Fri, 01 Apr 2022 11:24:49 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhuHK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work studies the application of nonorthogonal transmission in beamforming (BF) based forward links for next-generation satellite communication (SATCOM) with multiple gateways. With the aim of enhancing the throughput of BF SATCOM systems, the state-of-the-art nonorthogonal multiple access (NOMA) technique is exploited by serving multiple users per beam in the same time slot. In this regard, the feeder link limitations and multibeam satellite payload constraints must be considered for BF design and power allocation (PA) optimization in nonorthogonal SATCOM. To address these challenges, distributed resource optimization strategies are investigated for BF and flexible payload power resource allocation in multigateway (multi-GW) nonorthogonal SATCOM systems. Specifically, a per-feed available power-constrained BF strategy via maximization of the worst-user signal-to-leakage-and-noise ratio (SLNR) is explored with local channel state information (CSI) for a distributed operation of GWs. As an upper-bound performance limit, a centralized multilayer BF strategy is processed in a central unit with full global CSI and data sharing. After the BF direction optimization, a weighted sum-rate maximization-based (WSRM-based) power resource optimization strategy is locally applied at each GW to efficiently use the power resources for higher performance increment. The nonconvex WSRM problem, under the constraints of the practical satellite payload power budget, successful successive interference cancellation (SIC) decoding, and minimum data rate, is recast into an equivalent weighted sum-MSE minimization (WMMSE) counterpart for a tractable solution. Finally, an efficient user scheduling is designed to enable the operator to capture a substantial system-throughput gain. Accurate simulations are conducted with the near-to-real coverage area (footprints), the random distributions of users, and interference, relying on geographical locations of users. The results over a realistic simulation environment show the efficiency of our strategies.}
}


@article{DBLP:journals/jsac/ZhangZZLK22,
	author = {Yaomin Zhang and
                  Haijun Zhang and
                  Huan Zhou and
                  Keping Long and
                  George K. Karagiannidis},
	title = {Resource Allocation in Terrestrial-Satellite-Based Next Generation
                  Multiple Access Networks With Interference Cooperation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1210--1221},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3145810},
	doi = {10.1109/JSAC.2022.3145810},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZZLK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, an uplink non-orthogonal multiple access (NOMA) terrestrial-satellite network is investigated, where the terrestrial base stations (BSs) communicate with satellite by backhaul link, and user equipments (UEs) share spectrum resource of access link. Firstly, a utility function which consists of the achieved terrestrial user rate and cross-tier interference caused by terrestrial BSs to satellite is design. Thus, the optimization problem can be modeled by maximizing the system utility function while satisfying the varying backhaul rate and UEs’ quality of service (QoS) constraints. The optimization problem is highly non-convex and can not be solved directly. Thus, we decouple the original problem into user association sub-problem, bandwidth assignment sub-problem, and power allocation sub-problem. In user association sub-problem, an enhanced-caching, preference relation, and swapping based algorithm is proposed, where the satellite UEs are selected by the channel coefficient ratio. The terrestrial UEs association considers the both caching state and backhaul link. Then we derive the closed-form expression of the bandwidth assignment. In power allocation sub-problem, we convert the non-convex term of the target function into the convex one by the Taylor expansion, and solve the transformed convex problem by an iterative power allocation algorithm. Finally, a three-stages iterative resource allocation algorithm by joint considering the three sub-problems is proposed. Simulation results are discussed to show the effectiveness of the proposed algorithms.}
}


@article{DBLP:journals/jsac/LiuDENK22,
	author = {Yan Liu and
                  Yansha Deng and
                  Maged Elkashlan and
                  Arumugam Nallanathan and
                  George K. Karagiannidis},
	title = {Optimization of Grant-Free {NOMA} With Multiple Configured-Grants
                  for mURLLC},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1222--1236},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143264},
	doi = {10.1109/JSAC.2022.3143264},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuDENK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Massive Ultra-Reliable and Low-Latency Communications (mURLLC), which integrates URLLC with massive access, is emerging as a new and important service class in the next generation (6G) for time-sensitive traffics and has recently received tremendous research attention. However, realizing efficient, delay-bounded, and reliable communications for a massive number of user equipments (UEs) in mURLLC, is extremely challenging as it needs to simultaneously take into account the latency, reliability, and massive access requirements. To support these requirements, the third generation partnership project (3GPP) has introduced enhanced grant-free (GF) transmission in the uplink (UL), with multiple active configured-grants (CGs) for URLLC UEs. With multiple CGs (MCG) for UL, UE can choose any of these grants as soon as the data arrives. In addition, non-orthogonal multiple access (NOMA) has been proposed to synergize with GF transmission to mitigate the serious transmission delay and network congestion problems. In this paper, we develop a novel learning framework for MCG-GF-NOMA systems with bursty traffic. We first design the MCG-GF-NOMA model by characterizing each CG using the parameters: the number of contention-transmission units (CTUs), the starting slot of each CG within a subframe, and the number of repetitions of each CG. Based on the model, the latency and reliability performances are characterized. We then formulate the MCG-GF-NOMA resources configuration problem taking into account three constraints. Finally, we propose a Cooperative Multi-Agent based Double Deep Q-Network (CMA-DDQN) algorithm to balance the allocations of the channel resources among MCGs so as to maximize the number of successful transmissions under the latency constraint. Our results show that the MCG-GF-NOMA framework can simultaneously improve the low latency and high reliability performances in massive URLLC.}
}


@article{DBLP:journals/jsac/MeiHWP22,
	author = {Jie Mei and
                  Wudan Han and
                  Xianbin Wang and
                  H. Vincent Poor},
	title = {Multi-Dimensional Multiple Access With Resource Utilization Cost Awareness
                  for Individualized Service Provisioning in 6G},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1237--1252},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3145909},
	doi = {10.1109/JSAC.2022.3145909},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/MeiHWP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasingly diversified Quality-of-Service (QoS) requirements envisioned for future wireless networks call for more flexible and inclusive multiple access techniques in 6G for supporting emerging applications and communication scenarios. To achieve this, we propose a multi-dimensional multiple access (MDMA) protocol to meet individual User Equipment’s (UE’s) unique QoS demands while utilizing multi-dimensional radio resources cost-effectively. In detail, the proposed scheme consists of two novel aspects, i.e., selection of a tailored multiple access mode for each UE while considering the UE-specific radio resource utilization cost caused by non-orthogonal interference cancellation; and multi-dimensional radio resource allocation among coexisting UEs under dynamic network conditions. To reduce the UE-specific resource utilization cost, the base station (BS) organizes UEs with disparate multi-domain resource constraints as UE coalition by considering each UE’s specific resource availability, perceived quality, and utilization capability. Each UE within a coalition could utilize its preferred radio resources, which leads to low utilization cost while avoiding resource-sharing conflicts with remaining UEs. Furthermore, to meet UE-specific QoS requirements and varying resource conditions at the UE side, the multi-dimensional radio resource allocation among coexisting UEs is formulated as an optimization problem to maximize the summation of cost-aware utility functions of all UEs. A solution to solve this NP-hard problem with low complexity is developed using the successive convex approximation and the Lagrange dual decomposition methods. The effectiveness of our proposed scheme is validated by numerical simulation and performance comparison with state-of-the-art schemes. In particular, the simulation results demonstrate that our proposed scheme outperforms these benchmark schemes by large margins.}
}


@article{DBLP:journals/jsac/CaoYHAYHPH22,
	author = {Xuelin Cao and
                  Bo Yang and
                  Chongwen Huang and
                  George C. Alexandropoulos and
                  Chau Yuen and
                  Zhu Han and
                  H. Vincent Poor and
                  Lajos Hanzo},
	title = {Massive Access of Static and Mobile Users via Reconfigurable Intelligent
                  Surfaces: Protocol Design and Performance Analysis},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1253--1269},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3145908},
	doi = {10.1109/JSAC.2022.3145908},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/CaoYHAYHPH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The envisioned wireless networks of the future entail the provisioning of massive numbers of connections, heterogeneous data traffic, ultra-high spectral efficiency, and low latency services. This vision is spurring research activities focused on defining a next generation multiple access (NGMA) protocol that can accommodate massive numbers of users in different resource blocks, thereby, achieving higher spectral efficiency and increased connectivity compared to conventional multiple access schemes. In this article, we present a multiple access scheme for NGMA in wireless communication systems assisted by multiple reconfigurable intelligent surfaces (RISs). In this regard, considering the practical scenario of static users operating together with mobile ones, we first study the interplay of the design of NGMA schemes and RIS phase configuration in terms of efficiency and complexity. Based on this, we then propose a multiple access framework for RIS-assisted communication systems, and we also design a medium access control (MAC) protocol incorporating RISs. In addition, we give a detailed performance analysis of the designed RIS-assisted MAC protocol. Our extensive simulation results demonstrate that the proposed MAC design outperforms the benchmarks in terms of system throughput and access fairness, and also reveal a trade-off relationship between the system throughput and fairness.}
}


@article{DBLP:journals/jsac/ElhattabAAG22,
	author = {Mohamed Kadry Elhattab and
                  Mohamed Amine Arfaoui and
                  Chadi Assi and
                  Ali Ghrayeb},
	title = {RIS-Assisted Joint Transmission in a Two-Cell Downlink {NOMA} Cellular
                  System},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1270--1286},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143211},
	doi = {10.1109/JSAC.2022.3143211},
	timestamp = {Fri, 01 Apr 2022 11:24:49 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ElhattabAAG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the integration of reconfigurable intelligent surface (RIS) with downlink non-orthogonal-multiple-access (NOMA) in a multi-user two-cell network assisted by the joint-transmission coordinated multipoint (JT-CoMP). Specifically, the RIS is deployed at the edge of two adjacent cells to assist the JT-CoMP from these two cells to multiple far NOMA users located at their edges. Under this setup, we jointly optimize the power allocation (PA) coefficients at the base stations (BSs), the user clustering (UC) policy, and the phase-shift (PS) matrix of the RIS with the objective of maximizing the network sum-rate subject to a target quality-of-service, defined in terms of the minimum required data rate at each cellular user, and the successive interference cancellation (SIC) constraints. The formulated problem ends to be a non-convex mixed-integer non-linear program that is difficult to be solved in a straightforward manner. To alleviate this issue, and with the aid of alternating optimization (AO), the original optimization problem is decomposed into two sub-problems, a joint PA and UC sub-problem and a PS sub-problem, that are solved in an alternating way. For the first sub-problem, we invoke the bi-level optimization approach to decouple the PA sub-problem from the UC sub-problem. For the PA sub-problem, closed-form expressions for the optimal PA coefficients are derived. On the other hand, the UC problem is projected to multiple 2-dimensional assignment problems, each of which is solved using the Hungarian method. Finally, the PS sub-problem is formulated as a difference-of-convex problem and an efficient solution is obtained using the successive convex approximation technique. The numerical results reveal that the network sum-rate of the proposed RIS-assisted CoMP NOMA networks outperforms the conventional CoMP NOMA scheme without the assistance of the RIS, the RIS-assisted CoMP orthogonal multiple access (OMA) scheme, and RIS-assisted NOMA scheme, especially for low transmit power from the BSs.}
}


@article{DBLP:journals/jsac/ZhaoYCZH22,
	author = {Jingjing Zhao and
                  Lanchenhui Yu and
                  Kaiquan Cai and
                  Yanbo Zhu and
                  Zhu Han},
	title = {RIS-Aided Ground-Aerial {NOMA} Communications: {A} Distributionally
                  Robust {DRL} Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1287--1301},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143230},
	doi = {10.1109/JSAC.2022.3143230},
	timestamp = {Fri, 01 Apr 2022 11:24:49 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhaoYCZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A reconfigurable intelligent surface (RIS) aided air-to-ground uplink non-orthogonal transmission framework is investigated for next generation multiple access. Occupying the same spectrum resource, unmanned aerial vehicle (UAV) users and ground users (GUs) are connected to terrestrial cellular networks via the uplink non-orthogonal multiple access (NOMA) protocol. As the flight safety is important for employing UAVs in civil airspace, the collision avoidance mechanism has to be considered during the flight. Therefore, a joint optimization problem of the UAV trajectory design, RIS configuration, and uploading power control is formulated for maximizing the network sum rate, while ensuring the UAV’s fight safety and satisfying the minimum data rate requirements of both the UAV and GU. The resultant problem is a sequential decision making one across multiple coherent time slots. Besides, the unknown locations of obstacles bring uncertainties into the decision making process. To tackle this challenging problem, a sample-efficient deep reinforcement learning (DRL) algorithm is proposed to optimize the UAV trajectory, RIS configuration, and power control simultaneously. Moreover, considering the ambiguous uncertainties in the environment, a distributionally robust DRL algorithm is further proposed to provide the worst-case performance guarantee. Numerical results demonstrate that the two proposed DRL algorithms outperform the conventional ones in terms of learning efficiency and robustness. It is also shown that the network sum rate is significantly improved by the proposed RIS-NOMA scheme compared to the conventional RIS-orthogonal multiple access (OMA) scheme and the case where no RIS is deployed.}
}


@article{DBLP:journals/jsac/ChenGJSW22,
	author = {Jian Chen and
                  Liang Guo and
                  Jie Jia and
                  Jianhui Shang and
                  Xingwei Wang},
	title = {Resource Allocation for {IRS} Assisted {SGF} {NOMA} Transmission:
                  {A} {MADRL} Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1302--1316},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3144726},
	doi = {10.1109/JSAC.2022.3144726},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenGJSW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non-orthogonal multiple access (NOMA) assisted semi-grant-free (SGF) transmission has been viewed as one of the promising technologies to meet massive connectivity requirements of the next-generation networks. A novel intelligent reconfigurable surface (IRS) assisted SGF NOMA transmission system is proposed, where the IRS is employed to satisfy the channel gain requirements for grant-based users (GBUs) and grant-free users (GFUs). The dynamic optimization on the sub-carrier assignment and power allocation for roaming GFUs, and the amplitude control and phase shift design for reflecting elements of the IRS, is formulated. Aiming at maximizing the long-term data rate of all GFUs, the optimization problem is first modeled as a multi-agent Markov decision problem. Then, three multi-agent deep reinforcement learning based frameworks are proposed to solve the problem under three different IRS cases, including the ideal IRS, non-ideal IRS with continuous phase shifts, and non-ideal IRS with discrete phase shifts. Specifically, for each GFU agent, a sub-carrier assignment deep Q-network (DQN) and a power allocation deep deterministic policy gradient (DDPG) are integrated to dynamically assign network resources for each GFU. For the only IRS agent, two DDPGs are integrated to dynamically assign phase shift and amplitude for each reflecting element of ideal IRS. The single DDPG for dynamically assigning continuous phase shifts, and parallel DQNs for dynamically assigning discrete phase shifts for non-ideal IRS with fixed amplitude are also proposed. Simulation results demonstrate that: 1) The network sum rates of all GFUs can achieve a significant improvement with the aid of IRS, comparing with the system without IRS. 2) The network sum rates of the NOMA assisted SGF transmissions are superior to that of OMA assisted GF transmissions.}
}


@article{DBLP:journals/jsac/DengDZS22,
	author = {Ruoqi Deng and
                  Boya Di and
                  Hongliang Zhang and
                  Lingyang Song},
	title = {{HDMA:} Holographic-Pattern Division Multiple Access},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1317--1332},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143221},
	doi = {10.1109/JSAC.2022.3143221},
	timestamp = {Mon, 12 Feb 2024 16:07:18 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/DengDZS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The next generation wireless communications aiming at enhancing capacity and massive connectivity significantly over high-frequency bands urge the development of novel multiple access technologies. In this paper, we propose a new type of space-division multiple access (SDMA), called holographic-pattern division multiple access (HDMA). We develop the principle for HDMA with the main idea of mapping the intended signals for receivers to a superposed holographic pattern. The multi-user holographic beamforming scheme for HDMA is then presented. Based on the theoretical analysis, we find that there exists an optimal holographic pattern such that the sum rate with simple zero-forcing precoding can achieve the asymptotic capacity of the HDMA system. Simulation results verify the theoretical analysis and show that the HDMA scheme outperforms the traditional SDMA scheme in terms of both the cost-efficiency and the sum rate.}
}


@article{DBLP:journals/jsac/YinCNML22,
	author = {Lu Yin and
                  Jiameng Cao and
                  Qiang Ni and
                  Yuzheng Ma and
                  Song Li},
	title = {Design and Performance Analysis of Multi-Scale {NOMA} for Future Communication-Positioning
                  Integration System},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1333--1345},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143223},
	doi = {10.1109/JSAC.2022.3143223},
	timestamp = {Tue, 12 Apr 2022 15:00:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YinCNML22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a feasibility study of a novel multiple access technique called Multi-Scale Non-Orthogonal Multiple Access (MS-NOMA) for the next generation communication-positioning integration system. Different from the traditional positioning signals which are mostly Time Division Multiple Access with communication signals and are broadcast to all users, MS-NOMA supports continuous positioning waveform and flexible configurations for different positioning users to obtain higher ranging accuracy, lower positioning latency, less resource consumption and better signal coverage. Our major contributions are: Firstly, we present the MS-NOMA waveform and evaluate its performances by theoretical and simulation analyses. The results show it is feasible to use the MS-NOMA waveform to achieve high positioning accuracy and low Bit Error Rate with little resource consumption simultaneously. Secondly, to achieve optimal positioning accuracy and signal coverage, we model the power allocation problem for MS-NOMA as a convex optimization problem satisfying the Quality of Services requirement and other constraints. Then, we propose a novel Communication and Positioning Performances constrained Positioning Power Allocation (CP4A) algorithm which allocates the power of all P-Users iteratively. The theoretical and numerical results show our proposed MS-NOMA waveform with CP4A algorithm has great improvements of ranging/positioning accuracy than traditional Positioning Reference Signal in cellular network.}
}


@article{DBLP:journals/jsac/KhorovKLA22,
	author = {Evgeny M. Khorov and
                  Alexey Kureev and
                  Ilya Levitsky and
                  Ian F. Akyildiz},
	title = {A Phase Noise Resistant Constellation Rotation Method and Its Experimental
                  Validation for {NOMA} Wi-Fi},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1346--1354},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143236},
	doi = {10.1109/JSAC.2022.3143236},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KhorovKLA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non-orthogonal multiple access (NOMA) is a well-accepted technology for future Wi-Fi systems to improve spectral efficiency. NOMA allows an access point (AP) to simultaneously serve multiple devices by splitting the transmit power between them. Using the superposition coding the AP combines signals of different frames with predefined power weights. However, as it is already known, the phase noise caused by hardware imperfections limits the performance of NOMA transmissions. The paper proposes a practical, easy-to-implement, and backward-compatible method to rotate the constellation of the low power signal in order to make it more robust to the phase noise. A mathematical model is developed to find such a rotation angle that minimizes the bit error rate (BER) of the low power frame. A new NOMA Wi-Fi prototype testbed is developed with the new feature of constellation rotation ability, which is used to validate the performance of our proposed method. Many experimental results show the proposed constellation rotation approach significantly decreases the BER in high signal-to-noise scenarios.}
}


@article{DBLP:journals/jsac/XuTLZNW22,
	author = {Yao Xu and
                  Jie Tang and
                  Bo Li and
                  Nan Zhao and
                  Dusit Niyato and
                  Kai{-}Kit Wong},
	title = {Adaptive Aggregate Transmission for Device-to-Multi-Device Aided Cooperative
                  {NOMA} Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1355--1370},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143267},
	doi = {10.1109/JSAC.2022.3143267},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XuTLZNW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The integration of device-to-device (D2D) communications with cooperative non-orthogonal multiple access (NOMA) can achieve superior spectral efficiency. However, the mutual interference caused by D2D communications may prevent NOMA from diverging its high spectral efficiency advantage. Meanwhile, the low adaptability of the fixed transmission strategy can decrease the reliability of the cell-edge user (CEU). To further improve the spectral efficiency, we investigate a device-to-multi-device (D2MD) assisted cooperative NOMA system, where two cell-center users (CCUs) and one CEU are paired as a D2MD cluster. Specifically, the base station directly serves the two CCUs while communicating with the CEU via one CCU. Moreover, we propose an adaptive aggregate transmission scheme using dynamic superposition coding, pre-designing the decoding orders and prior information cancellation for the D2MD assisted cooperative NOMA system to enhance the reliability of the CEU. We provide the closed-form expressions for the outage probability, diversity order, outage throughput, ergodic sum capacity, average spectral efficiency, and spectral efficiency scaling over Nakagami-\nm\nfading channels under perfect and imperfect successive interference cancellation. The numerical results validate the correctness of the analytical derivations and the effectiveness of the proposed scheme.}
}


@article{DBLP:journals/jsac/XieZCT22,
	author = {Ning Xie and
                  Qihong Zhang and
                  Junjie Chen and
                  Hai{-}Jun Tan},
	title = {Privacy-Preserving Physical-Layer Authentication for Non-Orthogonal
                  Multiple Access Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {4},
	pages = {1371--1385},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143222},
	doi = {10.1109/JSAC.2022.3143222},
	timestamp = {Fri, 01 Apr 2022 11:24:50 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XieZCT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper addresses the problems of both authentication and privacy in a Non-Orthogonal Multiple Access (NOMA) system by using a privacy-preserving Physical-Layer Authentication (PLA) scheme. The prior scheme has the following limitations: no privacy, low authentication performance, management problem of different secret keys, and constraint to the two-user scenario. In this paper, we propose two privacy-preserving PLA schemes: the Privacy-Preserving PLA (PP-PLA) scheme and the Enhanced Privacy-Preserving PLA (EPP-PLA) scheme, which improve both the privacy and authentication performance as compared to the prior scheme. The fundamental difference between the EPP-PLA and PP-PLA schemes is how to encrypt the source message of a certain user while the other operations of the two proposed schemes keep the same. We provide the theoretical analysis of the proposed schemes in terms of robustness, compatibility, privacy, and security, and derive their closed-form expressions. Moreover, we provide the theoretical comparisons between the proposed schemes and the prior scheme. We optimize the parameters of the proposed schemes to achieve both message-rate fairness and authentication-accuracy fairness. We implement the proposed schemes and conduct extensive performance comparisons through simulations. Experimental results show that the theoretical results perfectly match the corresponding simulation results. Specifically, we take the second user, acting as an administrator for a NOMA system with three users, as an example, where SNR = 16 dB. In comparison with the prior scheme, both proposed schemes have the same compatibility, whereas they improve the robustness by 4.72%. Moreover, the EPP-PLA and PP-PLA schemes improve the security by 32.8%, whereas they improve the privacy by 3000.75% and 1000.75%, respectively.}
}


@article{DBLP:journals/jsac/LiuZDSAHS22a,
	author = {Yuanwei Liu and
                  Shuowen Zhang and
                  Zhiguo Ding and
                  Robert Schober and
                  Naofal Al{-}Dhahir and
                  Ekram Hossain and
                  Xuemin Shen},
	title = {Guest Editorial Special Issue on Next Generation Multiple Access -
                  Part {II}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1387--1391},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2021.3139737},
	doi = {10.1109/JSAC.2021.3139737},
	timestamp = {Tue, 23 Aug 2022 09:19:57 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuZDSAHS22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the long-term evolution (LTE) system is reaching maturity and the fifth-generation (5G) systems are being commercially deployed, researchers have turned their attention to the development of next-generation wireless networks. Compared to current wireless networks, on the one hand, next-generation wireless networks are expected to achieve significantly higher capacity, extremely low latency, ultra-high reliability, as well as massive and ubiquitous connectivity for supporting diverse disruptive applications (e.g., virtual reality (VR), augmented reality (AR), and industry 4.0). On the other hand, the evolution toward next-generation wireless networks requires a paradigm shift from the communication-oriented design to a multi-functional design, including communication, sensing, imaging, computing, and localization. Looking back at the history of wireless communication systems, multiple access (MA) techniques have been key enablers. From the first generation (1G) to the fifth generation (5G), orthogonal multiple access (OMA) schemes are mainly employed, where multiple users are allotted in orthogonal frequency/time/code resources, and the uplink transmission of the code code-division multiple-access (CDMA) uses non-orthogonal code resources. However, given the enormous challenges and diverse services of next-generation wireless networks, which significantly differ from that in current and previous wireless networks, existing MA schemes may not be applicable. As a result, a fundamental issue is the design of next-generation multiple access (NGMA) techniques. The key concept of NGMA is to enable a very large number of users/devices to be efficiently, flexibly, and intelligently connected with the network over the given wireless radio resources to not only satisfy stringent communication requirements but also realize heterogeneous functions. The investigation of NGMA is still in the infancy stage, and extensive research efforts have to be devoted to areas, including but not limited to 1) the development of new MA schemes, such as non-orthogonal multiple access (NOMA) and space division multiple access (SDMA), which are capable of achieving higher bandwidth efficiency and higher connectivity compared with conventional MA schemes; 2) the development of innovative techniques, such as reconfigurable metasurfaces, random access, advanced modulation, and channel coding, which are beneficial to the overall design of NGMA; and 3) the exploitation of advanced machine learning (ML) tools and big data techniques for providing effective solutions to address newly emerging NGMA problems.}
}


@article{DBLP:journals/jsac/JiangY22,
	author = {Tao Jiang and
                  Wei Yu},
	title = {Interference Nulling Using Reconfigurable Intelligent Surface},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1392--1406},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143220},
	doi = {10.1109/JSAC.2022.3143220},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/JiangY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the interference nulling capability of reconfigurable intelligent surface (RIS) in a multiuser environment where multiple single-antenna transceivers communicate simultaneously in a shared spectrum. From a theoretical perspective, we show that when the channels between the RIS and the transceivers have line-of-sight and the direct paths are blocked, it is possible to adjust the phases of the RIS elements to null out all the interference completely and to achieve the maximum\nK\ndegrees-of-freedom (DoF) in the overall\nK\n-user interference channel, provided that the number of RIS elements exceeds some finite value that depends on\nK\n. Algorithmically, for any fixed channel realization we formulate the interference nulling problem as a feasibility problem, and propose an alternating projection algorithm to efficiently solve the resulting nonconvex problem with local convergence guarantee. Numerical results show that the proposed alternating projection algorithm can null all the interference if the number of RIS elements is only slightly larger than a threshold of\n2K(K−1)\n. For the practical sum-rate maximization objective, this paper proposes to use the zero-forcing solution obtained from alternating projection as an initial point for subsequent Riemannian conjugate gradient optimization and shows that it has a significant performance advantage over random initializations. For the objective of maximizing the minimum rate, this paper proposes a subgradient projection method which is capable of achieving excellent performance at low complexity.}
}


@article{DBLP:journals/jsac/XuYWC22,
	author = {Hao Xu and
                  Tianyu Yang and
                  Kai{-}Kit Wong and
                  Giuseppe Caire},
	title = {Achievable Regions and Precoder Designs for the Multiple Access Wiretap
                  Channels With Confidential and Open Messages},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1407--1427},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3145916},
	doi = {10.1109/JSAC.2022.3145916},
	timestamp = {Fri, 27 Oct 2023 15:11:42 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XuYWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the secrecy achievable region of multiple access wiretap (MAC-WT) channels where, besides confidential messages, the users have also open messages to transmit. All these messages are intended for the legitimate receiver (or Bob for brevity) but only the confidential messages need to be protected from the eavesdropper (Eve). We first consider a discrete memoryless (DM) MAC-WT channel where both Bob and Eve jointly decode their interested messages. By using random coding, we find an achievable rate region, within which perfect secrecy can be realized, i.e., all users can communicate with Bob with arbitrarily small probability of error, while the confidential information leaked to Eve tends to zero. Due to the high implementation complexity of joint decoding, we also consider the DM MAC-WT channel where Bob simply decodes messages independently while Eve still applies joint decoding. We then extend the results in the DM case to a Gaussian vector (GV) MAC-WT channel. Based on the information theoretic results, we further maximize the sum secrecy rate of the GV MAC-WT system by designing precoders for all users. Since the problems are non-convex, we provide iterative algorithms to obtain suboptimal solutions. Simulation results show that compared with existing schemes, secure communication can be greatly enhanced by the proposed algorithms, and in contrast to the works which only focus on the network secrecy performance, the system spectrum efficiency can be effectively improved since open messages can be simultaneously transmitted.}
}


@article{DBLP:journals/jsac/WangADZ22,
	author = {Xinhua Wang and
                  Alexei Ashikhmin and
                  Zhicheng Dong and
                  Chao Zhai},
	title = {Two-Stage Channel Estimation Approach for Cell-Free IoT With Massive
                  Random Access},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1428--1440},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143213},
	doi = {10.1109/JSAC.2022.3143213},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangADZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the activity detection and channel estimation issues for cell-free Internet of Things (IoT) networks with massive random access. In each time slot, only partial devices are active and communicate with neighboring access points (APs) using non-orthogonal random pilot sequences. Different from the centralized processing in cellular networks, the activity detection and channel estimation in cell-free IoT is more challenging due to the distributed and user-centric architecture. We propose a two-stage approach to detect the random activities of devices and estimate their channel states. In the first stage, the activity of each device is jointly detected by its adjacent APs based on the vector approximate message passing (Vector AMP) algorithm. In the second stage, each AP re-estimates the channel using the linear minimum mean square error (LMMSE) method based on the detected activities to improve the channel estimation accuracy. We derive closed-form expressions for the activity detection error probability and the mean-squared channel estimation errors for a typical device. Finally, we analyze the performance of the entire cell-free IoT network in terms of coverage probability. Simulation results validate the derived closed-form expressions and show that the cell-free IoT significantly outperforms the collocated massive MIMO and small-cell schemes in terms of coverage probability.}
}


@article{DBLP:journals/jsac/FangWRHPH22,
	author = {Zhengru Fang and
                  Jingjing Wang and
                  Yong Ren and
                  Zhu Han and
                  H. Vincent Poor and
                  Lajos Hanzo},
	title = {Age of Information in Energy Harvesting Aided Massive Multiple Access
                  Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1441--1456},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143252},
	doi = {10.1109/JSAC.2022.3143252},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/FangWRHPH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the proliferation of the massive machine type communication devices (MTCDs) in beyond 5G (B5G) wireless networks, energy harvesting (EH) aided next generation multiple access (NGMA) systems have drawn substantial attention in the context of energy-efficient data sensing and transmission. However, without adaptive time slot (TS) and power allocation schemes, NGMA systems relying on stochastic sampling instants might lead to tardy actions associated both with high age of information (AoI) as well as high power consumption. For mitigating the energy consumption, we exploit a pair of sleep-scheduling policies, namely the multiple vacation (MV) policy and start-up threshold (ST) policy, which are characterized in the context of three typical multiple access protocols, including time-division multiple access (TDMA), frequency-division multiple access (FDMA) and non-orthogonal multiple access (NOMA). Furthermore, we derive closed-form expressions for the MTCD system’s peak AoI, which are formulated as the optimization objective under the constraints of EH power, status update rate and stability conditions. An exact linear search based algorithm is proposed for finding the optimal solution by fixing the status update rate. As a design alternative, a low complexity concave-convex procedure (CCP) is also formulated for finding a near-optimal solution relying on the original problem’s transformation into a form represented by the difference of two convex problems. Our simulation results show that the proposed algorithms are beneficial in terms of yielding a lower peak AoI at a low power consumption in the context of the multiple access protocols considered.}
}


@article{DBLP:journals/jsac/HuangZHYZ22,
	author = {Jianhao Huang and
                  Han Zhang and
                  Chuan Huang and
                  Lian Yang and
                  Wei Zhang},
	title = {Noncoherent Massive Random Access for Inhomogeneous Networks: From
                  Message Passing to Deep Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1457--1472},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143260},
	doi = {10.1109/JSAC.2022.3143260},
	timestamp = {Wed, 27 Apr 2022 20:12:19 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuangZHYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Massive machine-type communications (mMTC) are expected to support a large amount of randomly deployed users for short package transmissions. Noncoherent random access provides an efficient and practical multi-access protocol for mMTC, and also poses new challenges for the receiver design. In this paper, we leverage two well-known methods, i.e., message passing and deep learning, to jointly detect the user activity and the desired data for the noncoherent mMTC. First, by exploiting the exact distribution information of the received signal, a generalized approximate message passing (GAMP)-based algorithm is proposed, which is shown to jointly detect the user activity and the desired data by two modules: inter-user interference elimination and data detection for each user. Inspired by the two-module GAMP-based algorithm, we then propose a model-driven deep learning method, which utilizes the deep neural networks (DNNs) to approximate both the two modules. The loss function for training the DNNs is derived by formulating the two-module detection as an unconstrained optimization problem. Simulation results reveal that the proposed GAMP-based algorithm outperforms the proposed deep learning method when the channel distribution is perfectly known, while it suffers from a significant performance degradation for the case with imperfect channel distribution information.}
}


@article{DBLP:journals/jsac/LiCL22,
	author = {Changkun Li and
                  Wei Chen and
                  Khaled B. Letaief},
	title = {Achieving Low Latency in Massive Access: {A} Mean-Field Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1473--1488},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143266},
	doi = {10.1109/JSAC.2022.3143266},
	timestamp = {Wed, 27 Apr 2022 20:12:19 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The next generation massive access has attracted considerable recent attention due to its potential in smart meters, industrial internet of things (IIoT), and smart traffics, etc. However, how to achieve the minimum queuing delay in massive access still remains open, thereby making quality-of-service (QoS) assurance a challenging issue in practice. In this paper, we aim at minimizing the average queuing delay by applying cross-layer scheduling with joint channel and buffer awareness, the complexity of which increases exponentially with the number of users. Fortunately, with massive users or devices, mean-field approximation can be adopted to substantially simplify the design and analysis of the delay-optimal scheduling. More specifically, we present a cocktail filling policy and a queue-aware multiuser diversity protocol, in which all backlogged packets of a user will be served by either NOMA or TDMA mode respectively, if the user’s channel gain is beyond a certain threshold. The average queuing delay and queue-length-violation probability are derived based on a Markov model. Numerical results will also demonstrate that the mean-field approximation based joint physical and network layer scheduling is capable of improving the QoS in massive access.}
}


@article{DBLP:journals/jsac/QiaoZGZHGNR22,
	author = {Li Qiao and
                  Jun Zhang and
                  Zhen Gao and
                  Dezhi Zheng and
                  Md. Jahangir Hossain and
                  Yue Gao and
                  Derrick Wing Kwan Ng and
                  Marco Di Renzo},
	title = {Joint Activity and Blind Information Detection for UAV-Assisted Massive
                  IoT Access},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1489--1508},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143255},
	doi = {10.1109/JSAC.2022.3143255},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/QiaoZGZHGNR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Grant-free non-coherent index-modulation (NC-IM) has been recently considered as an efficient massive access scheme for enabling cost- and energy-limited Internet-of-Things (IoT) devices that transmit small data packets. This paper investigates the grant-free NC-IM scheme combined with orthogonal frequency division multiplexing for applicant to unmanned aerial vehicle (UAV)-based massive IoT access. Specifically, each device is assigned a unique non-orthogonal signature sequence codebook. Each active device transmits one of its signature sequences in the given time-frequency resources, by modulating the information in the index of the transmitted signature sequence. For small-scale multiple-input multiple-output (MIMO) deployed at the UAV-based aerial base station (BS), by jointly exploiting the space-time-frequency domain device activity, we propose a computationally efficient space-time-frequency joint activity and blind information detection (JABID) algorithm with significantly improved detection performance. Furthermore, for large-scale MIMO deployed at the aerial BS, by leveraging the sparsity of the virtual angular-domain channels, we propose an angular-domain based JABID algorithm for improving the system performance with reduced access latency. In addition, for the case of high mobility IoT devices and/or UAVs, we introduce a time-frequency spread transmission (TFST) strategy for the proposed JABID algorithms to combat doubly-selective fading channels. Finally, extensive simulation results are illustrated to verify the superiority of the proposed algorithms and the TFST strategy over known state-of-the-art algorithms.}
}


@article{DBLP:journals/jsac/LiuW22,
	author = {Jiaai Liu and
                  Xiaodong Wang},
	title = {Unsourced Multiple Access Based on Sparse Tanner Graph - Efficient
                  Decoding, Analysis, and Optimization},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1509--1521},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143225},
	doi = {10.1109/JSAC.2022.3143225},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose novel sparse-graph-based transmission schemes and receiver algorithms for unsourced multiple access (UMA) in MIMO channels. The channel coherence interval is divided into a number of sub-slots and each active transmitter selects certain sub-slots to repeatedly transmit its codeword according to a sparse Tanner graph. We propose iterative receiver algorithms that at each iteration decode either a single codeword, or two or three codewords jointly, and then subtract the decoded codewords from received signals during all sub-slots. The keys to these decoders are novel blind channel estimation algorithms when the received signal contains one, two, or three codewords. We perform density evolution analysis on the proposed UMA systems to obtain the asymptotic upper bounds on the maximum achievable rates for different decoders under both regular and irregular Tanner graphs. Extensive simulation results are provided to illustrate the performance of the proposed UMA systems, and its advantages over existing compressed-sensing (CS)-based UMA schemes.}
}


@article{DBLP:journals/jsac/FenglerMJC22,
	author = {Alexander Fengler and
                  Osman Musa and
                  Peter Jung and
                  Giuseppe Caire},
	title = {Pilot-Based Unsourced Random Access With a Massive {MIMO} Receiver,
                  Interference Cancellation, and Power Control},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1522--1534},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3144748},
	doi = {10.1109/JSAC.2022.3144748},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/FenglerMJC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the unsourced random access problem on a Rayleigh block-fading AWGN channel with multiple receive antennas. Specifically, we treat the slow fading scenario where the coherence blocklength is large compared to the number of active users and a message can be transmitted in a single fading coherence block. Unsourced random access refers to a form of grant-free random access where users are constrained to use the same codebook and therefore are a priori indistinguishable. The receiver must recover the list of transmitted messages up to permutations. In this paper, we propose an approach based on splitting the user messages into two parts. First, a small block of bits selects a relatively short codeword from a common “pilot” codebook. Then the remaining message bits are encoded by a standard block code for the Gaussian channel. The receiver makes use of a multiple measurement vector approximate message passing (MMV-AMP) algorithm to estimate the active user channels from the “pilot” part, and then uses the estimated channels to perform coherent maximum ratio combining (MRC) to decode the second part. We provide an accurate closed-form approximated analysis of the proposed scheme. Furthermore, we analyze the MRC decoding when successive interference cancellation is performed over groups of users, striking an attractive tradeoff between complexity and performance. Finally, we investigate the impact of power control policies, taking into account the unique nature of massive random access. As a byproduct, we also present an extension of the MMV-AMP algorithm which allows pathloss coefficients to be treated as deterministic unknowns by performing maximum likelihood estimation in each step of the MMV-AMP algorithm.}
}


@article{DBLP:journals/jsac/LiWZZXAXX22,
	author = {Tianya Li and
                  Yongpeng Wu and
                  Mengfan Zheng and
                  Wenjun Zhang and
                  Chengwen Xing and
                  Jianping An and
                  Xiang{-}Gen Xia and
                  Chengshan Xiao},
	title = {Joint Device Detection, Channel Estimation, and Data Decoding With
                  Collision Resolution for {MIMO} Massive Unsourced Random Access},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1535--1555},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3145914},
	doi = {10.1109/JSAC.2022.3145914},
	timestamp = {Mon, 28 Aug 2023 21:38:10 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiWZZXAXX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate a joint device activity detection (DAD), channel estimation (CE), and data decoding (DD) algorithm for multiple-input multiple-output (MIMO) massive unsourced random access (URA). Different from the state-of-the-art slotted transmission scheme, the data in the proposed framework is split into only two parts. A portion of the data is coded by compressed sensing (CS) and the rest is low-density-parity-check (LDPC) coded. In addition to being part of the data, information bits in the CS phase also undertake the task of interleaving pattern design and CE. The principle of interleave-division multiple access (IDMA) is exploited to reduce the interference among devices in the LDPC phase. Based on the belief propagation (BP) algorithm, a low-complexity iterative message passing (MP) algorithm is utilized to decode the data embedded in these two phases separately. Moreover, combined with successive interference cancellation (SIC), the proposed joint DAD-CE-DD algorithm is performed to further improve performance by utilizing the belief of each other. Additionally, based on the energy detection (ED) and sliding window protocol (SWP), we develop a collision resolution protocol to handle the codeword collision, a common issue in the URA system. In addition to the complexity reduction, the proposed algorithm exhibits a substantial performance enhancement compared to the state-of-the-art in terms of efficiency and accuracy.}
}


@article{DBLP:journals/jsac/YueRXZZZ22,
	author = {Sheng Yue and
                  Ju Ren and
                  Jiang Xin and
                  Deyu Zhang and
                  Yaoxue Zhang and
                  Weihua Zhuang},
	title = {Efficient Federated Meta-Learning Over Multi-Access Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1556--1570},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143259},
	doi = {10.1109/JSAC.2022.3143259},
	timestamp = {Mon, 25 Mar 2024 12:48:07 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/YueRXZZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated meta-learning (FML) has emerged as a promising paradigm to cope with the data limitation and heterogeneity challenges in today’s edge learning arena. However, its performance is often limited by slow convergence and corresponding low communication efficiency. In addition, since the available radio spectrum and IoT devices’ energy capacity are usually insufficient, it is crucial to control the resource allocation and energy consumption when deploying FML in practical wireless networks. To overcome the challenges, in this paper, we rigorously analyze the contribution of each device to the global loss reduction in each round and develop an FML algorithm (called NUFM) with a non-uniform device selection scheme to accelerate the convergence. After that, we formulate a resource allocation problem integrating NUFM in multi-access wireless systems to jointly improve the convergence rate and minimize the wall-clock time along with energy cost. By deconstructing the original problem step by step, we devise a joint device selection and resource allocation strategy to solve the problem with theoretical guarantees. Further, we show that the computational complexity of NUFM can be reduced from\nO(\nd\n2\n)\nto\nO(d)\n(with the model dimension\nd\n) via combining two first-order approximation techniques. Extensive simulation results demonstrate the effectiveness and superiority of the proposed methods in comparison with existing baselines.}
}


@article{DBLP:journals/jsac/CaoZXC22,
	author = {Xiaowen Cao and
                  Guangxu Zhu and
                  Jie Xu and
                  Shuguang Cui},
	title = {Transmission Power Control for Over-the-Air Federated Averaging at
                  Network Edge},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1571--1586},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143217},
	doi = {10.1109/JSAC.2022.3143217},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/CaoZXC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over-the-air computation (AirComp) has emerged as a new analog power-domain non-orthogonal multiple access (NOMA) technique for low-latency model/gradient-updates aggregation in federated edge learning (FEEL). By integrating communication and computation into a joint design, AirComp can significantly enhance the communication efficiency, but at the cost of aggregation errors caused by channel fading and noise. This paper studies a particular type of FEEL with federated averaging (FedAvg) and AirComp-based model-update aggregation, namely over-the-air FedAvg (Air-FedAvg). We investigate the transmission power control in Air-FedAvg to combat against the AirComp aggregation errors for enhancing the training accuracy and accelerating the training speed. Towards this end, we first analyze the convergence behavior (in terms of the optimality gap) of Air-FedAvg with aggregation errors at different outer iterations. Then, to enhance the training accuracy, we minimize the optimality gap by jointly optimizing the transmission power control at edge devices and the denoising factors at edge server, subject to a series of power constraints at individual edge devices. Furthermore, to accelerate the training speed, we also minimize the training latency of Air-FedAvg with a given targeted optimality gap, in which learning hyper-parameters including the numbers of outer iterations and local training epochs are optimized jointly with the power control. Finally, numerical results show that the proposed transmission power control policy achieves significantly faster convergence speed for Air-FedAvg, as compared with benchmark policies with fixed power transmission or per-iteration mean squared error (MSE) minimization. It is also shown that the Air-FedAvg achieves an order-of-magnitude shorter training latency than the conventional FedAvg with digital orthogonal multiple access (OMA-FedAvg).}
}


@article{DBLP:journals/jsac/GuoCLLYS22,
	author = {Ziyang Guo and
                  Zhenyu Chen and
                  Peng Liu and
                  Jianjun Luo and
                  Xun Yang and
                  Xinghua Sun},
	title = {Multi-Agent Reinforcement Learning-Based Distributed Channel Access
                  for Next Generation Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1587--1599},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143251},
	doi = {10.1109/JSAC.2022.3143251},
	timestamp = {Fri, 19 Aug 2022 12:31:11 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GuoCLLYS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the next generation wireless networks, more applications will emerge, covering virtual reality movies, augmented reality, holographic three-dimensional telepresence, haptic telemedicine and so on, which require the provisioning of high bandwidth efficiency and low latency services. In order to better support the aforementioned applications and services, novel distributed channel access (DCA) schemes are necessary. Therefore, we propose a new MAC protocol, QMIX-advanced Listen-Before-Talk (QLBT), based on the cutting-edge multi-agent reinforcement learning (MARL) algorithm. It employs a centralized training with decentralized execution (CTDE) framework to exploit the overall information of all agents during training, and ensure that each agent can independently infer the optimal channel access behavior based on its local observation. We enhance QMIX, a well-known MARL algorithm, by introducing an extra individual Q-value for each agent in the mixing network apart from the original total Q-value, which makes QLBT more stable. Moreover, delay to last successful transmission (D2LT) is first introduced in this work as a part of the observations of each QLBT agent, which facilitates agents to reach a cooperative policy that prioritizes the agent with the longest delay. Finally, extensive simulation experiments are provided to show that the proposed QLBT algorithm: 1) outperforms CSMA/CA and even its theoretical performance bound in various scenarios including saturated traffic, unsaturated traffic and delay-sensitive traffic; 2) is robust in dynamic environment; and 3) is able to friendly coexist with “legacy” CSMA/CA stations.}
}


@article{DBLP:journals/jsac/FuZZCQ22,
	author = {Yaru Fu and
                  Yue Zhang and
                  Qi Zhu and
                  Mingzhe Chen and
                  Tony Q. S. Quek},
	title = {Joint Content Caching, Recommendation, and Transmission Optimization
                  for Next Generation Multiple Access Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1600--1614},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3146901},
	doi = {10.1109/JSAC.2022.3146901},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/FuZZCQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We exploit a behavior-shaping proactive mechanism, namely, recommendation, in cache-assisted non-orthogonal multiple access (NOMA) networks, aiming at minimizing the average system’s latency. Thereof, the considered latency consists of two parts, i.e., the backhaul link transmission delay and the content delivery latency. Towards this end, we first examine the expression of system latency, demonstrating how it is critically determined by content cache placement, personalized recommendation, and delivery associated NOMA user pairing and power control strategies. Thereafter, we formulate the minimization problem mathematically taking into account the cache capacity budget, the recommendation-oriented requirements, and the total transmit power constraint, which is a non-convex, multi-timescale, and mixed-integer programming problem. To facilitate the process, we put forth an entirely new paradigm named divide-and-rule . Specifically, we first solve the short-term optimization problem regarding user pairing as well as power allocation and the long-term decision-making problem with respect to recommendation and caching, respectively. On this basis, an iterative algorithm is developed to optimize all the optimization variables alternately. Particularly, for solving the short-timescale problem, graph theory enabled NOMA user grouping and efficient inter-group power control manners are invoked. Meanwhile, a dynamic programming approach and a complexity-controllable swap-then-compare method with convergence insurance are designed to derive the caching and recommendation policies, respectively. From Monte-Carlo simulation, we show the superiority of the proposed joint optimization method in terms of both system latency and cache hit ratio when compared to extensive benchmark strategies.}
}


@article{DBLP:journals/jsac/XiaoXFDYZLM22,
	author = {Han Xiao and
                  Changqiao Xu and
                  Zichen Feng and
                  Renjie Ding and
                  Shujie Yang and
                  Lujie Zhong and
                  Jie Liang and
                  Gabriel{-}Miro Muntean},
	title = {A Transcoding-Enabled 360{\textdegree} {VR} Video Caching and Delivery
                  Framework for Edge-Enhanced Next-Generation Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1615--1631},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3145813},
	doi = {10.1109/JSAC.2022.3145813},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XiaoXFDYZLM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual reality (VR) content, including 360° panoramic video, provides users with an immersive multimedia experience and therefore attracts increasing research and development attention. However, the requirement of high bandwidth and low latency of virtual reality service demand puts forward greater challenges to the current infrastructure, especially mobile networks. Inspired by the sharable nature of virtual reality content tiles, we further considered the potential opportunities for computing, caching, and multicast to address the challenges of transmission of panoramic content. This paper proposes a novel transcoding-enabled VR video caching and delivery framework for edge-enhanced next-generation wireless networks. Firstly, an edge cooperative caching scheme based on multi-agent reinforcement learning is introduced to improve the utilization efficiency of computing and storage resources, and then reduce service delay. Second, a two-tier NOMA-based base station-multicast group matching mechanism is designed to solve the collaboration challenge during the edge delivery process. A series of experiments have demonstrated the advantages of the proposed scheme in terms of cache hit rate, latency and other aspects in comparison with alternative approaches.}
}


@article{DBLP:journals/jsac/ShahsavariSKE22,
	author = {Shahram Shahsavari and
                  Farhad Shirani and
                  Mohammad Ali Khojastepour and
                  Elza Erkip},
	title = {Opportunistic Temporal Fair Mode Selection and User Scheduling in
                  Full-Duplex Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1632--1651},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143212},
	doi = {10.1109/JSAC.2022.3143212},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ShahsavariSKE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In-band full-duplex (FD) communication has emerged as one of the promising techniques to improve data rates in next generation wireless systems. Typical FD scenarios considered in the literature assume FD base stations (BSs) and half-duplex (HD) users activated either in uplink (UL) or downlink (DL), where inter-user interference (IUI) is treated as noise at the DL user. This paper considers more general FD scenarios where an arbitrary fraction of the users are capable of FD and/or they can perform successive interference cancellation (SIC) to mitigate IUI. Consequently, one user can be activated in either UL or DL (HD-UL and HD-DL modes), or simultaneously in both directions requiring self-interference mitigation (SIM) at that user (FD-SIM mode). Furthermore, two users can be scheduled, one in UL and the other in DL (both operating in HD), where the DL user can treat IUI as noise (FD-IN mode) or perform SIC to mitigate IUI (FD-SIC mode). This paper studies opportunistic mode selection and user scheduling under long-term and short-term temporal fairness in single-carrier and multi-carrier (OFDM) FD systems, with the goal of maximizing system utility (e.g. sum-rate). First, the feasible region of temporal demands is characterized for both long-term and short-term fairness. Subsequently, optimal temporal fair schedulers as well as practical low-complexity online algorithms are devised. Simulation results demonstrate that using SIC to mitigate IUI as well as having FD capability at users can improve FD throughput gains significantly especially, when user distribution is concentrated around a few hotspots.}
}


@article{DBLP:journals/jsac/HuangLLX22,
	author = {Mingfeng Huang and
                  Victor C. M. Leung and
                  Anfeng Liu and
                  Neal N. Xiong},
	title = {{TMA-DPSO:} Towards Efficient Multi-Task Allocation With Time Constraints
                  for Next Generation Multiple Access},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1652--1666},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143205},
	doi = {10.1109/JSAC.2022.3143205},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuangLLX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future heterogeneous services and applications require the provisioning of unprecedented massive user access, heterogeneous data traffic, high bandwidth efficiency, and low latency services in next generation multiple access. In response to the requests from these services and applications, a large number of workers with scattered computing power need to be managed uniformly and scheduled in an efficient manner to perform various tasks. Therefore, task allocation has become a crucial issue to determining whether next generation multiple access can support future heterogeneous services and applications. In this paper, we propose a novel Two-stage Multi-task Allocation method based on Discrete Particle Swarm Optimization (TMA-DPSO). TMA-DPSO is easy to implement and has good search efficiency, which is suitable for large-scale task allocation in next generation networks. Under TMA-DPSO, we redefine the particles in discrete coding form, iteratively update the position and velocity based on the individual optimal particles and the global optimal particle, and finally obtain a corrected optimal solution. Unlike previous methods that only focused on the first-stage task allocation, we make full use of workers’ remaining time to perform second-stage redundant task allocation, which can not only increase workers’ income, but also potentially improve fault tolerance and security. As far as we know, this is the first attempt to utilize the remaining time after first-stage allocation. Finally, we evaluate TMA-DPSO extensively using the synthetic and real-life datasets. The results demonstrate that whether in a compactly or uniformly distributed scene, TMA-DPSO outperforms three benchmark methods by increasing 2.15%-42.24% platform revenue and 6.1%-46.63% workers income.}
}


@article{DBLP:journals/jsac/HashidaKKIM22,
	author = {Hiroaki Hashida and
                  Yuichi Kawamoto and
                  Nei Kato and
                  Masashi Iwabuchi and
                  Tomoki Murakami},
	title = {Mobility-Aware User Association Strategy for IRS-Aided mm-Wave Multibeam
                  Transmission Towards 6G},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1667--1678},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143216},
	doi = {10.1109/JSAC.2022.3143216},
	timestamp = {Wed, 27 Apr 2022 20:12:19 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HashidaKKIM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, intelligent reflecting surfaces (IRSs) for large-capacity and highly reliable wireless communication have attracted widespread attention. However, a multiuser access system with multiple IRSs poses limitations in reducing the large signaling overhead of channel estimation for numerous links between the IRSs and users. One approach to reduce the exhaustive channel estimation involves associating the IRS with a user and performing beam tracking for a certain period. However, as the IRS–user association is fixed during the tracking period, the dynamic variations in their link status caused by user mobility degrade the system performance if the association is decided without prior planning. Therefore, this paper proposes an IRS–user association strategy considering user mobility for IRS-aided multibeam transmission systems. Contrary to prior works, our association strategy aims to optimize the long-term performance of systems in terms of capacity and reliability. The proposed strategy minimized performance degradation even under drastic fluctuations of link conditions, thereby reducing channel estimation overhead because both the IRS and user can be associated for long periods with low performance degradation.}
}


@article{DBLP:journals/jsac/WangCZZZ22,
	author = {Jianyu Wang and
                  Wenchi Cheng and
                  Weizheng Zhang and
                  Wei Zhang and
                  Hailin Zhang},
	title = {Multi-Frequency Access for Magnetic Induction-Based {SWIPT}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1679--1691},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143265},
	doi = {10.1109/JSAC.2022.3143265},
	timestamp = {Wed, 06 Jul 2022 10:42:17 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangCZZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Magnetic Induction (MI) based transmissions, where the typical applications are wireless power transfer (WPT) and MI communications, have gained substantial attention in recent years. Existing works related to MI based transmissions mainly focus on the case with single resonant frequency. However, from the perspective of practical applications, it is highly demanded to achieve multi-frequency access for MI based transmissions. Although multiple coils can be used to generate additional resonant frequencies, each coil is often with one resonant frequency. In this paper, we develop the Multi-frequency Resonating Compensation (MuReC) coil based Multiple-band, Multiple-Input, and Multiple-Output (MbMIMO) simultaneous wireless information and power transfer (SWIPT), which can generate multiple resonant frequencies with one coil. The access point (AP) is equipped with multiple MuReC coils as well as delivers power and data to single-coil receivers (RXs) with different resonant frequencies. We propose the magnetic beamforming scheme for MuReC-MbMIMO-SWIPT, which aims to minimize the transmit power as well as guarantee the network throughput, total delivered power, and individual requirements of each channel. The beamforming schemes for two special cases of MuReC-MbMIMO-SWIPT, that is, MuReC-MbMIMO-communications and MuReC-MbMIMO-WPT, are also given. The optimal beamforming scheme in closed-form for MuReC-MbMIMO-communications is derived. In addition, the parameter design scheme for MuReC coils, which can support an arbitrary number of resonant frequencies, is developed. Numerical results verify our theoretical analyses and show that MuReC-MbMIMO transmissions and the proposed beamforming schemes can fully use antenna resources and effectively support multi-frequency access.}
}


@article{DBLP:journals/jsac/LiYC22,
	author = {Ruifu Li and
                  Han Yan and
                  Danijela Cabric},
	title = {Rainbow-Link: Beam-Alignment-Free and Grant-Free mmW Multiple Access
                  Using True-Time-Delay Array},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1692--1705},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3143261},
	doi = {10.1109/JSAC.2022.3143261},
	timestamp = {Fri, 29 Apr 2022 16:53:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiYC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The millimeter-wave (mmW) communications is a key enabling technology in 5G to provide ultra-high throughput. Current mmW technologies rely on analog phased arrays to realize beamforming gain and overcome high path loss. However, due to a limited number of simultaneous beams that can be created with analog/hybrid phased antenna arrays, the overheads of beam training and beam scheduling become a bottleneck for emerging networks that need to support a large number of users and low latency applications. This paper introduces rainbow-link, a novel multiple access protocol, that can achieve low latency and massive connectivity by exploiting wide bandwidth at mmW frequencies and novel analog true-time-delay array architecture with frequency dependent beamforming capability. In the proposed design, the network infrastructure is equipped with the true-time-delay array to simultaneously steer different frequency resource blocks towards distinct directions covering the entire cell sector. Users or devices, equipped with a narrowband receiver and either a single antenna or small phased antenna array, connect to the network based on their angular positions by selecting frequency resources within their rainbow beam allocation. Rainbow-link is combined with a contention-based grant-free access to eliminate the explicit beam training and user scheduling. The proposed design and analysis show that rainbow-link grant-free access is a potential candidate for latency-critical use cases within massive connectivity. Our results show that, given less than 10 −5 probability of packet loss, a rainbow-link cell, over 1 GHz bandwidth using 64 element antenna array, attains sub-millisecond user-plane latency and Mbps user rates with an approximate 400m line-of-sight coverage and a density of up to 5 active single antenna users per second per m 2 .}
}


@article{DBLP:journals/jsac/XingHLY22,
	author = {Fangyuan Xing and
                  Shibo He and
                  Victor C. M. Leung and
                  Hongxi Yin},
	title = {Energy Efficiency Optimization for Rate-Splitting Multiple Access-Based
                  Indoor Visible Light Communication Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {5},
	pages = {1706--1720},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3145818},
	doi = {10.1109/JSAC.2022.3145818},
	timestamp = {Wed, 27 Apr 2022 20:12:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XingHLY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosive proliferation of connected devices and mobile users in the Internet-of-things, multiple access techniques are urged to be developed for the next generation wireless communications. Recently, rate-splitting multiple access (RSMA) has been a promising communication technology that holds advantages of strong robustness, low complexity, and high spectral efficiency, which can be integrated with the indoor visible light communication (VLC) broadcast system to compensate for the shortcomings of limited modulation bandwidth of LEDs. However, the research on the RSMA-based VLC systems is still in its infancy and there exist various problems to be explored. To benefit from the RSMA technique, this paper investigates the energy efficiency optimizations for both single-cell and multi-cell RSMA-based VLC broadcast systems. Specifically, these two systems are modeled, where the VLC broadcast channel follows Lambertian radiation model, and the splitting design and successive interference cancellation of RSMA are employed to mitigate the multi-user interference. Especially for multi-cell networks, the zero-forcing approach is adopted to eliminate the inter-cell interference. To maximize the energy efficiency, the precoding and power allocation problems are formulated for single-cell and multi-cell networks while accommodating multiple constraints including dynamic operation ranges of LEDs, QoS requirements, and interference elimination. For solving these non-convex fractional problems, two pieces of successive convex approximation (SCA)-based algorithms are proposed, in which the variable transformation and linear approximation are adopted. Simulation results indicate that the proposed schemes can achieve superior energy efficiency with fast convergence for various network loads and user deployments.}
}


@article{DBLP:journals/jsac/LiuMXHHEB22,
	author = {Fan Liu and
                  Christos Masouros and
                  Jie Xu and
                  Tony Xiao Han and
                  Aboulnasr Hassanien and
                  Yonina C. Eldar and
                  Stefano Buzzi},
	title = {Guest Editorial Special Issue on Integrated Sensing and Communication
                  - Part {I}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1723--1727},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3157507},
	doi = {10.1109/JSAC.2022.3157507},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuMXHHEB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Driving a gradual integration of the physical and digital worlds is perceived to become a reality in the 6G era, from vehicles to drones, from surveillance facilities in cities to agricultural tools in the countryside. Jointly motivated by recent advances in communication and signal processing, radio sensing functionality can be integrated into a 6G radio access network (RAN) in a low-cost and fast manner. That is, future networks have the ability to “see” the physical world through imaging and measuring the surrounding environment, which enables advanced location-aware services, ranging from the physical to application layers. In essence, a radio emission could simultaneously convey communication data from the transmitter to the receiver and deliver environmental information from the scattered echoes. Therefore, sensing and communication (S&C) functionalities are possible to be co-designed to utilize resources efficiently and to assist each other for mutual benefits. This type of research is typically referred to as integrated sensing and communication (ISAC).}
}


@article{DBLP:journals/jsac/LiuCMXHEB22,
	author = {Fan Liu and
                  Yuanhao Cui and
                  Christos Masouros and
                  Jie Xu and
                  Tony Xiao Han and
                  Yonina C. Eldar and
                  Stefano Buzzi},
	title = {Integrated Sensing and Communications: Toward Dual-Functional Wireless
                  Networks for 6G and Beyond},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1728--1767},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3156632},
	doi = {10.1109/JSAC.2022.3156632},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuCMXHEB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the standardization of 5G solidifies, researchers are speculating what 6G will be. The integration of sensing functionality is emerging as a key feature of the 6G Radio Access Network (RAN), allowing for the exploitation of dense cell infrastructures to construct a perceptive network. In this IEEE Journal on Selected Areas in Communications (JSAC) Special Issue overview, we provide a comprehensive review on the background, range of key applications and state-of-the-art approaches of Integrated Sensing and Communications (ISAC). We commence by discussing the interplay between sensing and communications (S&C) from a historical point of view, and then consider the multiple facets of ISAC and the resulting performance gains. By introducing both ongoing and potential use cases, we shed light on the industrial progress and standardization activities related to ISAC. We analyze a number of performance tradeoffs between S&C, spanning from information theoretical limits to physical layer performance tradeoffs, and the cross-layer design tradeoffs. Next, we discuss the signal processing aspects of ISAC, namely ISAC waveform design and receive signal processing. As a step further, we provide our vision on the deeper integration between S&C within the framework of perceptive networks, where the two functionalities are expected to mutually assist each other, i.e., via communication-assisted sensing and sensing-assisted communications. Finally, we identify the potential integration of ISAC with other emerging communication technologies, and their positive impacts on the future of wireless networks.}
}


@article{DBLP:journals/jsac/MehrotraS22,
	author = {Nishant Mehrotra and
                  Ashutosh Sabharwal},
	title = {On the Degrees of Freedom Region for Simultaneous Imaging {\&}
                  Uplink Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1768--1779},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155518},
	doi = {10.1109/JSAC.2022.3155518},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/MehrotraS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we take the first step towards quantifying the fundamental performance trade-offs between imaging and communication supported simultaneously using the same network resources. We analyze an uplink system configuration with a full-duplex base station (BS) illuminating an imaging scene while receiving data from a communication user. Our main contributions are two-fold. First, we propose a unified signal space analysis framework based on the degrees of freedom metric to characterize the trade-offs between the two operations in the high signal-to-noise ratio regime. Second, we propose a dual-function joint processing scheme, decode-and-image, that allows the BS to simultaneously form an image of the scene while decoding the uplink user’s data. Our analysis and proposed scheme highlight the benefits of exploiting the uplink signals for imaging, at the cost of increased cooperation between the BS and uplink user. Moreover, our proposed scheme outperforms traditional schemes that enable dual-function operation via spatial or temporal isolation of imaging and communication signals.}
}


@article{DBLP:journals/jsac/SohrabiJCY22,
	author = {Foad Sohrabi and
                  Tao Jiang and
                  Wei Cui and
                  Wei Yu},
	title = {Active Sensing for Communications by Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1780--1794},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155496},
	doi = {10.1109/JSAC.2022.3155496},
	timestamp = {Thu, 23 Jun 2022 20:01:47 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/SohrabiJCY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a deep learning approach to a class of active sensing problems in wireless communications in which an agent sequentially interacts with an environment over a predetermined number of time frames to gather information in order to perform a sensing or actuation task for maximizing some utility function. In such an active learning setting, the agent needs to design an adaptive sensing strategy sequentially based on the observations made so far. To tackle such a challenging problem in which the dimension of historical observations increases over time, we propose to use a long short-term memory (LSTM) network to exploit the temporal correlations in the sequence of observations and to map each observation to a fixed-size state information vector. We then use a deep neural network (DNN) to map the LSTM state at each time frame to the design of the next measurement step. Finally, we employ another DNN to map the final LSTM state to the desired solution. We investigate the performance of the proposed framework for adaptive channel sensing problems in wireless communications. In particular, we consider the adaptive beamforming problem for mmWave beam alignment and the adaptive reconfigurable intelligent surface sensing problem for reflection alignment. Numerical results demonstrate that the proposed deep active sensing strategy outperforms the existing adaptive or nonadaptive sensing schemes.}
}


@article{DBLP:journals/jsac/ChenWDCY22,
	author = {Li Chen and
                  Zhiqin Wang and
                  Ying Du and
                  Yunfei Chen and
                  F. Richard Yu},
	title = {Generalized Transceiver Beamforming for {DFRC} With {MIMO} Radar and
                  {MU-MIMO} Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1795--1808},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155515},
	doi = {10.1109/JSAC.2022.3155515},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenWDCY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial beamforming is an efficient way to realize dual-functional radar-communication (DFRC). In this paper, we study the DFRC design for a general scenario, where the dual-functional base station (BS) simultaneously detects the target as a multiple-input-multiple-output (MIMO) radar while communicating with multiple multi-antenna communication users (CUs). This necessitates a joint transceiver beamforming design for both MIMO radar and multi-user MIMO (MU-MIMO) communication. In order to characterize the performance tradeoff between MIMO radar and MU-MIMO communication, we first define the achievable performance region of the DFRC system. Then, both radar-centric and communication-centric optimizations are formulated to achieve the boundary of the performance region. For the radar-centric optimization, successive convex approximation (SCA) method is adopted to solve the non-convex constraint. For the communication-centric optimization, a solution based on weighted mean square error (MSE) criterion is obtained to solve the non-convex objective function. Furthermore, two low-complexity beamforming designs based on CU-selection and zero-forcing are proposed to avoid iteration, and the closed-form expressions of the low-complexity beamforming designs are derived. Simulation results are provided to verify the effectiveness of all proposed designs.}
}


@article{DBLP:journals/jsac/YeZFLLT22,
	author = {Zhifan Ye and
                  Zhengchun Zhou and
                  Pingzhi Fan and
                  Zilong Liu and
                  Xianfu Lei and
                  Xiaohu Tang},
	title = {Low Ambiguity Zone: Theoretical Bounds and Doppler-Resilient Sequence
                  Design in Integrated Sensing and Communication Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1809--1822},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155510},
	doi = {10.1109/JSAC.2022.3155510},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YeZFLLT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In radar sensing and communications, designing Doppler resilient sequences (DRSs) with low ambiguity function for delay over the entire signal duration and Doppler shift over the entire signal bandwidth is an extremely difficult task. However, in practice, the Doppler frequency range is normally much smaller than the bandwidth of the transmitted signal, and it is relatively easy to attain quasi-synchronization for delays far less than the entire signal duration. Motivated by this observation, we propose a new concept called low ambiguity zone (LAZ) which is a small area of the corresponding ambiguity function of interest defined by the certain Doppler frequency and delay. Such an LAZ will reduce to a zero ambiguity zone (ZAZ) if the maximum ambiguity values of interest are zero. In this paper, we derive a set of theoretical bounds on periodic LAZ/ZAZ of unimodular DRSs with and without spectral constraints, which include the existing bounds on periodic global ambiguity function as special cases. These bounds may be used as theoretical design guidelines to measure the optimality of sequences against Doppler effect. We then introduce four optimal constructions of DRSs with respect to the derived ambiguity lower bounds based on some algebraic tools such as characters over finite field and cyclic difference sets.}
}


@article{DBLP:journals/jsac/XiaoZ22,
	author = {Zhiqiang Xiao and
                  Yong Zeng},
	title = {Waveform Design and Performance Analysis for Full-Duplex Integrated
                  Sensing and Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1823--1837},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155509},
	doi = {10.1109/JSAC.2022.3155509},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XiaoZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrated sensing and communication (ISAC) is a promising technology to fully utilize the precious spectrum and hardware in wireless systems, which has attracted significant attentions recently. This paper studies ISAC for the important and challenging monostatic setup, where one single ISAC node wishes to simultaneously sense a radar target while communicating with a communication receiver. Different from most existing schemes that rely on either radar-centric half-duplex (HD) pulsed transmission with information embedding that suffers from extremely low communication rate, or communication-centric waveform that suffers from degraded sensing performance, we propose a novel full-duplex (FD) ISAC scheme that utilizes the waiting time of conventional pulsed radars to transmit communication signals. Compared to radar-centric pulsed waveform with information embedding, the proposed design can drastically increase the communication rate, and also mitigate the sensing eclipsing and near-target blind range issues, as long as the self-interference (SI) is effectively suppressed. On the other hand, compared to communication-centric ISAC waveform, the proposed design has better auto-correlation property as it preserves the classic radar waveform for sensing. Performance analysis is developed by taking into account the residual SI, in terms of the probability of detection and ambiguity function for sensing, as well as the spectrum efficiency for communication. Numerical results are provided to show the significant performance gain of our proposed design over benchmark schemes.}
}


@article{DBLP:journals/jsac/ShiLZC22,
	author = {Qin Shi and
                  Liang Liu and
                  Shuowen Zhang and
                  Shuguang Cui},
	title = {Device-Free Sensing in {OFDM} Cellular Network},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1838--1853},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155543},
	doi = {10.1109/JSAC.2022.3155543},
	timestamp = {Thu, 23 Nov 2023 13:15:01 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ShiLZC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considers device-free sensing in an orthogonal frequency division multiplexing (OFDM) cellular network to enable integrated sensing and communication (ISAC). A novel two-phase sensing framework is proposed to localize the passive targets that cannot transmit/receive reference signals to/from the base stations (BSs), where the ranges of the targets are estimated based on their reflected OFDM signals to the BSs in Phase I, and the location of each target is estimated based on its ranges to different BSs in Phase II. Specifically, in Phase I, we design a model-free range estimation approach by leveraging the OFDM channel estimation technique for determining the delay values of all the two-way BS-target-BS paths, which does not rely on any BS-target channel model. In Phase II, we reveal that ghost targets may be falsely detected in some cases as all the targets reflect the same signals to the BSs, which thus do not know how to match each estimated range with the right target. Interestingly, we show that the above data association issue is not a fundamental limitation for device-free sensing: under the ideal case of perfect range estimation in Phase I, the probability for ghost targets to exist is proved to be negligible when the targets are randomly located. Moreover, under the practical case of imperfect range estimation in Phase I, we propose an efficient algorithm for joint data association and target localization in Phase II. Numerical results show that our proposed two-phase framework can achieve very high accuracy in the localization of passive targets, which increases with the system bandwidth.}
}


@article{DBLP:journals/jsac/LiYLWYBN22,
	author = {Shuangyang Li and
                  Weijie Yuan and
                  Chang Liu and
                  Zhiqiang Wei and
                  Jinhong Yuan and
                  Baoming Bai and
                  Derrick Wing Kwan Ng},
	title = {A Novel {ISAC} Transmission Framework Based on Spatially-Spread Orthogonal
                  Time Frequency Space Modulation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1854--1872},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155538},
	doi = {10.1109/JSAC.2022.3155538},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiYLWYBN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a novel integrated sensing and communication (ISAC) transmission framework based on the spatially spread orthogonal time frequency space (SS-OTFS) modulation by considering the fact that communication channel strengths cannot be directly obtained from radar sensing. We first propose the concept of SS-OTFS modulation, where the key novelty is the angular domain discretization enabled by the spatial spreading/de-spreading. This discretization gives rise to simple and insightful effective models for both radar sensing and communication, which results in simplified designs for the related estimation and detection problems. In particular, we design simple beam tracking, angle estimation, and power allocation schemes for radar sensing, by utilizing the special structure of the effective radar sensing matrix. Meanwhile, we provide a detailed analysis on the pair-wise error probability (PEP) for communication, which unveils the key conditions for both precoding and power allocation designs for communication. Based on those conditions, we design a symbol-wise precoding scheme for communication based only on the delay, Doppler, and angle estimates from radar sensing, without the a priori knowledge of the communication channel fading coefficients, and also propose a suitable power allocation. Furthermore, we notice that radar sensing and communication requires different power allocations. Therefore, we discuss the performances of both the radar sensing and communication with different power allocations and show that the power allocation should be designed leaning towards radar sensing in practical scenarios. The effectiveness of the proposed ISAC transmission framework is verified by our numerical results, which also agree with our analysis and discussions.}
}


@article{DBLP:journals/jsac/WuZHG22,
	author = {Kai Wu and
                  J. Andrew Zhang and
                  Xiaojing Huang and
                  Y. Jay Guo},
	title = {Integrating Low-Complexity and Flexible Sensing Into Communication
                  Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1873--1889},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3156649},
	doi = {10.1109/JSAC.2022.3156649},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WuZHG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrating sensing into standardized communication systems can potentially benefit many consumer applications that require both radio frequency functions. However, without an effective sensing method, such integration may not achieve the expected gains of cost and energy efficiency. Existing sensing methods, which use communication payload signals, either have limited sensing performance or suffer from high complexity. In this paper, we develop a novel and flexible sensing framework which has a complexity only dominated by a Fourier transform and also provides the flexibility in adapting to different sensing needs. We propose to segment a whole block of echo signal evenly into sub-blocks; adjacent ones are allowed to overlap. We design a virtual cyclic prefix (VCP) for each sub-block that allows us to employ two common ways of removing communication data symbols and generate two types of range-Doppler maps (RDMs) for sensing. We perform a comprehensive analysis of the signal components in the RDMs, proving that their interference-plus-noise (IN) terms are approximately Gaussian distributed. The statistical properties of the distributions are derived, which leads to the analytical comparisons between the two RDMs as well as between the prior and our sensing methods. Moreover, the impact of the lengths of sub-block, VCP and overlapping signal on sensing performance is analyzed. Criteria for designing these lengths for better sensing performance are also provided. Extensive simulations validate the superiority of the proposed sensing framework over prior methods in terms of signal-to-IN ratios in RDMs, detecting performance and flexibility.}
}


@article{DBLP:journals/jsac/ChengL22,
	author = {Ziyang Cheng and
                  Bin Liao},
	title = {QoS-Aware Hybrid Beamforming and {DOA} Estimation in Multi-Carrier
                  Dual-Function Radar-Communication Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1890--1905},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155529},
	doi = {10.1109/JSAC.2022.3155529},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChengL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, the issues of transmit hybrid beamforming (HBF) design and direction-of-arrival (DOA) estimation in multi-carrier dual-function radar-communication (DFRC) systems, in consideration of quality-of-service (QoS) for multiple users (MUs), are investigated. In the designed system, communication symbols are embedded into radar pulse interval with multiple orthogonal waveforms, and the HBF is optimized to focus the transmit energy within the spatial sectors of interest by taking the QoS requirement for MUs into account. The problem involving these considerations is formulated as the minimization of mean squared error (MSE) between the achieved spatial spectrum and a desired one, subject to constraints of communication QoS, constant modulus, power and orthogonality. Accordingly, a consensus alternating direction method of multipliers (consensus-ADMM) framework based on weighted mean-square error minimization (WMMSE) is devised to tackle the resultant nonconvex problem. Further, the closed-form solutions of the primal variables are derived. Additionally, the MUltiple SIgnal Classification (MUSIC)-based DOA estimation with the designed HBF architecture is presented, and the corresponding Cramér-Rao bound is derived. Numerical simulations are performed to demonstrate the effectiveness of the proposed designs.}
}


@article{DBLP:journals/jsac/WuHCHY22,
	author = {Wenhua Wu and
                  Guojun Han and
                  Yunhe Cao and
                  Yongwei Huang and
                  Tat Soon Yeo},
	title = {{MIMO} Waveform Design for Dual Functions of Radar and Communication
                  With Space-Time Coding},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1906--1917},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155508},
	doi = {10.1109/JSAC.2022.3155508},
	timestamp = {Thu, 15 Feb 2024 19:05:32 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WuHCHY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sharing a multiple-input multiple-output (MIMO) radar, the single platform can achieve dual functions of radar and communication (DFRC) within the same frequency spectrum, via the same transmit waveforms. In this paper, a space-time coding scheme is developed for transmit beamforming of DFRC and embedding communication information, without their cross-interference. For transmit beampattern design of DFRC, the shape approximation and integrated power approximation criteria are adopted respectively for waveforms optimization with the constant-envelope constraints of transmit waveforms and the equivalent signal in the communication direction. Based on the space-time coding scheme, the direct constellation mapping (DCM) and phase-rotation constellation mapping (PRCM) methods are proposed to embed information symbols. It turns out that the proposed space-time coding scheme for information constellation mapping can prevent missing information symbols and have better performance in bit-error rate (BER), compared to the existing information-embedding techniques. Moreover, the scheme can reduce the dependence of the communication data rate on radar pulse repetition frequency (PRF). Simulation results are presented to demonstrate the effectiveness of the proposed methods.}
}


@article{DBLP:journals/jsac/LiuLLS22,
	author = {Rang Liu and
                  Ming Li and
                  Qian Liu and
                  A. Lee Swindlehurst},
	title = {Joint Waveform and Filter Designs for STAP-SLP-Based {MIMO-DFRC} Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1918--1931},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155501},
	doi = {10.1109/JSAC.2022.3155501},
	timestamp = {Mon, 28 Aug 2023 21:38:10 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuLLS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dual-function radar-communication (DFRC), which can simultaneously perform both radar and communication functionalities using the same hardware platform, spectral resource and transmit waveform, is a promising technique for realizing integrated sensing and communication (ISAC). Space-time adaptive processing (STAP) in multi-antenna radar systems is the primary tool for detecting moving targets in the presence of strong clutter. The idea of joint spatial-temporal optimization in STAP-based radar systems is consistent with the concept of symbol-level precoding (SLP) for multi-input multi-output (MIMO) communications, which optimizes the transmit waveform for each of the transmitted symbols. In this paper, we combine STAP and SLP and propose a novel STAP-SLP-based DFRC system that enjoys the advantages of both techniques. The radar output signal-to-interference-plus-noise ratio (SINR) is maximized by jointly optimizing the transmit waveform and receive filter, while satisfying the communication quality-of-service (QoS) constraint and various waveform constraints including constant-modulus, similarity and peak-to-average power ratio (PAPR). An efficient algorithm framework based on majorization-minimization (MM) and nonlinear equality constrained alternative direction method of multipliers (neADMM) methods is proposed to solve these complicated non-convex optimization problems. Simulation results verify the effectiveness of the proposed STAP-SLP-based MIMO-DRFC scheme and the associate algorithms.}
}


@article{DBLP:journals/jsac/LiuHL22,
	author = {Xiang Liu and
                  Tianyao Huang and
                  Yimin Liu},
	title = {Transmit Design for Joint {MIMO} Radar and Multiuser Communications
                  With Transmit Covariance Constraint},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1932--1950},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155512},
	doi = {10.1109/JSAC.2022.3155512},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuHL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider the waveform design of a multiple-input multiple-output (MIMO) transmitter which simultaneously functions as a MIMO radar and a base station for downlink multiuser communications. In addition to a power constraint, we require the covariance of the transmit waveform be equal to a given optimal covariance for MIMO radar, to guarantee the radar performance. With this constraint, we formulate and solve the signal-to-interference-plus-noise ratio (SINR) balancing problem for multiuser transmit beamforming via convex optimization. Considering that the interference cannot be completely eliminated with this constraint, we introduce dirty paper coding (DPC) to further cancel the interference, and formulate the SINR balancing and sum rate maximization problem in the DPC regime. Although both of the two problems are non-convex, we show that they can be reformulated to convex optimizations via the Lagrange and downlink-uplink duality. In addition, we propose gradient projection based algorithms to solve the equivalent dual problem of SINR balancing, in both transmit beamforming and DPC regimes. The simulation results demonstrate significant performance improvement of DPC over transmit beamforming, and also indicate that the degrees of freedom for the communication transmitter is restricted by the rank of the covariance.}
}


@article{DBLP:journals/jsac/JohnstonVGLW22,
	author = {Jeremy Johnston and
                  Luca Venturino and
                  Emanuele Grossi and
                  Marco Lops and
                  Xiaodong Wang},
	title = {{MIMO} {OFDM} Dual-Function Radar-Communication Under Error Rate and
                  Beampattern Constraints},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1951--1964},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3156651},
	doi = {10.1109/JSAC.2022.3156651},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/JohnstonVGLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work we consider a multiple-input multiple-output (MIMO) dual-function radar-communication (DFRC) system, which senses multiple spatial directions and serves multiple users. Upon resorting to an orthogonal frequency division multiplexing (OFDM) transmission format and a differential phase shift keying (DPSK) modulation, we study the design of the radiated waveforms and of the receive filters employed by the radar and the users. The approach is communication-centric, in the sense that a radar-oriented objective is optimized under constraints on the average transmit power, the power leakage towards specific directions, and the error rate of each user, thus safeguarding the communication quality of service (QoS). We adopt a unified design approach allowing a broad family of radar objectives, including both estimation- and detection-oriented merit functions. We devise a suboptimal solution based on alternating optimization of the involved variables, a convex restriction of the feasible search set, and minorization-maximization, offering a single algorithm for all of the radar merit functions in the considered family. Finally, the performance is inspected through numerical examples.}
}


@article{DBLP:journals/jsac/YuYXCHH22,
	author = {Xiaoyou Yu and
                  Qi Yang and
                  Zhu Xiao and
                  Hongyang Chen and
                  Vincent Havyarimana and
                  Zhu Han},
	title = {A Precoding Approach for Dual-Functional Radar-Communication System
                  With One-Bit DACs},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1965--1977},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155532},
	doi = {10.1109/JSAC.2022.3155532},
	timestamp = {Sat, 30 Sep 2023 10:20:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YuYXCHH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate the precoder design for multiple-input multiple-output (MIMO) dual-functional radar-communication (DFRC) system with one-bit digital-to-analog converters (DACs). In order to form the dual-functional beam-pattern, we formulate the precoding problem as a weighted optimization problem with the constant modulus constraint, which aims at minimizing the average error power and guaranteeing radar waveform similarity. The problem is divided into three sub-problems corresponding to the multiple variables, i.e., the precoding factor, transmit signal matrix, and radar waveform matrix. Due to the discrete and non-convex properties of the optimization problem, we propose a multi-variable alternating minimization (MVAM) framework to achieve the near-optimal solutions. The precoding factor and radar waveform can be solved in closed-forms. For the transmit signal matrix, we devise a binary particle swarm optimization-simulated annealing (BPSO-SA) algorithm to obtain it under the MVAM framework. Extensive simulations validate the effectiveness of the proposed approach under various scenarios, including the case without perfect channel state information. The simulation results show that, compared with existing non-linear precoders, the proposed approach achieves 7dB SNR gain at the bit error rate of 10 −4 in the 8-antenna system, and the gain of SNR is 0.2dB in the massive MIMO system with 128 antennas.}
}


@article{DBLP:journals/jsac/MuLGLH22,
	author = {Xidong Mu and
                  Yuanwei Liu and
                  Li Guo and
                  Jiaru Lin and
                  Lajos Hanzo},
	title = {NOMA-Aided Joint Radar and Multicast-Unicast Communication Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1978--1992},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155524},
	doi = {10.1109/JSAC.2022.3155524},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/MuLGLH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The novel concept of non-orthogonal multiple access (NOMA) aided joint radar and multicast-unicast communication (Rad-MU-Com) is investigated. Employing the same spectrum resource, a multi-input-multi-output (MIMO) dual-functional radar-communication (DFRC) base station detects the radar-centric users (R-user), while transmitting mixed multicast-unicast messages both to the R-user and to the communication-centric user (C-user). In particular, the multicast information is intended for both the R- and C-users, whereas the unicast information is only intended for the C-user. More explicitly, NOMA is employed to facilitate this double spectrum sharing , where the multicast and unicast signals are superimposed in the power domain and the superimposed communication signals are also exploited as radar probing waveforms. First, a beamformer-based NOMA-aided joint Rad-MU-Com framework is proposed for the system having a single R-user and a single C-user. Based on this framework, the unicast rate maximization problem is formulated by optimizing the beamformers employed, while satisfying the rate requirement of multicast and the predefined accuracy of the radar beam pattern. The resultant non-convex optimization problem is solved by a penalty-based iterative algorithm to find a high-quality near-optimal solution. Next, the system is extended to the scenario of multiple pairs of R- and C-users, where a cluster-based NOMA-aided joint Rad-MU-Com framework is proposed. A joint beamformer design and power allocation optimization problem is formulated for the maximization of the sum of the unicast rate at each C-user, subject to the constraints on both the minimum multicast rate for each R&C pair and on accuracy of the radar beam pattern for detecting multiple R-users. The resultant joint optimization problem is efficiently solved by another penalty-based iterative algorithm developed. Finally, our numerical results reveal that significant performance gains can be achieved by the proposed schemes over the benchmark schemes employing conventional transmission strategies.}
}


@article{DBLP:journals/jsac/BaiLHZ22,
	author = {Lin Bai and
                  Jiexun Liu and
                  Rui Han and
                  Wei Zhang},
	title = {Wireless Radar Sensor Networks: Epidemiological Modeling and Optimization},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {6},
	pages = {1993--2005},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155549},
	doi = {10.1109/JSAC.2022.3155549},
	timestamp = {Thu, 02 Jun 2022 16:42:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/BaiLHZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To extend the conventional wireless sensor networks (WSNs) to support wider applications such as intruder detection and border security monitoring, active radar sensors are introduced into WSNs to further enhance their capability, thus forming wireless radar sensor networks (WRSNs). To improve the network efficiency, the technology of integrated sensing and communication (ISAC) can be applied to co-design the sensing and communication functionalities of radar sensors. Since the cooperative operations of WRSNs require effective information interaction among radar sensors, data dissemination techniques need to be investigated, which become even more critical in desolate areas without the coverage of the base stations (BSs). Therefore, in this paper, a duty cycling mechanism is applied to the network to enhance the usage of WRSNs and support data dissemination, where a storage node is deployed to store the data spreading from radar sensors and a mobile data collector is employed to collect the data from the storage node periodically. Then, the epidemic theory, as an innovative tool for modeling data dissemination, is adopted to analyze the performance of WRSNs. After epidemiological modeling, the density of radar sensors is optimized by the epidemiological analytical method to maximize the throughput of the storage node by jointly considering the functions of radar detection and communication. Simulation results validate the accuracy of analysis, which also show the efficiency of the optimization for data dissemination.}
}


@article{DBLP:journals/jsac/LiuMXHHEB22a,
	author = {Fan Liu and
                  Christos Masouros and
                  Jie Xu and
                  Tony Xiao Han and
                  Aboulnasr Hassanien and
                  Yonina C. Eldar and
                  Stefano Buzzi},
	title = {Guest Editorial Special Issue on Integrated Sensing and Communication
                  - Part {II}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2007--2010},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3157514},
	doi = {10.1109/JSAC.2022.3157514},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuMXHHEB22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This is Part II of the double-part Special Issue (SI) on Integrated Sensing and Communication (ISAC). This SI aims at bringing together contributions from both academia and industry to highlight the recent progress of ISAC, where sensing and communication (S\n$\nC) functionalities are jointly designed to utilize wireless/hardware resources efficiently and to assist each other for mutual benefits. The 32 accepted articles of this SI are arranged into six groups, namely, 1) Fundamental Performance Bounds and Optimization, 2) Time-Frequency Signal Processing, 3) Spatial Signal Processing, 4) Networking and Resource Allocation, 5) ISAC With Emerging Communications Technologies, and 6) ISAC Applications. We kindly refer readers to Part I of this SI for a comprehensive overview written by the Guest Editorial Team, which provides both a bird’s eye view and technical details regarding state-of-the-art ISAC innovations. The contributions made by the papers in Part II are summarized as follows, which correspond to paper groups 4), 5), and 6).}
}


@article{DBLP:journals/jsac/WangLSCW22,
	author = {Ziyi Wang and
                  Zhenyu Liu and
                  Yuan Shen and
                  Andrea Conti and
                  Moe Z. Win},
	title = {Location Awareness in Beyond 5G Networks via Reconfigurable Intelligent
                  Surfaces},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2011--2025},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155542},
	doi = {10.1109/JSAC.2022.3155542},
	timestamp = {Mon, 23 Oct 2023 20:48:24 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangLSCW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Achieving accurate location-awareness in wireless networks requires integrated sensing and communication (ISAC), where optimization, signal processing, and data fusion are performed under a common framework. The efficiency of ISAC in complex wireless environments can be improved via the use of reconfigurable intelligent surfaces (RISs). This paper introduces the concept of continuous intelligent surface (CIS) and establishes the fundamental limits of RIS-aided ISAC systems, specifically, an RIS-aided localization and communication system. In particular, this paper considers two types of RISs, namely CISs and discrete intelligent surfaces (DISs). First, this paper proposes a general signal model for RIS-aided localization and communication valid for both near-field and far-field scenarios, and then theoretical limits on the localization and communication performance are derived. Based on the proposed model, Fisher information analyses of the localization performance in networks with RISs are performed. Numerical results show that RISs with optimized phase responses can improve the received signal-to-noise ratio (SNR) and spectral efficiency of communication, and the localization accuracy significantly.}
}


@article{DBLP:journals/jsac/WuMSO22,
	author = {Linlong Wu and
                  Kumar Vijay Mishra and
                  M. R. Bhavani Shankar and
                  Bj{\"{o}}rn E. Ottersten},
	title = {Resource Allocation in Heterogeneously-Distributed Joint Radar-Communications
                  Under Asynchronous Bayesian Tracking Framework},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2026--2042},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3157371},
	doi = {10.1109/JSAC.2022.3157371},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WuMSO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optimal allocation of shared resources is key to deliver the promise of jointly operating radar and communications systems. In this paper, unlike prior works which examine synergistic access to resources in colocated joint radar-communications or among identical systems, we investigate this problem for a distributed system comprising heterogeneous radars and multi-tier communications. In particular, we focus on resource allocation in the context of multi-target tracking (MTT) while maintaining stable communications connections. By simultaneously allocating the available power, dwell time and shared bandwidth, we improve the MTT performance under a Bayesian tracking framework and guarantee the communications throughput. Our\na\nlter\nn\nating allo\nc\nation of\nh\neterogene\no\nus\nr\nesources (ANCHOR) approach solves the resulting non-convex problem based on the alternating optimization method that monotonically improves the Bayesian Cramér-Rao bound. Numerical experiments demonstrate that ANCHOR significantly improves the tracking error over two baseline allocations and stability under different target scenarios and radar-communications network distributions.}
}


@article{DBLP:journals/jsac/PucciPG22,
	author = {Lorenzo Pucci and
                  Enrico Paolini and
                  Andrea Giorgetti},
	title = {System-Level Analysis of Joint Sensing and Communication Based on
                  5G New Radio},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2043--2055},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155522},
	doi = {10.1109/JSAC.2022.3155522},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/PucciPG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work investigates a multibeam system for joint sensing and communication (JSC) based on multiple-input multiple-output (MIMO) 5G new radio (NR) waveforms. In particular, we consider a base station (BS) acting as a monostatic sensor that estimates the range, speed, and direction of arrival (DoA) of multiple targets via beam scanning using a fraction of the transmitted power. The target position is then obtained via range and DoA estimation. We derive the sensing performance in terms of probability of detection and root mean squared error (RMSE) of position and velocity estimation of a target under line-of-sight (LOS) conditions. Furthermore, we evaluate the system performance when multiple targets are present, using the optimal sub-pattern assignment (OSPA) metric. Finally, we provide an in-depth investigation of the dominant factors that affect performance, including the fraction of power reserved for sensing.}
}


@article{DBLP:journals/jsac/LiuZLZLP22,
	author = {Xiangnan Liu and
                  Haijun Zhang and
                  Keping Long and
                  Mingyu Zhou and
                  Yonghui Li and
                  H. Vincent Poor},
	title = {Proximal Policy Optimization-Based Transmit Beamforming and Phase-Shift
                  Design in an IRS-Aided {ISAC} System for the THz Band},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2056--2069},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3158696},
	doi = {10.1109/JSAC.2022.3158696},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuZLZLP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, an IRS-aided integrated sensing and communications (ISAC) system operating in the terahertz (THz) band is proposed to maximize the system capacity. Transmit beamforming and phase-shift design are transformed into a universal optimization problem with ergodic constraints. Then the joint optimization of transmit beamforming and phase-shift design is achieved by gradient-based, primal-dual proximal policy optimization (PPO) in the multi-user multiple-input single-output (MISO) scenario. Specifically, the actor part generates continuous transmit beamforming and the critic part takes charge of discrete phase shift design. Based on the MISO scenario, we investigate a distributed PPO (DPPO) framework with the concept of multi-threading learning in the multi-user multiple-input multiple-output (MIMO) scenario. Simulation results demonstrate the effectiveness of the primal-dual PPO algorithm and its multi-threading version in terms of transmit beamforming and phase-shift design.}
}


@article{DBLP:journals/jsac/ShaoYMCZ22,
	author = {Xiaodan Shao and
                  Changsheng You and
                  Wenyan Ma and
                  Xiaoming Chen and
                  Rui Zhang},
	title = {Target Sensing With Intelligent Reflecting Surface: Architecture and
                  Performance},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2070--2084},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155546},
	doi = {10.1109/JSAC.2022.3155546},
	timestamp = {Mon, 26 Jun 2023 20:51:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ShaoYMCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intelligent reflecting surface (IRS) has emerged as a promising technology to reconfigure the radio propagation environment by dynamically controlling wireless signal’s amplitude and/or phase via a large number of reflecting elements. In contrast to the vast literature on studying IRS’s performance gains in wireless communications, we study in this paper a new application of IRS for sensing/localizing targets in wireless networks. Specifically, we propose a new self-sensing IRS architecture where the IRS controller is capable of transmitting probing signals that are not only directly reflected by the target (referred to as the direct echo link), but also consecutively reflected by the IRS and then the target (referred to as the IRS-reflected echo link). Moreover, dedicated sensors are installed at the IRS for receiving both the direct and IRS-reflected echo signals from the target, such that the IRS can sense the direction of its nearby target by applying a customized multiple signal classification (MUSIC) algorithm. However, since the angle estimation mean square error (MSE) by the MUSIC algorithm is intractable, we propose to optimize the IRS passive reflection for maximizing the average echo signals’ total power at the IRS sensors and derive the resultant Cramer-Rao bound (CRB) of the angle estimation MSE. Last, numerical results are presented to show the effectiveness of the proposed new IRS sensing architecture and algorithm, as compared to other benchmark sensing systems/algorithms.}
}


@article{DBLP:journals/jsac/DingWZLL22,
	author = {Changfeng Ding and
                  Jun{-}Bo Wang and
                  Hua Zhang and
                  Min Lin and
                  Geoffrey Ye Li},
	title = {Joint {MIMO} Precoding and Computation Resource Allocation for Dual-Function
                  Radar and Communication Systems With Mobile Edge Computing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2085--2102},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3157389},
	doi = {10.1109/JSAC.2022.3157389},
	timestamp = {Fri, 29 Jul 2022 15:16:51 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/DingWZLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, an integrated communication, radar sensing, and mobile-edge computing (CRMEC) architecture is developed, where user terminals (UTs) perform radar sensing and computation offloading simultaneously at the same spectrum by using multiple-input and multiple-output (MIMO) arrays and dual-function radar-communication techniques. We formulate a multi-objective optimization problem to jointly consider the performance of multi-UT MIMO radar beampattern design and computation offloading energy consumption while jointly optimizing individual transmit precoding for radar and communication and computation resource allocation. To address the optimization problem, we first decompose the it into three subproblems and adopt an iterative optimization algorithm. Specifically, quadratic transform based fractional programming methods are used to minimize the offloading energy consumption. The design objective of MIMO radar beampattern is handled by the first-order Taylor expansion. Transmit precoding is designed to optimize radar sensing and computation task offloading. The local and edge computation resource allocation are obtained in closed-form. Numerical results verify the effectiveness of the proposed algorithms. The proposed CRMEC architecture can generate the desired multi-UT MIMO radar beampattern and perform computation offloading simultaneously.}
}


@article{DBLP:journals/jsac/ChangTYTC22,
	author = {Bo Chang and
                  Wei Tang and
                  Xiaoyu Yan and
                  Xin Tong and
                  Zhi Chen},
	title = {Integrated Scheduling of Sensing, Communication, and Control for mmWave/THz
                  Communications in Cellular Connected {UAV} Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2103--2113},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3157366},
	doi = {10.1109/JSAC.2022.3157366},
	timestamp = {Wed, 01 May 2024 10:27:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChangTYTC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By providing ultra-high transmission data rate, millimeter wave (mmWave) and terahertz (THz) communications are promising to enable backhaul data transmission in cellular connected unmanned aerial vehicle (UAV) networks. In such networks, with little or no human assistance, connected autonomous UAVs (CA-UAV) can build air-ground networks and achieve seamless wide-area coverage. With the usage of high frequency (i.e., mmWave/THz), radio/radar sensing function is expected to be achieved in wireless networks, which can be used to track UAV for beam tracking in mmWave/THz communications and motion control of UAV. However, it is extremely difficult to jointly design sensing, communication, and motion control since they have been developing in relatively parallel with limited intersections. In this paper, we propose a new integrated scheduling method of sensing, communication, and control for mmWave/THz communications in UAV networks to enable data transmission of the backhaul from UAV to the ground base station (BS). In the proposed method, we first analyze the interactions among sensing, communication, and motion control, where sensing and motion control are strongly coupled to form the sensing-control pattern. Then, we provide a new definition from motion control perspective, i.e., state-to-noise-ratio, which links the relationship between sensing-control pattern activation and data rate determined by beam alignment in mmWave/THz communications. Finally, a closed-form expression is obtained for data rate triggered sensing-control pattern activation design, where both data rate requirement in mmWave/THz communications and motion control performance of UAV are guaranteed. Simulation results show remarkable performance of the proposed method.}
}


@article{DBLP:journals/jsac/ZhangZDRHPS22,
	author = {Haobo Zhang and
                  Hongliang Zhang and
                  Boya Di and
                  Marco Di Renzo and
                  Zhu Han and
                  H. Vincent Poor and
                  Lingyang Song},
	title = {Holographic Integrated Sensing and Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2114--2130},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155548},
	doi = {10.1109/JSAC.2022.3155548},
	timestamp = {Mon, 12 Feb 2024 16:07:18 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZDRHPS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To overcome spectrum congestion, a promising approach is to integrate sensing and communication (ISAC) functions in one hardware platform. Recently, metamaterial antennas, whose tunable radiation elements are arranged more densely than those of traditional multiple-input-multiple-output (MIMO) arrays, have been developed to enhance the sensing and communication performance by offering a finer controllability of the antenna beampattern. In this paper, we propose a holographic beamforming scheme, which is enabled by metamaterial antennas with tunable radiated amplitudes, that jointly performs sensing and communication. However, it is challenging to design the beamformer for ISAC functions by taking into account the unique amplitude-controlled structure of holographic beamforming. To address this challenge, we formulate an integrated sensing and communication problem to optimize the beamformer, and design a holographic beamforming optimization algorithm to efficiently solve the formulated problem. A lower bound for the maximum beampattern gain is provided through theoretical analysis, which reveals the potential performance enhancement gain that is obtained by densely deploying several elements in a metamaterial antenna. Simulation results substantiate the theoretical analysis and show that the maximum beamforming gain of a metamaterial antenna that utilizes the proposed holographic beamforming scheme can be increased by at least 50% compared with that of a traditional MIMO array of the same size. In addition, the cost of the proposed scheme is lower than that of a traditional MIMO scheme while providing the same ISAC performance.}
}


@article{DBLP:journals/jsac/HeCMY22,
	author = {Yinghui He and
                  Yunlong Cai and
                  Hao Mao and
                  Guanding Yu},
	title = {RIS-Assisted Communication Radar Coexistence: Joint Beamforming Design
                  and Analysis},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2131--2145},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155507},
	doi = {10.1109/JSAC.2022.3155507},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HeCMY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrated sensing and communication (ISAC) has been regarded as one of the most promising technologies for future wireless communications. However, the mutual interference in the communication radar coexistence system cannot be ignored. Inspired by the studies of reconfigurable intelligent surface (RIS), we propose a double-RIS-assisted coexistence system where two RISs are deployed for enhancing communication signals and suppressing mutual interference. We aim to jointly optimize the beamforming of RISs and radar to maximize communication performance while maintaining radar detection performance. The investigated problem is challenging, and thus we transform it into an equivalent but more tractable form by introducing auxiliary variables. Then, we propose a penalty dual decomposition (PDD)-based algorithm to solve the resultant problem. Moreover, we consider two special cases: the large radar transmit power scenario and the low radar transmit power scenario. For the former, we prove that the beamforming design is only determined by the communication channel and the corresponding optimal joint beamforming strategy can be obtained in closed-form. For the latter, we minimize the mutual interference via the block coordinate descent (BCD) method. By combining the solutions of these two cases, a low-complexity algorithm is also developed. Finally, simulation results show that both the PDD-based and low-complexity algorithms outperform benchmark algorithms.}
}


@article{DBLP:journals/jsac/YangWJ22,
	author = {Jie Yang and
                  Chao{-}Kai Wen and
                  Shi Jin},
	title = {Hybrid Active and Passive Sensing for {SLAM} in Wireless Communication
                  Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2146--2163},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3156630},
	doi = {10.1109/JSAC.2022.3156630},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YangWJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrating sensing functions into future mobile equipment has become an important trend. Realizing different types of sensing and achieving mutual enhancement under the existing communication hardware architecture is a crucial challenge in realizing the deep integration of sensing and communication. In the 5G New Radio context, active sensing can be performed through uplink beam sweeping on the user equipment (UE) side to observe the surrounding environment. In addition, the UE can perform passive sensing through downlink channel estimation to measure the multipath component (MPC) information. This study is the first to develop a hybrid simultaneous localization and mapping (SLAM) mechanism that combines active and passive sensing, in which mutual enhancement between the two sensing modes is realized in communication systems. Specifically, we first establish a common feature associated with the reflective surface to bridge active and passive sensing, thus enabling information fusion. Based on the common feature, we can attain physical anchor initialization through MPC with the assistance of active sensing. Then, we extend the classic probabilistic data association SLAM mechanism to achieve UE localization and continuously refine the physical anchor and target reflections through the subsequent passive sensing. Numerical results show that the proposed hybrid active and passive sensing-based SLAM mechanism can work successfully in tricky scenarios without any prior information on the floor plan, anchors, or agents. Moreover, the proposed algorithm demonstrates significant performance gains compared with active or passive sensing only mechanisms.}
}


@article{DBLP:journals/jsac/NiuWZZYZ22,
	author = {Kai Niu and
                  Xuanzhi Wang and
                  Fusang Zhang and
                  Rong Zheng and
                  Zhiyun Yao and
                  Daqing Zhang},
	title = {Rethinking Doppler Effect for Accurate Velocity Estimation With Commodity
                  WiFi Devices},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2164--2178},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155523},
	doi = {10.1109/JSAC.2022.3155523},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/NiuWZZYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Enabling pervasive WiFi devices with non-contact sensing capability is an important topic in the field of integrated sensing and communication. Doppler effect has been widely exploited to estimate targets’ velocity from wireless signals. However, the separation of signal sources and receivers complicates the relationship between Doppler frequency shift (DFS) and target velocity in WiFi-based non-contact sensing systems. In contrast to existing works that rely on either approximated relations or coarse-grained information such as whether a target is moving toward or away from WiFi transceivers, this paper investigates rigorously the dependency of velocity estimation accuracy on target locations and headings in WiFi sensing systems. The theoretical insights allow us to derive a closed-form solution and understand the fundamental limitation of velocity estimation. To optimize velocity estimation performance, we devise a receiving device selection scheme that dynamically chooses the optimal set of receivers among multiple available WiFi devices. A prototype real-time target tracking system has been implemented using commodity WiFi devices. Extensive experimental results show that the proposed system outperforms state-of-the-art approaches in velocity estimation and tracking, and is able to achieve\n9.38cm/s\n, 13.42°,\n31.08cm\nmedian errors in speed, heading and location estimation amongst experiments conducted in three indoor environments with three device placements and eight human subjects over 15 trajectories.}
}


@article{DBLP:journals/jsac/GeKKJTVSKW22,
	author = {Yu Ge and
                  Ossi Kaltiokallio and
                  Hyowon Kim and
                  Fan Jiang and
                  Jukka Talvitie and
                  Mikko Valkama and
                  Lennart Svensson and
                  Sunwoo Kim and
                  Henk Wymeersch},
	title = {A Computationally Efficient {EK-PMBM} Filter for Bistatic mmWave Radio
                  {SLAM}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2179--2192},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155504},
	doi = {10.1109/JSAC.2022.3155504},
	timestamp = {Mon, 19 Dec 2022 20:39:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/GeKKJTVSKW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Millimeter wave (mmWave) signals are useful for simultaneous localization and mapping (SLAM), due to their inherent geometric connection to the propagation environment and the propagation channel. To solve the SLAM problem, existing approaches rely on sigma-point or particle-based approximations, leading to high computational complexity, precluding real-time execution. We propose a novel low-complexity SLAM filter, based on the Poisson multi-Bernoulli mixture (PMBM) filter. It utilizes the extended Kalman (EK) first-order Taylor series based Gaussian approximation of the filtering distribution, and applies the track-oriented marginal multi-Bernoulli/Poisson (TOMB/P) algorithm to approximate the resulting PMBM as a Poisson multi-Bernoulli (PMB). The filter can account for different landmark types in radio SLAM and multiple data association hypotheses. Hence, it has an adjustable complexity/performance trade-off. Simulation results show that the developed SLAM filter can greatly reduce the computational cost, while it keeps the good performance of mapping and user state estimation.}
}


@article{DBLP:journals/jsac/ZhangJWZJM22,
	author = {Ronghui Zhang and
                  Chunxiao Jiang and
                  Sheng Wu and
                  Quan Zhou and
                  Xiaojun Jing and
                  Junsheng Mu},
	title = {Wi-Fi Sensing for Joint Gesture Recognition and Human Identification
                  From Few Samples in Human-Computer Interaction},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2193--2205},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155526},
	doi = {10.1109/JSAC.2022.3155526},
	timestamp = {Fri, 12 Jan 2024 21:08:41 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangJWZJM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gesture recognition is the central enabler of human-computer interaction (HCI). In addition to the semantic information contained in gestures, gesture-based user identification can effortlessly enhance HCI system security. Recently, the Wi-Fi-integrated sensing and communication (ISAC) technology has shown great potential in a field hitherto occupied by computer vision and radar sensing. In this work, leveraging Wi-Fi sensing, we propose a system called WiGesID that achieves joint gesture recognition and human identification (JGRHI). The basic idea behind WiGesID is to identify personalized spatiotemporal dynamic patterns from the gestures of different users. Moreover, we develop an effective approach to recognize new categories of gestures and users by computing relation scores between the features of the new category samples and the support samples. To evaluate the performance, we implemented WiGesID and conducted extensive experiments. The results demonstrate that our system outperforms the state-of-the-art method for cross-domain sensing and accurately recognizes new categories, which promotes the use of this application of Wi-Fi sensing in HCI.}
}


@article{DBLP:journals/jsac/ZhangSGWF22,
	author = {Qixun Zhang and
                  Hongzhuo Sun and
                  Xinye Gao and
                  Xinna Wang and
                  Zhiyong Feng},
	title = {Time-Division {ISAC} Enabled Connected Automated Vehicles Cooperation
                  Algorithm Design and Performance Evaluation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2206--2218},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155506},
	doi = {10.1109/JSAC.2022.3155506},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangSGWF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To overcome the bottleneck of unreliable environment sensing caused by sensor failure and obstacle blockage, the cooperation among connected automated vehicles (CAVs) is crucial for the reliable and efficient raw sensing data sharing in order to guarantee the driving safety. Empowered by the narrow beamwidth and high data rate abilities, the millimeter wave (mmWave) communication technology can substantially improve the environment sensing ability among multiple CAVs. In this paper, a mmWave enabled CAVs cooperation algorithm is designed based on the proposed time-division integrated sensing and communication (TD-ISAC) system for raw sensing data sharing among CAVs. Considering various computing abilities at vehicle and infrastructure, a closed-form solution to the V2V or V2V/V2I cooperative communication mode selection is theoretically achieved based on response delay analysis to guarantee the timeliness of raw sensing data sharing. And the age of information based system status update algorithm is proposed for the V2V/V2I collaborative communication mode. The feasibility of the proposed TD-ISAC system is verified by simulation and hardware testbed results. Based on simulation results, the proposed communication mode selection algorithm can effectively minimize the response time delay in different conditions. The mmWave enabled TD-ISAC hardware testbed is developed and the position error of target detection can be reduced by 18.5 % using the sensing data fusion from two vehicles, while the communication throughput remains over 2.2 Gbps.}
}


@article{DBLP:journals/jsac/KongLLZQC22,
	author = {Linghe Kong and
                  Yutong Liu and
                  Yunxin Liu and
                  Le Zheng and
                  Meikang Qiu and
                  Guihai Chen},
	title = {WheelLoc: Practical and Accurate Localization for Wheeled Mobile Targets
                  via Integrated Sensing and Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2219--2232},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3155530},
	doi = {10.1109/JSAC.2022.3155530},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KongLLZQC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Practical and accurate localization systems are important to mobile targets that enable promising services such as navigation and augmented reality. With the proliferation of WiFi, existing WiFi-based localization systems have leveraged RSSI, fingerprints, landmarks, time of arrival, or angle of arrival to locate targets, while no related work pays attention to mobile targets themselves. For wheel-driven mobile targets, such as vehicles, bikes, and wheeled robots, we design and implement WheelLoc, a novel WiFi-based localization system leveraging the rotation of wheels. The specially designed WheelLoc hardware is cost-effective and self-powered with the composition of three commercial antennas and a solar cell, which is also easy to be installed on wheels. A hybrid WheelLoc algorithm is further proposed to realize accurate localization in diverse environments, whether the wheel of targets is static or mobile, indoor or outdoor, on flat or bumpy ground. The movements of individual antennas are exploited to emulate linear, cycloid, and circular antenna arrays using a new formulation of Synthetic Aperture Radar (SAR). Extensive experiments are conducted on bikes in the real world. Performance results demonstrate that WheelLoc does not require any user interaction, yet achieves comparable accuracy with the state-of-the-art localization systems using WiFi.}
}


@article{DBLP:journals/jsac/GaoWLL22,
	author = {Kaixuan Gao and
                  Huiqiang Wang and
                  Hongwu Lv and
                  Wenxue Liu},
	title = {Toward 5G {NR} High-Precision Indoor Positioning via Channel Frequency
                  Response: {A} New Paradigm and Dataset Generation Method},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {7},
	pages = {2233--2247},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3157397},
	doi = {10.1109/JSAC.2022.3157397},
	timestamp = {Tue, 28 Jun 2022 21:07:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GaoWLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Location-based services (LBSs) provide necessary infrastructure for daily life, from bicycle sharing to nursing care. In contrast to traditional positioning methods such as Wi-Fi, Bluetooth, and ultra-wideband (UWB), fifth-generation (5G) networking is defined as a paradigm of integrated sensing and communication (ISAC). With its advantages of wide-range coverage and indoor-outdoor integration, 5G is promising for high-precision positioning in indoor and urban canyon environments. However, 5G location studies face great obstacles due to the lack of commercialized 5G ISAC base stations that support positioning functions as well as publicly available datasets. In this paper, we first propose a dataset generation method, the Multilevel Feature Synthesis Method (Multilevel-FSM), to obtain positioning features. In particular, the features of a multiple-input multiple-output (MIMO) channel are flattened into a single image to increase the information density and improve feature expression, and data augmentation is performed to provide stronger robustness to noise. Subsequently, we devise a specially designed deep learning positioning method, Multipath Res-Inception (MPRI), trained on the proposed dataset to enhance positioning accuracy. Finally, the results of extensive experiments conducted in two typical 5G scenarios (indoors and urban canyon) show that Multilevel-FSM and MPRI outperform state-of-the-art works in accuracy, time overhead and robustness to noise.}
}


@article{DBLP:journals/jsac/LiSOKQH0GE22,
	author = {Geoffrey Ye Li and
                  Walid Saad and
                  Ayfer {\"{O}}zg{\"{u}}r and
                  Peter Kairouz and
                  Zhijin Qin and
                  Jakob Hoydis and
                  Zhu Han and
                  Deniz G{\"{u}}nd{\"{u}}z and
                  Jaafar M. H. Elmirghani},
	title = {The Fifth Issue of the Series on Machine Learning in Communications
                  and Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2251--2253},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3181863},
	doi = {10.1109/JSAC.2022.3181863},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiSOKQH0GE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fourth call for papers of the Series on Machine Learning in Communications and Networks has continued to receive a great number of high-quality papers covering various aspects of intelligent communications, from which we have included 16 original contributions in this issue. In the following, we provide a brief review of these papers according to their topics.}
}


@article{DBLP:journals/jsac/YangGW0X22,
	author = {Yuwen Yang and
                  Feifei Gao and
                  Mingjin Wang and
                  Jiang Xue and
                  Zongben Xu},
	title = {Dynamic Neural Network for {MIMO} Detection},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2254--2266},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180794},
	doi = {10.1109/JSAC.2022.3180794},
	timestamp = {Thu, 25 Aug 2022 08:37:06 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YangGW0X22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Achieving adequate precision in deep learning based communications often requires large network architectures, which results into unacceptable time delay and power consumption. This paper introduces the dynamic neural network (DyNN) into the design of wireless communications systems. DyNN allocates different samples with computation resources on demand by preforming dynamic inferences, thereby reducing the redundant computational cost and enhancing the network efficiency. We design a dynamic depth architecture that allows samples to adaptively skip layers with various dynamic strategies, from which we further develop a c onfidence criterion based d ynamic i mproved DetNet (CD-IDetNet) and a p olicy network based d ynamic i mproved DetNet (PD-IDetNet) for multiple-input multiple-output (MIMO) detection. Specifically, in CD-IDetNet, a confidence criterion is adopted to control samples exiting early, while in PD-IDetNet, policy networks are trained by reinforcement learning to selectively skip layers for varying samples. Simulation results demonstrate that CD-IDetNet and PD-IDetNet detectors can respectively reduce 17.4% and 31.1% computational costs while preserving the full accuracy of IDetNet. Desirable tradeoffs between accuracy and computational complexity can be further achieved by fine-tuning the hyper-parameters of CD-IDetNet and PD-IDetNet. Moreover, over-the-air (OTA) tests are conducted to validate the effectiveness of the proposed detectors in practical systems.}
}


@article{DBLP:journals/jsac/GuoW022,
	author = {Jiajia Guo and
                  Chao{-}Kai Wen and
                  Shi Jin},
	title = {Eliminating {CSI} Feedback Overhead via Deep Learning-Based Data Hiding},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2267--2281},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180806},
	doi = {10.1109/JSAC.2022.3180806},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GuoW022.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Channel state information (CSI) plays a crucial role in the capacity of multiple-input and multiple-output systems, but CSI feedback occupies substantial precious transmission resources in frequency-division duplexing (FDD) systems. In this work, we propose a data hiding-based CSI feedback framework, namely, EliCsiNet, to eliminate the CSI feedback overhead in FDD systems through deep learning. The key idea is to hide/superimpose CSI in transmitted messages (e.g., images) with no transmission resource occupation and few effects on message semantics. Concretely, we introduce a novel neural network framework in which the user extracts and hides CSI features in images, and the base station recovers the CSI from the transmitted images. However, the essential source coding (e.g., JPEG compression) before data transmission causes two problems in the proposed EliCsiNet framework when applied in practical systems. First, the compression inevitably disturbs the information of the hidden CSI in images and affects the CSI reconstruction accuracy. Therefore, a two-stage separable training strategy, which includes coding-free end-to-end and coding-aware decoder-only training, is adopted to reduce these effects. Second, the bit length of the images coded via JPEG is unpredictable and uncontrollable, and CSI superimposition may lead to an increase in the bit length of the coded images. To avoid this issue, we divide a full image into several sub-blocks and select the one with the smallest length increment. Image entropy is also introduced to accelerate block selection. Simulation results demonstrate that the proposed EliCsiNet framework can eliminate the CSI feedback overhead with few effects on the features properties of transmitted images, including image quality and bit length.}
}


@article{DBLP:journals/jsac/Xiao0H0ZD22,
	author = {Zhuoran Xiao and
                  Zhaoyang Zhang and
                  Chongwen Huang and
                  Xiaoming Chen and
                  Caijun Zhong and
                  M{\'{e}}rouane Debbah},
	title = {C-GRBFnet: {A} Physics-Inspired Generative Deep Neural Network for
                  Channel Representation and Prediction},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2282--2299},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180800},
	doi = {10.1109/JSAC.2022.3180800},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/Xiao0H0ZD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we aim to efficiently and accurately predict the static channel impulse response (CIR) with only the user’s position information and a set of channel instances obtained within a certain wireless communication environment. Such a problem is by no means trivial since it needs to reconstruct the high-dimensional information (here the CIR everywhere) from the extremely low-dimensional data (here the location coordinates), which often results in overfitting and large prediction error. To this end, we resort to a novel physics-inspired generative approach. Specifically, we first use a forward deep neural network to infer the positions of all possible images of the source reflected by the surrounding scatterers within that environment, and then use the well-known Gaussian Radial Basis Function network (GRBF) to approximate the amplitudes of all possible propagation paths. We further incorporate the most recently developed sinusoidal representation network (SIREN) into the proposed network to implicitly represent the highly dynamic phases of all possible paths, which usually cannot be well predicted by the conventional neural networks with non-periodic activators. The resultant framework of Cosine-Gaussian Radial Basis Function network (C-GRBFnet) is also extended to the MIMO channel case. Key performance measures including prediction accuracy, convergence speed, network scale and robustness to channel estimation error are comprehensively evaluated and compared with existing popular networks, which show that our proposed network is much more efficient in representing, learning and predicting wireless channels in a given communication environment.}
}


@article{DBLP:journals/jsac/DaiWTSQ0022,
	author = {Jincheng Dai and
                  Sixian Wang and
                  Kailin Tan and
                  Zhongwei Si and
                  Xiaoqi Qin and
                  Kai Niu and
                  Ping Zhang},
	title = {Nonlinear Transform Source-Channel Coding for Semantic Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2300--2316},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180802},
	doi = {10.1109/JSAC.2022.3180802},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/DaiWTSQ0022.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a class of high-efficiency deep joint source-channel coding methods that can closely adapt to the source distribution under the nonlinear transform, it can be collected under the name nonlinear transform source-channel coding (NTSCC). In the considered model, the transmitter first learns a nonlinear analysis transform to map the source data into latent space, then transmits the latent representation to the receiver via deep joint source-channel coding. Our model incorporates the nonlinear transform as a strong prior to effectively extract the source semantic features and provide side information for source-channel coding. Unlike existing conventional deep joint source-channel coding methods, the proposed NTSCC essentially learns both the source latent representation and an entropy model as the prior on the latent representation. Accordingly, novel adaptive rate transmission and hyperprior-aided codec refinement mechanisms are developed to upgrade deep joint source-channel coding. The whole system design is formulated as an optimization problem whose goal is to minimize the end-to-end transmission rate-distortion performance under established perceptual quality metrics. Across test image sources with various resolutions, we find that the proposed NTSCC transmission method generally outperforms both the analog transmission using the standard deep joint source-channel coding and the classical separation-based digital transmission. Notably, the proposed NTSCC method can potentially support future semantic communications due to its content-aware ability and perceptual optimization goal.}
}


@article{DBLP:journals/jsac/0003YLLLN022,
	author = {Chang Liu and
                  Weijie Yuan and
                  Shuangyang Li and
                  Xuemeng Liu and
                  Husheng Li and
                  Derrick Wing Kwan Ng and
                  Yonghui Li},
	title = {Learning-Based Predictive Beamforming for Integrated Sensing and Communication
                  in Vehicular Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2317--2334},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180803},
	doi = {10.1109/JSAC.2022.3180803},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/0003YLLLN022.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the integrated sensing and communication (ISAC) in vehicle-to-infrastructure (V2I) networks. To realize ISAC, an effective beamforming design is essential which however, highly depends on the availability of accurate channel tracking requiring large training overhead and computational complexity. Motivated by this, we adopt a deep learning (DL) approach to implicitly learn the features of historical channels and directly predict the beamforming matrix to be adopted for the next time slot to maximize the average achievable sum-rate of an ISAC system. The proposed method can bypass the need of explicit channel tracking process and reduce the signaling overhead significantly. To this end, a general sum-rate maximization problem with Cramer-Rao lower bounds-based sensing constraints is first formulated for the considered ISAC system taking into account the multiple access interference. Then, by exploiting the penalty method, a versatile unsupervised DL-based predictive beamforming design framework is developed to address the formulated design problem. As a realization of the developed framework, a historical channels-based convolutional long short-term memory (LSTM) network (HCL-Net) is devised for predictive beamforming in the ISAC-based V2I network. Specifically, the convolution and LSTM modules are successively adopted in the proposed HCL-Net to exploit the spatial and temporal dependencies of communication channels to further improve the learning performance. Finally, simulation results show that the proposed predictive method not only guarantees the required sensing performance, but also achieves a satisfactory sum-rate that can approach the upper bound obtained by the genie-aided scheme with the perfect instantaneous channel state information available.}
}


@article{DBLP:journals/jsac/0171022,
	author = {Wei Wang and
                  Wei Zhang},
	title = {Intelligent Reflecting Surface Configurations for Smart Radio Using
                  Deep Reinforcement Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2335--2346},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180787},
	doi = {10.1109/JSAC.2022.3180787},
	timestamp = {Thu, 25 Aug 2022 08:37:06 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/0171022.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intelligent reflecting surface (IRS) is envisioned to change the paradigm of wireless communications from “adapting to wireless channels” to “changing wireless channels”. However, current IRS configuration schemes, consisting of sub-channel estimation and passive beamforming in sequence, conform to the conventional model-based design philosophies and are difficult to be realized practically in the complex radio environment. To create the smart radio environment, we propose a model-free design of IRS control that is independent of the sub-channel channel state information (CSI) and requires the minimum interaction between IRS and the wireless communication system. We firstly model the control of IRS as a Markov decision process (MDP) and apply deep reinforcement learning (DRL) to perform real-time coarse phase control of IRS. Then, we apply extremum seeking control (ESC) as the fine phase control of IRS. Finally, by updating the frame structure, we integrate DRL and ESC in the model-free control of IRS to improve its adaptivity to different channel dynamics. Numerical results show the superiority of our proposed joint DRL and ESC scheme and verify its effectiveness in model-free IRS control without sub-channel CSI.}
}


@article{DBLP:journals/jsac/WangYL22,
	author = {Zhiyuan Wang and
                  Jiancheng Ye and
                  John C. S. Lui},
	title = {Toward Large-Scale Hybrid Edge Server Provision: An Online Mean Field
                  Learning Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2347--2360},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180781},
	doi = {10.1109/JSAC.2022.3180781},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangYL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The efficiency of a large-scale edge computing system primarily depends on three aspects: i) edge server provision, ii) task migration, and iii) computing resource configuration. In this paper, we study the dynamic resource configuration for hybrid edge server provision under two decentralized task migration schemes. We formulate the dynamic resource configuration as an online cost minimization problem, aiming to jointly minimize performance degradation and operation expenditure. Due to the stochastic nature, it is an online learning problem with partial feedback. To address it, we derive a deterministic mean field model to approximate the stochastic edge computing system. We show that the mean field model provides the increasingly accurate full feedback as the system scales. We then propose a learning policy based on the mean field model, and show that our proposed policy performs asymptotically as well as the offline optimal configuration. We provide two ways of setting the policy parameters, which achieve a constant competitive ratio (under certain mild conditions) and a sub-linear regret, respectively. Numerical results show that the mean field model significantly improves the convergence speed. Moreover, our proposed policy under the decentralized task migration schemes considerably reduces the operating cost (by 23%) and incurs little communication overhead.}
}


@article{DBLP:journals/jsac/Wang0SZ22,
	author = {Zhibin Wang and
                  Yong Zhou and
                  Yuanming Shi and
                  Weihua Zhuang},
	title = {Interference Management for Over-the-Air Federated Learning in Multi-Cell
                  Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2361--2377},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180799},
	doi = {10.1109/JSAC.2022.3180799},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/Wang0SZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) over resource-constrained wireless networks has recently attracted much attention. However, most existing studies consider one FL task in single-cell wireless networks and ignore the impact of downlink/uplink inter-cell interference on the learning performance. In this paper, we investigate FL over a multi-cell wireless network, where each cell performs a different FL task and over-the-air computation (AirComp) is adopted to enable fast uplink gradient aggregation. We conduct convergence analysis of AirComp-assisted FL systems, taking into account the inter-cell interference in both the downlink and uplink model/gradient transmissions, which reveals that the distorted model/gradient exchanges induce a gap to hinder the convergence of FL. We characterize the Pareto boundary of the error-induced gap region to quantify the learning performance trade-off among different FL tasks, based on which we formulate an optimization problem to minimize the sum of error-induced gaps in all cells. To tackle the coupling between the downlink and uplink transmissions as well as the coupling among multiple cells, we propose a cooperative multi-cell FL optimization framework to achieve efficient interference management for downlink and uplink transmission design. Results demonstrate that our proposed algorithm achieves much better average learning performance over multiple cells than non-cooperative baseline schemes.}
}


@article{DBLP:journals/jsac/WangCZT022,
	author = {Tianxin Wang and
                  Suhong Chen and
                  Yifei Zhu and
                  Aimin Tang and
                  Xudong Wang},
	title = {LinkSlice: Fine-Grained Network Slice Enforcement Based on Deep Reinforcement
                  Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2378--2394},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180776},
	doi = {10.1109/JSAC.2022.3180776},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangCZT022.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Considering network slicing in a cellular network, one of the most intriguing tasks is slice enforcement over air interfaces across multiple cells. The challenges lie in several aspects. First, resources allocated to different slices must achieve soft isolation at the link level. Second, users’ diverse QoS requirements must be satisfied even when communication links experience fading and interference. Third, long-term slicing policies must be conformed, no matter how unbalanced they are. To address these challenges, link-level slice enforcement is first formulated as a resource allocation problem that minimizes radio resource consumption while ensuring link-level soft slice isolation, guaranteeing users’ diverse QoS requirements, and conforming to slicing policies. Next, this problem is tackled via a deep reinforcement learning (DRL) based approach, through which LinkSlice is designed as an iterative two-stage algorithm. The first stage determines transmission rates for each link based on DRL. It is embedded with a graph neural network (GNN) to characterize link interference. Based on the transmission rates from the first stage, the second stage allocates resources to each slice. Performance results show that LinkSlice converges quickly to a near-optimal solution. It gracefully tackles the three challenges of link-level slice enforcement while further improving throughput by 18.5%.}
}


@article{DBLP:journals/jsac/GuoL0QS022,
	author = {Wei Guo and
                  Ran Li and
                  Chuan Huang and
                  Xiaoqi Qin and
                  Kaiming Shen and
                  Wei Zhang},
	title = {Joint Device Selection and Power Control for Wireless Federated Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2395--2410},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180807},
	doi = {10.1109/JSAC.2022.3180807},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GuoL0QS022.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies the joint device selection and power control scheme for wireless federated learning (FL), considering both the downlink and uplink communications between the parameter server (PS) and the terminal devices. In each round of model training, the PS first broadcasts the global model to the terminal devices in an analog fashion, and then the terminal devices perform local training and upload the updated model parameters to the PS via over-the-air computation (AirComp). First, we propose an AirComp-based adaptive reweighing scheme for the aggregation of local updated models, where the model aggregation weights are directly determined by the uplink transmit power values of the selected devices and which enables the joint learning and communication optimization simply by the device selection and power control. Furthermore, we provide a convergence analysis for the proposed wireless FL algorithm and the upper bound on the expected optimality gap between the expected and optimal global loss values is derived. With instantaneous channel state information (CSI), we formulate the optimality gap minimization problems under both the individual and sum uplink transmit power constraints, respectively, which are shown to be solved by the semidefinite programming (SDR) technique. Numerical results reveal that our proposed wireless FL algorithm achieves close to the best performance by using the ideal FedAvg scheme with error-free model exchange and full device participation.}
}


@article{DBLP:journals/jsac/WangZ0Z0L22,
	author = {Ne Wang and
                  Ruiting Zhou and
                  Lei Jiao and
                  Renli Zhang and
                  Bo Li and
                  Zongpeng Li},
	title = {Preemptive Scheduling for Distributed Machine Learning Jobs in Edge-Cloud
                  Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2411--2425},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180772},
	doi = {10.1109/JSAC.2022.3180772},
	timestamp = {Mon, 28 Aug 2023 21:38:10 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangZ0Z0L22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in 5G and edge computing enable rapid development and deployment of edge-cloud systems, which are ideal for delay-sensitive machine learning (ML) applications such as autonomous driving and smart city. Distributed ML jobs often need to train a large model with enormous datasets, which can only be handled by deploying a distributed set of workers in an edge-cloud system. One common approach is to employ a parameter server (PS) architecture, in which training is carried out at multiple workers, while PSs are used for aggregation and model updates. In this architecture, one of the fundamental challenges is how to dispatch ML jobs to workers and PSs such that the average job completion time (JCT) can be minimized. In this work, we propose a novel online preemptive scheduling framework to decide the location and the execution time window of concurrent workers and PSs upon each job arrival. Specifically, our proposed scheduling framework consists of: i) a job dispatching and scheduling algorithm that assigns each ML job to workers and decides the schedule to train each data chunk; ii) a PS assignment algorithm that determines the placement of PS. We prove theoretically that our proposed algorithm is\nD\nmax\n(1+1/ϵ)\n-competitive with\n(1+ϵ)\n-speed augmentation, where\nD\nmax\nis the maximal number of data chunks in any job. Extensive testbed experiments and trace-driven simulations show that our algorithm can reduce the average JCT by up to 30% compared with state-of-the-art baselines.}
}


@article{DBLP:journals/jsac/0001LLY22,
	author = {Kun Zhu and
                  Jiawei Liang and
                  Juan Li and
                  Changyan Yi},
	title = {Coded Distributed Computing With Predictive Heterogeneous User Demands:
                  {A} Learning Auction Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2426--2439},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180811},
	doi = {10.1109/JSAC.2022.3180811},
	timestamp = {Wed, 10 Apr 2024 16:20:18 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/0001LLY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Coded distributed computing(CDC) has shown great potentials to solve the unexpected delay caused by stragglers in distributed computing. In this paper, we focus on the auction design for efficient resource allocation in CDC. Specifically, we aim to design a learning auction mechanism to handle heterogeneous user demands and also to free users from the complexity of specifying valuations for resource combinations, which increases exponentially with the resource dimensions. The user demand type is heterogeneous according to different variation trends of the value with finish time and workload, which is modeled by deep learning. The platform would allocate resources according to the user value function. Then users do not need to consider the complex relationship between uncertain finish time and resource configuration in CDC. Due to the inference error of the learning model and the complexity of calculating uncertain finish time, the considered social welfare optimization problem is a non-linear and non-convex integer problem. Even worse, the typical VCG-based payment scheme cannot guarantee truthfulness with the inference error. In response to these difficulties, we transform the social welfare optimization problem into a mixed integer programming problem which already has efficient solutions. The social welfare gap caused by the inference error is analyzed theoretically. The relationship between the utility regret of reporting truthfully and the inference error is also analyzed. We prove that our mechanism satisfies incentive alignment and individual rationality. Extensive experiments show the superiority of our mechanism compared with existing ones.}
}


@article{DBLP:journals/jsac/ZhangZLFSZZPSLY22,
	author = {Shenglin Zhang and
                  Zhenyu Zhong and
                  Dongwen Li and
                  Qiliang Fan and
                  Yongqian Sun and
                  Man Zhu and
                  Yuzhi Zhang and
                  Dan Pei and
                  Jiyan Sun and
                  Yinlong Liu and
                  Hui Yang and
                  Yongqiang Zou},
	title = {Efficient {KPI} Anomaly Detection Through Transfer Learning for Large-Scale
                  Web Services},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2440--2455},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180785},
	doi = {10.1109/JSAC.2022.3180785},
	timestamp = {Tue, 16 Aug 2022 23:06:38 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZLFSZZPSLY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Timely anomaly detection of key performance indicators (KPIs), e.g. , service response time, error rate, is of utmost importance to Web services. Over the years, many unsupervised deep learning-based anomaly detection approaches have been proposed. To achieve good performance, they require a long period of KPI data for model training, which is not easy to guarantee with frequent service changes. Additionally, the training overhead is too significant for the vast number of KPIs in large-scale Web services. To address the problems, we propose an unsupervised KPI anomaly detection approach, named AnoTransfer , by combining a novel Variational Auto-Encoder (VAE)-based KPI clustering algorithm with an adaptive transfer learning strategy. Extensive evaluation experiments using real-world data collected from several large-scale Web service providers demonstrate that AnoTransfer reduces the average initialization time by 65.71% and improves the training efficiency by 50.62 times, without significantly degrading anomaly detection accuracy.}
}


@article{DBLP:journals/jsac/KnofczynskiDW22,
	author = {Jared Knofczynski and
                  Ramakrishnan Durairajan and
                  Walter Willinger},
	title = {{ARISE:} {A} Multitask Weak Supervision Framework for Network Measurements},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2456--2473},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180783},
	doi = {10.1109/JSAC.2022.3180783},
	timestamp = {Mon, 25 Jul 2022 08:41:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KnofczynskiDW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The application of machine learning (ML) to mitigate network-related problems poses significant challenges for researchers and operators alike. For one, there is a general lack of labeled training data in networking, and labeling techniques popular in other domains are ill-suited due to the scarcity of operators’ domain expertise. Second, network problems are typically multi-tasked in nature, requiring multiple ML models (one per task) and resulting in multiplicative increases in training times as the number of tasks increases. Third, the adoption of ML by network operators hinges on the models’ ability to provide basic reasoning about their decision-making procedures. To address these challenges, we propose ARISE, a multi-task weak supervision framework for network measurements. ARISE uses weak supervision-based data programming to label network data at scale and applies learning paradigms such as multi-task learning (MTL) and meta-learning to facilitate information sharing between tasks as well as reduce overall training time. Using community datasets, we show that ARISE can generate MTL models with improved classification accuracy compared to multiple single-task learning (STL) models. We also report findings that show the promise of MTL models for providing a means for reasoning about their decision-making process, at least at the level of individual tasks.}
}


@article{DBLP:journals/jsac/WangW0022,
	author = {Wufan Wang and
                  Bo Wang and
                  Lei Zhang and
                  Hua Huang},
	title = {Sensitivity-Aware Spatial Quality Adaptation for Live Video Analytics},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2474--2484},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180801},
	doi = {10.1109/JSAC.2022.3180801},
	timestamp = {Thu, 25 Aug 2022 08:37:06 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangW0022.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To address the conflict between the limited network bandwidth and high DNN inference accuracy, live video analytics desires a bandwidth-efficient streaming approach. To this end, more and more works study spatially variable quality streaming where high quality is only used for important regions. The key challenges are to accurately identify the important regions and select the right qualities for them to maximize accuracy. Existing approaches use either cheap analytics models or low-quality videos to locate important regions, and employ heuristic rules to make quality decisions, which struggle to address the above challenges. Our key insight is that the region’s accuracy “sensitivity” obtained by running the expensive DNN model on the high-quality video provides a reliable indication of the region’s importance and allows to allocate the available bandwidth optimally over regions by explicitly maximizing the frame accuracy. This work presents a sensitivity-aware algorithm Orchestra, which incorporates sensitivity into the design of spatial quality adaptation, including video zoning and quality selection. The design of Orchestra entails three main contributions: a feasible way of sensitivity estimation, sensitivity-aware zoning, and deduction-based accuracy estimation. Extensive experiments over realistic videos and network traces show that Orchestra improves accuracy by upto 14.1% with comparable bandwidth usage or reduces bandwidth usage by upto 44.2% while maintaining higher accuracy compared to baselines.}
}


@article{DBLP:journals/jsac/HuangZZWS22,
	author = {Tianchi Huang and
                  Chao Zhou and
                  Rui{-}Xiao Zhang and
                  Chenglei Wu and
                  Lifeng Sun},
	title = {Learning Tailored Adaptive Bitrate Algorithms to Heterogeneous Network
                  Conditions: {A} Domain-Specific Priors and Meta-Reinforcement Learning
                  Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {8},
	pages = {2485--2503},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3180804},
	doi = {10.1109/JSAC.2022.3180804},
	timestamp = {Sat, 22 Apr 2023 00:14:05 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuangZZWS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet adaptive video streaming is a typical form of video delivery that leverages adaptive bitrate (ABR) algorithms to provide video services with high quality of experience (QoE) for various users in diverse and unique network conditions. Such heterogeneous network environments, which can be viewed as exogenous input processes, often lead to the unstable performance of ABR algorithms. Unfortunately, learning-based ABR algorithm which generated by state-of-the-art reinforcement learning (RL) technologies achieves good average performance but fails to perform well in all kinds of network conditions. In this work, considering the video playback process as the Input-driven Markov Decision Process (IMDP), we propose\nA\n2\nBR (Adaptation of ABR), a novel meta-RL ABR approach.\nA\n2\nBR is mainly composed of an online stage and an offline stage. It leverages meta-RL to learn an initial meta-policy with various network conditions at the offline stage and makes decisions in personalized network conditions at the online stage. At the same time, we continually optimize the meta-policy to the tailor-made ABR policy for varying the current network environment within few shots. Moreover, in order to improve the learning efficiency, we fully utilize domain knowledge for implementing a virtual player to replay the previously experienced network. Using trace-driven experiments on various scenarios including different vehicles, users, network types, and heterogeneous user-preferences, we show that\nA\n2\nBR outperforming recent ABR approaches with rapidly adapting to the personalized QoE metrics and specific network conditions. Testbed experimental results also illustrate the superiority of\nA\n2\nBR in adapting to the unseen environments.}
}


@article{DBLP:journals/jsac/LiSOKQHHGE22a,
	author = {Geoffrey Ye Li and
                  Walid Saad and
                  Ayfer {\"{O}}zg{\"{u}}r and
                  Peter Kairouz and
                  Zhijin Qin and
                  Jakob Hoydis and
                  Zhu Han and
                  Deniz G{\"{u}}nd{\"{u}}z and
                  Jaafar M. H. Elmirghani},
	title = {Series Editorial The Sixth Issue of the Series on Machine Learning
                  in Communications and Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2507--2509},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3190650},
	doi = {10.1109/JSAC.2022.3190650},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiSOKQHHGE22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fourth (and final) call for papers of the Series on Machine Learning in Communications and Networks has continued to receive a great number of high-quality papers covering various aspects of intelligent communications. In addition to those published in the August issue, we include in this issue 16 articles submitted to the call. In the following, we provide a brief review of these articles according to their topics.}
}


@article{DBLP:journals/jsac/KangHCYHE22,
	author = {Kai Kang and
                  Qiyu Hu and
                  Yunlong Cai and
                  Guanding Yu and
                  Jakob Hoydis and
                  Yonina C. Eldar},
	title = {Mixed-Timescale Deep-Unfolding for Joint Channel Estimation and Hybrid
                  Beamforming},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2510--2528},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191124},
	doi = {10.1109/JSAC.2022.3191124},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KangHCYHE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In massive multiple-input multiple-output (MIMO) systems, hybrid analog-digital beamforming is an essential technique for exploiting the potential array gain without using a dedicated radio frequency chain for each antenna. However, due to the large number of antennas, the conventional channel estimation and hybrid beamforming algorithms generally require high computational complexity and signaling overhead. In this work, we propose an end-to-end deep-unfolding neural network (NN) joint channel estimation and hybrid beamforming (JCEHB) algorithm to maximize the system sum rate in time-division duplex (TDD) massive MIMO. Specifically, the recursive least-squares (RLS) algorithm and stochastic successive convex approximation (SSCA) algorithm are unfolded for channel estimation and hybrid beamforming, respectively. In order to reduce the signaling overhead, we consider a mixed-timescale hybrid beamforming scheme, where the analog beamforming matrices are optimized based on the channel state information (CSI) statistics offline, while the digital beamforming matrices are designed at each time slot based on the estimated low-dimensional equivalent CSI matrices. We jointly train the analog beamformers together with the trainable parameters of the RLS and SSCA induced deep-unfolding NNs based on the CSI statistics offline. During data transmission, we estimate the low-dimensional equivalent CSI by the RLS induced deep-unfolding NN and update the digital beamformers. In addition, we propose a mixed-timescale deep-unfolding NN where the analog beamformers are optimized online, and extend the framework to frequency-division duplex (FDD) systems where channel feedback is considered. Simulation results show that the proposed algorithm can significantly outperform conventional algorithms with reduced computational complexity and signaling overhead.}
}


@article{DBLP:journals/jsac/LauingerBS22,
	author = {Vincent Lauinger and
                  Fred Buchali and
                  Laurent Schmalen},
	title = {Blind Equalization and Channel Estimation in Coherent Optical Communications
                  Using Variational Autoencoders},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2529--2539},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191346},
	doi = {10.1109/JSAC.2022.3191346},
	timestamp = {Thu, 27 Jul 2023 08:18:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LauingerBS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the potential of adaptive blind equalizers based on variational inference for carrier recovery in optical communications. These equalizers are based on a low-complexity approximation of maximum likelihood channel estimation. We generalize the concept of variational autoencoder (VAE) equalizers to higher order modulation formats encompassing probabilistic constellation shaping (PCS), ubiquitous in optical communications, oversampling at the receiver, and dual-polarization transmission. Besides black-box equalizers based on convolutional neural networks, we propose a model-based equalizer based on a linear butterfly filter and train the filter coefficients using the variational inference paradigm. As a byproduct, the VAE also provides a reliable channel estimation. We analyze the VAE in terms of performance and flexibility over a classical additive white Gaussian noise (AWGN) channel with inter-symbol interference (ISI) and over a dispersive linear optical dual-polarization channel. We show that it can extend the application range of blind adaptive equalizers by outperforming the state-of-the-art constant-modulus algorithm (CMA) for PCS for both fixed but also time-varying channels. The evaluation is accompanied with a hyperparameter analysis.}
}


@article{DBLP:journals/jsac/KosasihOMHAV22,
	author = {Alva Kosasih and
                  Vincent Onasis and
                  Vera Miloslavskaya and
                  Wibowo Hardjawana and
                  Victor Andrean and
                  Branka Vucetic},
	title = {Graph Neural Network Aided {MU-MIMO} Detectors},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2540--2555},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191344},
	doi = {10.1109/JSAC.2022.3191344},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KosasihOMHAV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-user multiple-input multiple-output (MU-MIMO) systems can be used to meet high throughput requirements of 5G and beyond networks. A base station serves many users in an uplink MU-MIMO system, leading to a substantial multi-user interference (MUI). Designing a high-performance detector for dealing with a strong MUI is challenging. This paper analyses the performance degradation caused by the posterior distribution approximation used in the state-of-the-art message passing (MP) detectors in the presence of high MUI. We develop a graph neural network based framework to fine-tune the MP detectors’ cavity distributions and thus improve the posterior distribution approximation in the MP detectors. We then propose two novel neural network based detectors which rely on the expectation propagation (EP) and Bayesian parallel interference cancellation (BPIC), referred to as the GEPNet and GPICNet detectors, respectively. The GEPNet detector maximizes detection performance, while GPICNet detector balances the performance and complexity. We provide proof of the permutation equivariance property, allowing the detectors to be trained only once, even in the systems with dynamic changes of the number of users. The simulation results show that the proposed GEPNet detector performance approaches maximum likelihood performance in various configurations and GPICNet detector doubles the multiplexing gain of BPIC detector.}
}


@article{DBLP:journals/jsac/ZhongLMCWH22,
	author = {Ruikang Zhong and
                  Yuanwei Liu and
                  Xidong Mu and
                  Yue Chen and
                  Xianbin Wang and
                  Lajos Hanzo},
	title = {Hybrid Reinforcement Learning for STAR-RISs: {A} Coupled Phase-Shift
                  Model Based Beamformer},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2556--2569},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3192053},
	doi = {10.1109/JSAC.2022.3192053},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhongLMCWH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted multi-user downlink multiple-input single-output (MISO) communication system is investigated. In contrast to the existing ideal STAR-RIS model assuming an independent transmission and reflection phase-shift control, a practical coupled phase-shift model is considered. Then, a joint active and passive beamforming optimization problem is formulated for minimizing the long-term transmission power consumption, subject to the coupled phase-shift constraint and the minimum data rate constraint. Despite the coupled nature of the phase-shift model, the formulated problem is solved by invoking a hybrid continuous and discrete phase-shift control policy. Inspired by this observation, a pair of hybrid reinforcement learning (RL) algorithms, namely the hybrid deep deterministic policy gradient (hybrid DDPG) algorithm and the joint DDPG & deep-Q network (DDPG-DQN) based algorithm are proposed. The hybrid DDPG algorithm controls the associated high-dimensional continuous and discrete actions by relying on the hybrid action mapping. By contrast, the joint DDPG-DQN algorithm constructs two Markov decision processes (MDPs) relying on an inner and an outer environment, thereby amalgamating the two agents to accomplish a joint hybrid control. Simulation results demonstrate that the STAR-RIS has superiority over other conventional RISs in terms of its energy consumption. Furthermore, both the proposed algorithms outperform the baseline DDPG algorithm, and the joint DDPG-DQN algorithm achieves a superior performance, albeit at an increased computational complexity.}
}


@article{DBLP:journals/jsac/TungG22,
	author = {Tze{-}Yang Tung and
                  Deniz G{\"{u}}nd{\"{u}}z},
	title = {DeepWiVe: Deep-Learning-Aided Wireless Video Transmission},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2570--2583},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191354},
	doi = {10.1109/JSAC.2022.3191354},
	timestamp = {Thu, 22 Sep 2022 19:58:57 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TungG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present DeepWiVe , the first-ever end-to-end joint source-channel coding (JSCC) video transmission scheme that leverages the power of deep neural networks (DNNs) to directly map video signals to channel symbols, combining video compression, channel coding, and modulation steps into a single neural transform. Our DNN decoder predicts residuals without distortion feedback, which improves the video quality by accounting for occlusion/disocclusion and camera movements. We simultaneously train different bandwidth allocation networks for the frames to allow variable bandwidth transmission. Then, we train a bandwidth allocation network using reinforcement learning (RL) that optimizes the allocation of limited available channel bandwidth among video frames to maximize the overall visual quality. Our results show that DeepWiVe can overcome the cliff-effect , which is prevalent in conventional separation-based digital communication schemes, and achieve graceful degradation with the mismatch between the estimated and actual channel qualities. DeepWiVe outperforms H.264 video compression followed by low-density parity check (LDPC) codes in all channel conditions by up to 0.0485 in terms of the multi-scale structural similarity index measure (MS-SSIM), and H.265+ LDPC by up to 0.0069 on average. We also illustrate the importance of optimizing bandwidth allocation in JSCC video transmission by showing that our optimal bandwidth allocation policy is superior to uniform allocation as well as a heuristic policy benchmark.}
}


@article{DBLP:journals/jsac/XieQTL22,
	author = {Huiqiang Xie and
                  Zhijin Qin and
                  Xiaoming Tao and
                  Khaled B. Letaief},
	title = {Task-Oriented Multi-User Semantic Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2584--2597},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191326},
	doi = {10.1109/JSAC.2022.3191326},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XieQTL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While semantic communications have shown the potential in the case of single-modal single-users, its applications to the multi-user scenario remain limited. In this paper, we investigate deep learning (DL) based multi-user semantic communication systems for transmitting single-modal data and multimodal data, respectively. We adopt three intelligent tasks, including, image retrieval, machine translation, and visual question answering (VQA) as the transmission goal of semantic communication systems. We propose a Transformer based framework to unify the structure of transmitters for different tasks. For the single-modal multi-user system, we propose two Transformer based models, named, DeepSC-IR and DeepSC-MT, to perform image retrieval and machine translation, respectively. In this case, DeepSC-IR is trained to optimize the distance in embedding space between images and DeepSC-MT is trained to minimize the semantic errors by recovering the semantic meaning of sentences. For the multimodal multi-user system, we develop a Transformer enabled model, named, DeepSC-VQA, for the VQA task by extracting text-image information at the transmitters and fusing it at the receiver. In particular, a novel layer-wise Transformer is designed to help fuse multimodal data by adding connection between each of the encoder and decoder layers. Numerical results show that the proposed models are superior to traditional communications in terms of the robustness to channels, computational complexity, transmission delay, and the task-execution performance at various task-specific metrics.}
}


@article{DBLP:journals/jsac/WangCLSNPC22,
	author = {Yining Wang and
                  Mingzhe Chen and
                  Tao Luo and
                  Walid Saad and
                  Dusit Niyato and
                  H. Vincent Poor and
                  Shuguang Cui},
	title = {Performance Optimization for Semantic Communications: An Attention-Based
                  Reinforcement Learning Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2598--2613},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191112},
	doi = {10.1109/JSAC.2022.3191112},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangCLSNPC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, a semantic communication framework is proposed for textual data transmission. In the studied model, a base station (BS) extracts the semantic information from textual data, and transmits it to each user. The semantic information is modeled by a knowledge graph (KG) that consists of a set of semantic triples. After receiving the semantic information, each user recovers the original text using a graph-to-text generation model. To measure the performance of the considered semantic communication framework, a metric of semantic similarity (MSS) that jointly captures the semantic accuracy and completeness of the recovered text is proposed. Due to wireless resource limitations, the BS may not be able to transmit the entire semantic information to each user and satisfy the transmission delay constraint. Hence, the BS must select an appropriate resource block for each user as well as determine and transmit part of the semantic information to the users. As such, we formulate an optimization problem whose goal is to maximize the total MSS by jointly optimizing the resource allocation policy and determining the partial semantic information to be transmitted. To solve this problem, a proximal-policy-optimization-based reinforcement learning (RL) algorithm integrated with an attention network is proposed. The proposed algorithm can evaluate the importance of each triple in the semantic information using an attention network and then, build a relationship between the importance distribution of the triples in the semantic information and the total MSS. Compared to traditional RL algorithms, the proposed algorithm can dynamically adjust its learning rate thus ensuring convergence to a locally optimal solution. Simulation results show that the proposed framework can reduce by 41.3% data that the BS needs to transmit and improve by two-fold the total MSS compared to a standard communication network without using semantic communication techniques.}
}


@article{DBLP:journals/jsac/FerianiWXLJHLD22,
	author = {Amal Feriani and
                  Di Wu and
                  Yi Tian Xu and
                  Jimmy Li and
                  Seowoo Jang and
                  Ekram Hossain and
                  Xue Liu and
                  Gregory Dudek},
	title = {Multiobjective Load Balancing for Multiband Downlink Cellular Networks:
                  {A} Meta- Reinforcement Learning Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2614--2629},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191114},
	doi = {10.1109/JSAC.2022.3191114},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/FerianiWXLJHLD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Load balancing has become a key technique to handle the increasing traffic demand and improve the user experience. It evenly distributes the traffic across network resources by offloading users from overloaded base stations or channels to less crowded ones. Load balancing is a multi-objective optimization problem involving the automatic adjustment of several parameters to simultaneously maximize multiple network performance indicators. However, the existing methods mostly rely on single-objective approaches which lead to sub-optimal solutions. In this paper, we introduce the first multi-objective reinforcement learning (MORL) framework for load balancing. Specifically, we propose a solution based on meta-reinforcement learning (meta-RL) to learn a general policy capable of quickly adapting to new trade-offs between the objectives. We further enhance the generalization of our proposed solution using policy distillation techniques. To showcase the effectiveness of our framework, experiments are conducted based on real-world traffic scenarios. Our results show that our load balancing framework can (i) significantly outperform the existing rule-based and single-objective solutions, (ii) compute better Pareto front approximations compared to MORL baselines, and (iii) quickly adapt to new objective trade-offs.}
}


@article{DBLP:journals/jsac/XiaZSDWZ22,
	author = {Wenchao Xia and
                  Yongxu Zhu and
                  Lorenzo De Simone and
                  Tasos Dagiuklas and
                  Kai{-}Kit Wong and
                  Gan Zheng},
	title = {Multiagent Collaborative Learning for {UAV} Enabled Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2630--2642},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191329},
	doi = {10.1109/JSAC.2022.3191329},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XiaZSDWZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The unmanned aerial vehicle (UAV) technique provides a potential solution to scalable wireless edge networks. This paper uses two UAVs, with accelerated motions and fixed altitudes, to realize a wireless edge network, where one UAV forwards downlink signals to user terminals (UTs) distributed over an area while the other one collects uplink data. The conditional average achievable rates, as well as their lower bounds, of both the uplink and downlink transmission are derived considering the active probability of UTs and the service queues of two UAVs. In addition, a problem aiming to maximize the energy efficiency of the whole system is formulated, which takes into account communication related energy and propulsion energy consumption. Then, we develop a novel multi-agent Q-learning (MA-QL) algorithm to maximize the energy efficiency, through optimizing the trajectory and transmit power of the UAVs. Finally, simulation results are conducted to verify our analysis and examine the impact of different parameters on the downlink and uplink achievable rates, UAV energy consumption, and system energy efficiency. It is demonstrated that the proposed algorithm achieves much higher energy efficiency than other benchmark schemes.}
}


@article{DBLP:journals/jsac/CongZLWXX22,
	author = {Peizhuang Cong and
                  Yuchao Zhang and
                  Bin Liu and
                  Wendong Wang and
                  Zehui Xiong and
                  Ke Xu},
	title = {A{\&}B: {AI} and Block-Based {TCAM} Entries Replacement Scheme
                  for Routers},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2643--2661},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191351},
	doi = {10.1109/JSAC.2022.3191351},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/CongZLWXX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the ever-increasing deployment of 5G and IoT, the number of end-hosts/terminals is increasing rapidly, so that routers have to cache more and more forwarding entries to guarantee communication reachability of these terminals, which makes Ternary Content Addressable Memory (TCAM)-based routers keep expanding resource requirements. However, the design and implementation of large-capacity TCAM-based routers are faced with such challenges: difficult circuit design, high production cost and energy consumption, thereby posing an urgent requirement on a lightweight TCAM that can still maintain those massive communication connections. In this paper, we aim to design a lightweight router with small storage requirement while still retaining the original communication connection performance, which is not straightforward due to the following two challenges: First, under the condition of massive sequential flow data, it’s difficult to accurately and timely select the entries to cache for a small capacity TCAM. Second, given the strict prefix matching principle, how to efficiently insert the selected entries into TCAM is also challenging. To address these problems, we propose A&B: an AI-based Routing entry prediction strategy (AIR) and a Block-based entry Insertion Tactic (BIT). AIR can precisely select entries by conducting accurate entry predictions, which converts dynamic flow-based prediction into stable and parallelizable entry-based prediction by decoupling spatio-temporal characteristics. BIT optimizes entry insertion by isolating TCAM into several blocks, thus eliminating the time-consuming entry movements. The experiment results based on real backbone traffic show that our lightweight A&B achieves comparable performance compared to the traditional schemes by using only 1/8 TCAM storage.}
}


@article{DBLP:journals/jsac/YeHZGC22,
	author = {Minghao Ye and
                  Yang Hu and
                  Junjie Zhang and
                  Zehua Guo and
                  H. Jonathan Chao},
	title = {Mitigating Routing Update Overhead for Traffic Engineering by Combining
                  Destination-Based Routing With Reinforcement Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2662--2677},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191337},
	doi = {10.1109/JSAC.2022.3191337},
	timestamp = {Sun, 02 Oct 2022 15:42:35 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YeHZGC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic Engineering (TE) is a widely-adopted network operation to optimize network performance and resource utilization. Destination-based routing is supported by legacy routers and more readily deployed than flow-based routing, where the forwarding entries could be frequently updated by TE to accommodate traffic dynamics. However, as the network size grows, destination-based TE could render high time complexity when generating and updating many forwarding entries, which may limit the responsiveness of TE and degrade network performance. In this paper, we propose a novel destination-based TE solution called FlexEntry, which leverages emerging Reinforcement Learning (RL) to reduce the time complexity and routing update overhead while achieving good network performance simultaneously. For each traffic matrix, FlexEntry only updates a few forwarding entries called critical entries for redistributing a small portion of the total traffic to improve network performance. These critical entries are intelligently selected by RL with traffic split ratios optimized by Linear Programming (LP). We find out that the combination of RL and LP is very effective. Our simulation results on six real-world network topologies show that FlexEntry reduces up to 99.3% entry updates on average and generalizes well to unseen traffic matrices with near-optimal load balancing performance.}
}


@article{DBLP:journals/jsac/YanLHLS22,
	author = {Guangfeng Yan and
                  Tan Li and
                  Shao{-}Lun Huang and
                  Tian Lan and
                  Linqi Song},
	title = {{AC-SGD:} Adaptively Compressed {SGD} for Communication-Efficient
                  Distributed Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2678--2693},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3192050},
	doi = {10.1109/JSAC.2022.3192050},
	timestamp = {Mon, 28 Aug 2023 21:38:10 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YanLHLS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gradient compression (e.g., gradient quantization and gradient sparsification) is a core technique in reducing communication costs in distributed learning systems. The recent trend of gradient compression is to use a varying number of bits across iterations, however, relying on empirical observations or engineering heuristics without a systematic treatment and analysis. To the best of our knowledge, a general dynamic gradient compression that leverages both quantization and sparsification techniques is still far from understanding. This paper proposes a novel Adaptively-Compressed Stochastic Gradient Descent (AC-SGD) strategy to adjust the number of quantization bits and the sparsification size with respect to the norm of gradients, the communication budget, and the remaining number of iterations. In particular, we derive an upper bound, tight in some cases, of the convergence error for arbitrary dynamic compression strategy. Then we consider communication budget constraints and propose an optimization formulation - denoted as the Adaptive Compression Problem (ACP) - for minimizing the deep model’s convergence error under such constraints. By solving the ACP, we obtain an enhanced compression algorithm that significantly improves model accuracy under given communication budget constraints. Finally, through extensive experiments on computer vision and natural language processing tasks on MNIST, CIFAR-10, CIFAR-100 and AG-News datasets, respectively, we demonstrate that our compression scheme significantly outperforms the state-of-the-art gradient compression methods in terms of mitigating communication costs.}
}


@article{DBLP:journals/jsac/ElkordyPA22,
	author = {Ahmed Roushdy Elkordy and
                  Saurav Prakash and
                  Salman Avestimehr},
	title = {Basil: {A} Fast and Byzantine-Resilient Approach for Decentralized
                  Training},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2694--2716},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191347},
	doi = {10.1109/JSAC.2022.3191347},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ElkordyPA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized (i.e., serverless) training across edge nodes can suffer substantially from potential Byzantine nodes that can degrade the training performance. However, detection and mitigation of Byzantine behaviors in a decentralized learning setting is a daunting task, especially when the data distribution at the users is heterogeneous. As our main contribution, we propose Basil , a fast and computationally efficient Byzantine-robust algorithm for decentralized training systems, which leverages a novel sequential, memory-assisted and performance-based criteria for training over a logical ring while filtering the Byzantine users. In the IID dataset setting, we provide the theoretical convergence guarantees of Basil , demonstrating its linear convergence rate. Furthermore, for the IID setting, we experimentally demonstrate that Basil is robust to various Byzantine attacks, including the strong Hidden attack, while providing up to absolute ~16% higher test accuracy over the state-of-the-art Byzantine-resilient decentralized learning approach. Additionally, we generalize Basil to the non-IID setting by proposing Anonymous Cyclic Data Sharing (ACDS), a technique that allows each node to anonymously share a random fraction of its local non-sensitive dataset (e.g., landmarks images) with all other nodes. Finally, to reduce the overall latency of Basil resulting from its sequential implementation over the logical ring, we propose Basil+ that enables Byzantine-robust parallel training across groups of logical rings, and at the same time, it retains the performance gains of Basil due to sequential training within each group. Furthermore, we experimentally demonstrate the scalability gains of Basil+ through different sets of experiments.}
}


@article{DBLP:journals/jsac/JiangCND22,
	author = {Hao Jiang and
                  Mingyao Cui and
                  Derrick Wing Kwan Ng and
                  Linglong Dai},
	title = {Accurate Channel Prediction Based on Transformer: Making Mobility
                  Negligible},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2717--2732},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191334},
	doi = {10.1109/JSAC.2022.3191334},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/JiangCND22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate channel prediction is vital to address the channel aging issue in mobile communications with fast time-varying channels. Existing channel prediction schemes are generally based on the sequential signal processing, i.e., the channel in the next frame can only be sequentially predicted. Thus, the accuracy of channel prediction rapidly degrades with the evolution of frame due to the error propagation problem in the sequential operation. To overcome this challenging problem, we propose a transformer-based parallel channel prediction scheme to predict future channels in parallel. Specifically, we first formulate the channel prediction problem as a parallel channel mapping problem, which predicts the channels in next several frames in parallel. Then, inspired by the recently proposed parallel vector mapping model named transformer, a transformer-based parallel channel prediction scheme is proposed to solve this formulated problem. Relying on the attention mechanism in machine learning, the transformer-based scheme naturally enables parallel signal processing to avoid the error propagation problem. The transformer can also adaptively assign more weights and resources to the more relevant historical channels to facilitate accurate prediction for future channels. Moreover, we propose a pilot-to-precoder (P2P) prediction scheme that incorporates the transformer-based parallel channel prediction as well as pilot-based channel estimation and precoding. In this way, the dedicated channel estimation and precoding can be avoided to reduce the signal processing complexity. Finally, simulation results verify that the proposed schemes are able to achieve a negligible sum-rate performance loss for practical 5G systems in mobile scenarios.}
}


@article{DBLP:journals/jsac/XueWLXW22,
	author = {Guoliang Xue and
                  Yinxin Wan and
                  Xuanli Lin and
                  Kuai Xu and
                  Feng Wang},
	title = {An Effective Machine Learning Based Algorithm for Inferring User Activities
                  From IoT Device Events},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2733--2745},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191123},
	doi = {10.1109/JSAC.2022.3191123},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XueWLXW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid and ubiquitous deployment of Internet of Things (IoT) in smart homes has created unprecedented opportunities to automatically extract environmental knowledge, awareness, and intelligence. Many existing studies have adopted either machine learning approaches or deterministic approaches to infer IoT device events and/or user activities from network traffic in smart homes. In this paper, we study the problem of inferring user activity patterns from a sequence of device events by first deterministically extracting a small number of representative user activity patterns from the sequence of device events, then applying unsupervised learning to compute an optimal subset of these user activity patterns to infer user activity patterns. Based on extensive experiments with sequences of device events triggered by 2,959 real user activities and up to 30,000 synthetic user activities, we demonstrate that our scheme is resilient to device malfunctions and transient failures/delays, and outperforms the state-of-the-art solution.}
}


@article{DBLP:journals/jsac/LiZGZWCJVSP22,
	author = {Zhihan Li and
                  Youjian Zhao and
                  Yitong Geng and
                  Zhanxiang Zhao and
                  Hanzhang Wang and
                  Wenxiao Chen and
                  Huai Jiang and
                  Amber Vaidya and
                  Liangfei Su and
                  Dan Pei},
	title = {Situation-Aware Multivariate Time Series Anomaly Detection Through
                  Active Learning and Contrast VAE-Based Models in Large Distributed
                  Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {9},
	pages = {2746--2765},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3191341},
	doi = {10.1109/JSAC.2022.3191341},
	timestamp = {Sat, 10 Sep 2022 20:59:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiZGZWCJVSP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The massive amounts of monitoring data in network applications bring an urgent need for intelligent operation in large distributed systems. The key problem is precisely detecting anomalies in multivariate time series (MTS) monitoring metrics with the awareness of different application scenarios. Unsupervised MTS anomaly detection methods aim at detecting data anomalies from historical MTS without considering the out-of-band information (including user feedback and background information like code deployment status), which leads to poor performance in practice. To take advantage of the out-of-band information, we propose ACVAE, an MTS anomaly detection algorithm through active learning and contrast VAE-based detection models, which simultaneously learns MTS data’s normal and anomalous patterns for anomaly detection. We also use a learnable prior to capture system status from the background information. Moreover, we propose a query model for VAE-based methods, which can learn to query labels of the most useful instances to train the detection model. We evaluate our algorithm on three different monitoring situations in eBay’s search back-end systems. ACVAE achieves a range F1 score of 0.68~0.96 with only 3% labels, significantly outperforming the best competing methods by 0.18~0.50, and even better than a supervised ensemble method designed by domain experts in eBay.}
}


@article{DBLP:journals/jsac/XiaoHNDCCHT22,
	author = {Zhenyu Xiao and
                  Zhu Han and
                  Arumugam Nallanathan and
                  Octavia A. Dobre and
                  Bruno Clerckx and
                  Jinho Choi and
                  Chong He and
                  Wen Tong},
	title = {Guest Editorial Special Issue on Antenna Array Enabled Space/Air/Ground
                  Communications and Networking},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2767--2772},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3195678},
	doi = {10.1109/JSAC.2022.3195678},
	timestamp = {Mon, 05 Feb 2024 20:23:18 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XiaoHNDCCHT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of electronic and information technologies, the Internet of Everything (IoE) has become one of the trendiest topics in both academia and industry. Therein, many types of space/air/ground platforms need to be connected to networks for breaking down the isolation of information islands and providing various services. Space/air/ground platforms, such as satellites, unmanned aerial vehicles (UAVs), airships, balloons, terrestrial vehicles, and high-speed trains (HSTs) have emerged for accomplishing various complex tasks. Wireless communication is one of the most important technologies to support the real-time delivery of control commands and mission-related data. On the other hand, the space-air-ground integrated network has become a promising paradigm for the six-generation (6G) mobile communication network, where the aerospace and terrestrial vehicles may need to connect to existing mobile cellular networks or act as base stations (BSs) or relays to assist terrestrial wireless communications. To meet the ever-increasing demands of high capacity, wide coverage, low latency, and strong robustness for communications, it is promising to adopt large-scale antenna arrays at the transceivers to obtain considerable array gains and improve the channel quality. Antenna array-enabled beamforming technologies can facilitate spectrum reuse, interference mitigation, coverage enhancement, and physical-layer security. Antenna arrays can also be used to promote the sensing capability of space/air/ground networks, where the sensing information may be carefully processed to assist communications. However, enabling antenna array for space/air/ground communication networks poses specific, distinctive, and tricky challenges in antenna array design, physical layer, multiple access control layer, and network layer. As a result, numerous new research issues require to be addressed, which cover a wide range of disciplines including communication theory, network theory, antenna theory, signal processing, protocol design, resource allocation, optimization, hardware implementation, and experimentation.}
}


@article{DBLP:journals/jsac/XiaoHNDCCHT22a,
	author = {Zhenyu Xiao and
                  Zhu Han and
                  Arumugam Nallanathan and
                  Octavia A. Dobre and
                  Bruno Clerckx and
                  Jinho Choi and
                  Chong He and
                  Wen Tong},
	title = {Antenna Array Enabled Space/Air/Ground Communications and Networking
                  for 6G},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2773--2804},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196320},
	doi = {10.1109/JSAC.2022.3196320},
	timestamp = {Tue, 18 Oct 2022 22:17:22 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XiaoHNDCCHT22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Antenna arrays have a long history of more than 100 years and have evolved closely with the development of electronic and information technologies, playing an indispensable role in wireless communications and radar. With the rapid development of electronic and information technologies, the demand for all-time, all-domain, and full-space network services has exploded, and new communication requirements have been put forward on various space/air/ground platforms. To meet the ever increasing requirements of the future sixth generation (6G) wireless communications, such as high capacity, wide coverage, low latency, and strong robustness, it is promising to employ different types of antenna arrays (e.g., phased arrays, digital arrays, and reconfigurable intelligent surfaces, etc.) with various beamforming technologies (e.g., analog beamforming, digital beamforming, hybrid beamforming, and passive beamforming, etc.) in space/air/ground communication networks, bringing in advantages such as considerable antenna gains, multiplexing gains, and diversity gains. However, enabling antenna array for space/air/ground communication networks poses specific, distinctive and tricky challenges, which has aroused extensive research attention. This paper aims to overview the field of antenna array enabled space/air/ground communications and networking. The technical potentials and challenges of antenna array enabled space/air/ground communications and networking are presented first. Subsequently, the antenna array structures and designs are discussed. We then discuss various emerging technologies facilitated by antenna arrays to meet the new communication requirements of space/air/ground communication systems. Enabled by these emerging technologies, the distinct characteristics, challenges, and solutions for space communications, airborne communications, and ground communications are reviewed. Finally, we present promising directions for future research in antenna array enabled space/air/ground communications and networking.}
}


@article{DBLP:journals/jsac/DingSZ22,
	author = {Liqin Ding and
                  Erik G. Str{\"{o}}m and
                  Jiliang Zhang},
	title = {Degrees of Freedom in 3D Linear Large-Scale Antenna Array Communications
                  - {A} Spatial Bandwidth Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2805--2822},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196106},
	doi = {10.1109/JSAC.2022.3196106},
	timestamp = {Mon, 28 Aug 2023 21:38:10 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/DingSZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For wireless communications using linear large-scale antenna arrays, we define a receiving coordinate system and parameterization strategy to facilitate the study of the impact of three-dimensional position and rotation of the arrays on the achievable spatial degrees of freedom (DoF) in line-of-sight (LOS) channels. An analytical framework based on spatial bandwidth analysis is developed, under which three elementary problems corresponding to three basic orthogonal receiving directions are investigated. For each of them, accurate, simple, and interpretable closed-form approximations for the achievable spatial DoF are derived, and the spatial region where a sufficient amount of spatial DoF is expected available is determined. The expressions can easily be integrated into large-scale system-level simulations. Some interesting and surprising observations are made from simulation studies based on the analytical results. For instance, the spatial bandwidth is shown to be approximately constant in almost the entire spatial multiplexing region. Moreover, in significant parts of this region, the optimal receive array orientation is not parallel with the transmitting array.}
}


@article{DBLP:journals/jsac/ZhengZBLA22,
	author = {Jiakang Zheng and
                  Jiayi Zhang and
                  Emil Bj{\"{o}}rnson and
                  Zhetao Li and
                  Bo Ai},
	title = {Cell-Free Massive {MIMO-OFDM} for High-Speed Train Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2823--2839},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196088},
	doi = {10.1109/JSAC.2022.3196088},
	timestamp = {Mon, 21 Aug 2023 15:51:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengZBLA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cell-free (CF) massive multiple-input multiple-output (MIMO) systems show great potentials in low-mobility scenarios, due to cell boundary disappearance and strong macro diversity. However, the great Doppler frequency offset (DFO) leads to serious inter-carrier interference in orthogonal frequency division multiplexing (OFDM) technology, which makes it difficult to provide high-quality transmissions for both high-speed train (HST) operation control systems and passengers. In this paper, we focus on the performance of CF massive MIMO-OFDM systems with both fully centralized and local minimum mean square error (MMSE) combining in HST communications. Considering the local maximum ratio (MR) combining, the large-scale fading decoding (LSFD) cooperation and the practical effect of DFO on system performance, exact closed-form expressions for uplink spectral efficiency (SE) expressions are derived. We observe that cooperative MMSE combining achieves better SE performance than uncooperative MR combining. In addition, HST communications with small cell and cellular massive MIMO-OFDM systems are compared in terms of SE. Numerical results reveal that the CF massive MIMO-OFDM system achieves a larger and more uniform SE than the other systems. Finally, the train antenna centric (TA-centric) CF massive MIMO-OFDM system is designed for practical implementation in HST communications, and three power control schemes are adopted to optimize the propagation of TAs for reducing the impact of the DFO.}
}


@article{DBLP:journals/jsac/YanHY22,
	author = {Longfei Yan and
                  Chong Han and
                  Jinhong Yuan},
	title = {Energy-Efficient Dynamic-Subarray With Fixed True-Time-Delay Design
                  for Terahertz Wideband Hybrid Beamforming},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2840--2854},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196090},
	doi = {10.1109/JSAC.2022.3196090},
	timestamp = {Tue, 18 Oct 2022 22:17:22 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YanHY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hybrid beamforming for Terahertz (THz) ultra-massive multiple-input multiple-output (UM-MIMO) systems is a promising technology for 6G space-air-ground integrated networks, which can overcome huge propagation loss and offer unprecedented data rates. With ultra-wide bandwidth and ultra-large-scale antennas array in THz band, the beam squint becomes one of the critical problems which could reduce the array gain and degrade the data rate substantially. However, the traditional phase-shifters-based hybrid beamforming architectures cannot tackle this issue due to the frequency-flat property of the phase shifters. In this paper, to combat the beam squint while keeping high energy efficiency, a novel dynamic-subarray with fixed true-time-delay (DS-FTTD) architecture is proposed. Compared to the existing studies which use the complicated adjustable TTDs, the DS-FTTD architecture has lower power consumption and hardware complexity, thanks to the low-cost FTTDs. Furthermore, a low-complexity row-decomposition (RD) algorithm is proposed to design hybrid beamforming matrices for the DS-FTTD architecture. Extensive simulation results show that, by using the RD algorithm, the DS-FTTD architecture achieves near-optimal array gain and significantly higher energy efficiency than the existing architectures. Moreover, the spectral efficiency of DS-FTTD architecture with the RD algorithm is robust to the imperfect channel state information.}
}


@article{DBLP:journals/jsac/AlshawaqfehGM22,
	author = {Mustafa Alshawaqfeh and
                  Ammar Gharaibeh and
                  Raed Mesleh},
	title = {Optimal Low Complexity Detector for Signed-Quadrature Spatial Modulation
                  {MIMO} System},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2855--2864},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196107},
	doi = {10.1109/JSAC.2022.3196107},
	timestamp = {Tue, 18 Oct 2022 22:17:22 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/AlshawaqfehGM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Very recently, signed quadrature spatial modulation (sQSM) is developed as a competent technique that expands the spatial constellation diagram of QSM system by adding a bipolar dimension. Despite the enhanced spectral efficiency, the existing optimal maximum likelihood (ML) presents a serious computational challenge for large scale sQSM systems. Therefore, developing a reduced complexity detector for sQSM schemes is of significant importance to enable implementing and enjoying the inherent advantages of this promising system. Toward this end, a Tree Search (TS) optimal low complexity detector, called TSopt , for sQSM Multiple Input Multiple Output (MIMO) system is proposed and analyzed in this paper. The proposed detector expands the computationally complex ML detector for sQSM into a tree-structure representation. The idea of the suggested algorithm is to employ an efficient searching strategy that can expeditiously find the branch corresponding to the minimum error without tracing the entire nodes as in the ML case. It is reported that the proposed TSopt algorithm achieves the exact error performance as ML detector but with substantial reduction in computational complexity. Besides, complexity analysis in terms of the number of visited nodes of the TSopt algorithm is analyzed and a closed-form expression for the expected complexity at high SNR values is derived. Reported results disclose agreement between simulation and expected analytical complexity with substantial gains of around 60–80% in complexity reduction for different system parameters.}
}


@article{DBLP:journals/jsac/ShenWAXZZ22,
	author = {Boxiao Shen and
                  Yongpeng Wu and
                  Jianping An and
                  Chengwen Xing and
                  Lian Zhao and
                  Wenjun Zhang},
	title = {Random Access With Massive {MIMO-OTFS} in {LEO} Satellite Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2865--2881},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196128},
	doi = {10.1109/JSAC.2022.3196128},
	timestamp = {Tue, 18 Oct 2022 22:17:22 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ShenWAXZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considers the joint channel estimation and device activity detection in the grant-free random access systems, where a large number of Internet-of-Things devices intend to communicate with a low-earth orbit satellite in a sporadic way. In addition, the massive multiple-input multiple-output (MIMO) with orthogonal time-frequency space (OTFS) modulation is adopted to combat the dynamics of the terrestrial-satellite link. We first analyze the input-output relationship of the single-input single-output OTFS when the large delay and Doppler shift both exist, and then extend it to the grant-free random access with massive MIMO-OTFS. Next, by exploring the sparsity of channel in the delay-Doppler-angle domain, a two-dimensional pattern coupled hierarchical prior with the sparse Bayesian learning and covariance-free method (TDSBL-FM) is developed for the channel estimation. Then, the active devices are detected by computing the energy of the estimated channel. Finally, the generalized approximate message passing algorithm combined with the sparse Bayesian learning and two-dimensional convolution (ConvSBL-GAMP) is proposed to decrease the computations of the TDSBL-FM algorithm. Simulation results demonstrate that the proposed algorithms outperform conventional methods.}
}


@article{DBLP:journals/jsac/WangLHJRJL22,
	author = {Shiguo Wang and
                  Zhetao Li and
                  Mingyue He and
                  Tao Jiang and
                  Rukhsana Ruby and
                  Hong Ji and
                  Victor C. M. Leung},
	title = {A Joint Hybrid Precoding/Combining Scheme Based on Equivalent Channel
                  for Massive {MIMO} Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2882--2893},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196099},
	doi = {10.1109/JSAC.2022.3196099},
	timestamp = {Tue, 18 Oct 2022 22:17:22 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangLHJRJL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to its inherent ability in reducing hardware cost and power consumption while maintaining high system capacity, hybrid precoding is deemed as one of the key technologies in the upcoming 5G/6G millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) systems. However, it is challenging to design high performance hybrid precoders/combiners with low computational complexity. In this paper, based on the singular value decomposition (SVD) technique and the concept of equivalent channel, joint hybrid precoding strategies with high spectral-efficiency and low complexity are proposed for both single-user and multi-user massive MIMO systems. Specifically, for single-user massive MIMO scenarios, after transforming the design of hybrid beamforming into the problem of maximizing the square of sum eigenvalues for an equivalent channel, a two-stage successive method is conceived to design the analog precoder and combiner jointly, and the corresponding equivalent channel is constructed. Then, the digital precoding and combining operations are realized directly by applying the SVD technique to the matrix of equivalent channel. Meanwhile, the hybrid precoding strategy is extended to the multi-user scenario for achieving high performance resultant from multi-user diversity. Extensive simulations are conducted to verify the effectiveness of the precoding/combing schemes. The results show that our proposed schemes can achieve superior performance with lower complexity compared to the existing ones.}
}


@article{DBLP:journals/jsac/GaoWHGWZZ22,
	author = {Zhen Gao and
                  Minghui Wu and
                  Chun Hu and
                  Feifei Gao and
                  Guanghui Wen and
                  Dezhi Zheng and
                  Jun Zhang},
	title = {Data-Driven Deep Learning Based Hybrid Beamforming for Aerial Massive
                  {MIMO-OFDM} Systems With Implicit {CSI}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2894--2913},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196064},
	doi = {10.1109/JSAC.2022.3196064},
	timestamp = {Mon, 09 Oct 2023 17:01:04 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GaoWHGWZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In an aerial hybrid massive multiple-input multiple-output (MIMO) and orthogonal frequency division multiplexing (OFDM) system, how to design a spectral-efficient broadband multi-user hybrid beamforming with a limited pilot and feedback overhead is challenging. To this end, by modeling the key transmission modules as an end-to-end (E2E) neural network, this paper proposes a data-driven deep learning (DL)-based unified hybrid beamforming framework for both the time division duplex (TDD) and frequency division duplex (FDD) systems with implicit channel state information (CSI). For TDD systems, the proposed DL-based approach jointly models the uplink pilot combining and downlink hybrid beamforming modules as an E2E neural network. While for FDD systems, we jointly model the downlink pilot transmission, uplink CSI feedback, and downlink hybrid beamforming modules as an E2E neural network. Different from conventional approaches separately processing different modules, the proposed solution simultaneously optimizes all modules with the sum rate as the optimization object. Therefore, by perceiving the inherent property of air-to-ground massive MIMO-OFDM channel samples, the DL-based E2E neural network can establish the mapping function from the channel to the beamformer, so that the explicit channel reconstruction can be avoided with reduced pilot and feedback overhead. Besides, practical low-resolution phase shifters (PSs) introduce the quantization constraint, leading to the intractable gradient backpropagation when training the neural network. To mitigate the performance loss caused by the phase quantization error, we adopt the transfer learning strategy to further fine-tune the E2E neural network based on a pre-trained network that assumes the ideal infinite-resolution PSs. Numerical results show that our DL-based schemes have considerable advantages over state-of-the-art schemes.}
}


@article{DBLP:journals/jsac/YuanJHS22,
	author = {Xiaopeng Yuan and
                  Hao Jiang and
                  Yulin Hu and
                  Anke Schmeink},
	title = {Joint Analog Beamforming and Trajectory Planning for Energy-Efficient
                  UAV-Enabled Nonlinear Wireless Power Transfer},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2914--2929},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196108},
	doi = {10.1109/JSAC.2022.3196108},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YuanJHS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider an unmanned aerial vehicle (UAV)-enabled multi-user network with nonlinear wireless power transfer (WPT), where multiple user sensors are distributed on the ground. Acting as an energy source, the UAV operates at a fixed height and transfers energy to the multiple sensor nodes (SNs) via wireless signals. For more efficient energy harvesting (EH), an antenna array has been installed on UAV with a structure of three dimensional (3D) uniform linear array (ULA), which enables the UAV to perform analog beamforming for power concentration. Taking into account the UAV energy consumption and considering a practical nonlinear EH model, we characterize the UAV energy efficiency particularly for WPT task and subsequently formulate an efficiency maximization problem, in which the analog beamforming and UAV trajectory planning are jointly determined together with the transmit power control scheme. To deal with the nonconvex joint optimization problem, we first propose a cosine-based approximation for the complicated 3D ULA antenna pattern, in which a convex property is proved. Combining with the proved convexity in nonlinear EH model, through a series of mathematical analysis, we construct a convex subproblem based on any feasible point, solving which guarantees an improvement of the energy efficiency. Afterwards, an iterative algorithm is proposed for iteratively addressing the joint design until a convergence to a suboptimal solution. Via simulations, we verify the convergence and performance advantages of our proposed iterative solution. Among the solution, different beamforming preferences regarding the beam coverage enlargement and power concentration are also observed with respect to different antenna array scales.}
}


@article{DBLP:journals/jsac/YuHWSD22,
	author = {Xiangbin Yu and
                  Xu Huang and
                  Kezhi Wang and
                  Feng Shu and
                  Xiaoyu Dang},
	title = {Joint Design of Power Allocation, Beamforming, and Positioning for
                  Energy-Efficient UAV-Aided Multiuser Millimeter-Wave Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2930--2945},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196111},
	doi = {10.1109/JSAC.2022.3196111},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YuHWSD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, the joint design of power allocation (PA), beamforming (BF) and positioning is studied for unmanned-aerial-vehicle (UAV) aided millimeter-Wave (UAV-mmWave) systems, with the objective of maximizing the energy efficiency (EE), under the constraints of maximum transmitting power, minimum data rate from the ground users and positioning range of the UAV. To address the above problem, we first obtain the positioning of the UAV, with the help of approximate beam pattern. Then, near-optimal BF and closed-form PA are derived given the obtained position, with the help of block coordinate descent method. To reduce the complexity, two suboptimal BF schemes with one-loop iteration and closed-form solutions are respectively derived. Furthermore, we propose the simplified algorithms for two special cases, i.e., only line-of-sight (LoS) path and Non-LoS (NLoS) path exist between the users and the UAV. Simulation results verify the effectiveness of the developed joint schemes and show the superior EE performance. Moreover, they can obtain almost the same performance as the existing benchmark schemes but with lower complexity.}
}


@article{DBLP:journals/jsac/BaiCBW22,
	author = {Lin Bai and
                  Qun Chen and
                  Tong Bai and
                  Jingchao Wang},
	title = {UAV-Enabled Secure Multiuser Backscatter Communications With Planar
                  Array},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2946--2961},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196086},
	doi = {10.1109/JSAC.2022.3196086},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/BaiCBW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned aerial vehicle (UAV)-enabled backscatter communications (BackComm) is deemed to be a vital technique enabling the data transmission over massive battery-less devices for Internet of Things (IoT). However, the UAV-enabled Backcomm suffers from information leakage due to the broadcasting nature of wireless channels. To cope with the security issue, in this paper, a UAV-enabled multi-user secure BackComm system is developed using analog beamforming (ABF) and randomized continuous wave (RCW) techniques, where the multiple users are supported by the multi-carrier RCW over a single low-complexity radio frequency (RF) chain. By exploiting the RCW transmitted towards backscatter, the eavesdropping link can be eroded without any specific jamming signals. The closed-form of the secrecy rate is studied with the approximations, which is then maximized by jointly optimizing the beamforming together with the UAV’s location and the RCW settings. Simulation results are carried out to confirm the accuracy of the proposed approximation, while the convergence behavior of the optimization algorithm is analyzed. As a result, it can be shown that the secrecy rate can be significantly improved compared with the benchmark schemes.}
}


@article{DBLP:journals/jsac/DuNXCKK22,
	author = {Hongyang Du and
                  Dusit Niyato and
                  Yuan{-}Ai Xie and
                  Yanyu Cheng and
                  Jiawen Kang and
                  Dong In Kim},
	title = {Performance Analysis and Optimization for Jammer-Aided Multiantenna
                  {UAV} Covert Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2962--2979},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196131},
	doi = {10.1109/JSAC.2022.3196131},
	timestamp = {Fri, 28 Jun 2024 14:57:07 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/DuNXCKK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned aerial vehicles (UAVs) have attracted a lot of research attention because of their high mobility and low cost in serving as temporary aerial base stations (BSs) and providing high data rates for next-generation communication networks. To protect user privacy while avoiding detection by a warden, we investigate a jammer-aided UAV covert communication system, which aims to maximize the user’s covert rate with optimized transmit and jamming power. The UAV is equipped with multi-antennas to serve multi-users simultaneously and enhance the Quality of Service. By considering the general composite fading and shadowing channel models, we derive the exact probability density (PDF) and cumulative distribution functions (CDF) of the signal-to-interference-plus-noise ratio (SINR). The obtained PDF and CDF are used to derive the closed-form expressions for detection error probability and covert rate. Furthermore, the covert rate maximization problem is formulated as a Nash bargaining game, and the Nash bargaining solution (NBS) is introduced to investigate the negotiation among users. To solve the NBS, we propose two algorithms, i.e., particle swarm optimization-based and joint two-stage power allocation algorithms, to achieve covertness and high data rates under the warden’s optimal detection threshold. All formulated problems are proven to be convex, and the complexity is analyzed. The numerical results are presented to verify the theoretical performance analysis and show the effectiveness and success of achieving the covert communication of our algorithms.}
}


@article{DBLP:journals/jsac/LiuLK22,
	author = {Beiyuan Liu and
                  Jiajia Liu and
                  Nei Kato},
	title = {Optimal Beamformer Design for Millimeter Wave Dual-Functional Radar-Communication
                  Based {V2X} Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2980--2993},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196089},
	doi = {10.1109/JSAC.2022.3196089},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuLK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Millimeter wave (MmWave) dual-functional radar-communication (DFRC) technology is believed to hold the ability to alleviate spectrum congestion and inter-radar interference in 5G vehicle-to-everything (V2X) systems. The radar target sizes in V2X system may not be ignored in views of the demands of short-range sensing and ultra-narrow beams supported by massive MIMO mmWave beamforming. Under such scenario, a novel single-target-multi-beams (STMB) radar beam alignment scheme is proposed to acquire more accurate information on estimated ranges and velocities by allocating multiple radar beams to a certain target. For instance, the relative velocity direction can be accurately estimated based on STMB scheme by using a weighted linear estimation methods. Then, the hybrid analog-digital beamforming under STMB scheme is formulated and optimized by maximizing transmission rate subject to radar signal-to-interference-and-noise (SINR) constraints, where a radar beam cancellation algorithm is proposed to adjust adaptively the radar beam number pointing to a certain target, which can guarantee strict radar SINR constraint under different transmission power levels. The numerical results verify the effectiveness and reliability of STMB scheme and show that the proposed beamformer outperforms the benchmark in both spectral efficiency and minimum radar SINR.}
}


@article{DBLP:journals/jsac/YouQTLWGO22,
	author = {Li You and
                  Xiaoyu Qiang and
                  Christos G. Tsinos and
                  Fan Liu and
                  Wenjin Wang and
                  Xiqi Gao and
                  Bj{\"{o}}rn E. Ottersten},
	title = {Beam Squint-Aware Integrated Sensing and Communications for Hybrid
                  Massive {MIMO} {LEO} Satellite Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {2994--3009},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196114},
	doi = {10.1109/JSAC.2022.3196114},
	timestamp = {Mon, 31 Jul 2023 09:43:28 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YouQTLWGO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The space-air-ground-sea integrated network (SAGSIN) plays an important role in offering global coverage. To improve the efficient utilization of spectral and hardware resources in the SAGSIN, integrated sensing and communications (ISAC) has drawn extensive attention. Most existing ISAC works focus on terrestrial networks and cannot be straightforwardly applied in satellite systems due to the significantly different electromagnetic wave propagation properties. In this work, we investigate the application of ISAC in massive multiple-input multiple-output (MIMO) low earth orbit (LEO) satellite systems. We first characterize the statistical wave propagation properties by considering beam squint effects. Based on this analysis, we propose a beam squint-aware ISAC technique for hybrid analog/digital massive MIMO LEO satellite systems exploiting statistical channel state information. Simulation results demonstrate that the proposed scheme can operate both the wireless communications and the target sensing simultaneously with satisfactory performance, and the beam-squint effects can be efficiently mitigated with the proposed method in typical LEO satellite systems.}
}


@article{DBLP:journals/jsac/ZhiPZRES22,
	author = {Kangda Zhi and
                  Cunhua Pan and
                  Gui Zhou and
                  Hong Ren and
                  Maged Elkashlan and
                  Robert Schober},
	title = {Is RIS-Aided Massive {MIMO} Promising With {ZF} Detectors and Imperfect
                  CSI?},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {3010--3026},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196097},
	doi = {10.1109/JSAC.2022.3196097},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhiPZRES22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper provides a theoretical framework for understanding the performance of reconfigurable intelligent surface (RIS)-aided massive multiple-input multiple-output (MIMO) with zero-forcing (ZF) detectors under imperfect channel state information (CSI). We first introduce a low-overhead minimum mean square error (MMSE) channel estimator, and then derive and analyze closed-form expressions for the uplink achievable rate. Our analytical results demonstrate that: 1) regardless of the RIS phase shift design, the rate of all users scales at least on the order of\nO(\nlog\n2\n(MN))\n, where\nM\nand\nN\nare the numbers of antennas and reflecting elements, respectively; 2) by aligning the RIS phase shifts to one user, the rate of this user can at most scale on the order of\nO(\nlog\n2\n(M\nN\n2\n))\n; 3) either\nM\nor the transmit power can be reduced inversely proportional to\nN\n, while maintaining a given rate. Furthermore, we propose two low-complexity majorization-minimization (MM)-based algorithms to optimize the sum user rate and the minimum user rate, respectively, where closed-form solutions are obtained in each iteration. Finally, simulation results validate the accuracy of all derived analytical results. Our simulation results also show that the maximum sum rate can be closely approached by simply aligning the RIS phase shifts to an arbitrary user.}
}


@article{DBLP:journals/jsac/MaAHMYWZF22,
	author = {Zhangfeng Ma and
                  Bo Ai and
                  Ruisi He and
                  Hang Mi and
                  Mi Yang and
                  Ning Wang and
                  Zhangdui Zhong and
                  Wei Fan},
	title = {Modeling and Analysis of {MIMO} Multipath Channels With Aerial Intelligent
                  Reflecting Surface},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {3027--3040},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196112},
	doi = {10.1109/JSAC.2022.3196112},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/MaAHMYWZF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, intelligent reflecting surface (IRS) has become a research focus for its capability of controlling the radio propagation environments. Compared to the conventional terrestrial IRS, aerial IRS (AIRS) exploiting unmanned aerial vehicle (UAV)/high-altitude platform (HAP) can provide better deployment flexibility. To this end, a three-dimensional (3D) one-cylinder model is first developed for AIRS-assisted multiple-input multiple-output (MIMO) narrowband channels. In order to change the wireless channel with AIRS and create a favorable propagation environment, we propose a novel method of designing the phase-shifts for the IRS elements. Based on the model, channel impulse response (CIR), space-time correlation function, and channel capacity are derived and thoroughly investigated. A key observation in this paper is that multipath and Doppler effects in radio propagation environments can be effectively mitigated via adjusting the phase-shifts of IRS. More specifically, for the special propagation environments in the absence of any scatterers, it is found that the effects of multipath fading can be completely eliminated by IRSs. While for the general propagation environments with multiple scatterers, a small number of IRS elements can also significantly reduce the Doppler spread and the deep fades of the channels. Based on the numerical investigation of channel correlations, it is shown that channel non-stationarity is not introduced into the time domain when the phase shift of IRS is linear related to the time. Moreover, the channel capacity can also be improved by the proposed methods. Finally, the model with non-ideal IRSs is considered and it is found that using non-ideal IRSs results in poor performances compared with using ideal IRSs. These conclusions will provide a fundamental support for developing intelligent and controllable propagation environments of the future sixth-generation (6G) wireless networks.}
}


@article{DBLP:journals/jsac/ZhaoZMCLH22,
	author = {Jingjing Zhao and
                  Yanbo Zhu and
                  Xidong Mu and
                  Kaiquan Cai and
                  Yuanwei Liu and
                  Lajos Hanzo},
	title = {Simultaneously Transmitting and Reflecting Reconfigurable Intelligent
                  Surface {(STAR-RIS)} Assisted {UAV} Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {3041--3056},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196102},
	doi = {10.1109/JSAC.2022.3196102},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhaoZMCLH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A novel air-to-ground communication paradigm is conceived, where an unmanned aerial vehicle (UAV)-mounted base station (BS) equipped with multiple antennas sends information to multiple ground users (GUs) with the aid of a simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). In contrast to the conventional RIS whose main function is to reflect incident signals, the STAR-RIS is capable of both transmitting and reflecting the impinging signals from either side of the surface, thereby leading to full-space 360 degree coverage. However, the transmissive and reflective capabilities of the STAR-RIS require more complex transmission/reflection coefficient design. Therefore, in this work, a sum-rate maximization problem is formulated for the joint optimization of the UAV’s trajectory, the active beamforming at the UAV, and the passive transmission/reflection beamforming at the STAR-RIS. This cutting-edge optimization problem is also subject to the UAV’s flight safety, to the maximum flight duration constraint, as well as to the GUs’ minimum data rate requirements. Given the unknown locations of obstacles prior to the UAV’s flight, we provide an online decision making framework employing reinforcement learning (RL) to simultaneously adjust both the UAV’s trajectory as well as the active and passive beamformer. To enhance the system’s robustness against the associated uncertainties caused by limited sampling of the environment, a novel “distributionally-robust” RL (DRRL) algorithm is proposed for offering an adequate worst-case performance guarantee. Our numerical results unveil that: 1) the STAR-RIS assisted UAV communications benefit from significant sum-rate gain over the conventional reflecting-only RIS; and 2) the proposed DRRL algorithm achieves both more stable and more robust performance than the state-of-the-art RL algorithms.}
}


@article{DBLP:journals/jsac/ZhengLZ22,
	author = {Beixiong Zheng and
                  Shaoe Lin and
                  Rui Zhang},
	title = {Intelligent Reflecting Surface-Aided {LEO} Satellite Communication:
                  Cooperative Passive Beamforming and Distributed Channel Estimation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {3057--3070},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196119},
	doi = {10.1109/JSAC.2022.3196119},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Low-earth orbit (LEO) satellite communication plays an important role in assisting/complementing terrestrial communications by providing worldwide coverage, especially in harsh environments such as high seas, mountains, and deserts which are uncovered by terrestrial networks. Traditionally, the passive reflect-array with fixed phase shifts has been applied in satellite communications to compensate for the high path loss due to long propagation distance with low-cost directional beamforming; however, it is unable to flexibly adapt the beamforming direction to dynamic channel conditions. In view of this, we consider in this paper a new intelligent reflecting surface (IRS)-aided LEO satellite communication system, by utilizing the controllable phase shifts of massive passive reflecting elements to achieve flexible beamforming, which copes with the time-varying channel between the high-mobility satellite (SAT) and ground node (GN) cost-effectively. In particular, we propose a new architecture for IRS-aided LEO satellite communication where IRSs are deployed at both sides of the SAT and GN, and study their cooperative passive beamforming (CPB) design over line-of-sight (LoS)-dominant single-reflection and double-reflection channels. Specifically, we jointly optimize the active transmit/receive beamforming at the SAT/GN as well as the CPB at two-sided IRSs to maximize the overall channel gain from the SAT to each GN. Interestingly, we show that under LoS channel conditions, the high-dimensional SAT-GN channel can be decomposed into the outer product of two low-dimensional vectors. By exploiting the decomposed SAT-GN channel, we decouple the original beamforming optimization problem into two simpler subproblems corresponding to the SAT and GN sides, respectively, which are both solved in closed-form. Furthermore, we propose an efficient transmission protocol to conduct channel estimation and beam tracking, which only requires independent processing of the SAT and GN in a distributed manner, thus substantially reducing the implementation complexity. Simulation results validate the performance advantages of the proposed IRS-aided LEO satellite communication system with two-sided cooperative IRSs, as compared to various baseline schemes such as the conventional reflect-array and one-sided IRS.}
}


@article{DBLP:journals/jsac/DengDZPS22,
	author = {Ruoqi Deng and
                  Boya Di and
                  Hongliang Zhang and
                  H. Vincent Poor and
                  Lingyang Song},
	title = {Holographic {MIMO} for {LEO} Satellite Communications Aided by Reconfigurable
                  Holographic Surfaces},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {3071--3085},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196110},
	doi = {10.1109/JSAC.2022.3196110},
	timestamp = {Mon, 12 Feb 2024 16:07:18 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/DengDZPS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ultra-dense low-Earth-orbit (LEO) satellite communication networks have significant potential for providing high-speed data services. To compensate the severe path loss in satellite communications, a key conceptual enabler is the holographic multiple input multiple output (HMIMO) with a spatially continuous aperture which can achieve a high directive gain with a small antenna size. In this paper, we consider a novel metamaterial antenna called a reconfigurable holographic surface (RHS) integrated with a user terminal (UT) to support LEO satellite communications. Composing of densely packing sub-wavelength metamaterial elements, the RHS can realize continuous or quasi-continuous apertures and provide a practical way towards the implementation of HMIMO. To obtain the desired beam directions towards the satellites, we propose a LEO satellite tracking scheme based on the temporal variation law such that frequent satellite positioning can be avoided. A holographic beamforming algorithm for sum rate maximization is then developed where a closed-form for the optimal holographic beamformer is derived. The robustness of the algorithm against the tracking errors of the satellites’ positions is also proved. Simulation results verify the theoretical analysis and show that the RHS outperforms the traditional phased array of the same physical dimension in terms of the sum rate when the compact element spacing of the RHS leads to much more RHS elements. Moreover, the RHS also provides a more cost-effective solution for pursuing high data rate compared with the phased array.}
}


@article{DBLP:journals/jsac/ChenWWZ22,
	author = {Yuanbin Chen and
                  Ying Wang and
                  Zhaocheng Wang and
                  Ping Zhang},
	title = {Robust Beamforming for Active Reconfigurable Intelligent Omni-Surface
                  in Vehicular Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {3086--3103},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196095},
	doi = {10.1109/JSAC.2022.3196095},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenWWZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Two key impediments to reconfigurable intelligent surface (RIS)-aided vehicular communications are, respectively, the double fading experienced by the signal on RIS-aided cascaded links and the high-mobility-induced intractability of acquiring channel state information (CSI). To overcome these challenges, a novel kind of RIS is presented in this paper, namely active reconfigurable intelligent omni-surface (RIOS), each element of which is supported by active loads, that concurrently transmits and reflects the incident signal amplified rather than just reflecting it as compared to the case of a passive reflecting-only RIS. We consider the use of an active RIOS to a vehicular communication system for mitigating double fading effect. Specifically, the active RIOS is mounted on the vehicle window to enhance transmission for users in the vehicle and for adjacent vehicles. We aim to jointly optimize the transmit precoding matrix at the base station (BS) and RIOS coefficient matrices to minimize the BS’s transmit power relying exclusively upon the imperfect knowledge of the large-scale CSI. To significantly relax the frequency of channel information updates, initially an efficient transmission protocol is put forward to reap the high active RIOS beamforming gain with low channel training overhead by appropriately tailoring the time-scale of CSI acquisition. Then, two algorithms, namely an alternating optimization (AO)-based algorithm and a constrained stochastic successive convex approximation (CSSCA)-based algorithm, are developed to tackle with the investigated resource allocation problem, whose pros and cons are elaborated, respectively. Simulation results substantiate the significant performance improvement of active RIOS as well as determine the validity and robustness of our proposed algorithms over various benchmark schemes.}
}


@article{DBLP:journals/jsac/LiuWHNS22,
	author = {Dongxiao Liu and
                  Huaqing Wu and
                  Cheng Huang and
                  Jianbing Ni and
                  Xuemin Shen},
	title = {Blockchain-Based Credential Management for Anonymous Authentication
                  in {SAGVN}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {10},
	pages = {3104--3116},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3196091},
	doi = {10.1109/JSAC.2022.3196091},
	timestamp = {Tue, 18 Oct 2022 22:17:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuWHNS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a blockchain-based collaborative credential management scheme for anonymous authentication in space-air-ground integrated vehicular networks (SAGVN), named SAG-BC . First, we build a consortium blockchain among service providers and design a distributed system setup (DSS) scheme to securely generate public parameters for issuing credentials. Second, we design a collaborative credential issuance (CCI) scheme to generate a succinct and easy-to-manage subscription credential. The credential can be used by users to access different access points in SAGVN efficiently without revealing true identities from the authentication messages. With co-designs of zero-knowledge proofs and succinct on-chain commitments, SAG-BC provides efficient verifiability and incentives for credential management operations in SAGVN. By doing so, expensive on-chain storage and computational overheads are reduced in the DSS and CCI. Finally, we conduct a thorough security analysis to demonstrate that SAG-BC achieves security and verifiability for credential management in SAGVN. We set up a real-world blockchain network and conduct extensive experiments to show the feasibility and efficiency of SAG-BC .}
}


@article{DBLP:journals/jsac/Balasubramaniam22,
	author = {Sasitharan Balasubramaniam and
                  Robert Schober and
                  Massimiliano Pierobon and
                  Sudip Misra and
                  Peter Thomas},
	title = {Guest Editorial Special Issue on "Edge-Based Wireless Communications
                  Technologies to Counter Communicable Infectious Diseases"},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3119--3121},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3210805},
	doi = {10.1109/JSAC.2022.3210805},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/Balasubramaniam22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The COVID-19 pandemic has resulted in one of the major challenges for humanity in the 21st century. The impact of these challenges has led to a tremendous loss of life, impact on long-term health, well-being as well as personal psychology, and negative societal changes and not to mention its impact on the global economy. Since this is a health issue, similar to other forms of diseases and pandemics, society has largely relied on the fields of medical, virology, immunology, biotechnology, and pharmaceutical science to develop novel therapeutic solutions for treatments. This has resulted in vaccines that have been rolled out to elevate immunity levels that will hopefully allow the majority of the population to reach herd immunity. However, given the technological advancements that we have reached in the 21st century, questions have also risen as to how other disciplines can play a role in solving and obtaining new knowledge of communicable disease pandemics.}
}


@article{DBLP:journals/jsac/YangWYXZKAG22,
	author = {Yaoqi Yang and
                  Weizheng Wang and
                  Zhimeng Yin and
                  Renhui Xu and
                  Xiaokang Zhou and
                  Neeraj Kumar and
                  Mamoun Alazab and
                  Thippa Reddy Gadekallu},
	title = {Mixed Game-Based AoI Optimization for Combating {COVID-19} With {AI}
                  Bots},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3122--3138},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3215508},
	doi = {10.1109/JSAC.2022.3215508},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/YangWYXZKAG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since the outbreak of COVID-19 pandemic in 2020, a dramatic loss of human life has occurred and this trend presents an unprecedented challenge to public health, economic systems and social operations. Hence, it is urgent for us to take some countermeasures to restrain and dispel epidemic diffusion to the uttermost. Data freshness plays an inevitable role in timely infestor determination during this process. However, existing works pay little attention to optimizing this indicator in health monitoring. To make up this research gap, in this paper, we propose a mixed game-based Age of Information (AoI) optimization scheme, where the edge-based wireless technologies and AI-empowered diagnostic bots are adopted. Firstly, we establish the system model for Epidemic Prevention and Control Center (EPCC)-based health state monitoring network, where ultimate biosensing data is transmitted from AI bots via edge servers. Then, upon deriving AoI expression with a closed form, the minimization goal between edge servers and bots is specified. Simultaneously, we reformulate the AoI optimization problem from the mixed game viewpoint (i.e., coalition formation game and ordinary potential game), and then propose two algorithms for cooperative order-based bot deployment and stochastic learning-based channel selection. Finally, compared with the typical baselines, the experiment result shows our scheme can reach the lower AoI value for biosensing data transmission under different parameter settings.}
}


@article{DBLP:journals/jsac/GaoNWZ22,
	author = {Yun Gao and
                  Shouxiang Ni and
                  Dan Wu and
                  Liang Zhou},
	title = {Edge-Based Cross-Modal Communications for Remote Healthcare},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3139--3151},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3211539},
	doi = {10.1109/JSAC.2022.3211539},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/GaoNWZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medical robots with audio-video-haptic streams, as indispensable devices for remote healthcare, are playing ever-increasing roles in mitigating the spread of infectious diseases. However, existing medical robots are far from precise and efficient because of the following two technical challenges, including i) how to ensure the haptic fidelity for precise manipulation, and ii) how to alleviate the impact of haptic streams on the quality of visual navigation for efficient operation. To this end, this work explores the benefits of edge-based cross-modal communications (CMCs), which take full advantage of potential correlations among different modalities’ streams, to realize high reliability and throughput. Specifically, to compensate for the reliability loss caused by wireless transmission, a semantic-aided cross-modal reconstruction framework is firstly designed at edge nodes for high haptic fidelity. Then, a user experience-driven stream scheduling strategy is developed to enhance the visual quality by fully leveraging edge computing and network slicing. In particular, different from traditionally interrupting audio/video stream transmission to prioritize haptic streams, we jointly schedule resources to different modalities’ streams via estimating haptic arrival time. Finally, as a classical case study, we independently construct a remote throat swab sampling platform based on CMCs to evaluate practical performance, and numerical results indicate the significant improvements in terms of various metrics.}
}


@article{DBLP:journals/jsac/XieWCZH22,
	author = {Ning Xie and
                  Wenya Wang and
                  Yicong Chen and
                  Peichang Zhang and
                  Lei Huang},
	title = {Confidentiality-Preserving Edge-Based Wireless Communications for
                  Contact Tracing Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3152--3171},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3211549},
	doi = {10.1109/JSAC.2022.3211549},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XieWCZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper addresses two issues of a contact-tracing system with edge-based wireless communication techniques: to locate close contacts and to provide confidentiality-preserving communications. In this paper, we propose the Confidentiality-Preserving Contact-Tracing (CPCT) system with multiple wireless edge-based nodes. The CPCT system consists of three stages: registration, authentication, and confidentiality-preserving communication stages. We propose two Physical-Layer Authentication (PLA) schemes for the authentication stage of the CPCT system: the Coordinate-based Location PLA (CLP) scheme using the estimated coordinates and the Time-of-Arrival (ToA) based Location PLA (TLP) scheme using the estimated ToAs. We propose a distributed encryption scheme for the confidentiality-preserving communication stage of the CPCT system named the Distributed Channel Impulse Response (CIR)-based Encryption (DCE) scheme. We provide the theoretical analysis of the proposed schemes and derive their closed-form expressions. We implement the proposed schemes and conduct extensive performance comparisons through simulations. We observe that the theoretical results perfectly match the corresponding simulation results. Moreover, the proposed PLA schemes provide higher authentication performance than the prior PLA scheme, while the proposed encryption scheme provides higher confidentiality performance than the prior encryption scheme.}
}


@article{DBLP:journals/jsac/ChengLXW22,
	author = {Jieren Cheng and
                  Ping Luo and
                  Naixue Xiong and
                  Jie Wu},
	title = {{AAFL:} Asynchronous-Adaptive Federated Learning in Edge-Based Wireless
                  Communication Systems for Countering Communicable Infectious Diseasess},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3172--3190},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3211564},
	doi = {10.1109/JSAC.2022.3211564},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChengLXW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid growth of the coronavirus disease of 2019 (COVID-19) cases, massive amounts of relevant data are being trained on machine learning models for countering communicable infectious diseases. Federated Learning (FL) is a paradigm of distributed machine learning to deal with the individual COVID-19 data, and enable the protection of data privacy. However, FL has low efficiency in Edge-Based wireless communication systems with system heterogeneity. In this paper, we propose an “Asynchronous-Adaptive FL” (AAFL) scheme. Specifically, we allow that medical devices with different performances have a heterogeneous number of local SGD iterations in each communication round, called asynchronous iteration strategy which is balanced under adaptive control. We theoretically analyze the convergence of the AAFL scheme under a given time budget and obtain a mathematical relationship between the heterogeneous number of local SGD iterations and the optimal model parameters. Based on the mathematical relationship, we design an algorithm for parameter server and work nodes to adaptively control the heterogeneous number of local SGD iterations. Subsequently, we build a prototype heterogeneous system and conduct experiments on various scenarios for analyzing the general properties of our algorithm, and then apply our algorithm to public COVID-19 databases. The experimental results and application performance demonstrate the effectiveness and efficiency of our AAFL scheme.}
}


@article{DBLP:journals/jsac/LiYYFJSM22,
	author = {Teng Li and
                  Siwei Yin and
                  Runze Yu and
                  Yebo Feng and
                  Lei Jiao and
                  Yulong Shen and
                  Jianfeng Ma},
	title = {CoAvoid: Secure, Privacy-Preserved Tracing of Contacts for Infectious
                  Diseases},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3191--3206},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3211547},
	doi = {10.1109/JSAC.2022.3211547},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiYYFJSM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To fight against infectious diseases (e.g., SARS, COVID-19, Ebola, etc.), government agencies, technology companies and health institutes have launched various contact tracing approaches to identify and notify the people exposed to infection sources. However, existing tracing approaches can lead to severe privacy and security concerns, thereby preventing their secure and widespread use among communities. To tackle these problems, this paper proposes CoAvoid , an edge-based, privacy-preserved contact tracing system that features good dependability and usability. CoAvoid leverages the Google/Apple Exposure Notification (GAEN) API to achieve decent device compatibility and operating efficiency. It utilizes Bluetooth Low Energy (BLE) to detect close contact with other people and leverages GPS with fine-grained matching algorithms to verify user information. In addition, to enhance privacy protection, CoAvoid applies fuzzification and obfuscation measures to shelter sensitive data, making both servers and users agnostic to information of both low and high-risk populations. The evaluation demonstrates good efficacy and security of CoAvoid. Compared with four state-of-the-art contact tracing applications, CoAvoid can reduce the size of upload data by at least 90% and reduce the verification time by 92%. More importantly, CoAvoid can preserve user privacy and resist replay and wormhole attacks in all analysis scenarios.}
}


@article{DBLP:journals/jsac/ZhangWXZZ22,
	author = {Bohan Zhang and
                  Ruiyu Wang and
                  Hao Xu and
                  Xiaoshuai Zhang and
                  Lei Zhang},
	title = {{DISTERNING:} Distance Estimation Using Machine Learning Approach
                  for {COVID-19} Contact Tracing and Beyond},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3207--3223},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3214277},
	doi = {10.1109/JSAC.2022.3214277},
	timestamp = {Mon, 27 Nov 2023 18:50:36 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangWXZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since the coronavirus disease 19 (COVID-19) outbreak, the epidemiological analysis has raised a strong requirement for more effective and accurate contact tracing solution. However, the existing contact tracing solutions either lacked the evaluation of tracing proximity or the features used for the tracing proximity evaluation were susceptible to certain negative environmental factors (e.g., body shielding). In this article, we propose a novel distance estimation algorithm based on machine learning for contact tracing: DISTERNING, where we leverage machine learning algorithms including Learning Vector Quantization, Regression, and Deep Feed-forward (DFF) Neural Network, data processing methods, and digital filters to process the Bluetooth signal information collected by the mobile phone for contact distance estimation. A contact tracing scheme based on edge computing is also proposed for algorithm deployment due to the requirements of the computational power. Compared with the existing contact tracing solutions, our algorithm considers the factors that have significant negative influence on the Bluetooth signal for distance estimation in reality. The evaluation results show that when the collected Bluetooth signal is influenced by real-world negative environmental factors, employing our proposed algorithm DISTERNING can keep the accuracy of the estimated distance reliable. The output distance can be combined with some medical models to conduct infection risk assessments.}
}


@article{DBLP:journals/jsac/WeiMWZWP22,
	author = {Zhongxiang Wei and
                  Christos Masouros and
                  Ping Wang and
                  Xu Zhu and
                  Jingjing Wang and
                  Athina P. Petropulu},
	title = {Physical Layer Anonymous Precoding Design: From the Perspective of
                  Anonymity Entropy},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3224--3238},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3211556},
	doi = {10.1109/JSAC.2022.3211556},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WeiMWZWP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the era of e-Health, privacy protection has become imperative in applications that carry personal and sensitive data. Departing from the data-perturbation based privacy-preserving techniques that reduce the fidelity of the disclosed data, in this paper we investigate anonymous communications, which mask the identity of the data sender while providing high data reliability. Focusing on the physical (PHY) layer, we first explore the break of privacy through a statistical attribute based sender detection (SD) from the receiver. Compared to the existing literature, this enables a much enhanced SD performance, especially when the users are equipped with different numbers of antennas. To counteract the advanced SD approach above, we formulate explicit anonymity constraints for the design of the anonymous precoder, which mask the sender’s PHY attributes that can be exploited by SD, while at the same time preserving the reliability of the data. Then, anonymity entropy-oriented precoders are proposed for different antenna configurations at the users, which adaptively construct a maximum number of aliases while obeying users’ signal-to-noise-ratio requirements for data accuracy. Simulation results demonstrate that the proposed anonymous precoders provide the highest level of anonymity entropy over the benchmarks, while achieving reasonable symbol error rate for the communication signal.}
}


@article{DBLP:journals/jsac/LiGDL22,
	author = {Xuran Li and
                  Shuaishuai Guo and
                  Hong{-}Ning Dai and
                  Dengwang Li},
	title = {Infectious Probability Analysis on {COVID-19} Spreading With Wireless
                  Edge Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3239--3254},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3211534},
	doi = {10.1109/JSAC.2022.3211534},
	timestamp = {Sat, 30 Sep 2023 10:20:13 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiGDL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of infectious disease COVID-19 has challenged and changed the world in an unprecedented manner. The integration of wireless networks with edge computing (namely wireless edge networks) brings opportunities to address this crisis. In this paper, we aim to investigate the prediction of the infectious probability and propose precautionary measures against COVID-19 with the assistance of wireless edge networks. Due to the availability of the recorded detention time and the density of individuals within a wireless edge network, we propose a stochastic geometry-based method to analyze the infectious probability of individuals. The proposed method can well keep the privacy of individuals in the system since it does not require to know the location or trajectory of each individual. Moreover, we also consider three types of mobility models and the static model of individuals. Numerical results show that analytical results well match with simulation results, thereby validating the accuracy of the proposed model. Moreover, numerical results also offer many insightful implications. Thereafter, we also offer a number of countermeasures against the spread of COVID-19 based on wireless edge networks. This study lays the foundation toward predicting the infectious risk in realistic environment and points out directions in mitigating the spread of infectious diseases with the aid of wireless edge networks.}
}


@article{DBLP:journals/jsac/ChenWJHTE22,
	author = {Xuan Chen and
                  Miaowen Wen and
                  Fei Ji and
                  Yu Huang and
                  Yuankun Tang and
                  Andrew W. Eckford},
	title = {Detection Interval of Aerosol Propagation From the Perspective of
                  Molecular Communication: How Long is Enough?},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3255--3270},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3211541},
	doi = {10.1109/JSAC.2022.3211541},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenWJHTE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a two-layer heterogeneous network to realize the remote monitoring and advanced warning for infectious diseases spread by airborne pathogens, whose detection can be considered as a binary detection problem. To intuitively study the detection process, we abstract it as a molecular communication via diffusion (MCvD) model and uncover that one of the key factors to impact the detection performance is inter-symbol interference (ISI), i.e., the viral aerosol from other biological entities. Therefore, overcoming ISI is imperative to ensure reliable detection. In the abstracted MCvD model, the detection performance can be described by the bit error rate (BER) performance. Following this assumption, we propose to optimize the detection interval to minimize the impact of ISI while ensuring the accurate detection of the transmitted information symbol, which is suitable for both the absorbing and passive receivers. For tractability, based on the signal-to-interference difference (SID) and signal-to-interference-and-noise amplitude ratio (SINAR), we design a modified-SINAR (mSINAR) to measure BER performance for the MCvD system with a variable detection interval. Besides, we derive the optimal detection interval in closed-form. Using simulation results, we show that in terms of BER, our proposed mSINAR scheme is superior to the competitive schemes, and performs similarly to the scheme with optimal intervals determined by the exhaustive search.}
}


@article{DBLP:journals/jsac/SangwanJ22,
	author = {Amit Sangwan and
                  Josep Miquel Jornet},
	title = {Joint Communication and Bio-Sensing With Plasmonic Nano-Systems to
                  Prevent the Spread of Infectious Diseases in the Internet of Nano-Bio
                  Things},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3271--3284},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3214288},
	doi = {10.1109/JSAC.2022.3214288},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SangwanJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advances in nanotechnology, novel nanosensing technologies can play a pivotal role in today’s society. Plasmonic sensing has demonstrated unprecedented detection reliability and resolution in a very compact form factor. Traditional plasmonic sensors leverage biofunctionalized metallic grating structures whose frequency response in transmission or reflection changes according to the presence of targeted biomarkers. However, these sensing setups require bulky measurement equipment to couple light to and from sensors for excitation and detection. In parallel, for over a decade, the nanoscale electromagnetic communication community has been leveraging plasmonic structures to transmit information at the nanoscale efficiently. By combining the two realms, this paper proposes the concept of joint nanoscale communication and bio-sensing systems enabled by plasmonic sensing nanoantennas. Sensing nanonodes can communicate from nanonode to nanonode for intra-body networks and from nanonode to a wearable device which, by leveraging the edge, can process and transmit the sensing information to the cloud, resulting in accurate diagnosis and reduced load on the medical testing infrastructure. First, we model the changes in the frequency response of a biofunctionalized plasmonic nanoantenna when exposed to different biomarkers. Then, we propose a chirp-spread spectrum excitation and detection system to enable simultaneous communication and sensing at the nanoscale. We present a data-driven human tissue model for communication through human tissue. We also present numerical results to demonstrate the performance of the proposed system.}
}


@article{DBLP:journals/jsac/AktasA22,
	author = {Dilara Aktas and
                  {\"{O}}zg{\"{u}}r B. Akan},
	title = {Weight Shift Keying {(WSK)} With Practical Mechanical Receivers for
                  Molecular Communications in Internet of Everything},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {11},
	pages = {3285--3294},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3211553},
	doi = {10.1109/JSAC.2022.3211553},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/AktasA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Molecular communication (MC) is one of the emerging technologies enabling nanonetworks and the Internet of Everything (IoE). The practical implementation of the intra-body MC systems is crucial for realizing smart healthcare applications, i.e., drug delivery, early detection, and health monitoring, through communication between nanomachines. A Flexure field-effect transistor (FET) based MC receiver, providing high sensitivity by utilizing nonlinear electromechanical coupling, has recently been proposed. It can also identify neutral molecules, unlike bioFETs. Thus, virus or pathogen detection can be performed with onboard computing by these receivers placed in the Edge. To date, biosensor-based MC receivers have been analyzed only for concentration shift keying (CSK), although weight shift keying (WSK) is a very robust modulation technique. The Flexure-FET-based MC receiver is a great candidate for use in a WSK-based MC system since its transduction mechanism relies on the molecular weight. This work presents the first practical approach to a WSK-based MC system with an improved Flexure-FET-based MC receiver. Its key performance metrics are analyzed from a theoretical MC perspective, also considering biological interference to obtain a more realistic simulation.}
}


@article{DBLP:journals/jsac/HuangKKXZKBY22,
	author = {Huawei Huang and
                  Salil S. Kanhere and
                  Jiawen Kang and
                  Zehui Xiong and
                  Lei Zhang and
                  Bhaskar Krishnamachari and
                  Elisa Bertino and
                  Sichao Yang},
	title = {Guest Editorial Special Issue on Intelligent Blockchain for Future
                  Communications and Networking: Technologies, Trends, and Applications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3299--3304},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3212898},
	doi = {10.1109/JSAC.2022.3212898},
	timestamp = {Fri, 28 Jun 2024 14:57:07 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuangKKXZKBY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain technology is becoming the cornerstone for the development and deployment of other technologies like Federated Learning (FL) and the Internet of Things (IoT), as it plays a critical role in data sharing and incentives. Blockchains supports decentralization, data-privacy protection, security, and reliability. Assuring secure data sharing in mobile computing and FL is challenging because of untrustworthy participants and unknown data quality. Blockchain provides trust in decentralized environments without requiring trusted third parties. By using smart contracts, blockchain has been able to supporting rich decentralized applications. However, the scalability of blockchain is a challenge that prevents its wide adoption by high-performance applications. To address the blockchain scalability issue, various blockchain sharding technologies and off-chain solutions have been proposed. To improve the network throughput, blockchain sharding divides the entire network into several smaller parallel groups and exploits fast consensus algorithms in blockchain shards. Off-chain solutions, such as payment channel networks (PCNs), transfer the slow on-chain transactions to the off-chain environment, in which transactions can be accelerated. Without consensus and on-chain expensive operations, off-chain scalable solutions significantly reduce transaction costs and increase transaction throughput. This special issue aims to provide a forum for the presentation of state-of-the-art research approaches that advance the construction of intelligent blockchain systems. A total of 27 articles were accepted after a two-round rigorous review process. Based on their topics, we have grouped the accepted articles into four categories: blockchain-based federated learning systems, blockchain and the IoT, blockchain scalability, and high-performance blockchains. In what follows, we introduce these articles and their contributions.}
}


@article{DBLP:journals/jsac/WangPSLBW22,
	author = {Yuntao Wang and
                  Haixia Peng and
                  Zhou Su and
                  Tom H. Luan and
                  Abderrahim Benslimane and
                  Yuan Wu},
	title = {A Platform-Free Proof of Federated Learning Consensus Mechanism for
                  Sustainable Blockchains},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3305--3324},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213347},
	doi = {10.1109/JSAC.2022.3213347},
	timestamp = {Fri, 19 Jan 2024 08:33:22 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangPSLBW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proof of work (PoW), as the representative consensus protocol for blockchain, consumes enormous amounts of computation and energy to determine bookkeeping rights among miners but does not achieve any practical purposes. To address the drawback of PoW, we propose a novel energy-recycling consensus mechanism named platform-free proof of federated learning (PF-PoFL), which leverages the computing power originally wasted in solving hard but meaningless PoW puzzles to conduct practical federated learning (FL) tasks. Nevertheless, potential security threats and efficiency concerns may occur due to the untrusted environment and miners’ self-interested features. In this paper, by devising a novel block structure, new transaction types, and credit-based incentives, PF-PoFL allows efficient artificial intelligence (AI) task outsourcing, federated mining, model evaluation, and reward distribution in a fully decentralized manner, while resisting spoofing and Sybil attacks. Besides, PF-PoFL equips with a user-level differential privacy mechanism for miners to prevent implicit privacy leakage in training FL models. Furthermore, by considering dynamic miner characteristics (e.g., training samples, non-IID degree, and network delay) under diverse FL tasks, a federation formation game-based mechanism is presented to distributively form the optimized disjoint miner partition structure with Nash-stable convergence. Extensive simulations validate the efficiency and effectiveness of PF-PoFL.}
}


@article{DBLP:journals/jsac/WangZQLNL22,
	author = {Xiaofei Wang and
                  Yunfeng Zhao and
                  Chao Qiu and
                  Zhicheng Liu and
                  Jiangtian Nie and
                  Victor C. M. Leung},
	title = {InFEDge: {A} Blockchain-Based Incentive Mechanism in Hierarchical
                  Federated Learning for End-Edge-Cloud Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3325--3342},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213323},
	doi = {10.1109/JSAC.2022.3213323},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangZQLNL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advances in communications and networking technologies are driving the computing paradigm toward the end-edge-cloud collaborative architecture to leverage ubiquitous data and resources. Opposite to centralized intelligence, Hierarchical Federated Learning (HFL) relieves overwhelmed communication overhead and enjoys the advantages of high bandwidth as well as abundant computing resources while retaining privacy-preserving benefits of Federated Learning (FL). It is difficult to balance system overhead and model performance in the HFL framework, while it could be solved by introducing an incentive mechanism. Although the incentive mechanism can alleviate the above anxiety by compensating relevant participants, some limitations (multi-dimensional properties, incomplete information and unreliable participants) will significantly degrade the performance and efficiency of the designed mechanism. To address the challenges caused by the above limitations, we propose InFEDge, a blockchain-based incentive mechanism in the HFL. The InFEDge considers 1) multi-dimensional individual properties to model system participants and proves the uniqueness of Nash equilibrium with the closed-form solution. Meanwhile, 2) we transform the problem under incomplete information into a contract game where we obtain the optimal solution. Moreover, 3) we also leverage the blockchain to provide economic incentives, prevent unreliable participants’ disturbance and further ensure data privacy by implementing the mechanism in the smart contract to offer a credible, faster, and transparent resource trading system. Experimental evaluations on a proof-of-concept testbed along with real traces demonstrate the superiority of our mechanism. Further, our method solves a real-world user allocation problem for future communications and networking.}
}


@article{DBLP:journals/jsac/ZhangZZZWN22,
	author = {Chuan Zhang and
                  Mingyang Zhao and
                  Liehuang Zhu and
                  Weiting Zhang and
                  Tong Wu and
                  Jianbing Ni},
	title = {{FRUIT:} {A} Blockchain-Based Efficient and Privacy-Preserving Quality-Aware
                  Incentive Scheme},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3343--3357},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213341},
	doi = {10.1109/JSAC.2022.3213341},
	timestamp = {Thu, 06 Apr 2023 13:35:41 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZZZWN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incentive plays an important role in knowledge discovery, as it impels users to provide high-quality knowledge. To promise incentive schemes with transparency, blockchain technology has been widely used in incentive schemes. Currently, privacy, reliability, streamlined processing, and quality awareness are major challenges in designing blockchain-based incentive schemes. In this paper, we design a blockchain-based eFficient and pRivacy-preserving qUality-aware IncenTive scheme called FRUIT. With well-designed smart contracts, FRUIT achieves privacy, reliability, streamlined processing, and quality awareness during the whole procedure. Specifically, we design a novel lightweight encryption method by combining matrix decomposition with proxy re-encryption and a privacy-preserving task allocation based on the polynomial fitting function and hash function. Then, we leverage our proposed lightweight encryption and task allocation to build an efficient and privacy-preserving knowledge discovery protocol in order to securely calculate the data quality and truthful knowledge. To promise user reliability in the incentive scheme, we utilize the Dirichlet distribution to realize the automatic reputation prediction based on the data quality by deploying the reputation management on the blockchain. Moreover, we also deploy the payment management on the blockchain, endowing the incentive scheme to reward participants based on the data quality automatically. Through a detailed security analysis, we demonstrate that data privacy and task privacy are well preserved during the whole process. Theoretical analysis and extensive experiments on real-world datasets demonstrate that FRUIT has acceptable efficiency and affordable performance in terms of computation cost, communication overhead, and gas consumption.}
}


@article{DBLP:journals/jsac/CuiSZ22,
	author = {Laizhong Cui and
                  Xiaoxin Su and
                  Yipeng Zhou},
	title = {A Fast Blockchain-Based Federated Learning Framework With Compressed
                  Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3358--3372},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213345},
	doi = {10.1109/JSAC.2022.3213345},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/CuiSZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, blockchain-based federated learning (BFL) has attracted intensive research attention due to that the training process is auditable and the architecture is serverless avoiding the single point failure of the parameter server in vanilla federated learning (VFL). Nevertheless, BFL tremendously escalates the communication traffic volume because all local model updates (i.e., changes of model parameters) obtained by BFL clients will be transmitted to all miners for verification and to all clients for aggregation. In contrast, the parameter server and clients in VFL only retain aggregated model updates. Consequently, the huge communication traffic in BFL will inevitably impair the training efficiency and hinder the deployment of BFL in reality. To improve the practicality of BFL, we are among the first to propose a fast blockchain-based communication-efficient federated learning framework by compressing communications in BFL, called BCFL. Meanwhile, we derive the convergence rate of BCFL with non-convex loss. To maximize the final model accuracy, we further formulate the problem to minimize the training loss of the convergence rate subject to a limited training time with respect to the compression rate and the block generation rate, which is a bi-convex optimization problem and can be efficiently solved. To the end, to demonstrate the efficiency of BCFL, we carry out extensive experiments with standard CIFAR-10 and FEMNIST datasets. Our experimental results not only verify the correctness of our analysis, but also manifest that BCFL can remarkably reduce the communication traffic by 95–98% or shorten the training time by 90–95% compared with BFL.}
}


@article{DBLP:journals/jsac/NguyenHLPB22,
	author = {Dinh C. Nguyen and
                  Seyyedali Hosseinalipour and
                  David J. Love and
                  Pubudu N. Pathirana and
                  Christopher G. Brinton},
	title = {Latency Optimization for Blockchain-Empowered Federated Learning in
                  Multi-Server Edge Computing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3373--3390},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213344},
	doi = {10.1109/JSAC.2022.3213344},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/NguyenHLPB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study a new latency optimization problem for blockchain-based federated learning (BFL) in multi-server edge computing. In this system model, distributed mobile devices (MDs) communicate with a set of edge servers (ESs) to handle both machine learning (ML) model training and block mining simultaneously. To assist the ML model training for resource-constrained MDs, we develop an offloading strategy that enables MDs to transmit their data to one of the associated ESs. We then propose a new decentralized ML model aggregation solution at the edge layer based on a consensus mechanism to build a global ML model via peer-to-peer (P2P)-based blockchain communications. Blockchain builds trust among MDs and ESs to facilitate reliable ML model sharing and cooperative consensus formation, and enables rapid elimination of manipulated models caused by poisoning attacks. We formulate latency-aware BFL as an optimization aiming to minimize the system latency via joint consideration of the data offloading decisions, MDs’ transmit power, channel bandwidth allocation for MDs’ data offloading, MDs’ computational allocation, and hash power allocation. Given the mixed action space of discrete offloading and continuous allocation variables, we propose a novel deep reinforcement learning scheme with a parameterized advantage actor critic algorithm. We theoretically characterize the convergence properties of BFL in terms of the aggregation delay, mini-batch size, and number of P2P communication rounds. Our numerical evaluation demonstrates the superiority of our proposed scheme over baselines in terms of model training efficiency, convergence rate, system latency, and robustness against model poisoning attacks.}
}


@article{DBLP:journals/jsac/ZhouLMW22,
	author = {Ao Zhou and
                  Sisi Li and
                  Xiao Ma and
                  Shangguang Wang},
	title = {Service-Oriented Resource Allocation for Blockchain-Empowered Mobile
                  Edge Computing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3391--3404},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213343},
	doi = {10.1109/JSAC.2022.3213343},
	timestamp = {Mon, 30 Oct 2023 12:08:58 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhouLMW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrating dense small cell (DSC) networks with mobile edge computing is employed by 5G to tackle the contradiction between the computation limitations of user equipment (UE) and the stringent latency requirement of services. This paper investigates the service-oriented edge resource allocation problem in DSC networks, determining where to deploy the service entity, how many service entities should be deployed at each edge cloud, and how to assign the UEs to service entities. The problem is challenging for the following three aspects: 1) Service entity deployment and UE assignment are highly coupled. 2) Due to the overlap of coverage regions of densely deployed small cells, the allocation mechanism of different base stations has mutual effects on the overall service performance. 3) Considering the limited resources of edge clouds, it is a thorny problem to encourage edge clouds to cache and share service startup images. We devote the following efforts to tackle the problem under these challenges. First, we explore blockchain’s decentralized, traceable, and secure characteristics, and propose a scheme to encourage image sharing in mobile edge computing. Second, we formulate the service-oriented edge resource allocation as mixed integer non-linear programming. Third, towards the target of reducing the computational complexity, we decouple UE assignment from service entity deployment and solve it through Gibbs sampling. Moreover, the power of Lyapunov optimization and convex optimization is incorporated to reduce the long-term power consumption and budget. Experiment results demonstrate the superiority of our approach over current notable solutions.}
}


@article{DBLP:journals/jsac/WangZOWQLXZ22,
	author = {Pengfei Wang and
                  Yian Zhao and
                  Mohammad S. Obaidat and
                  Zongzheng Wei and
                  Heng Qi and
                  Chi Lin and
                  Yunming Xiao and
                  Qiang Zhang},
	title = {Blockchain-Enhanced Federated Learning Market With Social Internet
                  of Things},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3405--3421},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213314},
	doi = {10.1109/JSAC.2022.3213314},
	timestamp = {Fri, 24 Nov 2023 12:32:47 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangZOWQLXZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The machine learning performance usually could be improved by training with massive data. However, requesters can only select a subset of devices with limited training data to execute federated learning (FL) tasks as a result of their limited budgets in today’s IoT scenario. To resolve this pressing issue, we devise a blockchain-enhanced FL market (BFL) to\n(i)\nmake data in computationally bounded devices available for training with social Internet of things,\n(ii)\nmaximize the amount of training data with given budgets for an FL task, and\n(iii)\ndecentralize the FL market with blockchain. To achieve these goals, we firstly propose a trust-enhanced collaborative learning strategy (TCL) and a quality-oriented task allocation algorithm (QTA), where TCL enables training data sharing among trusted devices with social Internet of things, and QTA allocates suitable devices to execute FL tasks while maximizing the training quality with fixed budgets. Then, we devise an encrypted model training scheme (EMT) based on a simple but countervailable differential privacy methodology to prevent attacks from malicious devices. In addition, we also propose a contribution-driven delegated proof of stake (DPoS) consensus mechanism to guarantee the fairness of reward distribution in the block generation process. Finally, extensive evaluations are conducted to verify the proposed BFL could improve the total utility of requesters and average accuracy of FL models significantly.}
}


@article{DBLP:journals/jsac/ZhangGXZC22,
	author = {Yue Zhang and
                  Keke Gai and
                  Jiang Xiao and
                  Liehuang Zhu and
                  Kim{-}Kwang Raymond Choo},
	title = {Blockchain-Empowered Efficient Data Sharing in Internet of Things
                  Settings},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3422--3436},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213353},
	doi = {10.1109/JSAC.2022.3213353},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangGXZC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sharing data across various Internet of Things (IoT) devices has been a common challenge due to efficiency, security, and stability issues. Blockchain, with security features, is considered to be a potential solution for data sharing in IoT settings. However, traditional blockchain-based solutions cannot satisfy the efficiency requirement of high-frequency data sharing among IoT devices. In this paper, we propose an efficient IoT data sharing approach by adopting the Payment Channel Network (PCN)-extended blockchain. Besides, we develop a homomorphic hashing-based transaction segmentation scheme to solve the issue of low transaction success ratio caused by channel deposit restrictions in PCN. In addition, a Multi-point Relay (MPR)-based multi-path routing scheme has been developed to ensure high-frequency transaction forwarding. The communication overhead of maintaining the routing table is reduced by our proposed Multi-point Relay Selection algorithm, and multiple alternate paths generated by Multiple Routing Path algorithm can improve the transaction success rate. Experiment evaluations have demonstrated that that our proposed approach outperforms the baseline approaches in terms of the transaction efficiency and success ratio.}
}


@article{DBLP:journals/jsac/XueLHSZSY22,
	author = {Liang Xue and
                  Dongxiao Liu and
                  Cheng Huang and
                  Xuemin Shen and
                  Weihua Zhuang and
                  Rob Sun and
                  Bidi Ying},
	title = {Blockchain-Based Data Sharing With Key Update for Future Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3437--3451},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213312},
	doi = {10.1109/JSAC.2022.3213312},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XueLHSZSY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future networks incorporate artificial intelligence to enable smart resource management and adaptive service provisioning. With a heterogeneous architecture and a large number of users in future networks, transparent and decentralized data sharing is required to promote data circulation and break data silos, for which blockchain is a potential solution to allow intelligent access permission control. However, it remains a challenging task to achieve flexible authorization management for blockchain-based data sharing and efficient key update for multi-users in case of key exposure. In this paper, we propose an intelligent blockchain-based data-sharing scheme with key update for future networks. First, we design a new encryption scheme, where keywords of data are extracted using machine learning algorithms that are published on the blockchain. Then, keywords of data and time validity are used to encrypt different types of data for flexible data authorization. Second, using hierarchical identity-based encryption, we construct an efficient key update mechanism, where update tokens are generated by invoking a smart contract deployed on the blockchain to facilitate key and ciphertext updates. We formally prove that the proposed scheme can guarantee three essential security properties: forward security, post-compromise security, and collusion attack resistance. On-chain and off-chain experiment results are provided to demonstrate that the proposed scheme can achieve computational and communication efficiency for key and ciphertext updates.}
}


@article{DBLP:journals/jsac/WangYYDZLQS22,
	author = {Weizheng Wang and
                  Yaoqi Yang and
                  Zhimeng Yin and
                  Kapal Dev and
                  Xiaokang Zhou and
                  Xingwang Li and
                  Nawab Muhammad Faseeh Qureshi and
                  Chunhua Su},
	title = {{BSIF:} Blockchain-Based Secure, Interactive, and Fair Mobile Crowdsensing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3452--3469},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213306},
	doi = {10.1109/JSAC.2022.3213306},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangYYDZLQS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the explosive growth of portable devices, mobile crowdsensing (MCS) is becoming an essential approach that fully utilizes pervasive idle resources to accomplish sensing tasks. The traditional MCS relies on the centralized server for task handle is susceptible to a single point of failure. Targeting this security issue, researchers have proposed a series of blockchain-based MCS. However, nodes in the blockchain suffer from high computation cost for data processing. Simultaneously, most blockchain-based MCS systems lack an efficient incentive mechanism for service requesters and workers. In this work, we integrate the smart contract and mobile devices to establish a secure, interactive, and fair blockchain-based MCS system called BSIF. To prevent illegitimate participants, BSIF requests all users to verify their identities using private keys from the registration phase. In the case of worker location privacy leakage, the location-based symmetric key generator is adopted to coordinate a session key for target range worker selection. Besides, we transfer the data evaluation process to the requester side (e.g., a personal computer), reducing computation cost in the blockchain nodes. Due to the homomorphic feature of the Paillier Cryptosystem and common interest, the requester cannot violate the directives from the blockchain. Subsequently, the Stackelberg game is adopted to investigate the participation level of the workers and the fair reward mechanism for the requesters to achieve a dynamic balance. Finally, the security analysis and performance evaluation demonstrate that our BSIF can defend against possible adversaries while significantly cutting overhead and giving participants the utmost incentive.}
}


@article{DBLP:journals/jsac/TangLLZH22,
	author = {Xiao Tang and
                  Xunqiang Lan and
                  Lixin Li and
                  Yan Zhang and
                  Zhu Han},
	title = {Incentivizing Proof-of-Stake Blockchain for Secured Data Collection
                  in UAV-Assisted IoT: {A} Multi-Agent Reinforcement Learning Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3470--3484},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213360},
	doi = {10.1109/JSAC.2022.3213360},
	timestamp = {Thu, 02 Nov 2023 16:27:12 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/TangLLZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) can be conveniently deployed while empowering various applications, where the IoT nodes can form clusters to finish certain missions collectively. In this paper, we propose to employ unmanned aerial vehicles (UAVs) to assist the clustered IoT data collection with blockchain-based security provisioning. In particular, the UAVs generate candidate blocks based on the collected data, which are then audited through a lightweight proof-of-stake consensus mechanism within the UAV-based blockchain network. To motivate efficient blockchain while reducing the operational cost, a stake pool is constructed at the active UAV while encouraging stake investment from other UAVs with profit sharing. The problem is formulated to maximize the overall profit through the blockchain system in unit time by jointly investigating the IoT transmission, incentives through investment and profit-sharing, and UAV deployment strategies. Then, the problem is solved in a distributed manner while being decoupled into two layers. The inner layer incorporates IoT transmission and incentive design, which are tackled with large-system approximation and one-leader-multi-follower Stackelberg game analysis, respectively. The outer layer for UAV deployment is undertaken with a multi-agent deep deterministic policy gradient approach. Results show the convergence of the proposed learning process and the UAV deployment, and also demonstrated the performance superiority of our proposal as compared with the baselines.}
}


@article{DBLP:journals/jsac/YaoWQZZXX22,
	author = {Su Yao and
                  Mu Wang and
                  Qiang Qu and
                  Ziyi Zhang and
                  Yi{-}Feng Zhang and
                  Ke Xu and
                  Mingwei Xu},
	title = {Blockchain-Empowered Collaborative Task Offloading for Cloud-Edge-Device
                  Computing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3485--3500},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213358},
	doi = {10.1109/JSAC.2022.3213358},
	timestamp = {Sun, 22 Oct 2023 11:15:51 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YaoWQZZXX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How to enable high-performance task offloading and preserve the trust between participants is imperative yet nontrivial to the Cloud-Edge-Device (CED) computing, mainly because the resources are geo-distributed and operated by different parties. Also, the CED participants are highly dynamic and heterogeneous in resource provision and may conflict in interest. This paper proposes BlockChain-empowered CED (BC-CED), a blockchain-empowered collaborative task offloading for CED computing. In BC-CED, blockchain plays a central role in the main functionality of CED, including task offloading, brokerage of resource usage, and incentives. We distinguish the BC-CED from the existing solutions by modifying the blockchain consensus process, enabling the participants to reach an agreement via solving the task offloading problem. For this purpose, we formulate the offloading problem by considering the computation capabilities of candidate nodes and the network performance. BC-CED allows each participant to apply reinforcement learning-based methods to solve this problem and compete for the right of block output by comparing the offloading policy performance and accepting the best policy as the offloading scheme within the next period. We also propose a truthful incentive mechanism to encourage resource contributions in BC-CED and force them to be honest. Extensive tests by implementing our solutions in a commercialized blockchain platform have shown how BC-CED achieves a superior performance in task offloading and blockchain maintenance.}
}


@article{DBLP:journals/jsac/TangWLZK22,
	author = {Fengxiao Tang and
                  Cong Wen and
                  Linfeng Luo and
                  Ming Zhao and
                  Nei Kato},
	title = {Blockchain-Based Trusted Traffic Offloading in Space-Air-Ground Integrated
                  Networks {(SAGIN):} {A} Federated Reinforcement Learning Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3501--3516},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213317},
	doi = {10.1109/JSAC.2022.3213317},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/TangWLZK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the future era of intelligent networks, communication technology and network architecture need to be further developed to provide users with high-quality services. The Space-Air-Ground Integrated Networks (SAGIN) is seen as a potential architecture to provide ubiquitous communication and drive the era of the intelligent global network. The space and air segments in SAGIN can assist in offloading traffic from the ground segment. However, in a highly dynamic and heterogeneous network like SAGIN, offloading decisions are easily affected by the incorporated/malicious nodes. How to ensure security and improve network performance becomes a critical problem. In this paper, we address the above problem by jointly using blockchain and federated reinforcement learning (FRL). Firstly, we propose a blockchain-based secure federated learning framework that combines topology information chain and model chain to assist traffic offloading. Then, we propose a node security evaluation and an enhanced practical byzantine fault tolerance (EPBFT) algorithm to secure the traffic offloading process. Furthermore, we describe the traffic offloading problem as a Markov decision problem (MDP) and employ the Blockchain-based Federated Asynchronous Advantage Actor-Critic (BFA3C) algorithm to solve this problem. Finally, the simulation results show that the BFA3C-based algorithm used in SAGIN with/without malicious nodes achieves superior performance in terms of latency and security.}
}


@article{DBLP:journals/jsac/SeidLAA22,
	author = {Abegaz Mohammed Seid and
                  Jianfeng Lu and
                  Hayla Nahom Abishu and
                  Tewodros Ayall},
	title = {Blockchain-Enabled Task Offloading With Energy Harvesting in Multi-UAV-Assisted
                  IoT Networks: {A} Multi-Agent {DRL} Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3517--3532},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213352},
	doi = {10.1109/JSAC.2022.3213352},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SeidLAA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned Aerial Vehicle (UAV) is a promising technology that can serve as aerial base stations to assist Internet of Things (IoT) networks, solving various problems such as extending network coverage, enhancing network performance, transferring energy to IoT devices (IoTDs), and perform computationally-intensive tasks of IoTDs. Heterogeneous IoTDs connected to IoT networks have limited processing capability, so they cannot perform resource-intensive activities for extended periods. Additionally, IoT network is vulnerable to security threats and natural calamities, limiting the execution of real-time applications. Although there have been many attempts to solve resource scarcity through computational offloading with Energy Harvesting (EH), the emergency and vulnerability issues have still been under-explored so far. This paper proposes a blockchain and multi-agent deep reinforcement learning (MADRL) integrated framework for computation offloading with EH in a multi-UAV-assisted IoT network, where IoTDs obtain computing and energy resources from UAVs. We first formulate the optimization problem as the joint optimization problem of computation offloading and EH problems while considering the optimal resource price. And then, we model the optimization problem as a Stackelberg game to investigate the interaction between IoTDs and UAVs by allowing them to continuously adjust their resource demands and pricing strategies. In particular, the formulated problem can be addressed indirectly by a stochastic game model to minimize computation costs for IoTDs while maximizing the utility of UAVs. The MADRL algorithm solves the defined problem due to its dynamic and large-dimensional properties. Finally, extensive simulation results demonstrate the superiority of our proposed framework compared to the state-of-the-art.}
}


@article{DBLP:journals/jsac/LiuCP22,
	author = {Weikang Liu and
                  Bin Cao and
                  Mugen Peng},
	title = {Blockchain Based Offloading Strategy: Incentive, Effectiveness and
                  Security},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3533--3546},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213324},
	doi = {10.1109/JSAC.2022.3213324},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuCP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To securely integrate Mobile Edge Computing (MEC) into Wireless Blockchain Network (WBN), this paper proposes a framework for blockchain based offloading strategy, where blockchain nodes are categorized as blockchain users and blockchain miners from a motivation perspective. Particularly, aiming at improving the motivation ability, a block generation process is first designed for blockchain miners’ short transaction processing time lower bound. Then, to further maximize the utilities of both blockchain users and blockchain miners, an optimization problem is formulated to determine an optimal strategy which involves a trade-off between the fast transaction confirmation rate required by blockchain users and the transaction fees obtained by blockchain miners. A Stackelberg game is introduced to model the interaction between the blockchain users and miners. Meanwhile, a distributed algorithm is designed to converge this strategy in an iterative manner based on the buyer-seller negotiation. Additionally, double-spending attack and selfish mining attack are analysed to examine their impact on the system performance in terms of confirmation delay and throughput while guaranteeing the high security level. Finally, extensive experiments have been conducted to show the rightness and effectiveness of the proposed equilibrium-based strategy and mathematical analysis, and some insights are discussed for the further guide as well.}
}


@article{DBLP:journals/jsac/WangCYLWYW22,
	author = {En Wang and
                  Jiatong Cai and
                  Yongjian Yang and
                  Wenbin Liu and
                  Hengzhi Wang and
                  Bo Yang and
                  Jie Wu},
	title = {Trustworthy and Efficient Crowdsensed Data Trading on Sharding Blockchain},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3547--3561},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213331},
	doi = {10.1109/JSAC.2022.3213331},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangCYLWYW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of communications, networking, and information technology, Crowdsensed Data Trading (CDT) becomes a novel data trading paradigm. In CDT, the data requesters publish crowdsensing tasks with specific data requirements, and then workers complete these tasks, upload the data and obtain corresponding rewards. To efficiently deal with data trading, most of the existing CDT systems assume a trusted centralized platform. However, we argue that the platform may collude with workers or requesters to trick others for achieving more benefits. For example, according to the workers’ uploaded data, the platform can modify the reward functions by colluding with the requester. Similarly, the platform might collude with workers to let them know the reward function, then workers could forge data. Meanwhile, requesters and workers may also be malicious. For example, requesters may post tasks but fail to pay and workers can upload wrong data to mislead the system. To solve the above problems, we combine the Crowdsensed Data Trading system with intelligent Blockchain (CDT-B), which contains a smart contract called CDToken. As a credible third-party, the CDToken is used to record the requesters’ reward function and workers’ data uploading function to avoid targeted trick. At the same time, we not only design a Data Uploading and Preprocessing (DUP) mechanism in CDToken to collect and process the workers’ sensed data, but also propose a Grouping Truth Discovery (GTD) to evaluate their data quality for determining the payments. Moreover, to hold a large number of requesters and workers in CDT-B, we propose a Layered Sharding blockchain based on Membership Degree (LSMD) to solve the blockchain inefficiency problem. Finally, we deploy CDToken to an experimental environment based on Ethereum and demonstrate its efficient performance and practicability.}
}


@article{DBLP:journals/jsac/ZhengXZZYZ22,
	author = {Peilin Zheng and
                  Quanqing Xu and
                  Zibin Zheng and
                  Zhiyuan Zhou and
                  Ying Yan and
                  Hui Zhang},
	title = {Meepo: Multiple Execution Environments per Organization in Sharded
                  Consortium Blockchain},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3562--3574},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213326},
	doi = {10.1109/JSAC.2022.3213326},
	timestamp = {Mon, 05 Feb 2024 20:23:18 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengXZZYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain performance cannot meet the requirement nowadays. One of the crucial ways to improve performance is sharding. However, most blockchain sharding research focuses on the public blockchain. As for consortium blockchain, previous studies cannot support high cross-shard efficiency, multiple-shard contract calling, strict transaction atomicity, and shard availability, which are essential requirements but also challenges in consortium blockchain systems. Facing these challenges, we propose Meepo, a systematic study on sharded consortium blockchain. Meepo enhances cross-shard efficiency via the cross-epoch and cross-call. Moreover, a partial cross-call merging strategy is designed to handle the multi-state dependency in contract calls, achieving flexible multiple-shard contract calling. Meepo employs a replay-epoch to ensure strict transaction atomicity, and it also uses a backup algorithm called shadow shard based recovery to improve the shard robustness. On a test-bed of 128 AliCloud servers, setting 32 shards and 4 consortium members, Meepo-OpenEtheruem can achieve more than 140,000 cross-shard TPS under the workload of 100,000,000 asset transactions. It also shows more than 50,000 TPS under the transactions of real-world shopping behaviors.}
}


@article{DBLP:journals/jsac/HongGL22,
	author = {Zicong Hong and
                  Song Guo and
                  Peng Li},
	title = {Scaling Blockchain via Layered Sharding},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3575--3588},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213350},
	doi = {10.1109/JSAC.2022.3213350},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HongGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a promising solution to blockchain scalability, sharding divides blockchain nodes into small groups called shards, splitting the workload. Existing works for sharding, however, are limited by cross-shard transactions, since they need to split each cross-shard transaction into multiple sub-transactions, each of which costs a consensus round to commit. In this paper, we introduce PYRAMID, a novel sharding system based on the idea of layered sharding. In PYRAMID, the nodes with better hardware are allowed to participate in multiple shards and store the blockchains of these shards thus they can validate and execute the cross-shard transactions without splitting. Next, to commit the cross-shard transactions with consistency among the related shards, we design a cooperative cross-shard consensus based on collective signature-based inter-shard collaboration. Furthermore, we present an optimization framework to compute an optimal layered sharding strategy maximizing the transaction throughput with the constraint of system security and node resource. Finally, we implement a prototype for PYRAMID based on Ethereum and the experimental results reveal the efficiency of PYRAMID in terms of performance and scalability, especially in workloads with a high percentage of cross-shard transactions. PYRAMID improves the throughput by up to 3.2 times compared with the state-of-the-art works and achieves about 3821 transaction per seconds for 20 shards.}
}


@article{DBLP:journals/jsac/LuoL22,
	author = {Xiaofei Luo and
                  Peng Li},
	title = {Learning-Based Off-Chain Transaction Scheduling in Prioritized Payment
                  Channel Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3589--3599},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213333},
	doi = {10.1109/JSAC.2022.3213333},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LuoL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Payment channel network (PCN) is one of the promising solutions for scalable blockchains since it shows great potential in improving blockchain network throughput. However, the growing number of transactions and the payment-channel sharing of concurrent transactions can lead to channel congestion. Although many studies have proposed different solutions to solve this problem, they ignore a fact that applications may have different transaction rate requirements at different times. In this paper, we propose a priority-aware PCN to meet the requirements of those transactions. Senders in priority-aware PCNs can specify the priority of their transactions by paying a corresponding forwarding fee on each hop along the transaction path. However, capacity competition occurs on the shared hops. Moreover, we propose a multi-agent DQN-based priority assignment algorithm to address the competition issue and design a PCN simulator for performance evaluation. Simulation results show that our solution can guarantee a high throughput of transactions and assign priorities appropriately to balance the transaction rate and forwarding fee cost. The experimental results demonstrate that the priority scheduling scheme can achieve higher transaction throughput and success ratio than other scheduling methods in a congested PCN environment.}
}


@article{DBLP:journals/jsac/DuYTH22,
	author = {Miao Du and
                  Peng Yang and
                  Wen Tian and
                  Zhu Han},
	title = {Anti-Collusion Multiparty Smart Contracts for Distributed Watchtowers
                  in Payment Channel Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3600--3614},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213355},
	doi = {10.1109/JSAC.2022.3213355},
	timestamp = {Fri, 19 Jan 2024 08:33:22 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/DuYTH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Leveraging watchtowers to monitor payment channel networks (PCNs) is regarded to be a promising option to ensure off-chain transaction security and boost cryptocurrency scalability. However, existing solutions have two major limitations: First, since the watchtower’s inaction or collusion with counterparties, the deposits in off-chain transactions will be threatened; Second, due to occasional false positives, the efficiency of the single watchtower in monitoring the payment channels for fraud is questionable. To solve this, we present anti-collusion multiparty smart contracts for distributed watchtowers in PCNs. Specifically, we first design the distributed watchtower mechanism to solve the false positive problem in regulating PCNs. In addition, we utilize smart contracts to constrain and force counterparties to relinquish collusion in the distributed watchtower mechanism, thus making collusion impossible for rational parties. We further offer a mathematical proof and contract implementation in Solidity. Finally, extensive experiments and contracts executed on Ethereum under various benchmarks with baseline comparison demonstrate the validity of our proposals. Specifically, our scheme can both improve the throughput and accuracy by up to 20-25% and 10-15%, respectively, and reduce the false positive rate by up to 10% compared with existing single watchtower mechanism.}
}


@article{DBLP:journals/jsac/LiSXYNX22,
	author = {Zhenni Li and
                  Wensheng Su and
                  Minrui Xu and
                  Rong Yu and
                  Dusit Niyato and
                  Shengli Xie},
	title = {Compact Learning Model for Dynamic Off-Chain Routing in Blockchain-Based
                  IoT},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3615--3630},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213283},
	doi = {10.1109/JSAC.2022.3213283},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiSXYNX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic off-chain routing in payment channel network (PCN)-based Internet of Things (IoT) is attracting increasing research attention. However, there are two major issues in dynamic routing in PCN-based IoT with resource-limited devices. The first issue is how to achieve high long-term transaction efficiency in PCN with dynamic channel capacities. The second issue is how to achieve a lightweight routing algorithm deployed on IoT devices while achieving high transaction efficiency, i.e., successful payment amount and success ratio. Therefore, in this paper, we propose a compact deep reinforcement learning (DRL) algorithm to learn the joint dynamic and lightweight routing policy for maximizing long-term transaction efficiency. To obtain optimal performance in dynamic routing problems for off-chain systems, a proximal policy optimization algorithm is employed to create an actor–critic learning structure for training the teacher DRL model. To obtain a compact and efficient student DRL model, an adaptive pruning technique is utilized for pruning unnecessary parameters of networks in the teacher model adaptively without affecting its learning ability. Furthermore, knowledge distillation is leveraged to improve the performance of the student network. Thus, a compact and efficient student DRL model can be developed and implemented to maximize the long-term transaction efficiency in off-chain systems on resource-limited IoT devices. The simulation results demonstrate that the proposed DRL algorithm outperforms the other baseline algorithms in PCN transaction efficiency while requiring only 10% of the computation and storage resources compared with that of the original teacher model.}
}


@article{DBLP:journals/jsac/WangJLWS22,
	author = {Xin Wang and
                  Xin Jiang and
                  Yanxiu Liu and
                  Jiaping Wang and
                  Yi Sun},
	title = {Data Propagation for Low Latency Blockchain Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3631--3644},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213330},
	doi = {10.1109/JSAC.2022.3213330},
	timestamp = {Fri, 22 Mar 2024 09:01:01 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangJLWS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Broadcasting plays a vital role in the consensus mechanisms of blockchain systems, since the consensus of each block must wait until the previous block is received by (nearly) all the nodes in the blockchain systems. Therefore, optimizing the performance of broadcasting can significantly improve the performance of the blockchain system. However, compared with other traditional P2P applications such as file downloading or video delivery, the broadcasting in blockchain has two new requirements, namely low redundancy and low propagation latency, which all the existing mechanisms (e.g. flooding, structural DHT etc.) can not meet well. In this paper, we propose Swift, a new broadcasting mechanism for blockchain systems. It optimizes the P2P topology construction and broadcast algorithm in the structured network based on unsupervised learning and greedy algorithm, effectively reducing the propagation latency of the blockchain P2P network while avoiding the waste of redundant bandwidth. We implemented a prototype of Swift and evaluated its performance on a testbed network that consists of 1000 blockchain nodes. The experimental findings show that Swift can reduce propagation latency by 19.8% with similar bandwidth consumption, generating an 18% increase in the throughput performance of the blockchain. Finally, with the increase in connections, Swift can simultaneously achieve low latency and maintain a relatively stable redundant bandwidth waste, instead of linearly increasing in flooding.}
}


@article{DBLP:journals/jsac/LiuKFCCH22,
	author = {Yunshu Liu and
                  Shulin Ke and
                  Zhixuan Fang and
                  Man Hon Cheung and
                  Wei Cai and
                  Jianwei Huang},
	title = {A Storage Sustainability Mechanism With Heterogeneous Miners in Blockchain},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3645--3659},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213309},
	doi = {10.1109/JSAC.2022.3213309},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuKFCCH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In current blockchain systems, the transaction fee is often not enough to cover the storage cost, jeopardizing blockchain sustainability in the long run. Such a storage sustainability issue is partially due to miners’ heterogeneous storage costs and users’ low-intensity fee competition. Motivated by these two observations, we propose a Fee and Transaction Expiration Time (FTET) mechanism to alleviate this issue. Specifically, we model the blockchain operation as a three-stage game. In Stage I, the system designer proposes the storage sustainability mechanism. In Stage II, each user decides whether to propose transactions and the corresponding transaction fees. In Stage III, each miner decides which transactions to include in the block. Although the analysis of the heterogeneous miner interaction is technically challenging, we fully solve it in closed-form motivated by how miners select transactions in practice. The equilibrium analysis reveals that high-storage-cost miners admit transactions with fees above a time-increasing threshold. Under the optimal FTET mechanism, the blockchain system can achieve the storage sustainability without any social welfare loss, comparing with the maximum achievable social welfare without the storage sustainability constraint. Moreover, the optimal FTET mechanism achieves a higher social welfare than the fee mechanism in current practice by selectively rejecting some transactions suffering high delays. Finally, we implement a blockchain prototype to compare the performance of the optimal FTET mechanism with the mining round time adjustment (MRTA) mechanism. The optimal FTET mechanism achieves higher social welfare (94.5% on average) and better storage sustainability. We find that more pending transactions may lead to lower transaction fees.}
}


@article{DBLP:journals/jsac/JinLXZDL22,
	author = {Hai Jin and
                  Chenchen Li and
                  Jiang Xiao and
                  Teng Zhang and
                  Xiaohai Dai and
                  Bo Li},
	title = {Detecting Arbitrage on Ethereum Through Feature Fusion and Positive-Unlabeled
                  Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3660--3671},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213335},
	doi = {10.1109/JSAC.2022.3213335},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/JinLXZDL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the lack of supervision in the decentralized exchanges (DEXs), arbitrageurs can utilize information and take advantage of price gap to make profits over such platforms such as Ethereum blockchain. DEX arbitrage poses possibilities and opportunities for defrauding and can seriously impair the operation of the Ethereum ecosystem. It motivates this work to explore and characterize the unique features of arbitrage which differ from other frauds such as money laundering and Ponzi games for better detection. This work makes the first attempt for detecting arbitrage on Ethereum through feature fusion and positive-unlabeled learning (PU learning). We first conduct an in-depth analysis and exploit two-fold arbitrage features by fusion including: 1) statistical features that explicitly represent the node activity levels according to expert knowledge; and 2) structural features that implicitly encode the transactions information by graph machine learning. We then apply PU learning to generate negative instances for compensating the imbalanced arbitrage datasets. We evaluate our proposed method through extensive experiments over a real-world dataset and demonstrate that it can achieve 90% accuracy in detecting arbitrage activities on Ethereum.}
}


@article{DBLP:journals/jsac/XuLLSXWL22,
	author = {Hao Xu and
                  Xiulong Liu and
                  Zhelin Liang and
                  Hongyan Sun and
                  Weilian Xue and
                  Jianrong Wang and
                  Keqiu Li},
	title = {A Transaction Cardinality Estimation Approach for QoS-Adjustable Intelligent
                  Blockchain Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3672--3684},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213327},
	doi = {10.1109/JSAC.2022.3213327},
	timestamp = {Wed, 20 Mar 2024 17:39:31 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XuLLSXWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of the blockchain leads to a blowout of on-chain transactions, contracts, and currencies, which will further accelerate the increase of data. The existing blockchain systems typically support exact transaction queries, which, however, cannot satisfy the QoS requirements with intelligent adjustment in the blockchain systems. To this end, this paper takes the first step to define and address the practically important problem of transaction cardinality estimation for QoS-adjustable intelligent blockchain systems. We first establish a mathematical relationship between the bit string and transaction cardinality. Thus, we can leverage the number of leading 1s of the obtained bit string to estimate the transaction cardinality. We then improve the block header and body with a corresponding search algorithm to access bit strings in blocks. We also propose an estimation protocol with intelligent adjustable QoS to support accuracy-guaranteed and efficiency-optimized estimation. Finally, we design an authentication scheme and guarantee the reliability of our protocol through rigorous theoretical derivation. When achieving the transaction cardinality estimation in blockchain, two technical challenges need to be addressed. (i) To ensure efficient, verifiable, and overhead-saving bit string accessing mechanism in blockchain, we propose the Merkle Cardinality Tree (MCT) and target block filtering mechanism based on Bloom Filter (BF) in off-chain and improve on-chain block header by joining the abstract of MCT and BF. (ii) To improve estimation efficiency while guaranteeing accuracy requirements in hybrid blockchain scheme, we propose a Dynamic One-round Sampling-based cardinality Estimation (DOSE) protocol and integrate BF-DOSE to intelligently accelerate estimation. We build MCT in Ethereum and store the MCT Root in the block header for estimation authentication. Extensive experiments reveal that our BF-DOSE protocol can well satisfy various accuracy and efficiency requirements of QoS-adjustable intelligent blockchain systems, and is one to two orders of magnitude faster compared with benchmark schemes.}
}


@article{DBLP:journals/jsac/ChenCF22,
	author = {Canhui Chen and
                  Xu Chen and
                  Zhixuan Fang},
	title = {{TIPS:} Transaction Inclusion Protocol With Signaling in DAG-Based
                  Blockchain},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3685--3701},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213357},
	doi = {10.1109/JSAC.2022.3213357},
	timestamp = {Mon, 05 Dec 2022 13:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenCF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Directed Acyclic Graph (DAG) is a popular approach to achieve scalability of blockchain networks. Due to its high efficiency in data communication and great scalability, DAG has been widely adopted in many applications such as Internet of Things (IoT) and Decentralized Finance (DeFi). DAG-based blockchain, nevertheless, faces the key challenge of transaction inclusion collision due to the high concurrency and the network delay. Particularly, the transaction inclusion collision in DAG-based blockchain leads to the revenue and throughput dilemmas, which would greatly degrade the system performance. In this paper, we propose “TIPS”, the Transaction Inclusion Protocol with Signaling, which broadcasts a signal indicating the transactions in the block. We show that with the prompt broadcast of a signal, TIPS substantially reduces the transaction collision and thus resolves these dilemmas. Moreover, we show that TIPS can defend against both the denial-of-service and the delay-of-service attacks. We also conduct intensive experiments to demonstrate the superior performance of the proposed protocol.}
}


@article{DBLP:journals/jsac/CaoWYXLW22,
	author = {Mingpei Cao and
                  Hao Wang and
                  Tailing Yuan and
                  Kun Xu and
                  Kai Lei and
                  Jiaping Wang},
	title = {Meta-Regulation: Adaptive Adjustment to Block Size and Creation Interval
                  for Blockchain Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {40},
	number = {12},
	pages = {3702--3718},
	year = {2022},
	url = {https://doi.org/10.1109/JSAC.2022.3213338},
	doi = {10.1109/JSAC.2022.3213338},
	timestamp = {Tue, 23 Jan 2024 07:32:44 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/CaoWYXLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Once deployed, a decentralized blockchain system ensures that it will operate faithfully so that no one can interfere with or manipulate its predefined regulations, such as block size and block creation interval investigated in this paper. However, fixed regulations prevent that system from adapting to the change of the environment, such as increasing the underlying network capacity, and result in sub-optimal performance. For example, Bitcoin remains at 7 TPS (transactions per second), even operating over the current Internet. In this paper, we propose a new paradigm for defining the behavior of a consensus system, named as Meta-Regulation, which allows autonomous evolution of the system behavior. A meta-regulation adjusts the actual behavior of a consensus system in response to the changing capacity of the underlying infrastructure and the community of participants. We demonstrate the effectiveness of the proposed meta-regulation by achieving significantly improved throughput and latency for Bitcoin, adapted to the current capacity of the Internet. Our experimental results show that Meta-Regulation can achieve at least\n7×\nperformance improvement over Bitcoin network deployed in 2009, resulting in 49.7 TPS or 68% reduction confirmation latency by fully utilizing the bandwidth and the computing power of average network nodes.}
}
