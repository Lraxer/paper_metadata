@article{DBLP:journals/jsac/AmendolaCBJYZ24,
	author = {Danilo Amendola and
                  Nicola Cordeschi and
                  Fan Bai and
                  Yusheng Ji and
                  Shen Yan and
                  Weihua Zhuang},
	title = {Guest Editorial Special Issue on 5G/6G Precise Positioning on Cooperative
                  Intelligent Transportation Systems {(C-ITS)} and Connected Automated
                  Vehicles {(CAV)} - Part {II}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {1--5},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322070},
	doi = {10.1109/JSAC.2023.3322070},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/AmendolaCBJYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This is Part II of the two-part Special Issue (SI) on 5G/6G Precise Positioning on Cooperative Intelligent Transportation Systems (C-ITS) and Connected Automated Vehicles (CAV). The SI aims at bringing together contribution from both academia and industry to highlight the recent progress in various aspects of positioning systems. We have included 30 original contributions in this two-parts SI. We kindly refer readers to Part I of this SI for a comprehensive overview written by the Guest Editorial Team.}
}


@article{DBLP:journals/jsac/WuZML24,
	author = {Guangyu Wu and
                  Fuhui Zhou and
                  Chengzhen Meng and
                  Xiang{-}Yang Li},
	title = {Precise {UAV} MMW-Vision Positioning: {A} Modal-Oriented Self-Tuning
                  Fusion Framework},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {6--20},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322851},
	doi = {10.1109/JSAC.2023.3322851},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WuZML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Precise real-time unmanned aerial vehicle (UAV) positioning is crucial for preventing unauthorized UAVs from damaging cooperative intelligent transportation systems (C-ITSs). However, UAV positioning remains extremely challenging due to the small target size and high flexibility. Therefore, we develop a modal-oriented self-tuning fusion framework for precise UAV millimeter-wave(MMW)-vision positioning. The framework selects and extracts cross-modal features based on modality characters, and migrates the Doppler features of MMW radar data to the image features for precise pixel-level positioning. Based on the framework, a modal-oriented self-tuning fusion network is proposed to adaptively enhance UAV feature without direct supervision by exploiting the cross-modal correlations. A novel characteristic-based 3DMMW feature extraction method is presented to extract UAV Doppler motion characteristics while a self-tuning cross-modal affine transfer is proposed for UAV visual feature enhancement. Due to lack of dataset for our task, we establish a practical positioning platform and two novel datasets containing synchronized visual images and MMW radio frequency (RF) sequences in various scenarios. Experimental results confirm that our framework outperforms the benchmark methods in terms of positioning accuracy while maintaining real-time performance. Moreover, ablation studies also confirm the effectiveness of each module in the framework.}
}


@article{DBLP:journals/jsac/GuZLZZZ24,
	author = {Xiaobo Gu and
                  Chengye Zheng and
                  Zeyu Li and
                  Guoxu Zhou and
                  Haibo Zhou and
                  Lian Zhao},
	title = {Cooperative Localization for {UAV} Systems From the Perspective of
                  Physical Clock Synchronization},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {21--33},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322797},
	doi = {10.1109/JSAC.2023.3322797},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/GuZLZZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The positioning accuracy determines the scope of the application of an unmanned aerial vehicle (UAV). In view of the existing UAV cooperative localization methods that normally require prior information and the assistance of external systems, such as the global positioning system (GPS), this study aims to adopt range radios to measure the time-of-arrival (TOA) information among UAVs and then perform clock synchronization and cooperative localization based on ranging measurements. We propose a framework to jointly estimate the clock error and relative distance, adjust the onboard clock, and perform relative positioning. To achieve autonomous clock synchronization and ranging, a practical approach based on peer-to-peer pseudorange measurements is proposed in this study. We modeled the synchronous two-way ranging (STWR) process using a discretetime state-space model, according to which a linear parameter estimation method and clock steering method are presented. Finally, a closed loop consisting of STWR, parameter estimation, and clock tuning is constructed to improve the ranging accuracy, which leads to improved localization accuracy. Simulation results show that the proposed approach outperforms existing methods and can achieve sub-nanosecond-level time synchronization and meter-level cooperative localization.}
}


@article{DBLP:journals/jsac/XuZLPYY24,
	author = {Xueting Xu and
                  Yang Zhou and
                  Huiying Li and
                  Ao Peng and
                  Qiang Ye and
                  Qi Yang},
	title = {RIS-Aided Passive Detection for {LSS} Targets: {A} {GNSS} Multipath-Assisted
                  Scheme},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {34--51},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322801},
	doi = {10.1109/JSAC.2023.3322801},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XuZLPYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The complex topography of urban canyons with many reflectors and scatterers makes it challenging to detect low-altitude, smaller, and slow-speed targets. In this paper, we present a novel multipath-assisted passive detection scheme based on the global navigation satellite system signals in urban canyons. We first propose an information-level target detection scheme, where a binary hypothesis test is conducted according to variation in the received signal given the presence or absence of targets in the environment. To take usage of multipath components (MPCs) in the proposed scheme, we introduce virtual anchors to model reflected signals’ propagation paths. We also introduce the reconfigurable intelligent surface to artificially improve the reflective environment and enhance the quality of received MPCs. The detection performance indicators are analyzed theoretically. Simulation results show that the proposed schemes respectively reach 90% and 94% detection probability at a signal-to-noise ratio of 5 dB. The RIS-based method outperforms the multipath-assisted method when the RIS error is less than 0.41 m.}
}


@article{DBLP:journals/jsac/NguyenTFCCBV24,
	author = {Tan N. Nguyen and
                  Lam{-}Thanh Tu and
                  Peppino Fazio and
                  Trinh Van Chien and
                  Le Van Cuong and
                  Huynh Thi Thanh Binh and
                  Miroslav Vozn{\'{a}}k},
	title = {On the Dilemma of Reliability or Security in Unmanned Aerial Vehicle
                  Communications Assisted by Energy Harvesting Relaying},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {52--67},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322756},
	doi = {10.1109/JSAC.2023.3322756},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/NguyenTFCCBV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, we investigate the trade-off between reliability and security in unmanned aerial vehicle (UAV) communications systems, considering a UAV-terrestrial network aided by a relay powered by a dedicated power beacon. For this system, we derive the outage probability (OP) under both exact and approximate frameworks and compute the approximations in the closed-form expressions. For the security aspect, we also derive the intercept probability (IP) under exact and approximated frameworks. To minimize the IP, a friendly jamming technique is employed whereby the power beacon constantly broadcasts artificial noise (AN) toward an eavesdropper. Based on the derived mathematical framework, we then formulate a bi-objective optimization problem by jointly minimizing the OP and IP with respect to the UAV’s position and the time-switching (TS) ratio. A suitable algorithm, named non-dominated sorting genetic algorithm version II (NSGA-II), is deployed to obtain the sub-optimal solution. Finally, numerical results are presented to verify the accuracy of the proposed mathematical framework and the superiority of jointly minimizing both the OP and IP using only the channel statistics.}
}


@article{DBLP:journals/jsac/ZhuMK24,
	author = {Yishi Zhu and
                  Bomin Mao and
                  Nei Kato},
	title = {On a Novel High Accuracy Positioning With Intelligent Reflecting Surface
                  and Unscented Kalman Filter for Intelligent Transportation Systems
                  in {B5G}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {68--77},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322805},
	doi = {10.1109/JSAC.2023.3322805},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhuMK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High accuracy and simultaneous positioning is an essential demand in future Intelligent Transportation Systems (ITS), while the mobility and dynamics of vehicles place great challenges. Single Base Station (BS) positioning has become popular for its fast speed, high convenience, and low cost. With the construction of 5G, the wide bandwidth and high separation capability of millimeter Wave (mmWave) bring more possibilities for vehicle positioning via single BS. However, mmWave signals have high distance attenuation and are easily blocked by obstacles. In urban scenarios, the prevalent None-Line-of-Sight (NLoS) situations have severe impacts on positioning accuracy. The multipath effects, Doppler effects, and tracking lags further degrade the performance. To address these issues, we introduce the Intelligent Reflecting Surface (IRS) to single BS vehicle positioning for beyond Line-of-Sight (LoS) communications. We study the advantages of IRS in urban ITS to alleviate the multipath effects, Doppler effects, and tracking delay. To realize the real-time target tracking for IRS, the Unscented Kalman Filter (UKF) is adopted, for which stable communications between the BS and moving vehicle can be maintained. Simulation results show that the utilization of IRS can significantly improve the positioning accuracy and the adoption of UKF further enhances the performance.}
}


@article{DBLP:journals/jsac/HeWZLXS24,
	author = {Wei He and
                  Yong Wang and
                  Mu Zhou and
                  Ruidong Li and
                  Liangbo Xie and
                  Zhou Su},
	title = {An Efficient and Robust Fusion Positioning System Based on Entangled
                  Photons},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {78--92},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322759},
	doi = {10.1109/JSAC.2023.3322759},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HeWZLXS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Precise positioning is a key factor and enabler technology for many use cases on intelligent transportation systems (ITS) and connected and automated vehicles (CAVs). Recently, the quantum positioning system (QPS) based on quantum ranging has emerged as a novel way to improve security and precision. As a key process of QPS, the entangled photons based ranging technology has picosecond-level clock synchronization, and the ranging accuracy can reach the Heisenberg limit. If promising QPS is deployed in the ITS and CAVs, it will cause a profound change. However, the existing QPS still lacks accuracy and robustness in different scenarios. To solve this problem, we proposed an efficient and robust fusion positioning system based on entangled photons. In this system, we derive the ranging accuracy limit with many factors and propose a fast data grouping and selection algorithm to improve real-time performance. Furthermore, we propose a fusion extended fingerprint localization method for robust positioning in the dynamic environment. The effectiveness and robustness of the system are verified by extensive experiments. When the range is 15m, the ranging accuracy can be limited to 0.0018m. The proposed system achieves the probability of positioning errors 90% within 0.13m with only two APs.}
}


@article{DBLP:journals/jsac/ZookSY24,
	author = {Yousef Zook and
                  Ahmed Shokry and
                  Moustafa Youssef},
	title = {A Quantum Fingerprinting Algorithm for Next Generation Cellular Positioning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {93--102},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322763},
	doi = {10.1109/JSAC.2023.3322763},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZookSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent release of the third-generation partnership project, Release 17, calls for sub-meter cellular positioning accuracy with reduced latency in the calculation. To provide such high accuracy on a worldwide scale, leveraging the received signal strength (RSS) for positioning promises ubiquitous availability in the current and future equipment. RSS Fingerprint-based techniques have shown great potential for providing high accuracy in both indoor and outdoor environments. However, fingerprint-based positioning faces the challenge of providing a fast matching algorithm that can scale worldwide. In this paper, we propose a cosine similarity-based quantum algorithm for enabling fingerprint-based high accuracy and worldwide positioning that can be integrated with the next generation of 5G and 6G networks and beyond. By entangling the test RSS vector with the fingerprint RSS vectors, the proposed quantum algorithm has a complexity that is exponentially better than its classical version as well as the state-of-the-art quantum fingerprint positioning systems, both in the storage space and the running time. We implement the proposed quantum algorithm and evaluate it in a cellular testbed on a real IBM quantum machine. Results show the exponential saving in both time and space for the proposed quantum algorithm while keeping the same positioning accuracy compared to the traditional classical fingerprinting techniques and the state-of-the-art quantum algorithms.}
}


@article{DBLP:journals/jsac/MaMALWZ24,
	author = {Yiyan Ma and
                  Guo{-}Yu Ma and
                  Bo Ai and
                  Jingrong Liu and
                  Ning Wang and
                  Zhangdui Zhong},
	title = {OTFCS-Modulated Waveform Design for Joint Grant-Free Random Access
                  and Positioning in {C-V2X}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {103--119},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322796},
	doi = {10.1109/JSAC.2023.3322796},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MaMALWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cellular-vehicle-to-everything (C-V2X) communication network is constantly evolving and changing the way people travel. To realize connected automated vehicles, both precise positioning and reliable communications of vehicles and associated terminals are demanding. Since the orthogonal frequency division multiplexing (OFDM) scheme is vulnerable to Doppler spread under high-mobility, the orthogonal time frequency space (OTFS) modulation is proposed recently to tackle this challenge based on the sparsity and stability of the channel spreading function. To this end, this article proposes a waveform design for V2X based on OTFS modulation, named orthogonal time frequency code space modulated waveform (OTFCSMW). The waveform design is able to realize random access and positioning simultaneously. In detail, the transceiver design of OTFCSMW is introduced, where orthogonal spreading sequences are utilized to provide spreading gain and represent terminal identifications based on the proposed orthogonal spreading combinations. Then a joint time-of-arrival (ToA) estimation and channel estimation strategy is proposed. The ToAs of terminals are estimated based on the sparsity of taps in the channel spreading function, and remaining unknown channel parameters are estimated based on the minimum-mean-square-error (MMSE) principle. Finally, the equalization scheme for OTFCSMW based on MMSE principle is proposed. Simulation results demonstrate that OTFCSMW can realize similar positioning performance to OFDM and outperforms the orthogonal-spreading-based-OFDM-waveform (S-OFDMW) scheme on bit error rate (BER) in different V2X channel environments.}
}


@article{DBLP:journals/jsac/DecarliGGGM24,
	author = {Nicol{\`{o}} Decarli and
                  Anna Guerra and
                  Caterina Giovannetti and
                  Francesco Guidi and
                  Barbara M. Masini},
	title = {{V2X} Sidelink Localization of Connected Automated Vehicles},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {120--133},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322853},
	doi = {10.1109/JSAC.2023.3322853},
	timestamp = {Mon, 03 Mar 2025 22:17:40 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/DecarliGGGM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future automated driving relies on two pillars, (i) ultra-low-latency and reliable communications, and (ii) accurate positioning information. In particular, the knowledge of vehicle positions is becoming fundamental with the increase of the automation level, allowing autonomous navigation of the environment. Today’s positioning techniques cannot provide the accuracy, robustness, and latency required for stringent applications, like platooning, where vehicles are expected to travel at extremely short distances. In this paper, we leverage vehicle-to-everything (V2X) sidelink communication for localization purposes, capitalizing on the near-field propagation attributes of signals generated utilizing high carrier frequencies and/or large antenna arrays. Consequently, a receiving vehicle can accurately determine the transmitting vehicle’s location through V2X sidelink packet reception, obviating the need for supplementary reference nodes or stringent synchronization. Fundamental limits on localization accuracy are derived to characterize the positioning performance in vehicular contexts. A case study based on 5G new radio (NR) V2X sidelink shows how this technique is extremely promising and capable of providing high accuracy, low latency, high update rate, and high availability of position information in realistic vehicular scenarios.}
}


@article{DBLP:journals/jsac/LizarribarGBL24,
	author = {Yago Lizarribar and
                  Domenico Giustiniano and
                  G{\'{e}}r{\^{o}}me Bovet and
                  Vincent Lenders},
	title = {SkyPos: Real-World Evaluation of Self-Positioning With Aircraft Signals
                  for IoT Devices},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {134--145},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322829},
	doi = {10.1109/JSAC.2023.3322829},
	timestamp = {Fri, 26 Jan 2024 07:57:14 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LizarribarGBL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Positioning based on aircraft signals has been proposed as an alternative to satellite-based positioning systems (e.g. GPS). However, so far, no deployment of this technique exists, and the real-world performance remains unclear. This paper contributes at better understanding the performance tradeoffs under realistic conditions. We implement SkyPos, a localization system for GPS-denied areas or location integrity that opportunistically uses the large availability of aircraft signals to self-localize receivers. We analyze SkyPos with data collected from hundreds of sensors and thousands of aircraft around Europe. Our results show that we can achieve median accuracy down to 10m in seconds, enabling almost real-time positioning or location verification using aircraft signals at scale.}
}


@article{DBLP:journals/jsac/NeinavaieK24,
	author = {Mohammad Neinavaie and
                  Zaher M. Kassas},
	title = {Cognitive Sensing and Navigation With Unknown {OFDM} Signals With
                  Application to Terrestrial 5G and Starlink {LEO} Satellites},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {146--160},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322811},
	doi = {10.1109/JSAC.2023.3322811},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/NeinavaieK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A receiver architecture for cognitive sensing and navigation with orthogonal frequency division multiplexing (OFDM)-based systems is proposed. The proposed receiver enables exploiting all the transmitted periodic beacons of 5G new radio (NR) and Starlink low Earth orbit (LEO) signals to draw navigation observables. Reference signals (RSs) of modern OFDM-based systems, such as 5G NR, contain both always-on and on-demand components. These components can be unknown or known but subject to change. To leverage all transmitted signals for navigation purposes, the RS signals should be detected and tracked cognitively. Similar to conventional navigation receivers, the proposed architecture involves acquisition and tracking stages. However, both stages are supplemented by the unorthodox capability of estimating and updating the RS signals. The acquisition stage instructs the tracking stage by reporting performance metrics, which are used to adjust the tracking loop gains to update the RS accordingly. A chirp model is considered to capture the high dynamics of Doppler frequency in intensive Doppler scenarios, where the navigating vehicle is maneuvering or the transmitting source is not static. The effect of Doppler rate estimation error on frame length estimation is analyzed. Experimental results are presented demonstrating the performance of the proposed receiver by: (i) enabling an unmanned aerial vehicle (UAV) to detect and exploit terrestrial 5G NR cellular signals in a blind fashion for navigation purposes, achieving a two-dimensional (2D) root-mean squared error (RMSE) of 4.2 m over a total trajectory of 416 m; (ii) enabling a ground vehicle that traversed a trajectory of 1.79 km to cognitively sense an unknown gNB (blindly detect, track, and exploit transmitted always-on and on-demand signals), localizing it with a 2D error of 5.83 m; and (iii) tracking Starlink LEO OFDM signals, producing Doppler measurements, which were fused to localize a stationary receiver with a 2D error of 6.5 m, starting from an initial estimate 179 km away from the receiver’s true position.}
}


@article{DBLP:journals/jsac/WangDNZKXJ24,
	author = {Jiacheng Wang and
                  Hongyang Du and
                  Dusit Niyato and
                  Mu Zhou and
                  Jiawen Kang and
                  Zehui Xiong and
                  Abbas Jamalipour},
	title = {Through the Wall Detection and Localization of Autonomous Mobile Device
                  in Indoor Scenario},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {161--176},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322819},
	doi = {10.1109/JSAC.2023.3322819},
	timestamp = {Fri, 28 Jun 2024 14:57:07 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangDNZKXJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the intelligent logistics and warehouses, the autonomous mobile device (AMD) holds a key position as it is equipped with the ability to carry out functions like material transportation and inventory inspection. Nevertheless, the effective execution of these functions necessitates the location of the AMD. Given the increasing proliferation of networks like WiFi and 5G, leveraging these signals to achieve AMD localization is a desirable solution. Therefore, this paper proposes a channel state information (CSI) based system for through-the-wall (TTW) passive AMD detection and localization, named T-DeLo. T-DeLo first establishes a reference channel and utilizes it to cancel the strong signal interference (SSI) and phase errors, ensuring that the reflections introduced by the AMD can be estimated. Built upon this core, it uses the proposed novel two-dimensional matrix pencil algorithm to estimate jointly the path length change rate (PLCR) and time of flight (ToF) of the AMD induced reflections, in the TTW scenario. Unlike existing algorithms, this algorithm aggregates multiple measurements to improve the estimation performance under conditions of low signal-to-noise ratio (SNR). Finally, leveraging the estimated ToF and PLCR, T-DeLo realizes TTW AMD detection and localization via statistical and geometric analysis, respectively. In the TTW glass and brick wall scenarios, the extensive experimental evaluation shows that the AMD detection accuracy of T-DeLo is 0.964 and 0.952, while the median localization errors are 1.65 m and 2.05 m, respectively, laying a solid foundation for practical and ubiquitous AMD passive detection and localization.}
}


@article{DBLP:journals/jsac/ShiLTFBC24,
	author = {Fangzhan Shi and
                  Wenda Li and
                  Chong Tang and
                  Yuan Fang and
                  Paul V. Brennan and
                  Kevin Chetty},
	title = {Decimeter-Level Indoor Localization Using WiFi Round-Trip Phase and
                  Factor Graph Optimization},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {177--191},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322812},
	doi = {10.1109/JSAC.2023.3322812},
	timestamp = {Thu, 06 Feb 2025 09:20:35 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ShiLTFBC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indoor localization using WiFi signals has been studied since the emergence of WiFi communication. This paper presents a novel training-free approach to indoor localization using a customized WiFi protocol for data collection and a factor graph-based back-end for localization. The protocol measures the round-trip phase, which is very sensitive to small changes in displacement. This is because the sub-wavelength displacements introduce significant phase changes in WiFi signal. However, the phase cannot provide absolute range information due to angle wrap. Consequently, it can only be used for relative distance (displacement) measurement. By tracking the round-trip phase over time and unwrapping it, a relative distance measurement can be realized and achieve a mean absolute error (MAE) of 0.06m. For 2-D localization, factor graph optimization is applied to the round-trip phase measurements between the STA (station) and four APs (access points). Experiments show the proposed concept can offer a decimeter-level (0.26m MAE and 0.24m 50%CDF) performance for real-world indoor localization.}
}


@article{DBLP:journals/jsac/ChenG24,
	author = {Zhiwei Chen and
                  Xiaohu Ge},
	title = {An Information Geometry Inference Approach of Fine-Grained Spatial
                  Distribution for Connected and Automated Vehicles},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {192--206},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322798},
	doi = {10.1109/JSAC.2023.3322798},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapidly increasing number of connected and automated vehicles (CAVs) in intelligent transportation systems, identifying and predicting the fine-grained spatial distribution (SD) of CAV clusters is important to improve the positioning accuracy of CAVs. Although some practical schemes based on computer vision technologies and wireless sensor networks are developed to count the number of CAVs in the global navigation satellite system denied areas, the inference of fine-grained SDs of CAVs from coarse SD observations has not been studied. Based on the collective graphical model, a novel information geometry inference approach is proposed to apply the individual-CAV mobility model for refining the SD observations of CAVs. Within the proposed approach, the identification and prediction of fine-grained SDs of CAVs are formulated as a non-convex constrained Kullback-Leibler divergence minimization problem. From the information geometry perspective, the non-convex problem is reformulated as the I-projection searching problem on a dually flat manifold and then is solved based on the general Pythagorean theorem. Furthermore, an iterative algorithm with closed-form iteration expression is designed to converge to the optimal solution for the I-projection searching problem. Simulation results demonstrate that the designed algorithm outperforms the IMM-MC and UR schemes for identifying the SD of CAVs. Compared with the IMM-MC scheme, the designed algorithm improves the accuracy of predicting the SD of CAVs by up to 71.6%.}
}


@article{DBLP:journals/jsac/LuoSCZZYL24,
	author = {Guiyang Luo and
                  Chongzhang Shao and
                  Nan Cheng and
                  Haibo Zhou and
                  Hui Zhang and
                  Quan Yuan and
                  Jinglin Li},
	title = {EdgeCooper: Network-Aware Cooperative LiDAR Perception for Enhanced
                  Vehicular Awareness},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {207--222},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322764},
	doi = {10.1109/JSAC.2023.3322764},
	timestamp = {Fri, 08 Mar 2024 13:21:35 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LuoSCZZYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous driving vehicle (ADV) that is ready to transform our society and economy, is in desperate need of precise positioning over itself as well as surrounding environments. However, it is still a challenging issue for ADV to retrieve real-time positioning knowledge over road participants and dynamic surrounding environments, due to unsatisfied perception accuracy caused by sparse observations and limited perception range. Cooperative perception, which advocates cooperatively disseminating perception data among vehicles, has the potential to overcome the above limitations. To this end, this article proposes a novel edge-assisted multi-vehicle perception system to enhance vehicles’ awareness over surrounding environments, which is termed as EdgeCooper. EdgeCooper first schedules vehicles to share complementarity-enhanced and redundancy-minimized raw sensor data with an edge server, using multi-hop cooperative 5G V2X communications. Then, EdgeCooper merges vehicles’ individual views to form a holistic view with a higher resolution, thus enhancing perception robustness and enlarging perception range. We formulate multi-vehicle multi-hop cooperative data sharing as a minimum cost flow problem with conflict, and further prove that there exists no polynomial-time approximation algorithm with a constant performance ratio unless P = NP. Furthermore, a two-dimension graph coloring algorithm with guaranteed performance is proposed to eliminate conflict. We evaluate EdgeCooper by building a comprehensive simulation platform through a joint manipulation of SUMO, CARLA, NS3, and PyTorch. The experiment results show that, compared to a single vehicle’s perception, EdgeCooper performs effective and efficient in enhancing vehicular awareness, e.g., extending up to 3.6 times detection range and improving perception accuracy by 20%.}
}


@article{DBLP:journals/jsac/YinSNXSG24,
	author = {Lu Yin and
                  Tianzhu Song and
                  Qiang Ni and
                  Quanbin Xiao and
                  Yuan Sun and
                  Wenfang Guo},
	title = {New Signal and Algorithms for 5G/6G High Precision Train Positioning
                  in Tunnel With Leaky Coaxial Cable},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {1},
	pages = {223--238},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3322790},
	doi = {10.1109/JSAC.2023.3322790},
	timestamp = {Sat, 13 Jan 2024 17:37:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/YinSNXSG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High precision train positioning is a crucial component of intelligent transportation systems. Tunnels are commonly encountered in subways and mountainous regions. As part of the communication system infrastructure, Leaky CoaXial (LCX) Cable is widely equipped as antenna in tunnels with many advantages. LCX positioning holds great promise as a technology for rail applications in the upcoming B5G (beyond-5G) and 6G eras. This paper focuses on the LCX positioning methodology and proposes two novel algorithms along with a novel communication-positioning integration signal. Firstly, a novel algorithm called Multiple Slot Distinction (MSD) LCX positioning algorithm is proposed. The algorithm utilizes a generated pseudo spectrum to fully utilize the coupled signals radiated from different slots of LCX. This approach offers higher time resolution compared to traditional methods. To further improve the positioning accuracy to centimeter-level and increase the measuring frequency for fast trains, a novel communication-positioning integration signal is designed. It consists of traditional Positioning Reference Signal (PRS) and a significantly low power Fine Ranging Signal (FRS). FRS is configured to be continuous and superposed onto the cellular signal using Non-Orthogonal Multiple Access (NOMA) principle to minimize its interference to communication. A two-stage LCX positioning method is then executed: At the first stage, the closest slot between the receiver and LCX is estimated by the proposed MSD algorithm using PRS; At the second stage, centimeter-level positioning is achieved by tracking the carrier phase of the continuous FRS. This process is assisted by the closest slot estimation, which helps mitigate interference between neighboring slots and eliminate the integer ambiguities. Simulation results show our proposed LCX position methodology outperforms the existing ones and offer great potentials for future implementations.}
}


@article{DBLP:journals/jsac/PoleseDDEJKM24,
	author = {Michele Polese and
                  Mischa Dohler and
                  Falko Dressler and
                  Melike Erol{-}Kantarci and
                  Rittwik Jana and
                  Raymond Knopp and
                  Tommaso Melodia},
	title = {Guest Editorial Open {RAN:} {A} New Paradigm for Open, Virtualized,
                  Programmable, and Intelligent Cellular Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {241--244},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3334605},
	doi = {10.1109/JSAC.2023.3334605},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/PoleseDDEJKM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Open Radio Access Network (Open RAN) vision is based on the three principles of (i) open interfaces; (ii) cloudification; and (iii) automation through closed-loop control. It is a network architecture paradigm embodied and augmented through technical reference specifications of the 3GPP and the O-RAN Alliance. At the centre of Open RAN are open, programmable, and virtualized components, connected to each other through open interfaces that enable closed-loop, data-driven, and intelligent control. For instance, the O-RAN Alliance introduced two RAN Intelligent Controllers (or RICs) that connect through open interfaces to the disaggregated components of the RAN, and implement control loops that run at different time scales.}
}


@article{DBLP:journals/jsac/PoleseDDEJKM24a,
	author = {Michele Polese and
                  Mischa Dohler and
                  Falko Dressler and
                  Melike Erol{-}Kantarci and
                  Rittwik Jana and
                  Raymond Knopp and
                  Tommaso Melodia},
	title = {Empowering the 6G Cellular Architecture With Open {RAN}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {245--262},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3334610},
	doi = {10.1109/JSAC.2023.3334610},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/PoleseDDEJKM24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Innovation and standardization in 5G have brought advancements to every facet of the cellular architecture. This ranges from the introduction of new frequency bands and signaling technologies for the radio access network (RAN), to a core network underpinned by micro-services and network function virtualization (NFV). However, like any emerging technology, the pace of real-world deployments does not instantly match the pace of innovation. To address this discrepancy, one of the key aspects under continuous development is the RAN with the aim of making it more open, adaptive, functional, and easy to manage. In this paper, we highlight the transformative potential of embracing novel cellular architectures by transitioning from conventional systems to the progressive principles of Open RAN. This promises to make 6G networks more agile, cost-effective, energy-efficient, and resilient. It opens up a plethora of novel use cases, ranging from ubiquitous support for autonomous devices to cost-effective expansions in regions previously underserved. The principles of Open RAN encompass: (i) a disaggregated architecture with modular and standardized interfaces; (ii) cloudification, programmability and orchestration; and (iii) AI-enabled data-centric closed-loop control and automation. We first discuss the transformative role Open RAN principles have played in the 5G era. Then, we adopt a system-level approach and describe how these Open RAN principles will support 6G RAN and architecture innovation. We qualitatively discuss potential performance gains that Open RAN principles yield for specific 6G use cases. For each principle, we outline the steps that research, development and standardization communities ought to take to make Open RAN principles central to next-generation cellular network designs.}
}


@article{DBLP:journals/jsac/ApostolakisGCSBS24,
	author = {Nikolaos Apostolakis and
                  Marco Gramaglia and
                  Livia Elena Chatzieleftheriou and
                  Tejas Subramanya and
                  Albert Banchs and
                  Henning Sanneck},
	title = {{ATHENA:} Machine Learning and Reasoning for Radio Resources Scheduling
                  in vRAN Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {263--279},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336155},
	doi = {10.1109/JSAC.2023.3336155},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ApostolakisGCSBS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Next-generation mobile networks will rely on their autonomous operation. Virtual Network Functions empowered by Artificial Intelligence (AI) and Machine Learning (ML) can adapt to varying environments that encompass both network conditions and the cloud platform executing them. In this view, it becomes paramount to understand why AI/ML algorithms made a decision, to be able to reason upon those decisions and, eventually, take further decisions related to e.g., network orchestration. In this paper, we present ATHENA, an ML-based radio resource scheduler for virtualized Radio Access Network (RAN) system. Our real-software implementation shows that the proposed ML-based approach can outperform the baseline solution. We discuss how additional re-orchestration actions can be taken by analyzing our scheduling decisions and learning from the past.}
}


@article{DBLP:journals/jsac/ZangooeiGRSB24,
	author = {Mohammad Zangooei and
                  Morteza Golkarifard and
                  Mohamed Rouili and
                  Niloy Saha and
                  Raouf Boutaba},
	title = {Flexible {RAN} Slicing in Open {RAN} With Constrained Multi-Agent
                  Reinforcement Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {280--294},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336156},
	doi = {10.1109/JSAC.2023.3336156},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZangooeiGRSB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network slicing enables the provision of customized services in next-generation mobile networks. Accordingly, the network is divided into logically isolated networks that share underlying resources but are tailored to meet the distinct service requirements of their users. However, allocating the minimum necessary resources to satisfy slices’ requirements is challenging, particularly when the number of slices is variable or too large which is envisioned in Open RAN. State-of-the-art proposals leverage reinforcement learning (RL) algorithms; however, they suffer from over-provisioning and/or frequent violations of service-level agreement (SLA) due to the large and changing state and action spaces. This paper introduces a novel cooperative multi-agent RL algorithm for RAN slicing in Open RAN, designed to adapt to variable slice numbers and effectively scale as they grow. To train this model, we exploit a novel constrained RL algorithm that explicitly considers SLA constraints to maintain a decreasing SLA violation ratio during training. Our approach is compatible with the Open RAN architecture, allowing for feasible deployment in future mobile networks. CMARS surpasses RL methods in SLA satisfaction by 50% in large-scale slicing, using only 9% more resources. It has 8% fewer SLA violations and 19% lower resource consumption for a flexible number of slices.}
}


@article{DBLP:journals/jsac/ZhangZHZCJ24,
	author = {Xiaoxi Zhang and
                  Jinhang Zuo and
                  Zhe Huang and
                  Zhi Zhou and
                  Xu Chen and
                  Carlee Joe{-}Wong},
	title = {Learning With Side Information: Elastic Multi-Resource Control for
                  the Open {RAN}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {295--309},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3339174},
	doi = {10.1109/JSAC.2023.3339174},
	timestamp = {Fri, 24 Jan 2025 08:36:54 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZHZCJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The open radio access network (O-RAN) architecture provides enhanced opportunities for integrating machine learning in 5G/6G resource management by decomposing RAN functionalities. Yet, generic learning mechanisms either do not fully exploit the disaggregated non-real-time and near-real-time RAN controllers or ignore the potential elasticity of application demands, another degree of freedom in managing RAN resources. We introduce a two-timescale framework aimed at optimizing users’ long-term total QoS. Rather than reactive resource allocation, our approach proactively modifies multi-resource user demands using congestion indicators, prior to enforcing any allocation rules. Addressing the issue of insufficient user feedback on individual resource utilities, we employ a bandit-feedback version of the combinatorial multi-armed bandit framework to deduce resource-specific signals. Also, to compensate for insufficient and infrequent feedback, we’ve developed an algorithm that gleans side information from live network traffic to refine predictions on user resource sensitivities. This streamlines the algorithm’s optimality convergence and leverages the two-tier O-RAN controller structure. We validate our algorithms’ efficacy through analysis and 5G usage experiments, revealing our proposed method improves application utility by 13-60%, throughput by 8-19%, and reduces latency by 10-18%.}
}


@article{DBLP:journals/jsac/NagibAH24,
	author = {Ahmad M. Nagib and
                  Hatem Abou{-}Zeid and
                  Hossam S. Hassanein},
	title = {Safe and Accelerated Deep Reinforcement Learning-Based {O-RAN} Slicing:
                  {A} Hybrid Transfer Learning Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {310--325},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336191},
	doi = {10.1109/JSAC.2023.3336191},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/NagibAH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The open radio access network (O-RAN) architecture supports intelligent network control algorithms as one of its core capabilities. Data-driven applications incorporate such algorithms to optimize radio access network (RAN) functions via RAN intelligent controllers (RICs). Deep reinforcement learning (DRL) algorithms are among the main approaches adopted in the O-RAN literature to solve dynamic radio resource management problems. However, despite the benefits introduced by the O-RAN RICs, the practical adoption of DRL algorithms in real network deployments falls behind. This is primarily due to the slow convergence and unstable performance exhibited by DRL agents upon deployment and when encountering previously unseen network conditions. In this paper, we address these challenges by proposing transfer learning (TL) as a core component of the training and deployment workflows for the DRL-based closed-loop control of O-RAN functionalities. To this end, we propose and design a hybrid TL-aided approach that leverages the advantages of both policy reuse and distillation TL methods to provide safe and accelerated convergence in DRL-based O-RAN slicing. We conduct a thorough experiment that accommodates multiple services, including real VR gaming traffic to reflect practical scenarios of O-RAN slicing. We also propose and implement policy reuse and distillation-aided DRL and non-TL-aided DRL as three separate baselines. The proposed hybrid approach shows at least: 7.7% and 20.7% improvements in the average initial reward value and the percentage of converged scenarios, and a 64.6% decrease in reward variance while maintaining fast convergence and enhancing the generalizability compared with the baselines.}
}


@article{DBLP:journals/jsac/MunsUDSSSC24,
	author = {Guillem Reus Muns and
                  Pratheek S. Upadhyaya and
                  Utku Demir and
                  Nathan Stephenson and
                  Nasim Soltani and
                  Vijay K. Shah and
                  Kaushik R. Chowdhury},
	title = {SenseORAN: O-RAN-Based Radar Detection in the {CBRS} Band},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {326--338},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336152},
	doi = {10.1109/JSAC.2023.3336152},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MunsUDSSSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open RAN (O-RAN) has the potential for revolutionizing not only cellular communication but also spectrum sensing by carefully controlling uplink/downlink traffic in shared spectrum bands. In this paper, we present the design of SenseORAN, which detects the presence of radar pulses within the Citizens Broadband Radio Service (CBRS) band. SenseORAN is especially useful for scenarios where these pulses (highest priority) are fully overlapping with interfering LTE signals (secondary priority licensee), requiring immediate detection of such an occurrence. This design paradigm of re-using existing cellular infrastructure with ORAN-compliant sensing and communication slices can potentially eliminate the need for dedicated spectrum sensors along the coastline as well as severe restrictions on the transmit power for the LTE operators that are enforced today. Our approach involves a machine learning module deployed as a Radar Detection xApp at the near-Real-Time (near-RT) Radio Access Network (RAN) Intelligent Controller, i.e., near-RT RIC. The base station or gNB: 1) uses the you-only-look-once (YOLO)-based machine learning framework that is modified to detect radar signals present within spectrograms generated from I/Q samples collected during the regular uplink cellular operation; and 2) maintains a list of ‘occupied’ channels in the 3.5-GHz CBRS band that indicate radar presence. Our design is validated with: 1) an over the air collected dataset composed of Type 1 radar and standard-compliant LTE waveforms; and 2) an experimental testbed of SDRs running a complete Open RAN stack with a near-RT RIC implementation integrated with our YOLO-based xApp. We show radar detection accuracy of 100% under SINR conditions 12-dB after combining 7 spectrograms into a single decision. Furthermore, using testbed results, we demonstrate that the gNB can be reconfigured to avoid radar interference within 866-ms, which represents a reduction of 85.5% over the 60-s response time mandated for pausing cellular operation in detecting radar presence in the CBRS band today.}
}


@article{DBLP:journals/jsac/ChenHLRK24,
	author = {Yongce Chen and
                  Y. Thomas Hou and
                  Wenjing Lou and
                  Jeffrey H. Reed and
                  Sastry Kompella},
	title = {O-M\({}^{\mbox{3}}\): Real-Time Multi-Cell {MIMO} Scheduling in 5G
                  {O-RAN}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {339--355},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336164},
	doi = {10.1109/JSAC.2023.3336164},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenHLRK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open radio access network (O-RAN) enables cooperative signal processing among multiple cells at a centralized O-RAN distributed unit (O-DU). It is a key technology for cellular networks to increase spectrum efficiency. To achieve cooperative signal processing across multiple cells, a new scheduler is needed. Specifically, the scheduler must jointly determine RB allocation, MCS assignment, and beamforming matrices for all users from all the cells that are involved in multi-cell processing. In addition, the scheduler must obtain its scheduling solution within each TTI (i.e., at most 1 ms) to be useful for the frame structure defined by 5G NR. In this paper, we present O- \\mathbf M^{3} —a real-time scheduler for multi-cell MIMO networks under the O-RAN architecture. O- \\mathbf M^{3} can meet the stringent timing requirement with joint optimization of beamforming matrices, RB allocation, and MCS assignment among multiple cells. O- \\mathbf M^{3} is developed through a novel multi-pipeline design that exploits parallelism. Under this design, one pipeline performs a sequence of operations for cell-edge users to explore joint transmission, and in parallel, the other pipeline is performed for cell-center users to explore MU-MIMO transmission. We implement O- \\mathbf M^{3} on a commercial off-the-shelf (COTS) GPU. Experimental results show that O- \\mathbf M^{3} is capable of offering a scheduling solution within 500 \\mu \\text{s} for an O-RAN system with 7 O-RAN radio units (O-RUs), 100 users, 100 RBs, and 2\\times 8 MIMO. O- \\mathbf M^{3} can also meet the 1 ms requirement for 2\\times 12 MIMO systems. Meanwhile, O- \\mathbf M^{3} can provide ~40% throughput gain on average through joint transmission across multiple cells.}
}


@article{DBLP:journals/jsac/DemirMBC24,
	author = {{\"{O}}zlem Tugfe Demir and
                  Meysam Masoudi and
                  Emil Bj{\"{o}}rnson and
                  Cicek Cavdar},
	title = {Cell-Free Massive {MIMO} in {O-RAN:} Energy-Aware Joint Orchestration
                  of Cloud, Fronthaul, and Radio Resources},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {356--372},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336187},
	doi = {10.1109/JSAC.2023.3336187},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/DemirMBC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For the energy-efficient deployment of cell-free massive MIMO functionality in a practical wireless network, the end-to-end (from radio site to the cloud) energy-aware operation is essential. In line with the cloudification and virtualization in the open radio access networks (O-RAN), it is indisputable to envision prospective cell-free infrastructure on top of the O-RAN architecture. In this paper, we explore the performance and power consumption of cell-free massive MIMO technology in comparison with traditional small-cell systems, in the virtualized O-RAN architecture. We compare two different functional split options and different resource orchestration mechanisms. In the end-to-end orchestration scheme, we aim to minimize the end-to-end power consumption by jointly allocating the radio, optical fronthaul, and virtualized cloud processing resources. We compare end-to-end orchestration with two other schemes: 1) “radio-only” where radio resources are optimized independently from the cloud; and 2) “local cloud coordination” where orchestration is only allowed among a local cluster of radio units. We develop several algorithms to solve the end-to-end power minimization and sum spectral efficiency maximization problems. The numerical results demonstrate that end-to-end resource allocation with fully virtualized fronthaul and cloud resources provides a substantial additional power saving than the other resource orchestration schemes.}
}


@article{DBLP:journals/jsac/OhDHKLB24,
	author = {Myeung Suk Oh and
                  Anindya Bijoy Das and
                  Seyyedali Hosseinalipour and
                  Taejoon Kim and
                  David J. Love and
                  Christopher G. Brinton},
	title = {A Decentralized Pilot Assignment Algorithm for Scalable {O-RAN} Cell-Free
                  Massive {MIMO}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {373--388},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336154},
	doi = {10.1109/JSAC.2023.3336154},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/OhDHKLB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio access networks (RANs) in monolithic architectures have limited adaptability to supporting different network scenarios. Recently, open-RAN (O-RAN) techniques have begun adding enormous flexibility to RAN implementations. O-RAN is a natural architectural fit for cell-free massive multiple-input multiple-output (CFmMIMO) systems, where many geographically-distributed access points (APs) are employed to achieve ubiquitous coverage and enhanced user performance. In this paper, we address the decentralized pilot assignment (PA) problem for scalable O-RAN-based CFmMIMO systems. We propose a low-complexity PA scheme using a multi-agent deep reinforcement learning (MA-DRL) framework in which multiple learning agents perform distributed learning over the O-RAN communication architecture to suppress pilot contamination. Our approach does not require prior channel knowledge but instead relies on real-time interactions made with the environment during the learning procedure. In addition, we design a codebook search (CS) scheme that exploits the decentralization of our O-RAN CFmMIMO architecture, where different codebook sets can be utilized to further improve PA performance without any significant additional complexities. Numerical evaluations verify that our proposed scheme provides substantial computational scalability advantages and improvements in channel estimation performance compared to the state-of-the-art.}
}


@article{DBLP:journals/jsac/NguyenVNNJLHNC24,
	author = {Van{-}Dinh Nguyen and
                  Thang X. Vu and
                  Nhan Thanh Nguyen and
                  Dinh C. Nguyen and
                  Markku J. Juntti and
                  Nguyen Cong Luong and
                  Dinh Thai Hoang and
                  Diep N. Nguyen and
                  Symeon Chatzinotas},
	title = {Network-Aided Intelligent Traffic Steering in 6G {O-RAN:} {A} Multi-Layer
                  Optimization Framework},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {389--405},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336183},
	doi = {10.1109/JSAC.2023.3336183},
	timestamp = {Thu, 17 Oct 2024 17:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/NguyenVNNJLHNC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To enable an intelligent, programmable and multi-vendor radio access network (RAN) for 6G networks, considerable efforts have been made in standardization and development of open RAN (O-RAN). So far, however, the applicability of O-RAN in controlling and optimizing RAN functions has not been widely investigated. In this paper, we jointly optimize the flow-split distribution, congestion control and scheduling (JFCS) to enable an intelligent traffic steering application in O-RAN. Combining tools from network utility maximization and stochastic optimization, we introduce a multi-layer optimization framework that provides fast convergence, long-term utility-optimality and significant delay reduction compared to the state-of-the-art and baseline RAN approaches. Our main contributions are three-fold: i ) we propose the novel JFCS framework to efficiently and adaptively direct traffic to appropriate radio units; ii ) we develop low-complexity algorithms based on the reinforcement learning, inner approximation and bisection search methods to effectively solve the JFCS problem in different time scales; and iii ) the rigorous theoretical performance results are analyzed to show that there exists a scaling factor to improve the tradeoff between delay and utility-optimization. Collectively, the insights in this work will open the door towards fully automated networks with enhanced control and flexibility. Numerical results are provided to demonstrate the effectiveness of the proposed algorithms in terms of the convergence rate, long-term utility-optimality and delay reduction.}
}


@article{DBLP:journals/jsac/IrazabalN24,
	author = {Mikel Irazabal and
                  Navid Nikaein},
	title = {{TC-RAN:} {A} Programmable Traffic Control Service Model for 5G/6G
                  {SD-RAN}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {406--419},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336162},
	doi = {10.1109/JSAC.2023.3336162},
	timestamp = {Fri, 08 Mar 2024 13:21:35 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/IrazabalN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Driven by the key principles of open interfaces, virtualization and programmability, Open RAN has emerged as a new paradigm to evolve contemporary Radio Access Networks (RANs) into a more vendor-agnostic, softwarized, and intelligent ecosystem. To this end, Software Defined RAN (SD-RAN) initiatives (e.g., O-RAN) are drafting specifications to provide the means to embrace it. However, even though O-RAN following the Open RAN paradigm specifies Service Models (SMs) to monitor and control the RAN, it does not go beyond the Quality of Service (QoS) mechanisms provided by 3GPP. Therefore, the QoS degradation that occurs mostly due to data flow’s nature at the slowest data path link (e.g., high L2 sublayers), is not addressed by contemporary O-RAN SMs. In this paper, we present a traffic control system for SD-RAN, denoted as TC-RAN, that consists of an E2 service Model (E2SM) and a RAN Function (RF) that adheres to the Open RAN principles and promotes data flows to first-class citizens in cellular networks, upgrading contemporary 5G QoS mechanism. TC-RAN introduces a 6 programmable, extendable, and customizable pipeline composed of a classifier, a policer, a queue, a scheduler, a shaper and a pacer. Additionally, TC-RAN addresses QoS degradation scenarios unsolvable through Resource Block (RB) allocation or 3GPP slicing mechanisms, unleashing the true potential for deploying extremely demanding applications and creating a green field for AI/ML cross-optimization algorithms on the road to 6G. We prototype and validate TC-RAN in a real 5G Stand Alone (SA) RAN stack using an O-RAN compatible near Real-Time Radio Intelligent Controller (nearRT-RIC), xApps, and Commercial off-the-shelf (COTS) User Equipments (UEs). The results show that intelligently composing a TC-RAN pipeline in cellular networks can considerably reduce the latency, notably enhancing the Quality of Experience (QoE) in a real multiplayer online game.}
}


@article{DBLP:journals/jsac/KlementLK24,
	author = {Felix Klement and
                  Wuhao Liu and
                  Stefan Katzenbeisser},
	title = {Toward Securing the 6G Transition: {A} Comprehensive Empirical Method
                  to Analyze Threats in {O-RAN} Environments},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {420--431},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3339172},
	doi = {10.1109/JSAC.2023.3339172},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/KlementLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present a new methodology that enables the MITRE ATT&CK framework to objectively assess specific threats in 6G Radio Access Networks (RANs). This helps address new security challenges that arise in the transition to open RANs. We analyze the O-Cloud component within the O-RAN ecosystem as a representative example, wherein no individual threat class demonstrates complete security. The inherent modularity of our approach ensures great adaptability and allows it to be applied to various other components within this system. This allows us to effectively detect and combat threats, thereby ensuring the resilience and security of future communication networks.}
}


@article{DBLP:journals/jsac/LozanoGLC24,
	author = {J. Xavier Salvat Lozano and
                  Andres Garcia{-}Saavedra and
                  Xi Li and
                  Xavier Costa{-}P{\'{e}}rez},
	title = {{AIRIC:} Orchestration of Virtualized Radio Access Networks With Noisy
                  Neighbours},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {432--445},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3339749},
	doi = {10.1109/JSAC.2023.3339749},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LozanoGLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio Access Networks virtualization (vRAN) is on its way becoming a reality driven by the new requirements in mobile networks, such as scalability and cost reduction. Unfortunately, there is no free lunch but a high price to be paid in terms of computing overhead introduced by noisy neighbors problem when multiple virtualized base station instances share computing platforms. In this paper, first, we thoroughly dissect the multiple sources of computing overhead in a vRAN, quantifying their different contributions to the overall performance degradation. Second, we design an AI-driven Radio Intelligent Controller (AIRIC) to orchestrate vRAN computing resources. AIRIC relies upon a hybrid neural network architecture combining a relation network (RN) and a deep Q-Network (DQN) such that: ( i\n) the demand of concurrent virtual base stations is satisfied considering the overhead posed by the noisy neighbors problem while the operating costs of the vRAN infrastructure is minimized; and ( ii\n) dynamically changing contexts in terms of network demand, signal-to-noise ratio (SNR) and the number of base station instances are efficiently supported. Our results show that AIRIC performs very closely to an offline optimal oracle, attaining up to 30% resource savings, and substantially outperforms existing benchmarks in service guarantees.}
}


@article{DBLP:journals/jsac/AlmeidaBHHDBC24,
	author = {Gabriel Matheus de Almeida and
                  Gustavo Zanatta Bruno and
                  Alexandre Huff and
                  Matti A. Hiltunen and
                  Elias P. Duarte and
                  Cristiano Bonato Both and
                  Kleber Vieira Cardoso},
	title = {{RIC-O:} Efficient Placement of a Disaggregated and Distributed {RAN}
                  Intelligent Controller With Dynamic Clustering of Radio Nodes},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {446--459},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336159},
	doi = {10.1109/JSAC.2023.3336159},
	timestamp = {Sat, 10 Feb 2024 18:05:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/AlmeidaBHHDBC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Radio Access Network (RAN) is the segment of cellular networks that provides wireless connectivity to end-users. The O-RAN Alliance has been transforming the RAN industry by proposing open RAN specifications and the programmable Non-Real-Time and Near-Real-Time RAN Intelligent Controllers (Non-RT RIC and Near-RT RIC). Both RICs provide platforms for running applications called rApps and xApps, respectively, to optimize the RAN behavior. We investigate the disaggregation of the Near-RT RIC into components that meet stringent latency requirements while presenting a cost-effective solution. For example, the O-RAN Signalling Storm Protection requires the Near-RT RIC to support end-to-end control loop latencies as low as 10 ms. We propose the novel RIC Orchestrator (RIC-O) that optimizes the deployment of the Near-RT RIC components across the cloud-edge continuum. Edge computing nodes often present limited resources and are expensive compared to cloud computing. Performance-critical components of Near-RT RIC and certain xApps should run at the edge while other components can run on the cloud. Furthermore, RIC-O employs an efficient strategy to react to sudden changes and re-deploy components dynamically. The proposal is evaluated both analytically and through real-world experiments in an extended Kubernetes deployment implementing RIC-O and the disaggregated Near-RT RIC.}
}


@article{DBLP:journals/jsac/MohammadiN24,
	author = {Alireza Mohammadi and
                  Navid Nikaein},
	title = {Athena: An Intelligent Multi-x Cloud Native Network Operator},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {460--472},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336172},
	doi = {10.1109/JSAC.2023.3336172},
	timestamp = {Fri, 08 Mar 2024 13:21:35 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MohammadiN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents Athena, a novel design and a new generation of MANO/OAM that fully adheres to the cloud native principles, while fostering innovation and sustainable deployment for 4G, 5G, and beyond. It elicits an agile and intelligent, dynamic control over a variety of vendors and radio stacks (multi-x) coexisting on the same network with built-in observability and at the scale. With an intent-based, declarative, and distributed constitution, authentic to the cloud native pillars of isolation, scalability, and observability, we have established a scalable and efficient design and implemented its concrete proof-of-concept platform that is able to simplify the adaptation of cloud native for telecommunication. Athena automates both the semantics and synthetics of the lifecycle of telco workloads while attending to the performance and sustainability requirements. Accompanied by intensive evaluation on a concrete implementation, we show how several uses cases including private networking, Open RAN, and green computing would be facilitated and sustained with a low footprint and green management and operation. In particular, we improve the agility by 75% on Day-1 and 60% on Day-2 in comparison to OSM, while reducing over 93% overhead in Operation, 70% in Management, and 90% in Orchestration. Athena shows less than 2% performance loss for high throughput, with less than 50~\\mu \\text{s} jitter. It demonstrates 99.9995% availability for immutable Day-2 upgrades and zero down-time for mutable reconfigurations. And for energy efficiency, we show improvements of maximum 17.4% per UE and 78.3% per gNB using the proposed decision-making framework.}
}


@article{DBLP:journals/jsac/HoffmannJSKADKKB24,
	author = {Marcin Hoffmann and
                  Salim Janji and
                  Adam Samorzewski and
                  Lukasz Kulacz and
                  Cezary Adamczyk and
                  Marcin Dryjanski and
                  Pawel Kryszkiewicz and
                  Adrian Kliks and
                  Hanna Bogucka},
	title = {Open {RAN} xApps Design and Evaluation: Lessons Learnt and Identified
                  Challenges},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {473--486},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336190},
	doi = {10.1109/JSAC.2023.3336190},
	timestamp = {Fri, 08 Mar 2024 13:21:35 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HoffmannJSKADKKB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The concept of open radio access networks (RAN) creates numerous opportunities for developing new technology and economy branches. At the same time, a flexible and modular approach in the disaggregated RAN entails the need for careful design of the overall RAN architecture and the implementation and deployment process of new applications. It is assumed that dedicated and specialized software companies may deliver the latter. A joint effort must be guaranteed among different sectors (industry, academia, and standardization bodies) to make the whole process efficient, safe, and reliable. Here, one of the critical driving forces origins from the open-source community that often stimulates the development of a specific technology. In this paper, we address the challenges that have to be faced by third-party application developers in the context of Open RAN. Based on many implemented applications (called xApps or rApps), we compare various available solutions. We pose the most critical issues that must be tackled in the near future to stimulate the progress in open RAN development further. In particular, we compare available open platforms for xApp development and testing. We present the details of implementing four selected applications describing the problems encountered. The paper is split into two logical parts - first, we identify the key ambiguities related to the development of new xApps, which address more complicated use cases like beam management. In the second part, we present the challenges associated with detailed software implementation in existing open platforms. In the first case, we show that dedicated beam mobility management xApp can reduce beam switches and keep beam failures low. However, it requires access to detailed localization information. Similarly, the signaling storm detection xApp provides expected performance under the assumption that there is access to detailed information on, e.g., time advance resolution parameter. We conclude here that several aspects still need to be well-defined to allow smooth software implementation; these include the rules for data reporting in time, parameters available in service models, and localization features. Concerning the second logical part, related to low-level implementation, we compare the numerical results of the traffic steering and quality-of-service-based resource allocation xApps and draw conclusions related to implementation and testing. In particular, we point out problems associated with the simulator, the software, and conflicts inside. Finally, we identify the key challenges which should be treated as incentives for joint academia-industry cooperation in the field of Open RAN. Thus, the paper presents the lesson learned during the first years of xApp development.}
}


@article{DBLP:journals/jsac/HuangSLCHDI24,
	author = {Yuhong Huang and
                  Qi Sun and
                  Nan Li and
                  Ziqi Chen and
                  Jinri Huang and
                  Haiyu Ding and
                  Chih{-}Lin I},
	title = {Validation of Current {O-RAN} Technologies and Insights on the Future
                  Evolution},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {2},
	pages = {487--505},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3336180},
	doi = {10.1109/JSAC.2023.3336180},
	timestamp = {Fri, 01 Mar 2024 19:09:02 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HuangSLCHDI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entering the 5G era, the mobile network operators (MNO) are facing greater challenges in providing services cost effectively than any other previous generations. The potential solutions to this are lying on the emerging trend of deep convergence of information technology (IT), communication technology (CT) and data technology (DT). In particular, the O-RAN technology, the representation of such ICDT convergence and proposed by the O-RAN ALLIANCE in 2018, is transforming Radio Access Networks towards a new paradigm featuring openness, cloudification and intelligence. O-RAN has gained huge attention from both industry and academia since its inception. In this paper, we presented the recent endeavors from China Mobile, including our deployment scenarios, various test results from open fronthaul, cloud platform to the intelligent controller. Our rich and comprehensive tests have demonstrated the viability and superiority of current O-RAN technologies. Furthermore, we also provide our deep thinking on the O-RAN future evolution in order to better serve the emerging applications such as Metaverse, cloud extended-reality (XR), extensive enterprise private 5G verticals and so on.}
}


@article{DBLP:journals/jsac/LiGCDA24,
	author = {Peng Li and
                  Song Guo and
                  Lin Cai and
                  Mehrdad Dianati and
                  Nirwan Ansari},
	title = {Guest Editorial Human-Centric Communication and Networking for Metaverse
                  Over 5G and Beyond Networks - Part {I}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {509--513},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3344091},
	doi = {10.1109/JSAC.2023.3344091},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiGCDA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse, a hypothetical digital environment linking the cyber world and the physical world, is expected to revolutionize the way people interact. In the metaverse, people interact with objects, the environment, and each other through digital representations of themselves or avatars across time and space. For example, in the metaverse, people can have meetings with colleagues hundreds of miles away. They can also walk through the aisles of a store, find the best fit and have it delivered to their doorstep. It is also possible to simulate the optimal process manufacturing line to adjust for product variation and minimize bottlenecks, or test an innovative aircraft wing design without building expensive prototypes.}
}


@article{DBLP:journals/jsac/ZhaoQY24,
	author = {Jun Zhao and
                  Liangxin Qian and
                  Wenhan Yu},
	title = {Human-Centric Resource Allocation in the Metaverse Over Wireless Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {514--537},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345397},
	doi = {10.1109/JSAC.2023.3345397},
	timestamp = {Sun, 04 Aug 2024 19:48:08 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhaoQY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Metaverse will provide numerous immersive applications for human users, by consolidating technologies like extended reality (XR), video streaming, and cellular networks. Optimizing wireless communications to enable the human-centric Metaverse is important to satisfy the demands of mobile users. In this paper, we formulate the optimization of the system utility-cost ratio (UCR) for the Metaverse over wireless networks. Our human-centric utility measure for virtual reality (VR) applications of the Metaverse represents users’ perceptual assessment of the VR video quality as a function of the data rate and the video resolution and is learned from real datasets. The variables jointly optimized in our problem include the allocation of both communication and computation resources as well as VR video resolutions. The system cost in our problem comprises the energy consumption and delay and is non-convex with respect to the optimization variables. To solve the non-convex optimization, we develop a novel fractional programming technique, which contributes to optimization theory and has broad applicability beyond our paper. Our proposed algorithm for the system UCR optimization is computationally efficient and finds a stationary point to the constrained optimization. Through extensive simulations, our algorithm is demonstrated to outperform other approaches.}
}


@article{DBLP:journals/jsac/MaOD24,
	author = {Yuyin Ma and
                  Kaoru Ota and
                  Mianxiong Dong},
	title = {QoE Optimization for Virtual Reality Services in Multi-RIS-Assisted
                  Terahertz Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {538--551},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345394},
	doi = {10.1109/JSAC.2023.3345394},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MaOD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The immersive experience and 360-degree visual stimulation offered by virtual reality (VR) have contributed to its widespread adoption in games, education, and healthcare. The quality of experience (QoE), as a significant performance indicator, is used to measure user experience from subjective and objective perspectives and is required to satisfy high data rate, low delay, and high reliability in the wireless VR system. To achieve a higher data rate for VR users, a terahertz (THz) network is deployed. However, THz frequency experiences severe signal attenuation due to complex indoor obstacles, which can be alleviated by utilizing a reconfigurable intelligent surface (RIS) equipped with programmable metamaterial reflective elements. Taking inspiration from these considerations, this paper investigates a new framework for indoor multi-user multi-RIS-assisted THz wireless VR systems. Based on the scenario, an optimization problem is formulated to maximize the QoE by jointly optimizing the passive beamforming at RIS, the transmit power allocation among VR users, and the rendering capacity allocation among virtual objects. To achieve an optimal solution, we decompose the optimization problem into two stages: stage-1 aims to minimize BER and maximize data transmission rate, while stage-2 aims to maximize rendering capacity among virtual objects. Objective function conversion and alternative optimization (AO) methods are employed to address the two problems. Extensive simulations are conducted to validate the feasibility of the proposed system model and to showcase the superior performance of the proposed method in terms of QoE compared to other baseline methods.}
}


@article{DBLP:journals/jsac/WangLNSGJ24,
	author = {Xiaojie Wang and
                  Jiameng Li and
                  Zhaolong Ning and
                  Qingyang Song and
                  Lei Guo and
                  Abbas Jamalipour},
	title = {Wireless Powered Metaverse: Joint Task Scheduling and Trajectory Design
                  for Multi-Devices and Multi-UAVs},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {552--569},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345433},
	doi = {10.1109/JSAC.2023.3345433},
	timestamp = {Sun, 06 Oct 2024 21:33:56 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangLNSGJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To support the running of human-centric metaverse applications on mobile devices, Unmanned Aerial Vehicle (UAV)-assisted Wireless Powered Mobile Edge Computing (WPMEC) is promising to compensate for limited computational capabilities and energy supplies of mobile devices. The high-speed computational processing demands and significant energy consumption of metaverse applications require joint resource scheduling of multiple devices and UAVs, but existing WPMEC solutions address either device or UAV scheduling due to the complexity of combinatorial optimization. To solve the above challenge, we propose a two-stage alternating optimization algorithm based on multi-task Deep Reinforcement Learning (DRL) to jointly allocate charging time, schedule computation tasks, and optimize trajectory of UAVs and mobile devices in a wireless powered metaverse scenario. First, considering energy constraints of both UAVs and mobile devices, we formulate an optimization problem to maximize the computation efficiency of the system. Second, we propose a heuristic algorithm to efficiently perform time allocation and charging scheduling for mobile devices. Following this, we design a multi-task DRL scheme to make charging scheduling and trajectory design decisions for UAVs. Finally, theoretical analysis and performance results demonstrate that our algorithm exhibits significant advantages over representative methods in terms of convergence speed and average computation efficiency.}
}


@article{DBLP:journals/jsac/ZhangZP24,
	author = {Xi Zhang and
                  Qixuan Zhu and
                  H. Vincent Poor},
	title = {Neyman-Pearson Criterion Driven {NFV-SDN} Architectures and Optimal
                  Resource-Allocations for Statistical-QoS Based mURLLC Over Next- Generation
                  Metaverse Mobile Networks Using {FBC}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {570--587},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345428},
	doi = {10.1109/JSAC.2023.3345428},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse streaming, as one of the key wireless services over 6G mobile networks, generates the delay/error-sensitive and bandwidth-intensive wireless traffics with stringent quality-of-service (QoS) requirements. Consequently, metaverse streaming can be modeled as a new type of massive ultra-reliable low-latency communications (mURLLC) traffic over 6G mobile networks. However, how to efficiently support metaverse streaming with constrained wireless resources and dynamic network conditions has imposed many new challenges not encountered before. To conquer these difficulties, in this paper we propose the Neyman-Pearson criterion driven network functions virtualization (NFV) and software-defined network (SDN) architectures and optimal resource-allocations for statistical-QoS theory based mURLLC streaming over 6G metaverse mobile networks using finite blocklength coding (FBC). First, we use Neyman-Pearson hypothesis tests for characterizing metaverse streaming requests’ distribution profiles to predict their future accessing frequencies/patterns. Second, our formulated NFV/SDN architectures and virtual-network slices are assigned to the designated metaverse mobile users with the same predicted data request distributions, categories, and statistical-QoS requirements. Third, integrating the statistical QoS theory with FBC, we develop metaverse-streaming schemes by maximizing aggregate \\epsilon -effective capacity and deriving optimal transmit power allocations. Finally, we use numerical analyses to validate and evaluate our proposed schemes over 6G mobile networks.}
}


@article{DBLP:journals/jsac/XiaoDCZ24,
	author = {Yuquan Xiao and
                  Qinghe Du and
                  Wenchi Cheng and
                  Wei Zhang},
	title = {Adaptive Sampling and Transmission for Minimizing Age of Information
                  in Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {588--602},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345417},
	doi = {10.1109/JSAC.2023.3345417},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XiaoDCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse is envisioned to shape a virtual digital world accommodating people to live, work, and interact with each other, which requires massive information exchange for frequent updates of panoramic information in the digital world and imposes unprecedented pressure on future networks, so it is desirable to only sample the information updating process covering objects of user’s main attention. Yet under the always-limited wireless capacity compared to the persistently-growing information load, a critically important but unanswered question remains, i.e., how often shall we sample information updating process and deliver it to users, while keeping information at users’ side as fresh as possible. To answer this question, we investigate the statistical age-of-information (AoI) minimization problems to catch varying wireless channels and attention of users. Unlike conventional average or maximum AoI optimization technologies, we concentrate on statistical feature of AoI to more accurately characterize the capability of supporting metaverse applications. The formulated problems are solved by fractional programming. Specifically, using the Dinkelbach’s and quadratic transforms, we derive the adaptive sampling and transmission schemes for cases with single and multiple users, respectively. The interaction among multiple users is also considered. Analyses reveal that the optimized sampling rate shall decrease as the information updating process covers more varying objects or the channel gets poorer. Moreover, when the AoI requirement becomes extremely stringent, the sampling rate approaches a constant. Numerical results validate that our proposals can achieve lower statistical AoI than baseline schemes, thus offering better experiences for metaverse users.}
}


@article{DBLP:journals/jsac/ZhangZSLL24,
	author = {Xiaoqi Zhang and
                  Haijun Zhang and
                  Kai Sun and
                  Keping Long and
                  Yonghui Li},
	title = {Human-Centric Irregular RIS-Assisted Multi-UAV Networks With Resource
                  Allocation and Reflecting Design for Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {603--615},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345426},
	doi = {10.1109/JSAC.2023.3345426},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZSLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human-centric Metaverse services requires novel communication and networking technologies to achieve seamless connectivity for Metaverse users. Reconfigurable intelligent surface (RIS) in 5G and beyond networks can provide highly reliable communication connections, superior user quality of service (QoS), seamless user connections, and extensive signal coverage for Metaverse. Deploying RIS in unmanned aerial vehicle (UAV) networks for Metaverse can enormously improve the signal propagation environment and human-centric communication experiences. Considering the channel uncertainty of the air-ground cascade communication link in Metaverse, an RIS-aided multi-UAV cross-layer network system is proposed. Under the cross-tier interference limitation and the rate outage probability constraint, the system EE improved by maximizing the minimal energy efficiency (EE) of UAV units. Different from the existing RIS schemes, which suffer from the significant channel acquisition cost or power consumption, this paper first proposes a topology design scheme of irregular RIS, which Metaverse user only connects a few RIS elements to obtain high EE. Secondly, with the imperfect cascade channel state information (CSI) error model, the rate outage probability constraint is approximated by Bernstein type inequality to enhance the seamless human-centric connectivity service. Hence a low complexity scheme is invoked to co-design the power control parameter at the UAV transmitter and RIS reflecting phase. Finally, affluent simulation curves verify that the irregular RIS controller deployment combined with low power loss topology design and low-complexity phase shift design contributes to improve human-centric QoS for Metaverse service.}
}


@article{DBLP:journals/jsac/LiuHXZSY24,
	author = {Dongxiao Liu and
                  Cheng Huang and
                  Liang Xue and
                  Weihua Zhuang and
                  Xuemin Shen and
                  Bidi Ying},
	title = {Collaborative and Verifiable {VNF} Management for Metaverse With Efficient
                  Modular Designs},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {616--628},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345422},
	doi = {10.1109/JSAC.2023.3345422},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuHXZSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The metaverse is envisioned to create immersive and virtual worlds for people to experience interoperable 3D applications. However, the real-time, interactive, and multimedia characteristics of the metaverse applications require strict quality-of-service (QoS) on the underlying networking architecture, including high throughput, ultra-low delay, and human-centric service configurations. Network function virtualization (NFV)-enabled networking resource management can provide a promising solution to service-oriented QoS satisfaction for metaverse users. In this paper, we propose a blockchain-based collaborative and verifiable virtualized network function (VNF) management scheme for metaverse, named BVNF+. BVNF+ enables multiple network providers across different trust domains to abstract their services as VNFs and collaboratively manage end-to-end network slices for human-centric network services in metaverse. To address the design challenge of balancing the on-chain and off-chain overheads, we decouple the computations of VNF queries into modular components based on software and hardware verifiable computation (vc) approaches. Our modular strategy can achieve on/off-chain computation and communication efficiency while keeping low usage of the secure hardware. We conduct security analysis and extensive experiments based on a real-world blockchain testing network. The analysis and experimental results demonstrate that BVNF+ is both secure and efficient as compared with the existing works.}
}


@article{DBLP:journals/jsac/ChenLXWJQ24,
	author = {Qimei Chen and
                  Ruixue Li and
                  Xiaoxia Xu and
                  Jing Wu and
                  Hao Jiang and
                  Meikang Qiu},
	title = {Human-Aware Dynamic Hierarchical Network Control for Distributed Metaverse
                  Services},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {629--642},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345399},
	doi = {10.1109/JSAC.2023.3345399},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenLXWJQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse has emerged as a revolutionary technique for transforming the way people interact with digital content, which relies on a distributed computing and communication infrastructure, encompassing terminal users, edge servers, and cloud servers. However, the rapid evolution of the Metaverse presents challenges that surpass the capabilities of existing communication and network infrastructures, particularly on network bandwidth and latency. Additionally, human experience becomes a critical factor in this domain. Therefore, we introduce a human-aware hierarchical software defined network (SDN) architecture consisting of a Metaverse cloud layer, a mobile edge computing (MEC) server empowered edge layer, and a distributed terminal layer. Each MEC server dynamically controls a multi-antenna base station (BS) and several reconfigurable intelligent surfaces (RISs) according to the terminal immersive experience requirements in real-time. To overcome the bandwidth limitation, we propose a novel smart reconfigurable spatial reuse new radio in unlicensed spectrum (NR-U) framework, which can realize customizable communications through flexibly and coordinately reconfiguring beams among the coordination between BSs and RISs. The objective function is formulated as a Lyapunov optimization based decentralized partially-observable Markov decision process (Dec-POMDP) problem to maximize the spectral efficiency while guaranteeing the latency and reliability requirements in Metaverse, via a joint user selection, phase-shift control, and beam coordination strategy. To solve the above non-convex, strongly coupled, and mixed integer nonlinear programming (MINLP), we propose a novel multi-agent hierarchical deep reinforcement learning (MAHDRL) algorithm that integrates deep Q-network (DQN) to solve discrete problems, deep deterministic policy gradient (DDPG) to solve continuous problems, and mixing network to capture complex interactions between multiple agents. Numerical results demonstrate the effectiveness of the proposed algorithm and verify the performance improvements compared to traditional multi-agent deep reinforcement learning (MADRL) algorithms.}
}


@article{DBLP:journals/jsac/ZhengZJ24,
	author = {Jun Zheng and
                  Qiangfeng Zhu and
                  Abbas Jamalipour},
	title = {Content Delivery Performance Analysis of a Cache-Enabled {UAV} Base
                  Station Assisted Cellular Network for Metaverse Users},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {643--657},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345424},
	doi = {10.1109/JSAC.2023.3345424},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse can provide powerful human-centric interactive experiences for users and metaverse application content is the fundamental component that supports the metaverse. Considering that metaverse users are more sensitive to the delay of content delivery service, unmanned aerial vehicles (UAV) can be used as aerial base stations (BSs) to assist a cellular network to provide better content delivery service for delay-sensitive metaverse users as UAV base stations (UBSs) have big potential for line-of-sight (LoS) transmission and can be deployed closer to metaverse users than macro base stations (MBSs). This paper studies the content delivery performance analysis of a cache-enabled UBS-assisted cellular network for metaverse users. Analytical models are derived for investigating the content delivery performance of the network in terms of the content delivery success probability of the network and the average content delivery delay of a metaverse user. In deriving the analytical models, a more realistic repulsive point process is considered for modeling the location distribution of MBSs, and an air-to-ground (A2G) channel model with both a LoS link and a non-line-of-sight (NLoS) link is considered. Moreover, the cache hit probability of a UBS using a probabilistic caching strategy is also taken into consideration. A BS association strategy for delay-sensitive metaverse users based on the strongest average received power at a user and the cache hit probability of a UBS is proposed. In addition, the association probabilities with the association strategy are derived for different types of base stations. A lower bound of the content delivery success probability and an upper bound of the average content delivery delay are obtained based on the derived analytical models. The numerical results justify the effectiveness and advantage of the proposed BS association strategy and show that there exist an optimal UBS height and an optimal value of the number of UBSs, which result in the optimal content delivery performance. The obtained results can provide theoretical guidance for the deployment of UBSs in a cache-enabled UBS-assisted cellular network to provide better human-centric content delivery service for metaverse user.}
}


@article{DBLP:journals/jsac/LiHSLW24,
	author = {Fuliang Li and
                  Chenyang Hei and
                  Jiaxing Shen and
                  Qing Li and
                  Xingwei Wang},
	title = {Human-Intent-Driven Cellular Configuration Generation Using Program
                  Synthesis},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {658--668},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345387},
	doi = {10.1109/JSAC.2023.3345387},
	timestamp = {Thu, 15 Aug 2024 07:54:33 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiHSLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cellular networks are vital for emerging applications like the Metaverse, which impose demanding quality and quantity requirements. This necessitates frequent reconfiguration of both new and existing base stations to balance network service quality (e.g., ultra-low latency and high bandwidth) and resource consumption. Existing data-driven configuration methods learn from historical data, but have two key limitations. First, they yield only approximate solutions, lacking precision. Second, poor bootstrapping for new base stations with previously unobserved attributes. In this paper, we pioneer intent-driven configuration synthesis by designing an intent language and utilizing satisfiability modulo theory (SMT) for cellular networks to enable exact and precise solutions. We formulate synthesis as an SMT problem, permitting verification of precision. First, we cast configuration generation as a program synthesis problem via novel modeling to bridge the intent-configuration gap. Second, we extend SMT synthesis to scale to large networks. However, vanilla SMT approaches have poor scalability. Hence, we propose an optimization using sampling for constraint verification instead of exhaustive forward solving. We also design a domain-specific optimization to prune the sample space and improve efficiency. Experiments on various network scales demonstrate the effectiveness of our proposed SMT-based cellular network configuration synthesis.}
}


@article{DBLP:journals/jsac/NanLZMX24,
	author = {Haihan Nan and
                  Ruidong Li and
                  Xiaoyan Zhu and
                  Jianfeng Ma and
                  Kaiping Xue},
	title = {Spatio-Temporal Identity Multi-Graph Convolutional Network for Traffic
                  Prediction in the Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {669--679},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345389},
	doi = {10.1109/JSAC.2023.3345389},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/NanLZMX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The metaverse is at the forefront of the next-generation internet application, where billions of users seamlessly immerse themselves in a hybrid reality of physical-virtual worlds and switch between virtual environments thanks to reliable resource allocation and synchronization. However, the exponential growth of users and computationally intensive applications make joint optimization of multiple indicators challenging. Therefore, predicting user behavior is pivotal in assisting the optimization process. Although graph neural networks have demonstrated remarkable performance in traffic prediction, most existing schemes link nodes based on their distances and require significant computational resources, limiting their generalization and deployment in the metaverse. To solve this problem, we propose an efficient Spatio-temporal Identity Multi-graph convolutional network Framework (SIMF) for application-level traffic prediction in the metaverse. In the SIMF, we design a spatio-temporal embedding layer and multi-graph convolutional module to jointly capture spatio-temporal correlations among nodes (avatars) and reduce the dependence on topology information, which is more consistent with the real relationship between avatars in the metaverse. We conduct extensive experiments to evaluate the SIMF, which show that our proposed framework achieves superior accuracy even without graph information while maintaining low time complexity, making it suitable for traffic prediction in the metaverse.}
}


@article{DBLP:journals/jsac/LiuTZLHCGYZ24,
	author = {Jiacheng Liu and
                  Feilong Tang and
                  Zhijian Zheng and
                  Hao Liu and
                  Xiaofeng Hou and
                  Long Chen and
                  Ming Gao and
                  Jiadi Yu and
                  Yanmin Zhu},
	title = {Practical Network Modeling Using Weak Supervision Signals for Human-Centric
                  Networking in Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {680--693},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345391},
	doi = {10.1109/JSAC.2023.3345391},
	timestamp = {Sun, 06 Oct 2024 21:33:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuTZLHCGYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the metaverse continues to expand, it becomes increasingly critical to have human-centric networks that are both efficient and high-performing to optimize the user experience. Network modeling plays a fundamental role in optimizing and allocating resources efficiently, and configuring networks to satisfy the demands of diverse applications and users. Recently, traditional queuing theory-based approaches to network modeling have given way to machine learning-based methods. These methods rely on vast amounts of data for building precise models. Although high-precision simulators are ubiquitous, data collection is still an expensive and time-consuming process, resulting in a data bottleneck. In this paper, we propose a weakly supervised learning approach to modeling networks for human-centric networking in the metaverse. Specifically, we identify that queuing theory-based labels can be used to design the supervision signal at a very low cost. Therefore, we propose an approach that combines the inaccurate network modeling obtained from queuing theory-based approaches with an efficient and precise network model through only a small amount of simulation data. To make it a reality, we propose a novel neural network model that combines the powerful graph neural network and transformers. Additionally, we propose several additional supervision signals and a training algorithm to build a better network model. Experimental results demonstrate that our approach reduces the burden of data collection while achieving prediction accuracy comparable to results from large amounts of expensive simulation data. Furthermore, our approach exhibits superior generalization ability.}
}


@article{DBLP:journals/jsac/XuNWZKXMH24,
	author = {Minrui Xu and
                  Dusit Niyato and
                  Benjamin Wright and
                  Hongliang Zhang and
                  Jiawen Kang and
                  Zehui Xiong and
                  Shiwen Mao and
                  Zhu Han},
	title = {EPViSA: Efficient Auction Design for Real-Time Physical-Virtual Synchronization
                  in the Human-Centric Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {694--709},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345383},
	doi = {10.1109/JSAC.2023.3345383},
	timestamp = {Fri, 28 Jun 2024 14:57:07 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XuNWZKXMH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse can obscure the boundary between the physical and virtual worlds. Specifically, for the human-centric Metaverse in vehicular networks, i.e., the vehicular Metaverse, vehicles are no longer isolated physical spaces but interfaces that extend the virtual worlds to the physical world. Accessing the human-centric Metaverse via autonomous vehicles (AVs), drivers and passengers can immerse in and interact with 3D virtual objects overlaying views of streets on head-up displays (HUD) via augmented reality (AR). The seamless, immersive, and interactive experience rather relies on real-time multi-dimensional data synchronization between physical entities, i.e., AVs, and virtual entities, i.e., Metaverse billboard providers (MBPs). However, mechanisms to allocate and match synchronizing AV and MBP pairs to roadside units (RSUs) in a synchronization service market, which consists of the physical and virtual submarkets, are vulnerable to adverse selection. In this paper, we propose an enhanced second-score auction-based mechanism, named EPViSA, to allocate physical and virtual entities in the synchronization service market of the vehicular Metaverse. The EPViSA mechanism can determine synchronizing AV and MBP pairs simultaneously while protecting participants from adverse selection and thus achieving high total social welfare. We propose a synchronization scoring rule to eliminate the external effects from the virtual submarkets. Then, a price scaling factor is introduced to enhance the allocation of synchronizing virtual entities in the virtual submarkets. Finally, rigorous analysis and extensive experiments demonstrate EPViSA can achieve at least 96% of the social welfare compared to the omniscient benchmark while ensuring strategy-proof and adverse selection free through a simulation testbed.}
}


@article{DBLP:journals/jsac/LotfiNSKS24,
	author = {Ismail Lotfi and
                  Dusit Niyato and
                  Sumei Sun and
                  Dong In Kim and
                  Xuemin Shen},
	title = {Semantic Information Marketing in the Metaverse: {A} Learning-Based
                  Contract Theory Framework},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {710--723},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345402},
	doi = {10.1109/JSAC.2023.3345402},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LotfiNSKS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we address the problem of designing incentive mechanisms by a virtual service provider (VSP) to hire sensing IoT devices to sell their sensing data to help creating and rendering the digital copy of the physical world in the Metaverse. Due to the limited bandwidth, we propose to use semantic extraction algorithms to reduce the delivered data by the sensing IoT devices. Nevertheless, mechanisms to hire sensing IoT devices to share their data with the VSP and then deliver the constructed digital twin to the Metaverse users are vulnerable to adverse selection problem. The adverse selection problem, which is caused by information asymmetry between the system entities, becomes harder to solve when the private information of the different entities are multi-dimensional. We propose a novel iterative contract design and use a new variant of multi-agent reinforcement learning (MARL) to solve the modelled multi-dimensional contract problem. To demonstrate the effectiveness of our algorithm, we conduct extensive simulations and measure several key performance metrics of the contract for the Metaverse. Our results show that our designed iterative contract is able to incentivize the participants to interact truthfully, which maximizes the profit of the VSP with minimal individual rationality (IR) and incentive compatibility (IC) violation rates. Furthermore, the proposed learning-based iterative contract framework has limited access to the private information of the participants, which is to the best of our knowledge, the first of its kind in addressing the problem of adverse selection in incentive mechanisms.}
}


@article{DBLP:journals/jsac/LiuQWFLDL24,
	author = {Xiang Liu and
                  Yifan Qin and
                  Weiwei Wu and
                  Chenchen Fu and
                  Yan Lyu and
                  Fang Dong and
                  Junzhou Luo},
	title = {B\({}^{\mbox{2}}\)-Bandit: Budgeted Pricing With Blocking Constraints
                  for Metaverse Crowdsensing Under Uncertainty},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {724--736},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345396},
	doi = {10.1109/JSAC.2023.3345396},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuQWFLDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse has been viewed as the next generation of human-computer interaction, which requires collecting information from both the physical and virtual world. One potential way is to employ virtual service providers (VSPs) to finish collection tasks by designing posted-pricing mechanisms via the crowdsensing platform. As VSPs’ costs and values are usually unknown, learning the optimal posted-pricing policy under uncertainty is undoubtedly critical to utilize the budget efficiently. However, existing posted-pricing learning algorithms assume that agents provide services without blocking and agents’ attributes follow an independent identical distribution, both of which are unrealistic in Metaverse, e.g., VSPs should continuously sense the physical world to make provided services realistic, which makes the long working VSP unavailable/blocked for a certain period of time. In this paper, we address the budgeted pricing problem under uncertainty by considering blocking constraints and unknown non-identical VSPs’ attributes. The problem is modeled as a Budgeted-pricing Blocking Bandit (B2-bandit) problem, which remains unaddressed even for the oracle case with known VSPs’ information. We thus first propose a pricing policy for the oracle case with an instance-dependent approximation ratio to the global optimum. For the general B2-bandit problem with unknown information, we propose an online learning algorithm satisfying blocking constraints and incurring an accumulated regret up to O(MK\\log B) as compared to the oracle approximation algorithm, where M,K,B are the number of VSPs, candidate prices and the budget, respectively. Experiments on real datasets validate that the proposed algorithm improves more than 172% accumulated value compared to baseline pricing algorithms.}
}


@article{DBLP:journals/jsac/SuL24,
	author = {Ningxin Su and
                  Baochun Li},
	title = {MLOps in the Metaverse: Human-Centric Continuous Integration},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {737--751},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345385},
	doi = {10.1109/JSAC.2023.3345385},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SuL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The metaverse is a virtual world that exists entirely in a computer-generated environment, and it offers a new frontier for machine learning. One of the major challenges for using machine learning in the metaverse is MLOps (Machine Learning Operations), an emerging field that focuses on deploying and managing machine learning models in production. It has been widely acknowledged that machine learning models require a large amount of data to learn and make accurate predictions, and such data is generated progressively in real-time as human users interact with the metaverse. Due to the human-centric nature of the metaverse, it goes without saying that, once deployed, models need to be able to adapt to the constantly changing interactive environment and still make accurate predictions. Borrowing a page from software engineering, in this paper, we explore the design space of human-centric continuous integration in metaverse environments, where labeled data samples accumulated with explicit human interactive behavior (e.g., using virtual reality or augmented reality headsets) are used for fine-tuning a deployed deep learning model over a sustained period of time. We propose SPIN, a new mechanism that efficiently utilizes data samples collected from a large number of participating human users over time to fine-tune a deployed model that is shared across all the users. In an extensive array of experimental results using image classification and state-of-the-art YOLOv8 object detection models as case studies, we show that SPIN outperforms FedBuff, a state-of-the-art asynchronous FL mechanism from conventional federated learning, by a substantial margin.}
}


@article{DBLP:journals/jsac/MengCDSZIV24,
	author = {Zhen Meng and
                  Kan Chen and
                  Yufeng Diao and
                  Changyang She and
                  Guodong Zhao and
                  Muhammad Ali Imran and
                  Branka Vucetic},
	title = {Task-Oriented Cross-System Design for Timely and Accurate Modeling
                  in the Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {752--766},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345398},
	doi = {10.1109/JSAC.2023.3345398},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MengCDSZIV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we establish a task-oriented cross-system design framework to minimize the required packet rate for timely and accurate modeling of a real-world robotic arm in the Metaverse, where sensing, communication, prediction, control, and rendering are considered. To optimize a scheduling policy and prediction horizons, we design a Constraint Proximal Policy Optimization (C-PPO) algorithm by integrating domain knowledge from relevant systems into the advanced reinforcement learning algorithm, Proximal Policy Optimization (PPO). Specifically, the Jacobian matrix for analyzing the motion of the robotic arm is included in the state of the C-PPO algorithm, and the Conditional Value-at-Risk (CVaR) of the state-value function characterizing the long-term modeling error is adopted in the constraint. Besides, the policy is represented by a two-branch neural network determining the scheduling policy and the prediction horizons, respectively. To evaluate our algorithm, we build a prototype including a real-world robotic arm and its digital model in the Metaverse. The experimental results indicate that domain knowledge helps to reduce the convergence time and the required packet rate by up to 50%, and the cross-system design framework outperforms a baseline framework in terms of the required packet rate and the tail distribution of the modeling error.}
}


@article{DBLP:journals/jsac/ChenLXSL24,
	author = {Miaojiang Chen and
                  Anfeng Liu and
                  Neal N. Xiong and
                  Houbing Song and
                  Victor C. M. Leung},
	title = {{SGPL:} An Intelligent Game-Based Secure Collaborative Communication
                  Scheme for Metaverse Over 5G and Beyond Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {767--782},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345403},
	doi = {10.1109/JSAC.2023.3345403},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenLXSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human-centric communication metaverse relies on the convergent integration of multiple existing technologies such as 5G and beyond networks, virtual reality, augmented reality, and digital twins, and thus their security vulnerabilities and vulnerability to interference attacks may also be inherited by the metaverse. In particular, existing security policies may be inefficient for communication interference problems encountered in multi-device collaborative computing in a metaverse 5G environment and lack adaptability to metaverse applications. In this paper, we propose a novel intelligent game anti-interference collaborative computing model that accurately describes the interference relationships among source devices, cooperating devices, and interferers in metaverse collaborative computing. We model the offensive and defensive confrontation between multiple metaverse devices as a Stackelberg game, where the source device is the leader, the collaborative computing device acts as the sub-leader, adjusts its antijamming strategy according to the source device’s strategy to improve the source device’s communication anti-jamming performance, and the jammer acts as the follower. We design an intelligent Stackelberg Game-theoretic Policy-based Learning (SGPL) algorithm for jamming resistance in metaverses over 5G and Beyond Networks, where the leaders (co-computing devices) update their training parameters using the total derivatives of the objective function, while the followers (i.e., jammers) update their training parameters using an independent gradient dynamics strategy. Loops are eased and convergence is accelerated by introducing differential dynamics into the leader training network to reflect the interaction structure of the critic and actor network layers. Finally, numerical results demonstrate the effectiveness of the proposed SGPL algorithm in metaverse anti-jamming countermeasures. The proposed SGPL algorithm has the potential to be generalized to other metaverse applications with multi-user attack and defense characteristics.}
}


@article{DBLP:journals/jsac/YeWLDLWT24,
	author = {Yuxiao Ye and
                  Hao Wang and
                  Chi Harold Liu and
                  Zipeng Dai and
                  Guozheng Li and
                  Guoren Wang and
                  Jian Tang},
	title = {QoI-Aware Mobile Crowdsensing for Metaverse by Multi-Agent Deep Reinforcement
                  Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {783--798},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345395},
	doi = {10.1109/JSAC.2023.3345395},
	timestamp = {Tue, 16 Apr 2024 15:32:13 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YeWLDLWT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse is expected to provide mobile users with emerging applications both in regular situation like intelligent transportation services and in emergencies like wireless search and disaster response. These applications are usually associated with stringent quality-of-information (QoI) requirements like throughput and age-of-information (AoI), which can be further guaranteed by using unmanned aerial vehicles (UAVs) as aerial base stations (BSs) to compensate the existing 5G infrastructures. In this paper, we consider a new QoI-aware mobile crowdsensing (MCS) campaign by UAVs which move around and collect data from mobile users wearing metaverse devices. Specifically, we propose “MetaCS”, a multi-agent deep reinforcement learning (MADRL) framework with improvements on a Transformer-based user mobility prediction module between regions and a relational graph learning mechanism to enable the selection of most informative partners to communicate for each UAV. Extensive results and trajectory visualizations on three real mobility datasets in NCSU, KAIST and Beijing show that MetaCS consistently outperforms six baselines in terms of overall QoI index, when varying different numbers of UAVs, throughput requirement, and AoI threshold.}
}


@article{DBLP:journals/jsac/CaiCMG24,
	author = {Zinuo Cai and
                  Zebin Chen and
                  Ruhui Ma and
                  Haibing Guan},
	title = {{SMSS:} Stateful Model Serving in Metaverse With Serverless Computing
                  and {GPU} Sharing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {3},
	pages = {799--811},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345401},
	doi = {10.1109/JSAC.2023.3345401},
	timestamp = {Sat, 16 Mar 2024 15:10:26 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/CaiCMG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of information technology, the concept of the Metaverse has swept the world and set off a new wave of the industrial revolution. The construction of living and manufacturing scenes based on the Metaverse requires the joint participation of scientists and engineers from various fields where “human” is at the core. In the Metaverse, predicting human behavior and response based on the deep learning model is meaningful because the prediction results can provide more satisfactory services for participants. Therefore, how to deploy a multi-stage machine learning reasoning model has become the bottleneck to improving the development level of Metaverse. Thanks to its scalability and pay-as-you-go billing model, the emerging serverless computing can effectively cope with the workload of machine learning inference. However, the statelessness of serverless computing and the lack of good GPU resource-sharing support make it difficult to deploy the machine learning model directly on the serverless computing platform to play its advantages. Therefore, we propose SMSS, a stateful model inference service, which is deployed on a serverless computing platform that supports GPU sharing. Since the serverless computing platform does not support stateful workflow execution, SMSS adopts log-based workflow runtime support. We also design a mechanism of two-layer GPU sharing to fully explore the potential of inter-model and intra-model GPU sharing. We evaluate the effectiveness of SMSS with real workloads. Our experimental results show that log-based stateful workflow operation support can ensure the stateful execution of tasks with low overhead but facilitate error location and recovery. Two-layer GPU Sharing can reduce the cold start time of inference tasks to two orders of magnitude at most.}
}


@article{DBLP:journals/jsac/LiGCDA24a,
	author = {Peng Li and
                  Song Guo and
                  Lin Cai and
                  Mehrdad Dianati and
                  Nirwan Ansari},
	title = {Guest Editorial Human-Centric Communication and Networking for Metaverse
                  Over 5G and Beyond Networks - Part {II}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {813--816},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3344109},
	doi = {10.1109/JSAC.2023.3344109},
	timestamp = {Mon, 15 Apr 2024 08:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiGCDA24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse, a hypothetical digital environment linking the cyber world and the physical world, is expected to revolutionize the way people interact. In the metaverse, people interact with objects, the environment, and each other through digital representations of themselves or avatars across time and space. For example, in the metaverse, people can have meetings with colleagues hundreds of miles away. They can also walk through the aisles of a store, find the best fit, and have it delivered to their doorstep. It is also possible to simulate the optimal process manufacturing line to adjust for product variation and minimize bottlenecks, or test an innovative aircraft wing design without building expensive prototypes.}
}


@article{DBLP:journals/jsac/ZhouYZLWMPJ24,
	author = {Xiaokang Zhou and
                  Qiuyue Yang and
                  Xuzhe Zheng and
                  Wei Liang and
                  Kevin I{-}Kai Wang and
                  Jianhua Ma and
                  Yi Pan and
                  Qun Jin},
	title = {Personalized Federated Learning With Model-Contrastive Learning for
                  Multi-Modal User Modeling in Human-Centric Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {817--831},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345431},
	doi = {10.1109/JSAC.2023.3345431},
	timestamp = {Sat, 08 Jun 2024 13:14:28 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhouYZLWMPJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the flourish of digital technologies and rapid development of 5G and beyond networks, Metaverse has become an increasingly hotly discussed topic, which offers users with multiple roles for diversified experience interacting with virtual services. How to capture and model users’ multi-platform or cross-space data/behaviors become essential to enrich people with more realistic and immersed experience in Metaverse-enabled smart applications over 5G and beyond networks. In this study, we propose a Personalized Federated Learning with Model-Contrastive Learning (PFL-MCL) framework, which may efficiently enhance the communication and interaction in human-centric Metaverse environments by making use of the large-scale, heterogeneous, and multi-modal Metaverse data. Differing from the conventional Federated Learning (FL) architecture, a multi-center aggregation structure to learn multiple global models based on the changes of dynamically updated local model weights, is developed in global, while a hierarchical neural network structure which includes a personalized module and a federated module to tackle both issues on data heterogeneity and model heterogeneity, is designed in local, so as to enhance the performance of PFL with unique characteristics of Metaverse data. In particular, a two-stage iterative clustering algorithm with a more precise initialization is developed to facilitate the personalized global aggregation with dynamically updated multiple aggregation centers. A personalized multi-modal fusion network is constructed to greatly reduce the computational cost and feature dimensions from the high-dimensional heterogeneous inputs for more efficient cross-modal fusion, based on a hierarchical shift-window attention mechanism and a newly designed bridge attention mechanism. A MCL scheme is then incorporated to speed up the model convergence with less communication overload between the local federated module and global model, while an embedding layer which effectively enables the delivered global model to better adapt to the local personality in each client is further integrated. Compared with five baseline methods, experiment and evaluation results based on two different real-world datasets demonstrate the excellent performance of our proposed PFL-MCL model in a fine-grain personalized training strategy, toward more efficient communication and networking among human-centric Metaverse enabled smart applications.}
}


@article{DBLP:journals/jsac/WangWQWXSZ24,
	author = {Pengfei Wang and
                  Zongzheng Wei and
                  Heng Qi and
                  Shaohua Wan and
                  Yunming Xiao and
                  Geng Sun and
                  Qiang Zhang},
	title = {Mitigating Poor Data Quality Impact with Federated Unlearning for
                  Human-Centric Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {832--849},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345388},
	doi = {10.1109/JSAC.2023.3345388},
	timestamp = {Thu, 25 Jul 2024 07:46:12 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangWQWXSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL), which has been employed to train machine learning models on the data with a distributed manner, could enhance the immersive user experience for the human-centric metaverse. However, it’s challenging to train machine learning models accurately and promptly with FL for the human-centric metaverse due to massive data communication and user unreliability. User experience could be negatively affected by using low-quality machine learning models for human-centric metaverse, e.g., it cannot scrutinize and arrive at decisions accurately and timely. To resolve this pressing issue, we propose MetaFul a federated unlearning solution which reduces the negative influences of low-quality data with no data transmission by removing low-quality training models at the server side. To be specific, MetaFul includes three main components. (i) Low-throughput federated learning (LT-FL) addresses the issue of large model transmission in FL by decreasing the dimension and the number of transmitted model parameters. (ii) Loss-based model quality assessment (LM-QA) utilizes the model loss generated in LT-FL to estimate user data quality. (iii) Non-communicative federated unlearning (NC-FUL) revokes the low-quality data impact on the FL model with careful designed federated unlearning at the server side. Both LM-QA and NC-FUL have no communications with clients. Finally, extensive evaluations are conducted to show MetaFul could improve the model accuracy by at least 2.5% and decrease the user perception time by at least 19.3% in human-centric metaverse compared to benchmarks.}
}


@article{DBLP:journals/jsac/HouWJMCR24,
	author = {Xiangwang Hou and
                  Jingjing Wang and
                  Chunxiao Jiang and
                  Zezhao Meng and
                  Jianrui Chen and
                  Yong Ren},
	title = {Efficient Federated Learning for Metaverse via Dynamic User Selection,
                  Gradient Quantization and Resource Allocation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {850--866},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345393},
	doi = {10.1109/JSAC.2023.3345393},
	timestamp = {Mon, 03 Mar 2025 22:17:41 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HouWJMCR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse is envisioned to merge the actual world with a virtual world to bring users unprecedented immersive feelings. To ensure user experience, federated learning (FL) has been expected as a critical enabler to provide metaverse users with high-quality sensing, communicating, and rendering. However, considering the limitation of wireless communication resources and the stringent requirements of users, collaborating with massive metaverse users to realize FL still has tremendous challenges. Most pioneer works on improving the performance of FL assume that the system states are static, which is unsuitable in the metaverse. Because the FL in the metaverse is always a complicated long-term iteration process, where the fluctuations of channel status and available computing resources of users are inevitable, a changeless strategy may lead to poor results. Therefore, this paper proposes an efficient FL scheme relying on dynamic user selection, gradient quantization, and resource allocation. Specifically, we derive the convergence error bound to reveal the impact of user selection, wireless transmission error, and gradient quantization error of each iteration on FL’s convergence. Based on the theoretical analysis, we jointly and dynamically optimize the user selection, gradient quantization, and resource allocation to minimize the error bound with time and energy consumption budgets. Furthermore, to make the formulated sequential decision-making problem tractable, we transform it into a Markov decision process and design a soft actor-critic-based solution. Extensive experiments validate that our proposed scheme has superior performance compared to conventional schemes in dynamic-changing network environments.}
}


@article{DBLP:journals/jsac/GuoQTL24,
	author = {Yiyu Guo and
                  Zhijin Qin and
                  Xiaoming Tao and
                  Geoffrey Ye Li},
	title = {Federated Multi-View Synthesizing for Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {867--879},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345427},
	doi = {10.1109/JSAC.2023.3345427},
	timestamp = {Mon, 16 Sep 2024 19:30:57 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GuoQTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The metaverse is expected to provide immersive entertainment, education, and business applications. However, virtual reality (VR) transmission over wireless networks is data- and computation-intensive, making it critical to introduce novel solutions that meet stringent quality-of-service requirements. With recent advances in edge intelligence and deep learning, we have developed a novel multi-view synthesizing framework that can efficiently provide computation, storage, and communication resources for wireless content delivery in the metaverse. We propose a three-dimensional (3D)-aware generative model that uses collections of single-view images. These single-view images are transmitted to a group of users with overlapping fields of view, which avoids massive content transmission compared to transmitting tiles or whole 3D models. We then present a federated learning approach to guarantee an efficient learning process. The training performance can be improved by characterizing the vertical and horizontal data samples with a large latent feature space, while low-latency communication can be achieved with a reduced number of transmitted parameters during federated learning. We also propose a federated transfer learning framework to enable fast domain adaptation to different target domains. Simulation results have demonstrated the effectiveness of our proposed federated multi-view synthesizing framework for VR content delivery.}
}


@article{DBLP:journals/jsac/LiuZSZDGT24,
	author = {Yuan Liu and
                  Yanan Zhang and
                  Shen Su and
                  Lejun Zhang and
                  Xiaojiang Du and
                  Mohsen Guizani and
                  Zhihong Tian},
	title = {BlockSC: {A} Blockchain Empowered Spatial Crowdsourcing Service in
                  Metaverse While Preserving User Location Privacy},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {880--892},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345416},
	doi = {10.1109/JSAC.2023.3345416},
	timestamp = {Mon, 15 Apr 2024 08:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuZSZDGT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial crowdsourcing (SC) has become a fundamental and emerging technology in Metaverse, facilitating the creation of immersive experiences through location-based services. In these systems, a central SC server leverages SC workers who physically travel to task locations to gather spatiotemporal environment data. However, conventional SC systems face two significant challenges: (1) the SC server, functioning as a centralized authority, can sometimes be unreliable, either due to intentional or unintentional misconduct, (2) to ensure efficient task assignment and validation, the location privacy of tasks and workers is openly accessible. In this study, we formally define location privacy preserved proof generation and verification problem (LP-PGVP) within an SC task matching scenario, with the aim to the above two challenges. Our proposed solution is a blockchain-based SC system (BlockSC), which provides a decentralized platform for task requesters and workers in the Metaverse context through calling smart contracts. We also introduce a ciphertext-based task matching scheme where task location access is granted only to eligible workers executing a task, benefiting from the design of geographic coordinate transformation and bilinear mapping methodology. To further demonstrate the task matching scheme’s operation and impact, we present an easy-to-understand case study. Our evaluation findings confirm that the proposed system effectively maintains location privacy for both SC workers and task requesters, without a considerable sacrifice in task matching efficiency.}
}


@article{DBLP:journals/jsac/ChengGXHYC24,
	author = {Ye Cheng and
                  Yihao Guo and
                  Minghui Xu and
                  Qin Hu and
                  Dongxiao Yu and
                  Xiuzhen Cheng},
	title = {An Adaptive and Modular Blockchain Enabled Architecture for a Decentralized
                  Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {893--904},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345432},
	doi = {10.1109/JSAC.2023.3345432},
	timestamp = {Mon, 15 Apr 2024 08:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChengGXHYC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A metaverse breaks the boundaries of time and space between people, realizing a more realistic virtual experience, improving work efficiency, and creating a new business model. Blockchain, as one of the key supporting technologies for a metaverse design, provides a trusted interactive environment. However, the rich and varied scenes of a metaverse have led to excessive consumption of on-chain resources, raising the threshold for ordinary users to join, thereby losing the human-centered design. Therefore, we propose an adaptive and modular blockchain-enabled architecture for a decentralized metaverse to address these issues. The solution includes an adaptive consensus/ledger protocol based on a modular blockchain, which can effectively adapt to the ever-changing scenarios of the metaverse, reduce resource consumption, and provide a secure and reliable interactive environment. In addition, we propose the concept of Non-Fungible Resource (NFR) to virtualize idle resources. Users can establish a temporary trusted environment and rent others’ NFR to meet their computing needs. Finally, we simulate and test our solution based on XuperChain, and the experimental results prove the feasibility of our design.}
}


@article{DBLP:journals/jsac/PaingSUZDDS24,
	author = {Saw Nang Paing and
                  Jason William Setiawan and
                  Muhammad Asad Ullah and
                  Fakhar Zaman and
                  Trung Q. Duong and
                  Octavia A. Dobre and
                  Hyundong Shin},
	title = {Counterfactual Quantum Byzantine Consensus for Human-Centric Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {905--918},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345420},
	doi = {10.1109/JSAC.2023.3345420},
	timestamp = {Mon, 15 Apr 2024 08:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/PaingSUZDDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum Byzantine fault tolerance (BFT) consensus is a secure and reliable mechanism that enables network nodes to reach an agreement even in the presence of faulty nodes, by using distributed private correlated lists. It plays a crucial role in developing the blockchain-based Metaverse to ensure its integrity and security. In this paper, we propose a counterfactual quantum BFT (CQ-BFT) protocol for a multipartite network using counterfactual unitary telecomputation with the chained quantum Zeno gates. This consensus protocol achieves an agreement among the parties without the passage of any physical particles through the quantum channel. Due to the unique properties of counterfactual communication, we demonstrate that the CQ-BFT protocol can operate in the absence of a shared phase reference and provide a quantum layer of security and robustness against dephasing noise, fulfilling the stringent requirements of blockchain technology. In addition, we analyze the performance tradeoff of the CQ-BFT protocol in terms of the three pillars of blockchain—i.e., security, scalability, and decentralization. The human-centric Metaverse could leverage high degrees of security, noise resilience, and fault tolerance of the CQ-BFT protocol to enhance its underlying network infrastructure. This protocol leads to more robust and immersive virtual environments that prioritize the needs and experiences of Metaverse users.}
}


@article{DBLP:journals/jsac/LiuFWCP24,
	author = {Lei Liu and
                  Jie Feng and
                  Celimuge Wu and
                  Chen Chen and
                  Qingqi Pei},
	title = {Reputation Management for Consensus Mechanism in Vehicular Edge Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {919--932},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345382},
	doi = {10.1109/JSAC.2023.3345382},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuFWCP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse is a visually rich virtual space in which users can interact with each other. By introducing metaverse into vehicular networks, vehicular metaverse can provide users real-time immersive experiences based on augmented technologies. Vehicular edge computing is a desirable approach to support computation-intensive vehicular metaverse services by network resource collaboration. User collaboration needs to reach a consensus on perception information, operation control and so on to realize user autonomy. However, the existing consensus algorithms often require computational proof or frequent communication, making them unsuitable for dynamically changing vehicular edge metaverse with low latency and energy restrictions. In this paper, we have proposed a reputation model maintained in the vehicular edge metaverse to score the vehicles, so the vehicles with a high reputation can be selected to participate in practical Byzantine fault tolerant (PBFT) consensus, which improves the probability of success and credibility of consensus without increasing the number of participating vehicles. Meanwhile, an optimization problem is formulated for each vehicle to allocate its computation and communication resources to reach a PBFT consensus. Also, the optimized communication time interval of each phase in the PBFT consensus can be used as a reference for setting the agreed upper time, which reduces the waiting time of vehicles and the probability of re-consensus. Simulation results have demonstrated that the proposed scheme effectively achieves PBFT information consensus with lower latency and energy consumption, and thus is more scalable and efficient.}
}


@article{DBLP:journals/jsac/YangCWWWY24,
	author = {Zhigang Yang and
                  Xia Cao and
                  Honggang Wang and
                  Dapeng Wu and
                  Ruyan Wang and
                  Boran Yang},
	title = {{VRIL:} {A} Tuple Frequency-Based Identity Privacy Protection Framework
                  for Metaverse},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {933--947},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345425},
	doi = {10.1109/JSAC.2023.3345425},
	timestamp = {Wed, 05 Jun 2024 17:31:54 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YangCWWWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The metaverse is a human-centric beyond-reality virtual world, in which people use virtual identities to live, work, and socialize. Due to the openness and sharing of metaverse applications, the virtual-real identity link (VRIL) may cause uncertainties and unpredictable risks. At present, the research on VRIL risks is still in its infancy and VRIL risk predictions lack a comprehensive theoretical system and methodological tool. In this paper, we first construct a VRIL attack model, according to which an attacker can link a user’s real and virtual identities together using the information observed in the real and virtual worlds. Then we propose the tuple frequency-based VRIL prediction (TupPre) model and discover the population distribution, recursive hypergeometric (RH) distribution, and approximate binomial distribution of the tuple frequency (i.e., the occurrence times of attribute value combinations) given incomplete information. Focusing on the tuple frequency estimation error in biased samples, we introduce attribute value correlation knowledge to improve the prediction performance. The experimental results on generated and real-world datasets show that the TupPre model has excellent performance, with a mean area under the curves (AUCs) of 0.86 to 0.98 on these datasets, and it performs even more superior with certain background knowledge (mean AUC 0.95~0.98). The discovered basic distribution rules of the tuple frequency and the proposed quantitative analysis method for metaverse VRIL risk predictions construct the foundation of the identity privacy framework for the metaverse.}
}


@article{DBLP:journals/jsac/YuLGMK24,
	author = {Yinbo Yu and
                  Jiajia Liu and
                  Hongzhi Guo and
                  Bomin Mao and
                  Nei Kato},
	title = {A Spatiotemporal Backdoor Attack Against Behavior-Oriented Decision
                  Makers in Metaverse: From Perspective of Autonomous Driving},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {948--962},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345379},
	doi = {10.1109/JSAC.2023.3345379},
	timestamp = {Mon, 15 Apr 2024 08:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YuLGMK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Behavior-oriented decision-makers are critical components in generating intelligent decisions for user virtual interactions in metaverse. In this work, we study the efficiency and security of behavior-oriented decision-makers in metaverse from perspective of autonomous driving (AD), where modeling human uncertain driving behaviors is the key factor of their performance. We first explore the ability of different deep-neural-network-based decision-makers used in deep reinforcement learning for efficient autonomous vehicle control, and then we propose a novel neural backdoor attack against them using spatiotemporal driving behaviors, rather than an immediate state. With our attack, the adversary acts as a normal driver and can trigger attacks by driving his vehicle following specific spatiotemporal behaviors. Extensive experiments show that our proposed backdoor attack can achieve high stealthiness and effectiveness (less than 1% clean performance variance rate and more than 98% attack success rate) on behavior-oriented decision-makers, and is sustainable against existing advanced defenses.}
}


@article{DBLP:journals/jsac/ZhangZZFNZ24,
	author = {Chuan Zhang and
                  Mingyang Zhao and
                  Weiting Zhang and
                  Qing Fan and
                  Jianbing Ni and
                  Liehuang Zhu},
	title = {Privacy-Preserving Identity-Based Data Rights Governance for Blockchain-Empowered
                  Human-Centric Metaverse Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {963--977},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345392},
	doi = {10.1109/JSAC.2023.3345392},
	timestamp = {Fri, 07 Feb 2025 10:18:47 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZZFNZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse provides human-centric immersive communication experiences where humans can teleport across different virtual landscapes and build real-time communications via digital identities with others in the same landscape. Despite great benefits, a natural question in human-centric metaverse communications is how to secure digital content among humans. In this regard, blockchain has been widely applied due to its distinct features (e.g., decentralization, transparency, and immutability). Unfortunately, the inherent properties of the blockchain also hinder humans from further deploying preferences to flexibly govern the digital content (i.e., who can read and who can edit), limiting human-centric communication abilities. Some redactable blockchain-based solutions have been proposed, but most of them suffer from the issues of data and preference leakage. To address the issues, we propose a privacy-preserving identity-based data governance (IDRG) scheme for blockchain-empowered human-centric metaverse communications. Combining digital identities, IDRG cryptographically allows humans to govern readability and editability with the right downward compatibility (i.e., humans with editability are endowed with readability) while protecting policy privacy. Specifically, IDRG leverages the polynomial function technique to break through the bottleneck of the traditional identity-based encryption technique (i.e., a policy only contains a user) to achieve a policy for multiple users. Subsequently, the optimized policies are utilized to enrich chameleon hash-based redactable blockchains for comprehensive rights governance. Further, IDRG supports user accountability and revocation by combining the proxy re-encryption technique. Security analysis proves the security of IDRG under the chosen-ciphertext attack. Experiments on the FISCO blockchain platform demonstrate that IDRG requires approximately 0.1 s to process an encryption request, 0.01 s for a reading request, and 1 s for an editing request. Overall, IDRG achieves a $3\\times $ reduction in computational costs compared with state-of-the-art solutions.}
}


@article{DBLP:journals/jsac/ChaiCLWHZW24,
	author = {Baili Chai and
                  Jinyu Chen and
                  Zhenxiao Luo and
                  Zelong Wang and
                  Miao Hu and
                  Yipeng Zhou and
                  Di Wu},
	title = {{SDSR:} Optimizing Metaverse Video Streaming via Saliency-Driven Dynamic
                  Super-Resolution},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {978--989},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345418},
	doi = {10.1109/JSAC.2023.3345418},
	timestamp = {Thu, 13 Feb 2025 15:46:14 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChaiCLWHZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse (especially 360-degree) video streaming allows broadcasting virtual events in the metaverse to a broad audience. To reduce the huge bandwidth consumption, quite a few super-resolution (SR)-enhanced 360-degree video streaming systems have been proposed. However, there is very limited work to investigate how the granularity of SR model affects the system performance, and how to choose a proper SR model for different video contents under diverse environmental conditions. In this paper, we first conduct a dedicated measurement study to unveil the impact of different granularities of SR models. It is found that the scene of a video largely determines the effectiveness of SR models in different granularities. Based on our observations, we propose a novel 360-degree video streaming framework with saliency-driven dynamic super-resolution, called SDSR. To maximize user QoE, we formally formulate an optimization problem and adopt the model predictive control (MPC) theory for bitrate adaptation and SR model selection. To improve the effectiveness of SR model, we leverage the saliency information, which well reflects users’ view interests, for model training. In addition, we reuse an SR model for similar chunks based on temporal redundancy of a video. Finally, we conduct extensive experiments on real traces and the results show that SDSR outperforms the state-of-the-art algorithms with an improvement up to 32.78% in terms of the average QoE.}
}


@article{DBLP:journals/jsac/HuJXCDL24,
	author = {Jingyang Hu and
                  Hongbo Jiang and
                  Zhu Xiao and
                  Siyu Chen and
                  Schahram Dustdar and
                  Jiangchuan Liu},
	title = {HeadTrack: Real-Time Human-Computer Interaction via Wireless Earphones},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {990--1002},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345381},
	doi = {10.1109/JSAC.2023.3345381},
	timestamp = {Mon, 15 Apr 2024 08:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuJXCDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate head movement tracking is crucial for virtual reality and Metaverse in ubiquitous human-computer interaction (HCI) applications. Existing works for head tracking with wearable VR kits and wireless signals require expensive devices and heavy algorithmic processing. To resolve this problem, we propose HeadTrack, a low-cost, high-precision head motion tracking system that uses commercially available wireless earphones to capture the user’s head motion in real-time. HeadTrack uses smartphones as ‘sound anchors’ and emits inaudible chirps picked up by the user’s wireless earphones. By measuring the time-of-flight of these signals from the smartphone to each microphone on the earphone, we can deduce the user’s face orientation and distance relative to the smartphone, enabling us to accurately track the user’s head movement. To realize HeadTrack, we use the cross-correlation method to optimize the Frequency Modulated Continuous Wave (FMCW) based acoustic ranging method, which solves the problem of insufficient wireless earphone bandwidth. Moreover, we solve the problems of asynchronous startup time between devices and the existence of sampling frequency offset. We conduct excessive experiments in real scenarios, and the results prove that HeadTrack can continuously track the direction of the user’s head, with an average error under 6.3° in pitch and 4.9° in yaw.}
}


@article{DBLP:journals/jsac/HuangBZQSYZ24,
	author = {Yakun Huang and
                  Boyuan Bai and
                  Yuanwei Zhu and
                  Xiuquan Qiao and
                  Xiang Su and
                  Lei Yang and
                  Ping Zhang},
	title = {ISCom: Interest-Aware Semantic Communication Scheme for Point Cloud
                  Video Streaming on Metaverse {XR} Devices},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {4},
	pages = {1003--1021},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2023.3345430},
	doi = {10.1109/JSAC.2023.3345430},
	timestamp = {Mon, 15 Apr 2024 08:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuangBZQSYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the metaverse era, point cloud video (PCV) streaming on mobile XR devices is pivotal. While most current methods focus on PCV compression from traditional 3-DoF video services, emerging AI techniques extract vital semantic information, producing content resembling the original. However, these are early-stage and computationally intensive. To enhance the inference efficacy of AI-based approaches, accommodate dynamic environments, and facilitate applicability to metaverse XR devices, we present ISCom, an interest-aware semantic communication scheme for lightweight PCV streaming. ISCom is featured with a region-of-interest (ROI) selection module, a lightweight encoder-decoder training module, and a learning-based scheduler to achieve real-time PCV decoding and rendering on resource-constrained devices. ISCom’s dual-stage ROI selection provides significantly reduces data volume according to real-time interest. The lightweight PCV encoder-decoder training is tailored to resource-constrained devices and adapts to the heterogeneous computing capabilities of devices. Furthermore, We provide a deep reinforcement learning (DRL)-based scheduler to select optimal encoder-decoder model for various devices adaptivelly, considering the dynamic network environments and device computing capabilities. Our extensive experiments demonstrate that ISCom outperforms baselines on mobile devices, achieving a minimum rendering frame rate improvement of 10 FPS and up to 22 FPS. Furthermore, our method significantly reduces memory usage by 41.7% compared to the state-of-the-art AITransfer method. These results highlight the effectiveness of ISCom in enabling lightweight PCV streaming and its potential to improve immersive experiences for emerging metaverse application.}
}


@article{DBLP:journals/jsac/GaudenziOPYHL24,
	author = {Riccardo De Gaudenzi and
                  Bj{\"{o}}rn E. Ottersten and
                  Ana I. P{\'{e}}rez{-}Neira and
                  Halim Yanikomeroglu and
                  Thomas Heyn and
                  Stephen M. Lichten},
	title = {Guest Editorial Space Communications New Frontiers: From Near Earth
                  to Deep Space},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1023--1028},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3378585},
	doi = {10.1109/JSAC.2024.3378585},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GaudenziOPYHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The low-Earth orbiting (LEO) satellite constellations in the 90s (such as Iridium and Globalstar), although representing a major technical breakthrough, were not able to achieve the initial goal of complementing the second-generation mobile terrestrial networks due to the rapid worldwide adoption of GSM and other standards. However, the decline of conventional linear television and the persisting need to mitigate the digital divide still affecting billions of people recently generated a renewed interest by private investors for Low-Earth Orbiting (LEO) satellite mega-constellations. The mega-constellations under deployment can provide lower delays versus geostationary (GEO) satellites, broadband access anywhere, anytime leveraging the low-cost series production of small satellites, and more affordable launch solutions. At the end of the last decade, key industrial players realized the potential complementary role satellites can play to extend the 5G terrestrial network coverage over low-density populated areas, oceans, or similar. This has led to great technological developments and a sharp reduction in LEO satellite volume, weight, and, ultimately, manufacturing and launching costs. Also, it has triggered the inclusion of a non terrestrial network (NTN) component in the latest 5G 3GPP standard releases. Yet, there are many technological challenges remaining to ensure that both the quality and cost of the NTN services are comparable to the terrestrial counterpart. This is mainly due to the constraints in satellite payload power, mass, and antenna size. This comes in addition to the stringent power flux density limitations on the ground, in particular in the below 6 GHz satellite bands. The required order of magnitude increase of the effective delivered throughput and service cost reduction can only be achieved by a mix of system architectures and innovative technologies for both the space and ground segments. Space communication systems and technologies will also play a key role in human return to the Moon planned for mid-2020, to prepare for human exploration of Mars in the more distant future and further cosmic exploration. As missions voyage further from Earth, it is important to consider how we can continue to reliably communicate with them and how they will accurately navigate through space when they are so far from home.}
}


@article{DBLP:journals/jsac/HuangCXXHC24,
	author = {Chong Huang and
                  Gaojie Chen and
                  Pei Xiao and
                  Yue Xiao and
                  Zhu Han and
                  Jonathon A. Chambers},
	title = {Joint Offloading and Resource Allocation for Hybrid Cloud and Edge
                  Computing in SAGINs: {A} Decision Assisted Hybrid Action Space Deep
                  Reinforcement Learning Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1029--1043},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365899},
	doi = {10.1109/JSAC.2024.3365899},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuangCXXHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the amalgamation of satellite communications and aerial platforms into space-air-ground integrated network (SAGINs) has emerged as an indispensable area of research for future communications due to the global coverage capacity of low Earth orbit (LEO) satellites and the flexible Deployment of aerial platforms. This paper presents a deep reinforcement learning (DRL)-based approach for the joint optimization of offloading and resource allocation in hybrid cloud and multi-access edge computing (MEC) scenarios within SAGINs. The proposed system considers the presence of multiple satellites, clouds and unmanned aerial vehicles (UAVs). The multiple tasks from ground users are modeled as directed acyclic graphs (DAGs). With the goal of reducing energy consumption and latency in MEC, we propose a novel multi-agent algorithm based on DRL that optimizes both the offloading strategy and the allocation of resources in the MEC infrastructure within SAGIN. A hybrid action algorithm is utilized to address the challenge of hybrid continuous and discrete action space in the proposed problems, and a decision-assisted DRL method is adopted to reduce the impact of unavailable actions in the training process of DRL. Through extensive simulations, the results demonstrate the efficacy of the proposed learning-based scheme, the proposed approach consistently outperforms benchmark schemes, highlighting its superior performance and potential for practical applications.}
}


@article{DBLP:journals/jsac/ChenQSZZ24,
	author = {Geng Chen and
                  Shuhu Qi and
                  Fei Shen and
                  Qingtian Zeng and
                  Yudong Zhang},
	title = {Information-Aware Driven Dynamic {LEO-RAN} Slicing Algorithm Joint
                  With Communication, Computing, and Caching},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1044--1062},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365893},
	doi = {10.1109/JSAC.2024.3365893},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenQSZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of applications with different use cases and service demands for edge network, network slicing is an emerging solution for satisfying service-oriented requirements, while the low earth orbit (LEO) satellite caching-assisted communication has been considered as one of the key elements for effective services. With limited resources at the edge of the radio access network (RAN), it is challenging to take advantage of the LEO content cache to joint allocation of communication, computing and caching space (3C) resources. To this end, we investigate the problem of resource slicing and scheduling of joint 3C resources in RAN edge scenario assisted by LEO content caching. A hierarchical resource slicing framework is proposed for dynamic allocation of multidimensional resources. The optimization variables are relaxed and the constraints are adjusted. The sequential quadratic programming (SQP) iteration algorithm is proposed as theoretical offline baseline. Due to its complex solving process and limited real-time performance, we incorporate Long Short-Term Memory (LSTM) into the Soft Actor-Critic (SAC) algorithm to aware extract the distribution characteristics of historical information and propose the deep reinforcement learning algorithm of LSTM-SAC. Meanwhile, the proportional priority based scheduling algorithm is employed in the intra-slice. Compared to SAC, TD3 and DDPG algorithms, the proposed algorithm is the closest to the theoretical value, improves the objective function by 6.95%, 9.52% and 11.52% respectively, which can significantly improve the system rate while satisfying the service level agreements.}
}


@article{DBLP:journals/jsac/TangXFHCZY24,
	author = {Qinqin Tang and
                  Renchao Xie and
                  Zeru Fang and
                  Tao Huang and
                  Tianjiao Chen and
                  Ran Zhang and
                  F. Richard Yu},
	title = {Joint Service Deployment and Task Scheduling for Satellite Edge Computing:
                  {A} Two-Timescale Hierarchical Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1063--1079},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365889},
	doi = {10.1109/JSAC.2024.3365889},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TangXFHCZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we establish a two-timescale framework for the joint service deployment and task scheduling problem in satellite edge computing networks. We aim to optimize the computing performance of networks with diverse quality-of-service (QoS) guarantees for computing tasks. Specifically, to capture the small-timescale network dynamics and task randomness, we formulate the task scheduling problem as a constrained Markov decision process (CMDP) to minimize the energy consumption, load imbalance and packet loss of networks while ensuring the long-term delay. The Lyapunov technique is employed to deal with the delay constraints. A soft actor-critic (SAC)-based deep reinforcement learning (DRL) framework is designed to learn the stationary scheduling policy. We further explore the significant impact of deploying diverse services on the performance of task scheduling in satellite edge computing. Considering that frequent deployment of services will incur huge deployment overhead, we optimize the service deployment on a larger timescale. The optimization problem is modeled as an integer programming problem to improve the service capability of networks and reduce service deployment costs. A heuristic-based atomic orbital search (AOS) approach is proposed to obtain the superior policy with low complexity. Due to the correlation between the problems of two timescales, a hierarchical solution is constructed to iteratively find the excellent solution. Finally, extensive simulations are conducted to validate the effectiveness and superiority of the proposed scheme.}
}


@article{DBLP:journals/jsac/HanHLCB24,
	author = {Dong{-}Jun Han and
                  Seyyedali Hosseinalipour and
                  David J. Love and
                  Mung Chiang and
                  Christopher G. Brinton},
	title = {Cooperative Federated Learning Over Ground-to-Satellite Integrated
                  Networks: Joint Local Computation and Data Offloading},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1080--1096},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365901},
	doi = {10.1109/JSAC.2024.3365901},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HanHLCB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While network coverage maps continue to expand, many devices located in remote areas remain unconnected to terrestrial communication infrastructures, preventing them from getting access to the associated data-driven services. In this paper, we propose a ground-to-satellite cooperative federated learning (FL) methodology to facilitate machine learning service management over remote regions. Our methodology orchestrates satellite constellations to provide the following key functions during FL: (i) processing data offloaded from ground devices, (ii) aggregating models within device clusters, and (iii) relaying models/data to other satellites via inter-satellite links (ISLs). Due to the limited coverage time of each satellite over a particular remote area, we facilitate satellite transmission of trained models and acquired data to neighboring satellites via ISL, so that the incoming satellite can continue conducting FL for the region. We theoretically analyze the convergence behavior of our algorithm, and develop a training latency minimizer which optimizes over satellite-specific network resources, including the amount of data to be offloaded from ground devices to satellites and satellites’ computation speeds. Through experiments on three datasets, we show that our methodology can significantly speed up the convergence of FL compared with terrestrial-only and other satellite baseline approaches.}
}


@article{DBLP:journals/jsac/ElmahallawyLR24,
	author = {Mohamed Elmahallawy and
                  Tie Luo and
                  Khaled Ramadan},
	title = {Communication-Efficient Federated Learning for {LEO} Constellations
                  Integrated With HAPs Using Hybrid {NOMA-OFDM}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1097--1114},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365885},
	doi = {10.1109/JSAC.2024.3365885},
	timestamp = {Wed, 19 Feb 2025 12:54:38 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ElmahallawyLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Space AI has become increasingly important and sometimes even necessary for government, businesses, and society. An active research topic under this mission is integrating federated learning (FL) with satellite communications (SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively train a machine learning model. However, the special communication environment of SatCom leads to a very slow FL training process up to days and weeks. This paper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO satellites, that (1) utilizes high-altitude platforms (HAPs) as distributed parameter servers ( \\mathcal {PS}\\text{s}\n) to enhance satellite visibility, and (2) introduces non-orthogonal multiple access (NOMA) into LEO to enable fast and bandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a new communication topology that exploits HAPs to bridge satellites among different orbits to mitigate the Doppler shift, and (4) a new FL model aggregation scheme that optimally balances models between different orbits and shells. Moreover, we (5) derive a closed-form expression of the outage probability for satellites in near and far shells, as well as for the entire system. Our extensive simulations have validated the mathematical analysis and demonstrated the superior performance of NomaFedHAP in achieving fast and efficient FL model convergence with high accuracy as compared to the state-of-the-art.}
}


@article{DBLP:journals/jsac/ZhouLZYSC24,
	author = {Yu Zhou and
                  Lei Lei and
                  Xiaohui Zhao and
                  Lei You and
                  Yaohua Sun and
                  Symeon Chatzinotas},
	title = {Decomposition and Meta-DRL Based Multi-Objective Optimization for
                  Asynchronous Federated Learning in 6G-Satellite Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1115--1129},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365902},
	doi = {10.1109/JSAC.2024.3365902},
	timestamp = {Sun, 19 Jan 2025 14:06:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhouLZYSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless-based federated learning (FL), as an emerging distributed learning approach, has been widely studied for 6G systems. When the paradigm shifts from terrestrial to non-terrestrial networks (NTN), FL may need to address several open challenges, e.g., the limited service time of low earth orbit (LEO) satellites, the straggler issue in synchronous FL, and time-efficient uploading and aggregation for massive devices. In this work, we exploit the synergy of LEO and FL for future integrated 6G-satellite systems by taking advantage of ubiquitous wireless access provided by LEO and appealing characteristics of collaborative training and data privacy preservation in FL. The studied LEO-FL framework may need to improve multi-metric performance in practice. Different from most FL works, we simultaneously improve the communication-training efficiency and local training accuracy from a multi-objective optimization (MOO) perspective. To solve the problem, we propose a decomposition and meta-deep reinforcement learning based MOO algorithm for FL (DMMA-FL), aiming at adapting to the dynamic satellite-terrestrial environments, achieving efficient uploading and aggregation, and approaching Pareto optimal sets. Compared to single-objective optimization, heuristics-based, and learning-based MOO algorithms, the effectiveness and advantages of the proposed LEO-FL framework and DMMA-FL algorithm are assessed on MNIST and CIFAR-10 datasets.}
}


@article{DBLP:journals/jsac/ZhangLCSHW24,
	author = {Weicheng Zhang and
                  Yajing Liu and
                  Lingyu Chen and
                  Jianghong Shi and
                  Xuemin Hong and
                  Xianbin Wang},
	title = {Semantically-Disentangled Progressive Image Compression for Deep Space
                  Communications: Exploring the Ultra-Low Rate Regime},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1130--1144},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3369654},
	doi = {10.1109/JSAC.2024.3369654},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangLCSHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While sensing imagery in space missions has broad applications, the growing image resolution and data volume have caused a major challenge due to limited deep space channel capacities. To address this challenge, semantics-aware image compression becomes a promising direction. This paper is motivated to explore lossy compression at the ultra-low rate regime, which is a deviation from the high-fidelity- oriented tradition. Specifically, we propose an ultra-low rate deep image compression (DIC) codec by synthesizing multiple neural computing techniques such as style generative adversarial network (GAN), inverse GAN mapping, and contrastive disentangled representation learning. In addition, a residual-based progressive encoding framework is proposed to enable smooth transitions from the ultra-low rate regime to near- lossless regime. Experiments on the FFHQ and DOTA dataset demonstrate that compared with existing DICs, the proposed DIC can push the minimum rate boundary by about one order of magnitude while preserving the semantic attributes and maintaining a high perception quality. We further elaborate the design considerations for cross-rate-regime progressive DIC. Our study confirm that a semantically disentangled DIC holds the promise to bridge multiple rate regimes.}
}


@article{DBLP:journals/jsac/ZhengNNP24,
	author = {Guhan Zheng and
                  Qiang Ni and
                  Keivan Navaie and
                  Haris Pervaiz},
	title = {Semantic Communication in Satellite-Borne Edge Cloud Network for Computation
                  Offloading},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1145--1158},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365879},
	doi = {10.1109/JSAC.2024.3365879},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengNNP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The low earth orbit (LEO) satellite-borne edge cloud (SEC) and machine learning (ML) based semantic communication (SemCom) are both enabling technologies for 6G systems facilitating computation offloading. Nevertheless, integrating SemCom into the SEC networks for user computation offloading introduces semantic coder updating requirements as well as additional semantic extraction costs. Offloading user computation in SEC networks via SemCom also results in new functional challenges considering, e.g., latency, energy, and privacy. In this paper, we present a novel SemCom-assisted SEC (SemCom-SEC) framework for computation offloading of resource-limited users. We then propose an adaptive pruning-split federated learning (PSFed) method for updating the semantic coder in SemCom-SEC. We further show that the proposed method guarantees training convergence speed and accuracy. This method also improves the privacy of the semantic coder while reducing training delay and energy consumption. In the case of trained semantic coders in service, for the users processing computational tasks, the main objective is to minimise the users’ delay and energy consumption, subject to sustaining users’ privacy and fairness amongst them. This problem is then formulated as an incomplete information mixed integer nonlinear programming (MINLP) problem. A new computational task processing scheduling (CTPS) mechanism is also proposed based on the Rubinstein bargaining game. Simulation results demonstrate the proposed PSFed and game theoretical CTPS mechanism outperforms the baseline solutions reducing delay and energy consumption while enhancing users’ privacy.}
}


@article{DBLP:journals/jsac/GaoLXZY24,
	author = {Ronghao Gao and
                  Yue Li and
                  Yunlai Xu and
                  Qin{-}Yu Zhang and
                  Zhihua Yang},
	title = {Semantic {LTP:} An Age-Optimal Bundle Delivery Mechanism in Space
                  Disruption-Tolerant Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1159--1174},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365872},
	doi = {10.1109/JSAC.2024.3365872},
	timestamp = {Sun, 06 Oct 2024 21:33:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GaoLXZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In long-span space communication, the current Licklider Transmission Protocol (LTP) confronts apparent challenges such as high packet loss rate and huge latency when carrying the bundles in the Disruption Tolerant Networks (DTN). These challenges incur obviously low freshness of satellite telemetry and instruction data with high timeliness requirements since the typical Automatic Repeat reQuest (ARQ) mechanism is exploited in the LTP for reliable transfer. To address this issue, in this paper, we propose an age-driven bundle delivery mechanism called as Semantic LTP (S-LTP) by considering the semantic correlations in the context-dependent data, which has excellent error-tolerant capability by a well-designed Semantic Supplement Hybrid Automatic Repeat reQuest (SS-HARQ), making it with high timeliness. In particular, a novel metric of semantic freshness of data called Age of Semantic Information (AoSI) is proposed to evaluate the timeliness contribution of information at the semantic level. The simulation results indicate that the proposed SS-HARQ scheme performs better in reducing the average AoSI and AoI by 62.24% and 64.52% respectively compared to the conventional LTP-ARQ with Cyclic Redundancy Check (CRC), 6.39% and 27.09% respectively compared to the Semantic Coding HARQ (SCHARQ) with a similarity detection network called Sim32.}
}


@article{DBLP:journals/jsac/ChenYZWZC24,
	author = {Quan Chen and
                  Lei Yang and
                  Yong Zhao and
                  Yi Wang and
                  Haibo Zhou and
                  Xiaoqian Chen},
	title = {Shortest Path in {LEO} Satellite Constellation Networks: An Explicit
                  Analytic Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1175--1187},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365873},
	doi = {10.1109/JSAC.2024.3365873},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenYZWZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Shortest Distance Path (SDP) problem is a critical routing issue in communication networks, particularly in satellite networks. Typically, SDP is solved by graph-based iterative algorithms, while an explicit or analytic approach is challenging. However, considering the orbit dynamics and topology regularity, this paper proposes, for the first time, an explicit analytic phase-based algorithm StepClimb to directly solve the SDP in low-Earth orbit (LEO) satellite networks. Based on the relationship between satellite phase and inter-satellite link distance, the SDP is modeled with the satellite phase, and SDP problem is converted into a total phase offset problem through theoretical derivations. Then StepClimb is derived in two cases, respectively. Monte-Carlo simulations verify StepClimb’s accuracy, which has zero error in the mono-valley case and has less than 0.1% error in the bi-valley case. The algorithm performs better in larger-scale constellations and can save over 99.4% computational cost compared to Dijkstra algorithm. Further, the SDP pattern and features in Starlink constellation are analyzed. The model proves that most inter-plane hops in the SDP occur successively, and the simulations further indicate that these hops prefer satellites in the higher latitude regions.}
}


@article{DBLP:journals/jsac/LiZYGXY24,
	author = {Yuanfeng Li and
                  Qi Zhang and
                  Haipeng Yao and
                  Ran Gao and
                  Xiangjun Xin and
                  F. Richard Yu},
	title = {Stigmergy and Hierarchical Learning for Routing Optimization in Multi-Domain
                  Collaborative Satellite Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1188--1203},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365878},
	doi = {10.1109/JSAC.2024.3365878},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiZYGXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The integration of Software-Defined Networking (SDN) and Artificial Intelligence (AI) presents promising opportunities for managing and optimizing LEO satellite network routing. However, as the scale and coverage of satellite networks continue to expand, challenges are posed to both centralized and distributed architectures in terms of managing network information and coping with routing complexity. To overcome these challenges, leveraging distributed SDN technology, a stigmergy multi-agent hierarchical deep reinforcement learning routing algorithm is proposed in multi-domain collaborative satellite networks. A pheromone-based mechanism is incorporated to facilitate collaboration during independent training, and hierarchical control is employed to decouple the complexity of cross-domain routing decisions. Simulation results demonstrate that our proposed algorithm exhibits good scalability and performance in large-scale satellite networks.}
}


@article{DBLP:journals/jsac/LyuHFLAM24,
	author = {Yifeng Lyu and
                  Han Hu and
                  Rongfei Fan and
                  Zhi Liu and
                  Jianping An and
                  Shiwen Mao},
	title = {Dynamic Routing for Integrated Satellite-Terrestrial Networks: {A}
                  Constrained Multi-Agent Reinforcement Learning Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1204--1218},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365869},
	doi = {10.1109/JSAC.2024.3365869},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LyuHFLAM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The integrated satellite-terrestrial network (ISTN) system has experienced significant growth, offering seamless communication services in remote areas with limited terrestrial infrastructure. However, designing a routing scheme for ISTN is exceedingly difficult, primarily due to the heightened complexity resulting from the inclusion of additional ground stations, along with the requirement to satisfy various constraints related to satellite service quality. To address these challenges, we study packet routing with ground stations and satellites working jointly to transmit packets, while prioritizing fast communication and meeting energy efficiency and packet loss requirements. Specifically, we formulate the problem of packet routing with constraints as a max-min problem using the Lagrange method. Then we propose a novel constrained Multi-Agent reinforcement learning (MARL) dynamic routing algorithm named CMADR, which efficiently balances objective improvement and constraint satisfaction during the updating of policy and Lagrange multipliers. Finally, we conduct extensive experiments and an ablation study using the OneWeb and Telesat mega-constellations. Results demonstrate that CMADR reduces the packet delay by a minimum of 21% and 15%, while meeting stringent energy consumption and packet loss rate constraints, outperforming several baseline algorithms.}
}


@article{DBLP:journals/jsac/MaoZLK24,
	author = {Bomin Mao and
                  Xueming Zhou and
                  Jiajia Liu and
                  Nei Kato},
	title = {On an Intelligent Hierarchical Routing Strategy for Ultra-Dense Free
                  Space Optical Low Earth Orbit Satellite Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1219--1230},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365880},
	doi = {10.1109/JSAC.2024.3365880},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/MaoZLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an essential 6G component, the Low Earth Orbit (LEO) satellite communication has aroused increasing attentions from academia and industry to provide seamless and highly-efficient networking services. However, existing routing strategies are primarily designed for terrestrial networks or small-scale satellite networks, making it inapplicable to future LEO satellite constellations of ultra density, high dynamics, and large scale. Moreover, since Free Space Optical (FSO) communications have been expected for Inter-satellite Links (ISLs) and the number of constructed FSO ISLs depends on the Acquisition, Pointing, and Tracking (APT) terminals and geometric visibilities, the routing algorithm needs to be adaptive. To address these issues, this paper considers the dual-layer network architecture composed of Medium Earth Orbit (MEO) satellites and LEO satellites, where the regional network division is adopted for the LEO satellite layer to alleviate the complexity and improve the routing efficiency. Then, a multi-objective reinforcement learning-based routing strategy with local information considered is proposed to meet the differentiated Quality of Service (QoS) requirements of diversified terrestrial applications. A cooperative mechanism is also designed to address the conflicts caused by the routing design for different applications. The simulation results demonstrate the proposal is applicable to varying numbers of APT terminals and outperforms benchmark algorithms in terms of diversified QoS metrics.}
}


@article{DBLP:journals/jsac/WangKA24,
	author = {Ruibo Wang and
                  Mustafa A. Kishk and
                  Mohamed{-}Slim Alouini},
	title = {Ultra Reliable Low Latency Routing in {LEO} Satellite Constellations:
                  {A} Stochastic Geometry Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1231--1245},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365884},
	doi = {10.1109/JSAC.2024.3365884},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangKA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, LEO satellite constellations have become envisioned as a core component of the next-generation wireless communication networks. The successive establishment of mega satellite constellations has triggered further demands for satellite communication advanced features: high reliability and low latency. In this article, we first establish a multi-objective optimization problem that simultaneously maximizes reliability and minimizes latency, then we solve it by two methods. According to the optimal solution, ideal upper bounds for reliability and latency performance of LEO satellite routing can be derived. Next, we design an algorithm for relay satellite subset selection, which can approach the ideal upper bounds in terms of performance. Furthermore, we derive analytical expressions for satellite availability, coverage probability, and latency under the stochastic geometry (SG) framework, and the accuracy is verified by Monte Carlo simulation. In the numerical results, we study the routing performance of three existing mega constellations and the impact of different constellation parameter configurations on performance. By comparing with existing routing strategies, we demonstrate the advantages of our proposed routing strategy and extend the scope of our research.}
}


@article{DBLP:journals/jsac/BhandariVC24,
	author = {Sovit Bhandari and
                  Thang X. Vu and
                  Symeon Chatzinotas},
	title = {User-Centric Flexible Resource Management Framework for {LEO} Satellites
                  With Fully Regenerative Payload},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1246--1261},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365883},
	doi = {10.1109/JSAC.2024.3365883},
	timestamp = {Sat, 08 Jun 2024 13:14:28 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/BhandariVC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The regenerative capabilities of next-generation satellite systems offer a novel approach to design low earth orbit (LEO) satellite communication systems, enabling full flexibility in bandwidth and spot beam management, power control, and onboard data processing. These advancements allow the implementation of intelligent spatial multiplexing techniques, addressing the ever-increasing demand for future broadband data traffic. Existing satellite resource management solutions, however, do not fully exploit these capabilities. To address this issue, a novel framework called flexible resource management algorithm for LEO satellites (FLARE-LEO) is proposed to jointly design bandwidth, power, and spot beam coverage optimized for the geographic distribution of users. It incorporates multi-spot beam multicasting, spatial multiplexing, caching, and handover (HO). In particular, the spot beam coverage is optimized by using the unsupervised K-means algorithm applied to the realistic geographical user demands, followed by a proposed successive convex approximation (SCA)-based iterative algorithm for optimizing the radio resources. Furthermore, we propose two joint transmission architectures during the HO period, which jointly estimate the downlink channel state information (CSI) using deep learning and optimize the transmit power of the LEOs involved in the HO process to improve the overall system throughput. Simulations demonstrate superior performance in terms of delivery time reduction of the proposed algorithm over the existing solutions.}
}


@article{DBLP:journals/jsac/HassanPTSHH24,
	author = {Sheikh Salman Hassan and
                  Yu Min Park and
                  Yan Kyaw Tun and
                  Walid Saad and
                  Zhu Han and
                  Choong Seon Hong},
	title = {SpaceRIS: {LEO} Satellite Coverage Maximization in 6G Sub-THz Networks
                  by {MAPPO} {DRL} and Whale Optimization},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1262--1278},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3369665},
	doi = {10.1109/JSAC.2024.3369665},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HassanPTSHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Satellite systems face a significant challenge in effectively utilizing limited communication resources to meet the demands of ground network traffic, characterized by asymmetrical spatial distribution and time-varying characteristics. Moreover, the coverage range and signal transmission distance of low Earth orbit (LEO) satellites are restricted by notable propagation attenuation, molecular absorption, and space losses in sub-terahertz (THz) frequencies. This paper introduces a novel approach to maximize LEO satellite coverage by leveraging reconfigurable intelligent surface (RIS) within 6G sub-THz networks. Optimization objectives include improving end-to-end (E2E) data rate, optimizing satellite-remote user equipment (RUE) associations, data packet routing within satellite constellations, RIS phase shift, and ground base station (GBS) transmit power (i.e., active beamforming). The formulated joint optimization problem poses significant challenges because of its time-varying environment, non-convex characteristics, and NP-hard complexity. To address these challenges, we propose a block coordinate descent (BCD) algorithm that integrates balanced K-means clustering, multi-agent proximal policy optimization (MAPPO) deep reinforcement learning (DRL), and whale optimization algorithm (WOA) techniques. The performance of the proposed approach is demonstrated through comprehensive simulation results, demonstrating its superiority over existing baseline methods in the literature.}
}


@article{DBLP:journals/jsac/LeiWLHZWC24,
	author = {Lei Lei and
                  Anyue Wang and
                  Eva Lagunas and
                  Xin Hu and
                  Zhengquan Zhang and
                  Zhiqiang Wei and
                  Symeon Chatzinotas},
	title = {Spatial-Temporal Resource Optimization for Uneven-Traffic {LEO} Satellite
                  Systems: Beam Pattern Selection and User Scheduling},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1279--1291},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3383445},
	doi = {10.1109/JSAC.2024.3383445},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LeiWLHZWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the commercial deployment of low earth orbit (LEO) satellites, the future integrated 6G-satellite system represents an excellent solution for ubiquitous connectivity and high-throughput data service to massive users. Due to the heterogeneity of users’ traffic profiles, uneven traffic distribution among beams or users often occurs in LEO satellite systems. Conventional satellite payloads with fixed beam radiation patterns may result in large gaps between requested and allocated capacity. The advances of flexible satellite payloads with dynamic beamforming capabilities enable spot beams to adjust their coverage and adaptively schedule users, thus offering spatial-temporal domain flexibility. Motivated by this, as an early attempt, we investigate how adaptive beam patterns with flexible user scheduling schemes can help alleviate mismatches of requested-transmitted data in uneven-traffic and full-frequency reuse LEO systems. We formulate an optimization problem to jointly determine beam patterns, power allocation, user-LEO association, and user-slot scheduling. The problem is identified as mixed-integer nonconvex programming. We propose an efficient iterative algorithm to solve the problem by first determining beam patterns and user associations at the frame scale, followed by optimizing power allocation and user scheduling at the timeslot scale. The four-decision components are iteratively updated to improve the overall performance. Numerical results demonstrate the benefits brought by adaptive beam patterns and their effectiveness in reducing the mismatch effect in uneven-traffic LEO systems.}
}


@article{DBLP:journals/jsac/GomezVilardeboMNQ24,
	author = {Jes{\'{u}}s G{\'{o}}mez{-}Vilardeb{\'{o}} and
                  Xavier Mestre and
                  Monica Navarro and
                  Jorge Quintanilla},
	title = {On Noncoherent {FSK} Reception With Doppler Frequency Uncertainty
                  for Space Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1292--1303},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365881},
	doi = {10.1109/JSAC.2024.3365881},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GomezVilardeboMNQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies the mutual information for a general form of orthogonal M-ary frequency-shift keying (MFSK) modulations with non-coherent detection and Doppler frequency uncertainty at the receiver. The signal model includes as particular cases classical MFSK and special MFSK modulations, the later has been used in space communications for reporting spacecraft status and events during critical phases. The optimal code rates that minimize the energy-per-bit to noise power spectral density ratio required for reliable communications are studied. In addition, optimal and suboptimal metrics for soft-decoders are proposed for non-fading channels with or without average signal and noise power estimation and used to evaluate the performance of LDPC codes.}
}


@article{DBLP:journals/jsac/ZahrCFMV24,
	author = {Ayman Zahr and
                  Giulio Colavolpe and
                  Tommaso Foggi and
                  Bal{\'{a}}zs Matuz and
                  Armando Vannucci},
	title = {An Information-Theoretic Comparison Between Coherent and {IM/DD} Transmissions
                  for Free Space Optical Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1304--1315},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365898},
	doi = {10.1109/JSAC.2024.3365898},
	timestamp = {Sat, 08 Jun 2024 13:14:28 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZahrCFMV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the performance of free-space optical communication systems in the presence of atmospheric turbulence to assess the advantages that a coherent communication system can bring with respect to a conventional intensity modulation and direct detection (IM/DD) system. The perspective is an information-theoretic one, hence we evaluate the mutual information and the corresponding outage probability of both channels, with various traditional symbol constellations, as a pragmatic approximation to the capacity, or to the outage capacity, of those channels. In addition, we analyze non-uniform symbol constellations to evaluate the possible shaping gain that can be achieved under different channel conditions. We propose a method to quantify the gain that the coherent solution can achieve, in terms of signal-to-noise ratio (SNR), so that it can be compared, on a techno-economical basis, against the higher cost that it implies.}
}


@article{DBLP:journals/jsac/WangYDZ24,
	author = {Jie Wang and
                  Shenghao Yang and
                  Yanyan Dong and
                  Yiheng Zhang},
	title = {On Achievable Rates of Line Networks With Generalized Batched Network
                  Coding},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1316--1328},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365900},
	doi = {10.1109/JSAC.2024.3365900},
	timestamp = {Tue, 23 Jul 2024 08:22:33 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangYDZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To better understand the wireless network design with a large number of hops, we investigate a line network formed by general discrete memoryless channels (DMCs), which may not be identical. Our focus lies on Generalized Batched Network Coding (GBNC) that encompasses most existing schemes as special cases and achieves the min-cut upper bounds as the parameters batch size and inner block length tend to infinity. The inner blocklength of GBNC provides upper bounds on the required latency and buffer size at intermediate network nodes. By employing a “bottleneck status” technique, we derive new upper bounds on the achievable rates of GBNC. These bounds surpass the min-cut bound for large network lengths when the inner blocklength and batch size are small. For line networks of canonical channels, certain upper bounds hold even with relaxed inner blocklength constraints. Additionally, we employ a “channel reduction” technique to generalize the existing achievability results for line networks with identical DMCs to networks with non-identical DMCs. For line networks with packet erasure channels, we make refinement in both the upper bound and the coding scheme, and showcase their proximity through numerical evaluations.}
}


@article{DBLP:journals/jsac/Choi24,
	author = {Chang{-}Sik Choi},
	title = {Analysis of a Delay-Tolerant Data Harvest Architecture Leveraging
                  Low Earth Orbit Satellite Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1329--1343},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365871},
	doi = {10.1109/JSAC.2024.3365871},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/Choi24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reaching all regions of Earth, low Earth orbit (LEO) satellites can harvest delay-tolerant data from remotely located users on Earth without ground infrastructure. This work aims to assess a data harvest network architecture where users generate data and LEO satellites harvest data from users when passing by. By developing a novel stochastic geometry Cox point process model that simultaneously generates orbits and the motion of LEO satellite harvesters on them, we analyze key performance indices of such a network by deriving the following: (i) the average fraction of time that the typical user is served by LEO satellite harvesters, (ii) the average amount of data uploaded per each satellite pass, (iii) the maximum harvesting capacity of the proposed network model, and (iv) the delay distribution in the proposed network. These key metrics are given as functions of key network variables such as \\lambda the mean number of orbits and \\mu the mean number of satellites per orbit. Providing rich comprehensive analytical results and practical interpretations of these results, this work assesses the potential of the delay-tolerant use of LEO satellites and also serves as a versatile framework to analyze, design, and optimize delay-tolerant LEO satellite networks.}
}


@article{DBLP:journals/jsac/WangLYXSZYB24,
	author = {Ruhai Wang and
                  Xingya Liu and
                  Lei Yang and
                  Yuanrong Xi and
                  Mauro De Sanctis and
                  Kanglian Zhao and
                  Hong Yang and
                  Scott C. Burleigh},
	title = {A Study of {DTN} for Reliable Data Delivery From Space Station to
                  Ground Station},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1344--1358},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365876},
	doi = {10.1109/JSAC.2024.3365876},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangLYXSZYB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Delay/disruption-tolerant networking (DTN) is a networking technology conceived to manage opportunistic connections with no consistent end-to-end link connectivity which is common in both terrestrial and space communication environments. DTN is recognized as a baseline technology for implementing deep-space networks. Considered as the primary transport protocol of DTN in space, Licklider transmission protocol (LTP) is expected to provide reliable data delivery service in a challenging networking environment regardless of presence of random link disruptions and/or extremely long propagation delays. The National Aeronautics and Space Administration (NASA) has implemented the use of DTN protocols on the International Space Station (ISS) for data delivery to the earth ground station. However, little work has been done in studying the performance of LTP for reliable data/file delivery in such a communication environment, especially in presence of link disruption. There is a lack of a solid performance evaluation of LTP for its use in the space station communications. In this paper, an analytical framework is presented to evaluate the performance of LTP for reliable file delivery between the space station and the ground stations with a focus on the effect of link disruption, which may occur either over the downlink or over the uplink. The effect of data loss due to channel error is also integrated. Realistic data block transmission experiments using a PC-based experimental infrastructure are conducted to validate the analytical models.}
}


@article{DBLP:journals/jsac/TorgersonCDS24,
	author = {Leigh Torgerson and
                  Vinton G. Cerf and
                  Sky U. DeBaun and
                  Larissa C. Suzuki},
	title = {Space System Internetworking: The Foundational Role of Delay and Disruption-Tolerant
                  Networking},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1359--1370},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365896},
	doi = {10.1109/JSAC.2024.3365896},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TorgersonCDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As humanity’s reach in space exploration extends beyond Earth’s orbit, the demand for robust and efficient communication systems intensifies. The traditional paradigm of isolated missions has given way to a complex network of diverse spacecraft engaged in terrestrial research, lunar exploration, and the provision of essential satellite services. Yet, the limitations of current spacecraft communication technology, which predominantly rely on individual spacecraft connections, are becoming increasingly apparent. These systems grapple with issues of scalability, collaboration, automation, and reliability. This paper addresses these challenges by exploring the development of more sophisticated systems designed to meet the evolving demands of space exploration. It delves into the specifics of the Interplanetary Overlay Network (ION) implementation of Delay and Disruption Tolerant Networking (DTN), a comprehensive software system that accommodates a variety of applications, protocols, and Convergence Layer Adapters (CLAs). The paper also forecasts the future of DTN implementation, highlighting key developments and advancements anticipated between 2023 and 2029. These advancements are expected to enhance the functionality and reliability of DTN-based systems.}
}


@article{DBLP:journals/jsac/TorrensPJ24,
	author = {Sergi Aliaga Torrens and
                  Vitaly Petrov and
                  Josep Miquel Jornet},
	title = {Modeling Interference From Millimeter Wave and Terahertz Bands Cross-Links
                  in Low Earth Orbit Satellite Networks for 6G and Beyond},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1371--1386},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365894},
	doi = {10.1109/JSAC.2024.3365894},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TorrensPJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-rate satellite communications among hundreds and even thousands of satellites deployed at low-Earth orbits (LEO) will be an important element of the forthcoming sixth-generation (6G) of wireless systems beyond 2030. With millimeter wave communications (mmWave, ≈GHz–100GHz) completely integrated into 5G terrestrial networks, exploration of its potential, along with sub-terahertz (sub-THz, 100GHz–300GHz), and even THz (300GHz–3THz) frequencies, is underway for space-based networks. However, the interference problem between LEO mmWave/THz satellite cross-links in the same or different constellations is undeservedly forgotten. This article presents a comprehensive mathematical framework for modeling directional interference in all key possible scenario geometries. The framework description is followed by an in-depth numerical study on the impact of cross-link interference on various performance indicators, where the delivered analytical results are cross-verified via computer simulations. The study reveals that, while highly directional mmWave and, especially, THz beams minimize interference in many cases, there are numerous practical configurations where the impact of cross-link interference cannot be neglected and must be accounted for.}
}


@article{DBLP:journals/jsac/LiuDWPFZNL24,
	author = {Yalin Liu and
                  Hong{-}Ning Dai and
                  Qubeijian Wang and
                  Om Jee Pandey and
                  Yaru Fu and
                  Ning Zhang and
                  Dusit Niyato and
                  Chi Chung Lee},
	title = {Space-Air-Ground Integrated Networks: Spherical Stochastic Geometry-Based
                  Uplink Connectivity Analysis},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1387--1402},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365891},
	doi = {10.1109/JSAC.2024.3365891},
	timestamp = {Mon, 22 Jul 2024 08:24:23 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuDWPFZNL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By integrating the merits of aerial, terrestrial, and satellite communications, the space-air-ground integrated network (SAGIN) is an emerging solution that can provide massive access, seamless coverage, and reliable transmissions for global-range applications. In SAGINs, the uplink connectivity from ground users (GUs) to the satellite is essential because it ensures global-range data collections and interactions, thereby paving the technical foundation for practical implementations of SAGINs. In this article, we aim to establish an accurate analytical model for the uplink connectivity of SAGINs in consideration of the global distributions of both GUs and aerial vehicles (AVs). Particularly, we investigate the uplink path connectivity of SAGINs, which refers to the probability of establishing the end-to-end path from GUs to the satellite with or without AV relays. However, such an investigation on SAGINs is challenging because all GUs and AVs are approximately distributed on a spherical surface (instead of the horizontal surface), resulting in the complexity of network modeling. To address this challenge, this paper presents a new analytical approach based on spherical stochastic geometry. Based on this approach, we derive the analytical expression of the path connectivity in SAGINs. Extensive simulations confirm the accuracy of the analytical model.}
}


@article{DBLP:journals/jsac/KwonSCLW24,
	author = {Girim Kwon and
                  Wonjae Shin and
                  Andrea Conti and
                  William C. Lindsey and
                  Moe Z. Win},
	title = {Access-Backhaul Strategy via gNB Cooperation for Integrated Terrestrial-Satellite
                  Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1403--1419},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365877},
	doi = {10.1109/JSAC.2024.3365877},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KwonSCLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrated terrestrial-satellite networks (ITSNs) play an essential role in providing global and ubiquitous connectivity for next generation networks. Spectral efficiency of ITSNs depends on their integrated architecture and the operational strategies, including interference management and resource allocation. This paper proposes an efficient integrated access and backhaul (IAB) architecture for terrestrial-satellite networks considering both uplink (UL) and downlink (DL) communications. We aim to integrate terrestrial access and satellite backhaul networks by developing a novel optimization framework for their joint operation. In particular, in-band access-backhaul transmission is considered for high spectral efficiency, where a reverse time division duplexing is used to prevent both self-interference and interference between access links and backhaul links. In addition, cooperation among gNodeB is taken into account to overcome harsh propagation conditions such as blockage effects and severe pathloss. A framework for joint optimization of cooperative beamforming and resource allocation is developed to maximize the UL-DL rate region of the in-band IAB. The proposed architecture is verified using the 3rd Generation Partnership Project (3GPP) channel models. Numerical results show that the proposed architecture significantly outperforms the classical out-of-band backhauling while approaching an outer bound of the UL-DL rate region.}
}


@article{DBLP:journals/jsac/YuanHZSY24,
	author = {Afang Yuan and
                  Zhouyong Hu and
                  Qinyu Zhang and
                  Zhili Sun and
                  Zhihua Yang},
	title = {Toward the Age in Cislunar Communication: An AoI-Optimal Multi-Relay
                  Constellation With Heterogeneous Orbits},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1420--1435},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365892},
	doi = {10.1109/JSAC.2024.3365892},
	timestamp = {Sun, 06 Oct 2024 21:33:56 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YuanHZSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of massive explorations on Lunar Far-side Surface (LFS), deployments of scientific infrastructures have drawn substantial attention with the aids of relay satellites for the moon, i.e., China’s “Queqiao”, which allows real-time reporting for current status information from the landing equipment and space vehicles. Without suitable constellation with well-designed scheduling scheme, it would be very difficult to get timely information if depending only on single Halo relay satellite due to large coverage gap and limited energy budget for the communication links. In this paper, we design a hybrid circular-Halo orbital multi-relay constellation system for the LFS communication by minimizing the average per-device Age of Information (AoI) of users on the earth. In particular, we develop an age-optimal scheduling strategy with constellation design for accessing different relay satellite of constellation by solving a Constrained Markov Decision Process (CMDP) optimization problem to significantly reduce the average coverage gap in LFS area. Simulation results show that the average per-device AoI of the proposed scheduling algorithm with the well-designed constellation could achieve 16.20% less in time than that of single Halo satellite relay system compared with typical algorithms.}
}


@article{DBLP:journals/jsac/ChenWYZ24,
	author = {Guoquan Chen and
                  Shaohua Wu and
                  Junhua You and
                  Qinyu Zhang},
	title = {Communication-Navigation Integrated Satellite Constellation for Lunar
                  Exploration: Frozen-Orbit-Based HyInc Walker},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1436--1452},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365888},
	doi = {10.1109/JSAC.2024.3365888},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenWYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep space communication systems play a key role in human endeavors for lunar basing, Mars, and further cosmic exploration. In pursuit of establishing the Moon as a deep space Internet portal for future human exploration, a lunar communication and navigation integrated (CNI) satellite constellation design is intended into consideration. Based on Fibonacci lattice virtual observation point model, featuring better uniformity and stochasticity, we derive objectives related to access coverage, power, quadruple coverage, and geometric dilution of precision (GDOP), together with multiple multi-objective optimization problems (MOPs) combined with Earth-Moon difference analysis to explore better utilization of overall resources in the lunar integrated constellation. The pareto model, non-dominated sorting genetic algorithm-II (NSGA-II), and the construction of the constellation system are incorporated into the solution to pursue a higher guiding value. In particular, inspired by the lunar frozen orbit (LFO), the hybrid inclination (HyInc) Walker configuration is proposed with theoretical validation and simulation evaluation, showing some superiority over traditional Walker and remains generalizable. Extensive simulation and comprehensive analysis are performed, including the pareto-optimal integrated constellations and the revelation of HyInc Walker’s coverage equalization capability, with the latter being less studied. The entire constellation design process of this work is highly migratory and the proposed perspective of the configuration is enlightening.}
}


@article{DBLP:journals/jsac/AmatettiACVP24,
	author = {Carla Amatetti and
                  Madyan Alsenwi and
                  Houcine Chougrani and
                  Alessandro Vanelli{-}Coralli and
                  Maria Rita Palattella},
	title = {A Novel Twofold Approach to Enhance NB-IoT {MAC} Procedure in {NTN}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1453--1464},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365868},
	doi = {10.1109/JSAC.2024.3365868},
	timestamp = {Sat, 08 Jun 2024 13:14:28 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/AmatettiACVP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Through the transition from 5G to 6G, a significant rise in the number of Internet of Things (IoT) devices is anticipated, enabling pervasive and uninterrupted connectivity for several applications, in different verticals. Coping with the substantial influx of IoT devices and fulfilling the high capacity demands of different IoT technologies, such as NB-IoT, will necessitate the involvement of Non-Terrestrial Networks (NTNs), which will serve as crucial complements to terrestrial systems, enhancing the availability, resilience, and coverage of the network and will guarantee cost/benefit for some services and will fully satisfy some key requirements. Nevertheless, a primary obstacle to be faced when integrating IoT terrestrial communication systems in NTN, in particular with Non-Geostationary satellites, lies in the short visibility time of the flying platform due to its high speed. The latter introduces criticalities in various communication phases, including the Random Access (RA) procedure. In a highly congested scenario, the large Round Trip Delay and a limited visibility window, which varies for each user within the satellite’s coverage area, contribute to reducing the number of users successfully concluding the RA procedure. In this paper, to enhance the percentage of users who successfully conclude the RA, we introduce the concept of Coverage Enhancement Levels in time and a novel backoff mechanism, namely Smart Backoff, that leverages the beam coverage visibility period of individual users to adjust the random backoff interval. The numerical results obtained from our proposed scheme substantiate significant improvements compared to the standard backoff scheme. Specifically, our approach yields an increase of up to 16% per channel in the percentage of users who successfully complete the RA process.}
}


@article{DBLP:journals/jsac/JeonB24,
	author = {Hyerim Jeon and
                  Hoki Baek},
	title = {Military Non-Terrestrial Networks Architecture and Spectrum Sharing
                  Method for Mitigating Jamming Attacks and Multiple Access Interference},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {5},
	pages = {1465--1474},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3365897},
	doi = {10.1109/JSAC.2024.3365897},
	timestamp = {Fri, 31 May 2024 21:05:53 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/JeonB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The non-terrestrial networks (NTN) have the potential to enhance military operations in the network-centric operational environment (NCOE) through improved communication coverage and connectivity. However, existing NTN cannot satisfy NCOE requirements. To satisfy the requirements, we propose the military NTN (M-NTN) architecture and a novel spectrum-sharing method for coexistence between Low Earth Orbit (LEO) beams and high altitude platforms (HAP) or unmanned aerial vehicles (UAV) cells. M-NTN employ slow frequency hopping (SFH) for primary users (PU) and fast frequency hopping (FFH) for secondary users (SU). To the best of our knowledge, there is no previous work where two different systems simultaneously performed FFH and SFH. We design the SFH method of the PU so that SU can easily access PU’s spectrum. Then, we propose two FFH methods, FFHR and A-FFHR, considering SU mobility and mitigating jamming attacks. Mathematical models analyze pulse collision probabilities, showing M-NTN’s effective spectrum-sharing and SU performing FFH, which has less multiple access interference among SUs. A-FFHR is effective owing to high jamming detection probability that we ensure via our proposed jamming detection algorithm. We can determine proper network parameters, such as the slot or frame length, to perform jamming detection algorithms via analysis of numerical results.}
}


@article{DBLP:journals/jsac/MishraLMKKM24,
	author = {Kumar Vijay Mishra and
                  Rodrigo C. de Lamare and
                  Michail Matthaiou and
                  Gerhard Kramer and
                  Edward W. Knightly and
                  Daniel M. Mittleman},
	title = {Guest Editorial: Introduction to the Special Issue on Electromagnetic
                  Signal and Information Theory for Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1475--1478},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3383168},
	doi = {10.1109/JSAC.2024.3383168},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/MishraLMKKM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To accommodate extremely high data rates, provide high reliability, improve coverage, and meet traffic demands in future wireless communication networks, novel technologies have emerged that exploit electromagnetic waves, large multiple-antenna systems, intelligent reflective surfaces, hardware innovations, new network architectures, and higher frequency bands. Considering advances in information theory and devices, fundamental questions arise for system designers on how to develop synergies between theory and practice. Current design and analysis methods are predominantly based on scalar-quantity, far-field, planar-wavefront, monochromatic, and other non-physically consistent assumptions, which can lead to significant mismatches with systems designed based on realistic propagation models.}
}


@article{DBLP:journals/jsac/Dardari24,
	author = {Davide Dardari},
	title = {Reconfigurable Electromagnetic Environments: {A} General Framework},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1479--1493},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389117},
	doi = {10.1109/JSAC.2024.3389117},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/Dardari24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent introduction of the smart radio environments (SREs) paradigm, facilitated by reconfigurable intelligent surfaces (RISs) and large surface antennas, has highlighted the need for physically consistent models and design tools in communication systems that integrate information theory (IT) and electromagnetic (EM) theory. In this paper, we present a comprehensive framework for characterizing and designing programmable EM environments, based on rigorous EM arguments and represented through a linear graph employing matrix operators. The framework enables the determination of the EM transfer function of the system and the channel matrix used in IT, along with their relationship as functions of the programmable parameters. Considering that the mapping of EM quantities into IT signals occurs through the presence of ports in antenna structures, using the framework, we analyze the constraints imposed by the ports in terms of potential degrees-of-freedom (DoF) and establish the fundamental limits on the DoF of large surface antennas. To demonstrate the utility and validity of the framework, we provide examples specifically related to the characterization and optimization of RISs.}
}


@article{DBLP:journals/jsac/SinghM24,
	author = {Amritpal Singh and
                  Thomas L. Marzetta},
	title = {Shannon Theory for Wireless Communication in a Resonant Chamber},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1494--1503},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389121},
	doi = {10.1109/JSAC.2024.3389121},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/SinghM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A closed electromagnetic resonant chamber (RC) is a highly favorable artificial environment for wireless communication. A pair of antennas within the chamber constitutes a two-port network described by an impedance matrix. We analyze communication between the two antennas when the RC has perfectly conducting walls and the impedance matrix is imaginary-valued. The transmit antenna is driven by a current source, and the receive antenna is connected to a load resistor whose voltage is measured by an infinite-impedance amplifier. There are a countably infinite number of poles in the channel, associated with resonance in the RC, which migrate towards the real frequency axis as the load resistance increases. There are two sources of receiver noise: the Johnson noise of the load resistor, and the internal amplifier noise. An application of Shannon theory yields the capacity of the link, subject to bandwidth and power constraints on the transmit current. For a constant transmit power, capacity increases without bound as the load resistance increases. Surprisingly, the capacity-attaining allocation of transmit power versus frequency avoids placing power close to the resonant frequencies.}
}


@article{DBLP:journals/jsac/LiuZWZD24,
	author = {Yongxi Liu and
                  Ming Zhang and
                  Tengjiao Wang and
                  Anxue Zhang and
                  M{\'{e}}rouane Debbah},
	title = {Densifying {MIMO:} Channel Modeling, Physical Constraints, and Performance
                  Evaluation for Holographic Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1504--1518},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389122},
	doi = {10.1109/JSAC.2024.3389122},
	timestamp = {Sun, 21 Jul 2024 18:15:37 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuZWZD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the backbone of the fifth-generation (5G) cellular network, massive multiple-input multiple-output (MIMO) encounters a significant challenge in practical applications: how to deploy a large number of antenna elements within limited spaces. Recently, holographic communication has emerged as a potential solution to this issue. It employs dense antenna arrays and provides a tractable model. Nevertheless, some challenges must be addressed to actualize this innovative concept. One is the mutual coupling among antenna elements within an array. When the element spacing is small, near-field coupling becomes the dominant factor that strongly restricts the array performance. Another is the polarization of electromagnetic waves. As an intrinsic property, it was not fully considered in the previous channel modeling of holographic communication. The third is the lack of real-world experiments to show the potential and possible defects of a holographic communication system. In this paper, we propose an electromagnetic channel model based on the characteristics of electromagnetic waves. This model encompasses the impact of mutual coupling in the transceiver sides and the depolarization in the propagation environment. Furthermore, by approximating an infinite array, the performance restrictions of large-scale dense antenna arrays are also studied theoretically to exploit the potential of the proposed channel. In addition, numerical simulations and a channel measurement experiment are conducted. The findings reveal that within limited spaces, the coupling effect, particularly for element spacing smaller than half of the wavelength, is the primary factor leading to the inflection point for the performance of holographic communications.}
}


@article{DBLP:journals/jsac/YangWHT24,
	author = {Yue Yang and
                  Cheng{-}Xiang Wang and
                  Jie Huang and
                  John S. Thompson},
	title = {Characteristics and Channel Capacity Studies of a Novel 6G Non-Stationary
                  Massive {MIMO} Channel Model Considering Mutual Coupling},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1519--1533},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389113},
	doi = {10.1109/JSAC.2024.3389113},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YangWHT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the sixth generation (6G) wireless communication networks, ultra-massive multiple-input multiple-output (MIMO) communication is one of the most promising technologies. In ultra-massive MIMO channels, the mutual coupling (MC) effect is more obvious when antenna elements are more closely spaced. In this paper, a novel 6G space-time-frequency (STF) non-stationary massive MIMO channel model is proposed, which jointly considers MC, antenna efficiency, and near-field steering vectors of different antenna topologies. As the Shannon capacity theorem is based on the wide-sense stationary (WSS) channel assumption and cannot be applied to non-stationary channels, we propose a novel non-stationary channel capacity calculation method that divides the non-stationary channel into WSS sub-channels. Important statistical properties and channel capacities of the proposed channel model are derived and verified by ultra-massive MIMO channel measurements and data post-processing. The results show that the simulated spatial cross-correlation function (CCF) and channel capacity considering MC and antenna efficiency are closer to measured results. It also shows that antenna topologies have an impact on channel capacities. Furthermore, channel capacities using the proposed novel calculation method match the measured channel capacities in non-stationary channels.}
}


@article{DBLP:journals/jsac/MizmiziTS24,
	author = {Marouan Mizmizi and
                  Dario Tagliaferri and
                  Umberto Spagnolini},
	title = {Wireless Communications With Space-Time Modulated Metasurfaces},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1534--1548},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389124},
	doi = {10.1109/JSAC.2024.3389124},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/MizmiziTS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Space-time modulated metasurfaces (STMMs) are a newly investigated technology for the next 6G generation wireless communication networks. An STMM augments the spatial phase function with a time-varying one across the meta-atoms, allowing for the conveyance of information that possibly modulates the impinging signal. Hence, STMM represents an evolution of reconfigurable intelligent surfaces (RIS), which only design the spatial phase pattern. STMMs convey signals without a relevant increase in the energy budget, which is convenient for applications where energy is a strong constraint. This paper proposes a mathematical model for STMM-based wireless communication, that creates the basics for two potential STMM architectures. One has excellent design flexibility, whereas the other is more cost-effective. The model describes STMM’s distinguishing features, such as space-time coupling, and their impact on system performance. The proposed STMM model addresses the design criteria of a full-duplex system architecture, in which the temporal signal originating at the STMM generates a modulation overlapped with the incident one. The presented numerical results demonstrate the efficacy of the proposed model and its potential to revolutionize wireless communication.}
}


@article{DBLP:journals/jsac/GongWHYHDY24,
	author = {Tierui Gong and
                  Li Wei and
                  Chongwen Huang and
                  Zhijia Yang and
                  Jiguang He and
                  M{\'{e}}rouane Debbah and
                  Chau Yuen},
	title = {Holographic {MIMO} Communications With Arbitrary Surface Placements:
                  Near-Field LoS Channel Model and Capacity Limit},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1549--1566},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389126},
	doi = {10.1109/JSAC.2024.3389126},
	timestamp = {Sun, 04 Aug 2024 19:48:07 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GongWHYHDY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Envisioned as one of the most promising technologies, holographic multiple-input multiple-output (H-MIMO) recently attracts notable research interests for its great potential in expanding wireless possibilities and achieving fundamental wireless limits. Empowered by the nearly continuous, large and energy-efficient surfaces with powerful electromagnetic (EM) wave control capabilities, H-MIMO opens up the opportunity for signal processing in a more fundamental EM-domain, paving the way for realizing holographic imaging level communications in supporting the extremely high spectral efficiency and energy efficiency in future networks. In this article, we propose a generalized EM-domain near-field channel modeling and study its capacity limit of point-to-point H-MIMO systems that equips arbitrarily placed surfaces in a line-of-sight (LoS) environment. Two effective and computational-efficient channel models are established from their integral counterpart, where one is with a sophisticated formula but showcases more accurate, and another is concise with a slight precision sacrifice. Furthermore, we unveil the capacity limit using our channel model, and derive a tight upper bound based upon an elaborately built analytical framework. Our result reveals that the capacity limit grows logarithmically with the product of transmit element area, receive element area, and the combined effects of\n1/\nd\n2\nmn\n,\n1/\nd\n4\nmn\n, and\n1/\nd\n6\nmn\nover all transmit and receive antenna elements, where\nd\nmn\nindicates the distance between each transmit element n and receive element m. Particularly,\n1/\nd\n6\nmn\ndominates in the near-field region whereas\n1/\nd\n2\nmn\ndominates in the far-field region. Numerical evaluations validate the effectiveness of our channel models, and showcase the slight disparity between the upper bound and the exact capacity, which is beneficial for predicting practical system performance.}
}


@article{DBLP:journals/jsac/YangXLNZY24,
	author = {Songjie Yang and
                  Chenfei Xie and
                  Wanting Lyu and
                  Boyu Ning and
                  Zhongpei Zhang and
                  Chau Yuen},
	title = {Near-Field Channel Estimation for Extremely Large-Scale Reconfigurable
                  Intelligent Surface (XL-RIS)-Aided Wideband mmWave Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1567--1582},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389120},
	doi = {10.1109/JSAC.2024.3389120},
	timestamp = {Mon, 03 Mar 2025 22:17:42 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/YangXLNZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Near-field communications present new opportunities over near-field channels, however, the spherical wavefront propagation makes near-field signal processing challenging. In this context, this paper proposes efficient near-field channel estimation methods for wideband MIMO mmWave systems with the aid of extremely large-scale reconfigurable intelligent surfaces (XL-RIS). For the wideband signals reflected by the analog RIS, we characterize their near-field beam squint effect in both angle and distance domains. Based on the mathematical analysis of the near-field beam patterns over all frequencies, a wideband spherical-domain dictionary is constructed by minimizing the coherence of two arbitrary beams. In light of this, we formulate a two-dimensional compressive sensing problem to recover the channel parameter based on the spherical-domain sparsity of mmWave channels. To this end, we present a correlation coefficient-based atom matching method within our proposed multi-frequency parallelizable subspace recovery framework for efficient solutions. Additionally, we propose a two-dimensional oracle estimator as a benchmark and derive its lower bound across all subcarriers. Our findings emphasize the significance of system hyperparameters and the sensing matrix of each subcarrier in determining the accuracy of the estimation. Finally, numerical results show that our proposed method achieves considerable performance compared with the lower bound and has a time complexity linear to the number of RIS elements.}
}


@article{DBLP:journals/jsac/ZhangY24,
	author = {Yunpu Zhang and
                  Changsheng You},
	title = {{SWIPT} in Mixed Near- and Far-Field Channels: Joint Beam Scheduling
                  and Power Allocation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1583--1597},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389115},
	doi = {10.1109/JSAC.2024.3389115},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extremely large-scale array (XL-array) has emerged as a promising technology to enhance the spectrum efficiency and spatial resolution in future wireless networks by exploiting massive number of antennas for generating pencil-like beamforming. This also leads to a fundamental paradigm shift from conventional far-field communications towards the new near-field communications. In contrast to the existing works that mostly considered simultaneous wireless information and power transfer (SWIPT) in the far field, we consider in this paper a new and practical scenario, called mixed near- and far-field SWIPT, where energy harvesting (EH) and information decoding (ID) receivers are located in the near- and far-field regions of the XL-array base station (BS), respectively. Specifically, we formulate an optimization problem to maximize the weighted sum-power harvested at all EH receivers by jointly designing the BS beam scheduling and power allocation, under the constraints on the maximum sum-rate and BS transmit power. First, for the general case with multiple EH and ID receivers, we propose an efficient algorithm to obtain a suboptimal solution by utilizing the binary variable elimination and successive convex approximation methods. To obtain useful insights, we then study the joint design for special cases. In particular, we show that when there are multiple EH receivers and one ID receiver, in most cases, the optimal design is allocating a portion of power to the ID receiver for satisfying the rate constraint, while the remaining power is allocated to one EH receiver with the highest EH capability. This is in sharp contrast to the conventional far-field SWIPT case, for which all powers should be allocated to ID receivers. Numerical results show that our proposed joint design significantly outperforms other benchmark schemes without the optimization of beam scheduling and/or power allocation.}
}


@article{DBLP:journals/jsac/LyuCWZ24,
	author = {Runyu Lyu and
                  Wenchi Cheng and
                  Muyao Wang and
                  Wei Zhang},
	title = {Fractal {OAM} Generation and Detection Schemes},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1598--1612},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389118},
	doi = {10.1109/JSAC.2024.3389118},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LyuCWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Orbital angular momentum (OAM) carried electromagnetic waves have the potential to improve spectrum efficiency in optical and radio-frequency communications due to the orthogonal wavefronts of different OAM modes. However, OAM beams are vortically hollow and divergent, which significantly decreases the capacity of OAM transmissions. In addition, unaligned transceivers in OAM transmissions can result in a high bit error rate (BER). The Talbot effect is a self-imaging phenomenon that can be used to generate optical or radio-frequency OAM beams with periodic repeating structures at multiples of a certain distance along the propagation direction. These periodic structures make it unnecessary for the transceiver antennas to be perfectly aligned and can also alleviate the hollow divergence of OAM beams. In this paper, we propose Talbot-effect-based fractal OAM generation and detection schemes using a uniform circular array (UCA) to significantly improve capacity and BER performance in unaligned OAM transmissions. We first provide a brief overview of fractal OAM. Then, we propose the fractal OAM beam generation and detection schemes. Numerical analysis and simulations verify the effectiveness of our proposed fractal OAM generation scheme and also demonstrate improved capacity and BER performance compared to normal OAM transmissions. We also analyze how the receive UCA radius and the distance between the UCAs impact the capacity and BER performances.}
}


@article{DBLP:journals/jsac/SasakiYKL24,
	author = {Hirofumi Sasaki and
                  Yasunori Yagi and
                  Riichi Kudo and
                  Doohwan Lee},
	title = {1.58 Tbps {OAM} Multiplexing Wireless Transmission With Wideband Butler
                  Matrix for Sub-THz Band},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1613--1625},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389125},
	doi = {10.1109/JSAC.2024.3389125},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SasakiYKL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile traffic growth requires the advancement of not only the wireless access networks but also their backhaul and fronthaul. Terabit-class wireless backhaul and fronthaul can be an alternative to optical fiber transmission and will be one of the key technologies to construct a more flexible and less expensive network infrastructure for sixth-generation mobile networks (6G). However, it is a challenge to provide an extremely high-capacity wireless link for point-to-point connection without spatial multiplexing gain obtained by the multi-path rich environment. We demonstrated the world’s highest wireless transmission data rate of 1.58 Tbps in the sub-terahertz (sub-THz) band for 6G backhaul and fronthaul networks on the basis of the orbital angular momentum (OAM) multiplexing technology with a wideband Butler matrix. Terabit-class wireless transmission was achieved by designing a wideband 8\\times 8\nButler matrix with two types of 3-dB couplers for the structure without crossover and differential phase shifters that give the desired phase difference over wide bandwidth. Our Butler matrix is capable of multiplexing eight OAM beams and show a high mode isolation of greater than 15 dB and low insertion loss of less than 1.5 dB from 135 to 170 GHz. We implemented the Butler matrices in our OAM multiplexing transmission system, in which the physical-layer data rate of 1.58 Tbps wireless transmission was confirmed with eight OAM modes and dual polarization using the 32 GHz bandwidth.}
}


@article{DBLP:journals/jsac/AcharjeeC24,
	author = {Siddharth Sankar Acharjee and
                  Arpan Chattopadhyay},
	title = {Design and Detection of Controller Manipulation Attack on {RIS} Assisted
                  Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1626--1641},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389119},
	doi = {10.1109/JSAC.2024.3389119},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/AcharjeeC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, research on signal and information theory from the electromagnetics viewpoint has drawn significant attention, mostly due to its potential use in various communication technologies such as multiple-input-multiple-output (MIMO) and Reconfigurable Intelligent Surface (RIS). In this paper, we introduce a new attack called controller manipulation attack (CMA) on a RIS assisted communication system between a transmitter and a receiver, and develop mathematical theory for its design and detection. An attacker has the capability to manipulate the RIS controller and modify the phase shift induced by the RIS elements on the incident electromagnetic signal. The goal of the attacker is to minimize the data rate at the receiver, subject to a constraint on the attack detection probability at the receiver. We consider a number of attack detection models: (i) composite hypothesis testing based attack detection in a given fading block for known channel gains, (ii) quickest detection of CMA in a given fading block for known channel gains, (iii) nonparametric hypothesis test to detect CMA for unknown channel gains over a fading block, and (iv) signal-to-noise-ratio (SNR) moment based detection over possibly multiple fading blocks. In the first case, we show that a simple energy detector is uniformly most powerful (UMP). In the second case, simplification of the standard CUSUM test and its performance bounds are obtained. In the third case, non-parametric Kolmogorov-Smirnov test is further simplified to a simple per-sample double threshold test. The optimal attack against these three detectors are designed via novel optimization formulations and semidefinite relaxation based solutions. In the fourth case, we consider threshold detection using moments of SNR; various SNR moments under no attack are obtained analytically for large RIS and then used to formulate the optimal attack design problem as a linear program. Finally, numerical results demonstrate the efficacy of the proposed schemes.}
}


@article{DBLP:journals/jsac/ZhaoC24,
	author = {Yang Zhao and
                  Bruno Clerckx},
	title = {RIScatter: Unifying Backscatter Communication and Reconfigurable Intelligent
                  Surface},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1642--1655},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389114},
	doi = {10.1109/JSAC.2024.3389114},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhaoC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Backscatter Communication (BackCom) nodes harvest energy from and modulate information over external carriers. Reconfigurable Intelligent Surface (RIS) adapts phase shift response to alter channel strength in specific directions. In this paper, we unify those two seemingly different technologies (and their derivatives) into one architecture called RIScatter. RIScatter is a batteryless cognitive radio that recycles ambient signal in an adaptive and customizable manner, where dispersed or co-located scatter nodes partially modulate their information and partially engineer the wireless channel. The key is to render the probability distribution of reflection states as a joint function of the information source, Channel State Information (CSI), and relative priority of coexisting links. This enables RIScatter to softly bridge BackCom and RIS; reduce to either in special cases; or evolve in a mixed form for heterogeneous traffic control and universal hardware design. We also propose a low-complexity Successive Interference Cancellation (SIC)-free receiver that exploits the properties of RIScatter. For a single-user multi-node network, we characterize the achievable primary-(total-)backscatter rate region by optimizing the input distribution at scatter nodes, the active beamforming at the Access Point (AP), and the energy decision regions at the user. Simulations demonstrate RIScatter nodes can shift between backscatter modulation and passive beamforming.}
}


@article{DBLP:journals/jsac/ZhiPRCWSY24,
	author = {Kangda Zhi and
                  Cunhua Pan and
                  Hong Ren and
                  Kok Keong Chai and
                  Cheng{-}Xiang Wang and
                  Robert Schober and
                  Xiaohu You},
	title = {Performance Analysis and Low-Complexity Design for {XL-MIMO} With
                  Near-Field Spatial Non-Stationarities},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1656--1672},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389128},
	doi = {10.1109/JSAC.2024.3389128},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhiPRCWSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extremely large-scale multiple-input multiple-output (XL-MIMO) is capable of supporting extremely high system capacities with large numbers of users. In this work, we build a framework for the analysis and low-complexity design of XL-MIMO in the near field with spatial non-stationarities. Specifically, we first analyze the theoretical performance of discrete-aperture XL-MIMO using an electromagnetic (EM) channel model based on the near-field spherical wavefront. We analytically reveal the impact of the discrete aperture and polarization mismatch on the received power. We also complement the classical Fraunhofer distance based on the considered EM channel model. Our analytical results indicate that a limited part of the XL-array receives the majority of the signal power in the near field, which leads to a notion of visibility region (VR) of a user. Thus, we propose a VR detection algorithm and leverage the acquired VR information to devise a low-complexity symbol detection scheme. Furthermore, we propose a graph theory-based user partition algorithm, relying on the VR overlap ratio between different users. Partial zero-forcing (PZF) is utilized to eliminate only the interference from users allocated to the same group, which further reduces computational complexity in matrix inversion. Numerical results confirm the correctness of the analytical results and the effectiveness of the proposed algorithms. It reveals that our algorithms approach the performance of conventional whole array (WA)-based designs but with much lower complexity.}
}


@article{DBLP:journals/jsac/NaderiPSBSM24,
	author = {Sanaz Naderi and
                  Dimitris A. Pados and
                  George Sklivanitis and
                  Elizabeth Serena Bentley and
                  Joseph Suprenant and
                  Michael J. Medley},
	title = {Self-Optimizing Near and Far-Field {MIMO} Transmit Waveforms},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1673--1683},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389123},
	doi = {10.1109/JSAC.2024.3389123},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/NaderiPSBSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the problem of dynamically optimizing a multiple-input multiple-output (MIMO) wireless waveform in a given potentially heavily utilized fixed frequency band with applications in near-field or far-field autonomous machine-to-machine communications. In particular, we find the transmitter beam weight vector and the pulse code sequence that maximize the signal-to-interference-plus-noise ratio (SINR) at the output of the maximum SINR joint space-time receiver filter. We propose and derive two novel model-based solutions: (a) Disjoint, space first (transmit weight vector) then time (pulse code sequence) waveform optimization and (b) jointly optimal transmit weight vector and pulse code sequence optimization (a mixed integer programming problem.) The proposed formally derived algorithmic solutions are studied in extensive simulations under varying waveform code length, near-field/far-field and spread-spectrum/non-spread-spectrum interference, in light and dense interference scenarios. Our findings highlight the effectiveness of the described methods compared to static conventionally designed MIMO links and the remarkable ability of the joint space-time optimized waveforms to avoid heavy interference.}
}


@article{DBLP:journals/jsac/ChenWWH24,
	author = {Yuanbin Chen and
                  Ying Wang and
                  Zhaocheng Wang and
                  Zhu Han},
	title = {Angular-Distance Based Channel Estimation for Holographic {MIMO}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1684--1702},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3389116},
	doi = {10.1109/JSAC.2024.3389116},
	timestamp = {Wed, 24 Jul 2024 07:51:34 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenWWH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Leveraging the concept of the electromagnetic signal and information theory, holographic multiple-input multiple-output (MIMO) technology opens the door to an intelligent and endogenously holography-capable wireless propagation environment, with their unparalleled capabilities for achieving high spectral and energy efficiency. Less examined are the important issues such as the acquisition of accurate channel information by accounting for holographic MIMO’s peculiarities. To fill this knowledge gap, this paper investigates the channel estimation for holographic MIMO systems by unmasking their distinctions from the conventional one. Specifically, we elucidate that the channel estimation, subject to holographic MIMO’s electromagnetically large antenna arrays, has to discriminate not only the angles of a user/scatterer but also its distance information, namely the three-dimensional (3D) azimuth and elevation angles plus the distance (AED) parameters. As the angular-domain representation fails to characterize the sparsity inherent in holographic MIMO channels, the tightly coupled 3D AED parameters are firstly decomposed for independently constructing their own covariance matrices. Then, the recovery of each individual parameter can be structured as a compressive sensing (CS) problem by harnessing the covariance matrix constructed. This pair of techniques contribute to a parametric decomposition and compressed deconstruction (DeRe) framework, along with a formulation of the maximum likelihood estimation for each parameter. Then, an efficient algorithm, namely DeRe-based variational Bayesian inference and message passing (DeRe-VM), is proposed for the sharp detection of the 3D AED parameters and the robust recovery of sparse channels. Finally, the proposed channel estimation regime is confirmed to be of great robustness in accommodating different channel conditions, regardless of the near-field and far-field contexts of a holographic MIMO system, as well as an improved performance in comparison to the state-of-the-art benchmarks.}
}


@article{DBLP:journals/jsac/SunGZJC24,
	author = {Haoran Sun and
                  Feifei Gao and
                  Shun Zhang and
                  Shi Jin and
                  Tie Jun Cui},
	title = {Computational Imaging With Holographic {RIS:} Sensing Principle and
                  Pathloss Analysis},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {6},
	pages = {1703--1716},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3398730},
	doi = {10.1109/JSAC.2024.3398730},
	timestamp = {Tue, 18 Jun 2024 09:25:14 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/SunGZJC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Realizing the wireless environmental sensing is another desired function of reconfigurable intelligent surface (RIS), in addition to enhancing the performance of wireless communication systems. In this paper, we design a holographic RIS-aided computational imaging system, which consists of a transmitter, a holographic RIS, a rectangular target and a receiver. Here, the target is composed of a series of discrete segments, each of which possesses a constant scattering density. The sensing task of the proposed system is to estimate the scattering densities of the target, which corresponds to the term computational imaging. The term holographic means that the RIS is modeled as a physically continuous surface with a physically continuous phase shift pattern, which can be approximately considered as having massive (possibly infinite) number of elements within a finite space. Both the RIS and the target are subject to the electromagnetic boundary conditions, whose scattered fields are computed by the equivalent current method and the physical equivalent. Based on the computed scattered fields of the target, we derive the pathloss of the proposed system. In order to perform the imaging, we alter the phase shift pattern of the RIS such that the main energy of its scattered fields is focused towards different segments of the target successively, which then produces multiple measurements of the scattering densities and simultaneously ensures a low pathloss. After all measurements are completed, the scattering densities of the target can be estimated with the observed measurement vector and the reconstructed sensing channel, i.e., the computational imaging is accomplished. Simulation results show that the proposed imaging strategy performs well if the system parameters are designed properly.}
}


@article{DBLP:journals/jsac/CacciapuotiBDRW24,
	author = {Angela Sara Cacciapuoti and
                  Anne Broadbent and
                  Eleni Diamanti and
                  Jacquiline Romero and
                  Stephanie Wehner},
	title = {Guest Editorial The Quantum Internet: Principles, Protocols and Architectures},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1719--1722},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3379106},
	doi = {10.1109/JSAC.2024.3379106},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/CacciapuotiBDRW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Quantum Internet is envisioned as a global network, interconnecting heterogeneous quantum networks, able to transmit quantum information (qubits, qudits, or continuous variables) and to distribute entangled quantum states with no classical equivalent, by exploiting quantum links in synergy with classical links. The Quantum Internet is disruptive, since it is capable of supporting functionalities with no direct counterpart in classical networks, such as advanced quantum cryptographic services, blind quantum computing, and distributed quantum computing characterized by exponential increases in computing power and new forms of communication. These functionalities have the potential to fundamentally change the world in ways we cannot imagine yet.}
}


@article{DBLP:journals/jsac/ChenXLLLYSL24,
	author = {Lutong Chen and
                  Kaiping Xue and
                  Jian Li and
                  Zhonghui Li and
                  Ruidong Li and
                  Nenghai Yu and
                  Qibin Sun and
                  Jun Lu},
	title = {{REDP:} Reliable Entanglement Distribution Protocol Design for Large-Scale
                  Quantum Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1723--1737},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380101},
	doi = {10.1109/JSAC.2024.3380101},
	timestamp = {Tue, 17 Dec 2024 16:57:28 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenXLLLYSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote entanglement distribution in an efficient and reliable manner, especially in the context of a large-scale quantum network with multiple requests, remains an unsolved challenge. The key difficulties lie in achieving spontaneous and precise control over the entanglement distribution procedure, as multiple nodes need to reach a consensus on how to perform it. From the network aspect, allocating link-layer entangled pairs as resources to achieve high efficiency is also challenging. To address these issues, we propose a decentralized Reliable Entanglement Distribution Protocol (REDP) for large-scale networks. The protocol operates in a Forward-Backward Propagation (FBP) manner, where consensus is reached hop-by-hop and disseminated to all nodes on the path. We further use probabilistic analysis and quasi-static modeling to seek the fairness and efficiency of the network based on the above transmission model. Accordingly, we introduce a Source Window Strategy (SWS) and an Entanglement Allocation Strategy (EAS) to assign sending windows and allocate resources for multiple requests, ensuring a high level of fairness and efficiency from a network perspective. Through systematic simulations involving both classical and quantum communication protocols, we demonstrate that REDP outperforms existing approaches in terms of fairness, throughput, and fidelity performance.}
}


@article{DBLP:journals/jsac/IacovelliVCG24,
	author = {Giovanni Iacovelli and
                  Francesco Vista and
                  Nicola Cordeschi and
                  Luigi Alfredo Grieco},
	title = {A Probability-Based Optimization Approach for Entanglement Distribution
                  and Source Position in Quantum Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1738--1748},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380084},
	doi = {10.1109/JSAC.2024.3380084},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/IacovelliVCG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum Internet (QI) is a system of interconnected quantum computers able to exchange information encoded in the so called quantum bits (qubits). Differently from the classical counterpart, qubits benefit from a manifold properties guaranteed by quantum mechanics, such as superposition and entanglement. Despite the fact that quantum networks bring significant advantages, several phenomena can negatively impact the overall system, potentially hindering communication. In order to evaluate the network performance, a comprehensive probability expression is derived in this work to ultimately determine how many qubits are expected to be successfully received by nodes. On this basis, a Mixed-Integer Non-Linear Programming (MINLP) problem is formulated to fairly maximize the qubits exchanged between node pairs and jointly optimize 1) the position of the quantum source, and 2) the entanglement distribution plan. To cope with the non-convexity of the problem, an iterative optimization algorithm, leveraging Block Coordinate Descendent (BCD) and Successive Convex Approximation (SCA) techniques, is proposed. A thorough simulation campaign is conducted to corroborate the theoretical findings. Numerical results demonstrates, under different parameter setups, that the proposed algorithm provides superior performance with respect to a baseline approach.}
}


@article{DBLP:journals/jsac/PromponasVGT24,
	author = {Panagiotis Promponas and
                  V{\'{\i}}ctor Valls and
                  Saikat Guha and
                  Leandros Tassiulas},
	title = {Maximizing Entanglement Rates via Efficient Memory Management in Flexible
                  Quantum Switches},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1749--1762},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380097},
	doi = {10.1109/JSAC.2024.3380097},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/PromponasVGT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of operating a quantum switch with memory constraints. In particular, the switch has to allocate quantum memories to clients to generate link-level entanglements (LLEs), and then use these to serve end-to-end entanglements requests. The paper’s main contributions are (i) to characterize the switch’s capacity region and study how it scales with respect to the number of quantum memories and probability of successful LLEs and (ii) to propose a memory allocation policy that is throughput optimal. In addition, when the requests are bipartite and the LLE attempts are always successful, we show that the proposed policy has polynomial time complexity. We evaluate the proposed policy numerically and illustrate its performance depending on the requests arrivals characteristics and the time available to obtain a memory allocation.}
}


@article{DBLP:journals/jsac/LiuMW24,
	author = {Zhenyu Liu and
                  Stefano Maran{\`{o}} and
                  Moe Z. Win},
	title = {Establishing High-Fidelity Entanglement in Quantum Repeater Chains},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1763--1778},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380092},
	doi = {10.1109/JSAC.2024.3380092},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuMW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entanglement is crucial for many applications such as quantum computing, quantum sensing, and quantum communication. Establishment of entanglement between remote nodes, referred to as remote entanglement establishment (REE), is a key element of the quantum internet. This paper develops a theoretical framework for establishing high-fidelity entanglement between two remote nodes of a quantum repeater chain via entanglement generation, distillation, and swapping operations. In particular, an upper bound on the optimal REE rate under minimum fidelity requirements is established, and an REE policy that achieves such a bound asymptotically is presented. Results in this paper provide guidelines for protocol design in the quantum internet.}
}


@article{DBLP:journals/jsac/ChenJ24,
	author = {Lin Chen and
                  Ziyue Jia},
	title = {On Optimum Entanglement Purification Scheduling in Quantum Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1779--1792},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380080},
	doi = {10.1109/JSAC.2024.3380080},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entanglement purification is a fundamental operation to combat against quantum decoherence and improve the fidelity of the entanglement. When multiple rounds of entanglement purification are performed, the fidelity of the final entanglement depends on the way how we schedule entanglement purification operations at each round. In this paper, we formulate and analyze the optimal entanglement purification scheduling problem arising from this context. Our main results include an optimal link-level purification scheduling algorithm and a joint entanglement purification scheduling and routing algorithm to establish fidelity-guaranteed end-to-end entanglements with quasi-optimal throughput in quantum networks. Our algorithmic framework developed in this paper can serve as functional building blocks for entanglement provisioning to support high-fidelity quantum information transfer by exploiting the limited quantum resources in a cost-effective way in order to fully realize the unrivalled capabilities offered by quantum networks.}
}


@article{DBLP:journals/jsac/MorRuizD24,
	author = {Maria Flors Mor{-}Ruiz and
                  Wolfgang D{\"{u}}r},
	title = {Influence of Noise in Entanglement-Based Quantum Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1793--1807},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380089},
	doi = {10.1109/JSAC.2024.3380089},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MorRuizD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider entanglement-based quantum networks, where multipartite entangled resource states are distributed and stored among the nodes and locally manipulated upon request to establish the desired target configuration. Separating the generation process from the requests enables a pre-preparation of resources, hence a reduced network latency. It also allows for an optimization of the entanglement topology, which is independent of the underlying network geometry. We concentrate on establishing Bell pairs or tripartite GHZ states between arbitrary parties. We study the influence of noise in this process, where we consider imperfections in state preparation, memories, and measurements - all of which can be modeled by local depolarizing noise. We compare different resource states corresponding to linear chains, trees, or multi-dimensional rectangular clusters, as well as centralized topologies using bipartite or tripartite entangled states. We compute the fidelity of the target states using a recently established efficient method, the noisy stabilizer formalism, and identify the best resource states within these classes. This allows us to treat networks of large size containing millions of nodes. We find that in large networks, high-dimensional cluster states are favorable and lead to a significantly higher target state fidelity.}
}


@article{DBLP:journals/jsac/ForlivesiVC24,
	author = {Diego Forlivesi and
                  Lorenzo Valentini and
                  Marco Chiani},
	title = {Logical Error Rates of {XZZX} and Rotated Quantum Surface Codes},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1808--1817},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380088},
	doi = {10.1109/JSAC.2024.3380088},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ForlivesiVC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Surface codes are versatile quantum error-correcting codes known for their planar geometry, making them ideal for practical implementations. While the original proposal used Pauli \\boldsymbol {X}\nor Pauli \\boldsymbol {Z}\noperators in a square structure, these codes can be improved by rotating the lattice or incorporating a mix of generators in the XZZX variant. However, a comprehensive theoretical analysis of the logical error rate for these variants has been lacking. To address this gap, we present theoretical formulas based on recent advancements in understanding the weight distribution of stabilizer codes. For example, over an asymmetric channel with asymmetry A=10\nand a physical error rate p \\to 0\n, we observe that the logical error rate asymptotically approaches p_{\\mathrm {L}} \\to 10~p^{2}\nfor the rotated [[{9,1,3}]]\nXZZX code and p_{\\mathrm {L}} \\to 18.3~p^{2}\nfor the [[{13,1,3}]]\nsurface code. Additionally, we observe a particular behavior regarding rectangular lattices in the presence of asymmetric channels. Our findings demonstrate that implementing both rotation and XZZX modifications simultaneously can lead to suboptimal performance. Thus, in scenarios involving a rectangular lattice, it is advisable to avoid using both modifications simultaneously.}
}


@article{DBLP:journals/jsac/SenthoorS24,
	author = {Kaushik Senthoor and
                  Pradeep Kiran Sarvepalli},
	title = {Communication Efficient Quantum Secret Sharing via Extended {CSS}
                  Codes},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1818--1829},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380082},
	doi = {10.1109/JSAC.2024.3380082},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/SenthoorS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, a class of quantum secret sharing schemes called communication efficient quantum threshold secret sharing schemes (CE-QTS) was introduced. These schemes reduced the communication cost during secret recovery. In this paper, we introduce a general class of communication efficient quantum secret sharing schemes (CE-QSS) which include both threshold and non-threshold schemes. We propose a framework for constructing CE-QSS schemes to generalize the earlier construction of CE-QTS schemes which was based on the staircase codes. The main component in this framework is a class of quantum codes which we call the extended Calderbank-Shor-Steane codes. These extended CSS codes could have other applications. We derive a bound on communication cost for CE-QSS schemes. Finally, we provide a construction of CE-QSS schemes meeting this bound using the proposed framework.}
}


@article{DBLP:journals/jsac/GoodenoughBAKJGE24,
	author = {Kenneth Goodenough and
                  S{\'{e}}bastian de Bone and
                  Vaishnavi L. Addala and
                  Stefan Krastanov and
                  Sarah Jansen and
                  Dion Gijswijt and
                  David Elkouss},
	title = {Near-Term n to k Distillation Protocols Using Graph Codes},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1830--1849},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380094},
	doi = {10.1109/JSAC.2024.3380094},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/GoodenoughBAKJGE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Noisy hardware forms one of the main hurdles to the realization of a near-term quantum internet. Distillation protocols allows one to overcome this noise at the cost of an increased overhead. We consider here an experimentally relevant class of distillation protocols, which distill n to k end-to-end entangled pairs using bilocal Clifford operations, a single round of communication and a possible final local operation depending on the observed measurement outcomes. In the case of permutationally invariant depolarizing noise on the input states, we find a correspondence between these distillation protocols and graph codes. We leverage this correspondence to find provably optimal distillation protocols in this class for several tasks important for the quantum internet. This correspondence allows us to investigate use cases for so-called non-trivial measurement syndromes. Furthermore, we detail a recipe to construct the circuit used for the distillation protocol given a graph code. We use this to find circuits of short depth and small number of two-qubit gates. Additionally, we develop a black-box circuit optimization algorithm, and find that both approaches yield comparable circuits. Finally, we investigate the teleportation of encoded states and find protocols which jointly improve the rate and fidelities with respect to prior art.}
}


@article{DBLP:journals/jsac/ZhuZW24,
	author = {Chengkai Zhu and
                  Chenghong Zhu and
                  Xin Wang},
	title = {Estimate Distillable Entanglement and Quantum Capacity by Squeezing
                  Useless Entanglement},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1850--1860},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380081},
	doi = {10.1109/JSAC.2024.3380081},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhuZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum Internet relies on quantum entanglement as a fundamental resource for secure and efficient quantum communication, reshaping data transmission. In this context, entanglement distillation emerges as a crucial process that plays a pivotal role in realizing the full potential of the quantum internet. Nevertheless, it remains challenging to accurately estimate the distillable entanglement and its closely related essential quantity, the quantum capacity. In this work, we consider a general resource measure known as the reverse divergence of resources which quantifies the minimum divergence between a target state and the set of free states. Leveraging this measure, we propose efficiently computable upper bounds for both quantities based on the idea that the useless entanglement within a state or a quantum channel does not contribute to the distillable entanglement or the quantum capacity, respectively. Our bounds can be computed via semidefinite programming and have practical applications for purifying maximally entangled states under practical noises, such as depolarizing and amplitude damping noises, leading to improvements in estimating the one-way distillable entanglement. Furthermore, we provide valuable benchmarks for evaluating the quantum capacities of qubit quantum channels, including the Pauli channels and the random mixed unitary channels, which are of great interest for the development of a quantum internet.}
}


@article{DBLP:journals/jsac/BushIC24,
	author = {Stephen F. Bush and
                  Christopher G. Iversen and
                  William A. Challener},
	title = {Design for High-Precision Time-Sensitive Networking: Synchronization
                  for the Quantum Network Control Plane},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1861--1870},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380093},
	doi = {10.1109/JSAC.2024.3380093},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/BushIC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tight integration between classical and quantum networking requires strict synchronization of events between the classical and quantum portions of the network. Time-Sensitive Networking (TSN) as defined by IEEE 802.1Q is limited to accuracy on the order of microseconds due to limitations in time synchronization performance; TSN gate control is thus similarly limited. This work presents a new High-Precision TSN that enables greater accuracy and resolution toward sub-nanosecond TSN gate control and can directly support entanglement distribution, a key component in a software-designed quantum network architecture where classical control can reach deep into the quantum network and directly control time critical operations.}
}


@article{DBLP:journals/jsac/ZhaoYFHC24,
	author = {Mufei Zhao and
                  Renzhi Yuan and
                  Chen Feng and
                  Shuai Han and
                  Julian Cheng},
	title = {Security of Coherent-State Quantum Key Distribution Using Displacement
                  Receiver},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1871--1884},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380102},
	doi = {10.1109/JSAC.2024.3380102},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhaoYFHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous variable quantum key distribution (CV-QKD) protocol has drawn much attention due to its compatibility with existing optical communication systems. In this paper, we propose a quaternary modulated CV-QKD protocol using displacement receivers and adopt the post-selection scheme to overcome the ‘3dB limit’. We first establish the model of displacement receiver for discriminating quaternary modulated coherent signals in a realistic situation. The performance of non-adaptive displacement receiver and multi-stage feedforward receiver are both investigated under different noises and device imperfections. To improve the receiver performance, we numerically optimize the displacement operation and check the quantum advantage of the displacement receivers over the classical homodyne detection. Then we analyze the security of the proposed CV-QKD protocol. The secret key rate is derived for both types of displacement receivers under the collective beam splitting attack. We also optimize the transmitted signal photons for different channel transmission efficiencies under practical system constraints. Numerical results shed light on the practical application of displacement receivers in CV-QKD protocols. This includes evaluating the necessity of optimizing the displacement and incorporating the feedforward structure in a displacement receiver according to different practical system limitations. Moreover, under higher channel transmission efficiency and increased receiver noise level, a larger coherent amplitude is required for transmitting signals to attain the maximum secret key rate.}
}


@article{DBLP:journals/jsac/ZhaoWWXHQ24,
	author = {Yangming Zhao and
                  Yangyu Wang and
                  Enshu Wang and
                  Hongli Xu and
                  Liusheng Huang and
                  Chunming Qiao},
	title = {An Asynchronous Transport Protocol for Quantum Data Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1885--1899},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380086},
	doi = {10.1109/JSAC.2024.3380086},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhaoWWXHQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum Data Networks (QDNs) are vital to building Distributed Quantum Computing (DQC) systems. Though several communication protocols have been proposed for QDNs, most of them are at the network layer or below. The only transport layer protocol used batch processing of requests for End-to-End (E2E) quantum data transmission. It not only limits the quantum resource utilization, more importantly, it cannot guarantee reliable E2E quantum data transmission. In this paper, we propose the first asynchronous transportation layer protocol, called AQTP, for QDNs to achieve high-speed and reliable E2E quantum data transmission. AQTP has several distinct features: 1) each quantum node locally allocates quantum resources in order to improve scalability; 2) requests are processed in an asynchronous manner, which results in a higher quantum resource utilization; and 3) it ensures reliable data transmission even if the teleportation operations fail. Extensive simulations show that compared with a batch processed transport layer protocol, AQTP can increase the network throughput by up to 82.97%, and reduce the Average Task Completion Time (ATCT) of DQC tasks by up to 94.69%.}
}


@article{DBLP:journals/jsac/JiangLM24,
	author = {Junli Jiang and
                  Ming{-}Xing Luo and
                  Songya Ma},
	title = {Quantum Network Capacity of Entangled Quantum Internet},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1900--1918},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380091},
	doi = {10.1109/JSAC.2024.3380091},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/JiangLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The quantum Internet’s significance in information technology is increasingly recognized for its potential to enable secure and private communication. The quantum Internet facilitates the transmission of quantum information over extensive distances, thus unlocking novel possibilities in various applications. In this study we explore the quantum communication capacity within general quantum entangled networks. Leveraging von Neumann entropy, we show the capability of state transfer and information concentration across four-party networks, thereby characterizing the bipartite quantum communication capacity with the support of local operations and classical communications from other parties. We introduce unidirectional and bidirectional models, employing chain or star transferring network configurations, and extend these frameworks to encompass general quantum networks. Furthermore, we provide illustrative examples to underscore the implications of our findings. This research yields the initial nontrivial outcome concerning quantum communication capacity across general quantum networks, shedding light on the potential of quantum networks for advanced communication protocols.}
}


@article{DBLP:journals/jsac/HeZLLL24,
	author = {Binjie He and
                  Dong Zhang and
                  Seng W. Loke and
                  Shengrui Lin and
                  Luke Lu},
	title = {Building a Hierarchical Architecture and Communication Model for the
                  Quantum Internet},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1919--1935},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380103},
	doi = {10.1109/JSAC.2024.3380103},
	timestamp = {Thu, 01 Aug 2024 11:09:02 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HeZLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The research of architecture has tremendous significance in realizing quantum Internet. Although there is not yet a standard quantum Internet architecture, the distributed architecture is one of the possible solutions, which utilizes quantum repeaters or dedicated entanglement sources in a flat structure for entanglement preparation & distribution. In this paper, we analyze the distributed architecture in detail and demonstrate that it has three limitations: 1) possible high maintenance overhead, 2) possible low-performance entanglement distribution, and 3) unable to support optimal entanglement routing. We design a hierarchical quantum Internet architecture and a communication model to solve the problems above. We also present a W-state Based Centralized Entanglement Preparation & Distribution (W-state Based CEPD) scheme and a Centralized Entanglement Routing (CER) algorithm within our hierarchical architecture and perform an experimental comparison with other entanglement preparation & distribution schemes and entanglement routing algorithms within the distributed architecture. The evaluation results show that the entanglement distribution efficiency of hierarchical architecture is 11.5% higher than that of distributed architecture on average (minimum 3.3%, maximum 37.3%), and the entanglement routing performance of hierarchical architecture is much better than that of a distributed architecture according to the fidelity and throughput.}
}


@article{DBLP:journals/jsac/KozlowskiKST24,
	author = {Wojciech Kozlowski and
                  Fernando A. Kuipers and
                  Rob Smets and
                  Belma Turkovic},
	title = {QuIP: {A} {P4} Quantum Internet Protocol Prototyping Framework},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1936--1949},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380096},
	doi = {10.1109/JSAC.2024.3380096},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/KozlowskiKST24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum entanglement is so fundamentally different from a network packet that several quantum network stacks have been proposed; one of which has even been experimentally demonstrated. Several simulators have also been developed to make up for limited hardware availability, and which facilitate the design and evaluation of quantum network protocols. However, the lack of shared tooling and community-agreed node architectures has resulted in protocol implementations that are tightly coupled to their simulators. Besides limiting their reusability between different simulators, it also makes building upon prior results and simulations difficult. To address this problem, we have developed QuIP: a P4-based Quantum Internet Protocol prototyping framework for quantum network protocol design. QuIP is a framework for designing and implementing quantum network protocols in a platform-agnostic fashion. It achieves this by providing the means to flexibly, but rigorously, define device architectures against which quantum network protocols can be implemented in the network programming language \\text{P}4_{16}\n. QuIP also comes with the necessary tooling to enable their execution in existing quantum network simulators. We demonstrate its use by showcasing V1Quantum, a completely new device architecture, implementing a link- and network-layer protocol, and simulating it in the existing simulator NetSquid.}
}


@article{DBLP:journals/jsac/ArslanAA24,
	author = {Syed M. Arslan and
                  Saif Al{-}Kuwari and
                  Tasawar Abbas},
	title = {Superdense Coding Using Bragg Diffracted Hyperentangled Atoms},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {7},
	pages = {1950--1959},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3380098},
	doi = {10.1109/JSAC.2024.3380098},
	timestamp = {Fri, 19 Jul 2024 23:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ArslanAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Superdense coding (SDC) is a popular protocol demonstrating the potential of using quantum mechanics to transfer data, where The sender (Alice) can transfer 2 bits of classical information over a single qubit. We present a scheme for quantum superdense coding through Bragg diffracted hyperentangled atoms generated using cavity quantum electrodynamics (QED). In our scheme, Alice transfers 2 bits of classical information over a single hyperentangled atom. This is achieved by introducing multiple quantum gates using resonant and off-resonant Bragg diffraction in cavity QED setup. This scheme uses multiple degrees of freedom to add an extra layer of security to the encoded information.}
}


@article{DBLP:journals/jsac/PetrovAHGAJ24,
	author = {Vitaly Petrov and
                  Sergi Abadal and
                  Chong Han and
                  Laura Galluccio and
                  Ian F. Akyildiz and
                  Josep Miquel Jornet},
	title = {Guest Editorial: Electromagnetic Nanonetworks: From On-Chip Communication
                  to Wearable and Implantable Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {1963--1966},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3401428},
	doi = {10.1109/JSAC.2024.3401428},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/PetrovAHGAJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nanotechnology is enabling the development of devices on a scale ranging from one to a few hundred nanometers. At this scale, a nanomachine is defined as the most basic functional unit, integrated by nano-components which can carry out sensing and actuation. Coordination and information communication among several nanomachines expand the potential applications of individual devices both in terms of complexity and range of operation. The resulting nanonetworks can cover wide areas, to reach unprecedented locations in a non-invasive way. Moreover, the integration of nanonetworks with classical networks and ultimately with the Internet results in a new networking paradigm, which is referred to as the Internet of Nano-Things (IoNT) by Akyildiz and Jornet one and a half decades ago.}
}


@article{DBLP:journals/jsac/GomezSD24,
	author = {Jorge Torres G{\'{o}}mez and
                  Jennifer Simonjan and
                  Falko Dressler},
	title = {Low-Complex Synchronization Method for Intra-Body Links in the Terahertz
                  Band},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {1967--1977},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399255},
	doi = {10.1109/JSAC.2024.3399255},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GomezSD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Precision medicine applications supported by nanotechnologies enforce designing a communication interface between in-body nanosensors and external gateways. Such a communication interface will enable both a data and a control channel between nanodevices operating within the human body and external control units. In this direction, recent literature focuses on deriving analytic channel models for intra-body links through the human tissues, including the analysis of achievable communication capacities in the terahertz band. A yet missing component, however, is a synchronization module to implement communication schemes in the intra-body link. Such synchronization module will ultimately bound the communication performance regarding the perceived signal to noise ratio (SNR) and bit error rate (BER), for instance. This paper contributes to the state of the art in two directions: (a) evaluating the bounds on the communication performance with the Cramer-Rao lower bound (CRLB) for the synchronization symbol timing offset (STO) and (b) designing a low-complex mechanism to synchronize communication. This analysis considers a communication link between external gateways located on the skin and nanosensor devices flowing in the human vessels. Using envelope and slope detectors, we devise a low-complex solution that relies on the received signal strength (RSS) metric to trigger data emissions. The method estimates the peak of the received RSS metric to ignite communication in the most favorable location, i.e., when the nanosensor is located at the shortest distance in the communication range with external gateways. Our findings illustrate the feasibility of such a low-complex synchronization method. Performance illustrates a BER less than 1\\times 10^{-5} for those nanosensors traveling close to the upper vessel wall.}
}


@article{DBLP:journals/jsac/KulsoomCSDV24,
	author = {Farzana Kulsoom and
                  Hassan Nazeer Chaudhry and
                  Pietro Savazzi and
                  Fabio Dell'Acqua and
                  Anna Vizziello},
	title = {An Energy-Efficient Carrier Synchronization Method for Galvanic Coupling
                  Intra-Body Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {1978--1991},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399256},
	doi = {10.1109/JSAC.2024.3399256},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/KulsoomCSDV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intra-body communication will facilitate next-generation personalized medicine by enabling interconnection among implanted devices. To this purpose, energy-efficient communication technologies are required such as galvanic coupling (GC). Although some GC testbeds have been developed to implement the entire communication chain, synchronization problems have not yet been tackled exhaustively. While some papers simply assume a-priori perfect synchronization between GC transmitter and receiver, other studies developed solutions that often are time-consuming. In this paper, an energy-efficient and fast maximum-log-likelihood (ML) synchronization method is proposed, that can operate in real time and follow channel variations. Experiments reveal that the proposed ML synchronization scheme is very effective for short-range GC communication up to 4 cm, with performance similar to the current State-of-the-Art. It shows slightly lower performance levels for higher distances, still it offers the benefit of lower computational requirements than the reference method.}
}


@article{DBLP:journals/jsac/BartraLPRSDP24,
	author = {Gerard Calvo Bartra and
                  Filip Lemic and
                  Guillem Pascual and
                  Aina P{\'{e}}rez Rodas and
                  Jakob Struye and
                  Carmen Delgado and
                  Xavier Costa{-}P{\'{e}}rez},
	title = {Graph Neural Networks as an Enabler of Terahertz-Based Flow-Guided
                  Nanoscale Localization Over Highly Erroneous Raw Data},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {1992--2008},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399257},
	doi = {10.1109/JSAC.2024.3399257},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/BartraLPRSDP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contemporary research advances in nanotechnology and material science are rooted in the emergence of nanodevices as a versatile tool that harmonizes sensing, computing, wireless communication, data storage, and energy harvesting. These devices hold promise in precision medicine, offering novel pathways for disease diagnostics, treatment, and monitoring within the bloodstreams. Ensuring precise localization of events of diagnostic interest, which underpins the concept of flow-guided in-body nanoscale localization, would intuitively provide an added diagnostic value to the detected events. Raw data generated by the nanodevices is pivotal for this localization and consist of an event detection indicator and the time elapsed since the last passage of a nanodevice through the heart. The communication and energy constraints of the nanodevices lead to intermittent operation and unreliable communication, intrinsically affecting this data. This posits a need for comprehensively modelling the features of this data. These imperfections also have profound implications for the viability of existing flow-guided localization approaches, which are ill-prepared to address the intricacies of the environment. Our first contribution lies in an analytical model of raw data for flow-guided localization, dissecting how communication and energy capabilities influence the nanodevices’ data output. This model acts as a vital bridge, reconciling idealized assumptions with practical challenges of flow-guided localization. Toward addressing these practical challenges, we also present an integration of Graph Neural Networks (GNNs) into the flow-guided localization paradigm. GNNs, reinforced by the adaptability and resilience of Heterogeneous Graph Transformers (HGTs), excel in capturing complex dynamic interactions inherent to the localization of events sensed by the nanodevices. Our results highlight the potential of GNNs not only to enhance localization accuracy but also extend coverage to encompass the entire bloodstream.}
}


@article{DBLP:journals/jsac/BoulogeorgosTTA24,
	author = {Alexandros{-}Apostolos A. Boulogeorgos and
                  Stylianos E. Trevlakis and
                  Theodoros A. Tsiftsis and
                  Angeliki Alexiou},
	title = {Toward Modeling and Assessing the Disorientation and Misalignment
                  Effect in Optical Wireless Nano-Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2009--2025},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399252},
	doi = {10.1109/JSAC.2024.3399252},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/BoulogeorgosTTA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is true that medical diagnosis and treatment have always been at the top of research activities. Recently, a very promising area that combines the operation of human body with the principles of wireless communications has arisen and given birth to the field of bio-photonics. Although the deployment of nano-networks inside the human body seems to be an achievable goal, the implementation of optical wireless nano-networks remains a very challenging field due to the lack of accurate channel modeling. Therefore, in this paper, we comprehensively investigate the optical wireless nano-communication channels by considering the deterministic geometric losses (e.g., optical absorption and scattering in human tissues), and modeling the impact of nano-node disorientation and misalignment in in-body nano-networks. To this end, we analytically study the stochastic nature of disorientation and misalignment coefficient in terms of the position and orientation of the nano-node with reference to the out-of-body optical receiver. In particular, we study the statistics of the joint disorientation and misalignment coefficient in terms of the probability density function, which is given in closed-form expression, whereas its cumulative distribution function is introduced as a semi-infinite series expression. Building upon them, we extract novel analytical expressions for the average signal-to-noise-ratio and the outage probability, and a thorough study on the impact of the human tissues on the above performance metrics is conducted. The analytical results are corroborated and cross-compared by means of Monte Carlo simulations, which reveal the importance of accounting for the joint impact of disorientation and misalignment of nano-node when designing optical wireless nano-networks.}
}


@article{DBLP:journals/jsac/TapiePIH24,
	author = {Jean Tapie and
                  Hugo Prod'homme and
                  Mohammadreza F. Imani and
                  Philipp del Hougne},
	title = {Systematic Physics-Compliant Analysis of Over-the-Air Channel Equalization
                  in RIS-Parametrized Wireless Networks-on-Chip},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2026--2038},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399205},
	doi = {10.1109/JSAC.2024.3399205},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TapiePIH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless networks-on-chip (WNoCs) are an enticing complementary interconnect technology for multi-core chips but face severe resource constraints. Being limited to simple on-off-keying modulation, the reverberant nature of the chip enclosure imposes limits on allowed modulation speeds in sight of inter-symbol interference, casting doubts on the competitiveness of WNoCs as interconnect technology. Fortunately, this vexing problem was recently overcome by parametrizing the on-chip radio environment with a reconfigurable intelligent surface (RIS). By suitably configuring the RIS, selected channel impulse responses (CIRs) can be tuned to be (almost) pulse-like despite rich scattering thanks to judiciously tailored multi-bounce path interferences. However, the exploration of this “over-the-air” (OTA) equalization is thwarted by (i) the overwhelming complexity of the propagation environment, and (ii) the non-linear dependence of the CIR on the RIS configuration, requiring a costly and lengthy full-wave simulation for every optimization step. Here, we show that a reduced-basis physics-compliant model for RIS-parametrized WNoCs can be calibrated with a single full-wave simulation. Thereby, we unlock the possibility of predicting the CIR for any RIS configuration almost instantaneously without any additional full-wave simulation. We leverage this new tool to systematically explore OTA equalization in RIS-parametrized WNoCs regarding the optimal choice of delay time for the RIS-shaped CIR’s peak. We also study the simultaneous optimization of multiple on-chip wireless links for broadcasting and conduct a performance evaluation in terms of the bit error rate. Looking forward, the introduced tools will enable the efficient exploration of various types of OTA analog computing in RIS-parametrized WNoCs.}
}


@article{DBLP:journals/jsac/HerathNGP24,
	author = {Kosala Herath and
                  Ampalavanapillai Nirmalathas and
                  Sarath D. Gunapala and
                  Malin Premaratne},
	title = {A Dual-Signaling Architecture for Enhancing Noise Resilience in Floquet
                  Engineering-Based Chip-Scale Wireless Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2039--2053},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399206},
	doi = {10.1109/JSAC.2024.3399206},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HerathNGP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, we introduce a novel theoretical framework for detecting and decoding Terahertz (THz) frequency chip-scale wireless communication signals. By considering the quantum behavior of charge carriers exposed to intense time-periodic radiation, we employ Floquet engineering techniques for system analysis. Using a two-dimensional semiconductor quantum well (2DSQW) based voltage divider, we showcase the detection and decoding of frequency modulated signals at nanoscale dimensions. Exploring noise impact within the Floquet-2DSQW framework, we identify voltage shifts that compromise data demodulation in single signaling setups. To address this challenge, we suggest a dynamic dual-signaling Floquet-2DSQW architecture that adapts the reference voltage to prevalent noise effects in chip-scale environments. Through a numerical analysis configured for Gigabit per second (Gbps) data transmission in the THz carrier frequency range, we show that our dual-signaling approach surpasses conventional single signaling setups, significantly reducing the bit error rate across various signal-to-noise ratio (SNR) values. A comprehensive parametric study emphasizes the importance of correlated noise effects at two 2DSQW receivers for enhanced performance. Our findings offer valuable insights for advancing nanoscale wireless communication within or between chips in noisy conditions, with potential applications in high-speed, reliable data transfer.}
}


@article{DBLP:journals/jsac/KhalidFBBFTBPC24,
	author = {Muhammad Khalid and
                  Simone Ferraresi and
                  Gaetano Bellanca and
                  Marina Barbiroli and
                  Franco Fuschini and
                  Velio Tralli and
                  Davide Bertozzi and
                  Vincenzo Petruzzelli and
                  Giovanna Cal{\`{o}}},
	title = {{LNOI} Wireless Switches Based on Optical Phased Arrays for On-Chip
                  Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2054--2065},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399207},
	doi = {10.1109/JSAC.2024.3399207},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/KhalidFBBFTBPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {On-chip optical wireless links are attracting a great deal of interest as they can provide a possible solution to overcome the drawbacks associated with wired connections. In this paper, we propose a new approach for on-chip communication using optical wireless switches based on thin-film lithium niobate on insulator (LNOI) technology. The optical wireless switches exploit reconfigurable optical phased arrays (OPAs) both at the transmitter and at the receivers. We investigate the radiation characteristics and design criteria of the LN antenna element serving as a unit radiator in the OPAs. We then demonstrate the implementation of an on-chip optical wireless switch in a simple infinite homogeneous host medium and assuming a realistic multilayer structure configuration. Moreover, we examine the impact of various geometrical parameters and the fabrication imperfections on the device performance and provide a discussion on the design optimization. Our findings assess the feasibility of optical wireless switches based on LNOI technology for on-chip wireless communication.}
}


@article{DBLP:journals/jsac/GorlaKPP24,
	author = {Karthik Reddy Gorla and
                  Eunkyoung Kim and
                  Gregory F. Payne and
                  Massimiliano Pierobon},
	title = {Modeling and Characterization of a Molecular-to-Electrical Communication
                  Channel Enabled by Redox Reactions},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2066--2079},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399254},
	doi = {10.1109/JSAC.2024.3399254},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GorlaKPP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Bio-Nano Things (IoBNT) is an emerging area of networking where seamless interconnection between biological and electrical nanotechnology-enabled devices is envisioned to enable disruptive applications. This paper focuses on characterizing the propagation of information (communication channel) through an interface between the biological and the electrical domains, whose components are commonly used as part of biosensing systems. On top of its sensing capabilities, this interface, based on electrochemical transduction, is here innovatively modeled and characterized in terms of communication performance, a key parameter in the context of IoBNT. In particular, the transduction at the basis of this channel is enabled by interactions with a circuit electrode of reduction-oxidation (redox) chemical reactions. Redox reactions are among the building blocks of communication channels in biological cells and tissues. Based on the underlying physical and chemical processes, an analytical system model is detailed for the channel. Based on the latter, an experimentally validated computational model is formulated to enable the empirical estimation of its performance through simulation data. The estimation of Signal-to-Noise Ratio (SNR), Limit of Detection (LoD), and Limit of Quantification (LoQ) are followed by frequency-based analysis of the channel and the estimation of an upper-bound to its information capacity. Design rules based on a trade-off between the dimension of the transducer and its communication performance are derived to aid in the integration of this communication channel into future IoBNT devices.}
}


@article{DBLP:journals/jsac/CovielloLSM24,
	author = {Antonio Coviello and
                  Francesco Linsalata and
                  Umberto Spagnolini and
                  Maurizio Magarini},
	title = {Artificial Neural Networks-Based Real-Time Classification of {ENG}
                  Signals for Implanted Nerve Interfaces},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2080--2095},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399258},
	doi = {10.1109/JSAC.2024.3399258},
	timestamp = {Mon, 03 Mar 2025 22:17:40 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/CovielloLSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Neuropathies are gaining higher relevance in clinical settings, as they risk permanently jeopardizing a person’s life. To support the recovery of patients, the use of fully implanted devices is emerging as one of the most promising solutions. However, these devices, even if becoming an integral part of a fully complex neural nanonetwork system, pose numerous challenges. In this article, we address one of them, which consists of the classification of motor/sensory stimuli. The task is performed by exploring four different types of artificial neural networks (ANNs) to extract various sensory stimuli from the electroneurographic (ENG) signal measured in the sciatic nerve of rats. Different sizes of the data sets are considered to analyze the feasibility of the investigated ANNs for real-time classification through a comparison of their performance in terms of accuracy, F1-score, and prediction time. The design of the ANNs takes advantage of the modelling of the ENG signal as a multiple-input multiple-output (MIMO) system to describe the measures taken by state-of-the-art implanted nerve interfaces. These are based on the use of multi-contact cuff electrodes to achieve nanoscale spatial discrimination of the nerve activity. The MIMO ENG signal model is another contribution of this paper. Our results show that some ANNs are more suitable for real-time applications, being capable of achieving accuracies over 90% for signal windows of 100 and 200\\, ms with a low enough processing time to be effective for pathology recovery.}
}


@article{DBLP:journals/jsac/AnjumP24,
	author = {Khizar Anjum and
                  Dario Pompili},
	title = {Battery-Less Implantable Continuous {EEG} Monitoring via Anisotropic
                  Diffusion},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2096--2107},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399203},
	doi = {10.1109/JSAC.2024.3399203},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/AnjumP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we introduce a groundbreaking approach for ultra-low-power hybrid analog-digital processing of multimodal physiological data at multiple locations, emphasizing EEG signals. We propose an innovative analog Convolutional Processing Unit (CvPU) that uniquely harnesses the properties of anisotropic diffusion in electrical circuits for convolution. This novel use of anisotropic diffusion-driven convolution sets our work apart. Additionally, we present a controller architecture that allows for the sequential execution of multiple consecutive convolutional layers using the same CvPU array. The proposed neural network architecture to detect seizures using EEG signals is evaluated on a publicly available clinical dataset. Our CvPU array-based convolution’s performance and feasibility metrics have been assessed using SPICE simulation software. Furthermore, we have delved deep into studying the scalability of our approach in terms of power and space and its feasibility for battery-less and implantable applications and have compared it with both digital and hybrid analog-digital methods.}
}


@article{DBLP:journals/jsac/WedageVBKB24,
	author = {Lasantha Thakshila Wedage and
                  Mehmet Can Vuran and
                  Bernard Butler and
                  Yevgeni Koucheryavy and
                  Sasitharan Balasubramaniam},
	title = {Internet of Paint (IoP): Channel Modeling and Capacity Analysis for
                  Terahertz Electromagnetic Nanonetworks Embedded in Paint},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2108--2121},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399201},
	doi = {10.1109/JSAC.2024.3399201},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WedageVBKB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work opens a new chapter in the 100, 000 year-old concept of paint, by leveraging innovations in nano-technology in the sub-THz frequency range. More specifically, the groundbreaking concept of Internet of Paint (IoP) is introduced along with a comprehensive channel model and a capacity analysis for nano-scale radios embedded in paint and communicating through paint. Nano-network devices, integrated within a paint medium, communicate via a multipath strategy, encompassing direct waves, reflections from interfaces, and lateral wave propagation. The evaluation incorporates three distinct paint types to assess path losses, received powers, and channel capacity. Analysis of path loss indicates a slight non-linear increase with both frequency and Line of Sight (LoS) distance between transceivers. Notably, paints with high refractive indexes result in the highest path loss. Moreover, burying transceivers at similar depths near the Air-Paint interface showcases promising performance of lateral waves with increasing LoS distance. Increasing paint layer depth leads to amplified attenuation, while total received power exhibits promising results when in close proximity to the Air-Paint interface but steeply declines with burial depth. Additionally, a substantial reduction in channel capacity is observed with LoS distance and burial depth, so transceivers need to be close together and in proximity of the A-P interface to communicate effectively. Comparing paint and air mediums, IoP demonstrates approximately two orders of magnitude reduction in channel capacity compared to air-based communication channels. This paper provides valuable insights into the potential of IoP communication within paint mediums and offers a foundation for further advancements in this emerging field.}
}


@article{DBLP:journals/jsac/AbadalHPGAJ24,
	author = {Sergi Abadal and
                  Chong Han and
                  Vitaly Petrov and
                  Laura Galluccio and
                  Ian F. Akyildiz and
                  Josep Miquel Jornet},
	title = {Electromagnetic Nanonetworks Beyond 6G: From Wearable and Implantable
                  Networks to On-Chip and Quantum Communication},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {8},
	pages = {2122--2142},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3399253},
	doi = {10.1109/JSAC.2024.3399253},
	timestamp = {Fri, 02 Aug 2024 21:40:16 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/AbadalHPGAJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging from the symbiotic combination of nanotechnology and communications, the field of nanonetworking has come a long way since its inception more than fifteen years ago. Significant progress has been achieved in several key communication technologies as enablers of the paradigm, as well as in the multiple application areas that it opens. In this paper, the focus is placed on the electromagnetic nanonetworking paradigm, providing an overview of the advances made in wireless nanocommunication technology from microwave through terahertz to optical bands. The characteristics and potential of the compared technologies are then confronted with the requirements and challenges of the broad set of nanonetworking applications in the Internet of NanoThings (IoNT) and on-chip networks paradigms, including quantum computing applications for the first time. Finally, a selection of cross-cutting issues and possible directions for future work are given, aiming to guide researchers and practitioners towards the next generation of electromagnetic nanonetworks.}
}


@article{DBLP:journals/jsac/YangCBLGCM24,
	author = {Yang Yang and
                  Mingzhe Chen and
                  Yufei W. Blankenship and
                  Jemin Lee and
                  Zabih Ghassemlooy and
                  Julian Cheng and
                  Shiwen Mao},
	title = {Guest Editorial Positioning and Sensing Over Wireless Networks - Part
                  {I}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2143--2148},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3423608},
	doi = {10.1109/JSAC.2024.3423608},
	timestamp = {Wed, 25 Sep 2024 21:22:01 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YangCBLGCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Positioning and sensing have long been an important area of research. Recently, this field has attracted more attention due to the rapid deployment of emerging applications and next-generation communication networks. On the one hand, emerging applications like extended reality (XR) and autonomous vehicle systems need to precisely “see” the physical world, thus greatly increasing the demands on positioning and sensing technologies. Moreover, these applications also require data rate communication links, and thus technologies like cellular networks and WiFi are excellent for supporting these applications. On the other hand, with the evolution of wireless networks, positioning, and sensing have also been considered important functions of future wireless networks that can further enhance communication performance. Although existing wireless communication has achieved significant success in the past several decades, achieving satisfying positioning and sensing performance for these emerging applications remains a challenge due to the complexity of the wireless environment and the stringent performance requirements.}
}


@article{DBLP:journals/jsac/YangCBLGCM24a,
	author = {Yang Yang and
                  Mingzhe Chen and
                  Yufei W. Blankenship and
                  Jemin Lee and
                  Zabih Ghassemlooy and
                  Julian Cheng and
                  Shiwen Mao},
	title = {Positioning Using Wireless Networks: Applications, Recent Progress,
                  and Future Challenges},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2149--2178},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3423629},
	doi = {10.1109/JSAC.2024.3423629},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YangCBLGCM24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Positioning has recently received considerable attention as a key enabler in emerging applications such as extended reality, unmanned aerial vehicles, and smart environments. These applications require both data communication and high-precision positioning, and thus they are particularly well-suited to be offered in wireless networks (WNs). The purpose of this paper is to provide a comprehensive overview of existing works and new trends in the field of positioning techniques from both academic and standard perspectives. The paper provides a comprehensive overview of indoor positioning in WNs, covering the background, applications, measurements, state-of-the-art technologies, and future challenges. The paper outlines the applications of positioning from the perspectives of public facilities, enterprises, and individual users. We investigate the key performance indicators and measurements of positioning systems, followed by the review of the key enabler techniques such as artificial intelligence/large models and adaptive systems. Next, we discuss a number of typical wireless positioning technologies. We extend our overview beyond the academic progress, to include the standardization efforts, and finally, we provide insight into the challenges that remain. The comprehensive overview of existing efforts and new trends in the field of indoor positioning from both academic and standardization perspectives would be a useful reference to researchers in the field.}
}


@article{DBLP:journals/jsac/ChenCCZY24,
	author = {Ang Chen and
                  Li Chen and
                  Yunfei Chen and
                  Nan Zhao and
                  Changsheng You},
	title = {Near-Field Positioning and Attitude Sensing Based on Electromagnetic
                  Propagation Modeling},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2179--2195},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413981},
	doi = {10.1109/JSAC.2024.3413981},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenCCZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Positioning and sensing over wireless networks are imperative for many emerging applications. However, since traditional wireless channel models over-simplify the user equipment (UE) as a point target, they cannot be used for sensing the attitude of the UE, which is typically described by the spatial orientation. In this paper, a comprehensive electromagnetic propagation modeling (EPM) based on electromagnetic theory is developed to precisely model the near-field channel. For the noise-free case, the EPM model establishes the non-linear functional dependence of observed signals on both the position and attitude of the UE. To address the difficulty in the non-linear coupling, we first propose to divide the distance domain into three regions, separated by the defined Phase ambiguity distance and Spacing constraint distance. Then, for each region, we obtain the closed-form solutions for joint position and attitude estimation with low complexity. Next, to investigate the impact of random noise on the joint estimation performance, the Ziv-Zakai bound (ZZB) is derived to yield useful insights. The expected Cramér-Rao bound (ECRB) is further provided to obtain the simplified closed-form expressions for the performance lower bounds. Our numerical results demonstrate that the derived ZZB can provide accurate predictions of the performance of estimators in all signal-to-noise ratio (SNR) regimes. More importantly, we achieve the millimeter-level accuracy in position estimation and attain the 0.1-level accuracy in attitude estimation.}
}


@article{DBLP:journals/jsac/LiWMPL24,
	author = {Haochen Li and
                  Zhaolin Wang and
                  Xidong Mu and
                  Zhiwen Pan and
                  Yuanwei Liu},
	title = {Near-Field Integrated Sensing, Positioning, and Communication: {A}
                  Downlink and Uplink Framework},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2196--2212},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413956},
	doi = {10.1109/JSAC.2024.3413956},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiWMPL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A near-field integrated sensing, positioning, and communication (ISPAC) framework is proposed, where a base station (BS) simultaneously serves multiple communication users and carries out target sensing and positioning. A novel double-array structure is proposed to enable the near-field ISPAC at the BS. Specifically, a small-scale assisting transceiver (AT) is attached to the large-scale main transceiver (MT) to empower the communication system with the ability of sensing and positioning. Based on the proposed framework, the joint angle and distance Cramér-Rao bound (CRB) is first derived. Then, the CRB is minimized subject to the minimum communication rate requirement in both downlink and uplink ISPAC scenarios: 1) For downlink ISPAC, a downlink target positioning algorithm is proposed and a penalty dual decomposition (PDD)-based double-loop algorithm is developed to tackle the non-convex optimization problem. 2) For uplink ISPAC, an uplink target positioning algorithm is proposed and an efficient alternating optimization algorithm is conceived to solve the non-convex CRB minimization problem with coupled user communication and target probing design. Both proposed optimization algorithms can converge to a stationary point of the CRB minimization problem. Numerical results show that: 1) The proposed ISPAC system can locate the target in both angle and distance domains merely relying on single BS and limited bandwidths; and 2) the positioning performance achieved by the hybrid-analog-and-digital ISPAC approaches that achieved by fully digital ISPAC when the communication rate requirement is not stringent.}
}


@article{DBLP:journals/jsac/GanHYCHZYGD24,
	author = {Xu Gan and
                  Chongwen Huang and
                  Zhaohui Yang and
                  Xiaoming Chen and
                  Jiguang He and
                  Zhaoyang Zhang and
                  Chau Yuen and
                  Yong Liang Guan and
                  M{\'{e}}rouane Debbah},
	title = {Coverage and Rate Analysis for Integrated Sensing and Communication
                  Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2213--2227},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413989},
	doi = {10.1109/JSAC.2024.3413989},
	timestamp = {Fri, 20 Sep 2024 14:02:39 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GanHYCHZYGD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrated sensing and communication (ISAC) is increasingly recognized as a pivotal technology for next-generation cellular networks, offering mutual benefits in both sensing and communication capabilities. This advancement necessitates a re-examination of the fundamental limits within networks where these two functions coexist via shared spectrum and infrastructures. However, traditional stochastic geometry-based performance analyses are confined to either communication or sensing networks separately. This paper bridges this gap by introducing a generalized stochastic geometry framework in ISAC networks. Based on this framework, we define and calculate the coverage and ergodic rate of sensing and communication performance under resource constraints. Then, we shed light on the fundamental limits of ISAC networks by presenting theoretical results for the coverage rate of the unified performance, taking into account the coupling effects of dual functions in coexistence networks. Further, we obtain the analytical formulations for evaluating the ergodic sensing rate constrained by the maximum communication rate, and the ergodic communication rate constrained by the maximum sensing rate. Extensive numerical results validate the accuracy of all theoretical derivations, and also indicate that denser networks significantly enhance ISAC coverage. Specifically, increasing the base station density from 1~\\text {km}^{-2}\nto 10~\\text {km}^{-2}\ncan boost the ISAC coverage rate from 1.4% to 39.8%. Further, results also reveal that with the increase of the constrained sensing rate, the ergodic communication rate improves significantly, but the reverse is not obvious.}
}


@article{DBLP:journals/jsac/ZhouLZXHC24,
	author = {Ziqin Zhou and
                  Xiaoyang Li and
                  Guangxu Zhu and
                  Jie Xu and
                  Kaibin Huang and
                  Shuguang Cui},
	title = {Integrating Sensing, Communication, and Power Transfer: Multiuser
                  Beamforming Design},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2228--2242},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413996},
	doi = {10.1109/JSAC.2024.3413996},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhouLZXHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the sixth-generation (6G) networks, massive low-power devices are expected to sense environment and deliver tremendous data. To enhance the radio resource efficiency, the integrated sensing and communication (ISAC) technique exploits the sensing and communication functionalities of signals, while the simultaneous wireless information and power transfer (SWIPT) techniques utilizes the same signals as the carriers for both information and power delivery. The further combination of ISAC and SWIPT leads to the advanced technology namely integrated sensing, communication, and power transfer (ISCPT). In this paper, a multi-user multiple-input multiple-output (MIMO) ISCPT system is considered, where a base station equipped with multiple antennas transmits messages to multiple information receivers (IRs), transfers power to multiple energy receivers (ERs), and senses a target simultaneously. The sensing target can be regarded as a point or an extended surface. When the locations of IRs and ERs are separated, the MIMO beamforming designs are optimized to improve the sensing performance while meeting the communication and power transfer requirements. The resultant non-convex optimization problems are solved based on a series of techniques including Schur complement transformation and rank reduction. Moreover, when the IRs and ERs are co-located, the power splitting factors are jointly optimized together with the beamformers to balance the performance of communication and power transfer. To better understand the performance of ISCPT, the target positioning problem is further investigated. Simulations are conducted to verify the effectiveness of our proposed designs, which also reveal a performance tradeoff among sensing, communication, and power transfer.}
}


@article{DBLP:journals/jsac/LiWF24,
	author = {Biwei Li and
                  Xianbin Wang and
                  Fang Fang},
	title = {Maximizing the Value of Service Provisioning in Multi-User {ISAC}
                  Systems Through Fairness Guaranteed Collaborative Resource Allocation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2243--2258},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413973},
	doi = {10.1109/JSAC.2024.3413973},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiWF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of wireless-enabled industrial applications highlights the growing importance of Integrated Sensing and Communication (ISAC) for concurrent provisioning of environment sensing and data transmission capabilities. However, the resource-hungry nature of sensing processes, coupled with competing demands from coexisting users, poses the fundamental challenge of effective and fair resource allocation in multi-user ISAC systems. To address this challenge, we propose a value of service (VoS)-oriented resource allocation scheme for concurrent heterogeneous service provisioning in a multi-user collaborative ISAC system. Specifically, a performance indicator VoS is utilized to guide system-wide effective resource allocation while guaranteeing fairness among all ISAC users. Specifically, we formulate the multi-user resource allocation problem as a bargaining game-based model and tackle it with an iterative algorithm to attain the Nash equilibrium. In each iteration, the allocation of power and bandwidth resources is optimized by solving the Lagrangian dual problem. Numerical simulations are performed under varying resource conditions, service demands, and channel states. The results demonstrate the superiority of the proposed scheme over non-collaborative alternatives and the other two benchmark schemes.}
}


@article{DBLP:journals/jsac/ZhangMLHCW24,
	author = {Fan Zhang and
                  Tianqi Mao and
                  Ruiqi Liu and
                  Zhu Han and
                  Sheng Chen and
                  Zhaocheng Wang},
	title = {Cross-Domain Dual-Functional {OFDM} Waveform Design for Accurate Sensing/Positioning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2259--2274},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414001},
	doi = {10.1109/JSAC.2024.3414001},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangMLHCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Orthogonal frequency division multiplexing (OFDM) has been widely recognized as the representative waveform for 5G wireless networks, which can directly support sensing/positioning with existing infrastructure. To guarantee superior sensing/positioning accuracy while supporting high-speed communication simultaneously, the dual functions tend to be assigned with different resource elements (REs) due to their diverse design requirements. This motivates optimization of resource allocation/waveform design across time, frequency, power and delay-Doppler domains. Therefore, this article proposes two cross-domain waveform optimization strategies for effective convergence of OFDM-based communication and sensing/positioning, following communication- and sensing-centric criteria, respectively. For the communication-centric design, to maximize the achievable data rate, a fraction of REs are optimally allocated for communication according to prior knowledge of the communication channel. The remaining REs are then employed for sensing/positioning, where the sidelobe level and peak-to-average power ratio are suppressed by optimizing its power-frequency and phase-frequency characteristics for sensing performance improvement. For the sensing-centric design, a ‘locally’ perfect auto-correlation property is ensured for accurate sensing and positioning by adjusting the unit cells of the ambiguity function within its region of interest (RoI). Afterwards, the irrelevant cells beyond RoI, which can readily determine the sensing power allocation, are optimized with the communication power allocation to enhance the achievable data rate. Numerical results demonstrate the superiority of the proposed waveform designs.}
}


@article{DBLP:journals/jsac/UlumKSDWS24,
	author = {Muhammad Shohibul Ulum and
                  Uman Khalid and
                  Jason William Setiawan and
                  Trung Q. Duong and
                  Moe Z. Win and
                  Hyundong Shin},
	title = {Variational Anonymous Quantum Sensing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2275--2291},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414932},
	doi = {10.1109/JSAC.2024.3414932},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/UlumKSDWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {QSNs (QSNs) incorporate quantum sensing and quantum communication to achieve Heisenberg precision and unconditional security by leveraging quantum properties such as superposition and entanglement. However, the QSNs deploying noisy intermediate-scale quantum (NISQ) devices face near-term practical challenges. In this paper, we employ variational quantum sensing (VQS) to optimize sensing configurations in noisy environments for the physical quantity of interest, e.g., magnetic-field sensing for navigation, localization, or detection. The VQS algorithm is variationally and evolutionarily optimized using a genetic algorithm for tailoring a variational or parameterized quantum circuit (PQC) structure that effectively mitigates quantum noise effects. This genetic VQS algorithm designs the PQC structure possessing the capability to create a variational probe state that metrologically outperforms the maximally entangled or product quantum state under bit-flip, dephasing, and amplitude-damping quantum noise for both single-parameter and multiparameter NISQ sensing, specifically as quantified by the quantum Fisher information. Furthermore, the quantum anonymous broadcast (QAB) shares the sensing information in the VQS network, ensuring anonymity and untraceability of sensing data. The broadcast bit error probability (BEP) is further analyzed for the QAB protocol under quantum noise, showing its robustness—i.e., error-free resilience—against bit-flip noise as well as the low-noise BEP behavior. This work provides a scalable framework for integrated quantum anonymous sensing and communication, particularly in a variational and untraceable manner.}
}


@article{DBLP:journals/jsac/ChenLH24,
	author = {Xu Chen and
                  Khaled B. Letaief and
                  Kaibin Huang},
	title = {On the View-and-Channel Aggregation Gain in Integrated Sensing and
                  Edge {AI}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2292--2305},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413988},
	doi = {10.1109/JSAC.2024.3413988},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sensing and edge artificial intelligence (AI) are two key features of the sixth-generation (6G) mobile networks. Their natural integration, termed Integrated sensing and edge AI (ISEA), is envisioned to automate wide-ranging Internet-of-Ting (IoT) applications. To achieve a high sensing accuracy, features of multiple sensor views are uploaded to an edge server for aggregation and inference using a large-scale AI model. The view aggregation is realized efficiently using over-the-air computing (AirComp), which also aggregates channels to suppress channel noise. As ISEA is at its nascent stage, there still lacks an analytical framework for quantifying the fundamental performance gains from view-and-channel aggregation, which motivates this work. Our framework is based on a well-established distribution model of multi-view sensing data where the classic Gaussian-mixture model is modified by adding sub-spaces matrices to represent individual sensor observation perspectives. Based on the model and linear classification, we study the End-to-End sensing (inference) uncertainty, a popular measure of inference accuracy, of the said ISEA system by a novel, tractable approach involving designing a scaling-tight uncertainty surrogate function, global discriminant gain, distribution of receive Signal-to-Noise Ratio (SNR), and channel induced discriminant loss. As a result, we prove that the E2E sensing uncertainty diminishes at an exponential rate as the number of views/sensors grows, where the rate is proportional to global discriminant gain. Given AirComp and channel distortion, we further show that the exponential scaling remains but the rate is reduced by a linear factor representing the channel induced discriminant loss. Furthermore, in the case of many spatial degrees of freedom, we benchmark AirComp against equally fast, traditional analog orthogonal access. The comparative performance analysis reveals a sensing-accuracy crossing point between the schemes corresponding to equal receive array size and sensor number. This leads to the proposal of a scheme for adaptive access-mode switching to enhance ISEA performance. Last, the insights from our framework are validated by experiments using a convolutional neural network model and real-world dataset.}
}


@article{DBLP:journals/jsac/XuZ24,
	author = {Chan Xu and
                  Shuowen Zhang},
	title = {{MIMO} Integrated Sensing and Communication Exploiting Prior Information},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2306--2321},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413972},
	doi = {10.1109/JSAC.2024.3413972},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/XuZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system where one multi-antenna base station (BS) sends information to a user with multiple antennas in the downlink and simultaneously senses the location parameter of a target based on its reflected echo signals received back at the BS receive antennas. We focus on the case where the location parameter to be sensed is unknown and random, for which the prior distribution information is available for exploitation. First, we propose to adopt the posterior Cramér-Rao bound (PCRB) as the sensing performance metric with prior information, which quantifies a lower bound of the mean-squared error (MSE). Since the PCRB is in a complicated form, we derive a tight upper bound of it to draw more insights. Moreover, we analytically show that by exploiting the prior distribution information, the PCRB is always no larger than the CRB averaged over random location realizations without prior information exploitation. Next, we formulate the transmit covariance matrix optimization problem to minimize the sensing PCRB under a communication rate constraint. We obtain the optimal solution and derive useful properties on its rank. Then, by considering the derived PCRB upper bound as the objective function, we propose a low-complexity suboptimal solution in semi-closed form. Numerical results demonstrate the effectiveness of our proposed designs in MIMO ISAC systems exploiting prior information.}
}


@article{DBLP:journals/jsac/TedeschiniKNW24,
	author = {Bernardo Camajori Tedeschini and
                  Girim Kwon and
                  Monica Nicoli and
                  Moe Z. Win},
	title = {Real-Time Bayesian Neural Networks for 6G Cooperative Positioning
                  and Tracking},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2322--2338},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413950},
	doi = {10.1109/JSAC.2024.3413950},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TedeschiniKNW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the evolving landscape of 5G new radio and related 6G evolution, achieving centimeter-level dynamic positioning is pivotal, especially in cooperative intelligent transportation system frameworks. With the challenges posed by higher path loss and blockages in the new frequency bands (i.e., millimeter waves), machine learning (ML) offers new approaches to draw location information from space-time wide-bandwidth radio signals and enable enhanced location-based services. This paper presents an approach to real-time 6G location tracking in urban settings with frequent signal blockages. We introduce a novel teacher-student Bayesian neural network (BNN) method, called Bayesian bright knowledge (BBK), that predicts both the location estimate and the associated uncertainty in real-time. Moreover, we propose a seamless integration of BNNs into a cellular multi-base station tracking system, where more complex channel measurements are taken into account. Our method employs a deep learning (DL)-based autoencoder structure that leverages the complete channel impulse response to deduce location-specific attributes in both line-of-sight and non-line-of-sight environments. Testing in 3GPP specification-compliant urban micro (UMi) scenario with ray-tracing and traffic simulations confirms the BBK’s superiority in estimating uncertainties and handling out-of-distribution testing positions. In dynamic conditions, our BNN-based tracking system surpasses geometric-based tracking techniques and state-of-the-art DL models, localizing a moving target with a median error of 46 cm.}
}


@article{DBLP:journals/jsac/ZhangZH24,
	author = {Shichen Zhang and
                  Huacheng Zeng and
                  Y. Thomas Hou},
	title = {Is Driver on Phone Call? Mobile Device Localization Using Cellular
                  Signal},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2339--2353},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413963},
	doi = {10.1109/JSAC.2024.3413963},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of mobile phones while driving is a major source of distraction for vehicle drivers and has resulted in a large number of car accidents. While surveillance cameras can be used to detect the violation of phone use, they do not work well in some scenarios (e.g., darkness and blockage) and may raise privacy concerns. In this paper, we present PhoLoc, a roadside device to detect the violation of phone use in personal vehicles using the cellular signals emitted by cellphones. PhoLoc is equipped with two sensors: a multi-antenna radio receiver and a low-cost lidar. It jointly processes the multimodal data from the two sensors to estimate the relative location of a phone in a vehicle. The enabler of PhoLoc is a new near-field localization scheme, which is capable of estimating the location of a moving phone at a specific time moment by overhearing its cellular signals. We have built a prototype of PhoLoc and evaluated its performance in realistic scenarios. Experimental results show that PhoLoc achieves 4.2% false positive rate and 13.8% false negative rate in the detection of phone call violation.}
}


@article{DBLP:journals/jsac/PaidimarriTSKGV24,
	author = {Arun Paidimarri and
                  Asaf Tzadok and
                  Sara Garcia Sanchez and
                  Atsutse Kludze and
                  Alexandra Gallyas{-}Sanhueza and
                  Alberto Valdes{-}Garcia},
	title = {Eye-Beam: {A} mmWave 5G-Compliant Platform for Integrated Communications
                  and Sensing Enabling AI-Based Object Recognition},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2354--2368},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413978},
	doi = {10.1109/JSAC.2024.3413978},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/PaidimarriTSKGV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present Eye-Beam, a programmable platform for integrated communication and sensing. Eye-Beam leverages the hardware and processing required for standard millimeter-wave (mmWave) 5G directional communications to enable sensing functions. Specifically, our platform (1) receives and synchronizes to the data frame of broadcast 5G signals, (2) extracts directional communication features, creating a tensor of spatial information, and (3) utilizes this data as input to a DNN that infers the presence of specific objects in the propagation environment. Eye-Beam includes a programmable 28 GHz 64-element phased array, an SDR, and custom FPGA-based firmware. Eye-Beam’s key capabilities and metrics include (i) synchronization of I/Q data (up to 200 MSPS) with beam steering (among 9,601 beams) with 10 ns accuracy; (ii) a signal processing pipeline that extracts communication features such as the SNR and channel response from received 5G waveforms; and (iii) system orchestration that synchronizes the receiver (RX) to the 5G frame structure of the base station (gNodeB) and maintains it within a worst-case OFDM cyclic prefix of 0.29~\\mu s. Eye-Beam is also able to emulate gNodeB transmissions. We demonstrate Eye-Beam’s performance by showcasing its communication capability (decoding up to 64-QAM), as well as its performance as a channel sounder (extracting detailed directional 5G features in 2,401 beam directions within just 20 ms). We then, for the first time, demonstrate AI-based object classification only using the directional communication features derived by Eye-Beam from ambient mmWave 5G signals transmitted by a gNodeB. Six object classes, including 4 distinct objects concealed in a backpack, are classified with 98% accuracy in an indoor environment.}
}


@article{DBLP:journals/jsac/ZhangCLR24,
	author = {Haijun Zhang and
                  Bowen Chen and
                  Xiangnan Liu and
                  Chao Ren},
	title = {Joint Radar Sensing, Location, and Communication Resources Optimization
                  in 6G Network},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2369--2379},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3415082},
	doi = {10.1109/JSAC.2024.3415082},
	timestamp = {Tue, 10 Sep 2024 16:25:34 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangCLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The possibility of jointly optimizing location sensing and communication resources, facilitated by the existence of communication and sensing spectrum sharing, is what promotes the system performance to a higher level. However, the rapid mobility of user equipment (UE) can result in inaccurate location estimation, which can severely degrade system performance. Therefore, the precise UE location sensing and resource allocation issues are investigated in a spectrum sharing sixth generation network. An approach is proposed for joint subcarrier and power optimization based on UE location sensing, aiming to minimize system energy consumption. The joint allocation process is separated into two key phases of operation. In the radar location sensing phase, the multipath interference and Doppler effects are considered simultaneously, and the issues of UE’s location and channel state estimation are transformed into a convex optimization problem, which is then solved through gradient descent. In the communication phase, a subcarrier allocation method based on subcarrier weights is proposed. To further minimize system energy consumption, a joint subcarrier and power allocation method is introduced, resolved via the Lagrange multiplier method for the non-convex resource allocation problem. Simulation analysis results indicate that the location sensing algorithm exhibits a prominent improvement in accuracy compared to benchmark algorithms. Simultaneously, the proposed resource allocation scheme also demonstrates a substantial enhancement in performance relative to baseline schemes.}
}


@article{DBLP:journals/jsac/HuCZM24,
	author = {Zhinan Hu and
                  Xin Chen and
                  Zhenyu Zhou and
                  Shahid Mumtaz},
	title = {Localization With Cellular Signal {RSRP} Fingerprint of Multiband
                  and Multicell},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2380--2394},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414000},
	doi = {10.1109/JSAC.2024.3414000},
	timestamp = {Mon, 11 Nov 2024 16:51:45 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HuCZM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Precisely predicting the location of the user in a Global-Navigation-Satellite-System-degraded environment is a highly challenging task. Localization based on cellular signal fingerprints is one of the promising solutions to this problem and has attracted increasing attention. Long Term Evolution (LTE) signal is popularly utilized for localization due to its global usage, extensive urban coverage, and favorable signal properties. This paper proposes a new multiband multicell Reference Signal Received Power (MBMC-R) fingerprint, which properly fuses LTE signals’ carrier band information, the physical cell identifier information, and RSRP values. Next, a sequential block-matching weight K nearest neighbor algorithm with a cosine similarity criterion is specially designed for performing the pattern-matching localization with the MBMC-R fingerprint. The proposed method also includes the derivation of the Cramer-Rao lower bound, which reveals the impact of various factors on the lower bound of position error. Simulation and on-field experiments prove the performance superiority over other fingerprint localization algorithms reported in the literature.}
}


@article{DBLP:journals/jsac/KozhayaK24,
	author = {Sharbel E. Kozhaya and
                  Zaher M. Kassas},
	title = {On the Fundamental Tracking Performance and Design Considerations
                  of Radio Navigation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2395--2409},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413998},
	doi = {10.1109/JSAC.2024.3413998},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KozhayaK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fundamental tracking performance in radio navigation is characterized, leading to optimal receiver design considerations. First, a generalized beacon model is proposed and its sufficient, salient parameters are defined. Second, closed-form approximations of the delay, Doppler, Doppler stretch, and Doppler rate ambiguity functions (AFs) and a generalized coherent integration efficiency model are proposed. Third, design considerations and optimal coherent processing interval (CPI) length selection are presented, based on the complete navigation framework, entailing the: (i) beacon’s parameters, (ii) channel dynamics between the transmitter and receiver, (iii) employed clocks by the transmitter and receiver, (iv) search space adopted in the acquisition stage, and (v) dynamical model’s order employed in the tracking stage. Fourth, the acquisition and tracking stages of the navigation receiver architecture are discussed. Fifth, three sets of experimental results are presented validating the proposed closed-form approximation of the Doppler stretch and Doppler rate AFs and demonstrating the performance of a receiver tuned by the proposed design considerations in acquiring, tracking, and localization, namely: (i) aircraft tracking of terrestrial 4G signals, (ii) stationary receiver tracking of Starlink low Earth orbit (LEO) signals, and (iii) stationary receiver localization with Starlink and OneWeb LEO signals. For the Starlink and OneWeb receiver localization experiment, the receiver was capable of tracking the Doppler and carrier phase of 5 Starlink and 3 OneWeb LEO satellites. Starting from an initial estimate 50 km away from its true position, the receiver converged to a final two-dimensional (2D) position error of 30.3 m.}
}


@article{DBLP:journals/jsac/RatnamSCSWNZ24,
	author = {Vishnu V. Ratnam and
                  Bilal Sadiq and
                  Hao Chen and
                  Wei Sun and
                  Shunyao Wu and
                  Boon Loong Ng and
                  Jianzhong Zhang},
	title = {WiDRa: Enabling Millimeter-Level Differential Ranging Accuracy in
                  Wi-Fi Using Carrier Phase},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2410--2423},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413985},
	doi = {10.1109/JSAC.2024.3413985},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/RatnamSCSWNZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although Wi-Fi is an ideal technology for many ranging applications, the performance of current methods is limited by the system bandwidth, leading to low accuracy of ~1 m. For many applications, measuring differential range, viz., the change in the range between adjacent measurements, is sufficient. Correspondingly, this work proposes WiDRa - a Wi-Fi based Differential Ranging solution that provides differential range estimates by using the sum-carrier-phase information. The proposed method is not limited by system bandwidth and can track range changes even smaller than the carrier wavelength. The proposed method is first theoretically justified, while taking into consideration the various hardware impairments affecting Wi-Fi chips. In the process, methods to isolate the sum-carrier phase from the hardware impairments are proposed. Extensive simulation results show that WiDRa can achieve a differential range estimation root-mean-square-error (RMSE) of \\approx 1 mm in channels with a Rician-factor \\geq 7 (a 100 \\times improvement to existing methods). The proposed methods are also validated on off-the-shelf Wi-Fi hardware to demonstrate feasibility, where they achieve an RMSE of <1 mm in the differential range. Finally, limitations of current investigation and future directions of exploration are suggested, to further tap into the potential of WiDRa.}
}


@article{DBLP:journals/jsac/LiuZCXTGL24,
	author = {Xiulong Liu and
                  Bojun Zhang and
                  Sheng Chen and
                  Xin Xie and
                  Xinyu Tong and
                  Tao Gu and
                  Keqiu Li},
	title = {A Wireless Signal Correlation Learning Framework for Accurate and
                  Robust Multi-Modal Sensing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2424--2439},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413986},
	doi = {10.1109/JSAC.2024.3413986},
	timestamp = {Wed, 04 Dec 2024 16:36:31 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuZCXTGL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless signal analytics in IoT systems can enable various promising wireless sensing applications such as localization, anomaly detection, and human activity recognition. As a matter of fact, there are significant correlations in terms of dimension, spatial and temporal aspects among wireless signals from multiple sensors. However, none of the wireless sensing research currently in use directly incorporates or exploits the signal correlations. Therefore, there is still substantial scope for improvement in regards to accuracy and robustness. We are introducing a novel framework called Signal Correlation Learning (SCL). This framework utilizes a directed graph to explicitly represent the signal correlation across various wireless sensors. We use signal embedding to depict the correlation features of a multi-dimensional sensor that arise from a multi-sensor system. Then, we perform Kullback-Leibler (KL) divergence on embedding vectors of any pair of sensors in the system to construct a subgraph at a given time point, which can measure the spatial signal correlation of sensors. Subsequently, several subgraphs spanning a specific time frame are fused into a coherent universal graph based on the small-world theory. This universal graph represents the three types of signal correlation simultaneously. A signal correlation aggregation structure is utilized to extract the features from the universal graph. These features can be used to address target sensing problems. We implement SCL in real RFID, Bluetooth, WIFI, and Zigbee systems, and evaluate its performance in three common wireless sensing problems including localization, anomaly detection, and human activity recognition. Extensive experiments demonstrate that our SCL framework significantly outperforms state-of-the-art wireless sensing algorithms by increasing 80\\%\\sim 190\\% in terms of accuracy, and by increasing 160\\%\\sim 220\\% in terms of robustness.}
}


@article{DBLP:journals/jsac/HeLLYH24,
	author = {Yinghui He and
                  Jianwei Liu and
                  Mo Li and
                  Guanding Yu and
                  Jinsong Han},
	title = {Forward-Compatible Integrated Sensing and Communication for WiFi},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2440--2456},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413955},
	doi = {10.1109/JSAC.2024.3413955},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HeLLYH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the fact that WiFi-based sensing can be realized through the reuse of WiFi communication facilities and frequency bands, integrated sensing and communication (ISAC) emerges as a pivotal direction for future WiFi standards, such as IEEE 802.11bf. Traditional WiFi sensing systems extract channel state information (CSI) from exclusive WiFi packets to quantify the characteristics of the sensing target. This poses challenges for existing WiFi systems originally designed for communication purposes, as it demands high-quality and sufficient CSI measurements. In this paper, we propose SenCom as a step towards forward-compatible ISAC solution. SenCom extracts CSI from general WiFi packets, enabling CSI calibration across different WiFi communication modes and delivering quality CSI measurements for upper-layer sensing applications. A fitting-resampling scheme and an incentive strategy are also developed. The former one is to obtain evenly sampled CSI with consistent dimensionality and the latter one is to guarantee sufficient CSI measurements over time. We build a prototype of SenCom and conduct extensive experiments involving 15 participants. The results show that SenCom’s competence for a variety of sensing tasks while making minimal compromises to WiFi communication performance.}
}


@article{DBLP:journals/jsac/ChiZDMYDXL24,
	author = {Guoxuan Chi and
                  Guidong Zhang and
                  Xuan Ding and
                  Qiang Ma and
                  Zheng Yang and
                  Zhenguo Du and
                  Houfei Xiao and
                  Zhuang Liu},
	title = {XFall: Domain Adaptive Wi-Fi-Based Fall Detection With Cross-Modal
                  Supervision},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2457--2471},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413997},
	doi = {10.1109/JSAC.2024.3413997},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChiZDMYDXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed an increasing demand for human fall detection systems. Among all existing methods, Wi-Fi-based fall detection has become one of the most promising solutions due to its pervasiveness. However, when applied to a new domain, existing Wi-Fi-based solutions suffer from severe performance degradation caused by low generalizability. In this paper, we propose XFall, a domain-adaptive fall detection system based on Wi-Fi. XFall overcomes the generalization problem from three aspects. To advance cross-environment sensing, XFall exploits an environment-independent feature called speed distribution profile, which is irrelevant to indoor layout and device deployment. To ensure sensitivity across all fall types, an attention-based encoder is designed to extract the general fall representation by associating both the spatial and temporal dimensions of the input. To train a large model with limited amounts of Wi-Fi data, we design a cross-modal learning framework, adopting a pre-trained visual model for supervision during the training process. We implement and evaluate XFall on one of the latest commercial wireless products through a year-long deployment in real-world settings. The result shows XFall achieves an overall accuracy of 96.8%, with a miss alarm rate of 3.1% and a false alarm rate of 3.3%, outperforming the state-of-the-art solutions in both in-domain and cross-domain evaluation.}
}


@article{DBLP:journals/jsac/YuSHWWVL24,
	author = {Haiyao Yu and
                  Changyang She and
                  Yunkai Hu and
                  Geng Wang and
                  Rui Wang and
                  Branka Vucetic and
                  Yonghui Li},
	title = {Floor-Plan-Aided Indoor Localization: Zero-Shot Learning Framework,
                  Data Sets, and Prototype},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2472--2486},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413994},
	doi = {10.1109/JSAC.2024.3413994},
	timestamp = {Wed, 05 Mar 2025 20:49:30 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/YuSHWWVL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning has been considered a promising approach for indoor localization. Nevertheless, the sample efficiency, scalability, and generalization ability remain open issues of implementing learning-based algorithms in practical systems. In this paper, we establish a zero-shot learning framework that does not need real-world measurements in a new communication environment. Specifically, a graph neural network that is scalable to the number of access points (APs) and mobile devices (MDs) is used for obtaining coarse locations of MDs. Based on the coarse locations, the floor-plan image between an MD and an AP is exploited to improve localization accuracy in a floor-plan-aided deep neural network. To further improve the generalization ability, we develop a synthetic data generator that provides synthetic data samples in different scenarios, where real-world samples are not available. We implement the framework in a prototype that estimates the locations of MDs. Experimental results show that our zero-shot learning method can reduce localization errors by around 30% to 55% compared with three baselines from the existing literature.}
}


@article{DBLP:journals/jsac/HanYKK24,
	author = {Kyuwon Han and
                  Seung Min Yu and
                  Seong{-}Lyun Kim and
                  Seung{-}Woo Ko},
	title = {Mobility-Induced Graph Learning for WiFi Positioning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2487--2502},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413968},
	doi = {10.1109/JSAC.2024.3413968},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HanYKK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A smartphone-based user mobility tracking could be effective in finding his/her location, while the unpredictable error therein due to low specification of built-in inertial measurement units (IMUs) rejects its standalone usage but demands the integration to another positioning technique like WiFi positioning. This paper aims to propose a novel integration technique using a graph neural network called Mobility-INduced Graph LEarning (MINGLE), which is designed based on two types of graphs made by capturing different user mobility features. Specifically, considering sequential measurement points (MPs) as nodes, a user’s regular mobility pattern allows us to connect neighbor MPs as edges, called time-driven mobility graph (TMG). Second, a user’s relatively straight transition at a constant pace when moving from one position to another can be captured by connecting the nodes on each path, called a direction-driven mobility graph (DMG). Then, we can design graph convolution network (GCN)-based cross-graph learning, where two different GCN models for TMG and DMG are jointly trained by feeding different input features created by WiFi RTTs yet sharing their weights. Besides, the loss function includes a mobility regularization term such that the differences between adjacent location estimates should be less variant due to the user’s stable moving pace. Noting that the regularization term does not require ground-truth location, MINGLE can be designed under semi- and self-supervised learning frameworks. The proposed MINGLE’s effectiveness is extensively verified through field experiments, showing a better positioning accuracy than benchmarks, say mean absolute errors (MAEs) being 1.510 (m) and 1.077 (m) for self- and semi-supervised learning cases, respectively.}
}


@article{DBLP:journals/jsac/KimMWSW24,
	author = {Seungnyun Kim and
                  Jihoon Moon and
                  Jiao Wu and
                  Byonghyo Shim and
                  Moe Z. Win},
	title = {Vision-Aided Positioning and Beam Focusing for 6G Terahertz Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2503--2519},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413949},
	doi = {10.1109/JSAC.2024.3413949},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/KimMWSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To meet the ever-increasing data rate demand expected in 6G networks, terahertz (THz) ultra-massive (UM) multiple-input multiple-output (MIMO) systems have gained much attention recently. One notable aspect of these systems is that the deployment of an extremely large-scale antenna array and high transmission frequency result in an expansion of the near-field region where the electromagnetic (EM) radiation is modeled as a spherical wave. In the near-field region, the channel becomes a function of a position of a user equipment (UE) rather than the direction, giving rise to a beam focusing operation that focuses the signal power onto the specific position. However, the traditional approaches relying on the sweeping of discretized beam codewords cannot support this ultra-sharp beam focusing operation in THz UM-MIMO systems. This paper proposes a novel beam focusing technique based on sensing and computer vision (CV) technologies. The essence of the proposed scheme is to estimate the UE’s position from the vision information using the CV technique and then generates the beam heading towards the estimated position. By replacing the discretized and time-consuming beam sweeping operation with a highly precise CV-based positioning, the positioning accuracy as well as the beam focusing gain can be improved significantly. Numerical results show that the proposed scheme achieves significant positioning accuracy and data rate gains over the conventional codebook-based beam focusing schemes.}
}


@article{DBLP:journals/jsac/ShiZZZ24,
	author = {Canran Shi and
                  Kehan Zhang and
                  Bingcheng Zhu and
                  Zaichen Zhang},
	title = {A Simultaneous Visible Light Positioning and {LED} Database Construction
                  Scheme},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2520--2534},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413959},
	doi = {10.1109/JSAC.2024.3413959},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ShiZZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visible light positioning (VLP) is endowed with high accuracy in indoor scenarios. However, the positioning algorithms require plenty of beacon light-emitting diode (LED) coordinates stored in databases, which are expensive to obtain by manual measurements. To circumvent such laborious efforts, we propose a two-step automatic scheme for simultaneous VLP and LED database construction. Specifically, in the first step, a receiver with a photodiode (PD) array samples the optical signals from few benchmark LEDs to locate itself. In the second step, the receiver estimates the unknown beacon LED coordinates through its own locations and the beacon LED signals. For the proposed two-step scheme, we derive closed-form error expressions for the beacon LED coordinates to evaluate the benchmark LEDs’ arrangement and the sampling places. Simulation results agree with the analytical error expressions and reveal that the proposed scheme can achieve centimeter-level accuracy with reasonable transmit powers. Experimental results from the hardware platform verify the feasibility of the scheme. The proposed scheme can circumvent laborious manual measurements and allow the LED database to “grow” while the receivers wander and more receivers enter.}
}


@article{DBLP:journals/jsac/YuanWLP24,
	author = {Renzhi Yuan and
                  Siming Wang and
                  Gang Liu and
                  Mugen Peng},
	title = {Non-Line-of-Sight Ultraviolet Positioning Using Linearly-Arrayed Photon-Counting
                  Receivers},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2535--2549},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413960},
	doi = {10.1109/JSAC.2024.3413960},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YuanWLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional optical positioning techniques employing visible light signals or infrared light signals require line-of-sight links between transmitters and receivers. The wireless positioning techniques using ultraviolet (UV) signals can enjoy both non-line-of-sight (NLOS) positioning ability and immunity to electromagnetic jamming. In this work, we focus on NLOS UV positioning techniques using linearly-arrayed photon-counting receivers. We first derive the geometrical and physical constrains for the NLOS UV positioning using linearly-arrayed receivers. We then derive the analytical relation between location parameters and pointing parameters of unknown transmitter and propose a NLOS UV positioning method with acceptable computational complexity. We further derive the Cramér-Rao bounds for the positioning method when the separate distance between adjacent receivers equals zero. Numerical results demonstrate that the proposed NLOS UV positioning methods using photon-counting receivers can achieve a distance error less than 2 m when the transmitting elevation angle is greater than 30 degrees and the separate distance is greater than 2 m. Besides, we demonstrate that at least three receivers are required to avoid multiple solution problem; and three receivers are enough for achieving an acceptable positioning error for NLOS UV positioning using photon-counting receivers.}
}


@article{DBLP:journals/jsac/RastorguevaFoiKGTTTKWV24,
	author = {Elizaveta Rastorgueva{-}Foi and
                  Ossi Kaltiokallio and
                  Yu Ge and
                  Matias Turunen and
                  Jukka Talvitie and
                  Bo Tan and
                  Musa Furkan Keskin and
                  Henk Wymeersch and
                  Mikko Valkama},
	title = {Millimeter-Wave Radio {SLAM:} End-to-End Processing Methods and Experimental
                  Validation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2550--2567},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413995},
	doi = {10.1109/JSAC.2024.3413995},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/RastorguevaFoiKGTTTKWV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we address the timely topic of cellular bistatic simultaneous localization and mapping (SLAM) with specific focus on end-to-end processing solutions, from raw I/Q samples, via channel parameter estimation to user equipment (UE) and landmark location information in millimeter-wave (mmWave) networks, with minimal prior knowledge. Firstly, we propose a new multipath channel parameter estimation solution that operates directly with beam reference signal received power (BRSRP) measurements, alleviating the need to know the true antenna beampatterns or the underlying beamforming weights. Additionally, the method has built-in robustness against unavoidable antenna sidelobes. Secondly, we propose new snapshot SLAM algorithms that have increased robustness and identifiability compared to prior art, in practical built environments with complex clutter and multi-bounce propagation scenarios, and do not rely on any a priori motion model. The performance of the proposed methods is assessed at the 60GHz mmWave band, via both realistic ray-tracing evaluations as well as true experimental measurements, in an indoor environment. A wide set of offered results demonstrate the improved performance, compared to the relevant prior art, in terms of the channel parameter estimation as well as the end-to-end SLAM performance. Finally, the article provides the measured 60GHz data openly available for the research community, facilitating results reproducibility as well as further algorithm development.}
}


@article{DBLP:journals/jsac/ZhengHZQCQZY24,
	author = {Shilian Zheng and
                  Jiacheng Hu and
                  Luxin Zhang and
                  Kunfeng Qiu and
                  Jie Chen and
                  Peihan Qi and
                  Zhijin Zhao and
                  Xiaoniu Yang},
	title = {FM-Based Positioning via Deep Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2568--2584},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413961},
	doi = {10.1109/JSAC.2024.3413961},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengHZQCQZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Frequency Modulation (FM) broadcast signals, regarded as opportunistic signals, hold significant potential for indoor and outdoor positioning applications. The existing FM-based positioning methods primarily rely on Received Signal Strength (RSS) for positioning, the accuracy of which needs improvement. In this paper, we introduce FM-Pnet, an end-to-end FM-based positioning method that leverages deep learning. This method utilizes the time-frequency representation of FM signals as network input, enabling automatically learning of deep features for positioning. We also propose two strategies, noise injection and enriching training samples, to enhance the model’s generalization performance over long time spans. We construct datasets for both indoor and outdoor scenarios and conduct extensive experiments to validate the performance of our proposed method. Experimental results demonstrate that FM-Pnet significantly outperforms traditional RSS-based positioning methods in terms of both positioning accuracy and stability.}
}


@article{DBLP:journals/jsac/OhDKLB24,
	author = {Myeung Suk Oh and
                  Anindya Bijoy Das and
                  Taejoon Kim and
                  David J. Love and
                  Christopher G. Brinton},
	title = {Minimum Description Feature Selection for Complexity Reduction in
                  Machine Learning-Based Wireless Positioning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {9},
	pages = {2585--2600},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3413977},
	doi = {10.1109/JSAC.2024.3413977},
	timestamp = {Sun, 08 Sep 2024 16:06:40 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/OhDKLB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, deep learning approaches have provided solutions to difficult problems in wireless positioning (WP). Although these WP algorithms have attained excellent and consistent performance against complex channel environments, the computational complexity coming from processing high-dimensional features can be prohibitive for mobile applications. In this work, we design a novel positioning neural network (P-NN) that utilizes the minimum description features to substantially reduce the complexity of deep learning-based WP. P-NN’s feature selection strategy is based on maximum power measurements and their temporal locations to convey information needed to conduct WP. We improve P-NN’s learning ability by intelligently processing two different types of inputs: sparse image and measurement matrices. Specifically, we implement a self-attention layer to reinforce the training ability of our network. We also develop a technique to adapt feature space size, optimizing over the expected information gain and the classification capability quantified with information-theoretic measures on signal bin selection. Numerical results show that P-NN achieves a significant advantage in performance-complexity tradeoff over deep learning baselines that leverage the full power delay profile (PDP). In particular, we find that P-NN achieves a large improvement in performance for low SNR, as unnecessary measurements are discarded in our minimum description features.}
}


@article{DBLP:journals/jsac/YangCBLGCM24b,
	author = {Yang Yang and
                  Mingzhe Chen and
                  Yufei W. Blankenship and
                  Jemin Lee and
                  Zabih Ghassemlooy and
                  Julian Cheng and
                  Shiwen Mao},
	title = {Guest Editorial Positioning and Sensing Over Wireless Networks - Part
                  {II}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2603--2607},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3423628},
	doi = {10.1109/JSAC.2024.3423628},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YangCBLGCM24b.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This is Part II of the double-part Special Issue (SI) on Positioning and Sensing Over Wireless Networks. The two-part SI aims to bring cutting-edge and novel contributions on positioning and sensing over wireless networks for future and emerging applications. The accepted 51 papers are arranged into eight groups: 1) fundamental performance analysis and optimization; 2) positioning and sensing with cellular networks; 3) positioning and sensing with WiFi networks; 4) positioning and sensing with emerging communication technologies; 5) positioning and sensing applications; 6) cooperative positioning and sensing; 7) reconfigurable intelligent surfaces (RIS)-assisted positioning and sensing; and 8) privacy and security. The contributions made by the papers in Part II are summarized as follows, which correspond to the last four paper groups.}
}


@article{DBLP:journals/jsac/GeSKHHW24,
	author = {Yu Ge and
                  Maximilian Stark and
                  Musa Furkan Keskin and
                  Frank Hofmann and
                  Thomas Hansen and
                  Henk Wymeersch},
	title = {{V2X} Sidelink Positioning in {FR1:} Scenarios, Algorithms, and Performance
                  Evaluation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2608--2624},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414579},
	doi = {10.1109/JSAC.2024.3414579},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GeSKHHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate sub-6 GHz V2X sidelink positioning scenarios in 5G vehicular networks through a comprehensive end-to-end methodology encompassing ray-tracing-based channel modeling, novel theoretical performance bounds, high-resolution channel parameter estimation, and geometric positioning using a round-trip-time (RTT) protocol. We first derive a novel, approximate Cramér-Rao bound (CRB) on the connected road user (CRU) position, explicitly taking into account multipath interference, path merging, and the RTT protocol. Capitalizing on tensor decomposition and ESPRIT methods, we propose high-resolution channel parameter estimation algorithms specifically tailored to dense multipath V2X sidelink environments, designed to detect multipath components (MPCs) and extract line-of-sight (LoS) parameters. Finally, using realistic ray-tracing data and antenna patterns, comprehensive simulations are conducted to evaluate channel estimation and positioning performance, indicating that sub-meter accuracy can be achieved in sub-6 GHz V2X with the proposed algorithms.}
}


@article{DBLP:journals/jsac/YangZWLLWTW24,
	author = {Haoming Yang and
                  Qiran Zhao and
                  Hao Wang and
                  Chi Harold Liu and
                  Guozheng Li and
                  Guoren Wang and
                  Jian Tang and
                  Dapeng Oliver Wu},
	title = {Indoor Periodic Fingerprint Collections by Vehicular Crowdsensing
                  via Primal-Dual Multi-Agent Deep Reinforcement Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2625--2641},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414608},
	doi = {10.1109/JSAC.2024.3414608},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YangZWLLWTW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indoor localization is drawing more and more attentions due to the growing demand of various location-based services, where fingerprinting is a popular data driven techniques that does not rely on complex measurement equipment, yet it requires site surveys which is both labor-intensive and time-consuming. Vehicular crowdsensing (VCS) with unmanned vehicles (UVs) is a novel paradigm to navigate a group of UVs to collect sensory data from certain point-of-interests periodically (PoIs, i.e., coverage holes in localization scenarios). In this paper, we formulate the multi-floor indoor fingerprint collection task with periodical PoI coverage requirements as a constrained optimization problem. Then, we propose a multi-agent deep reinforcement learning (MADRL) based solution, “MADRL-PosVCS”, which consists of a primal-dual framework to transform the above optimization problem into the unconstrained duality, with adjustable Lagrangian multipliers to ensure periodic fingerprint collection. We also propose a novel intrinsic reward mechanism consists of the mutual information between a UV’s observations and environment transition probability parameterized by a Bayesian Neural Network (BNN) for exploration, and a elevator-based reward to allow UVs to go cross different floors for collaborative fingerprint collections. Extensive simulation results on three real-world datasets in SML Center (Shanghai), Joy City (Hangzhou) and Haopu Fashion City (Shanghai) show that MADRL-PosVCS achieves better results over four baselines on fingerprint collection ratio, PoI coverage ratio for collection intervals, geographic fairness and average moving distance.}
}


@article{DBLP:journals/jsac/NingXLCBWLY24,
	author = {Jingyi Ning and
                  Lei Xie and
                  Yi Li and
                  Yingying Chen and
                  Yanling Bu and
                  Chuyu Wang and
                  Sanglu Lu and
                  Baoliu Ye},
	title = {Moir{\'{e}}Tracker: Continuous Camera-to-Screen 6-DoF Pose Tracking
                  Based on Moir{\'{e}} Pattern},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2642--2658},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414619},
	doi = {10.1109/JSAC.2024.3414619},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/NingXLCBWLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the realm of AR applications and particularly camera-to-screen interactions, camera tracking stands as a crucial technology. However, the ever-increasing demand for tracking accuracy makes it essential to explore a six-degrees of freedom (6-DoF) tracking technology with ultra-high precision to facilitate micro-motion sensing. In this paper, we propose a novel sensing method MoiréTracker to achieve camera’s 6-DoF pose tracking with ultra-high precision. MoiréTracker outputs camera’s continuous 3-DoF trajectory and 3-DoF posture changes according to the captured moiré patterns, which can be produced by the superposition of camera’s Color Filter Array (CFA) and the projection of screen raster on the CFA plane. Thanks to moiré pattern’s high sensitivity to 6-DoF motions, we characterize the relationship between moiré features and camera’s micro pose changes, so as to realize the continuous 6-DoF pose tracking for camera with ultra-high precision. Moreover, our proposal involves a thumbnail-based method aimed at expanding the working range of MoiréTracker, enabling the pervasive camera-to-screen interactions. We implement a prototype system and evaluate its performance in real-world environments. Extensive experiment results show that MoiréTracker achieves the average trajectory error of 1.20 cm and the posture error of 1.07°.}
}


@article{DBLP:journals/jsac/ChenHFWZYZ24,
	author = {Xu Chen and
                  Xinxin He and
                  Zhiyong Feng and
                  Zhiqing Wei and
                  Qixun Zhang and
                  Xin Yuan and
                  Ping Zhang},
	title = {Joint Localization and Communication Enhancement in Uplink Integrated
                  Sensing and Communications System With Clock Asynchronism},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2659--2673},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414625},
	doi = {10.1109/JSAC.2024.3414625},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ChenHFWZYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a joint single-base localization and communication enhancement scheme for the uplink (UL) integrated sensing and communications (ISAC) system with asynchronism, which can achieve accurate single-base localization of user equipment (UE) and significantly improve the communication reliability despite the existence of timing offset (TO) due to the clock asynchronism between UE and base station (BS). Our proposed scheme integrates the CSI enhancement into the multiple signal classification (MUSIC)-based AoA estimation and thus imposes no extra complexity on the ISAC system. We further exploit a MUSIC-based range estimation method and prove that it can suppress the time-varying TO-related phase terms. Exploiting the AoA and range estimation of UE, we can estimate the location of UE. Finally, we propose a joint CSI and data signals-based localization scheme that can coherently exploit the data and the CSI signals to improve the AoA and range estimation, which further enhances the single-base localization of UE. The extensive simulation results show that the enhanced CSI can achieve equivalent bit error rate performance to the minimum mean square error (MMSE) CSI estimator. The proposed joint CSI and data signals-based localization scheme can achieve decimeter-level localization accuracy despite the existing clock asynchronism and improve the localization root mean square error (RMSE) by about 6 dB compared with the maximum likelihood esimation (MLE)-based benchmark method.}
}


@article{DBLP:journals/jsac/HieuHNA24,
	author = {Nguyen Quang Hieu and
                  Dinh Thai Hoang and
                  Diep N. Nguyen and
                  Mohammad Abu Alsheikh},
	title = {Reconstructing Human Pose From Inertial Measurements: {A} Generative
                  Model-Based Compressive Sensing Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2674--2687},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414604},
	doi = {10.1109/JSAC.2024.3414604},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HieuHNA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ability to sense, localize, and estimate the 3D position and orientation of the human body is critical in virtual reality (VR) and extended reality (XR) applications. This becomes more important and challenging with the deployment of VR/XR applications over the next generation of wireless systems such as 5G and beyond. In this paper, we propose a novel framework that can reconstruct the 3D human body pose of the user given sparse measurements from Inertial Measurement Unit (IMU) sensors over a noisy wireless environment. Specifically, our framework enables reliable transmission of compressed IMU signals through noisy wireless channels and effective recovery of such signals at the receiver, e.g., an edge server. This task is very challenging due to the constraints of transmit power, recovery accuracy, and recovery latency. To address these challenges, we first develop a deep generative model at the receiver to recover the data from linear measurements of IMU signals. The linear measurements of the IMU signals are obtained by a linear projection with a measurement matrix based on the compressive sensing theory. The key to the success of our framework lies in the novel design of the measurement matrix at the transmitter, which can not only satisfy power constraints for the IMU devices but also obtain a highly accurate recovery for the IMU signals at the receiver. This can be achieved by extending the set-restricted eigenvalue condition of the measurement matrix and combining it with an upper bound for the power transmission constraint. Our framework can achieve robust performance for recovering 3D human poses from noisy compressed IMU signals. Additionally, our pre-trained deep generative model achieves signal reconstruction accuracy comparable to an optimization-based approach, i.e., Lasso, but is an order of magnitude faster.}
}


@article{DBLP:journals/jsac/WuZWL24,
	author = {Guangyu Wu and
                  Fuhui Zhou and
                  Kai{-}Kit Wong and
                  Xiangyang Li},
	title = {A Vehicle-Mounted Radar-Vision System for Precisely Positioning Clustering
                  UAVs},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2688--2703},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414610},
	doi = {10.1109/JSAC.2024.3414610},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WuZWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The clustering unmanned aerial vehicles (UAVs) positioning is significant for preventing unauthorized clustering UAVs from causing physical and informational damages. However, current positioning systems suffer from limited sensing view and positioning range, which result in poor positioning performance. In order to tackle those issues, a novel vehicle-mounted radar-vision clustering UAVs positioning system is developed, which achieves precise, wide-area, and dynamic-view sensing and positioning of the clustering UAVs. Moreover, a matching-based spatiotemporal fusion framework is established to mitigate cross-modal and cross-view spatiotemporal misalignment by adaptively exploiting the cross-modal and cross-view feature correlations. Furthermore, we propose an attention-based spatiotemporal fusion method that achieves a trinity projective attention with the unique structure and task-oriented format for effective feature matching and precise clustering UAVs positioning. Our method also exploited the modality-oriented cross-modal feature and the UAV-motion-oriented cross-view UAV spatiotemporal motion feature.We demonstrate the advantages of our proposed framework and positioning method in our developed clustering UAVs positioning system in practice. Experimental results confirm that our proposed method outperforms the benchmark methods in terms of the positioning precision, especially under the occlusion scenarios. Moreover, ablation studies confirm the effectiveness of each unit of our method.}
}


@article{DBLP:journals/jsac/LiZC24,
	author = {Zhuyin Li and
                  Xu Zhu and
                  Jie Cao},
	title = {Enhancing Location Awareness: {A} Perspective on Age of Information
                  and Localization Precision},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2704--2718},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414606},
	doi = {10.1109/JSAC.2024.3414606},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the realm of industrial Internet of Things (IIoT), the concept of location awareness plays a crucial role in the integrated sensing and communication (ISAC) framework. This paper introduces an innovative methodology for assessing the location awareness of a mobile entity by combining the precision of the positioning algorithm and the timeliness of location estimations based on the age of information (AoI). The assessment employs a novel metric termed as the aging error of localization (AEoL), which encapsulates both the accuracy of localization and its evolution over the data packet lifecycle. This metric bridges a gap in existing research, which predominantly emphasizes geographical precision while neglecting the dynamic spatial attributes of a mobile entity, thereby offering valuable insights into both the precision and temporal aspects of location awareness. The study delves into the evaluation of AEoL under scenarios of perfect and imperfect localization algorithm precision. By considering a scenario where an automated guided vehicle (AGV) adheres to the uniform rectilinear motion (URM) and transmits radio signals via specific queuing models, analytical expressions for the time-average AEoL are derived across varying update rates. These expressions are subsequently validated through numerical simulations. Furthermore, for specific root mean square error (RMSE) scenarios, optimal update rates are recommended, through which the performance of location awareness can be enhanced by reducing the AEoL metric by 10% to 68% compared to the worst-case scenario.}
}


@article{DBLP:journals/jsac/WangYZMZ24,
	author = {Xiao{-}Yang Wang and
                  Shaoshi Yang and
                  Jianhua Zhang and
                  Christos Masouros and
                  Ping Zhang},
	title = {Clutter Suppression, Time-Frequency Synchronization, and Sensing Parameter
                  Association in Asynchronous Perceptive Vehicular Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2719--2736},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414581},
	doi = {10.1109/JSAC.2024.3414581},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangYZMZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Significant challenges remain for realizing precise positioning and velocity estimation in practical perceptive vehicular networks (PVN) that rely on the emerging integrated sensing and communication (ISAC) technology. Firstly, complicated wireless propagation environment generates undesired clutter, which degrades the vehicular sensing performance and increases the computational complexity. Secondly, in practical PVN, multiple types of parameters individually estimated are not well associated with specific vehicles, which may cause error propagation in multiple-vehicle positioning. Thirdly, radio transceivers in a PVN are naturally asynchronous, which causes strong range and velocity ambiguity in vehicular sensing. To overcome these challenges, in this paper 1) we introduce a moving target indication (MTI) based joint clutter suppression and sensing algorithm, and analyze its clutter-suppression performance and the Cramér-Rao lower bound (CRLB) of the paired range-velocity estimation upon using the proposed clutter suppression algorithm; 2) we design an algorithm (and its low-complexity versions) for associating individual direction-of-arrival (DOA) estimates with the paired range-velocity estimates based on “domain transformation”; 3) we propose the first viable carrier frequency offset (CFO) and time offset (TO) estimation algorithm that supports passive vehicular sensing in non-line-of-sight (NLOS) environments. This algorithm treats the delay-Doppler spectrum of the signals reflected by static objects as an environment-specific “fingerprint spectrum”, which is shown to exhibit a circular shift property upon changing the CFO and/or TO. Then, the CFO and TO are efficiently estimated by acquiring the number of circular shifts, and we also analyse the mean squared error (MSE) performance of the proposed time-frequency synchronization algorithm. Finally, simulation results demonstrate the performance advantages of our algorithms under diverse configurations, while corroborating the theoretical analysis.}
}


@article{DBLP:journals/jsac/WangDNXKAHK24,
	author = {Jiacheng Wang and
                  Hongyang Du and
                  Dusit Niyato and
                  Zehui Xiong and
                  Jiawen Kang and
                  Bo Ai and
                  Zhu Han and
                  Dong In Kim},
	title = {Generative Artificial Intelligence Assisted Wireless Sensing: Human
                  Flow Detection in Practical Communication Environments},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2737--2753},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414628},
	doi = {10.1109/JSAC.2024.3414628},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangDNXKAHK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Groundbreaking applications such as ChatGPT have heightened research interest in generative artificial intelligence (GAI). Essentially, GAI excels not only in content generation but also signal processing, offering support for wireless sensing. Hence, we introduce a novel GAI-assisted human flow detection system (G-HFD). Rigorously, G-HFD first uses the channel state information (CSI) to estimate the velocity and acceleration of propagation path length change of the human induced reflection (HIR). Then, given the strong inference ability of the diffusion model, we propose a unified weighted conditional diffusion model (UW-CDM) to denoise the estimation results, enabling detection of the number of targets. Next, we use the CSI obtained by a uniform linear array with wavelength spacing to estimate the HIR’s time of flight and direction of arrival (DoA). In this process, UW-CDM solves the problem of ambiguous DoA spectrum, ensuring accurate DoA estimation. Finally, through clustering, G-HFD determines the number of subflows and the number of targets in each subflow, i.e., the subflow size. The evaluation based on practical downlink communication signals shows G-HFD’s accuracy of subflow size detection can reach 91%. This validates its effectiveness and underscores the significant potential of GAI in the context of wireless sensing.}
}


@article{DBLP:journals/jsac/HuNL24,
	author = {Jingzhi Hu and
                  Dusit Niyato and
                  Jun Luo},
	title = {Cross-Domain Learning Framework for Tracking Users in RIS-Aided Multi-Band
                  {ISAC} Systems With Sparse Labeled Data},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2754--2768},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414600},
	doi = {10.1109/JSAC.2024.3414600},
	timestamp = {Mon, 09 Dec 2024 22:46:11 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HuNL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrated sensing and communications (ISAC) is pivotal for 6G communications and is boosted by the rapid development of reconfigurable intelligent surfaces (RISs). Using the channel state information (CSI) across multiple frequency bands, RIS-aided multi-band ISAC systems can potentially track users’ positions with high precision. Though tracking with CSI is desirable as no communication overheads are incurred, it faces challenges due to the multi-modalities of CSI samples, irregular and asynchronous data traffic, and sparse labeled data for learning the tracking function. This paper proposes the X2Track framework, where we model the tracking function by a hierarchical architecture, jointly utilizing multi-modal CSI indicators across multiple bands, and optimize it in a cross-domain manner, tackling the sparsity of labeled data for the target deployment environment (namely, target domain) by adapting the knowledge learned from another environment (namely, source domain). Under X2Track, we design an efficient deep learning algorithm to minimize tracking errors, based on transformer neural networks and adversarial learning techniques. Simulation results verify that X2Track achieves decimeter-level axial tracking errors even under scarce UL data traffic and strong interference conditions and can adapt to diverse deployment environments with fewer than 5% training data, or equivalently, 5 minutes of UE tracks, being labeled.}
}


@article{DBLP:journals/jsac/WangWYWZAGL24,
	author = {Dawei Wang and
                  Zijun Wang and
                  Keping Yu and
                  Zhiqiang Wei and
                  Hongbo Zhao and
                  Naofal Al{-}Dhahir and
                  Mohsen Guizani and
                  Victor C. M. Leung},
	title = {Active Aerial Reconfigurable Intelligent Surface Assisted Secure Communications:
                  Integrating Sensing and Positioning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2769--2785},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414621},
	doi = {10.1109/JSAC.2024.3414621},
	timestamp = {Sun, 06 Oct 2024 21:33:56 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangWYWZAGL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes an active aerial reconfigurable intelligent surface (ARIS) assisted secure communication framework by integrating sensing and positioning against a mobile eavesdropper. In the proposed scheme, the base station (BS) beamforms the private information to the legitimate user and jams the eavesdropper with artificial noise (AN), while reconfiguring the phases and amplitudes of the passive signal by the active ARIS for promoting secure communications. To acquire the channel state information of the time-vary wiretap channel, the BS tracks the position of the eavesdropper by exploiting the reflected AN. Based on the tracked position of the eavesdropper in the previous time slot, we propose a secure communication scheme that aims to maximize the secrecy rate in the current time slot. This scheme is assisted by the ARIS through jointly optimizing the passive beamforming of the privacy information and AN, the reflection matrix of the ARIS, and the position of the ARIS. In the case of this non-convex quandary with highly coupled variables, we opt to disassemble it into three constituent subproblems and design an alternating optimization framework, where the optimal power beamforming at the BS is derived using a successive convex approximation method and semi-positive definite relaxation technique, the reconfigurable coefficient of the ARIS is optimized using the majorization-minimization algorithm, and the optimal position of the ARIS using the three-dimensional network is obtained by the deep deterministic policy gradient algorithm. Simulation results demonstrate the superior performance of the proposed scheme in the context of the secrecy rate when compared with benchmark schemes. By adopting the active beamforming and positioning technique, the secrecy rate can be increased by 38.3% and 10.8%, respectively.}
}


@article{DBLP:journals/jsac/AnYGRDPH24,
	author = {Jiancheng An and
                  Chau Yuen and
                  Yong Liang Guan and
                  Marco Di Renzo and
                  M{\'{e}}rouane Debbah and
                  H. Vincent Poor and
                  Lajos Hanzo},
	title = {Two-Dimensional Direction-of-Arrival Estimation Using Stacked Intelligent
                  Metasurfaces},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2786--2802},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414613},
	doi = {10.1109/JSAC.2024.3414613},
	timestamp = {Tue, 22 Oct 2024 21:09:06 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/AnYGRDPH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stacked intelligent metasurfaces (SIMs) are capable of emulating reconfigurable physical neural networks by utilizing electromagnetic (EM) waves as carriers. They can also perform various complex computational and signal processing tasks. An SIM is constructed by densely integrating multiple metasurface layers, each consisting of a large number of small meta-atoms that can control the EM waves passing through it. In this paper, we harness an SIM for two-dimensional (2D) direction-of-arrival (DOA) estimation. In contrast to conventional designs, an advanced SIM in front of a receiver array can be designed to automatically compute the 2D discrete Fourier transform (DFT) as the incident waves propagate through it. As a result, a receiver array can directly observe the angular spectrum of the incoming signal, and it can estimate the DOA by simply using probes to detect the energy distribution on the receiver array. This avoids the need for power inefficient radio frequency chains. To enable an SIM to perform the 2D DFT in the wave domain, we formulate an optimization problem that minimizes the mean square error (MSE) between the SIM’s EM response and the 2D DFT matrix. Then, a gradient descent algorithm is customized for iteratively updating the phase shift applied by each meta-atom of the SIM. To further improve the DOA estimation accuracy, we configure the phase shifts of the input layer of the SIM to generate a set of 2D DFT matrices associated with orthogonal spatial frequency bins. Additionally, we analytically evaluate the performance of the proposed SIM-based DOA estimator by deriving a tight upper bound for the MSE. Extensive numerical simulations verify the capability of an optimized SIM to perform DOA estimation and corroborate the theoretical analysis. Specifically, we show that an SIM is capable of performing DOA estimation with an MSE of the order of 10^{-4} .}
}


@article{DBLP:journals/jsac/WuPZREWSY24,
	author = {Tuo Wu and
                  Cunhua Pan and
                  Kangda Zhi and
                  Hong Ren and
                  Maged Elkashlan and
                  Cheng{-}Xiang Wang and
                  Robert Schober and
                  Xiaohu You},
	title = {Exploit High-Dimensional {RIS} Information to Localization: What Is
                  the Impact of Faulty Element?},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2803--2819},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414582},
	doi = {10.1109/JSAC.2024.3414582},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WuPZREWSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a novel localization algorithm using the reconfigurable intelligent surface (RIS) received signal, i.e., RIS information. Compared with BS received signal, i.e., BS information, RIS information offers higher dimension and richer feature set, thereby providing an enhanced capacity to distinguish positions of the mobile users (MUs). Additionally, we address a practical scenario where RIS contains some unknown (number and places) faulty elements that cannot receive signals. Initially, we employ transfer learning to design a two-phase transfer learning (TPTL) algorithm, designed for accurate detection of faulty elements. Then our objective is to regain the information lost from the faulty elements and reconstruct the complete high-dimensional RIS information for localization. To this end, we propose a transfer-enhanced dual-stage (TEDS) algorithm. In Stage I, we integrate the CNN and variational autoencoder (VAE) to obtain the RIS information, which in Stage II, is input to the transferred DenseNet 121 to estimate the location of the MU. To gain more insight, we propose an alternative algorithm named transfer-enhanced direct fingerprint (TEDF) algorithm which only requires the BS information. The comparison between TEDS and TEDF reveals the effectiveness of faulty element detection and the benefits of utilizing the high-dimensional RIS information for localization. Besides, our empirical results demonstrate that the performance of the localization algorithm is dominated by the high-dimensional RIS information and is robust to unoptimized phase shifts and signal-to-noise ratio (SNR).}
}


@article{DBLP:journals/jsac/WangXSDZ24,
	author = {Ran Wang and
                  Cheng Xu and
                  Jing Sun and
                  Shihong Duan and
                  Xiaotong Zhang},
	title = {Cooperative Localization for Multi-Agents Based on Reinforcement Learning
                  Compensated Filter},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2820--2831},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414599},
	doi = {10.1109/JSAC.2024.3414599},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/WangXSDZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In modern navigation and positioning systems, accurate location information is crucial for ensuring system performance and user experience. Particularly, in scenarios involving the use of multiple agents such as robots and drones for rescue operations in unknown complex environments, accurate localization is fundamental for subsequent actions. However, traditional filtering-based localization algorithms may exhibit suboptimal performance and are sensitive to initial estimates and system noise. To address these issues, this paper proposes a multi-agent collaborative localization algorithm based on reinforcement learning compensation filtering to tackle localization problems in complex environments and improve the robustness and accuracy. Specifically, this paper introduces a value decomposition-based reinforcement learning network for filtering compensation to reduce overall localization error and address the credit allocation problem in multi-agent reinforcement learning. The main contributions of this paper are as follows: Firstly, a local localization estimation method based on reinforcement learning compensation Extended Kalman Filter (EKF) is proposed, which further corrects the results of the EKF algorithm and eliminates initial estimation errors. Secondly, a global collaborative localization estimation algorithm (MARL_CF) based on credit allocation in multi-agent reinforcement learning is proposed, which maximizes the reduction of overall localization error through information sharing and global optimization. Finally, the effectiveness of the proposed algorithms is validated through both numerical simulation and physical experiments. The results demonstrate that the proposed MARL_CF significantly improve the accuracy and robustness of localization in complex environments.}
}


@article{DBLP:journals/jsac/HuLXQZ24,
	author = {Zhixiang Hu and
                  An Liu and
                  Wenkang Xu and
                  Tony Q. S. Quek and
                  Min{-}Jian Zhao},
	title = {A Stochastic Particle Variational Bayesian Inference Inspired Deep-Unfolding
                  Network for Sensing Over Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2832--2846},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414626},
	doi = {10.1109/JSAC.2024.3414626},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuLXQZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future wireless networks are envisioned to provide ubiquitous sensing services, driving a substantial demand for multi-dimensional non-convex parameter estimation. This entails dealing with non-convex likelihood functions containing numerous local optima. Variational Bayesian inference (VBI) provides a powerful tool for modeling complex estimation problems and leveraging prior information, but poses a long-standing challenge on computing intractable posterior distributions. Most existing variational methods depend on specific distribution assumptions for obtaining closed-form solutions, and are difficult to apply in practical scenarios. Given these challenges, firstly, we propose a parallel stochastic particle VBI (PSPVBI) algorithm. Due to innovations like particle approximation, added updates of particle positions, and parallel stochastic successive convex approximation (PSSCA), PSPVBI can flexibly drive particles to fit the posterior distribution with acceptable complexity, yielding high-precision estimates of the target parameters. Furthermore, additional speedup can be obtained by deep-unfolding this algorithm. Specifically, superior hyperparameters are learned to dramatically reduce iterations. In this PSPVBI-induced deep-unfolding network, some techniques related to gradient computation, data sub-sampling, differentiable sampling, and generalization ability are also employed to facilitate the practical deployment. Finally, we apply the learnable PSPVBI (LPSPVBI) to solve two important positioning/sensing problems over wireless networks. Simulations indicate that the LPSPVBI algorithm outperforms existing solutions.}
}


@article{DBLP:journals/jsac/ZhangCMYL24,
	author = {Haiying Zhang and
                  Shuyi Chen and
                  Weixiao Meng and
                  Jinhong Yuan and
                  Cheng Li},
	title = {Multiuser Association and Localization Over Doubly Dispersive Multipath
                  Channels for Integrated Sensing and Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2847--2862},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414627},
	doi = {10.1109/JSAC.2024.3414627},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangCMYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Supporting multiuser communication and localization is a typical scenario in Integrated sensing and communications (ISAC). However, the problem of multi-echo induced by multipath and multiuser makes it hard to determine the relationship between user equipments (UEs) and these echoes. Thus, applying traditional estimation algorithms at the radar receiver inevitably leads to weak communication and localization performances due to the mismatch between echoes and UEs. In this paper, aiming to achieve multiuser association and localization under doubly dispersive multipath channels, we construct an ISAC unified waveform based on the orthogonal delay-Doppler division multiplexing (ODDM) principle and develop an off-grid cluster sparse Bayesian learning estimation (OG-CSBL) algorithm. Particularly, we focus on the mono-static setup, where the base station (BS) expects to communicate with multiuser while sensing their locations. We utilize the high-resolution range profile (HRRP) to characterize the physical features of UEs and establish associations with their echoes by exploiting the inherent cluster structure. To estimate parameters, we design a hybrid Dirichlet process (DP)-Gaussian hierarchical prior distribution and propose a variational Bayesian inference (VBI)-EM strategy. Additionally, we develop a backtrack echo identification scheme to facilitate precise UE localization. Simulation results demonstrate that the proposed scheme achieves superior NMSE performance, offers meter-level localization accuracy, and obtains better BER performance in the complex multiuser coexistence scenario.}
}


@article{DBLP:journals/jsac/LiuXHHZMWLJWW24,
	author = {Guangyi Liu and
                  Rongyan Xi and
                  Zixiang Han and
                  Lincong Han and
                  Xiaozhou Zhang and
                  Liang Ma and
                  Yajuan Wang and
                  Mengting Lou and
                  Jing Jin and
                  Qixing Wang and
                  Jiangzhou Wang},
	title = {Cooperative Sensing for 6G Mobile Cellular Networks: Feasibility,
                  Performance, and Field Trial},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2863--2876},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414596},
	doi = {10.1109/JSAC.2024.3414596},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/LiuXHHZMWLJWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The combination of communication and sensing is envisioned as a novel feature in the forthcoming sixth-generation (6G) wireless communication. The conventional approach to the joint sensing and communication (JSAC) system is utilizing one base station (BS) as both a sensing transmitter and a sensing receiver, which is known as monostatic sensing. However, the resulting self-interference issue requires additional hardware promotion to achieve full-duplexing. To overcome this issue, in this paper, we focus on cooperative sensing where the transmitter and receivers are non-co-located, which includes the bistatic and multistatic sensing. Specifically, the system model of cooperative sensing based on mobile networks is established. To demonstrate the feasibility of cooperative sensing, the bistatic radar cross section (RCS) is provided. As for the sensing method, a refined orthogonal matching pursuit (R-OMP) method is proposed to estimate the channel parameters and data fusion is also provided to derive the objects’ positions and velocities. Considering the non-negligible interference in the cooperative JSAC networks, we also discuss interference management in this paper. Simulation results show that the proposed cooperative sensing system improves the position and velocity estimation accuracy by over 20% when compared with monostatic sensing. The preliminary experiment results also verify the feasibility of the proposed system.}
}


@article{DBLP:journals/jsac/JiangGZ24,
	author = {Peiyue Jiang and
                  Xiaobo Gu and
                  Haibo Zhou},
	title = {Cooperative Positioning of Wireless Networks in Complex Propagation
                  Environments},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2877--2889},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414589},
	doi = {10.1109/JSAC.2024.3414589},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/JiangGZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cooperative positioning in wireless networks has attracted great attention in recent years, as many applications require the exact location of all member nodes. The pairwise distance between the member nodes is conventionally constructed as an Euclidean Distance Matrix (EDM) for subsequent location estimation. In this paper, we address the problem of cooperative positioning in complex propagation environments, which results in an incomplete EDM. We proposed an improved EDM recovery algorithm based on low tank matrix completion (LRMC), which makes use of the sensor correlation by Laplacian and trace minimization. In addition, we derive a semi-definite relaxation estimator to localize the unknown sensors. Simulations are conducted to evaluate the performance of the proposed algorithm and the results show that the proposed method outperforms existing ones in both matrix completion and positioning accuracy.}
}


@article{DBLP:journals/jsac/YuanYCZYCZN24,
	author = {Weijie Yuan and
                  Zhaohui Yang and
                  Liangming Chen and
                  Ruiheng Zhang and
                  Yiheng Yao and
                  Yuanhao Cui and
                  Hong Zhang and
                  Derrick Wing Kwan Ng},
	title = {Wireless Localization and Formation Control With Asynchronous Agents},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2890--2904},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414616},
	doi = {10.1109/JSAC.2024.3414616},
	timestamp = {Sun, 06 Oct 2024 21:33:56 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/YuanYCZYCZN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The formation control of multi-agent systems has increasingly drawn attention for fulfilling numerous emerging applications and services. To achieve high-accuracy formation, the location awareness of all agents becomes an essential requirement. In this paper, we address the problem of network localization and formation control in a cooperative system with asynchronous agents. In particular, we formulate the joint localization and synchronization of agents as a statistical inference problem. The underlying probabilistic model is represented by a factor graph from which a message-passing algorithm is designed that computes approximations of the marginals of unknown variables, i.e. agents’ locations and clock offsets. Due to the Euclidean-norm operator involved in their computation no parametric closed-form expressions of the messages exist. As a compromise, implemented message-passing methods therefore resort to approximations of these messages. Conventional methods rely either on a first-order Taylor expansion of the norm operation or on non-parametric representations, e.g. by means particle filters (PFs), to compute such approximations. However, the former approach suffers from poor performance while the latter one experiences high complexity. The proposed message-passing algorithm in this paper is parametric. Specifically, it passes Gaussian messages that can be essentially obtained by suitably augmenting the factor graph and applying on it a hybrid method for combining belief propagation and variational message passing. Subsequently, the agents can exploit the estimated locations for determining the control policy. Two types of control policy are designed based on the optimization of a generalized cost function. We show that the proposed scheme enjoys a reduced complexity for multi-agent localization while achieving the desired formation with excellent accuracy.}
}


@article{DBLP:journals/jsac/TagliaferriMMTGPS24,
	author = {Dario Tagliaferri and
                  Marco Manzoni and
                  Marouan Mizmizi and
                  Stefano Tebaldini and
                  Andrea Virgilio Monti Guarnieri and
                  Claudio Maria Prati and
                  Umberto Spagnolini},
	title = {Cooperative Coherent Multistatic Imaging and Phase Synchronization
                  in Networked Sensing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2905--2921},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414609},
	doi = {10.1109/JSAC.2024.3414609},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/TagliaferriMMTGPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Coherent multistatic radio imaging represents a pivotal opportunity for forthcoming wireless networks, which involves distributed nodes cooperating to achieve accurate sensing resolution and robustness. This paper delves into cooperative coherent imaging for vehicular radar networks. Herein, multiple radar-equipped vehicles cooperate to improve collective sensing capabilities and address the fundamental issue of distinguishing weak targets in close proximity to strong ones, a critical challenge for vulnerable road users’ protection. We prove the significant benefits of cooperative coherent imaging in the considered automotive scenario in terms of both probability of correct detection, evaluated considering several system parameters, as well as resolution capabilities, showcased by a dedicated experimental campaign wherein the collaboration between two vehicles enables the detection of the legs of a pedestrian close to a parked car. Moreover, as coherent processing of several sensors’ data requires very tight accuracy on clock synchronization and sensor’s positioning—referred to as phase synchronization—(such that to predict sensor-target distances up to a fraction of the carrier wavelength), we present a general three-step cooperative multistatic phase synchronization procedure, detailing the required information exchange among vehicles in the specific automotive radar context and assessing its feasibility and performance by hybrid Cramér-Rao bound.}
}


@article{DBLP:journals/jsac/GaoWL24,
	author = {Kaixuan Gao and
                  Huiqiang Wang and
                  Hongwu Lv},
	title = {Surgical Strike on 5G Positioning: Selective-PRS-Spoofing Attacks
                  and Its Defence},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2922--2937},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414592},
	doi = {10.1109/JSAC.2024.3414592},
	timestamp = {Thu, 03 Oct 2024 00:45:36 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/GaoWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a solution for city-range integrated sensing and communication and intelligent positioning, 5G high-precision positioning is flooding into reality. Nevertheless, the underlying positioning security concerns have been overlooked, posing threats to more than a billion emerging 5G localization applications. In this work, we first identify a novel and far-reaching security vulnerability affecting current 5G positioning systems. Correspondingly, we introduce a threat model, called the selective-PRS-spoofing attack (SPS), which can cause substantial localization errors or even fully-hijacked positioning results at victims. The attacker first cracks the broadcast information of a 5G network and then poisons specific resource elements of the channel. Different from traditional communication-oriented 5G attacks, SPS targets the localization and exerts real-world threats. More seriously, we confirm that SPS attacks can evade multiple latest 3GPP R18 defense, and analyze its great stealthiness from its precise spoofing feature. To tackle this challenge, a Deep Learning-based defence method called in-phase quadrature intra-attention network (IQIA-Net) is proposed, which utilizes the hardware features of base stations to perform identification at the physical level, thereby thwarting SPS attacks on 5G positioning systems. Extensive experiments demonstrate the effectiveness of our method and its good robustness to noise.}
}


@article{DBLP:journals/jsac/BaiGXLW24,
	author = {Jing Bai and
                  Jinsong Gui and
                  Neal N. Xiong and
                  Anfeng Liu and
                  Jie Wu},
	title = {{L3P-DLI:} {A} Lightweight Positioning-Privacy Protection Scheme With
                  Double-Layer Incentives for Wireless Crowd Sensing Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2938--2953},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414580},
	doi = {10.1109/JSAC.2024.3414580},
	timestamp = {Thu, 03 Oct 2024 00:45:37 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/BaiGXLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Crowd Sensing (MCS), as a promising sensing paradigm, significantly relies on wireless communication networks and widely distributed mobile workers to capture data from the surroundings. However, the positioning-dependent nature of most MCS tasks often requires workers to embed their positionings in reports, which may result in privacy leakage and a decline in their participation enthusiasm. Considering workers’ diverse perceptions of positioning privacy, in this paper we propose the Lightweight Positioning-Privacy Protection Scheme with Double-Layer Incentives (L3P-DLI) to meet their personalized privacy requirements in an efficient and low-cost way while stimulating their participation. To the best of our knowledge, this scheme is the first attempt to employ proxy forwarding to protect workers’ sensitive positionings while ensuring high-quality sensing results. Moreover, our double-layer incentivizing mechanism is elaborately designed to motivate workers to actively participate or serve as proxies. Specifically, the bidirectional auction between data collectors and proxies can safeguard the security of data collectors, and compensate for the potential privacy leakage cost of proxies helping to forward data. Additionally, the reverse auction mechanism enables the platform to reward recruited workers to compensate for their various costs. Extensive experiments conducted on real-world datasets validate that L3P-DLI effectively preserves workers’ positioning privacy while maximizing their income to encourage participation.}
}


@article{DBLP:journals/jsac/ZhangZSZLZG24,
	author = {Weiting Zhang and
                  Mingyang Zhao and
                  Zhuoyu Sun and
                  Chuan Zhang and
                  Jinwen Liang and
                  Liehuang Zhu and
                  Song Guo},
	title = {VSpatial: Enabling Private and Verifiable Spatial Keyword-Based Positioning
                  in 6G-Oriented IoT},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2954--2969},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414605},
	doi = {10.1109/JSAC.2024.3414605},
	timestamp = {Fri, 07 Feb 2025 10:18:47 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangZSZLZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For increasing Internet of Things (IoT) devices, 6G wireless technology aims for ubiquitous communications in which positioning services are necessary. Private spatial keyword-based positioning service is promising in 6G-oriented IoT since it positions users based on spatial locations and textual keywords while protecting user privacy. However, due to economic benefits or malicious attacks, positioning service providers may return erroneous or incomplete results, which cause tremendous economic damage and security threats, e.g., always assigning a selective driver for the specific car-hailing user. A technical challenge for extending existing private schemes to enable users to verify the correctness and completeness of positioning results is the distinctive positioning paradigm between compared spatial locations and matched textual keywords. This paper proposes a private and verifiable spatial keyword positioning scheme named VSpatial in 6G-oriented IoT. VSpatial enables users to verify the correctness and completeness of spatial keyword-based positioning results while preserving user privacy. The main inspiration for addressing the technical challenge is converting both spatial locations and textual keywords into an internal status, i.e., adapting comparison and matching to existence judging by multiple cryptographic tools, such as hierarchical cube and pseudorandom function. Based on this inspiration, we design a novel private authenticated data structure (named PVTree), and then propose two constructions of VSpatial, i.e., VSpatial-S and VSpatial-D, to suit static and dynamic environments, respectively. The core idea for adapting VSpatial-S to VSpatial-D is transferring one whole PVTree into multiple exponential-size partitions. Security analysis proves the security and verifiability of VSpatial. Theoretical and experimental evaluations show that VSpatial achieves faster-than-linear positioning efficiency and linear verification overhead.}
}


@article{DBLP:journals/jsac/HuJCZXLLL24,
	author = {Jingyang Hu and
                  Hongbo Jiang and
                  Siyu Chen and
                  Qibo Zhang and
                  Zhu Xiao and
                  Daibo Liu and
                  Jiangchuan Liu and
                  Bo Li},
	title = {WiShield: Privacy Against Wi-Fi Human Tracking},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {10},
	pages = {2970--2984},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3414597},
	doi = {10.1109/JSAC.2024.3414597},
	timestamp = {Sun, 06 Oct 2024 21:33:55 +0200},
	biburl = {https://dblp.org/rec/journals/jsac/HuJCZXLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wi-Fi signals contain information about the surrounding propagation environment and have been widely used in various sensing applications such as gesture recognition, respiratory monitoring, and indoor position. Nevertheless, this information can also be easily stolen by eavesdroppers to obtain private information. In this paper, we propose WiShield, a new framework that protects legitimate users using Wi-Fi sensing applications while preventing unauthorized privacy attacks. The implementation of WiShield is based on a simple principle of physically encrypting Wi-Fi channel status information (CSI) to prevent eavesdroppers from inferring sensitive information through stolen CSI. To achieve a balance between encryption strength, sensing accuracy, and communication quality, we design an efficient multi-objective optimization framework that can safely deliver decryption keys to legitimate users and prevent illegal eavesdropping by eavesdroppers. We implemented the WiShield prototype on an SDR platform and conducted extensive experiments to verify its effectiveness in common Wi-Fi sensing applications. We believe that the implementation of WiShield can improve the privacy standards of Wi-Fi sensing applications, and it is also an important step towards making the integration of Integrated Sensing and Communications (ISAC).}
}


@article{DBLP:journals/jsac/LiuCHSJY24,
	author = {Ya{-}Feng Liu and
                  Tsung{-}Hui Chang and
                  Mingyi Hong and
                  Anthony Man{-}Cho So and
                  Eduard A. Jorswieck and
                  Wei Yu},
	title = {Guest Editorial Advanced Optimization Theory and Algorithms for Next-Generation
                  Wireless Communication Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {2987--2991},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3443808},
	doi = {10.1109/JSAC.2024.3443808},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuCHSJY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SECTION I.\nAbout the Special Issue\nMathematical optimization is now widely recognized as an indispensable tool for modeling and solving design challenges in wireless communication systems. Revolutionary innovations in wireless communication technologies and systems—from 1G to 5G and onto the future 6G—have significantly transformed the nature and structure of the underlying optimization problems and have also sparked many new ideas in the development of mathematical methodologies to understand, analyze, and solve these complex problems. This Special Issue (SI) focuses on advanced and novel optimization theory and algorithms for next-generation wireless communication networks, aiming at bringing together researchers and industry practitioners to share new ideas, latest findings, and state-of-the-art results as well as promoting the cross-fertilization of ideas in mathematical optimization and wireless communications.\nThis SI received 94 submissions, underscoring the significant importance of research on advanced mathematical optimization theory and algorithms for next-generation wireless communication networks. The review procedure for this SI comprised two stages. The first stage was the prescreening stage, where the relevance of the papers to the SI, i.e., whether the papers make sufficient contributions to either optimization theory and algorithms or novel applications of optimization techniques to wireless communication system design, was evaluated by the Guest Editors. The second stage was the peer-review stage, in which only those papers that passed the prescreening were reviewed by invited expert reviewers. Due to the tight publication schedule and limited available slots, only 19 papers were ultimately accepted for publication in this SI.\nThe SI begins with a survey paper [A1], in which Liu et al. provide a comprehensive survey of recent advances in nonconvex nonsmooth optimization, global optimization, distributed optimization, learning-based optimization, and their successful applications in wireless communication system design. Following this survey paper, there are 19 technical papers, which are grouped into three categories.\nNonconvex, Distributed, and Stochastic Optimization (nine papers).\nGlobal and Integer Optimization (five papers).\nLearning-Based Optimization (five papers).\nSECTION II.\nNonconvex, Distributed, and Stochastic Optimization\nIn [A2], Li et al. study the multiuser multi-input multi-output (MU-MIMO) beamforming design problem in the imperfect channel state information (CSI) case. A new approach to MU-MIMO beamforming that only uses a limited number of CSI data samples, called limited sample-based beamforming (LSBF), is proposed. The proposed LSBF bridges the true but unknown CSI distribution with the limited CSI data samples through the chance-constrained programming and the $\\infty $ -Wasserstein ambiguity set and is able to offer a guarantee to the users’ data rates for MU-MIMO beamforming. Simulation results show that the proposed LSBF can significantly improve the network performance while providing a probabilistic data rate guarantee to the users.\nIn [A3], Su et al. contribute to the field of distributed optimization theory in federated learning. In particular, the authors first develop a voting-based Top-K model compression algorithm tailored for accelerating the federated learning process in wireless environments. Then, a two-phase approach is introduced where, in Phase 1, clients vote for the most significant model updates, and in Phase 2, these updates are aggregated over-the-air. This method not only theoretically guarantees convergence under nonconvex loss conditions but also demonstrates significant improvements in communication efficiency and model accuracy compared to existing baselines. Additionally, the robustness of the proposed algorithm is verified under both IID and non-IID data distributions, showcasing its practical applicability in real-world federated learning scenarios.\nIn [A4], Han et al. introduce federated knowledge distillation enabled by adversarial learning (FedAL), a method that enhances collaborative learning among distributed clients with diverse local datasets and model architectures. FedAL uses a server as a discriminator in a min-max game to align clients’ model outputs, addressing issues caused by data heterogeneity. It also incorporates a less-forgetting regularization to prevent catastrophic forgetting during training and knowledge transfer. Experimental results show that FedAL outperforms traditional federated knowledge distillation methods in accuracy.\nIn [A5], Qiao et al. propose a massive digital over-the-air computation (MD-AirComp) scheme to integrate AirComp technology, which combines communication and computation over wireless networks. MD-AirComp utilizes vector quantization and shared codebooks to reduce communication overhead and employs a near-optimal algorithm at the receiver to compute model aggregation from superposed signals. When applied to federated edge learning (FEEL), MD-AirComp significantly accelerates FEEL convergence compared to state-of-the-art while using the same amount of communication resources.\nIn [A6], Xiong et al. contribute to the way from theoretical modeling and optimization of reconfigurable intelligent surface (RIS)-assisted multiuser systems via numerical assessments to practical experiment. In particular, the authors first develop a geometric optics-based model and problem formulation. Then, a max-min optimization algorithm based on Moreau-Yosida approximation is developed. Finally, the fair beam redistribution function of the RIS is numerically assessed and its performance is compared to baseline schemes. Additionally, the fair beam allocation framework is implemented and validated on a prototype experimental system.\nIn [A7], Shen et al. conduct an in-depth study of quadratic transform-type methods for solving a class of sum-of-weighted-ratios fractional programming problems. First, they design a new nonhomogeneous quadratic transform method and provide geometric insights into why it can be more advantageous than the existing quadratic transform method. Moreover, by leveraging Nesterov’s extrapolation technique, they obtain an accelerated version of their method. Second, they present the first convergence rate analysis of the quadratic transform method, which sheds light on its convergence performance. Third, they demonstrate the numerical advantage of their accelerated method through contemporary applications in wireless communications.\nIn [A8], Hou and Zhang study secure integrated sensing and communication for multiple-antenna base stations (BSs) in the scenario where the location of the target is unknown and random while the statistical information is known. The posterior Cramér-Rao bound is derived, including a closed-form tight approximation. Then, a nonconvex worst-case secrecy rate maximization problem over the unknown eavesdropper and target locations is formulated. The problem is solved by Charnes-Cooper transform and tight semi-definite relaxation (SDR). Low-complexity suboptimal algorithms are derived, too. Numerical assessments illustrate the achieved performance.\nIn [A9], Shan et al. study the radio-frequency (RF) energy harvest systems where the devices operate in harvest-then-transmission mode. The paper reveals the structural properties of the optimal timing between harvest and transmission and uses these properties to design online heuristic scheduling algorithms for time-varying RF-powered systems.\nIn [A10], Peng et al. propose a digital twin-assisted architecture for heterogeneous edge networks, aiming at minimizing the long-term energy consumption by jointly optimizing transmit power and computational resources. A long-term queue-aware energy minimization scheme is designed to address stochastic optimization problems by leveraging Lyapunov optimization methods, which transform the original problem with long-term time constraints into a deterministic upper bound problem for each time slot. Simulation results demonstrate the superiority of the proposed scheme over several benchmark schemes.\nSECTION III.\nGlobal and Integer Optimization\nIn [A11], Sun et al. study the age-of-information (AoI) optimization problem in multi-source energy harvesting networks. Closed-form expressions for average AoI are derived and based on them, two policies, the max energy-aware weight policy, and the energy-aware Whittle’s index policy, are further proposed for perfect and uncertain wireless channels, respectively, which are shown to achieve optimal or near-optimal AoI performance. Simulation results show that both of the proposed policies perform close to the theoretical lower bound and outperform several state-of-the-art schemes.\nIn [A12], Pachler et al. present a cooperative framework that tackles both the satellite routing and frequency assignment problems simultaneously, utilizing graph clustering and integer optimization techniques to maximize the system performance while mitigating self-interference within and between satellites. Simulation results demonstrate that the proposed collaborative approach outperforms other existing ones in terms of the system throughput and power consumption.\nIn [A13], Zhou et al. explore the use of quantum annealer to decode polar codes by transforming the decoding problem into a quadratic unconstrained binary optimization (QUBO) problem. The authors use the binary cross-entropy function to model the receiver constraints and further model the cyclic redundancy check polynomial in the QUBO form.\nIn [A14], Ren et al. study two technologies under consideration for 6G mobile communications, namely cell-free and integrated sensing and communications. While security is taken into account, the paper proposes an optimization problem to maximize the detection probability ensuring signal-to-interference-plus-noise-ratio (SINR) requirements at the communication users. To model the security aspect, the authors impose maximum tolerable SNR constraints at information eavesdroppers. The resulting joint transmit beamforming problem is highly nonconvex. The problem is tackled by SDR, and it is proved that the global optimum is achieved. Numerical simulations illustrate significant gains compared to benchmark schemes.\nIn [A15], Ferreira et al. contribute to the field of energy efficiency (EE) optimization in radio access networks. In particular, the authors first formulate the optimization problem as a mixed-integer geometric program (MIGP), which optimizes multiple system variables such as user association, working bandwidth, and BS transmission powers simultaneously. Then, they propose a piecewise concave approximation of the Shannon-Hartley formula and apply a variable transformation to convert the problem into a convex program when user-BS associations are provided. Finally, extensive evaluations in realistic scenarios based on data from a major European operator demonstrate the effectiveness of the proposed method in reducing the energy footprint of heterogeneous networks.\nSECTION IV.\nLearning-Based Optimization\nIn [A16], Yu et al. introduce an optimization framework based on radial basis function (RBF) to enhance EE of future 6G networks. Unlike traditional methods that optimize EE directly, this framework aims to maximize a metric called integrated relative energy efficiency (IREE) by transforming utility values using an RBF network that focuses on spectrum efficiency (SE). Numerical experiments demonstrate that the proposed IREE metric surpasses existing SE or EE designs and reveals a new region governed by Jensen-Shannon divergence, offering a different perspective from typical EE-SE trade-off regions.\nIn [A17], Ma et al. contribute to the field of federated learning by addressing the challenges posed by data heterogeneity in edge computing environments. Specifically, the authors first develop a framework called FlocOff, which leverages computation offloading to mitigate data heterogeneity and optimize federated learning processes. Then, they formulate the optimization problem in two steps: First minimizing the Kullback-Leibler divergence via computation offloading scheduling to reshape edge datasets, followed by scheduling the resources to enhance communication efficiency. Extensive experimental results demonstrate that FlocOff significantly improves model convergence and accuracy, with significant robustness across various heterogeneous data distributions.\nIn [A18], Liang et al. present an unsupervised deep learning approach for optimizing transmit beamforming in multiuser multi-input single-output downlink transmissions with channel uncertainties. Unlike traditional methods that rely on conservative convex approximations, this approach uses a model-driven learning framework with a novel beamforming structure and graph neural networks to efficiently infer key parameters. It addresses both the minimum rate quantile maximization and power minimization problems with probabilistic rate constraints. Numerical results demonstrate that this method achieves robust performance, higher data rates, greater power efficiency, and faster execution than existing optimization techniques.\nIn [A19], Peng et al. study the goal-oriented status updating problem, which aims to promote the timeliness and relevance of information in communications. They give a semi-Markov decision process formulation of the problem and provide insight into the structure of the optimal policy. Furthermore, in the absence of statistical information about the system parameters, they give an online learning formulation of the problem and develop a performance analysis for it. The numerical superiority of the proposed approach is demonstrated through an extensive comparison with existing methods.\nIn [A20], Zhang et al. study caching content at the mobile edge in next-generation wireless networks. The constraints at edge nodes in terms of storage and computational power at user equipment lead to stochastic and robust optimization problems. The problem is tackled by combining reliable reinforcement learning with digital twins. The network digital twins act as data-driven optimizers and safeguards for the wireless caching. Analytical results are developed to show convergence of the data-driven models as well as wireless caching performance guarantees under network reliability. Numerical experiments show the performance gains in terms of cache hit rate and load balance.\nACKNOWLEDGEMENT\nThe Guest Editorial team would like to thank all authors for their high-quality submissions and all reviewers for their time and efforts in improving the quality of the manuscripts. The Guest Editors are also deeply grateful to Prof. Ravi Mazumdar, the Senior Editor for this SI, and Prof. Petar Popovski, the Editor-in-Chief of IEEE Journal on Selected Areas in Communications, for their invaluable support and assistance throughout the organization and handling procedure of this SI.\nAppendix A\nRelated Articles\nY.-F. Liu et al., “A survey of recent advances in optimization methods for wireless communications,” IEEE J. Sel. Areas Commun., early access, Aug. 14, 2024, doi: 10.1109/JSAC.2024.3443759.\nS. Li, N. Jiang, Y. Chen, W. Xie, W. Lou, and Y. T. Hou, “MU-MIMO beamforming with limited channel data samples,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431515.\nX. Su, Y. Zhou, L. Cui, Q. Z. Sheng, Y. Wang, and S. Guo, “Fastconvergent wireless federated learning: A voting based TopK model compression approach,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431568.\nP. Han, X. Shi, and J. Huang, “FedAL: Black-box federated knowledge distillation enabled by adversarial learning,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431516.\nL. Qiao, Z. Gao, M. B. Mashhadi, and D. Güundüz, “Massive digital over-the-air computation for communication-efficient federated edge learning,” IEEE J. Sel. Areas Commun., early access, Aug. 26, 2024, doi: 10.1109/JSAC.2024.3431572.\nR. Xiong, K. Yin, T. Mi, J. Lu, K. Wan, and R. C. Qiu, “Fair beam allocations through reconfigurable intelligent surfaces,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431580.\nK. Shen, Z. Zhao, Y. Chen, Z. Zhang, and H. V. Cheng, “Accelerating quadratic transform and WMMSE,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431523.\nK. Hou and S. Zhang, “Optimal beamforming for secure integrated sensing and communication exploiting target location distribution,” IEEE J. Sel. Areas Commun., early access, Aug. 19, 2024, doi: 10.1109/JSAC.2024.3431573.\nF. Shan et al., “Optimal harvest-then-transmit scheduling for throughput maximization in time-varying RF powered systems,” IEEE J. Sel. Areas Commun., early access, Aug. 29, 2024, doi: 10.1109/JSAC.2024.3431569.\nY. Peng, J. Duan, J. Zhang, W. Li, Y. Liu, and F. Jiang, “Stochastic long-term energy optimization in digital twin-assisted heterogeneous edge networks,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431581.\nS. Sun, W. Wu, C. Fu, X. Qiu, J. Luo, and J. Wang, “AoI optimization in multi-source update network systems under stochastic energy harvesting model,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431518.\nN. Pachler, E. F. Crawley, and B. G. Cameron, “Avoiding selfinterference in megaconstellations through cooperative satellite routing and frequency assignment,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431571.\nH. Zhou, R. Seah, M. Jalaleddine, and W. J. Gross, “Decoding of polar codes using quadratic unconstrained binary optimization,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431579.\nZ. Ren, J. Xu, L. Qiu, and D. W. K. Ng, “Secure cell-free integrated sensing and communication in the presence of information and sensing eavesdroppers,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431582.\nG. O. Ferreira et al., “A joint optimization approach for powerefficient heterogeneous OFDMA radio access networks,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431524.\nT. Yu, P. Huang, S. Zhang, X. Chen, Y. Sun, and X. Wang, “IREE oriented green 6G networks: A radial basis function based approach,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431521.\nM. Ma, C. Gong, L. Zeng, Y. Yang, and L. Wu, “FlocOff: Data heterogeneity resilient federated learning with communication-efficient edge offloading,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431526.\nK. Liang, G. Zheng, Z. Li, K.-K. Wong, and C.-B. Chae, “A data and model-driven deep learning approach to robust downlink beamforming optimization,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431583.\nF. Peng, X. Wang, and X. Chen, “Online learning of goal-oriented status updating with unknown delay statistics,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024. 3431522.\nZ. Zhang, Y. Liu, Z. Peng, M. Chen, D. Xu, and S. Cui, “Digital twinassisted data-driven optimization for reliable edge caching in wireless networks,” IEEE J. Sel. Areas Commun., early access, Jul. 22, 2024, doi: 10.1109/JSAC.2024.3431575.}
}


@article{DBLP:journals/jsac/LiuCHWSJY24,
	author = {Ya{-}Feng Liu and
                  Tsung{-}Hui Chang and
                  Mingyi Hong and
                  Zheyu Wu and
                  Anthony Man{-}Cho So and
                  Eduard A. Jorswieck and
                  Wei Yu},
	title = {A Survey of Recent Advances in Optimization Methods for Wireless Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {2992--3031},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3443759},
	doi = {10.1109/JSAC.2024.3443759},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiuCHWSJY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mathematical optimization is now widely regarded as an indispensable modeling and solution tool for the design of wireless communications systems. While optimization has played a significant role in the revolutionary progress in wireless communication and networking technologies from 1G to 5G and onto the future 6G, the innovations in wireless technologies have also substantially transformed the nature of the underlying mathematical optimization problems upon which the system designs are based and have sparked significant innovations in the development of methodologies to understand, to analyze, and to solve those problems. In this paper, we provide a comprehensive survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. We begin by illustrating common features of mathematical optimization problems arising in wireless communication system design. We discuss various scenarios and use cases and their associated mathematical structures from an optimization perspective. We then provide an overview of recently developed optimization techniques in areas ranging from nonconvex optimization, global optimization, and integer programming, to distributed optimization and learning-based optimization. The key to successful solution of mathematical optimization problems is in carefully choosing or developing suitable algorithms (or neural network architectures) that can exploit the underlying problem structure. We conclude the paper by identifying several open research challenges and outlining future research directions.}
}


@article{DBLP:journals/jsac/LiJCXLH24,
	author = {Shaoran Li and
                  Nan Jiang and
                  Yongce Chen and
                  Weijun Xie and
                  Wenjing Lou and
                  Y. Thomas Hou},
	title = {{MU-MIMO} Beamforming With Limited Channel Data Samples},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3032--3047},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431515},
	doi = {10.1109/JSAC.2024.3431515},
	timestamp = {Mon, 03 Mar 2025 22:17:41 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiJCXLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Channel State Information (CSI) is a critical piece of information for MU-MIMO beamforming. However, CSI estimation errors are inevitable in practice. The random and uncertain nature of CSI estimation errors poses significant challenges to MU-MIMO beamforming. State-of-the-art works addressing such a CSI uncertainty can be categorized into model-based and data-driven works, both of which have limitations when providing a performance guarantee to the users. In contrast, this paper presents Limited Sample-based Beamforming (LSBF)—a novel approach to MU-MIMO beamforming that only uses a limited number of CSI data samples (without assuming any knowledge of channel distributions). Thanks to the use of CSI data samples, LSBF enjoys flexibility similar to data-driven approaches and can provide a theoretical guarantee to the users—a major strength of model-based approaches. To achieve both, LSBF employs chance-constrained programming (CCP) and utilizes the \\infty -Wasserstein ambiguity set to bridge the unknown CSI distribution with limited CSI samples. Through problem decomposition and a novel bilevel formulation for each subproblem based on limited CSI data samples, LSBF solves each subproblem with a binary search and convex approximation. We show that LSBF significantly improves the network performance while providing a probabilistic data rate guarantee to the users.}
}


@article{DBLP:journals/jsac/SuZCSWG24,
	author = {Xiaoxin Su and
                  Yipeng Zhou and
                  Laizhong Cui and
                  Quan Z. Sheng and
                  Yinggui Wang and
                  Song Guo},
	title = {Fast-Convergent Wireless Federated Learning: {A} Voting-Based TopK
                  Model Compression Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3048--3063},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431568},
	doi = {10.1109/JSAC.2024.3431568},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SuZCSWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has been extensively exploited in the training of machine learning models to preserve data privacy. In particular, wireless FL enables multiple clients to collaboratively train models by sharing model updates via wireless communication without exposing raw data. The state-of-the-art wireless FL advocates efficient aggregation of model updates from multiple clients by over-the-air computing. However, a significant deficiency of over-the-air aggregation lies in the infeasibility of TopK model compression given that top model updates cannot be aggregated directly before they are aligned according to their indices. In view of the fact that TopK can greatly accelerate FL, we design a novel wireless FL with voting based TopK algorithm, namely WFL-VTopK, so that top model updates can be aggregated by over-the-air computing directly. Specifically, there are two phases in WFL-VTopK. In Phase 1, clients vote their top model updates, based on which global top model updates can be efficiently identified. In Phase 2, clients formally upload global top model updates so that they can be directly aggregated by over-the-air computing. Furthermore, the convergence of WFL-VTopK is theoretically guaranteed under non-convex loss. Based on the convergence of WFL-VTopK, we optimize model utility subjecting to training time and energy constraints. To validate the superiority of WFL-VTopK, we extensively conduct experiments with real datasets under wireless communication. The experimental results demonstrate that WFL-VTopK can effectively aggregate models by only communicating 1%-2% top models updates, and hence significantly outperforms the state-of-the-art baselines. By significantly reducing the wireless communication traffic, our work paves the road to train large models in wireless FL.}
}


@article{DBLP:journals/jsac/HanSH24,
	author = {Pengchao Han and
                  Xingyan Shi and
                  Jianwei Huang},
	title = {FedAL: Black-Box Federated Knowledge Distillation Enabled by Adversarial
                  Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3064--3077},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431516},
	doi = {10.1109/JSAC.2024.3431516},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HanSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge distillation (KD) can enable collaborative learning among distributed clients that have different model architectures and do not share their local data and model parameters with others. Each client updates its local model using the average model output/feature of all client models as the target, known as federated KD. However, existing federated KD methods often do not perform well when clients’ local models are trained with heterogeneous local datasets. In this paper, we propose Federated knowledge distillation enabled by Adversarial Learning (FedAL) to address the data heterogeneity among clients. First, to alleviate the local model output divergence across clients caused by data heterogeneity, the server acts as a discriminator to guide clients’ local model training to achieve consensus model outputs among clients through a min-max game between clients and the discriminator. Moreover, catastrophic forgetting may happen during the clients’ local training and global knowledge transfer due to clients’ heterogeneous local data. Towards this challenge, we design the less-forgetting regularization for both local training and global knowledge transfer to guarantee clients’ ability to transfer/learn knowledge to/from others. Experimental results show that FedAL and its variants achieve higher accuracy than other federated KD baselines.}
}


@article{DBLP:journals/jsac/QiaoGMG24,
	author = {Li Qiao and
                  Zhen Gao and
                  Mahdi Boloursaz Mashhadi and
                  Deniz G{\"{u}}nd{\"{u}}z},
	title = {Massive Digital Over-the-Air Computation for Communication-Efficient
                  Federated Edge Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3078--3094},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431572},
	doi = {10.1109/JSAC.2024.3431572},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/QiaoGMG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over-the-air computation (AirComp) is a promising technology converging communication and computation over wireless networks, which can be particularly effective in model training, inference, and more emerging edge intelligence applications. AirComp relies on uncoded transmission of individual signals, which are added naturally over the multiple access channel thanks to the superposition property of the wireless medium. Despite significantly improved communication efficiency, how to accommodate AirComp in the existing and future digital communication networks, that are based on discrete modulation schemes, remains a challenge. This paper proposes a massive digital AirComp (MD-AirComp) scheme, that leverages an unsourced massive access protocol, to enhance compatibility with both current and next-generation wireless networks. MD-AirComp utilizes vector quantization to reduce the uplink communication overhead, and employs shared quantization and modulation codebooks. At the receiver, we propose a near-optimal approximate message passing-based algorithm to compute the model aggregation results from the superposed sequences, which relies on estimating the number of devices transmitting each code sequence, rather than trying to decode the messages of individual transmitters. We apply MD-AirComp to federated edge learning (FEEL), and show that it significantly accelerates FEEL convergence compared to state-of-the-art while using the same amount of communication resources.}
}


@article{DBLP:journals/jsac/XiongYMLWQ24,
	author = {Rujing Xiong and
                  Ke Yin and
                  Tiebin Mi and
                  Jialong Lu and
                  Kai Wan and
                  Robert Caiming Qiu},
	title = {Fair Beam Allocations Through Reconfigurable Intelligent Surfaces},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3095--3109},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431580},
	doi = {10.1109/JSAC.2024.3431580},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XiongYMLWQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A fair beam allocation framework through reconfigurable intelligent surfaces (RISs) is proposed, incorporating the Max-min criterion. This framework focuses on designing explicit beamforming functionalities through optimization. Firstly, realistic models, grounded in geometrical optics, are introduced to characterize the input/output behaviors of RISs, effectively bridging the gap between the requirements on explicit beamforming operations and their practical implementations. Then, a highly efficient algorithm is developed for Max-min optimizations involving quadratic forms. Leveraging the Moreau-Yosida approximation, we successfully reformulate the original problem and propose an iterative algorithm to obtain the optimal solution. A comprehensive analysis of the algorithm’s convergence is provided. Importantly, this approach exhibits excellent extensibility, making it readily applicable to address a broader class of Max-min optimization problems. Finally, numerical and prototype experiments are conducted to validate the effectiveness of the framework. With the proposed beam allocation framework and algorithm, we clarify that several crucial redistribution functionalities of RISs, such as explicit beam-splitting, fair beam allocation, and wide-beam generation, can be effectively implemented. These explicit beamforming functionalities have not been thoroughly examined previously.}
}


@article{DBLP:journals/jsac/ShenZCZC24,
	author = {Kaiming Shen and
                  Ziping Zhao and
                  Yannan Chen and
                  Zepeng Zhang and
                  Hei Victor Cheng},
	title = {Accelerating Quadratic Transform and {WMMSE}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3110--3124},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431523},
	doi = {10.1109/JSAC.2024.3431523},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ShenZCZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fractional programming (FP) arises in various communications and signal processing problems because several key quantities in these fields are fractionally structured, e.g., the Cramér-Rao bound, the Fisher information, and the signal-to-interference-plus-noise ratio (SINR). A recently proposed method called the quadratic transform has been applied to the FP problems extensively. The main contributions of the present paper are two-fold. First, we investigate how fast the quadratic transform converges. To the best of our knowledge, this is the first work that analyzes the convergence rate for the quadratic transform as well as its special case the weighted minimum mean square error (WMMSE) algorithm. Second, we accelerate the existing quadratic transform via a novel use of Nesterov’s extrapolation scheme. Specifically, by generalizing the minorization-maximization (MM) approach, we establish a subtle connection between the quadratic transform and the gradient projection, thereby further incorporating the gradient extrapolation into the quadratic transform to make it converge more rapidly. Moreover, the paper showcases the practical use of the accelerated quadratic transform with two frontier wireless applications: integrated sensing and communications (ISAC) and massive multiple-input multiple-output (MIMO).}
}


@article{DBLP:journals/jsac/HouZ24,
	author = {Kaiyue Hou and
                  Shuowen Zhang},
	title = {Optimal Beamforming for Secure Integrated Sensing and Communication
                  Exploiting Target Location Distribution},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3125--3139},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431573},
	doi = {10.1109/JSAC.2024.3431573},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HouZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study a secure integrated sensing and communication (ISAC) system where one multi-antenna base station (BS) simultaneously communicates with one single-antenna user and senses the location parameter of a target serving as a potential eavesdropper via its reflected echo signals. In particular, we consider a challenging scenario where the target’s location is unknown and random, while its distribution information is known a priori based on empirical data or target movement pattern. First, we derive the posterior Cramér-Rao bound (PCRB) of the mean-squared error (MSE) in target location sensing, which has a complicated expression. To draw more insights, we derive a tight approximation of the PCRB in closed form, which indicates that the transmit beamforming should achieve a “probability-dependent power focusing” effect over possible target locations. Next, considering an artificial noise (AN) based beamforming structure at the BS to alleviate information eavesdropping and enhance the target’s reflected signal power for sensing, we formulate the transmit beamforming optimization problem to maximize the worst-case secrecy rate among all possible target (eavesdropper) locations, subject to a maximum threshold on the sensing PCRB. The formulated problem is non-convex and difficult to solve. To deal with this problem, we first show that the problem can be solved via a two-stage method, by first obtaining the optimal beamforming corresponding to any given threshold on the signal-to-interference-plus-noise ratio (SINR) at the eavesdropper, and then obtaining the optimal threshold and consequently the optimal beamforming via one-dimensional search of the threshold. By applying the Charnes-Cooper equivalent transformation and semi-definite relaxation (SDR), we relax the first problem into a convex form and further prove that the rank-one relaxation is tight, based on which the optimal solution of the original beamforming optimization problem can be obtained via the two-stage method with polynomial-time complexity. Then, we further propose two suboptimal solutions with lower complexity by designing the information beam and/or AN beams in the null spaces of the possible eavesdropper channels and/or the user channel, respectively. Numerical results validate the effectiveness of our designs in achieving secure communication and high-quality sensing in the challenging scenario with unknown target (eavesdropper) location.}
}


@article{DBLP:journals/jsac/ShanLJCWLD24,
	author = {Feng Shan and
                  Junzhou Luo and
                  Qiao Jin and
                  Liwen Cao and
                  Weiwei Wu and
                  Zhen Ling and
                  Fang Dong},
	title = {Optimal Harvest-Then-Transmit Scheduling for Throughput Maximization
                  in Time-Varying {RF} Powered Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3140--3156},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431569},
	doi = {10.1109/JSAC.2024.3431569},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ShanLJCWLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Energy harvesting is a promising technique to address the energy hunger problem for thousands of wireless devices. In Radio Frequency (RF) energy harvesting systems, a wireless device first harvests energy and then transmits data with this energy, hence the ‘harvest-then-transmit’ (HTT) principle is widely adopted. We must carefully design the HTT schedule, i.e., schedule the timing between harvesting and transmission, and decide the data transmission power such that the throughput can be maximized with the limited harvested energy. Distinct from existing work, we assume energy harvested from RF sources is time-varying, which is more practical but more difficult to handle. We first discover a surprising result that the optimal transmission power is independent of the transmission time, but solely depends on the RF harvesting power, for a simple case when the energy harvesting is stable. We then obtain an optimal offline HTT-scheduling for the general case that allows the RF harvesting power to vary with time. To the best of our knowledge, it is the first optimal HTT-scheduling algorithm that achieves maximum data throughput for time-varying RF powered systems. Finally, an efficient online heuristic algorithm is designed based on the offline optimality properties. Simulations show that the proposed online algorithm has superior performance, which achieves more than 90% of the offline maximum throughput in most cases.}
}


@article{DBLP:journals/jsac/PengDZLLJ24,
	author = {Yingsheng Peng and
                  Jingpu Duan and
                  Jinbei Zhang and
                  Weichao Li and
                  Yong Liu and
                  Fuli Jiang},
	title = {Stochastic Long-Term Energy Optimization in Digital Twin-Assisted
                  Heterogeneous Edge Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3157--3171},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431581},
	doi = {10.1109/JSAC.2024.3431581},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/PengDZLLJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing (MEC) and digital twin (DT) technologies have been recognized as key enabling factors for the next generation of industrial Internet of Things (IoT) applications. In existing works, DT-assisted edge network resource optimization solutions mostly focus on short-term performance optimization, and long-term resource optimization has not been well studied. Thus, this paper introduces a digital twin-assisted heterogeneous edge network (DTHEN), aiming to minimize long-term energy consumption by jointly optimizing transmit power and computing resource. To solve the stochastic optimization problem, we propose a long-term queue-aware energy minimization (LQEM) scheme for joint communication and computing resource management. The proposed scheme uses Lyapunov optimization to transform the original problem with long-term time constraints into a deterministic upper bound problem for each time slot, decouples it into three independent sub-problems, and solves each sub-problem separately. We then theoretically prove the asymptotic optimality of the LQEM scheme and the tradeoff between system energy consumption and task queue backlog. Finally, experimental results verify the performance analysis of the LQEM scheme, demonstrating its superiority over several benchmark schemes, and reveal the impact of various parameters on the system.}
}


@article{DBLP:journals/jsac/SunWFQLW24,
	author = {Sujunjie Sun and
                  Weiwei Wu and
                  Chenchen Fu and
                  Xiaoxing Qiu and
                  Junzhou Luo and
                  Jianping Wang},
	title = {AoI Optimization in Multi-Source Update Network Systems Under Stochastic
                  Energy Harvesting Model},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3172--3187},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431518},
	doi = {10.1109/JSAC.2024.3431518},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SunWFQLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work studies the Age-of-Information (AoI) optimization problem in the information-gathering wireless network systems, where time-sensitive data updates are collected from multiple information sources, and each source is equipped with a battery and harvests energy from ambient energy, such as solar, wind, etc. The arrival of the harvested energy can be modeled as the stochastic process, and an information source can deliver its data update only when 1) there is energy in the battery, and 2) this source is selected to transmit its data update based on the transmission policy. This work analyzes how the energy arrival pattern of each source and the transmission policy jointly influence the average AoI among multiple sources. To the best of our knowledge, this is the first work that formally develops the closed-form expression of average AoI in the Stationary Randomized Sampling (SRS) policy space and proposes approximation schemes with constant ratios in multi-source systems under a stochastic energy harvesting model. More specifically, under the perfect wireless channel, the closed-form expression of AoI under the SRS policy space with arbitrary finite battery size is developed. Based on the result, we propose the Max Energy-Aware Weight (MEAW) policy, which is proven to achieve 2-approximation in the full policy space. Under the uncertain wireless channel, we develop the closed-form expression of Whittle’s index to address the target problem. Based on the result, we propose the Energy-aware Whittle’s index policy (EWIP) and prove its approximate performance by using the Lyapunov optimization techniques. Experimental results show that MEAW under the perfect channel setting and EWIP under the uncertain channel setting both perform close to the theoretical lower bound and outperform the state-of-the-art schemes.}
}


@article{DBLP:journals/jsac/PachlerCC24,
	author = {Nils Pachler and
                  Edward F. Crawley and
                  Bruce G. Cameron},
	title = {Avoiding Self-Interference in Megaconstellations Through Cooperative
                  Satellite Routing and Frequency Assignment},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3188--3203},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431571},
	doi = {10.1109/JSAC.2024.3431571},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/PachlerCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the reduced distance between satellites in modern megaconstellations, the potential for self-interference has emerged as a critical challenge that demands strategic solutions from satellite operators. The goal of this paper is to propose a cooperative framework that combines the Satellite Routing (i.e., mapping of beams to satellites) and Frequency Assignment (i.e., mapping of frequency spectrum to beams) strategies to mitigate self-interference both within and between satellites. This approach stands in contrast to current practices found in the literature, which address each problem independently and solely focus on intra-satellite interference. This study presents a novel methodology for addressing the Satellite Routing problem, specifically tailored for modern constellations to maximize capacity while effectively mitigating self-interference through the use of Integer Optimization. By combining this method with established Frequency Assignment techniques, the results demonstrate an increase in throughput of up to 138% for constellations such as SpaceX Starlink. Notably, the study reveals that relying on individual approaches to tackle interference may lead to undesired outcomes, underscoring the advantages of a cooperative framework. Through simulations, the study highlights the practicality and applicability of the proposed method under realistic operational conditions.}
}


@article{DBLP:journals/jsac/ZhouSJG24,
	author = {Huayi Zhou and
                  Ryan Seah and
                  Marwan Jalaleddine and
                  Warren J. Gross},
	title = {Decoding of Polar Codes Using Quadratic Unconstrained Binary Optimization},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3204--3216},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431579},
	doi = {10.1109/JSAC.2024.3431579},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhouSJG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Polar codes encounter challenges in decoder complexity while preserving good error-correction properties. Instead of conventional decoders, a quantum annealer (QA) decoder has been proposed to explore untapped possibilities. For future QA applications, a crucial prerequisite is transforming the optimization problem into quadratic unconstrained binary optimization (QUBO) form. However, existing QUBO forms for polar decoding result in suboptimal frame error rate (FER) performance for codes exceeding 8 bits. This paper redesigns the QUBO form for polar decoding. We first introduce a novel receiver constraint modeled by the binary cross-entropy (BCE) function. Utilizing a simulated annealing (SA) solver with the proposed QUBO form with BCE (QUBO-BCE) achieves maximum-likelihood (ML) performance for a code length of 32 bits. Next, to reduce the number of variables, we remove the frozen variables and introduce a simplified QUBO-BCE form (SQUBO-BCE). Additionally, CRC polynomials are modelled into constraints in QUBO form, resulting in a CRC-aided SQUBO-BCE (CA-SQUBO-BCE) form for polar decoding to further enhance the FER. Numerical results demonstrate that SQUBO-BCE achieves ML performance and reduces up to 61.5% of variables compared to QUBO-BCE. Furthermore, the proposed CA-SQUBO-BCE achieves near CRC-aided ML performance. The proposed SQUBO-BCE requires the lowest number of SA processes to reach a specific FER.}
}


@article{DBLP:journals/jsac/RenXQN24,
	author = {Zixiang Ren and
                  Jie Xu and
                  Ling Qiu and
                  Derrick Wing Kwan Ng},
	title = {Secure Cell-Free Integrated Sensing and Communication in the Presence
                  of Information and Sensing Eavesdroppers},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3217--3231},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431582},
	doi = {10.1109/JSAC.2024.3431582},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/RenXQN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies a secure cell-free integrated sensing and communication (ISAC) system, in which multiple ISAC transmitters collaboratively send confidential information to multiple communication users (CUs) and concurrently conduct target detection. Different from prior works investigating communication security against potential information eavesdropping, we consider the security of both communication and sensing in the presence of information and sensing eavesdroppers that aim to intercept confidential communication information and extract target information, respectively. Towards this end, we optimize the joint information and sensing transmit beamforming at these ISAC transmitters for secure cell-free ISAC. Our objective is to maximize the detection probability over a designated sensing area while ensuring the minimum signal-to-interference-plus-noise-ratio (SINR) requirements at CUs. Our formulation also takes into account the maximum tolerable signal-to-noise ratio (SNR) constraints at information eavesdroppers for ensuring the confidentiality of information transmission, and the maximum detection probability constraints at sensing eavesdroppers for preserving sensing privacy. The formulated secure joint transmit beamforming problem is highly non-convex due to the intricate interplay between the detection probabilities, beamforming vectors, and SINR constraints. Fortunately, through strategic manipulation and via applying the semidefinite relaxation (SDR) technique, we successfully obtain the globally optimal solution to the design problem by rigorously verifying the tightness of SDR. Furthermore, we present two alternative joint beamforming designs based on the sensing SNR maximization over the specific sensing area and the coordinated beamforming, respectively. Numerical results reveal the benefits of our proposed design over these alternative benchmarks.}
}


@article{DBLP:journals/jsac/FerreiraZBRDCWZF24,
	author = {Gabriel O. Ferreira and
                  Andr{\'{e}} Felipe Zanella and
                  Stefanos Bakirtzis and
                  Chiara Ravazzi and
                  Fabrizio Dabbene and
                  Giuseppe Carlo Calafiore and
                  Ian James Wassell and
                  Jie Zhang and
                  Marco Fiore},
	title = {A Joint Optimization Approach for Power-Efficient Heterogeneous {OFDMA}
                  Radio Access Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3232--3245},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431524},
	doi = {10.1109/JSAC.2024.3431524},
	timestamp = {Fri, 07 Feb 2025 08:54:37 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/FerreiraZBRDCWZF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous networks have emerged as a popular solution for accommodating the growing number of connected devices and increasing traffic demands in cellular networks. While offering broader coverage, higher capacity, and lower latency, the escalating energy consumption poses sustainability challenges. In this paper a novel optimization approach for orthogonal heterogeneous networks is proposed to minimize transmission power while respecting individual users’ throughput constraints. The problem is formulated as a mixed integer geometric program, and optimizes at once multiple system variables such as user association, working bandwidth, and base stations transmission powers. Crucially, the proposed approach becomes a convex optimization problem when user-base station associations are provided. Evaluations in multiple realistic scenarios from the production mobile network of a major European operator and based on precise channel gains and throughput requirements from measured data validate the effectiveness of the proposed approach. Overall, our original solution paves the road for greener connectivity by reducing the energy footprint of heterogeneous mobile networks, hence fostering more sustainable communication systems.}
}


@article{DBLP:journals/jsac/YuHZCSW24,
	author = {Tao Yu and
                  Pengbo Huang and
                  Shunqing Zhang and
                  Xiaojing Chen and
                  Yanzan Sun and
                  Xin Wang},
	title = {{IREE} Oriented Green 6G Networks: {A} Radial Basis Function-Based
                  Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3246--3261},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431521},
	doi = {10.1109/JSAC.2024.3431521},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/YuHZCSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to provide design guidelines for energy efficient 6G networks, we propose a novel radial basis function (RBF) based optimization framework to maximize the integrated relative energy efficiency (IREE) metric. Different from the conventional energy efficient optimization schemes, we maximize the transformed utility for any given IREE using spectrum efficiency oriented RBF network and gradually update the IREE metric using proposed Dinkelbach’s algorithm. The existence and uniqueness properties of RBF networks are provided, and the convergence conditions of the entire framework are discussed as well. Through some numerical experiments, we show that the proposed IREE outperforms many existing SE or EE oriented designs and find a new Jensen-Shannon (JS) divergence constrained region, which behaves differently from the conventional EE-SE region. Meanwhile, by studying IREE-SE trade-offs under different traffic requirements, we suggest that network operators shall spend more efforts to balance the distributions of traffic demands and network capacities in order to improve the IREE performance, especially when the spatial variations of the traffic distribution are significant.}
}


@article{DBLP:journals/jsac/MaGZYW24,
	author = {Mulei Ma and
                  Chenyu Gong and
                  Liekang Zeng and
                  Yang Yang and
                  Liantao Wu},
	title = {FlocOff: Data Heterogeneity Resilient Federated Learning With Communication-Efficient
                  Edge Offloading},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3262--3277},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431526},
	doi = {10.1109/JSAC.2024.3431526},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MaGZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has emerged as a fundamental learning paradigm to harness massive data scattered at geo-distributed edge devices in a privacy-preserving way. Given the heterogeneous deployment of edge devices, however, their data are usually Non-IID, introducing significant challenges to FL including degraded training accuracy, intensive communication costs, and high computing complexity. Towards that, traditional approaches typically utilize adaptive mechanisms, which may suffer from scalability issues, increased computational overhead, and limited adaptability to diverse edge environments. To address that, this paper instead leverages the observation that the computation offloading involves inherent functionalities such as node matching and service correlation to achieve data reshaping and proposes Federated learning based on computing Offloading (FlocOff) framework, to address data heterogeneity and resource-constrained challenges. Specifically, FlocOff formulates the FL process with Non-IID data in edge scenarios and derives rigorous analysis on the impact of imbalanced data distribution. Based on this, FlocOff decouples the optimization in two steps, namely: 1) Minimizes the Kullback-Leibler (KL) divergence via Computation Offloading scheduling (MKL-CO); 2) Minimizes the Communication Cost through Resource Allocation (MCC-RA). Extensive experimental results demonstrate that the proposed FlocOff effectively improves model convergence and accuracy by 14.3%-32.7% while reducing data heterogeneity under various data distributions.}
}


@article{DBLP:journals/jsac/LiangZLWC24,
	author = {Kai Liang and
                  Gan Zheng and
                  Zan Li and
                  Kai{-}Kit Wong and
                  Chan{-}Byoung Chae},
	title = {A Data and Model-Driven Deep Learning Approach to Robust Downlink
                  Beamforming Optimization},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3278--3292},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431583},
	doi = {10.1109/JSAC.2024.3431583},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiangZLWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the optimization of the probabilistically robust transmit beamforming problem with channel uncertainties in the multiuser multiple-input single-output (MISO) downlink transmission. This problem poses significant analytical and computational challenges. Currently, the state-of-the-art optimization method relies on convex restrictions as tractable approximations to ensure robustness against Gaussian channel uncertainties. However, this method not only exhibits high computational complexity and suffers from the rank relaxation issue but also yields conservative solutions. In this paper, we propose an unsupervised deep learning-based approach that incorporates the sampling of channel uncertainties in the training process to optimize the probabilistic system performance. We introduce a model-driven learning approach that defines a new beamforming structure with trainable parameters to account for channel uncertainties. Additionally, we employ a graph neural network to efficiently infer the key beamforming parameters. We successfully apply this approach to the minimum rate quantile maximization problem subject to outage and total power constraints. Furthermore, we propose a bisection search method to address the more challenging power minimization problem with probabilistic rate constraints by leveraging the aforementioned approach. Numerical results confirm that our approach achieves non-conservative robust performance, higher data rates, greater power efficiency, and faster execution compared to state-of-the-art optimization methods.}
}


@article{DBLP:journals/jsac/PengWC24,
	author = {Fuzhou Peng and
                  Xijun Wang and
                  Xiang Chen},
	title = {Online Learning of Goal-Oriented Status Updating With Unknown Delay
                  Statistics},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3293--3305},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431522},
	doi = {10.1109/JSAC.2024.3431522},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/PengWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of communication demand, goal-oriented communication goes beyond traditional bit-level approaches by emphasizing the significance of information and its relevance to specific goals. This paper addresses the goal-oriented status updating problem, where detecting status changes is crucial. We employ the Age of Changed Information (AoCI) as a metric, which considers both the timeliness and content of the update. Our goal is to minimize the weighted sum of AoCI and transmission cost without channel delay statistics. The investigated problem is formulated as a semi-Markov decision process (SMDP) and is tackled by converting it into a multi-variable optimization problem. We prove that the optimal updating policy is of threshold type, and derive a nearly closed-form expression for the optimal threshold. When delay statistics are available, the optimal threshold can be obtained by a bisection searching algorithm. In the absence of prior delay statistics, we develop an online learning policy. We demonstrate that the optimality gap decays at a rate of \\mathcal {O}(\\log K / K) , where K is the number of samples. Simulation results are presented to compare the performance of various policies under different statistical conditions, showcasing the superiority of our proposed algorithm.}
}


@article{DBLP:journals/jsac/ZhangLPCXC24,
	author = {Zifan Zhang and
                  Yuchen Liu and
                  Zhiyuan Peng and
                  Mingzhe Chen and
                  Dongkuan Xu and
                  Shuguang Cui},
	title = {Digital Twin-Assisted Data-Driven Optimization for Reliable Edge Caching
                  in Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {11},
	pages = {3306--3320},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3431575},
	doi = {10.1109/JSAC.2024.3431575},
	timestamp = {Sat, 30 Nov 2024 21:08:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangLPCXC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optimizing edge caching is crucial for the advancement of next-generation (nextG) wireless networks, ensuring high-speed and low-latency services for mobile users. Existing data-driven optimization approaches often lack awareness of the distribution of random data variables and focus solely on optimizing cache hit rates, neglecting potential reliability concerns, such as base station overload and unbalanced cache issues. This oversight can result in system crashes and degraded user experience. To bridge this gap, we introduce a novel digital twin-assisted optimization framework, called D-REC, which integrates reinforcement learning (RL) with diverse intervention modules to ensure reliable caching in nextG wireless networks. We first develop a joint vertical and horizontal twinning approach to efficiently create network digital twins, which are then employed by D-REC as RL optimizers and safeguards, providing ample datasets for training and predictive evaluation of our cache replacement policy. By incorporating reliability modules into a constrained Markov decision process, D-REC can adaptively adjust actions, rewards, and states to comply with advantageous constraints, minimizing the risk of network failures. Theoretical analysis demonstrates comparable convergence rates between D-REC and vanilla data-driven methods without compromising caching performance. Extensive experiments validate that D-REC outperforms conventional approaches in cache hit rate and load balancing while effectively enforcing predetermined reliability intervention modules.}
}


@article{DBLP:journals/jsac/XiaoXAAC24,
	author = {Yue Xiao and
                  Ming Xiao and
                  Mohamed{-}Slim Alouini and
                  Akram Al{-}Hourani and
                  Stefano Cioni},
	title = {Guest Editorial Integrated Ground-Air-Space Wireless Networks for
                  6G Mobile - Part {I}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3323--3326},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3468688},
	doi = {10.1109/JSAC.2024.3468688},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XiaoXAAC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SECTION I.\nIntroduction\nIn recent years, the pace of technological and scientific advancements has been unprecedented, leading to significant progress on various aspects of communication, from user experience (UE) to the services and applications being supported. With the widespread adoption and commercialization of the fifth-generation mobile communication network (5G), researchers are now focused on developing more advanced communication technologies to create an integrated network system that spans regions, airspace, and seas, towards true global coverage. However, current communication systems, including 5G non-terrestrial networks (NTN), fall short of this vision due to their limited access flexibility and high latency.\nTo address these challenges, the concept of space-air-ground integrated network (SAGIN) has been developed. This architecture leverages advancements in satellite technology, transportation systems, unmanned aerial vehicle (UAV), artificial intelligence (AI), security, and computing power networks to create a unified system that integrates satellites, airborne platforms, and terrestrial networks. By combining the strengths of traditional satellite communication with ground-based mobile communication, SAGIN uses its diverse components to enhance global coverage, reliability, and throughput. With its significant potential, SAGIN is poised to bring transformative changes to human society while offering numerous benefits for the development of 6G communications and services.\nMeanwhile, SAGIN has the potential to be applied across various practical domains, including earth observation and mapping, intelligent transportation systems (ITS), military operations, disaster relief, and more. Moreover, the SAGIN architecture is expected to enable 6G to deliver an improved user experience across all scenarios that demand wide-area broadband access, large-scale connectivity, time-sensitive communication, and high-precision positioning. This includes applications such as emergency communications, wide-area Internet of Things (IoT), ecological remote sensing, and the industrial Internet of Things (IIoT) which connects factories and machinery.\nThis Special Issue has received over 150 high-quality submissions from researchers around the world. Based on a rigorous review process, 52 submissions were selected for publication in double issues. Every submission received at least two reviews, and each accepted paper went through two review rounds.\nThe first part of this Special Issue contains 26 papers, mainly focusing on sensing and communications, scheduling, and spectrum management. In this guest editorial, we briefly review the research featured in this part. The papers included in this part are grouped into the following areas: satellite-assisted remote sensing and communications, scheduling of communication and computation, and spectrum management and engineering. The contributions of these papers are summarized in the following sections.\nPart I of this double issue starts with an overview paper [A1] written by the guest editorial team, which was reviewed by the Senior Editors of the IEEE Journal on Selected Areas in Communications. The paper provides a thorough examination of SAGIN for 6G by discussing the foundational architecture, key technologies, and emerging trends. It also highlights the potential challenges and future research directions in this field. We hope that this detailed survey on SAGIN-enabled 6G will serve as a valuable resource for researchers and practitioners, aiding in the advancement of this promising technology.\nSECTION II.\nSatellite-Assisted Remote Sensing and Communications\nIn [A2], Sun et al. introduce dynamic topology-informed pruning (DTIP), a novel framework that integrates differential privacy and graph pruning into graph neural networks, to optimize privacy, accuracy, and computational efficiency in satellite communications, demonstrating significant improvements in distributed learning across various datasets.\nIn [A3], Luo et al. propose an energy-efficient training algorithm, FedAAC, designed for the hierarchical collaborative learning system in low-earth orbit satellite constellations (LEO-HCL), which optimizes aggregation frequency and model compression to significantly improve convergence speed, reduce energy consumption, and cut down on communication overhead in the face of challenges like variable topology, limited resources, and stringent energy constraints.\nIn [A4], Mao et al. introduce a digital twin-enabled framework for an integrated space-air-ground network that utilizes UAVs and satellites to enhance data collection and computation for environmentally-aware applications, significantly improving latency and efficiency over existing methods.\nIn [A5], Li et al. propose a distributed collaborative beamforming (DCB)-based communication paradigm for ground-space direct communications, employing a multi-objective optimization and an evolutionary multi-objective deep reinforcement learning algorithm to enhance terminal-to-satellite uplink rates and manage energy and switching trade-offs.\nIn [A6], Zheng et al. investigate a sensing-enabled integrated space-air-ground data collection network, in which a UAV can not only work singly to sense data from multiple targets but also collaborate with an LEO satellite to collect communication data from multiple users.\nIn [A7], Dong et al. propose a stochastic geometry-based innovative model to characterize the impact of the finite-size distribution region of terrestrial terminals in the cooperative satellite-aerial-terrestrial network by jointly using a binomial point process (BPP) and a type-II Matérn hard-core point process (MHCPP).\nIn [A8], Zheng et al. investigate an integrated terrestrial and non-terrestrial wireless network that leverages LEO satellites and reconfigurable intelligent surfaces (RISs) to achieve simultaneous tracking of the 3D position, velocity, and orientation of user equipment, developing a Riemannian manifold-based unscented Kalman filter method to enhance tracking accuracy despite urban signal reception challenges.\nIn [A9], Gao et al. propose dynamic strategies for facilitating task hosting between mobile devices and UAVs, offloading computations, managing associations between UAVs and base stations (BSs), and allocating computing resources. The objective is to minimize the time-averaged network cost, considering the uncertainty of device locations, speeds, and even types.\nIn [A10], Xu et al. propose an efficient hashing multi-arm beam (HMB) training scheme to address the high complexity and low identification accuracy of existing beam training techniques. In addition, they logically prove that the traversal complexity is at the logarithmic level.\nIn [A11], Capez et al. propose a comprehensive framework to integrate LEO platforms with 6G NTNs. The study leverages the mega-constellation services in space (MCSS) paradigm, using expansive LEO mega-constellations such as Starlink and OneWeb, initially designed for terrestrial connectivity, to serve lower LEO spacecraft.\nIn [A12], Han et al. focus on the implementation of machine learning services in remote areas, deploying federated learning frameworks in space-air-ground integrated networks, and utilizing the computing power of the air and space layers to compensate for the insufficient computing power of ground users.\nSECTION III.\nScheduling of Communication and Computation\nIn [A13], Tao et al. propose an innovative approach for computing power scheduling in UAV-empowered aerial computing systems. The proposed multi-agent cooperation algorithms, including Q-learning and actor-critic-based deep reinforcement learning, offer promising solutions to enhance mission execution capabilities and user service quality.\nIn [A14], Chen et al. propose a traffic-aware lightweight hierarchical offloading framework towards adaptive slicing (THOAS), as a novel framework for adaptive resource management in SAGIN, featuring a separation into communication and computation offloading platforms, with a self-attention-based traffic prediction method and an enhanced deep reinforcement learning approach, significantly improving quality-of-service (QoS) and resource utilization compared to existing methods.\nIn [A15], Peng et al. introduce FastTS, as a scheduling strategy designed to optimize fault tolerance and time sensitivity in space-terrestrial integrated networks (STINs), which are pivotal in realizing the 6G vision. FastTS employs a heuristic approach to manage the complex problem of scheduling in such environments while integrating time-variant routing and frame replication and elimination for reliability (FRER) to ensure QoS under stringent resource constraints.\nIn [A16], Zhao et al. propose an energy-efficient, termed goal-directed hierarchical multi-agent deep reinforcement learning method, goal-directed multi-agent deep reinforcement learning vehicular crowdsensing (gMADRL-VCS), for an integrated ground-air-space vehicular crowdsensing campaign, aiming at optimizing the navigation policies and sensing strategies of UAVs to maximize data collection, ensure geographical fairness, and minimize energy consumption.\nIn [A17], Zhang et al. address the complexities and interference issues in large-scale satellite communication networks for 6G by developing AI-driven generative agents for system modeling and using a mixture of experts (MoE) approach for optimized transmission strategies, demonstrating enhanced performance and adaptability in simulations.\nIn [A18], Sun et al. propose a novel framework that leverages multi-functional reconfigurable intelligent surfaces (MF-RIS) to enhance mobile edge computing in integrated aerial-ground networks (MEC-IAGN), targeting global coverage and robust anti-jamming communication in the face of computation-intensive tasks and environmental challenges.\nIn [A19], Huang et al. investigate the fair resource allocation for hierarchical federated edge learning in space-air-ground integrated networks, where UAVs and LEO satellites are utilized as edge and cloud nodes for aggregation in this study.\nIn [A20], Yu et al. address the optimization of energy consumption in a system combining high altitude platform stations (HAPs) with mobile edge computing (MEC) and non-orthogonal multiple access (NOMA). They propose joint design schemes for resource allocation and two-dimensional horizontal positioning to minimize energy consumption under various constraints.\nIn [A21], Deng et al. investigate the beam hopping scheduling of satellites for the purpose of interference avoidance. The beam hopping scheduling of the integrated satellite-terrestrial wireless networks system is formulated as a throughput-driven beam hopping (TDBH) problem and a satisfaction-rate-driven beam hopping (SDBH) problem, respectively. In particular, the TDBH problem is decomposed into two sub-problems by relaxation, and a genetic algorithm is introduced to handle the SDBH problem.\nIn [A22], Wang et al. propose an intelligent cloud-edge collaborative framework for optimizing user association and power allocation in SAGINs using a novel multi-agent deep reinforcement learning algorithm. By considering communication latencies and enabling each access point (AP) to make fully independent decisions based on local information, the proposed algorithm enhances global energy efficiency (GEE) and reduces time complexity compared to existing methods.\nSECTION IV.\nSpectrum Management and Engineering\nIn [A23], He et al. explore the potential of symbiotic communication in an STIN, proposing centralized and distributed optimization algorithms to enhance the weighted sum rate (WSR) while ensuring mutual benefits for ground and satellite network operators through a mutual benefit constraint (MBC), demonstrating that these methods enable efficient and beneficial resource sharing.\nIn [A24], Al-Gunid et al. propose the NOMA-enabled integrated space-ground cellular networks with control- and user-plane separation (ISGCN-CUPS) architecture to address scalability issues in 6G networks, while presenting an analytical model that employs stochastic geometry to evaluate coverage probabilities and efficiencies.\nIn [A25], Wei et al. address the challenge of providing differentiated services via a unified UAV network in the 6G era by introducing a novel intelligent hierarchical UAV slicing framework that operates on two different time scales, enabling dynamic resource slicing and UAV placement, and employing distributed learning to optimize intra-slice resource adjustments, achieving superior performance in system utility, throughput, and transmission delay.\nIn [A26], Chamberlain et al. propose an economic and game-theoretic framework for spectrum sharing in space-air-ground integrated networks, prioritizing passive microwave sensors while providing tiered access for commercial users, to enhance spectrum efficiency and optimize network deployment in 6G environments.\nACKNOWLEDGMENT\nThe Guest Editors would like to express sincere gratitude to all the authors who submit their contributions to this Special Issue. They would like to thank all the reviewers who provided thorough and timely reviews. They extend their appreciation to Senior Editors and the Editor-in-Chief of IEEE Journal on Selected Areas in Communications for their support and guidance.\nAppendix:\nRelated Articles\nY. Xiao et al., “Space-air-ground integrated wireless networks for 6G: Basics, key technologies and future trends,” IEEE J. Sel. Areas Commun., Dec. 2024.\nJ. Sun et al., “An efficient privacy-aware split learning framework for satellite communications,” IEEE J. Sel. Areas Commun., early access, Sep. 16, 2024, doi: 10.1109/JSAC.2024.3459027.\nL. Luo et al., “Energy-efficient hierarchical collaborative learning over LEO satellite constellations,” IEEE J. Sel. Areas Commun., Dec. 2024.\nS. Mao, L. Liu, X. Hou, M. Atiquzzaman, and K. Yang, “Multidomain resource management for space-air-ground integrated sensing, communication and computation networks,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459026.\nJ. Li et al., “Collaborative ground-space communications via evolutionary multi-objective deep reinforcement learning,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459029.\nX. Zheng, Y. Wu, L. Fan, X. Lei, R. Q. Hu, and G. K. Karagiannidis, “Dual-functional UAV-empowered space-air-ground networks: Joint communication and sensing,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459079.\nW. Dong et al., “Stochastic geometry based modeling and analysis of uplink cooperative satellite-aerial-terrestrial networks for nomadic communications with weak satellite coverage,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459268.\nP. Zheng, X. Liu, and T. Y. Al-Naffouri, “LEO- and RISempowered user tracking: A Riemannian manifold approach,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459074.\nY. Gao, Z. Ye, and H. Yu, “Cost-efficient computation offloading in SAGIN: A deep reinforcement learning and perception-aided approach,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459073.\nY. Xu et al., “Hashing beam training for near-field integrated sensing and communication systems,” IEEE J. Sel. Areas Commun., Dec. 2024.\nG. M. Capez et al., “On the use of mega constellation services in space: Integrating LEO platforms into 6G non-terrestrial networks,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459078.\nD.-J. Han, W. Fang, S. Hosseinalipour, M. Chiang, and C. G. Brinton, “Orchestrating federated learning in space-air-ground integrated networks: Adaptive data offloading and seamless handover,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459090.\nM. Tao, X. Li, J. Feng, D. Lan, J. Du, and C. Wu, “Multi-agent cooperation for computing power scheduling in UAVs empowered aerial computing systems,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459035.\nZ. Chen et al., “Traffic-aware lightweight hierarchical offloading towards adaptive slicing-enabled SAGIN,” IEEE J. Sel. Areas Commun., Dec. 2024.\nG. Peng et al., “FastTS: Enabling fault-tolerant and timesensitive scheduling in space-terrestrial integrated networks,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459008.\nY. Zhao, C. H. Liu, T. Yi, G. Li, and D. Wu, “Energyefficient ground-air-space vehicular crowdsensing by hierarchical multi-agent deep reinforcement learning with diffusion models,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459039.\nR. Zhang et al., “Generative AI agents with large language models for satellite networks via a mixture of experts transmission,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459037.\nY. Sun et al., “Multi-functional RIS-assisted semantic anti-jamming communication and computing in integrated aerial-ground networks,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459028.\nC. Huang et al., “Fair resource allocation for hierarchical federated edge learning in space-air-ground integrated networks via deep reinforcement learning with hybrid control,” IEEE J. Sel. Areas Commun., Dec. 2024.\nX. Yu, X. Zhang, Y. Rui, K. Wang, X. Dang, and M. Guizani, “Joint resource allocations for energy consumption optimization in HAPS-aided MEC-NOMA systems,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024. 3459084.\nH. Deng et al., “Satellites beam hopping scheduling for interference avoidance,” IEEE J. Sel. Areas Commun., Dec. 2024.\nZ. Wang, L. Zhang, D. Feng, G. Wu, and L. Yang, “Intelligent cloud-edge collaborations for energy-efficient user association and power allocation in space-air-ground integrated networks,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459089.\nS. He, J. Ge, Y.-C. Liang, and D. Niyato, “Towards symbiotic STIN through inter-operator resource and service sharing: Joint orchestration of user association and radio resources,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459042.\nH. M. Al-Gunid et al., “NOMA-enabled integrated space-ground cellular networks architecture relying on Control- and user-plane separation,” IEEE J. Sel. Areas Commun., early access, Sep. 17, 2024, doi: 10.1109/JSAC.2024.3459092.\nF. Wei, G. Feng, S. Qin, Y. Peng, and Y. Liu, “Hierarchical network slicing for UAV-assisted wireless networks with deployment optimization,” IEEE J. Sel. Areas Commun., early access, Sep. 12, 2024, doi: 10.1109/JSAC.2024.3459055.\nJ. Chamberlain, D. Starobinski, and J. T. Johnson, “Facilitating spectrum sharing with passive satellite incumbents,” IEEE J. Sel. Areas Commun., early access, Sep. 16, 2024, doi: 10.1109/JSAC.2024.3459034.}
}


@article{DBLP:journals/jsac/XiaoYWLXAAC24,
	author = {Yue Xiao and
                  Ziqiang Ye and
                  Mingming Wu and
                  Haoyun Li and
                  Ming Xiao and
                  Mohamed{-}Slim Alouini and
                  Akram Al{-}Hourani and
                  Stefano Cioni},
	title = {Space-Air-Ground Integrated Wireless Networks for 6G: Basics, Key
                  Technologies, and Future Trends},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3327--3354},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3492720},
	doi = {10.1109/JSAC.2024.3492720},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XiaoYWLXAAC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the expansive deployment of ground base stations, low Earth orbit (LEO) satellites, and aerial platforms such as unmanned aerial vehicles (UAVs) and high altitude platforms (HAPs), the concept of space-air-ground integrated network (SAGIN) has emerged as a promising architecture for future 6G wireless systems. In general, SAGIN aims to amalgamate terrestrial nodes, aerial platforms, and satellites to enhance global coverage and ensure seamless connectivity. Moreover, beyond mere communication functionality, computing capability is increasingly recognized as a critical attribute of sixth generation (6G) networks. To address this, integrated communication and computing have recently been advocated as a viable approach. Additionally, to overcome the technical challenges of complicated systems such as high mobility, unbalanced traffics, limited resources, and various demands in communication and computing among different network segments, various solutions have been introduced recently. Consequently, this paper offers a comprehensive survey of the technological advances in communication and computing within SAGIN for 6G, including system architecture, network characteristics, general communication, and computing technologies. Subsequently, we summarize the pivotal technologies of SAGIN-enabled 6G, including the physical layer, medium access control (MAC) layer, and network layer. Finally, we explore the technical challenges and future trends in this field.}
}


@article{DBLP:journals/jsac/SunWMTCWF24,
	author = {Jianfei Sun and
                  Cong Wu and
                  Shahid Mumtaz and
                  Junyi Tao and
                  Mingsheng Cao and
                  Mei Wang and
                  Valerio Frascolla},
	title = {An Efficient Privacy-Aware Split Learning Framework for Satellite
                  Communications},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3355--3365},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459027},
	doi = {10.1109/JSAC.2024.3459027},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SunWMTCWF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the rapidly evolving domain of satellite communications, integrating advanced machine learning techniques, particularly split learning, is crucial for enhancing data processing and model training efficiency across satellites, space stations, and ground stations. Traditional ML approaches often face significant challenges within satellite networks due to constraints such as limited bandwidth and computational resources. To address this gap, we propose a novel framework for more efficient SL in satellite communications. Our approach, Dynamic Topology-Informed Pruning, namely DTIP, combines differential privacy with graph and model pruning to optimize graph neural networks for distributed learning. DTIP strategically applies differential privacy to raw graph data and prunes GNNs, thereby optimizing both model size and communication load across network tiers. Extensive experiments across diverse datasets demonstrate DTIP’s efficacy in enhancing privacy, accuracy, and computational efficiency. Specifically, on Amazon2M dataset, DTIP maintains an accuracy of 0.82 while achieving a 50% reduction in floating-point operations per second. Similarly, on ArXiv dataset, DTIP achieves an accuracy of 0.85 under comparable conditions. Our framework not only significantly improves the operational efficiency of satellite communications but also establishes a new benchmark in privacy-aware distributed learning, potentially revolutionizing data handling in space-based networks.}
}


@article{DBLP:journals/jsac/LuoZYLSL24,
	author = {Long Luo and
                  Chi Zhang and
                  Hongfang Yu and
                  Zonghang Li and
                  Gang Sun and
                  Shouxi Luo},
	title = {Energy-Efficient Hierarchical Collaborative Learning Over {LEO} Satellite
                  Constellations},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3366--3379},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459021},
	doi = {10.1109/JSAC.2024.3459021},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LuoZYLSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The hierarchical collaborative learning within Low Earth Orbit (LEO) satellite constellations, termed LEO-HCL, is gaining increasing popularity by integrating intra-orbit Inter-Satellite Links and orbital edge computing to alleviate the latency issues caused by intermittent satellite connectivity in satellite-ground training architectures. However, LEO-HCL systems are confronted with a triad of challenges: the variable topology induced by satellite mobility, limited onboard computing and communication resources, and stringent energy constraints. In response to these challenges, we propose an energy-efficient training algorithm called FedAAC, which adaptively optimizes both aggregation frequency and model compression ratio within the resource-constrained LEO network. We have conducted a theoretical analysis of model convergence and investigated the relationship between convergence, aggregation frequency, and model compression ratio. Building on this analysis, we offer an approximation algorithm that dynamically calculates the optimal aggregation frequency and compression ratio during the training process. Extensive simulations have demonstrated that FedAAC significantly outperforms existing methods, offering enhanced convergence speed and energy efficiency. Compared to prior solutions, FedAAC achieves a 60% reduction in energy consumption, a 70% decrease in training time, and a 52% lower communication overhead.}
}


@article{DBLP:journals/jsac/MaoLHAY24,
	author = {Sun Mao and
                  Lei Liu and
                  Xiangwang Hou and
                  Mohammed Atiquzzaman and
                  Kun Yang},
	title = {Multi-Domain Resource Management for Space-Air-Ground Integrated Sensing,
                  Communication, and Computation Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3380--3394},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459026},
	doi = {10.1109/JSAC.2024.3459026},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/MaoLHAY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To support emerging environmentally-aware intelligent applications, a massive amount of data needs to be collected by sensor devices and transmitted to edge/cloud servers for further computation and analysis. However, due to the high deployment and operational cost, only depending on terrestrial infrastructures cannot satisfy the communication and computation requirements of sensor devices in the unexpected and emergency situations. To tackle this issue, this paper presents a digital twin-enabled space-air-ground integrated sensing, communication and computation network framework, where unmanned aerial vehicles (UAVs) serve as aerial edge access point to provide wireless access and edge computing services for ground sensor devices, and satellites provide access to cloud data center. In order to tackle the complex network environments and coupled multi-dimensional resources, the digital twin technique is utilized to realize real-time network monitoring and resource management, and the mapping deviation is also considered. To realize real-time data sensing and analysis, we formulate a maximum execution latency minimization problem while satisfying the energy consumption constraints and network resource restrictions. Based on the block coordinate descent method and successive convex approximation technique, we develop an efficient algorithm to obtain the optimal sensing time, transmit power, bandwidth allocation, UAV deployment position, data assignment strategy, and computation capability allocation scheme. Simulation results demonstrate that the proposed method outperforms several benchmark methods in terms of maximum execution latency among all sensor devices.}
}


@article{DBLP:journals/jsac/LiSWNKJL24,
	author = {Jiahui Li and
                  Geng Sun and
                  Qingqing Wu and
                  Dusit Niyato and
                  Jiawen Kang and
                  Abbas Jamalipour and
                  Victor C. M. Leung},
	title = {Collaborative Ground-Space Communications via Evolutionary Multi-Objective
                  Deep Reinforcement Learning},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3395--3411},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459029},
	doi = {10.1109/JSAC.2024.3459029},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/LiSWNKJL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Low Earth Orbit (LEO) satellites have emerged as crucial enablers of direct connections with remote terrestrial terminals. However, energy limitations and insufficient antenna capabilities at the terminals often hamper these connections, resulting in inefficient communications and frequent ping-pong handovers. This paper proposes a Distributed Collaborative Beamforming (DCB)-based uplink communication paradigm for enabling ground-space direct communications. Specifically, DCB treats the terminals that are unable to establish efficient direct connections with the LEO satellites as distributed antennas, forming a virtual antenna array to enhance the terminal-to-satellite uplink achievable rates and durations. However, such systems need multiple trade-off policies that jointly balance the terminal-satellite uplink achievable rate, energy consumption of terminals, and satellite switching frequency to satisfy the scenario requirement changes. Thus, we formulate a long-term multi-objective optimization problem to optimize these goals simultaneously. To address availability in different terminal cluster scales, we reformulate this problem into an action space-reduced and universal Multi-Objective Markov Decision Process (MOMDP). Then, we propose an Evolutionary Multi-Objective Deep Reinforcement Learning (EMODRL) algorithm to obtain multiple policies, in which the low-value actions are masked to speed up the training process. Simulation results show that DCB enables terminals that cannot reach the uplink achievable rate threshold to achieve efficient direct uplink transmission. Moreover, the proposed algorithm outmatches various baselines and saves 30% handover frequency with a similar uplink achievable rate compared with the rate greedy method, which thus reveals that the proposed method is an effective solution for enabling direct ground-space communications.}
}


@article{DBLP:journals/jsac/ZhengWFLHK24,
	author = {Xiangdong Zheng and
                  Yuxin Wu and
                  Lisheng Fan and
                  Xianfu Lei and
                  Rose Qingyang Hu and
                  George K. Karagiannidis},
	title = {Dual-Functional UAV-Empowered Space-Air-Ground Networks: Joint Communication
                  and Sensing},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3412--3427},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459079},
	doi = {10.1109/JSAC.2024.3459079},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengWFLHK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate a sensing-enabled integrated space-air-ground (SAG) data collection network, in which an unmanned aerial vehicle (UAV) can not only work singly to sense data from multiple targets but also collaborate with a low-earth orbit (LEO) satellite to collect communication data from multiple users. Since the coverage of the UAV is much smaller than that of the LEO satellite, we first determine the set of usable users and targets for the UAV by analyzing the signal-to-noise ratios between the UAV and the users and targets. Based on this, we pose an optimization problem designed to maximize the total amount of data collected in the network while satisfying the constraints of UAV energy consumption, memory capacity, and minimum amount of sensor data per target. Moreover, considering that the network consists of three layers and the UAV has dual functions of communication and sensing, this problem is solved by jointly optimizing the scheduling of the users’ data upload scheme, the UAV trajectory, and the allocation of communication and sensing time. However, the formulated problem is a mixed integer nonlinear programming (MINLP) problem, so it is difficult to find the optimal solution. Therefore, we further design an alternating iterative optimization algorithm (AIOA) framework to find an appropriate solution. Specifically, we alternately optimize the UAV trajectory, time allocation strategy, and data upload schedule in each iteration. Finally, simulation experiments validate the effectiveness of the AIOA and its superiority over other benchmarks in terms of the amount of data collected.}
}


@article{DBLP:journals/jsac/DongYZC24,
	author = {Wen{-}Yu Dong and
                  Shaoshi Yang and
                  Ping Zhang and
                  Sheng Chen},
	title = {Stochastic Geometry Based Modeling and Analysis of Uplink Cooperative
                  Satellite-Aerial-Terrestrial Networks for Nomadic Communications With
                  Weak Satellite Coverage},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3428--3444},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459268},
	doi = {10.1109/JSAC.2024.3459268},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/DongYZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cooperative satellite-aerial-terrestrial networks (CSATNs), where unmanned aerial vehicles (UAVs) are utilized as nomadic aerial relays (A), are highly valuable for many important applications, such as post-disaster urban reconstruction. In this scenario, direct communication between terrestrial terminals (T) and satellites (S) is often unavailable due to poor propagation conditions for satellite signals, and users tend to congregate in regions of finite size. There is a current dearth in the open literature regarding the uplink performance analysis of CSATN operating under the above constraints, and the few contributions on the uplink model terrestrial terminals by a Poisson point process (PPP) relying on the unrealistic assumption of an infinite area. This paper aims to fill the above research gap. First, we propose a stochastic geometry based innovative model to characterize the impact of the finite-size distribution region of terrestrial terminals in the CSATN by jointly using a binomial point process (BPP) and a type-II Matérn hard-core point process (MHCPP). Then, we analyze the relationship between the spatial distribution of the coverage areas of aerial nodes and the finite-size distribution region of terrestrial terminals, thereby deriving the distance distribution of the T-A links. Furthermore, we consider the stochastic nature of the spatial distributions of terrestrial terminals and UAVs, and conduct a thorough analysis of the coverage probability and average ergodic rate of the T-A links under Nakagami fading and the A-S links under shadowed-Rician fading. Finally, the accuracy of our theoretical derivations are confirmed by Monte Carlo simulations. Our research offers fundamental insights into the system-level performance optimization for the realistic CSATNs involving nomadic aerial relays and terrestrial terminals confined in a finite-size region.}
}


@article{DBLP:journals/jsac/ZhengLA24,
	author = {Pinjun Zheng and
                  Xing Liu and
                  Tareq Y. Al{-}Naffouri},
	title = {{LEO-} and RIS-Empowered User Tracking: {A} Riemannian Manifold Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3445--3461},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459074},
	doi = {10.1109/JSAC.2024.3459074},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhengLA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Low Earth orbit (LEO) satellites and reconfigurable intelligent surfaces (RISs) have recently drawn significant attention as two transformative technologies, and the synergy between them emerges as a promising paradigm for providing cross-environment communication and positioning services. This paper investigates an integrated terrestrial and non-terrestrial wireless network that leverages LEO satellites and RISs to achieve simultaneous tracking of the three-dimensional (3D) position, 3D velocity, and 3D orientation of user equipment (UE). To address inherent challenges including nonlinear observation function, constrained UE state, and unknown observation statistics, we develop a Riemannian manifold-based unscented Kalman filter (UKF) method. This method propagates statistics over nonlinear functions using generated sigma points and maintains state constraints through projection onto the defined manifold space. Additionally, by employing Fisher information matrices (FIMs) of the sigma points, a belief assignment principle is proposed to approximate the unknown observation covariance matrix, thereby ensuring accurate measurement updates in the UKF procedure. Numerical results demonstrate a substantial enhancement in tracking accuracy facilitated by RIS integration, despite urban signal reception challenges from LEO satellites. In addition, extensive simulations underscore the superior performance of the proposed tracking method and FIM-based belief assignment over the adopted benchmarks. Furthermore, the robustness of the proposed UKF is verified across various uncertainty levels.}
}


@article{DBLP:journals/jsac/GaoYY24,
	author = {Yulan Gao and
                  Ziqiang Ye and
                  Han Yu},
	title = {Cost-Efficient Computation Offloading in {SAGIN:} {A} Deep Reinforcement
                  Learning and Perception-Aided Approach},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3462--3476},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459073},
	doi = {10.1109/JSAC.2024.3459073},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/GaoYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Space-Air-Ground Integrated Network (SAGIN), crucial to the advancement of sixth-generation (6G) technology, plays a key role in ensuring universal connectivity, particularly by addressing the communication needs of remote areas lacking cellular network infrastructure. This paper delves into the role of unmanned aerial vehicles (UAVs) within SAGIN, where they act as a control layer owing to their adaptable deployment capabilities and their intermediary role. Equipped with millimeter-wave (mmWave) radar and vision sensors, these UAVs are capable of acquiring multi-source data, which helps to diminish uncertainty and enhance the accuracy of decision-making. Concurrently, UAVs collect tasks requiring computing resources from their coverage areas, originating from a variety of mobile devices moving at different speeds. These tasks are then allocated to ground base stations (BSs), low-earth-orbit (LEO) satellite, and local processing units to improve processing efficiency. Amidst this framework, our study concentrates on devising dynamic strategies for facilitating task hosting between mobile devices and UAVs, offloading computations, managing associations between UAVs and BSs, and allocating computing resources. The objective is to minimize the time-averaged network cost, considering the uncertainty of device locations, speeds, and even types. To tackle these complexities, we propose a deep reinforcement learning and perception-aided online approach (DRL-and-Perception-aided Approach) for this joint optimization in SAGIN, tailored for an environment filled with uncertainties. The effectiveness of our proposed approach is validated through extensive numerical simulations, which quantify its performance relative to various network parameters.}
}


@article{DBLP:journals/jsac/XuHWYHYZYD24,
	author = {Yuan Xu and
                  Chongwen Huang and
                  Li Wei and
                  Zhaohui Yang and
                  Ahmed Al Hammadi and
                  Jun Yang and
                  Zhaoyang Zhang and
                  Chau Yuen and
                  M{\'{e}}rouane Debbah},
	title = {Hashing Beam Training for Integrated Ground-Air-Space Wireless Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3477--3489},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459088},
	doi = {10.1109/JSAC.2024.3459088},
	timestamp = {Wed, 08 Jan 2025 21:12:40 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/XuHWYHYZYD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In integrated ground-air-space (IGAS) wireless networks, numerous services require sensing knowledge including location, angle, distance information, etc., which usually can be acquired during the beam training stage. On the other hand, IGAS networks employ large-scale antenna arrays to mitigate obstacle occlusion and path loss. However, large-scale arrays generate pencil-shaped beams, which necessitate a higher number of training beams to cover the desired space. These factors motivate our investigation into the IGAS beam training problem to achieve effective sensing services. To address the high complexity and low identification accuracy of existing beam training techniques, we propose an efficient hashing multi-arm beam (HMB) training scheme. Specifically, we first construct an IGAS single-beam training codebook for the uniform planar arrays. Then, the hash functions are chosen independently to construct the multi-arm beam training codebooks for each AP. All APs traverse the predefined multi-arm beam training codeword simultaneously and the multi-AP superimposed signals at the user are recorded. Finally, the soft decision and voting methods are applied to obtain the correctly aligned beams only based on the signal powers. In addition, we logically prove that the traversal complexity is at the logarithmic level. Simulation results show that our proposed IGAS HMB training method can achieve 96.4% identification accuracy of the exhaustive beam training method and greatly reduce the training overhead.}
}


@article{DBLP:journals/jsac/CapezCABFFG24,
	author = {Gabriel Maiolini Capez and
                  Mauricio A. C{\'{a}}ceres and
                  Roberto Armellin and
                  Christopher P. Bridges and
                  Juan A. Fraire and
                  Stefan Frey and
                  Roberto Garello},
	title = {On the Use of Mega Constellation Services in Space: Integrating {LEO}
                  Platforms Into 6G Non-Terrestrial Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3490--3504},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459078},
	doi = {10.1109/JSAC.2024.3459078},
	timestamp = {Mon, 16 Dec 2024 21:58:20 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/CapezCABFFG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a framework for integrating Low-Earth Orbit (LEO) platforms with Non-Terrestrial Networks (NTNs) in the emerging 6G communication landscape. Our work applies the Mega-Constellation Services in Space (MCSS) paradigm, leveraging LEO mega-constellations’ expansive coverage and capacity, designed initially for terrestrial devices, to serve platforms in lower LEO orbits. Results show that this approach overcomes the limitation of sporadic and time-bound satellite communication links, a challenge not fully resolved by available Ground Station Networks and Data Relay Systems. We contribute three key elements: (i) a detailed MCSS evaluation framework employing Monte Carlo simulations to assess space user links and distributions; (ii) a novel Space User Terminal (SUT) design optimized for MCSS, using different configurations and 5G New Radio Adaptive Coding and Modulation; (iii) extensive results demonstrating MCSS’s substantial improvement over existing Ground Station Networks and Data Relay Systems, motivating its role in the upcoming 6G NTNs. The space terminal, incorporating a multi-system, multi-orbit, and software-defined architecture, can handle Terabit-scale daily data volumes and minute-scale latencies. It offers a compact, power-efficient solution for properly integrating LEO platforms as space internet nodes.}
}


@article{DBLP:journals/jsac/HanFHCB24,
	author = {Dong{-}Jun Han and
                  Wenzhi Fang and
                  Seyyedali Hosseinalipour and
                  Mung Chiang and
                  Christopher G. Brinton},
	title = {Orchestrating Federated Learning in Space-Air- Ground Integrated Networks:
                  Adaptive Data Offloading and Seamless Handover},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3505--3520},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459090},
	doi = {10.1109/JSAC.2024.3459090},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HanFHCB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Devices located in remote regions often lack coverage from well-developed terrestrial communication infrastructure. This not only prevents them from experiencing high quality communication services but also hinders the delivery of machine learning services in remote regions. In this paper, we propose a new federated learning (FL) methodology tailored to space-air-ground integrated networks (SAGINs) to tackle this issue. Our approach strategically leverages the nodes within space and air layers as both 1) edge computing units and 2) model aggregators during the FL process, addressing the challenges that arise from the limited computation powers of ground devices and the absence of terrestrial base stations in the target region. The key idea behind our methodology is the adaptive data offloading and handover procedures that incorporate various network dynamics in SAGINs, including the mobility, heterogeneous computation powers, and inconsistent coverage times of incoming satellites. We analyze the latency of our scheme and develop an adaptive data offloading optimizer, and also characterize the theoretical convergence bound of our proposed algorithm. Experimental results confirm the advantage of our SAGIN-assisted FL methodology in terms of training time and test accuracy compared with various baselines.}
}


@article{DBLP:journals/jsac/TaoLFLDW24,
	author = {Ming Tao and
                  Xueqiang Li and
                  Jie Feng and
                  Dapeng Lan and
                  Jun Du and
                  Celimuge Wu},
	title = {Multi-Agent Cooperation for Computing Power Scheduling in UAVs Empowered
                  Aerial Computing Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3521--3535},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459035},
	doi = {10.1109/JSAC.2024.3459035},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/TaoLFLDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the paradigm of ubiquitous edge computing, with those advantages, e.g., high mobility, fast response, flexibility and controllability, and low cost of use, Unmanned Aerial Vehicles (UAVs) could be used not only as relays to assist with data collection, but also as computing power nodes to process uncomplicated computational workloads from ground users. Especially, UAVs could be employed to provide alternative computing power resources in field, lake, post-disaster and other complex regional environments. In this paper, to address the issue of computing power scheduling in UAVs empowered aerial computing systems, a scenario where multiple UAVs from the same departure station cooperatively fly over hovering points and achieve the data collection and computation in a decentralized manner is investigated. Nevertheless, due to limited onboard battery capacities of UAVs and diverse service requests of ground users, it is necessary to optimize energy efficiency and service fairness for improving mission execution capabilities of UAVs and the quality of service (QoS) experienced by ground users, and a joint optimization problem of energy efficiency and service fairness is formulated. Through considering complex coupling associations among the departure station, flight paths and hovering points of UAVs, the problem is investigated from the trajectory planning of UAVs and the location planning for both the departure station and hovering points. Proving investigations to be Markov decision processes (MDP), multi-agent cooperation approaches are proposed as promising solutions, and simulation results have been shown to demonstrate that the performance achieved by the proposal outperforms that achieved by schemes commonly used in literatures.}
}


@article{DBLP:journals/jsac/ChenZMNL24,
	author = {Zheyi Chen and
                  Junjie Zhang and
                  Geyong Min and
                  Zhaolong Ning and
                  Jie Li},
	title = {Traffic-Aware Lightweight Hierarchical Offloading Toward Adaptive
                  Slicing-Enabled {SAGIN}},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3536--3550},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459020},
	doi = {10.1109/JSAC.2024.3459020},
	timestamp = {Fri, 07 Feb 2025 08:03:19 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChenZMNL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emerging Space-Air-Ground Integrated Networks (SAGIN) empower Mobile Edge Computing (MEC) with wider communication coverage and more flexible network access. However, the fluctuating user traffic and constrained computing architecture seriously hinder the Quality-of-Service (QoS) and resource utilization in SAGIN. Existing solutions generally depend on prior knowledge or adopt static resource provisioning, lacking adaptability and resulting in serious system overheads. To address these important challenges, we propose THOAS, a novel Traffic-aware lightweight Hierarchical Offloading framework towards Adaptive Slicing-enabled SAGIN. First, we innovatively separate SAGIN into Communication Access Platforms (CAPs) and Computation Offloading Platforms (COPs). Next, we design a new self-attention-based prediction method to accurately capture the traffic changes on each platform, enabling adaptive slice resource adjustments. Finally, we develop an improved deep reinforcement learning method based on proximal clipping with dynamic confidence intervals to reach optimal offloading. Notably, we employ knowledge distillation to compress offloading policies into lightweight networks, enhancing their adaptability in resource-limited SAGIN. Using real-world datasets of user traffic, extensive experiments are conducted. The results show that the THOAS can accurately predict traffic and make adaptive resource adjustments and offloading decisions, which outperforms other benchmark methods on multiple metrics under various scenarios.}
}


@article{DBLP:journals/jsac/PengWHLZHX24,
	author = {Guoyu Peng and
                  Shuo Wang and
                  Tao Huang and
                  Fengtao Li and
                  Kangzhe Zhao and
                  Yudong Huang and
                  Zehui Xiong},
	title = {FastTS: Enabling Fault-Tolerant and Time-Sensitive Scheduling in Space-Terrestrial
                  Integrated Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3551--3565},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459008},
	doi = {10.1109/JSAC.2024.3459008},
	timestamp = {Mon, 03 Mar 2025 22:17:41 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/PengWHLZHX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emerging space-terrestrial integrated network (STIN) assumes a pivotal role within the 6G vision, promising to deliver seamless global coverage and connectivity. Achieving advanced, high-reliability, and time-sensitive (TS) services in a resource-constrained and failure-prone space environment is critical, but also presents challenges. Existing space-terrestrial communication approaches either suffer from temporary link failures with unstable reliability, or intolerable service latency due to the extensive coverage and uneven traffic distribution. This paper presents FastTS, a heuristic resilient and performant scheduling strategy to achieve fault-tolerant and time-sensitive scheduling in futuristic STINs. First, we model the high-dynamic and failure-prone topology in space, and formulate the scheduling problem as a mixed non-linear problem with the objective of minimizing the average task completion time. To approach the optimal solution, joint time-variant routing and frame replication and elimination for reliability (FRER) redundancy under resource constraints are formally considered in our design. During the path-stable duration, FastTS prioritizes the multipath selection with higher redundancy scores, all while ensuring a bounded low latency for TS services based on time-sensitive networking (TSN) techniques. Specifically, our FastTS is divided into three phases: time-sensitive multipath generation (TMG), series-parallel redundancy scoring (SPRS), and SPRS-based time-variant routing (STR). Finally, simulation results show that FastTS exhibits outstanding performance improvements in terms of packet delay, scheduling success ratio, task completion time and packet loss rate, when compared to other state-of-the-art methods.}
}


@article{DBLP:journals/jsac/ZhaoLYLW24,
	author = {Yinuo Zhao and
                  Chi Harold Liu and
                  Tianjiao Yi and
                  Guozheng Li and
                  Dapeng Wu},
	title = {Energy-Efficient Ground-Air-Space Vehicular Crowdsensing by Hierarchical
                  Multi-Agent Deep Reinforcement Learning With Diffusion Models},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3566--3580},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459039},
	doi = {10.1109/JSAC.2024.3459039},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhaoLYLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The integrated ground-air-space (GAS) communications system can enhance post-disaster rescue and management efforts when traditional networks fail, by navigating unmanned ground vehicles (UGVs) and unmanned arieal vehicles (UAVs) to collaboratively collect sufficient data from point-of-interests (PoIs) in a timely manner. In this paper, we consider the GAS vehicular crowdsensing (VCS) campaign, where UGVs dispatch and callback UAVs periodically across multiple stops in the workzone, to maximize the total collected amount of data, geographic fairness while minimizing the energy consumption simultaneously. Specifically, we propose an energy-efficient, go-directed hierarchical multi-agent deep reinforcement learning (MADRL) method with discrete diffusion models called “gMADRL-VCS”, to optimize the high-level goal-conditioned navigation policies of UGVs, and the low-level long-term sensing strategies of UAVs. Extensive experimental results on two real-world datasets in Roma, Italy, and Hong Kong SAR, China show that gMADRL-VCS outperforms baselines in terms of energy efficiency, data collection ratio, energy consumption, and UAV-UGV cooperation factor.}
}


@article{DBLP:journals/jsac/ZhangDLNKXJK24,
	author = {Ruichen Zhang and
                  Hongyang Du and
                  Yinqiu Liu and
                  Dusit Niyato and
                  Jiawen Kang and
                  Zehui Xiong and
                  Abbas Jamalipour and
                  Dong In Kim},
	title = {Generative {AI} Agents With Large Language Model for Satellite Networks
                  via a Mixture of Experts Transmission},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3581--3596},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459037},
	doi = {10.1109/JSAC.2024.3459037},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ZhangDLNKXJK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In response to the needs of 6G global communications, satellite communication networks have emerged as a key solution. However, the large-scale development of satellite communication networks is constrained by complex system models, whose modeling is challenging for massive users. Moreover, transmission interference between satellites and users seriously affects communication performance. To solve these problems, this paper develops generative artificial intelligence (AI) agents for model formulation and then applies a mixture of experts (MoE) approach to design transmission strategies. Specifically, we leverage large language models (LLMs) to build an interactive modeling paradigm and utilize retrieval-augmented generation (RAG) to extract satellite expert knowledge that supports mathematical modeling. Afterward, by integrating the expertise of multiple specialized components, we propose an MoE-proximal policy optimization (PPO) approach to solve the formulated problem. Each expert can optimize the optimization variables at which it excels through specialized training through its own network and then aggregate them through the gating network to perform joint optimization. The simulation results validate the accuracy and effectiveness of employing a generative agent for problem formulation. Furthermore, the superiority of the proposed MoE-ppo approach over other benchmarks is confirmed in solving the formulated problem. The adaptability of MoE-PPO to various customized modeling problems has also been demonstrated.}
}


@article{DBLP:journals/jsac/SunLALLZNAW24,
	author = {Yifu Sun and
                  Zhi Lin and
                  Kang An and
                  Dong Li and
                  Cheng Li and
                  Yonggang Zhu and
                  Derrick Wing Kwan Ng and
                  Naofal Al{-}Dhahir and
                  Jiangzhou Wang},
	title = {Multi-Functional RIS-Assisted Semantic Anti-Jamming Communication
                  and Computing in Integrated Aerial-Ground Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3597--3617},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459028},
	doi = {10.1109/JSAC.2024.3459028},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/SunLALLZNAW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing-assisted integrated aerial-ground network (MEC-IAGN) emerges as a promising key component of the sixth-generation (6G) wireless networks due to its potential capabilities in providing ubiquitous connectivity for global coverage and computing services. However, the inevitable existences of computation-intensive tasks, uncontrollable propagation environment, and malicious jamming attacks pose three significant bottlenecks for enabling efficient MEC-IAGN. With these focuses, we propose a novel framework of multi-functional reconfigurable intelligent surface (MF-RIS) aided semantic anti-jamming communication and computing in MEC-IAGN. Under this framework, a semantic transceiver exhibits inherent robustness and data compression capability, and MF-RIS can customize the full-space wireless environment by leveraging its signal reflection, refraction, amplification, and energy harvesting functions, thereby achieving substantial global coverage, reliable connectivity, and high-rate computing. Based on our proposed framework, we formulate a semantic computation rate maximization problem considering the impacts of jammer’s channel state information (CSI) imperfection, while maintaining the energy partition constraint for computation offloading decision, semantic similarity requirement, semantic computation rate target, and MF-RIS’s self-sustainability. Then, by transforming the imperfect CSI into a worst-case one by exploiting a discretization method, we propose a fast-converging monotonic optimization algorithm that is combined with decoupling second-order cone programming to obtain a globally optimal solution with fewer feasibility evaluations. Furthermore, to strike a satisfactory tradeoff between performance and computational complexity, we develop a suboptimal generalized power iteration algorithm. Numerical simulations demonstrate the superiority of our proposed framework and algorithms compared to various benchmarks.}
}


@article{DBLP:journals/jsac/HuangCXCH24,
	author = {Chong Huang and
                  Gaojie Chen and
                  Pei Xiao and
                  Jonathon A. Chambers and
                  Wei Huang},
	title = {Fair Resource Allocation for Hierarchical Federated Edge Learning
                  in Space-Air-Ground Integrated Networks via Deep Reinforcement Learning
                  With Hybrid Control},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3618--3631},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459086},
	doi = {10.1109/JSAC.2024.3459086},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HuangCXCH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The space-air-ground integrated network (SAGIN) has become a crucial research direction in future wireless communications due to its ubiquitous coverage, rapid and flexible deployment, and multi-layer cooperation capabilities. However, integrating hierarchical federated learning (HFL) with edge computing and SAGINs remains a complex open issue to be resolved. This paper proposes a novel framework for applying HFL in SAGINs, utilizing aerial platforms and low Earth orbit (LEO) satellites as edge servers and cloud servers, respectively, to provide multi-layer aggregation capabilities for HFL. The proposed system also considers the presence of inter-satellite links (ISLs), enabling satellites to exchange federated learning models with each other. Furthermore, we consider multiple different computational tasks that need to be completed within a limited satellite service time. To maximize the convergence performance of all tasks while ensuring fairness, we propose the use of the distributional soft-actor-critic (DSAC) algorithm to optimize resource allocation in the SAGIN and aggregation weights in HFL. Moreover, we address the efficiency issue of hybrid action spaces in deep reinforcement learning (DRL) through a decoupling and recoupling approach, and design a new dynamic adjusting reward function to ensure fairness among multiple tasks in federated learning. Simulation results demonstrate the superiority of our proposed algorithm, consistently outperforming baseline approaches and offering a promising solution for addressing highly complex optimization problems in SAGINs.}
}


@article{DBLP:journals/jsac/YuZRWDG24,
	author = {Xiangbin Yu and
                  Xinyi Zhang and
                  Yun Rui and
                  Kezhi Wang and
                  Xiaoyu Dang and
                  Mohsen Guizani},
	title = {Joint Resource Allocations for Energy Consumption Optimization in
                  HAPS-Aided {MEC-NOMA} Systems},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3632--3646},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459084},
	doi = {10.1109/JSAC.2024.3459084},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/YuZRWDG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, the energy consumption (EC) optimization of an aerial high altitude platform station (HAPS) aided mobile edge computing (MEC) network with non-orthogonal multiple access (NOMA) in the presence of imperfect successive interference cancellation is studied. Specifically, joint design schemes of the resource allocation (RA) and the two-dimensional (2D) horizontal position are proposed to minimize the sum EC subject to the different constraint conditions. In particular, we jointly optimize the receive beamforming (BF), the power allocation (PA), HAPS position, the local computation resource, the computation task offload coefficient, and the computation resource allocated for each user via the block coordinate descent method. Namely, given the other optimization parameters, we first optimize a 2D position of HAPS. Then, given the 2D position, by introducing the auxiliary variables, a joint design of BF, PA, offload coefficient and computation resource is solved by an efficient iteration algorithm based on the successive convex approximation method. Additionally, a suboptimal joint design scheme is also developed to lower the complexity. Simulation results show that the proposed two design schemes of the joint RA and position are effective in reducing the EC, and they have a lower EC when compared to benchmark schemes.}
}


@article{DBLP:journals/jsac/DengYFGHX24,
	author = {Huimin Deng and
                  Kai Ying and
                  Daquan Feng and
                  Lin Gui and
                  Yuanzhi He and
                  Xiang{-}Gen Xia},
	title = {Satellites Beam Hopping Scheduling for Interference Avoidance},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3647--3658},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459083},
	doi = {10.1109/JSAC.2024.3459083},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/DengYFGHX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The deployment of low earth orbit (LEO) satellites megaconstellations presents a promising way for achieving global coverage and service, attributed to their comparatively low round-trip latency and launch costs. However, this surge in LEO satellite launches exacerbates the scarcity of the limited spectrum resources. Spectrum sharing between satellite constellations and terrestrial networks and beam hopping (BH) technology emerge as viable strategies to mitigate this spectrum shortage. To enhance spectrum efficiency and avoid serious inter-system interference, we investigate the beam hopping scheduling of satellites for interference avoidance. The beam hopping scheduling of the integrated satellite-terrestrial wireless networks system is formulated as throughput-driven beam hopping (TDBH) problem and satisfaction-rate-driven beam hopping (SDBH) problem, respectively. In particular, we decompose the TDBH problem into two sub-problems by relaxation, and a genetic algorithm (GA) is introduced to handle the SDBH problem. The impact of channel conditions and traffic load intensity on the satellite system throughput is analyzed in TDBH simulation. As for SDBH optimization problem, the simulation results show that the proposed GA algorithm improves the average traffic satisfaction rate by 16.96% at least, compared with other benchmarks and suits to scenarios with different traffic demands and fading channel conditions.}
}


@article{DBLP:journals/jsac/WangZFWY24,
	author = {Zicun Wang and
                  Lin Zhang and
                  Daquan Feng and
                  Gang Wu and
                  Lin Yang},
	title = {Intelligent Cloud-Edge Collaborations for Energy-Efficient User Association
                  and Power Allocation in Space-Air-Ground Integrated Networks},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3659--3673},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459089},
	doi = {10.1109/JSAC.2024.3459089},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WangZFWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In space-air-ground integrated networks (SAGINs), the global energy efficiency (GEE) is a crucial metric for balancing the network throughput and energy consumption, and the maximization of GEE requires the optimizations of both user association and power allocation. Most existing methods optimize user association and power allocation separately or successively, relying on instantaneous non-local channel state information (CSI) exchanges. Nevertheless, both the separate and successive methods may fail to find the jointly optimal solution, and acquiring the instantaneous non-local CSI across the SAGINs is challenging due to the long communication distances between the access points (APs) and users. To address these issues, we leverage cloud-edge collaborations and propose an online delayed-interaction collaborative-learning independent-decision multi-agent DRL (DICLID-MADRL) algorithm. With the proposed algorithm, each AP can independently select users and configure transmit power with only local information to enhance GEE. Simulation results demonstrate that the proposed algorithm achieves a higher GEE with reduced time complexity compared to the state of the arts.}
}


@article{DBLP:journals/jsac/HeGLN24,
	author = {Shizhao He and
                  Jungang Ge and
                  Ying{-}Chang Liang and
                  Dusit Niyato},
	title = {Toward Symbiotic {STIN} Through Inter-Operator Resource and Service
                  Sharing: Joint Orchestration of User Association and Radio Resources},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3674--3689},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459042},
	doi = {10.1109/JSAC.2024.3459042},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/HeGLN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The space-terrestrial integrated network (STIN) is a pivotal architecture to support ubiquitous connectivity in the upcoming 6G era. Inter-operator resource and service sharing is a promising way to realize such a huge network, utilizing resources efficiently and reducing construction costs. Given the rationality of operators, the configuration of resources and services in STIN should focus on both the overall system performance and individual benefits of operators. Motivated by emerging symbiotic communication facilitating mutual benefits across different radio systems, we investigate the resource and service sharing in STIN from a symbiotic communication perspective in this paper. In particular, we consider a STIN consisting of a ground network operator (GNO) and a satellite network operator (SNO). Specifically, we aim to maximize the weighted sum rate (WSR) of the whole STIN by jointly optimizing the user association, resource allocation, and beamforming. Besides, we introduce a sharing coefficient to characterize the revenue of operators. Operators may suffer revenue loss when only focusing on maximizing the WSR. In pursuit of mutual benefits, we propose a mutual benefit constraint (MBC) to ensure that each operator obtains revenue gains. Then, we develop a centralized algorithm based on the successive convex approximation (SCA) method. Considering that the centralized algorithm is difficult to implement, we propose a distributed algorithm based on Lagrangian dual decomposition and the consensus alternating direction method of multipliers (ADMM). Finally, we provide extensive numerical simulations to demonstrate the effectiveness of the two proposed algorithms, and the distributed optimization algorithm can approach the performance of the centralized one. The results also reveal that the proposed MBCs can enable operators to achieve mutual benefits and realize a symbiotic resource and service sharing paradigm.}
}


@article{DBLP:journals/jsac/AlGunidWHYSTZZ24,
	author = {Haithm M. Al{-}Gunid and
                  Xingfu Wang and
                  Ammar Hawbani and
                  Mingchuan Yang and
                  Mohammed A. M. Sultan and
                  Hui Tian and
                  Liqiang Zhao and
                  Liang Zhao},
	title = {NOMA-Enabled Integrated Space-Ground Cellular Networks Architecture
                  Relying on Control- and User-Plane Separation},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3690--3704},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459092},
	doi = {10.1109/JSAC.2024.3459092},
	timestamp = {Mon, 03 Mar 2025 22:17:40 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/AlGunidWHYSTZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid expansion of Internet of Everything (IoE) devices and the increasing demand for high-speed data and reliable communication services, particularly within 6G cellular networks (CNs), the design of efficient and robust CNs has become a critical research area. Consequently, enabling massive connections, optimizing network resource utilization, and achieving cost-effective network operation pose significant challenges. To this end, integrated space-ground cellular networks based on control- and user-plane separation (ISGCN-CUPS) architecture has been proposed as a promising solution. Furthermore, it becomes an integral aspect of the broader paradigm of integrated space-air-ground CNs (ISAGCNs). However, scalability poses an issue when increasing the number of connected cellular users, especially when conventional orthogonal multiple access (OMA) is utilized. To address this challenge, this paper introduces the non-orthogonal multiple access (NOMA)-enabled ISGCN-CUPS architecture. Subsequently, we provide an analytical model to analyze the scenarios of proposed architecture. Utilizing stochastic geometry, we derive closed-forms for coverage probabilities over control and data channels, by considering the propagation channel models for control and data channels, both with and without interference. Furthermore, total area spectral and energy efficiencies are computed. The proposed architecture demonstrates significant enhancements in terms of the key evaluation metrics compared to conventional and OMA-enabled ISGCN-CUPS architectures.}
}


@article{DBLP:journals/jsac/WeiFQPL24,
	author = {Fengsheng Wei and
                  Gang Feng and
                  Shuang Qin and
                  Youkun Peng and
                  Yijing Liu},
	title = {Hierarchical Network Slicing for UAV-Assisted Wireless Networks With
                  Deployment Optimization},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3705--3718},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459055},
	doi = {10.1109/JSAC.2024.3459055},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/WeiFQPL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned aerial vehicle (UAV) has been recognized as a key supplement for terrestrial networks to meet the stringent requirements of the forthcoming 6G networks. However, a significant challenge lies in providing differentiated services through a common UAV network, without the need to deploy individual networks for each service type. In this paper, we consider the problem of joint network slicing and UAV deployment under dynamic wireless environments as well as the uncertain traffic demands. To overcome the challenges posed by the network dynamics, we propose an intelligent hierarchical UAV slicing framework that operates at two different time-scales. At the large time-scale, the problem of inter-slice resource slicing and UAV deployment is formulated as a mixed integer nonlinear program, and a decomposition technique is applied to resolve it. At the small time-scale, the problem of intra-slice resource adjustment is modeled as a stochastic game and a distributed learning algorithm is proposed to find its Nash Equilibrium. Simulation results demonstrate that the proposed framework is lightweight and outperforms a number of known benchmark algorithms in terms of system utility, throughput and transmission delay.}
}


@article{DBLP:journals/jsac/ChamberlainSJ24,
	author = {Jonathan Chamberlain and
                  David Starobinski and
                  Joel T. Johnson},
	title = {Facilitating Spectrum Sharing With Passive Satellite Incumbents},
	journal = {{IEEE} J. Sel. Areas Commun.},
	volume = {42},
	number = {12},
	pages = {3719--3733},
	year = {2024},
	url = {https://doi.org/10.1109/JSAC.2024.3459034},
	doi = {10.1109/JSAC.2024.3459034},
	timestamp = {Sun, 22 Dec 2024 15:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/jsac/ChamberlainSJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Space-Air-Ground Integrated Networks will facilitate seamless user experiences across a variety of 6G applications. The deployment of these networks will necessitate new approaches to spectrum allocation. Spectrum access by passive microwave sensors for earth-based and space-based scientific applications represents a spectrum use application having unique attributes that motivate consideration of spectrum sharing between these “incumbents” and commercial users to ensure the most efficient utilization of available frequencies across applications. Toward this end, we propose an economic framework where incumbents have priority use, with a primary and secondary commercial tier underneath. For commercial users, the option to join the primary tier is based on a model of short term post-paid leases of spectrum, while the secondary tier is available to join at no cost. Using a joint game-theoretic and queuing-theoretic model, we find that for practical parameters the revenue maximizing equilibrium is: 1) stable in the Evolutionary Stable Strategy sense; 2) associated with the maximum priority upgrade fee customers are willing to pay; 3) associated with an equilibrium where all customers wish to join the priority class; and 4) socially optimal. We validate our findings leveraging trace data from satellite radiometers operating in the vicinity of Boston, Massachusetts.}
}
