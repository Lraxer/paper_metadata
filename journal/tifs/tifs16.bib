@article{DBLP:journals/tifs/PanWWZ21,
	author = {Zaiyu Pan and
                  Jun Wang and
                  Guoqing Wang and
                  Jihong Zhu},
	title = {Multi-Scale Deep Representation Aggregation for Vein Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1--15},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.2994738},
	doi = {10.1109/TIFS.2020.2994738},
	timestamp = {Thu, 06 Jul 2023 09:15:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PanWWZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent success of Deep Convolutional Neural Network (DCNN) for various computer vision tasks such as image recognition has already demonstrated its robust feature representation ability. However, the limitation of training database on small scale vein recognition tasks restricts its performance because the recognition result of DCNN depends heavily on the number of trainsets. This motivates the design of a Multi-Scale Deep Representation Aggregation (MSDRA) model based on a pre-trained DCNN for vein recognition. First, the multi-scale feature maps are extracted by a pre-trained DCNN model. Second, a local mean threshold approach is designed to preliminarily remove the noisy information of multi-scale feature maps and generate the selected feature maps. Third, we propose an Unsupervised Vein Information Mining (UVIM) method to localize vein information of selected feature maps for generating a binary vein information mask, and then the vein information mask is utilized to keep useful deep representation and discard the background information. Finally, the discriminative multi-scale deep representations, which are generated by using the vein information mask to aggregate multi-scale feature maps, are concatenated into the final compact feature vectors, and then a Support Vector Machine (SVM) is introduced for final recognition. Our proposed model outperforms the state-of-the-art methods on two benchmark vein databases. Moreover, an additional experiment using the subset of PolyU Palmprint database illustrates the system's generalization ability and robustness.}
}


@article{DBLP:journals/tifs/ZhangCGNLZ21,
	author = {Zhi Zhang and
                  Yueqiang Cheng and
                  Yansong Gao and
                  Surya Nepal and
                  Dongxi Liu and
                  Yi Zou},
	title = {Detecting Hardware-Assisted Virtualization With Inconspicuous Features},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {16--27},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3004264},
	doi = {10.1109/TIFS.2020.3004264},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangCGNLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed the proliferation of the deployment of virtualization techniques. Virtualization is designed to be transparent, that is, unprivileged users should not be able to detect whether a system is virtualized. Such detection can result in serious security threats such as evading virtual machine (VM)-based malware dynamic analysis and exploiting vulnerabilities for cross-VM attacks. The traditional software-based virtualization leaves numerous artifacts/fingerprints, which can be exploited without much effort to detect the virtualization. In contrast, current mainstream hardware-assisted virtualization significantly enhances the virtualization transparency, making itself more transparent and difficult to be detected. Nonetheless, we showcase three new identified low-level inconspicuous features, which can be leveraged by an unprivileged adversary to effectively and stealthily detect the hardware-assisted virtualization. All three features come from the chipset fingerprints, rather than the traces of software-based virtualization implementations (e.g., Xen or KVM). The identified features include i) Translation-Lookaside Buffer (TLB) stores an extra layer of address translations; ii) Last-Level Cache (LLC) caches one more layer of page-table entries; and iii) Level-1 Data (L1D) Cache is unstable. Based on the above features, we develop three corresponding virtualization detection techniques, which are then comprehensively evaluated on three native environments and three popular cloud providers: i) Amazon Elastic Compute Cloud, ii) Google Compute Engine and iii) Microsoft Azure. Experimental results validate that these three adversarial detection techniques are effective (with no false positive) and stealthy (without triggering suspicious system events, e.g., VM-exit ) in detecting the above commodity virtualized environments.}
}


@article{DBLP:journals/tifs/MittalKM21,
	author = {Govind Mittal and
                  Pawel Korus and
                  Nasir D. Memon},
	title = {FiFTy: Large-Scale File Fragment Type Identification Using Convolutional
                  Neural Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {28--41},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3004266},
	doi = {10.1109/TIFS.2020.3004266},
	timestamp = {Thu, 27 Aug 2020 15:45:02 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MittalKM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present FiFTy , a modern file-type identification tool for memory forensics and data carving. In contrast to previous approaches based on hand-crafted features, we design a compact neural network architecture, which uses a trainable embedding space. Our approach dispenses with the explicit feature extraction which has been a bottleneck in legacy systems. We evaluate the proposed method on a novel dataset with 75 file-types – the most diverse and balanced dataset reported to date. FiFTy consistently outperforms all baselines in terms of speed, accuracy and individual misclassification rates. We achieved an average accuracy of 77.5% with processing speed of \\approx 38 sec/GB, which is better and more than an order of magnitude faster than the previous state-of-the-art tool - Sceadan (69% at 9 min/GB). Our tool and the corresponding dataset is open-source.}
}


@article{DBLP:journals/tifs/ChughJ21,
	author = {Tarang Chugh and
                  Anil K. Jain},
	title = {Fingerprint Spoof Detector Generalization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {42--55},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.2990789},
	doi = {10.1109/TIFS.2020.2990789},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChughJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a style-transfer based wrapper, called Universal Material Generator (UMG), to improve the generalization performance of any fingerprint spoof (presentation attack) detector against spoofs made from materials not seen during training. Specifically, we transfer the style (texture) characteristics between fingerprint images of known materials with the goal of synthesizing fingerprint images corresponding to unknown materials, that may occupy the space between the known materials in the deep feature space. Synthetic live fingerprint images are also added to the training dataset to supervise the CNN to learn generative-noise invariant features which discriminate between lives and spoofs. The proposed approach is shown to improve the generalization performance of two state-of-the-art spoof detectors, namely Fingerprint Spoof Buster and Slim-ResCNN, winner of the LivDet 2017 spoof detection competition. Specifically, the performance is improved from TDR of 75.24% and 73.09% to TDR of 91.78% and 90.63% @ FDR = 0.2% for Spoof Buster and Slim-ResCNN, respectively. These results are based on a large-scale dataset of 5,743 live and 4,912 spoof images fabricated using 12 different materials. In addition to generalization across different spoof materials, the proposed approach is also shown to improve the average cross-sensor spoof detection performance from 67.60% and 64.62% to 80.63% and 77.59%, for Fingerprint Spoof Buster and Slim-ResCNN, respectively, when tested on the LivDet 2017 dataset.}
}


@article{DBLP:journals/tifs/WangHSC21,
	author = {Guoqing Wang and
                  Hu Han and
                  Shiguang Shan and
                  Xilin Chen},
	title = {Unsupervised Adversarial Domain Adaptation for Cross-Domain Face Presentation
                  Attack Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {56--69},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3002390},
	doi = {10.1109/TIFS.2020.3002390},
	timestamp = {Thu, 02 Dec 2021 17:27:17 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangHSC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face presentation attack detection (PAD) is essential for securing the widely used face recognition systems. Most of the existing PAD methods do not generalize well to unseen scenarios because labeled training data of the new domain is usually not available. In light of this, we propose an unsupervised domain adaptation with disentangled representation (DR-UDA) approach to improve the generalization capability of PAD into new scenarios. DR-UDA consists of three modules, i.e., ML-Net, UDA-Net and DR-Net. ML-Net aims to learn a discriminative feature representation using the labeled source domain face images via metric learning. UDA-Net performs unsupervised adversarial domain adaptation in order to optimize the source domain and target domain encoders jointly, and obtain a common feature space shared by both domains. As a result, the source domain PAD model can be effectively transferred to the unlabeled target domain for PAD. DR-Net further disentangles the features irrelevant to specific domains by reconstructing the source and target domain face images from the common feature space. Therefore, DR-UDA can learn a disentangled representation space which is generative for face images in both domains and discriminative for live vs. spoof classification. The proposed approach shows promising generalization capability in several public-domain face PAD databases.}
}


@article{DBLP:journals/tifs/HuH21,
	author = {Weipeng Hu and
                  Haifeng Hu},
	title = {Dual Adversarial Disentanglement and Deep Representation Decorrelation
                  for {NIR-VIS} Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {70--85},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3005314},
	doi = {10.1109/TIFS.2020.3005314},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The task of near-infrared and visual (NIR-VIS) face recognition refers to matching face data from different modalities, which has broad application prospects in areas such as multimedia information retrieval and criminal investigation. However, it remains a challenging task due to high intra-class variations and small-scale NIR-VIS dataset. In this paper, we propose a novel approach called Dual Adversarial Disentanglement and deep Representation Decorrelation (DADRD) to solve the NIR-VIS matching problem. In order to reduce the gap between NIR-VIS images, three key components are designed for DADRD model, including Cross-modal Margin (CmM) loss, Dual Adversarial Disentangled Variations (DADV) and Deep Representation Decorrelation (DRD). Firstly, the CmM loss captures within- and between-class information of the data, and it further reduces modality difference by a center-variation item. Secondly, the Mixed Facial Representation (MFR) layer of the backbone network is divided into three parts: the identity-related layer, the modality-related layer and the residual-related layer. The DADV is designed to reduce the intra-class variations, which consists of Adversarial Disentangled Modality Variations (ADMV) and Adversarial Disentangled Residual Variations (ADRV). Specifically, the ADMV and ADRV aim at eliminating spectrum variations and residual variations (i.e., lighting, pose, expression, occlusion, etc) respectively via an adversarial mechanism. Finally, we impose a DRD on the three decomposed features to make them irrelevant to each other, which can more effectively separate the three component information and enhance feature representations. In particular, we develop a Joint Three-stage Optimization (JTsO) strategy to effectively optimize the network. The joint formulation leads to the purification of identity information and the disentanglement of within-class variation information. Extensive experiments have been carried out on three challenging datasets, and the results demonstrate the effectiveness of our method.}
}


@article{DBLP:journals/tifs/JoKPYS21,
	author = {Hyeonseong Jo and
                  Jinwoo Kim and
                  Phillip A. Porras and
                  Vinod Yegneswaran and
                  Seungwon Shin},
	title = {GapFinder: Finding Inconsistency of Security Information From Unstructured
                  Text},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {86--99},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3003570},
	doi = {10.1109/TIFS.2020.3003570},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JoKPYS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Textual data mining of open source intelligence on the Web has become an increasingly important topic across a wide range of domains such as business, law enforcement, military, and cybersecurity. Text mining efforts utilize natural language processing to transform unstructured web content into structured forms that can drive various machine learning applications and data indexing services. For example, applications for text mining in cybersecurity have produced a range of threat intelligence services that serve the IT industry. However, a less studied problem is that of automating the identification of semantic inconsistencies among various text input sources. In this paper, we introduce GapFinder, a new inconsistency checking system for identifying semantic inconsistencies within the cybersecurity domain. Specifically, we examine the problem of identifying technical inconsistencies that arise in the functional descriptions of open source malware threat reporting information. Our evaluation, using tens of thousands of relations derived from web-based malware threat reports, demonstrates the ability of GapFinder to identify the presence of inconsistencies.}
}


@article{DBLP:journals/tifs/YangZ21,
	author = {Wenyuan Yang and
                  Yuesheng Zhu},
	title = {A Verifiable Semantic Searching Scheme by Optimal Matching Over Encrypted
                  Data in Public Cloud},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {100--115},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3001728},
	doi = {10.1109/TIFS.2020.3001728},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Semantic searching over encrypted data is a crucial task for secure information retrieval in public cloud. It aims to provide retrieval service to arbitrary words so that queries and search results are flexible. In existing semantic searching schemes, the verifiable searching does not be supported since it is dependent on the forecasted results from predefined keywords to verify the search results from cloud, and the queries are expanded on plaintext and the exact matching is performed by the extended semantically words with predefined keywords, which limits their accuracy. In this paper, we propose a secure verifiable semantic searching scheme. For semantic optimal matching on ciphertext, we formulate word transportation (WT) problem to calculate the minimum word transportation cost (MWTC) as the similarity between queries and documents, and propose a secure transformation to transform WT problems into random linear programming (LP) problems to obtain the encrypted MWTC. For verifiability, we explore the duality theorem of LP to design a verification mechanism using the intermediate data produced in matching process to verify the correctness of search results. Security analysis demonstrates that our scheme can guarantee verifiability and confidentiality. Experimental results on two datasets show our scheme has higher accuracy than other schemes.}
}


@article{DBLP:journals/tifs/HwangTLH21,
	author = {Dae Yon Hwang and
                  Bilal Taha and
                  Da Saem Lee and
                  Dimitrios Hatzinakos},
	title = {Evaluation of the Time Stability and Uniqueness in PPG-Based Biometric
                  System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {116--130},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3006313},
	doi = {10.1109/TIFS.2020.3006313},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HwangTLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we demonstrates the feasibility of employing the biometric photoplethysmography (PPG) signal for human verification applications. The PPG signal has dominance in terms of accessibility and portability which makes its usage in many applications such as user access control very appealing. Therefore, we developed robust time-stable features using signal analysis and deep learning models to increase the robustness and performance of the verification system with the PPG signal. The proposed system focuses on utilizing different stretching mechanisms namely Dynamic Time Warping, zero padding and interpolation with Fourier transform, and fuses them at the data level to be then deployed with different deep learning models. The designed deep models consist of Convolutional Neural Network (CNN) and Long-Short Term Memory (LSTM) which are considered to build a user specific model for the verification task. We collected a dataset consisting of 100 participants and recorded at two different time sessions using Plux pulse sensor. This dataset along with another two public databases are deployed to evaluate the performance of the proposed verification system in terms of uniqueness and time stability. The final result demonstrates the superiority of our proposed system tested on the built dataset and compared with other two public databases. The best performance achieved from our collected two-sessions database in terms of accuracy is 98% for the single-session and 87.1% for the two-sessions scenarios.}
}


@article{DBLP:journals/tifs/TanWSLLH21,
	author = {Shunquan Tan and
                  Weilong Wu and
                  Zilong Shao and
                  Qiushi Li and
                  Bin Li and
                  Jiwu Huang},
	title = {{CALPA-NET:} Channel-Pruning-Assisted Deep Residual Network for Steganalysis
                  of Digital Images},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {131--146},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3005304},
	doi = {10.1109/TIFS.2020.3005304},
	timestamp = {Tue, 16 Aug 2022 23:06:34 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TanWSLLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the past few years, detection performance improvements of deep-learning based steganalyzers have been usually achieved through structure expansion. However, excessive expanded structure results in huge computational cost, storage overheads, and consequently difficulty in training and deployment. In this paper we propose CALPA-NET, a ChAnneL-Pruning-Assisted deep residual network architecture search approach to shrink the network structure of existing vast, over-parameterized deep-learning based steganalyzers. We observe that the broad inverted-pyramid structure of existing deep-learning based steganalyzers might contradict the well-established model diversity oriented philosophy, and therefore is not suitable for steganalysis. Then a hybrid criterion combined with two network pruning schemes is introduced to adaptively shrink every involved convolutional layer in a data-driven manner. The resulting network architecture presents a slender bottleneck-like structure. We have conducted extensive experiments on BOSSBase + BOWS2 dataset, more diverse ALASKA dataset and even a large-scale subset extracted from ImageNet CLS-LOC dataset. The experimental results show that the model structure generated by our proposed CALPA-NET can achieve comparative performance with less than two percent of parameters and about one third FLOPs compared to the original steganalytic model. The new model possesses even better adaptivity, transferability, and scalability.}
}


@article{DBLP:journals/tifs/HuangYWLY21,
	author = {Yuwen Huang and
                  Gongping Yang and
                  Kuikui Wang and
                  Haiying Liu and
                  Yilong Yin},
	title = {Learning Joint and Specific Patterns: {A} Unified Sparse Representation
                  for Off-the-Person {ECG} Biometric Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {147--160},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3006384},
	doi = {10.1109/TIFS.2020.3006384},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangYWLY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Devices such as smartphones and tablets have spurred interest in off-the-person electrocardiogram (ECG) biometric recognition. While the advantage of using multi-feature information for establishing identities has been widely recognized, computational sparse representation models for multi-feature biometric recognition have only recently received more attention. We propose a unified sparse representation framework which collaboratively exploits joint and specific patterns for ECG biometric recognition. In particular, unlike joint sparse representation, which only considers the consistency among sparsity patterns of multiple features, we combine the consistent and pairwise constraints, which not only learn latent discriminant representations for all features but capture the interactions between them. In addition, our framework is universal and easily adapts to other multi-feature sparse representation models by just tuning the regularization parameters. The optimization problem is solved by an efficient alternating direction method of multipliers (ADMM). Extensive experiments on two publicly available off-the-person datasets demonstrate that our method can achieve competitive or even superior performance compared to state-of-the-art ECG biometric recognition methods.}
}


@article{DBLP:journals/tifs/AbdullahCAC21,
	author = {Zaid Abdullah and
                  Gaojie Chen and
                  Mohammed A. M. Abdullah and
                  Jonathon A. Chambers},
	title = {Enhanced Secrecy Performance of Multihop IoT Networks With Cooperative
                  Hybrid-Duplex Jamming},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {161--172},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3005336},
	doi = {10.1109/TIFS.2020.3005336},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AbdullahCAC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the number of connected devices is exponentially increasing, security in Internet of Things (IoT) networks presents a major challenge. Accordingly, in this work we investigate the secrecy performance of multihop IoT networks assuming that each node is equipped with only two antennas, and can operate in both Half-Duplex (HD) and Full-Duplex (FD) modes. Moreover, we propose an FD Cooperative Jamming (CJ) scheme to provide higher security against randomly located eavesdroppers, where each information symbol is protected with two jamming signals by its two neighbouring nodes, one of which is the FD receiver. We demonstrate that under a total power constraint, the proposed FD-CJ scheme significantly outperforms the conventional FD Single Jamming (FD-SJ) approach, where only the receiving node acts as a jammer, especially when the number of hops is larger than two. Moreover, when the Channel State Information (CSI) is available at the transmitter, and transmit beamforming is applied, our results demonstrate that at low Signal-to-Noise Ratio (SNR), higher secrecy performance is obtained if the receiving node operates in HD and allocates both antennas for data reception, leaving only a single jammer active; while at high SNR, a significant secrecy enhancement can be achieved with FD jamming. Our proposed FD-CJ scheme is found to demonstrate a great resilience over multihop networks, as only a marginal performance loss is experienced as the number of hops increases. For each case, an integral closed-form expression is derived for the secrecy outage probability, and verified by Monte Carlo simulations.}
}


@article{DBLP:journals/tifs/TaburetBSF21,
	author = {Th{\'{e}}o Taburet and
                  Patrick Bas and
                  Wadih Sawaya and
                  Jessica J. Fridrich},
	title = {Natural Steganography in {JPEG} Domain With a Linear Development Pipeline},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {173--186},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3007354},
	doi = {10.1109/TIFS.2020.3007354},
	timestamp = {Wed, 17 Mar 2021 09:50:11 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TaburetBSF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to achieve high practical security, Natural Steganography (NS) uses cover images captured at ISO sensitivity ISO 1 and generates stego images mimicking ISO sensitivity ISO 2 > ISO 1 . This is achieved by adding a stego signal to the cover that mimics the sensor photonic noise. This paper proposes an embedding mechanism to perform NS in the JPEG domain after linear developments by explicitly computing the correlations between DCT coefficients before quantization. In order to compute the covariance matrix of the photonic noise in the DCT domain, we first develop the matrix representation of demosaicking, luminance averaging, pixel section, and 2D-DCT. A detailed analysis of the resulting covariance matrix is done in order to explain the origins of the correlations between the coefficients of 3 × 3 DCT blocks. An embedding scheme is then presented that takes into account all the correlations. It employs 4 sub-lattices and 64 lattices per sub-lattices. The modification probabilities of each DCT coefficient are then derived by computing conditional probabilities computed from a multivariate Gaussian distribution using the Cholesky decomposition of the covariance matrix. This derivation is also used to compute the embedding capacity of each image. Using a specific database called E1Base, we show that in the JPEG domain NS (J-Cov-NS) enables to achieve high capacity (more than 2 bits per non-zero AC DCT) and with high practical security (PE 40% using DCTR and PE 32% using SRNet) from QF 75 to QF 100).}
}


@article{DBLP:journals/tifs/DragoiC21,
	author = {Ioan{-}Catalin Dragoi and
                  Dinu Coltuc},
	title = {On the Security of Reversible Data Hiding in Encrypted Images by {MSB}
                  Prediction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {187--189},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3006382},
	doi = {10.1109/TIFS.2020.3006382},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DragoiC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The reversible data hiding in encrypted images by MSB prediction of P. Puteaux and W. Puesch not only provides high embedding bit-rates, but also entails a very low mathematical complexity. This correspondence investigates its security and shows flaws in embedding imperceptibility, unauthorized detection/removal of embedded data and unauthorized access to image content. Secure solutions are discussed.}
}


@article{DBLP:journals/tifs/CarletCGKT21,
	author = {Claude Carlet and
                  {\'{E}}loi de Ch{\'{e}}risey and
                  Sylvain Guilley and
                  Sel{\c{c}}uk Kavut and
                  Deng Tang},
	title = {Intrinsic Resiliency of S-Boxes Against Side-Channel Attacks-Best
                  and Worst Scenarios},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {203--218},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3006399},
	doi = {10.1109/TIFS.2020.3006399},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CarletCGKT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Constructing S-boxes that are inherently resistant against side-channel attacks is an important problem in cryptography. By using an optimal distinguisher under an additive Gaussian noise assumption, we clarify how a defender (resp., an attacker) can make side-channel attacks as difficult (resp., easy) as possible, in relation with the auto-correlation spectrum of Boolean functions. We then construct balanced Boolean functions that are optimal for each of these two scenarios. Generalizing the objectives for an S-box, we analyze the auto-correlation spectra of some well-known S-box constructions in dimensions at most 8 and compare their intrinsic resiliency against side-channel attacks. Finally, we perform several simulations of side-channel attacks against the aforementioned constructions, which confirm our theoretical approach.}
}


@article{DBLP:journals/tifs/YangYXSCY21,
	author = {Lu Yang and
                  Gongping Yang and
                  Xiaoming Xi and
                  Kun Su and
                  Qing Chen and
                  Yilong Yin},
	title = {Correction to "Finger Vein Code: From Indexing to Matching"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {219},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3008986},
	doi = {10.1109/TIFS.2020.3008986},
	timestamp = {Fri, 29 Oct 2021 16:42:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangYXSCY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In second paragraph of the footnote on the first page of [1] , the institution information of Lu Yang and Xiaoming Xi is inaccurate. The correct institution name is “School of Computer Science and Technology, Shandong University of Finance and Economics.” So this paragraph should be corrected as:}
}


@article{DBLP:journals/tifs/ChengGCMD21,
	author = {Wei Cheng and
                  Sylvain Guilley and
                  Claude Carlet and
                  Sihem Mesnager and
                  Jean{-}Luc Danger},
	title = {Optimizing Inner Product Masking Scheme by a Coding Theory Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {220--235},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3009609},
	doi = {10.1109/TIFS.2020.3009609},
	timestamp = {Fri, 11 Mar 2022 08:06:58 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChengGCMD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Masking is one of the most popular countermeasures to protect cryptographic implementations against side-channel analysis since it is provably secure and can be deployed at the algorithm level. To strengthen the original Boolean masking scheme, several works have suggested using schemes with high algebraic complexity. The Inner Product Masking (IPM) is one of those. In this paper, we propose a unified framework to quantitatively assess the side-channel security of the IPM in a coding-theoretic approach. Specifically, starting from the expression of IPM in a coded form, we use two defining parameters of the code to characterize its side-channel resistance. In order to validate the framework, we then connect it to two leakage metrics (namely signal-to-noise ratio and mutual information, from an information-theoretic aspect) and one typical attack metric (success rate, from a practical aspect) to build a firm foundation for our framework. As an application, our results provide ultimate explanations on the observations made by Balasch et al. at EUROCRYPT'15 and at ASIACRYPT'17, Wang et al. at CARDIS'16 and Poussier et al. at CARDIS'17 regarding the parameter effects in IPM, like higher security order in bounded moment model. Furthermore, we show how to systematically choose optimal codes (in the sense of a concrete security level) to optimize IPM by using this framework. Eventually, we present a simple but effective algorithm for choosing optimal codes for IPM, which is of special interest for designers when selecting optimal parameters for IPM.}
}


@article{DBLP:journals/tifs/HuaLWZY21,
	author = {Guang Hua and
                  Han Liao and
                  Qingyi Wang and
                  Haijian Zhang and
                  Dengpan Ye},
	title = {Detection of Electric Network Frequency in Audio Recordings-From Theory
                  to Practical Detectors},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {236--248},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3009579},
	doi = {10.1109/TIFS.2020.3009579},
	timestamp = {Thu, 10 Sep 2020 13:03:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuaLWZY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, it has been discovered that the electric network frequency (ENF) could be captured by digital audio, video, or even image files, and could further be exploited in forensic investigations. However, the existence of the ENF in multimedia content is not a sure thing, and if the ENF is not present, ENF-based forensic analysis would become useless or even misleading. In this paper, we address the problem of ENF detection in digital audio recordings, which is modeled as the detection of a weak (ENF) signal contaminated by unknown colored wide-sense stationary (WSS) Gaussian noise, while the signal also contains multiple unknown random parameters. We first derive three Neyman-Pearson (NP) detectors, i.e., general matched filter (GMF), matched filter (MF)-like detector, and the asymptotic approximation of the GMF, and choose the MF-like detector as the clairvoyant detector. For practical detectors, we show that the generalized likelihood ratio test (GLRT) could not be efficiently obtained due to the unknown noise and large matrix inversion. Alternatively, we propose two least-squares (LS)-based time domain detectors termed as LS-likelihood ratio test (LRT) and naive-LRT. Further, we propose a time-frequency (TF) domain detector, termed as TF detector, which exploits the a priori knowledge of the ENF. The performances of the derived detectors are extensively analyzed in terms of test statistic distributions, threshold selection, and computational complexity. The naive-LRT detector is found to be only effective for very short recordings. As the data recording length increases, both LS-LRT and TF detectors yield effective detection results, while the latter is approximately a constant false alarm rate (CFAR) detector. Practical experiments using real audio recordings justify the effectiveness of the proposed detectors and our analysis.}
}


@article{DBLP:journals/tifs/LiYYAKV21,
	author = {Songze Li and
                  Mingchao Yu and
                  Chien{-}Sheng Yang and
                  Amir Salman Avestimehr and
                  Sreeram Kannan and
                  Pramod Viswanath},
	title = {PolyShard: Coded Sharding Achieves Linearly Scaling Efficiency and
                  Security Simultaneously},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {249--261},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3009610},
	doi = {10.1109/TIFS.2020.3009610},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiYYAKV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today's blockchain designs suffer from a trilemma claiming that no blockchain system can simultaneously achieve decentralization, security, and performance scalability. For current blockchain systems, as more nodes join the network, the efficiency of the system (computation, communication, and storage) stays constant at best. A leading idea for enabling blockchains to scale efficiency is the notion of sharding: different subsets of nodes handle different portions of the blockchain, thereby reducing the load for each individual node. However, existing sharding proposals achieve efficiency scaling by compromising on trust - corrupting the nodes in a given shard will lead to the permanent loss of the corresponding portion of data. In this paper, we settle the trilemma by demonstrating a new protocol for coded storage and computation in blockchains. In particular, we propose PolyShard: “polynomially coded sharding” scheme that achieves information-theoretic upper bounds on the efficiency of the storage, system throughput, as well as on trust, thus enabling a truly scalable system. We provide simulation results that numerically demonstrate the performance improvement over state of the arts, and the scalability of the PolyShard system. Finally, we discuss potential enhancements, and highlight practical considerations in building such a system.}
}


@article{DBLP:journals/tifs/MaiCLY21,
	author = {Guangcan Mai and
                  Kai Cao and
                  Xiangyuan Lan and
                  Pong C. Yuen},
	title = {SecureFace: Face Template Protection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {262--277},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3009590},
	doi = {10.1109/TIFS.2020.3009590},
	timestamp = {Wed, 26 Aug 2020 11:05:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MaiCLY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It has been shown that face images can be reconstructed from their representations (templates). We propose a randomized CNN to generate protected face biometric templates given the input face image and a user-specific key. The use of user-specific keys introduces randomness to the secure template and hence strengthens the template security. To further enhance the security of the templates, instead of storing the key, we store a secure sketch that can be decoded to generate the key with genuine queries submitted to the system. We have evaluated the proposed protected template generation method using three benchmarking datasets for the face (FRGC v2.0, CFP, and IJB-A). The experimental results justify that the protected template generated by the proposed method are non-invertible and cancellable, while preserving the verification performance.}
}


@article{DBLP:journals/tifs/QuanL21,
	author = {Yijun Quan and
                  Chang{-}Tsun Li},
	title = {On Addressing the Impact of {ISO} Speed Upon {PRNU} and Forgery Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {190--202},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3009583},
	doi = {10.1109/TIFS.2020.3009583},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QuanL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Photo Response Non-Uniformity (PRNU) has been used as a powerful device fingerprint for image forgery detection because image forgeries can be revealed by finding the absence of the PRNU in the manipulated areas. The correlation between an image's noise residual with the device's reference PRNU is often compared with a decision threshold to check the existence of the PRNU. A PRNU correlation predictor is usually used to determine this decision threshold assuming the correlation is content-dependent. However, we found that not only the correlation is content-dependent, but it also depends on the camera sensitivity setting. Camera sensitivity, commonly known by the name of ISO speed, is an important attribute in digital photography. In this work, we will show the PRNU correlation's dependency on ISO speed. Due to such dependency, we postulate that a correlation predictor is ISO speed-specific, i.e. reliable correlation predictions can only be made when a correlation predictor is trained with images of similar ISO speeds to the image in question. We report the experiments we conducted to validate the postulate. It is realized that in the real-world, information about the ISO speed may not be available in the metadata to facilitate the implementation of our postulate in the correlation prediction process. We hence propose a method called Content-based Inference of ISO Speeds (CINFISOS) to infer the ISO speed from the image content.}
}


@article{DBLP:journals/tifs/LiangM21,
	author = {Junwei Liang and
                  Maode Ma},
	title = {{ECF-MRS:} An Efficient and Collaborative Framework With Markov-Based
                  Reputation Scheme for IDSs in Vehicular Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {278--290},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013211},
	doi = {10.1109/TIFS.2020.3013211},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiangM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicle Ad Hoc Networks (VANETs) are considered to be a next big thing that will remarkably change our lives, since this kind of technology is able to make our lives and roads safer. Intrusion Detection Systems (IDS) is an important technology that can mitigate both inner and outer threats for the vulnerable networks like VANETs. However, it is difficult to adopt the same IDSs that have been appropriately used in wired networks, due to the fast moving and highly dynamic nature of VANETs. Thus, in this article, an Efficient and Collaborative Framework with a Markov-based Reputation Scheme is proposed, namely ECF-MRS. In the proposed framework, the collaborative mechanism is achieved by using Non-dominant Sorting Genetic Algorithm-III (NSGA-III)-Collaboration to merge the advantages of IDSs in VANETs to generate a more superior IDS, while Non-Linear Programming (NLP)-Optimization is designed as the efficient mechanism to reduce the execution time of IDSs in VANETs. Moreover, considering the security risks of collaboration, a Reputation Scheme based on the Hidden Generalized Mixture Transition Distribution (HgMTD) model, namely RS-HgMTD, is proposed for each vehicle in VANETs to evaluate the creditworthiness of their neighbors. Experiments show that the IDS with ECF-MRS has better performance than other existing IDSs in terms of detection rate, detection time and overhead.}
}


@article{DBLP:journals/tifs/YouZZ21,
	author = {Weike You and
                  Hong Zhang and
                  Xianfeng Zhao},
	title = {A Siamese {CNN} for Image Steganalysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {291--306},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013204},
	doi = {10.1109/TIFS.2020.3013204},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YouZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image steganalysis is a technique for detecting data hidden in images. Recent research has shown the powerful capabilities of using convolutional neural networks (CNN) for image steganalysis. However, due to the particularity of steganographic signals, there are still few reliable CNN-based methods for applying steganalysis to images of arbitrary size. In this paper, we address this issue by exploring the possibility of exploiting a network for steganalyzing images of varying sizes without retraining its parameters. On the assumption that natural image noise is similar between different image sub-regions, we propose an end-to-end, deep learning, novel solution for distinguishing steganography images from normal images that provides satisfying performance. The proposed network first takes the image as the input, then identifies the relationships between the noise of different image sub-regions, and, finally, outputs the resulting classification based upon them. Our algorithm adopts a Siamese, CNN-based architecture, which consists of two symmetrical subnets with shared parameters, and contains three phases: preprocessing, feature extraction, and fusion/classification. To validate the network, we generated datasets composed of steganography images with multiple sizes and their corresponding normal images sourced from BOSSbase 1.01 and ALASKA #2. Experimental results produced by the data generated by various methods show that our proposed network is well-generalized and robust.}
}


@article{DBLP:journals/tifs/LiCMLD21,
	author = {Yan Li and
                  Yao Cheng and
                  Weizhi Meng and
                  Yingjiu Li and
                  Robert H. Deng},
	title = {Designing Leakage-Resilient Password Entry on Head-Mounted Smart Wearable
                  Glass Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {307--321},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013212},
	doi = {10.1109/TIFS.2020.3013212},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiCMLD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the boom of Augmented Reality (AR) and Virtual Reality (VR) applications, head-mounted smart wearable glass devices are becoming popular to help users access various services like E-mail freely. However, most existing password entry schemes on smart glasses rely on additional computers or mobile devices connected to smart glasses, which require users to switch between different systems and devices. This may greatly lower the practicability and usability of smart glasses. In this paper, we focus on this challenge and design three practical anti-eavesdropping password entry schemes on stand-alone smart glasses, named gTapper, gRotator and gTalker. The main idea is to break the correlation between the underlying password and the interaction observable to adversaries. In our IRB-approved user study, these schemes are found to be easy-to-use without additional hardware under various test conditions, where the participants can enter their passwords within moderate time, at high accuracy, and in various situations.}
}


@article{DBLP:journals/tifs/ChoL21,
	author = {Kang{-}Hee Cho and
                  Si{-}Hyeon Lee},
	title = {Treating Interference as Noise Is Optimal for Covert Communication
                  Over Interference Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {322--332},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013213},
	doi = {10.1109/TIFS.2020.3013213},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChoL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the covert communication over K-user-pair discrete memoryless interference channels (DM-ICs) with a warden. It is assumed that the warden's channel output distribution induced by K “off” input symbols, which are sent when no communication occurs, is not a convex combination of those induced by any other combination of input symbols (otherwise, the square-root law does not hold). We derive the exact covert capacity region and show that a simple point-to-point based scheme with treating interference as noise is optimal. In addition, we analyze the secret key length required for the reliable and covert communication with the desired rates, and present a channel condition where a secret key between each user pair is unnecessary. The results are extended to the Gaussian case and the case with multiple wardens.}
}


@article{DBLP:journals/tifs/WangCZ21,
	author = {Yu Wang and
                  Yun Cao and
                  Xianfeng Zhao},
	title = {Minimizing Embedding Impact for {H.264} Steganography by Progressive
                  Trellis Coding},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {333--345},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013523},
	doi = {10.1109/TIFS.2020.3013523},
	timestamp = {Mon, 19 Apr 2021 13:38:12 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangCZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a novel coding strategy to achieve distortion minimization for H.264 steganography with quantized discrete cosine transform (QDCT) coefficients. Currently, with the help of syndrome-trellis codes (STCs), state-of-the-art image steganography embeds messages while minimizing a heuristically defined distortion function. However, this concept cannot be directly ported to steganography using compressed video as the cover media. According to the intra prediction principle, an H.264 QDCT coefficient block is predicted and coded based on previously encoded blocks, so even a slight embedding change will set off a chain reaction in the remaining cover blocks. Considering the cover block dependency, we make necessary changes to the standard trellis coding structure so as to be applicable for the joint compression embedding scenario. During the coding/embedding procedure, we maintain multiple contexts corresponding to possible optimal routes, and retrace each route periodically to determine how each cover block should be modified. After each modification, the remaining cover blocks, as well as their embedding costs, are re-evaluated, and each context is updated to reflect the embedding effect. In this way, the global optimality can be approached progressively in a block-by-block manner, so our proposed method is named progressive trellis coding (PTC). Extensive experiments have been conducted, and corresponding results show that the adoption of PTC brings about a significant gain in embedding performance.}
}


@article{DBLP:journals/tifs/PengWLG21,
	author = {Chunlei Peng and
                  Nannan Wang and
                  Jie Li and
                  Xinbo Gao},
	title = {Soft Semantic Representation for Cross-Domain Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {346--360},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013209},
	doi = {10.1109/TIFS.2020.3013209},
	timestamp = {Mon, 20 Sep 2021 08:52:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PengWLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of cross-domain face recognition aims to identify facial images obtained across different domains, which attracts increasing attentions because of its wide applications on law-enforcement identification and camera surveillance. The problem is challenging due to the huge domain discrepancy. Despite great progress achieved in recent years, existing algorithms usually fail to fully exploit the semantic information for identifying cross-domain faces, which could be a strong clue for recognition. In this article, we propose an effective algorithm for cross-domain face recognition by exploiting semantic information integrated with deep convolutional neural networks (CNN). We first introduce a soft face parsing algorithm where the boundaries of facial components are measured as probabilistic values. By taking the original face image as the guidance to improve face parsing result, each pixel may belong partially to the facial component to avoid inaccurate segmentation around component boundaries. We then propose a hierarchical soft semantic representation framework for cross-domain face recognition. Both the soft semantic level and contour level deep features obtained via CNN are computed and combined together, which could fully exploit the identical semantic clue among cross-domain faces. We provide extensive experiments to demonstrate that the proposed soft semantic representation algorithm performs superior against state-of-the-art methods.}
}


@article{DBLP:journals/tifs/GeorgeM21,
	author = {Anjith George and
                  S{\'{e}}bastien Marcel},
	title = {Learning One Class Representations for Face Presentation Attack Detection
                  Using Multi-Channel Convolutional Neural Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {361--375},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013214},
	doi = {10.1109/TIFS.2020.3013214},
	timestamp = {Wed, 07 Dec 2022 23:04:09 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GeorgeM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face recognition has evolved as a widely used biometric modality. However, its vulnerability against presentation attacks poses a significant security threat. Though presentation attack detection (PAD) methods try to address this issue, they often fail in generalizing to unseen attacks. In this work, we propose a new framework for PAD using a one-class classifier, where the representation used is learned with a Multi-Channel Convolutional Neural Network (MCCNN). A novel loss function is introduced, which forces the network to learn a compact embedding for bonafide class while being far from the representation of attacks. A one-class Gaussian Mixture Model is used on top of these embeddings for the PAD task. The proposed framework introduces a novel approach to learn a robust PAD system from bonafide and available (known) attack classes. This is particularly important as collecting bonafide data and simpler attacks are much easier than collecting a wide variety of expensive attacks. The proposed system is evaluated on the publicly available WMCA multi-channel face PAD database, which contains a wide variety of 2D and 3D attacks. Further, we have performed experiments with MLFP and SiW-M datasets using RGB channels only. Superior performance in unseen attack protocols shows the effectiveness of the proposed approach. Software, data, and protocols to reproduce the results are made available publicly.}
}


@article{DBLP:journals/tifs/ChoKKLL21,
	author = {MyeongAh Cho and
                  Taeoh Kim and
                  Ig{-}Jae Kim and
                  Kyungjae Lee and
                  Sangyoun Lee},
	title = {Relational Deep Feature Learning for Heterogeneous Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {376--388},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013186},
	doi = {10.1109/TIFS.2020.3013186},
	timestamp = {Thu, 02 Sep 2021 18:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChoKKLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous Face Recognition (HFR) is a task that matches faces across two different domains such as visible light (VIS), near-infrared (NIR), or the sketch domain. Due to the lack of databases, HFR methods usually exploit the pre-trained features on a large-scale visual database that contain general facial information. However, these pre-trained features cause performance degradation due to the texture discrepancy with the visual domain. With this motivation, we propose a graph-structured module called Relational Graph Module (RGM) that extracts global relational information in addition to general facial features. Because each identity’s relational information between intra-facial parts is similar in any modality, the modeling relationship between features can help cross-domain matching. Through the RGM, relation propagation diminishes texture dependency without losing its advantages from the pre-trained features. Furthermore, the RGM captures global facial geometrics from locally correlated convolutional features to identify long-range relationships. In addition, we propose a Node Attention Unit (NAU) that performs node-wise recalibration to concentrate on the more informative nodes arising from relation-based propagation. Furthermore, we suggest a novel conditional-margin loss function (\nC\n-softmax) for the efficient projection learning of the embedding vector in HFR. The proposed method outperforms other state-of-the-art methods on five HFR databases. Furthermore, we demonstrate performance improvement on three backbones because our module can be plugged into any pre-trained face recognition backbone to overcome the limitations of a small HFR database.}
}


@article{DBLP:journals/tifs/ErdemirDG21,
	author = {Ece Naz Erdemir and
                  Pier Luigi Dragotti and
                  Deniz G{\"{u}}nd{\"{u}}z},
	title = {Privacy-Aware Time-Series Data Sharing With Deep Reinforcement Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {389--401},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013200},
	doi = {10.1109/TIFS.2020.3013200},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ErdemirDG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of things (IoT) devices are becoming increasingly popular thanks to many new services and applications they offer. However, in addition to their many benefits, they raise privacy concerns since they share fine-grained time-series user data with untrusted third parties. In this work, we study the privacy-utility trade-off (PUT) in time-series data sharing. Existing approaches to PUT mainly focus on a single data point; however, temporal correlations in time-series data introduce new challenges. Methods that preserve the privacy for the current time may leak significant amount of information at the trace level as the adversary can exploit temporal correlations in a trace. We consider sharing the distorted version of a user's true data sequence with an untrusted third party. We measure the privacy leakage by the mutual information between the user's true data sequence and shared version. We consider both the instantaneous and average distortion between the two sequences, under a given distortion measure, as the utility loss metric. To tackle the history-dependent mutual information minimization, we reformulate the problem as a Markov decision process (MDP), and solve it using asynchronous actor-critic deep reinforcement learning (RL). We evaluate the performance of the proposed solution in location trace privacy on both synthetic and GeoLife GPS trajectory datasets. For the latter, we show the validity of our solution by testing the privacy of the released location trajectory against an adversary network.}
}


@article{DBLP:journals/tifs/FanLLL21,
	author = {Ye Fan and
                  Ang Li and
                  Xuewen Liao and
                  Victor C. M. Leung},
	title = {Secure Interference Exploitation Precoding in {MISO} Wiretap Channel:
                  Destructive Region Redefinition With Efficient Solutions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {402--417},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013210},
	doi = {10.1109/TIFS.2020.3013210},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FanLLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we focus on the physical layer security for a\nK\n-user multiple-input-single-output (MISO) wiretap channel in the presence of a malicious eavesdropper, where we propose several interference exploitation (IE) precoding schemes for different types of the eavesdropper. Specifically, in the case where a common eavesdropper decodes the signal directly and Eve's full channel state information (CSI) is available at the transmitter, we show that the required transmit power can be further reduced by re-designing the `destructive region' of the constellations for symbol-level precoding and re-formulating the power minimization problem. We further study the SINR balancing problems with the derived `complete destructive region' with full, statistical and no Eve's CSI, respectively, and show that the SINR balancing problem becomes non-convex with statistical or no Eve's CSI. On the other hand, in the presence of a smart eavesdropper using maximal likelihood (ML) detection, the security cannot be guaranteed with all the existing approaches. To this end, we further propose a random jamming scheme (RJS) and a random precoding scheme (RPS), respectively. To solve the introduced convex/non-convex problems in an efficient manner, we propose an iterative algorithm for the convex ones based on the Karush-Kuhn-Tucker (KKT) conditions, and deal with the non-convex ones by resorting to Taylor expansions. Simulation results show that all proposed schemes outperform the existing works in secrecy performance, and that the proposed algorithm improves the computation efficiency significantly.}
}


@article{DBLP:journals/tifs/OuZLJ21,
	author = {Changhai Ou and
                  Chengju Zhou and
                  Siew{-}Kei Lam and
                  Guiyuan Jiang},
	title = {Multiple-Differential Mechanism for Collision-Optimized Divide-and-Conquer
                  Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {418--430},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3014490},
	doi = {10.1109/TIFS.2020.3014490},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/OuZLJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Several combined attacks have shown promising results in recovering cryptographic keys by introducing collision information into divide-and-conquer attacks to transform a part of the best key candidates within given thresholds into a much smaller collision space. However, these Collision-Optimized Divide-and-Conquer Attacks (CODCAs) uniformly demarcate the thresholds for all sub-keys, which is unreasonable. Moreover, the inadequate exploitation of collision information and backward fault tolerance mechanisms of CODCAs also lead to low attack efficiency. Finally, existing CODCAs mainly focus on improving collision detection algorithms but lack theoretical basis. We exploit Correlation-Enhanced Collision Attack (CECA) to optimize Template Attack (TA). To overcome the above-mentioned problems, we first introduce guessing theory into TA to enable the quick estimation of success probability and the corresponding complexity of key recovery. Next, a novel Multiple-Differential mechanism for CODCAs (MD-CODCA) is proposed. The first two differential mechanisms construct collision chains satisfying the given number of collisions from several sub-keys with the fewest candidates under a fixed probability provided by guessing theory, then exploit them to vote for the remaining sub-keys. This guarantees that the number of remaining chains is minimal, and makes MD-CODCA suitable for very high thresholds. Our third differential mechanism simply divides the key into several large non-overlapping “blocks” to further exploit intra-block collisions from the remaining candidates and properly ignore the inter-block collisions, thus facilitating the later key enumeration. The experimental results show that MD-CODCA significantly reduces the candidate space and lowers the complexity of collision detection, without considerably reducing the success probability of attacks.}
}


@article{DBLP:journals/tifs/GhadiH21,
	author = {Farshad Rostami Ghadi and
                  Ghosheh Abed Hodtani},
	title = {Copula-Based Analysis of Physical Layer Security Performances Over
                  Correlated Rayleigh Fading Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {431--440},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3014553},
	doi = {10.1109/TIFS.2020.3014553},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GhadiH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies performance analysis of physical layer security in a Rayleigh fading wiretap channel, where, the main (transmitter-to-legitimate receiver) and eavesdropper (transmitter-to-eavesdropper) channel coefficients are correlated. By exploiting the novel approach called Copula theory, we derive closed-form expressions for average secrecy capacity (ASC), secrecy outage probability (SOP), and secrecy coverage region (SCR). Moreover, to more evaluate the impact of channel correlation, the asymptotic behavior of SOP in high signal-to-noise ratio (SNR) regime and other scenarios is studied, and finally, the analytical results are illustrated numerically under the positive dependence, independence, and negative dependence structures. Based on the insights from this analysis, we found that the effect of correlated fading on the performance of physical layer security can be helpful or harmful in different scenarios, depending on the structure of dependency between the main and eavesdropper channels.}
}


@article{DBLP:journals/tifs/LavauzelleTFH21,
	author = {Julien Lavauzelle and
                  Razane Tajeddine and
                  Ragnar Freij{-}Hollanti and
                  Camilla Hollanti},
	title = {Private Information Retrieval Schemes With Product-Matrix {MBR} Codes},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {441--450},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3003572},
	doi = {10.1109/TIFS.2020.3003572},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LavauzelleTFH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A private information retrieval (PIR) scheme allows a user to retrieve a file from a database without revealing any information on the file being requested. As of now, PIR schemes have been proposed for several kinds of storage systems, including replicated and MDS-coded systems. However, the problem of constructing PIR schemes on regenerating codes has been sparsely considered. A regenerating code is a storage code whose codewords are distributed among nodes, enabling efficient storage of files, as well as low-bandwidth retrieval of files and repair of nodes. Minimum-bandwidth regenerating (MBR) codes define a family of regenerating codes allowing a node repair with optimal bandwidth. Rashmi, Shah, and Kumar obtained a large family of MBR codes using the product-matrix (PM) construction. In this work, a new PIR scheme over PM-MBR codes is designed. The inherent redundancy of the PM structure is used to reduce the download communication complexity of the scheme. A lower bound on the PIR capacity of MBR-coded PIR schemes is derived, showing an interesting storage space vs. PIR rate trade-off compared to existing PIR schemes with the same reconstruction capability. The present scheme also outperforms a recent PM-MBR PIR construction of Dorkson and Ng.}
}


@article{DBLP:journals/tifs/HanXZWZW21,
	author = {Weili Han and
                  Ming Xu and
                  Junjie Zhang and
                  Chuanwang Wang and
                  Kai Zhang and
                  X. Sean Wang},
	title = {TransPCFG: Transferring the Grammars From Short Passwords to Guess
                  Long Passwords Effectively},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {451--465},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3003696},
	doi = {10.1109/TIFS.2020.3003696},
	timestamp = {Sun, 23 Apr 2023 14:31:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HanXZWZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Long passwords are gaining popularity in password policy recommendations; however, data-driven guessing studies are woefully inadequate in adapting to long passwords, lacking in both guessing efficiency and their composition guidelines. For state-of-the-art data-driven password guessing methods such as PCFGs (Probabilistic Context-free Grammars), their guessing efficiency is limited by the presence of a large scale training data, or the lack thereof. Given that long passwords leaked in the real world are typically scarce, coupled with the fact that the data-driven methods’ performance depends on training data, obtaining good performance on long passwords has become a key challenge. To overcome the dataset limitation, we propose a framework TransPCFG , that transfers the knowledge, (i.e., grammars in PCFGs), from short passwords to facilitate long password guessing. We further perform an empirical evaluation based on three real-world datasets and the results demonstrate superior performance over the state-of-the-art data-driven guessing methods under\n10\n14\noffline guesses. For passwords with 16 characters, TransPCFG can compromise an average of 23.30% of the passwords, outperforming PCFG_v4.1 by 56.10%. Additionally,for better password-composition guidelines, we find that long password-composition policies requiring more segments are more resistant to guessing attacks. For the segment, the password 12zxcvbnword1997 has four segments since it follows the template\nDigit\n2\nKeyboard\n6\nLetter\n4\nYear\n4\n. We thus recommend users to create long passwords with four or more segments instead of the widely recommended more character classes for security.}
}


@article{DBLP:journals/tifs/TangJZWQ21,
	author = {Jie Tang and
                  Long Jiao and
                  Kai Zeng and
                  Hong Wen and
                  Kaiyu Qin},
	title = {Physical Layer Secure {MIMO} Communications Against Eavesdroppers
                  With Arbitrary Number of Antennas},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {466--481},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3015548},
	doi = {10.1109/TIFS.2020.3015548},
	timestamp = {Mon, 21 Aug 2023 15:51:16 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TangJZWQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, MIMO (multiple-input-multiple-output) physical layer secure transmission has attracted great attentions. However, current schemes cannot defend against the passive eavesdroppers with arbitrary number of antennas. To address this problem, in this work, we propose a practical physical layer MIMO secure communication scheme (PLSC) to defend against such an eavesdropper with arbitrary number of antennas. In the proposed scheme, the transmitter first independently generates a random binary sequence as the “key bits (KB)” to “encrypt” (XOR) the confidential information. After that, the transmitter sends the “encrypted information” over the wireless channel, along with mapping key bits to the legitimate receiver simultaneously. The key principle lies in that the KB information is coded in the indexes of the activated/non-activated antennas combination of the legitimate user. Then, the legitimate receiver first observes his/her activated antenna indexes to obtain the corresponding key bits. After that, he/she demodulates the “encrypted information” at the activated antennas, and finally “decrypts” (XOR) the confidential information by using the observed key bits. However, due to the uniqueness and independence of MIMO wireless channel, for any other eavesdroppers who suffer an independent channel from legitimate users, we prove that it cannot observe any information about KB from the received signals, regardless of how many antennas it has used. Consequently, without knowledge of KB, it cannot decrypt any information about the confidential information, too. The reliability and security of PLSC are theoretically demonstrated. The simulation and numerical results fully verified the validity and effectiveness of the proposed scheme.}
}


@article{DBLP:journals/tifs/LiangLLFZ21,
	author = {Liqian Liang and
                  Congyan Lang and
                  Yidong Li and
                  Songhe Feng and
                  Jian Zhao},
	title = {Fine-Grained Facial Expression Recognition in the Wild},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {482--494},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3007327},
	doi = {10.1109/TIFS.2020.3007327},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiangLLFZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the past decades, researches on facial expression recognition have been restricted within six basic expressions (anger, fear, disgust, happiness, sadness and surprise). However, these six words can not fully describe the richness and diversity of human beings' emotions. To enhance the recognitive capabilities for computers, in this paper, we focus on fine-grained facial expression recognition in the wild and build a brand new benchmark FG-Emotions to push the research frontiers on this topic, which extends the original six classes to more elaborate thirty-three classes. Our FG-Emotions contains 10,371 images and 1,491 video clips annotated with corresponding fine-grained facial expression categories and landmarks. FG-Emotions also provides several features (e.g., LBP features and dense trajectories features) to facilitate related research. Moreover, on top of FG-Emotions, we propose a new end-to-end Multi-Scale Action Unit (AU)-based Network (MSAU-Net) for facial expression recognition with image which learns a more powerful facial representation by directly focusing on locating facial action units and utilizing “zoom in” operation to aggregate distinctive local features. As for recognition with video, we further extend the MSAU-Net to a two-stream model (TMSAU-Net) by adding a module with attention mechanism and a temporal stream branch to jointly learn spatial and temporal features. (T)MSAU-Net consistently outperforms existing state-of-the-art solutions on our FG-Emotions and several other datasets, and serves as a strong baseline to drive the future research towards fine-grained facial expression recognition in the wild.}
}


@article{DBLP:journals/tifs/KarPCBHS21,
	author = {Arindam Kar and
                  Sourav Pramanik and
                  Arghya Chakraborty and
                  Debotosh Bhattacharjee and
                  Edmond S. L. Ho and
                  Hubert P. H. Shum},
	title = {{LMZMPM:} Local Modified Zernike Moment Per-Unit Mass for Robust Human
                  Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {495--509},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3015552},
	doi = {10.1109/TIFS.2020.3015552},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KarPCBHS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we proposed a novel method, called Local Modified Zernike Moment per unit Mass (LMZMPM), for face recognition, which is invariant to illumination, scaling, noise, in-plane rotation, and translation, along with other orthogonal and inherent properties of the Zernike Moments (ZMs). The proposed LMZMPM is computed for each pixel in a neighborhood of size 3 × 3 , and then considers the complex tuple that contains both the phase and magnitude coefficients of LMZMPM as the extracted features. As it contains both the phase and the magnitude components of the complex feature, it has more information about the image and thus preserves both the edge and structural information. We also propose a hybrid similarity measure, combining the Jaccard Similarity with the L1 distance, and applied to the extracted feature set for classification. The feasibility of the proposed LMZMPM technique on varying illumination has been evaluated on the CMU-PIE and the extended Yale B databases with an average Rank-1 Recognition (R1R) accuracy of 99.8% and 98.66% respectively. To assess the reliability of the method with variations in noise, rotation, scaling, and translation, we evaluate it on the AR database and obtain an average R1R higher than that of recent state-of-the-art methods. The proposed method shows a very high recognition rate on Heterogeneous Face Recognition as well, with 100% on CUFS, and 98.80% on CASIA-HFB.}
}


@article{DBLP:journals/tifs/FangCB21,
	author = {Zhaoyuan Fang and
                  Adam Czajka and
                  Kevin W. Bowyer},
	title = {Robust Iris Presentation Attack Detection Fusing 2D and 3D Information},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {510--520},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3015547},
	doi = {10.1109/TIFS.2020.3015547},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FangCB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Diversity and unpredictability of artifacts potentially presented to an iris sensor calls for presentation attack detection methods that are agnostic to specificity of presentation attack instruments. This article proposes a method that combines two-dimensional and three-dimensional properties of the observed iris to address the problem of spoof detection in case when some properties of artifacts are unknown. The 2D (textural) iris features are extracted by a state-of-the-art method employing Binary Statistical Image Features (BSIF) and an ensemble of classifiers is used to deliver 2D modality-related decision. The 3D (shape) iris features are reconstructed by a photometric stereo method from only two images captured under near-infrared illumination placed at two different angles, as in many current commercial iris recognition sensors. The map of normal vectors is used to assess the convexity of the observed iris surface. The combination of these two approaches has been applied to detect whether a subject is wearing a textured contact lens to disguise their identity. Extensive experiments with NDCLD'15 dataset, and a newly collected NDIris3D dataset show that the proposed method is highly robust under various open-set testing scenarios, and that it outperforms all available open-source iris PAD methods tested in identical scenarios. The source code and the newly prepared benchmark are made available along with this article.}
}


@article{DBLP:journals/tifs/ZhaoLLLRBLH21,
	author = {Shuai Zhao and
                  Fenghua Li and
                  Hongwei Li and
                  Rongxing Lu and
                  Siqi Ren and
                  Haiyong Bao and
                  Jianhong Lin and
                  Song Han},
	title = {Smart and Practical Privacy-Preserving Data Aggregation for Fog-Based
                  Smart Grids},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {521--536},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3014487},
	doi = {10.1109/TIFS.2020.3014487},
	timestamp = {Tue, 13 Feb 2024 08:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoLLLRBLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasingly powerful and extensive deployment of edge devices, edge/fog computing enables customers to manage and analyze data locally, and extends computing power and data analysis applications to network edges. Meanwhile, as the next generation of the power grid, the smart grid can achieve the goal of efficiency, economy, security, reliability, use safety and environmental friendliness for the power grid. However, privacy and secure issues in fog-based smart grid communications are challenging. Without proper protection, customers’ privacy will be readily violated. This article presents a smart and practical Privacy-preserving Data Aggregation (PDA) scheme with smart pricing and packing method for fog-based smart grids, which achieves diversified tariffs, multifunctional statistics and efficiency. Especially, we first propose a smart PDA scheme with Smart Pricing (PDA-SP). With PDA-SP, the Control Center (CC) can compute more complex and higher-order aggregation statistics to provide various services, provide diversiform pricing strategies and choose a double-winning strategy. Subsequently, we put forward a practical PDA scheme with Packing Method (PDA-PM), which is able to reduce the size of encrypted data and improve performance in performing various secure computations. Moreover, we extend our original packing method and present a more useful packing method, which can handle general vectors with large entries. The security analysis shows that our proposed scheme is secure against many threats. The performance evaluation reveals that the computation and communication overheads of our proposed scheme are effectively reduced by employing the Somewhat Homomorphic Encryption (SHE), and our packing method can further significantly reduce these overheads.}
}


@article{DBLP:journals/tifs/YangSZW21,
	author = {Zhihai Yang and
                  Qindong Sun and
                  Yaling Zhang and
                  Wei Wang},
	title = {Identification of Malicious Injection Attacks in Dense Rating and
                  Co-Visitation Behaviors},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {537--552},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3016827},
	doi = {10.1109/TIFS.2020.3016827},
	timestamp = {Thu, 12 Oct 2023 13:32:35 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangSZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized recommender systems are pervasive in different domains, ranging from e-commerce services, financial transaction systems to social networks. The generated ratings and reviews by users toward products are not only favourable to make targeted improvements on the products for online businesses, but also beneficial for other users to get a more insightful review of the products. In reality, recommender systems can also be deliberately manipulated by malicious users due to their fundamental vulnerabilities and openness. However, improving the detection performance for defending malicious threats including profile injection attacks and co-visitation injection attacks is constrained by the challenging issues: (1) various types of malicious attacks in real-world data coexist; (2) it is difficult to balance the commonality and speciality of rating behaviors in terms of accurate detection; and (3) rating behaviors between attackers and anchor users caused by the consistency of attack intentions are extremely similar. In this article, we develop a unified detection approach named IMIA-HCRF, to progressively discriminate malicious injection behaviors for recommender systems. First, disturbed data are empirically eliminated by implementing both the construction of association graph and enhancement of dense behaviors, which can be adapted to different attacks. Then, the smooth boundary of dense rating (or co-visitation) behaviors is further segmented using higher order potentials, which is finally leveraged to determine the concerned injection behaviors. Extensive experiments on both synthetic data and real-world data demonstrate that the proposed IMIA-HCRF outperforms all baselines on various metrics. The detection performance of IMIA-HCRF can achieve an improvement of 7.8% for mixed profile injection attacks as well as 6% for mixed co-visitation injection attacks over the baselines in terms of FAR (false alarm rate) while keeping the highest DR (detection rate). Additional experiments on real-world data show that IMIA-HCRF brings an improvement with the advantage of 11.5% FAR in average compared with the baselines.}
}


@article{DBLP:journals/tifs/ZhuFLLCC21,
	author = {Tiantian Zhu and
                  Lei Fu and
                  Qiang Liu and
                  Zi Lin and
                  Yan Chen and
                  Tieming Chen},
	title = {One Cycle Attack: Fool Sensor-Based Personal Gait Authentication With
                  Clustering},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {553--568},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3016819},
	doi = {10.1109/TIFS.2020.3016819},
	timestamp = {Sun, 05 Mar 2023 13:16:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuFLLCC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gait authentication, especially sensor-based patterns, has been studied by researchers for decades. Nowadays, gait authentication has become an important facet of biometric systems due to the so-called unique characteristics of each user. With the development of various technologies (i.e., hardware, data processing, features extraction, and learning algorithms), the performance of sensor-based authentication methods is gradually improving. But we have found that the vulnerability of most existing methods can be compromised easily. In this paper, we propose a novel attack model, called one cycle attack, to bypass existing gait authentication methods. Firstly, the gait sequence is divided into multiple gait cycles. By adopting the K-mean algorithm, we get the average distance of each feature sample (extracted from the gait cycle) to its closest cluster center, and its result confirms that independent individuals may have similar gait cycles. Secondly, using six state-of-the-art models it was found that the adversarial gait cycle found with the clustering method can bypass the victim’s model rapidly. Furthermore, to improve the accuracy of sensor-based gait authentication methods to fight against attacks, we present a WPD-LSTM (Wavelet Packet Decomposition and Long Short-Term Memory) multi-cycle defense model which considers the contextual contents of the neighboring gait cycles in the gait sequence. Experimental results on two datasets (the largest public sensor-based gait database OU-ISIR and new dataset from our laboratory) show that our attack model can bypass most of the victims’ models within a limited number of attempts. Specifically, we can compromise 20%–80% of users within 5 attempts by utilizing imitation. On the contrary, the success rate of attackers has been greatly mitigated by deploying our multi-cycle defense model.}
}


@article{DBLP:journals/tifs/YeZSZ21,
	author = {Dayong Ye and
                  Tianqing Zhu and
                  Sheng Shen and
                  Wanlei Zhou},
	title = {A Differentially Private Game Theoretic Approach for Deceiving Cyber
                  Adversaries},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {569--584},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3016842},
	doi = {10.1109/TIFS.2020.3016842},
	timestamp = {Thu, 21 Apr 2022 14:42:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YeZSZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber deception is one of the key approaches used to mislead attackers by hiding or providing inaccurate system information. There are two main factors limiting the real-world application of existing cyber deception approaches. The first limitation is that the number of systems in a network is assumed to be fixed. However, in the real world, the number of systems may be dynamically changed. The second limitation is that attackers' strategies are simplified in the literature. However, in the real world, attackers may be more powerful than theory suggests. To overcome these two limitations, we propose a novel differentially private game theoretic approach to cyber deception. In this proposed approach, a defender adopts differential privacy mechanisms to strategically change the number of systems and obfuscate the configurations of systems, while an attacker adopts a Bayesian inference approach to infer the real configurations of systems. By using the differential privacy technique, the proposed approach can 1) reduce the impacts on network security resulting from changes in the number of systems and 2) resist attacks regardless of attackers' reasoning power. The experimental results demonstrate the effectiveness of the proposed approach.}
}


@article{DBLP:journals/tifs/XuRS21,
	author = {Qian Xu and
                  Pinyi Ren and
                  A. Lee Swindlehurst},
	title = {Rethinking Secure Precoding via Interference Exploitation: {A} Smart
                  Eavesdropper Perspective},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {585--600},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3016836},
	doi = {10.1109/TIFS.2020.3016836},
	timestamp = {Mon, 28 Aug 2023 21:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuRS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Based on the concept of constructive interference (CI), multiuser interference (MUI) has recently been shown to be beneficial for communication secrecy. A few CI-based secure precoding algorithms have been proposed that use both the channel state information (CSI) and knowledge of the instantaneous transmit symbols. In this article, we examine the CI-based secure precoding problem with a focus on smart eavesdroppers that exploit statistical information gleaned from the precoded data for symbol detection. Moreover, the impact of correlation between the main and eavesdropper channels is taken into account. We first modify an existing CI-based precoding scheme to better utilize the destructive impact of the interference. Then, we point out the drawback of both the existing and the new modified CI-based precoders when faced with a smart eavesdropper. To address this deficiency, we provide a general principle for precoder design and then give two specific design examples. Finally, the scenario where the eavesdropper's CSI is unavailable is studied. Numerical results show that although our modified CI-based precoder can achieve a better energy-secrecy trade-off than the existing approach, both have a limited secrecy benefit. On the contrary, the precoders developed using the new CI-design principle can achieve a much improved tradeoff and significantly degrade the eavesdropper's performance.}
}


@article{DBLP:journals/tifs/GrozaPM21,
	author = {Bogdan Groza and
                  Lucian Popa and
                  Pal{-}Stefan Murvay},
	title = {{CANTO} - Covert AutheNtication With Timing Channels Over Optimized
                  Traffic Flows for {CAN}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {601--616},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3017892},
	doi = {10.1109/TIFS.2020.3017892},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GrozaPM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Previous research works have endorsed the use of delays and clock skews for detecting intrusions or fingerprinting controllers that communicate on the CAN bus. Recently, timing characteristics of CAN frames have been also used for establishing a covert channel for cryptographic authentication, in this way cleverly removing the need for cryptographic material inside the short payload of data frames. However, the main drawback of this approach is the limited security level that can be achieved over existing CAN bus traffic. In this work we significantly improve on this by relying on optimization algorithms for scheduling CAN frames and deploy the covert channel on optimized CAN traffic. Under practical bus allocations, we are able to extract 3-5 bits of authentication data from each frame which leads to an efficient intrusion detection and authentication mechanism. By accumulating covert channel data over several consecutive frames, we can achieve higher security levels that are in line with current real-world demands. To prove the correctness of our approach, we present experiments on automotive-grade controllers, i.e., Infineon Aurix, and bus measurements with the use of industry standard tools, i.e., CANoe.}
}


@article{DBLP:journals/tifs/PraseedT21,
	author = {Amit Praseed and
                  P. Santhi Thilagam},
	title = {Modelling Behavioural Dynamics for Asymmetric Application Layer DDoS
                  Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {617--626},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3017928},
	doi = {10.1109/TIFS.2020.3017928},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PraseedT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Asymmetric application layer DDoS attacks using computationally intensive HTTP requests are an extremely dangerous class of attacks capable of taking down web servers with relatively few attacking connections. These attacks consume limited network bandwidth and are similar to legitimate traffic, which makes their detection difficult. Existing detection mechanisms for these attacks use indirect representations of actual user behaviour and complex modelling techniques, which leads to a higher false positive rate (FPR) and longer detection time, which makes them unsuitable for real time use. There is a need for simple, efficient and adaptable detection mechanisms for asymmetric DDoS attacks. In this work, an attempt is made to model the actual behavioural dynamics of legitimate users using a simple annotated Probabilistic Timed Automata (PTA) along with a suspicion scoring mechanism for differentiating between legitimate and malicious users. This allows the detection mechanism to be extremely fast and have a low FPR. In addition, the model can incrementally learn from run-time traces, which makes it adaptable and reduces the FPR further. Experiments on public datasets reveal that our proposed approach has a high detection rate and low FPR and adds negligible overhead to the web server, which makes it ideal for real time use.}
}


@article{DBLP:journals/tifs/CuiFZ21,
	author = {Zhe Cui and
                  Jianjiang Feng and
                  Jie Zhou},
	title = {Dense Registration and Mosaicking of Fingerprints by Training an End-to-End
                  Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {627--642},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3017926},
	doi = {10.1109/TIFS.2020.3017926},
	timestamp = {Tue, 06 Oct 2020 17:44:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CuiFZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dense registration of fingerprints is a challenging task due to elastic skin distortion, low image quality, and self-similarity of ridge pattern. To overcome the limitation of handcraft features, we propose to train an end-to-end network to directly output pixel-wise displacement field between two fingerprints. The proposed network includes a siamese network for feature embedding, and a following encoder-decoder network for regressing displacement field. By applying displacement fields reliably estimated by tracing high quality fingerprint videos to challenging fingerprints, we synthesize a large number of training fingerprint pairs with ground truth displacement fields. In addition, based on the proposed registration algorithm, we propose a fingerprint mosaicking method based on optimal seam selection. Registration and matching experiments on FVC2004 databases, Tsinghua Distorted Fingerprint (TDF) database, and NIST SD27 latent fingerprint database show that our registration method outperforms previous dense registration methods in accuracy. Mosaicking experiments on FVC2004 DB1_A and a small fingerprint database demonstrate that the proposed algorithm produced higher quality fingerprints and led to higher matching accuracy, which also validates the performance of our registration algorithm.}
}


@article{DBLP:journals/tifs/AltinisikS21,
	author = {Enes Altinisik and
                  Husrev Taha Sencar},
	title = {Source Camera Verification for Strongly Stabilized Videos},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {643--657},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3016830},
	doi = {10.1109/TIFS.2020.3016830},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AltinisikS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image stabilization performed during imaging and/or post-processing poses one of the most significant challenges to photo-response non-uniformity based source camera attribution from videos. When performed digitally, stabilization involves cropping, warping, and inpainting of video frames to eliminate unwanted camera motion. Hence, successful attribution requires inversion of these transformations in a blind manner. To address this challenge, we introduce a source camera verification method for videos that takes into account spatially variant nature of stabilization transformations and assumes a larger degree of freedom in their search. Our method identifies transformations at a sub-frame level, incorporates a number of constraints to validate their correctness, and offers computational flexibility in the search for the correct transformation. The method also adopts a holistic approach in countering disruptive effects of other video generation steps, such as video coding and downsizing, for more reliable attribution. Tests performed on one public and two custom datasets show that the proposed method is able to verify the source of 23-30% of all videos that underwent stronger stabilization, depending on computation load, without a significant impact on false attribution.}
}


@article{DBLP:journals/tifs/WangLAJDZ21,
	author = {Ning Wang and
                  Weiwei Li and
                  Amir Alipour{-}Fanid and
                  Long Jiao and
                  Monireh Dabaghchian and
                  Kai Zeng},
	title = {Pilot Contamination Attack Detection for 5G MmWave Grant-Free IoT
                  Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {658--670},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3017932},
	doi = {10.1109/TIFS.2020.3017932},
	timestamp = {Mon, 17 Jun 2024 08:10:31 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangLAJDZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Grant-free random access is an emerging technology for providing massive connectivity for 5G massive machine-type communications (mMTC), where non-orthogonal pilot sequences are used to simultaneously detect active users and estimate channels. However, grant-free 5G IoT networks are vulnerable to pilot contamination attacks (PCA), where the attacker can send the same pilots as legitimate IoT users to harm the active user detection and channel estimation. To defend against this attack, in this article, we propose a physical-layer countermeasure based on the channel virtual representation (CVR). CVR can emphasize the unique characteristics of mmWave channels that are sensitive to the location of the sender. This can be utilized to counter PCA no matter if the attacker's pilots are superimposed to that of the victim or not. Based on this observation, to achieve an efficient PCA detection, a single-hidden-layer multiple measurement (SHMM) Siamese network is employed. This solution tackles the challenges of channel randomness and massive connectivity in mMTC IoT networks, and supports small sample learning. Simulation results evaluate and confirm the effectiveness of the proposed detection scheme under various scenarios. The detection accuracy can approach 99% with 128 antennas at the receiver and reach above 95% even with only 50 training samples.}
}


@article{DBLP:journals/tifs/DingWCZGFL21,
	author = {Baojin Ding and
                  Haixia Wang and
                  Peng Chen and
                  Yilong Zhang and
                  Zhenhua Guo and
                  Jianjiang Feng and
                  Ronghua Liang},
	title = {Surface and Internal Fingerprint Reconstruction From Optical Coherence
                  Tomography Through Convolutional Neural Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {685--700},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3016829},
	doi = {10.1109/TIFS.2020.3016829},
	timestamp = {Thu, 01 Feb 2024 13:32:26 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DingWCZGFL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optical coherence tomography (OCT), as a non-destructive and high-resolution fingerprint acquisition technology, is robust against poor skin conditions and resistant to spoof attacks. It measures fingertip information on and beneath skin as 3D volume data, containing the surface fingerprint, internal fingerprint and sweat glands. Various methods have been proposed to extract internal fingerprints, which ignore the inter-slice dependence and often require manually selected parameters. In this article, a modified U-Net that combines residual learning, bidirectional convolutional long short-term memory and hybrid dilated convolution (denoted as BCL-U Net) for OCT volume data segmentation and two fingerprint reconstruction approaches are proposed. To the best of our knowledge, it is the first time that simultaneous and automatic extraction is performed for surface fingerprint, internal fingerprint and sweat gland. The proposed BCL-U Net utilizes the spatial dependence in OCT volume data and deals with segmentation of objects with diverse sizes to achieve accurate extraction. Comparisons have been performed to demonstrate the advantages of the proposed method. A thorough evaluation of the recognition abilities of internal and surface fingerprints is conducted using a dataset significantly larger than previous studies. Four databases containing internal and surface fingerprints are generated from 1572 OCT volume data by the proposed method. The internal fingerprint matching experiment has achieved a lowest equal error rate (EER) of 0.95%. Mixed internal and surface fingerprint matching experiment is also performed and achieves an EER of 3.67%, verifying the consistency of the internal and surface fingerprints. The matching experiments for fingers under poor skin conditions show a 2.47% EER of internal fingerprints that is much lower than that of surface fingerprints, which proves the advantage of internal fingerprints and indicates the potential of the internal fingerprints to supplement or replace the surface fingerprints for some specific applications.}
}


@article{DBLP:journals/tifs/WangST21,
	author = {Chong Xiao Wang and
                  Yang Song and
                  Wee Peng Tay},
	title = {Arbitrarily Strong Utility-Privacy Tradeoff in Multi-Agent Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {671--684},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3016835},
	doi = {10.1109/TIFS.2020.3016835},
	timestamp = {Fri, 29 Apr 2022 16:37:06 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangST21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Each agent in a network makes a local observation that is linearly related to a set of public and private parameters. The agents send their observations to a fusion center to allow it to estimate the public parameters. To prevent leakage of the private parameters, each agent first sanitizes its local observation using a local privacy mechanism before transmitting it to the fusion center. We investigate the utility-privacy tradeoff in terms of the Cramér-Rao lower bounds for estimating the public and private parameters. We study the class of privacy mechanisms given by linear compression and noise perturbation, and derive necessary and sufficient conditions for achieving arbitrarily strong utility-privacy tradeoff in a multi-agent system for both the cases where prior information is available and unavailable, respectively. We also provide a method to find the maximum estimation privacy achievable without compromising the utility and propose an alternating algorithm to optimize the utility-privacy tradeoff in the case where arbitrarily strong utility-privacy tradeoff is not achievable.}
}


@article{DBLP:journals/tifs/ZhangAFA21,
	author = {Hanwei Zhang and
                  Yannis Avrithis and
                  Teddy Furon and
                  Laurent Amsaleg},
	title = {Walking on the Edge: Fast, Low-Distortion Adversarial Examples},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {701--713},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3021899},
	doi = {10.1109/TIFS.2020.3021899},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangAFA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial examples of deep neural networks are receiving ever increasing attention because they help in understanding and reducing the sensitivity to their input. This is natural given the increasing applications of deep neural networks in our everyday lives. When white-box attacks are almost always successful, it is typically only the distortion of the perturbations that matters in their evaluation. In this work, we argue that speed is important as well, especially when considering that fast attacks are required by adversarial training. Given more time, iterative methods can always find better solutions. We investigate this speed-distortion trade-off in some depth and introduce a new attack called boundary projection (BP) that improves upon existing methods by a large margin. Our key idea is that the classification boundary is a manifold in the image space: we therefore quickly reach the boundary and then optimize distortion on this manifold.}
}


@article{DBLP:journals/tifs/AiCLWY21,
	author = {Xin Ai and
                  Honglong Chen and
                  Kai Lin and
                  Zhibo Wang and
                  Jiguo Yu},
	title = {Nowhere to Hide: Efficiently Identifying Probabilistic Cloning Attacks
                  in Large-Scale {RFID} Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {714--727},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023785},
	doi = {10.1109/TIFS.2020.3023785},
	timestamp = {Tue, 21 Feb 2023 17:10:35 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AiCLWY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio-Frequency Identification (RFID) is an emerging technology which has been widely applied in various scenarios, such as tracking, object monitoring, and social networks, etc. Cloning attacks can severely disturb the RFID systems, such as missed detection for the missing tags. Although there are some techniques with physical architecture design or complicated encryption and cryptography proposed to prevent the tags from being cloned, it is difficult to definitely avoid the cloning attack. Therefore, cloning attack detection and identification are critical for the RFID systems. Prior works rely on that each clone tag will reply to the reader when its corresponding genuine tag is queried. In this article, we consider a more general attack model, in which each clone tag replies to the reader's query with a predefined probability, i.e., attack probability. We concentrate on identifying the tags being attacked with the probability no less than a threshold\nP\nt\nwith the required identification reliability\nα\n. We first propose a basic protocol to Identify the Probabilistic Cloning Attacks with required identification reliability for the large-scale RFID systems called IPCA. Then we propose two enhanced protocols called MS-IPCA and S-IPCA respectively to improve the identification efficiency. We theoretically analyze the parameters of the proposed IPCA, MS-IPCA and S-IPCA protocols to maximize the identification efficiency. Finally we conduct extensive simulations to validate the effectiveness of the proposed protocols.}
}


@article{DBLP:journals/tifs/YeSS21,
	author = {Mang Ye and
                  Jianbing Shen and
                  Ling Shao},
	title = {Visible-Infrared Person Re-Identification via Homogeneous Augmented
                  Tri-Modal Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {728--739},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3001665},
	doi = {10.1109/TIFS.2020.3001665},
	timestamp = {Tue, 01 Dec 2020 09:11:36 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YeSS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Matching person images between the daytime visible modality and night-time infrared modality (VI-ReID) is a challenging cross-modality pedestrian retrieval problem. Existing methods usually learn the multi-modality features in raw image, ignoring the image-level discrepancy. Some methods apply GAN technique to generate the cross-modality images, but it destroys the local structure and introduces unavoidable noise. In this paper, we propose a Homogeneous Augmented Tri-Modal (HAT) learning method for VI-ReID, where an auxiliary grayscale modality is generated from their homogeneous visible images, without additional training process. It preserves the structure information of visible images and approximates the image style of infrared modality. Learning with the grayscale visible images enforces the network to mine structure relations across multiple modalities, making it robust to color variations. Specifically, we solve the tri-modal feature learning from both multi-modal classification and multi-view retrieval perspectives. For multi-modal classification, we learn a multi-modality sharing identity classifier with a parameter-sharing network, trained with a homogeneous and heterogeneous identification loss. For multi-view retrieval, we develop a weighted tri-directional ranking loss to optimize the relative distance across multiple modalities. Incorporated with two invariant regularizers, HAT simultaneously minimizes multiple modality variations. In-depth analysis demonstrates the homogeneous grayscale augmentation significantly outperforms the current state-of-the-art by a large margin.}
}


@article{DBLP:journals/tifs/PierazziCBCML21,
	author = {Fabio Pierazzi and
                  Stefano Cristalli and
                  Danilo Bruschi and
                  Michele Colajanni and
                  Mirco Marchetti and
                  Andrea Lanzi},
	title = {Glyph: Efficient ML-Based Detection of Heap Spraying Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {740--755},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3017925},
	doi = {10.1109/TIFS.2020.3017925},
	timestamp = {Mon, 03 Jan 2022 22:10:35 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/PierazziCBCML21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heap spraying is probably the most simple and effective memory corruption attack, which fills the memory with malicious payloads and then jumps at a random location in hopes of starting the attacker's routines. To counter this threat, GRAFFITI has been recently proposed as the first OS-agnostic framework for monitoring memory allocations of arbitrary applications at runtime; however, the main contributions of GRAFFITI are on the monitoring system, and its detection engine only considers simple heuristics which are tailored to certain attack vectors and are easily evaded. In this article, we aim to overcome this limitation and propose GLYPH as the first ML-based heap spraying detection system, which is designed to be effective, efficient, and resilient to evasive attackers. GLYPH relies on the information monitored by GRAFFITI, and we investigate the effectiveness of different feature spaces based on information entropy and memory n-grams, and discuss the several engineering challenges we have faced to make GLYPH efficient with an overhead compatible with that of GRAFFITI. To evaluate GLYPH, we build a representative dataset with several variants of heap spraying attacks, and assess GLYPH's resilience against evasive attackers through selective hold-out experiments. Results show that GLYPH achieves high accuracy in detecting spraying and is able to generalize well, outperforming the state-of-the-art approach for heap spraying detection, NOZZLE. Finally, we thoroughly discuss the trade-offs between detection performance and runtime overhead of GLYPH's different configurations.}
}


@article{DBLP:journals/tifs/ChaterjeeMC21,
	author = {Urbi Chatterjee and
                  Debdeep Mukhopadhyay and
                  Rajat Subhra Chakraborty},
	title = {3PAA: {A} Private {PUF} Protocol for Anonymous Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {756--769},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3021917},
	doi = {10.1109/TIFS.2020.3021917},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChaterjeeMC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymous authentication (AA) schemes are used by an application provider to grant services to its n users for pre-defined k times after they have authenticated themselves anonymously. These privacy-preserving cryptographic schemes are essentially based on the secret key that is embedded in a trusted platform module (TPM). In this work, we propose a private physically unclonable function (PUF) based scheme that overcomes the shortcomings of prior attempts to incorporate PUF for AA schemes. Traditional PUF based authentication protocols have their limitations as they only work based on challenge-response pairs (CRPs) exposed to the verifier, thus violating the principle of anonymity. Here, we ensure that even if the PUF instance is private to the user, it can be used for authentication to the application provider. Besides, no raw CRPs need to be stored in a secure database, thus making it more difficult for an adversary to launch model-building attacks on the deployed PUFs. We reduce the execution time from O(n) to O(1) and storage overhead from O(nk) to O(n) compared to state-of-the-art AA protocols and also dispense the necessity of maintaining a revocation list for the compromised keys. In addition, we provide security proofs of the protocol under Elliptic Curve Diffie-Hellman assumption and decisional uniqueness assumption of a PUF. A prototype of the protocol has been implemented on a Z-Turn board integrated with dual-core ARM CortexA9 processor and Artix-7 FPGA. The resource footprint and performance characterization results show that the proposed scheme is suitable for implementation on resource-constrained platforms.}
}


@article{DBLP:journals/tifs/GaoZ21,
	author = {Yiwen Gao and
                  Yongbin Zhou},
	title = {Side-Channel Attacks With Multi-Thread Mixed Leakage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {770--785},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023278},
	doi = {10.1109/TIFS.2020.3023278},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GaoZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Side-channel attacks are one of the greatest practical threats to security-related applications, because they are capable of breaking ciphers that are assumed to be mathematically secure. Lots of studies have been devoted to power or electro-magnetic (EM) analysis against desktop CPUs, mobile CPUs (including ARM, MSP, AVR, etc) and FPGAs, but rarely targeted modern GPUs. Modern GPUs feature their special and specific single instruction multiple threads (SIMT) execution fashion, which makes their power/EM leakage more sophisticated in practical scenarios. In this article, we study side-channel attacks with leakage from SIMT systems, and propose leakage models suited to any SIMT systems and specifically to CUDA-enabled GPUs. Afterwards, we instantiate the models with a GPU AES implementation, which is also used for performance evaluations. In addition to the models, we provide optimizations on the attacks that are based on the models. To evaluate the models and optimizations, we run the GPU AES implementation on a CUDA-enabled GPU and, at the same time, collect its EM leakage. The experimental results show that the proposed models are more efficient and the optimizations are effective as well. Our study suggests that GPU-based cryptographic implementations may be much vulnerable to microarchitecture-based side-channel attacks. Therefore, GPU-specific countermeasures should be considered for GPU-based cryptographic implementations in practical applications.}
}


@article{DBLP:journals/tifs/CaoWDLDCG21,
	author = {Kunrui Cao and
                  Buhong Wang and
                  Haiyang Ding and
                  Lu Lv and
                  Runze Dong and
                  Tianhao Cheng and
                  Fengkui Gong},
	title = {Improving Physical Layer Security of Uplink {NOMA} via Energy Harvesting
                  Jammers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {786--799},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023277},
	doi = {10.1109/TIFS.2020.3023277},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CaoWDLDCG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the secrecy transmission of uplink non-orthogonal multiple access (NOMA) with the aid of energy harvesting (EH) jammers. During each time frame, communication is divided into two phases. At the first phase, the base station (BS) transfers wireless power to EH receivers (EHRs). At the second phase, users perform uplink NOMA transmission to BS, while one of EHRs is selected as a friendly jammer that uses the energy harvested from the previous phase to emit the artificial noise for confusing the eavesdropper. In terms of the requirement of channel state information (CSI), we propose three friendly EH jammer selection schemes, namely random EH jammer selection (REJS) scheme without the requirement of any CSI, maximal EH jammer selection (MEJS) scheme with the CSI between BS and each EHR, and optimal EH jammer selection (OEJS) scheme where both the CSIs from BS to EHRs and from EHRs to the eavesdropper need to be known. Analytical closed-form expressions for the connection outage probability (COP), secrecy outage probability (SOP) and effective secrecy throughput (EST) are derived to evaluate the system performance achieved by the proposed schemes, respectively. Also, the asymptotic analysis is provided to gain further insights. The analytical and numerical results indicate that the proposed schemes can realize better secrecy performance than conventional scheme without an EH jammer. Both the secrecy diversity orders of the REJS and MEJS schemes are one while the OEJS scheme can achieve a full secrecy diversity order. Furthermore, owing to the impact of connection outage, the three schemes converge to the same EST floor with the increase of signal-to-noise ratio (SNR).}
}


@article{DBLP:journals/tifs/ProencaYA21,
	author = {Hugo Proen{\c{c}}a and
                  Ehsan Yaghoubi and
                  Pendar Alirezazadeh},
	title = {A Quadruplet Loss for Enforcing Semantically Coherent Embeddings in
                  Multi-Output Classification Problems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {800--811},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023304},
	doi = {10.1109/TIFS.2020.3023304},
	timestamp = {Fri, 23 Apr 2021 09:00:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ProencaYA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article describes one objective function for learning semantically coherent feature embeddings in multi-output classification problems, i.e., when the response variables have dimension higher than one. Such coherent embeddings can be used simultaneously for different tasks, such as identity retrieval and soft biometrics labelling. We propose a generalization of the triplet loss that: 1) defines a metric that considers the number of agreeing labels between pairs of elements; 2) introduces the concept of similar classes, according to the values provided by the metric; and 3) disregards the notion of anchor, sampling four arbitrary elements at each time, from where two pairs are defined. The distances between elements in each pair are imposed according to their semantic similarity (i.e., the number of agreeing labels). Likewise the triplet loss, our proposal also privileges small distances between positive pairs. However, the key novelty is to additionally enforce that the distance between elements of any other pair corresponds inversely to their semantic similarity. The proposed loss yields embeddings with a strong correspondence between the classes centroids and their semantic descriptions. In practice, it is a natural choice to jointly infer coarse (soft biometrics) + fine (ID) labels, using simple rules such as k-neighbours. Also, in opposition to its triplet counterpart, the proposed loss appears to be agnostic with regard to demanding criteria for mining learning instances (such as the semi-hard pairs). Our experiments were carried out in five different datasets (BIODI, LFW, IJB-A, Megaface and PETA) and validate our assumptions, showing results that are comparable to the state-of-the-art in both the identity retrieval and soft biometrics labelling tasks.}
}


@article{DBLP:journals/tifs/BernardBKP21,
	author = {Sol{\`{e}}ne Bernard and
                  Patrick Bas and
                  John Klein and
                  Tom{\'{a}}s Pevn{\'{y}}},
	title = {Explicit Optimization of min max Steganographic Game},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {812--823},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3021913},
	doi = {10.1109/TIFS.2020.3021913},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BernardBKP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article proposes an algorithm which allows Alice to simulate the game played between her and Eve. Under the condition that the set of detectors that Alice assumes Eve to have is sufficiently rich (e.g. CNNs), and that she has an algorithm enabling to avoid detection by a single classifier (e.g adversarial embedding, gibbs sampler, dynamic STCs), the proposed algorithm converges to an efficient steganographic algorithm. This is possible by using a min max strategy which consists at each iteration in selecting the least detectable stego image for the best classifier among the set of Eve’s learned classifiers. The algorithm is extensively evaluated and compared to prior arts and results show the potential to increase the practical security of classical steganographic methods. For example the error probability\nP\nerr\nof XU-Net on detecting stego images with payload of 0.4 bpnzAC embedded by J-Uniward and QF 75 starts at 7.1% and is increased by +13.6% to reach 20.7% after eight iterations. For the same embedding rate and for QF 95, undetectability by XU-Net with J-Uniward embedding is 23.4%, and it jumps by +25.8% to reach 49.2% at iteration 3.}
}


@article{DBLP:journals/tifs/ZhengLSZZ21,
	author = {Linlin Zheng and
                  Jiakang Li and
                  Meng Sun and
                  Xiongwei Zhang and
                  Thomas Fang Zheng},
	title = {When Automatic Voice Disguise Meets Automatic Speaker Verification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {824--837},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023818},
	doi = {10.1109/TIFS.2020.3023818},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhengLSZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The technique of transforming voices in order to hide the real identity of a speaker is called voice disguise, among which automatic voice disguise (AVD) by modifying the spectral and temporal characteristics of voices with miscellaneous algorithms are easily conducted with softwares accessible to the public. AVD has posed great threat to both human listening and automatic speaker verification (ASV). In this paper, we have found that ASV is not only a victim of AVD but could be a tool to beat some simple types of AVD. Firstly, three types of AVD, pitch scaling, vocal tract length normalization (VTLN) and voice conversion (VC), are introduced as representative methods. State-of-the-art ASV methods are subsequently utilized to objectively evaluate the impact of AVD on ASV by equal error rates (EER). Moreover, an approach to restore disguised voice to its original version is proposed by minimizing a function of ASV scores w.r.t. restoration parameters. Experiments are then conducted on disguised voices from Voxceleb, a dataset recorded in real-world noisy scenario. The results have shown that, for the voice disguise by pitch scaling, the proposed approach obtains an EER around 7% comparing to the 30% EER of a recently proposed baseline using the ratio of fundamental frequencies. The proposed approach generalizes well to restore the disguise with nonlinear frequency warping in VTLN by reducing its EER from 34.3% to 18.5%. However, it is difficult to restore the source speakers in VC by our approach, where more complex forms of restoration functions or other paralinguistic cues might be necessary to restore the nonlinear transform in VC. Finally, contrastive visualization on ASV features with and without restoration illustrate the role of the proposed approach in an intuitive way.}
}


@article{DBLP:journals/tifs/FanWXLGL21,
	author = {Ming Fan and
                  Wenying Wei and
                  Xiaofei Xie and
                  Yang Liu and
                  Xiaohong Guan and
                  Ting Liu},
	title = {Can We Trust Your Explanations? Sanity Checks for Interpreters in
                  Android Malware Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {838--853},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3021924},
	doi = {10.1109/TIFS.2020.3021924},
	timestamp = {Thu, 23 Jun 2022 20:01:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FanWXLGL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid growth of Android malware, many machine learning-based malware analysis approaches are proposed to mitigate the severe phenomenon. However, such classifiers are opaque, non-intuitive, and difficult for analysts to understand the inner decision reason. For this reason, a variety of explanation approaches are proposed to interpret predictions by providing important features. Unfortunately, the explanation results obtained in the malware analysis domain cannot achieve a consensus in general, which makes the analysts confused about whether they can trust such results. In this work, we propose principled guidelines to assess the quality of five explanation approaches by designing three critical quantitative metrics to measure their stability, robustness, and effectiveness. Furthermore, we collect five widely-used malware datasets and apply the explanation approaches on them in two tasks, including malware detection and familial identification. Based on the generated explanation results, we conduct a sanity check of such explanation approaches in terms of the three metrics. The results demonstrate that our metrics can assess the explanation approaches and help us obtain the knowledge of most typical malicious behaviors for malware analysis.}
}


@article{DBLP:journals/tifs/AmsalegBBEFHRN21,
	author = {Laurent Amsaleg and
                  James Bailey and
                  Am{\'{e}}lie Barbe and
                  Sarah M. Erfani and
                  Teddy Furon and
                  Michael E. Houle and
                  Milos Radovanovic and
                  Xuan Vinh Nguyen},
	title = {High Intrinsic Dimensionality Facilitates Adversarial Attack: Theoretical
                  Evidence},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {854--865},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023274},
	doi = {10.1109/TIFS.2020.3023274},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AmsalegBBEFHRN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning systems are vulnerable to adversarial attack. By applying to the input object a small, carefully-designed perturbation, a classifier can be tricked into making an incorrect prediction. This phenomenon has drawn wide interest, with many attempts made to explain it. However, a complete understanding is yet to emerge. In this paper we adopt a slightly different perspective, still relevant to classification. We consider retrieval, where the output is a set of objects most similar to a user-supplied query object, corresponding to the set of k-nearest neighbors. We investigate the effect of adversarial perturbation on the ranking of objects with respect to a query. Through theoretical analysis, supported by experiments, we demonstrate that as the intrinsic dimensionality of the data domain rises, the amount of perturbation required to subvert neighborhood rankings diminishes, and the vulnerability to adversarial attack rises. We examine two modes of perturbation of the query: either `closer' to the target point, or `farther' from it. We also consider two perspectives: `query-centric', examining the effect of perturbation on the query's own neighborhood ranking, and `target-centric', considering the ranking of the query point in the target's neighborhood set. All four cases correspond to practical scenarios involving classification and retrieval.}
}


@article{DBLP:journals/tifs/WangK21,
	author = {Kuo Wang and
                  Ajay Kumar},
	title = {Periocular-Assisted Multi-Feature Collaboration for Dynamic Iris Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {866--879},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023289},
	doi = {10.1109/TIFS.2020.3023289},
	timestamp = {Tue, 01 Dec 2020 09:11:36 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Iris recognition has emerged as one of the most accurate and convenient biometric for person identification and has been increasingly employed in a wide range of e-security applications. The quality of iris images acquired at-a-distance or under less constrained imaging environments is known to degrade the iris recognition accuracy. The periocular information is inherently embedded in such iris images and can be exploited to assist in the iris recognition under such non-ideal scenarios. Our analysis of such iris templates also indicates significant degradation and reduction in the region of interest, where the iris recognition can benefit from a similarity distance that can consider importance of different binary bits, instead of the direct use of Hamming distance in the literature. Periocular information can be dynamically reinforced, by incorporating the differences in the effective area of available iris regions, for more accurate iris recognition. This article presents such a periocular-assisted dynamic framework for more accurate less-constrained iris recognition. The effectiveness of this framework is evaluated on three publicly available iris databases using within-dataset and cross-dataset performance evaluation, e.g., improvement in the recognition accuracy of 22.9%, 10.4% and 14.6% on three databases under both the verification and recognition scenarios.}
}


@article{DBLP:journals/tifs/YangZHHH21,
	author = {Zhongliang Yang and
                  Si{-}Yu Zhang and
                  Yuting Hu and
                  Zhiwen Hu and
                  Yongfeng Huang},
	title = {VAE-Stega: Linguistic Steganography Based on Variational Auto-Encoder},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {880--895},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023279},
	doi = {10.1109/TIFS.2020.3023279},
	timestamp = {Tue, 09 Mar 2021 14:31:01 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangZHHH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, linguistic steganography based on text auto-generation technology has been greatly developed, which is considered to be a very promising but also a very challenging research topic. Previous works mainly focus on optimizing the language model and conditional probability coding methods, aiming at generating steganographic sentences with better quality. In this paper, we first report some of our latest experimental findings, which seem to indicate that the quality of the generated steganographic text cannot fully guarantee its steganographic security, and even has a prominent perceptual-imperceptibility and statistical-imperceptibility conflict effect (Psic Effect). To further improve the imperceptibility and security of generated steganographic texts, in this paper, we propose a new linguistic steganography based on Variational Auto-Encoder (VAE), which can be called VAE-Stega. We use the encoder in VAE-Stega to learn the overall statistical distribution characteristics of a large number of normal texts, and then use the decoder in VAE-Stega to generate steganographic sentences which conform to both of the statistical language model as well as the overall statistical distribution of normal sentences, so as to guarantee both the perceptual-imperceptibility and statistical-imperceptibility of the generated steganographic texts at the same time. We design several experiments to test the proposed method. Experimental results show that the proposed model can greatly improve the imperceptibility of the generated steganographic sentences and thus achieves the state of the art performance.}
}


@article{DBLP:journals/tifs/WangZLSB21,
	author = {Qian Wang and
                  Baolin Zheng and
                  Qi Li and
                  Chao Shen and
                  Zhongjie Ba},
	title = {Towards Query-Efficient Adversarial Attacks Against Automatic Speech
                  Recognition Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {896--908},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3026543},
	doi = {10.1109/TIFS.2020.3026543},
	timestamp = {Thu, 23 Jun 2022 20:01:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangZLSB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial attacks, which attract explosive rese- arch attention in recent years, have achieved fantastic success in fooling neural networks, especially for image-classification tasks. While for automatic speech recognition (ASR) tasks, the state-of-the-arts mainly focus on white-box attacks where the adversary is assumed to get full access to the details inside the system, e.g., network architecture, weights, etc. However, this assumption does not hold in practice. The construction of real-world adversarial examples against ASR systems is still a very challenging problem. In this paper, we, for the first time, present a novel and effective attack on ASR systems, named Selective Gradient Estimation Attack (SGEA). Compared with prior literatures, SGEA only needs limited access to the output probabilities of neural networks, and achieves extremely high efficiency and success rates. We attacked the DeepSpeech system on Mozilla Common Voice and LibriSpeech datasets in our experiments. The results demonstrate that SGEA improves the attack success rate from 35% to 98%, while reducing the number of queries by 66%.}
}


@article{DBLP:journals/tifs/ZhangLCXHZH21,
	author = {Zhihong Zhang and
                  Ruiyang Liang and
                  Xu Chen and
                  Xuexin Xu and
                  Guosheng Hu and
                  Wangmeng Zuo and
                  Edwin R. Hancock},
	title = {Semi-Supervised Face Frontalization in the Wild},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {909--922},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3025412},
	doi = {10.1109/TIFS.2020.3025412},
	timestamp = {Fri, 06 May 2022 08:22:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLCXHZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Synthesizing a frontal view face from a single nonfrontal image, i.e. face frontalization, is a task of practical importance in a wide range of facial image analysis applications. However, to train the frontalization model in a supervised manner, most existing face frontalization methods rely on the availability of nonfrontal-frontal face pairs (typically from the Multi-PIE dataset) captured in a constrained environment. Such approaches, in return, limit the generalizability of their application to unconstrained scenarios. Unfortunately, although a large amount of in-the-wild face datasets are available, they cannot easily be utilized for face frontalization training since the nonfrontal and frontal facial images are not paired. To train a frontalization network which generalizes well to both constrained and unconstrained environments, we propose a semi-supervised learning framework which effectively uses both (labeled) indoor and (unlabeled) outdoor faces. Specifically, to achieve this goal, this article presents a Cycle-Consistent Face Frontalization Generative Adversarial Network (CCFF-GAN) which consists of both (1) the supervised and (2) the unsupervised components. For (1), we use the indoor paired (labeled) data to learn a roughly accurate frontalization network which may not generalize well to outdoor (in-the-wild) scenarios. For (2), to cope with the generalization issue, the unsupervised part uses the unpaired (unlabeled) images under the perceptual cycle consistency constraint in the semantic feature space to generalize the network from controlled (indoor) to uncontrolled (outdoor) environment. Extensive experiments demonstrate the effectiveness of the proposed method in comparison with the state-of-the-art face frontalization methods, especially under the in-the-wild scenarios.}
}


@article{DBLP:journals/tifs/ChenLLTHDCK21,
	author = {Guang Chen and
                  Peigen Liu and
                  Zhengfa Liu and
                  Huajin Tang and
                  Lin Hong and
                  Jinhu Dong and
                  J{\"{o}}rg Conradt and
                  Alois C. Knoll},
	title = {NeuroAED: Towards Efficient Abnormal Event Detection in Visual Surveillance
                  With Neuromorphic Vision Sensor},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {923--936},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023791},
	doi = {10.1109/TIFS.2020.3023791},
	timestamp = {Wed, 19 May 2021 08:30:41 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenLLTHDCK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Abnormal event detection is an important task in research and industrial applications, which has received considerable attention in recent years. Existing methods usually rely on standard frame-based cameras to record the data and process them with computer vision technologies. In contrast, this paper presents a novel neuromorphic vision based abnormal event detection system. Compared to the frame-based camera, neuromorphic vision sensors, such as Dynamic Vision Sensor (DVS), do not acquire full images at a fixed frame rate but rather have independent pixels that output intensity changes (called events) asynchronously at the time they occur. Thus, it avoids the design of the encryption scheme. Since events are triggered by moving edges on the scene, DVS is a natural motion detector for the abnormal objects and automatically filters out any temporally-redundant information. Based on this unique output, we first propose a highly efficient method based on the event density to select activated event cuboids and locate the foreground. We design a novel event-based multiscale spatio-temporal descriptor to extract features from the activated event cuboids for the abnormal event detection. Additionally, we build the NeuroAED dataset, the first public dataset dedicated to abnormal event detection with neuromorphic vision sensor. The NeuroAED dataset consists of four sub-datasets: Walking, Campus, Square, and Stair dataset. Experiments are conducted based on these datasets and demonstrate the high efficiency and accuracy of our method.}
}


@article{DBLP:journals/tifs/CaiLWCK21,
	author = {Rizhao Cai and
                  Haoliang Li and
                  Shiqi Wang and
                  Changsheng Chen and
                  Alex C. Kot},
	title = {{DRL-FAS:} {A} Novel Framework Based on Deep Reinforcement Learning
                  for Face Anti-Spoofing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {937--951},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3026553},
	doi = {10.1109/TIFS.2020.3026553},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CaiLWCK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inspired by the philosophy employed by human beings to determine whether a presented face example is genuine or not, i.e., to glance at the example globally first and then carefully observe the local regions to gain more discriminative information, for the face anti-spoofing problem, we propose a novel framework based on the Convolutional Neural Network (CNN) and the Recurrent Neural Network (RNN). In particular, we model the behavior of exploring face-spoofing-related information from image sub-patches by leveraging deep reinforcement learning. We further introduce a recurrent mechanism to learn representations of local information sequentially from the explored sub-patches with an RNN. Finally, for the classification purpose, we fuse the local information with the global one, which can be learned from the original input image through a CNN. Moreover, we conduct extensive experiments, including ablation study and visualization analysis, to evaluate our proposed framework on various public databases. The experiment results show that our method can generally achieve state-of-the-art performance among all scenarios, demonstrating its effectiveness.}
}


@article{DBLP:journals/tifs/TangLBLH21,
	author = {Weixuan Tang and
                  Bin Li and
                  Mauro Barni and
                  Jin Li and
                  Jiwu Huang},
	title = {An Automatic Cost Learning Framework for Image Steganography Using
                  Deep Reinforcement Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {952--967},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3025438},
	doi = {10.1109/TIFS.2020.3025438},
	timestamp = {Tue, 01 Dec 2020 09:11:36 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TangLBLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automatic cost learning for steganography based on deep neural networks is receiving increasing attention. Steganographic methods under such a framework have been shown to achieve better security performance than methods adopting hand-crafted costs. However, they still exhibit some limitations that prevent a full exploitation of their potentiality, including using a function-approximated neural-network-based embedding simulator and a coarse-grained optimization objective without explicitly using pixel-wise information. In this article, we propose a new embedding cost learning framework called SPAR-RL (Steganographic Pixel-wise Actions and Rewards with Reinforcement Learning) that overcomes the above limitations. In SPAR-RL, an agent utilizes a policy network which decomposes the embedding process into pixel-wise actions and aims at maximizing the total rewards from a simulated steganalytic environment, while the environment employs an environment network for pixel-wise reward assignment. A sampling process is utilized to emulate the message embedding of an optimal embedding simulator. Through the iterative interactions between the agent and the environment, the policy network learns a secure embedding policy which can be converted into pixel-wise embedding costs for practical message embedding. Experimental results demonstrate that the proposed framework achieves state-of-the-art security performance against various modern steganalyzers, and outperforms existing cost learning frameworks with regard to learning stability and efficiency.}
}


@article{DBLP:journals/tifs/LiSJZHC21,
	author = {Guyue Li and
                  Chen Sun and
                  Eduard A. Jorswieck and
                  Junqing Zhang and
                  Aiqun Hu and
                  You Chen},
	title = {Sum Secret Key Rate Maximization for {TDD} Multi-User Massive {MIMO}
                  Wireless Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {968--982},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3026466},
	doi = {10.1109/TIFS.2020.3026466},
	timestamp = {Tue, 11 May 2021 09:03:20 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiSJZHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical-layer key generation (PKG) based on channel reciprocity has recently emerged as a new technique to establish secret keys between devices. Most works focus on pairwise communication scenarios with single or small-scale antennas. However, the fifth generation (5G) wireless communications employ massive multiple-input multiple-output (MIMO) to support multiple users simultaneously, bringing serious overhead of reciprocal channel acquisition. This paper presents a multi-user secret key generation in massive MIMO wireless networks. We provide a beam domain channel model, in which different elements represent the channel gains from different transmit directions to different receive directions. Based on this channel model, we analyze the secret key rate and derive a closed-form expression under independent channel conditions. To maximize the sum secret key rate, we provide the optimal conditions for the Kronecker product of the precoding and receiving matrices and propose an algorithm to generate these matrices with pilot reuse. The proposed optimization design can significantly reduce the pilot overhead of the reciprocal channel state information acquisition. Furthermore, we analyze the security under the channel correlation between user terminals (UTs), and propose a low overhead multi-user secret key generation with non-overlapping beams between UTs. Simulation results demonstrate the near-optimal performance of the proposed precoding and receiving matrices design and the advantages of the non-overlapping beam allocation.}
}


@article{DBLP:journals/tifs/JiangZCHY21,
	author = {Xiaofeng Jiang and
                  Feng Zhou and
                  Shuangwu Chen and
                  Huasen He and
                  Jian Yang},
	title = {Jamming Resilient Tracking Using POMDP-Based Detection of Hidden Targets},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {983--998},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3027145},
	doi = {10.1109/TIFS.2020.3027145},
	timestamp = {Tue, 01 Dec 2020 09:11:36 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiangZCHY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considers the anti-jamming optimization problem for tracking multiple moving target flight vehicles in the presence of deception jammers. Since the radar is not able to separate the real target vehicles from a large number of deceptive vehicles, we promote the existing non-anti-jamming tracking model to the anti-jamming partially observable Markov decision process-based (POMDP-based) game tracking model by establishing a new anti-jamming Bayesian tracker. The proposed tracker is able to separate the hidden real target vehicles and establish their accurate trajectories, but the limited radar resources will decrease the accuracy. In order to effectively utilize the limited resources to guarantee the anti-jamming performance, this work deduces the anti-jamming performance gradients with respect to the resource management policy, which can be estimated with the asymptotically vanished biases. With the gradient estimates, the optimal anti-jamming resource management policy can be found with the tolerable complexity. The convergence analysis shows that the algorithm converges to a Nash equilibrium solution with probability 1. Numerical results show that the proposed algorithm can obtain the accurate target trajectories in the presence of jammers.}
}


@article{DBLP:journals/tifs/TipleaH21,
	author = {Ferucio Laurentiu Tiplea and
                  Cristian Hristea},
	title = {{PUF} Protected Variables: {A} Solution to {RFID} Security and Privacy
                  Under Corruption With Temporary State Disclosure},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {999--1013},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3027147},
	doi = {10.1109/TIFS.2020.3027147},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TipleaH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RFID tag corruption is a powerful attack on RFID systems, especially when it reveals the tag's temporary state. Under such an attack, no RFID scheme can achieve both security and privacy if the tags are not endowed with some hardware primitives, such as physically unclonable functions (PUFs), to prevent adversarial access to secret information. However, the use of such primitives does not constitute a guarantee for security and privacy because they do not substitute a good RFID system design. In this paper a general technique is proposed, to translate any (PUF-based) RFID scheme that is secure and private under corruption without temporary state disclosure into a PUF-based RFID scheme that is secure and private under corruption with temporary state disclosure. Our technique is optimal with respect to the tag overhead induced by PUFs. The technique is richly exemplified on both RFID and PUF-based RFID schemes. As a notable result, the first PUF-based RFID scheme is obtained, that is secure and forward private, but not destructive private, under corruption with temporary state disclosure. By using our technique, some flawed PUF-based RFID schemes that have been proposed so far in the literature can be fixed.}
}


@article{DBLP:journals/tifs/YamacAPRSG21,
	author = {Mehmet Yama{\c{c}} and
                  Mete Ahishali and
                  Nikolaos Passalis and
                  Jenni Raitoharju and
                  B{\"{u}}lent Sankur and
                  Moncef Gabbouj},
	title = {Multi-Level Reversible Data Anonymization via Compressive Sensing
                  and Data Hiding},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1014--1028},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3026467},
	doi = {10.1109/TIFS.2020.3026467},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YamacAPRSG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in intelligent surveillance systems have enabled a new era of smart monitoring in a wide range of applications from health monitoring to homeland security. However, this boom in data gathering, analyzing and sharing brings in also significant privacy concerns. We propose a Compressive Sensing (CS) based data encryption that is capable of both obfuscating selected sensitive parts of documents and compressively sampling, hence encrypting both sensitive and non-sensitive parts of the document. The scheme uses a data hiding technique on CS-encrypted signal to preserve the one-time use obfuscation matrix. The proposed privacy-preserving approach offers a low-cost multi-tier encryption system that provides different levels of reconstruction quality for different classes of users, e.g., semi-authorized, full-authorized. As a case study, we develop a secure video surveillance system and analyze its performance.}
}


@article{DBLP:journals/tifs/HuaZZ21,
	author = {Jingyu Hua and
                  Zidong Zhou and
                  Sheng Zhong},
	title = {Flow Misleading: Worm-Hole Attack in Software-Defined Networking via
                  Building In-Band Covert Channel},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1029--1043},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3013093},
	doi = {10.1109/TIFS.2020.3013093},
	timestamp = {Tue, 16 Aug 2022 23:06:35 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuaZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Link Layer Discovery Protocol (LLDP), which is widely used by the controller in Software-Defined Networking to discover the network topology, has been demonstrated to be unable to guarantee the integrity of its messages. Attackers could exploit this vulnerability to fabricate LLDP packets to declare a false link connecting two distant switches to the controller. By doing so, the controller would be misled to route flows to the false links, which leads to further DoS, eavesdropping and even hijacking attacks. This attack seems very similar to the well-known Worm-Hole Attack in wireless sensor networking (WSN). Nevertheless, in WSN, attackers are assumed to leverage an out-of-band wired channel to achieve the true packet transmission between the two cheating sensor nodes. Unfortunately, in SDN, there usually does not exist any out-of-band channels between the distant cheating switches. Flows misguided to the fake link will cause 100% packet loss, and thus be detected soon. In this article, we address this problem and propose the first True worm-hole attack in SDN, which could achieve packet transmission over the forged link without using any out-of-band channels. Instead, it introduces a relay host in the networks to build a completely in-band covert channel between the two cheating switches. Unlike the existing studies, a relay host is not required to be directly linked to them. Moreover, attackers are only assumed to poss the remote read and write privileges of the flow tables of the both cheating switches and do not have to alter any of their software or hardware. Our extensive experiments demonstrate the high feasibility of this attack. Both the increases of transmission delays and packet loss rates are within a reasonable range. We finally present and evaluate the countermeasures against the proposed attack.}
}


@article{DBLP:journals/tifs/CaiHCCLZ21,
	author = {Jiancheng Cai and
                  Hu Han and
                  Jiyun Cui and
                  Jie Chen and
                  Li Liu and
                  S. Kevin Zhou},
	title = {Semi-Supervised Natural Face De-Occlusion},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1044--1057},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3023793},
	doi = {10.1109/TIFS.2020.3023793},
	timestamp = {Mon, 31 May 2021 15:36:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CaiHCCLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Occlusions are often present in face images in the wild, e.g., under video surveillance and forensic scenarios. Existing face de-occlusion methods are limited as they require the knowledge of an occlusion mask. To overcome this limitation, we propose in this paper a new generative adversarial network (named OA-GAN) for natural face de-occlusion without an occlusion mask, enabled by learning in a semi-supervised fashion using (i) paired images with known masks of artificial occlusions and (ii) natural images without occlusion masks. The generator of our approach first predicts an occlusion mask, which is used for filtering the feature maps of the input image as a semantic cue for de-occlusion. The filtered feature maps are then used for face completion to recover a non-occluded face image. The initial occlusion mask prediction might not be accurate enough, but it gradually converges to the accurate one because of the adversarial loss we use to perceive which regions in a face image need to be recovered. The discriminator of our approach consists of an adversarial loss, distinguishing the recovered face images from natural face images, and an attribute preserving loss, ensuring that the face image after de-occlusion can retain the attributes of the input face image. Experimental evaluations on the widely used CelebA dataset and a dataset with natural occlusions we collected show that the proposed approach can outperform the state of the art methods in natural face de-occlusion.}
}


@article{DBLP:journals/tifs/HoffmannSP21,
	author = {Max Hoffmann and
                  Falk Schellenberg and
                  Christof Paar},
	title = {{ARMORY:} Fully Automated and Exhaustive Fault Simulation on {ARM-M}
                  Binaries},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1058--1073},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3027143},
	doi = {10.1109/TIFS.2020.3027143},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HoffmannSP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Embedded systems are ubiquitous. However, physical access of users and likewise attackers makes them often threatened by fault attacks: a single fault during the computation of a cryptographic primitive can lead to a total loss of system security. This can have serious consequences, e.g., in safety-critical systems, including bodily harm and catastrophic technical failures. However, countermeasures often focus on isolated fault models and high layers of abstraction. This leads to a dangerous sense of security, because exploitable faults that are only visible at machine code level might not be covered by countermeasures. In this work we present ARMORY, a fully automated open source framework for exhaustive fault simulation on binaries of the ubiquitous ARM-M class. It allows engineers and analysts to efficiently scan a binary for potential weaknesses against arbitrary combinations of multi-variate fault injections under a large variety of fault models. Using ARMORY, we demonstrate the power of fully automated fault analysis and the dangerous implications of applying countermeasures without knowledge of physical addresses and offsets. We exemplarily analyze two case studies, which are highly relevant for practice: a DFA on AES (cryptographic) and a secure bootloader (non-cryptographic). Our results show that indeed numerous exploitable faults found by ARMORY which occur in the actual implementations are easily missed in manual inspection. Crucially, most faults are only visible when taking machine code information, i.e., addresses and offsets, into account. Surprisingly, we show that a countermeasure that protects against one type of fault can actually largely increase the vulnerability to other fault models. Our work demonstrates the need for countermeasures that, at least in their evaluation, are not restricted to isolated fault models and consider low-level information during the design process.}
}


@article{DBLP:journals/tifs/HameedGG21,
	author = {Muhammad Zaid Hameed and
                  Andr{\'{a}}s Gy{\"{o}}rgy and
                  Deniz G{\"{u}}nd{\"{u}}z},
	title = {The Best Defense Is a Good Offense: Adversarial Attacks to Avoid Modulation
                  Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1074--1087},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3025441},
	doi = {10.1109/TIFS.2020.3025441},
	timestamp = {Tue, 01 Dec 2020 09:11:36 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HameedGG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a communication scenario, in which an intruder tries to determine the modulation scheme of the intercepted signal. Our aim is to minimize the accuracy of the intruder, while guaranteeing that the intended receiver can still recover the underlying message with the highest reliability. This is achieved by perturbing channel input symbols at the encoder, similarly to adversarial attacks against classifiers in machine learning. In image classification, the perturbation is limited to be imperceptible to a human observer, while in our case the perturbation is constrained so that the message can still be reliably decoded by the legitimate receiver, which is oblivious to the perturbation. Simulation results demonstrate the viability of our approach to make wireless communication secure against state-of-the-art intruders (using deep learning or decision trees) with minimal sacrifice in the communication performance. On the other hand, we also demonstrate that using diverse training data and curriculum learning can significantly boost the accuracy of the intruder.}
}


@article{DBLP:journals/tifs/ZhouP21,
	author = {Jizhe Zhou and
                  Chi{-}Man Pun},
	title = {Personal Privacy Protection via Irrelevant Faces Tracking and Pixelation
                  in Video Live Streaming},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1088--1103},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029913},
	doi = {10.1109/TIFS.2020.3029913},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To date, the privacy-protection intended pixelation tasks are still labor-intensive and yet to be studied. With the prevailing of video live streaming, establishing an online face pixelation mechanism during streaming is an urgency. In this paper, we develop a new method called Face Pixelation in Video Live Streaming (FPVLS) to generate automatic personal privacy filtering during unconstrained streaming activities. Simply applying multi-face trackers will encounter problems in target drifting, computing efficiency, and over-pixelation. Therefore, for fast and accurate pixelation of irrelevant people's faces, FPVLS is organized in a frame-to-video structure of two core stages. On individual frames, FPVLS utilizes image-based face detection and embedding networks to yield face vectors. In the raw trajectories generation stage, the proposed Positioned Incremental Affinity Propagation (PIAP) clustering algorithm leverages face vectors and positioned information to quickly associate the same person's faces across frames. Such frame-wise accumulated raw trajectories are likely to be intermittent and unreliable on video level. Hence, we further introduce the trajectory refinement stage that merges a proposal network with the two-sample test based on the Empirical Likelihood Ratio (ELR) statistic to refine the raw trajectories. A Gaussian filter is laid on the refined trajectories for final pixelation. On the video live streaming dataset we collected, FPVLS obtains satisfying accuracy, real-time efficiency, and contains the over-pixelation problems.}
}


@article{DBLP:journals/tifs/ShahzadZ21,
	author = {Khurram Shahzad and
                  Xiangyun Zhou},
	title = {Covert Wireless Communications Under Quasi-Static Fading With Channel
                  Uncertainty},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1104--1116},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029902},
	doi = {10.1109/TIFS.2020.3029902},
	timestamp = {Tue, 01 Dec 2020 09:11:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ShahzadZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Covert communications enable a transmitter to send information reliably in the presence of an adversary, who looks to detect whether the transmission took place or not. We consider covert communications over quasi-static block fading channels, where users suffer from channel uncertainty. We investigate the adversary Willie's optimal detection performance in two extreme cases, i.e., the case of perfect channel state information (CSI) and the case of channel distribution information (CDI) only. It is shown that in the large detection error regime, Willie's detection performances of these two cases are essentially indistinguishable, which implies that the quality of CSI does not help Willie in improving his detection performance. This result enables us to study the covert transmission design without the need to factor in the exact amount of channel uncertainty at Willie. We then obtain the optimal and suboptimal closed-form solution to the covert transmission design. Our result reveals fundamental difference in the design between the case of quasi-static fading channel and the previously studied case of non-fading AWGN channel.}
}


@article{DBLP:journals/tifs/WangZLY21,
	author = {Yaofei Wang and
                  Weiming Zhang and
                  Weixiang Li and
                  Nenghai Yu},
	title = {Non-Additive Cost Functions for {JPEG} Steganography Based on Block
                  Boundary Maintenance},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1117--1130},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029908},
	doi = {10.1109/TIFS.2020.3029908},
	timestamp = {Sun, 02 Oct 2022 15:51:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangZLY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances show that a reasonable non-additive cost function can significantly improve the security level of additive cost based steganography. So far, there is only one principle, called block boundary continuity (BBC), that has been proposed to define the non-additive cost function for JPEG steganography, and it aims at synchronizing the modification direction of inter-block boundaries in the spatial domain. In this article, we found that JPEG steganography usually introduces more and larger modifications on the boundary than on the inside of each intra-block in the spatial domain, which is another important factor affecting security. Therefore, we present a new principle, called block boundary maintenance (BBM), to minimize the modifications on the spatial block boundaries. In theory, we deduce the BBM principle on how to modify a pair of DCT coefficients of the intra-block to reduce the modifications on the spatial block boundary. According to the BBM principle, we design a new strategy to define non-additive cost functions for JPEG steganography by exploiting the coefficient correlation of the intra-block in the DCT domain. The experimental results show that the BBM-based strategy can minimize modifications on the spatial block boundaries and thus achieve a high-security level when resisting modern JPEG steganalysis. Furthermore, the two principles of BBC and BBM can be fused to further improve the empirical security.}
}


@article{DBLP:journals/tifs/JoshiAI21,
	author = {Chaitanya Joshi and
                  Jes{\'{u}}s M. R{\'{\i}}os Aliaga and
                  David R{\'{\i}}os Insua},
	title = {Insider Threat Modeling: An Adversarial Risk Analysis Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1131--1142},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029898},
	doi = {10.1109/TIFS.2020.3029898},
	timestamp = {Thu, 14 Oct 2021 09:37:26 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JoshiAI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Insider threats entail major security issues in many organizations. Game theoretic models of insider threats so far proposed do not take into account important factors such as the organizational culture and whether the attacker was detected or not. They also fail to model defensive mechanisms already put in place by an organization to mitigate insider attacks. We propose two new models which incorporate these settings and, hence, are more realistic, and use adversarial risk analysis to find their solutions. Our models and solutions are general and can be applied to most insider threat scenarios. A data security example illustrates the discussion.}
}


@article{DBLP:journals/tifs/DebJ21,
	author = {Debayan Deb and
                  Anil K. Jain},
	title = {Look Locally Infer Globally: {A} Generalizable Face Anti-Spoofing
                  Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1143--1157},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029879},
	doi = {10.1109/TIFS.2020.3029879},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DebJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {State-of-the-art presentation attack detection approaches tend to overfit to the presentation attack instruments seen during training and fail to generalize to unknown presentation attack instruments. Given that face presentation attack detection is inherently a local task, we propose a face presentation attack detection framework, namely Self-Supervised Regional Fully Convolutional Network (SSR-FCN), that is trained to learn local discriminative cues from a face image in a self-supervised manner. The proposed framework (i) improves generalizability while maintaining the computational efficiency of holistic face presentation attack detection approaches (<; 4 ms on a Nvidia GTX 1080Ti GPU), and (ii) is more interpretable since it localizes the parts of the face that are labeled as presentation attacks. Experimental results show that SSR-FCN can achieve TDR = 65% @ 2.0% FDR when evaluated on a dataset, SiW-M, comprising of 13 different presentation attack instruments under unknown attacks while achieving competitive performances under standard benchmark datasets (Oulu-NPU, CASIA-MFSD, and Replay-Attack).}
}


@article{DBLP:journals/tifs/ChengK21,
	author = {Kevin H. M. Cheng and
                  Ajay Kumar},
	title = {Deep Feature Collaboration for Challenging 3D Finger Knuckle Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1158--1173},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029906},
	doi = {10.1109/TIFS.2020.3029906},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChengK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contactless 3D finger knuckle pattern is a new biometric identifier which offers highly discriminative features for the finger knuckle based personal identification. State-of-the-art methods for object recognition, a more generic problem, employ deep neural network based approaches and demonstrate superior effectiveness. However, any direct applications from those methods do not outperform specialized hand-crafted feature description approaches for the problem addressed in this paper. In addition, such deep neural network based methods have to address challenges associated with emerging biometrics, e.g. availability of very limited training data, large intra-class or train-test sample variations as observed for the real applications, etc. This paper attempts to address the above challenges and introduces a new deep neural network based approach for the contactless 3D finger knuckle identification. Our approach simultaneously encodes and incorporates deep features from multiple scales to form a more robust deep feature representation. Such collaborative feature representations are robustly matched using an efficient alignment scheme with a fully convolutional architecture to accommodate involuntary finger variations during the contactless imaging. Comparative experimental results in the two-session 3D finger knuckle images database, acquired from over 200 subjects and is publicly introduced from this paper, illustrate superior performance over the state-of-the-art methods, e.g. offering ~22% GAR improvement at extremely low FAR under challenging comparison scenarios. Additional experiments in other publicly available databases including 3D palmprint, 3D fingerprint, and 2D finger knuckle further validate the effectiveness and demonstrate the generalizability of the proposed approach.}
}


@article{DBLP:journals/tifs/ZhuCWW21,
	author = {Qiang Zhu and
                  Mingliang Chen and
                  Chau{-}Wai Wong and
                  Min Wu},
	title = {Adaptive Multi-Trace Carving for Robust Frequency Tracking in Forensic
                  Applications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1174--1189},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3030182},
	doi = {10.1109/TIFS.2020.3030182},
	timestamp = {Thu, 31 Dec 2020 01:35:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuCWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the field of information forensics, many emerging problems involve a critical step that estimates and tracks weak frequency components in noisy signals. It is often challenging for the prior art of frequency tracking to i) achieve a high accuracy under noisy conditions, ii) detect and track multiple frequency components efficiently, or iii) strike a good trade-off of the processing delay versus the resilience and the accuracy of tracking. To address these issues, we propose Adaptive Multi-Trace Carving (AMTC), a unified approach for detecting and tracking one or more subtle frequency components under very low signal-to-noise ratio (SNR) conditions and in near real time. AMTC takes as input a time-frequency representation of the system's preprocessing results (such as the spectrogram), and identifies frequency components through iterative dynamic programming and adaptive trace compensation. The proposed algorithm considers relatively high energy traces sustaining over a certain duration as an indicator of the presence of frequency/oscillation components of interest and track their time-varying trend. Extensive experiments using both synthetic data and real-world forensic data of power signatures and physiological monitoring reveal that the proposed method outperforms representative prior art under low SNR conditions, and can be implemented in near real-time settings. The proposed AMTC algorithm can empower the development of new information forensic technologies that harness very small signals.}
}


@article{DBLP:journals/tifs/Gunlu21,
	author = {Onur G{\"{u}}nl{\"{u}}},
	title = {Multi-Entity and Multi-Enrollment Key Agreement With Correlated Noise},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1190--1202},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029885},
	doi = {10.1109/TIFS.2020.3029885},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Gunlu21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A basic model for key agreement with a remote (or hidden) source is extended to a multi-user model with joint secrecy and privacy constraints over all entities that do not trust each other after key agreement. Multiple entities using different measurements of the same source through broadcast channels (BCs) to agree on mutually-independent local secret keys are considered. Our model is the proper multi-user extension of the basic model since the encoder and decoder pairs are not assumed to trust other pairs after key agreement, unlike assumed in the literature. Strong secrecy constraints imposed on all secret keys jointly, which is more stringent than separate secrecy leakage constraints for each secret key considered in the literature, are satisfied. Inner bounds for maximum key rate, and minimum privacy-leakage and database-storage rates are proposed for any finite number of entities. Inner and outer bounds for degraded and less-noisy BCs are given to illustrate cases with strong privacy. A multi-enrollment model that is used for common physical unclonable functions is also considered to establish inner and outer bounds for key-leakage-storage regions that differ only in the Markov chains imposed. For this special case, the encoder and decoder measurement channels have the same channel transition matrix and secrecy leakage is measured for each secret key separately. We illustrate cases for which it is useful to have multiple enrollments as compared to a single enrollment and vice versa.}
}


@article{DBLP:journals/tifs/ZhangLCZ21,
	author = {Hangjing Zhang and
                  Yuejiang Li and
                  Yan Chen and
                  H. Vicky Zhao},
	title = {Smart Evolution for Information Diffusion Over Social Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1203--1217},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3032039},
	doi = {10.1109/TIFS.2020.3032039},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLCZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In social network, the existence of malicious users can create lots of detrimental consequences. To diminish their negative influences, it is necessary for rational users to identify and interact with each neighbor carefully to protect themselves from malicious ones. Therefore, it is crucial to establish a rule for users’ interaction in order to mitigate malicious users’ influences. In this paper, we propose a smart evolution model based on evolutionary game theory by introducing the reputation mechanism. The model takes into account both current reputation and instant incentives during users’ decision-making process. On the basis of whether users share reputation values with others, we introduce schemes without reciprocity principle and with the indirect reciprocity principle respectively. With the social norm and reputation updating policy, we theoretically analyze the evolutionary dynamics and corresponding ESSs by explicitly considering the effects of malicious users. Finally, simulations based on synthetic networks and real-world data are conducted to validate the effectiveness of the proposed smart evolution model.}
}


@article{DBLP:journals/tifs/DuanCWCL21,
	author = {Shuchao Duan and
                  Zhenxue Chen and
                  Q. M. Jonathan Wu and
                  Lei Cai and
                  Dan Lu},
	title = {Multi-Scale Gradients Self-Attention Residual Learning for Face Photo-Sketch
                  Transformation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1218--1230},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3031386},
	doi = {10.1109/TIFS.2020.3031386},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DuanCWCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face sketch synthesis, as a key technique for solving face sketch recognition, has made considerable progress in recent years. Due to the difference of modality between face photo and face sketch, traditional exemplar-based methods often lead to missed texture details and deformation while synthesizing sketches. And limited to the local receptive field, Convolutional Neural Networks-based methods cannot deal with the interdependence between features well, which makes the constraint of facial features insufficient; as such, it cannot retain some details in the synthetic image. Moreover, the deeper the network layer is, the more obvious the problems of gradient disappearance and explosion will be, which will lead to instability in the training process. Therefore, in this paper, we propose a multi-scale gradients self-attention residual learning framework for face photo-sketch transformation that embeds a self-attention mechanism in the residual block, making full use of the relationship between features to selectively enhance the characteristics of specific information through self-attention distribution. Simultaneously, residual learning can keep the characteristics of the original features from being destroyed. In addition, the problem of instability in GAN training is alleviated by allowing discriminator to become a function of multi-scale outputs of the generator in the training process. Based on cycle framework, the matching between the target domain image and the source domain image can be constrained while the mapping relationship between the two domains is established so that the tasks of face photo-to-sketch synthesis (FP2S) and face sketch-to-photo synthesis (FS2P) can be achieved simultaneously. Both Image Quality Assessment (IQA) and experiments related to face recognition show that our method can achieve state-of-the-art performance on the public benchmarks, whether using FP2S or FS2P.}
}


@article{DBLP:journals/tifs/GuFLZ21,
	author = {Shan Gu and
                  Jianjiang Feng and
                  Jiwen Lu and
                  Jie Zhou},
	title = {Latent Fingerprint Registration via Matching Densely Sampled Points},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1231--1244},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3032041},
	doi = {10.1109/TIFS.2020.3032041},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GuFLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Latent fingerprint matching is a very important but unsolved problem. As a key step of fingerprint matching, fingerprint registration has a great impact on the recognition performance. Existing latent fingerprint registration approaches are mainly based on establishing correspondences between minutiae, and hence will certainly fail when there are no sufficient number of extracted minutiae due to small fingerprint area or poor image quality. Minutiae extraction has become the bottleneck of latent fingerprint registration. In this paper, we propose a non-minutia latent fingerprint registration method which estimates the spatial transformation between a pair of fingerprints through a dense fingerprint patch alignment and matching procedure. Given a pair of fingerprints to match, we bypass the minutiae extraction step and take uniformly sampled points as key points. Then the proposed patch alignment and matching algorithm compares all pairs of sampling points and produces their similarities along with alignment parameters. Finally, a set of consistent correspondences are found by spectral clustering. Extensive experiments on NIST27 database and MOLF database show that the proposed method achieves the state-of-the-art registration performance, especially under challenging conditions. Code is made publicly available at: https://github.com/Gus233/Latent-Fingerprint-Registration.}
}


@article{DBLP:journals/tifs/XiaSCH21,
	author = {Yusheng Xia and
                  Jinshu Su and
                  Rongmao Chen and
                  Xinyi Huang},
	title = {{APGS:} An Efficient Source-Accountable and Metadata-Private Protocol
                  in the Network Layer},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1245--1260},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3032294},
	doi = {10.1109/TIFS.2020.3032294},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XiaSCH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the revelations of global-scale pervasive surveillance programs, Internet users have an increasing demand for privacy. However, this is usually undesirable for network service providers because attackers would be able to anonymize themselves and avoid regulation while conducting network attacks. Therefore, network service providers want to hold users accountable and it has been widely considered as a tussle to find a good balance point between the accountability and privacy for the Internet. In this work, we first show that existing representative approaches mainly suffer from narrow-range accountability, low efficiency or risky key management. Motivated by these observations, we propose an efficient network layer protocol called APGS to balance the accountability and privacy. At the core of our APGS is the group signature which, however, is not trivial to apply for the network layer mainly due to the efficiency, revocation, and privacy issues. We manage to overcome these challenges via proposing some novel approaches, including challenge-based cache strategy, scalable verifier-local revocation strategy, and Onion-then-Case strategy. We then evaluate the efficiency of APGS and conclude that in our environment, APGS can generate packets up to 20k pkts/s on a desktop and achieve approximately 80% of IP's goodput at most on a software router.}
}


@article{DBLP:journals/tifs/YuWL21,
	author = {Xinchun Yu and
                  Shuangqing Wei and
                  Yuan Luo},
	title = {Finite Blocklength Analysis of Gaussian Random Coding in {AWGN} Channels
                  Under Covert Constraint},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1261--1274},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3032292},
	doi = {10.1109/TIFS.2020.3032292},
	timestamp = {Fri, 05 Nov 2021 10:54:22 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YuWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is well known that finite blocklength analysis plays an important role in evaluating performances of communication systems in practical settings. This paper considers the achievability and converse bounds on the maximal channel coding rate (throughput) at a given blocklength and error probability in covert communication over AWGN channels. The covert constraint is given in terms of an upper bound on total variation distance (TVD) between the distributions of eavesdropped signals at an adversary with and without presence of active and legitimate communication, respectively. For the achievability, Gaussian random coding scheme is adopted for convenience in the analysis of TVD. The classical results of finite blocklength regime are not applicable in this case. By exploiting and extending canonical approaches, we first present new and more general achievability bounds for random coding schemes under maximal or average probability of error requirements. The general bounds are then applied to covert communication in AWGN channels where codewords are generated from Gaussian distribution while meeting the maximal power constraint. We further show an interesting connection between attaining tight achievability and converse bounds and solving two total variation distance based minimax and maxmin problems. The TVD constraint is analyzed under the given random coding scheme, which induces bounds on the transmission power through divergence inequalities. Further comparison is made between the new achievability bounds and existing ones derived under deterministic codebooks. Our thorough analysis thus leads us to a comprehensive characterization of the attainable throughput in covert communication over AWGN channels.}
}


@article{DBLP:journals/tifs/HigginsTP21,
	author = {Martin Higgins and
                  Fei Teng and
                  Thomas Parisini},
	title = {Stealthy {MTD} Against Unsupervised Learning-Based Blind {FDI} Attacks
                  in Power Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1275--1287},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3027148},
	doi = {10.1109/TIFS.2020.3027148},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HigginsTP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper examines how moving target defenses (MTD) implemented in power systems can be countered by unsupervised learning-based false data injection (FDI) attack and how MTD can be combined with physical watermarking to enhance the system resilience. A novel intelligent attack, which incorporates dimensionality reduction and density-based spatial clustering, is developed and shown to be effective in maintaining stealth in the presence of traditional MTD strategies. In resisting this new type of attack, a novel implementation of MTD combining with physical watermarking is proposed by adding Gaussian watermark into physical plant parameters to drive detection of traditional and intelligent FDI attacks, while remaining hidden to the attackers and limiting the impact on system operation and stability.}
}


@article{DBLP:journals/tifs/ZhangLWW21,
	author = {Jindan Zhang and
                  Rongxing Lu and
                  Baocang Wang and
                  Xu An Wang},
	title = {Comments on "Privacy-Preserving Public Auditing Protocol for Regenerating-Code-Based
                  Cloud Storage"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1288--1289},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3032283},
	doi = {10.1109/TIFS.2020.3032283},
	timestamp = {Mon, 03 Apr 2023 12:49:11 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Public auditing protocol is crucial for the success of cloud computing, as it can ensure the outsourced data in cloud server are not tampered by attackers. Due to its importance, public auditing protocol has received considerable attention in the past years. In 2015, Liu et al. proposed a privacy-preserving public auditing protocol for regenerating-code-based cloud storage (IEEE Transactions on Information Forensics and Security, 10(7):1513–1528, 2015) and claimed it is secure under the considered security model. However, in this article, we will show that their protocol is not as secure as they claimed, i.e., the proxy delegated by the data owner can forge an authenticator for any data block, which obviously invalidates their protocol’s security. We hope that by identifying the design flaw, similar weaknesses can be avoided in future protocol design.}
}


@article{DBLP:journals/tifs/ZhaoRYHZY21,
	author = {Fangyuan Zhao and
                  Xuebin Ren and
                  Shusen Yang and
                  Qing Han and
                  Peng Zhao and
                  Xinyu Yang},
	title = {Latent Dirichlet Allocation Model Training With Differential Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1290--1305},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3032021},
	doi = {10.1109/TIFS.2020.3032021},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoRYHZY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Latent Dirichlet Allocation (LDA) is a popular topic modeling technique for hidden semantic discovery of text data and serves as a fundamental tool for text analysis in various applications. However, the LDA model as well as the training process of LDA may expose the text information in the training data, thus bringing significant privacy concerns. To address the privacy issue in LDA, we systematically investigate the privacy protection of the main-stream LDA training algorithm based on Collapsed Gibbs Sampling (CGS) and propose several differentially private LDA algorithms for typical training scenarios. In particular, we present the first theoretical analysis on the inherent differential privacy guarantee of CGS based LDA training and further propose a centralized privacy-preserving algorithm (HDP-LDA) that can prevent data inference from the intermediate statistics in the CGS training. Also, we propose a locally private LDA training algorithm (LP-LDA) on crowdsourced data to provide local differential privacy for individual data contributors. Furthermore, we extend LP-LDA to an online version as OLP-LDA to achieve LDA training on locally private mini-batches in a streaming setting. Extensive analysis and experiment results validate both the effectiveness and efficiency of our proposed privacy-preserving LDA training algorithms.}
}


@article{DBLP:journals/tifs/TalrejaVN21,
	author = {Veeru Talreja and
                  Matthew C. Valenti and
                  Nasser M. Nasrabadi},
	title = {Deep Hashing for Secure Multimodal Biometrics},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1306--1321},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3033189},
	doi = {10.1109/TIFS.2020.3033189},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TalrejaVN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When compared to unimodal systems, multimodal biometric systems have several advantages, including lower error rate, higher accuracy, and larger population coverage. However, multimodal systems have an increased demand for integrity and privacy because they must store multiple biometric traits associated with each user. In this paper, we present a deep learning framework for feature-level fusion that generates a secure multimodal template from each user's face and iris biometrics. We integrate a deep hashing (binarization) technique into the fusion architecture to generate a robust binary multimodal shared latent representation. Further, we employ a hybrid secure architecture by combining cancelable biometrics with secure sketch techniques and integrate it with a deep hashing framework, which makes it computationally prohibitive to forge a combination of multiple biometrics that passes the authentication. The efficacy of the proposed approach is shown using a multimodal database of face and iris and it is observed that the matching performance is improved due to the fusion of multiple biometrics. Furthermore, the proposed approach also provides cancelability and unlinkability of the templates along with improved privacy of the biometric data. Additionally, we also test the proposed hashing function for an image retrieval application using a benchmark dataset. The main goal of this paper is to develop a method for integrating multimodal fusion, deep hashing, and biometric security, with an emphasis on structural data from modalities like face and iris. The proposed approach is in no way a general biometrics security framework that can be applied to all biometrics modalities, as further research is needed to extend the proposed framework to other unconstrained biometric modalities.}
}


@article{DBLP:journals/tifs/YangMAH21,
	author = {Yuli Yang and
                  Meng Ma and
                  Sonia A{\"{\i}}ssa and
                  Lajos Hanzo},
	title = {Physical-Layer Secret Key Generation via CQI-Mapped Spatial Modulation
                  in Multi-Hop Wiretap Ad-Hoc Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1322--1334},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3032276},
	doi = {10.1109/TIFS.2020.3032276},
	timestamp = {Thu, 17 Dec 2020 18:29:34 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangMAH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Providing security guarantee is a critical concern in the ad-hoc networks relying on multi-hop channels, since their flexible topology is vulnerable to security attacks. To enhance the security of a spatial modulation (SM) assisted wireless network, various SM mapping patterns are activated by random channel quality indicator (CQI) patterns over the legitimate link, as a physical-layer secret key. The SM signals are encrypted by random mapping patterns to prevent eavesdroppers from correctly demapping their detections. This secret key is developed for multi-hop wiretap ad-hoc networks, where eavesdroppers might monitor all the transmitting nodes of a legitimate link. We substantially characterise the multi-hop wiretap model with receiver diversity techniques adopted by eavesdroppers. The security performance of the conceived scheme is evaluated in the scenarios where eavesdroppers attempt to detect their received signals using maximal-ratio combining or maximum-gain selection. The achievable data rates of both legitimate and wiretapper links are formulated with the objective of quantifying the secrecy rates for both Gaussian-distributed and finite-alphabet inputs. Illustrative numerical results are provided for the metrics of ergodic secrecy rate and secrecy outage probability, which substantiate the compelling benefits of the physical-layer secret key generation via CQI-mapped SM.}
}


@article{DBLP:journals/tifs/MaruyamaOBS21,
	author = {Teruo M. Maruyama and
                  Luiz S. Oliveira and
                  Alceu S. Britto Jr. and
                  Robert Sabourin},
	title = {Intrapersonal Parameter Optimization for Offline Handwritten Signature
                  Augmentation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1335--1350},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3033442},
	doi = {10.1109/TIFS.2020.3033442},
	timestamp = {Thu, 11 Feb 2021 11:54:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MaruyamaOBS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Usually, in a real-world scenario, few signature samples are available to train an automatic signature verification system (ASVS). However, such systems do indeed need a lot of signatures to achieve an acceptable performance. Neuromotor signature duplication methods and feature space augmentation methods may be used to meet the need for an increase in the number of samples. Such techniques manually or empirically define a set of parameters to introduce a degree of writer variability. Therefore, in the present study, a method to automatically model the most common writer variability traits is proposed. The method is used to generate offline signatures in the image and the feature space and train an ASVS. We also introduce an alternative approach to evaluate the quality of samples considering their feature vectors. We evaluated the performance of an ASVS with the generated samples using three well-known offline signature datasets: GPDS, MCYT-75, and CEDAR. In GPDS-300, when the SVM classifier was trained using one genuine signature per writer and the duplicates generated in the image space, the Equal Error Rate (EER) decreased from 5.71% to 1.08%. Under the same conditions, the EER decreased to 1.04% using the feature space augmentation technique. We also verified that the model that generates duplicates in the image space reproduces the most common writer variability traits in the three different datasets.}
}


@article{DBLP:journals/tifs/Yli-MayryUMNBMG21,
	author = {Ville Yli{-}M{\"{a}}yry and
                  Rei Ueno and
                  Noriyuki Miura and
                  Makoto Nagata and
                  Shivam Bhasin and
                  Yves Mathieu and
                  Tarik Graba and
                  Jean{-}Luc Danger and
                  Naofumi Homma},
	title = {Diffusional Side-Channel Leakage From Unrolled Lightweight Block Ciphers:
                  {A} Case Study of Power Analysis on {PRINCE}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1351--1364},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3033441},
	doi = {10.1109/TIFS.2020.3033441},
	timestamp = {Mon, 28 Aug 2023 21:40:51 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/Yli-MayryUMNBMG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study investigates a new side-channel leakage observed in the inner rounds of an unrolled hardware implementation of block ciphers in a chosen-input attack scenario. The side-channel leakage occurs in the first round and it can be observed in the later inner rounds because it arises from path activation bias caused by the difference between two consecutive inputs. Therefore, a new attack that exploits the leakage is possible even for unrolled implementations equipped with countermeasures (masking and/or deglitchers that separate the circuit in terms of glitch propagation) in the round involving the leakage. We validate the existence of such a unique side-channel leakage through a set of experiments with a fully unrolled PRINCE cipher hardware, implemented on a field-programmable gate array (FPGA). In addition, we verify the validity and evaluate the hardware cost of a countermeasure for the unrolled implementation, namely the Threshold Implementation (TI) countermeasure.}
}


@article{DBLP:journals/tifs/Sepas-Moghaddam21,
	author = {Alireza Sepas{-}Moghaddam and
                  Ali Etemad and
                  Fernando Pereira and
                  Paulo Lobato Correia},
	title = {Long Short-Term Memory With Gate and State Level Fusion for Light
                  Field-Based Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1365--1379},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3036242},
	doi = {10.1109/TIFS.2020.3036242},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Sepas-Moghaddam21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Long Short-Term Memory (LSTM) is a prominent recurrent neural network for extracting dependencies from sequential data such as time-series and multi-view data, having achieved impressive results for different visual recognition tasks. A conventional LSTM network, hereafter referred only as LSTM network, can learn a model to posteriorly extract information from one input sequence. However, if two or more dependent sequences of data are simultaneously acquired, the LSTM networks may only process those sequences consecutively, not taking benefit of the information carried out by their mutual dependencies. In this context, this paper proposes two novel LSTM cell architectures that are able to jointly learn from multiple sequences simultaneously acquired, targeting to create richer and more effective models for recognition tasks. The efficacy of the novel LSTM cell architectures is assessed by integrating them into deep learning-based methods for face recognition with multi-view, light field images. The new cell architectures jointly learn the scene horizontal and vertical parallaxes available in a light field image, to capture richer spatio-angular information from both directions. A comprehensive evaluation, with the IST-EURECOM LFFD dataset using three challenging evaluation protocols, shows the advantage of using the novel LSTM cell architectures for face recognition over the state-of-the-art light field-based methods. These results highlight the added value of the novel cell architectures when learning from correlated input sequences.}
}


@article{DBLP:journals/tifs/LiLWWJ21,
	author = {Bingyu Li and
                  Jingqiang Lin and
                  Qiongxiao Wang and
                  Ze Wang and
                  Jiwu Jing},
	title = {Locally-Centralized Certificate Validation and its Application in
                  Desktop Virtualization Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1380--1395},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3035265},
	doi = {10.1109/TIFS.2020.3035265},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiLWWJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To validate a certificate, a user needs to install the certificate of the root certification authority (CA) and download the certificate revocation information (CRI). Although operating systems and browsers manage the certificate trust list (CTL) of publicly-trusted root CAs for global users, locally-trusted root CAs still play an important role and it is difficult for a user to manage its CTL properly by itself. Meanwhile, the CRI access is inefficient, sometimes even unavailable, and causes privacy leakage. We revisit these problems by analyzing the TLS sessions within an organization. To the best of our knowledge, we are the first to analyze CTL management and CRI access on the scale of medium-sized organizations. Based on the analysis, a locally-centralized design is proposed to manage the CTLs of all users by IT administrators and access the CRI services for all users, within an organization. We apply this design to desktop virtualization systems to demonstrate its applicability, and build vCertGuard with oVirt and KVM-QEMU. In vCertGuard, the CTLs of all virtual machines (VMs) are managed in the VM monitors (VMMs). In the CTL, the self-signed certificates of publicly-trusted root CAs are properly configured, while each locally-trusted certificate chain is specified one by one. vCertGuard accesses the CRI services for all VMs, and the downloaded CRI is cached and shared among VMs. Because most TLS servers are visited by multiple users of an organization, it reduces the cost of CRI access. Experimental results of the prototype system show that vCertGuard maintains the CTLs with a negligible overhead, and significantly improves the performance of CRI access.}
}


@article{DBLP:journals/tifs/XuYXNX21,
	author = {Weiyang Xu and
                  Chang Yuan and
                  Shengbo Xu and
                  Hien Quoc Ngo and
                  Wei Xiang},
	title = {On Pilot Spoofing Attack in Massive {MIMO} Systems: Detection and
                  Countermeasure},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1396--1409},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3036805},
	doi = {10.1109/TIFS.2020.3036805},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XuYXNX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Massive MIMO systems are vulnerable to pilot spoofing attacks (PSAs) since the estimated channel state information can be contaminated by the eavesdropping link, thus incurring severe information leakage in downlink transmission. To safeguard legitimate communications, this paper proposes a PSA detection method which relies on pilot manipulation. Specifically, users randomly partition pilot sequences into two parts, where the first part remains unchanged and the second one is multiplied with a diagonal matrix. Although a malicious node may follow the same way to send pilots, this makes it more likely to be detected. According to the principle of the likelihood-ratio test, the proposed detector is designed based on a decision metric that does not include the legitimate channel. This feature differentiates our scheme from existing ones and remarkably improves the detection accuracy. Besides, the possibility of performance enhancement by joint detection is discussed. Furthermore, based on pilot manipulation, a jamming-resistant receiver is designed. The key of this receiver is a new channel estimator that is robust to the PSA. Finally, extensive simulations are carried out to validate our proposed algorithms.}
}


@article{DBLP:journals/tifs/DengLCLS21,
	author = {Qiyao Deng and
                  Qi Li and
                  Jie Cao and
                  Yunfan Liu and
                  Zhenan Sun},
	title = {Controllable Multi-Attribute Editing of High-Resolution Face Images},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1410--1423},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3033184},
	doi = {10.1109/TIFS.2020.3033184},
	timestamp = {Fri, 24 May 2024 09:36:42 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DengLCLS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, significant progress has been achieved in face image editing due to the success of Generative Adversarial Network (GAN). However, state-of-the-art face editing methods mainly suffer from the following two limitations: 1) they are only applicable to face images with relative low-resolutions and 2) multi-attribute face editing may generate uncontrollable changes in non-target face attribute categories. To solve these problems, we propose a novel High-Quality Generative Adversarial Network (HQ-GAN) for controllable editing of multiple face attributes in high-resolution images. HQ-GAN has two novel ideas to break the limitations of resolution and controllability correspondingly: 1) fine-grained textures and realistic details of high-resolution face images are better preserved with the aid of textural features extracted by the wavelet transform module and 2) desired multi-attribute targets of face editing are emphasized using a weighted binary cross-entropy (BCE) loss so that the influence on non-target attributes is greatly reduced. To the best of our knowledge, HQ-GAN is the first attempt to achieve continuous editing of multiple face attributes on high-resolution images of the CelebA-HQ using only 28 000 training samples. Extensive qualitative results demonstrate the superiority of the proposed method in rendering realistic high-resolution face images with accurate attribute modification, and comprehensive quantitative results show that the proposed method significantly outperforms state-of-the-art face editing methods.}
}


@article{DBLP:journals/tifs/GhoshBSP21,
	author = {Saptarshi Ghosh and
                  Manav R. Bhatnagar and
                  Walid Saad and
                  Bijaya K. Panigrahi},
	title = {Defending False Data Injection on State Estimation Over Fading Wireless
                  Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1424--1439},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3031378},
	doi = {10.1109/TIFS.2020.3031378},
	timestamp = {Mon, 28 Aug 2023 21:40:51 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GhoshBSP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, a cyber-physical system (CPS) is considered, whose state estimation is done by a central controller (CC) using the measurements received from a wireless powered sensor network (WPSN) over fading channels. An adversary injects false data in this system by compromising some of the idle sensor nodes (SNs) of the WPSN. Using the WPSN for transmitting supervision and control data, in the aforementioned setting, makes the CPS vulnerable to both error and false data injection (FDI). The existing techniques of launching stealthy FDI attack are not applicable to the aforementioned network due to the random nature of wireless channels, which is used for both transmitting control and false data. The objectives of the adversary and the CC to launch stealthy FDI attack and to detect the same, respectively, are found to be depending on the powers they use for transmitting data over wireless channels. The transmit powers of the CC, and the adversary that fulfill their respective objectives are derived by modeling their interaction as a Bayesian Stackelberg game. Based on their objectives, novel utility functions are defined for the CC and the adversary. Subsequently, the equilibrium of the proposed game is obtained by solving a non-convex bi-level quadratic-quadratic program. Finally, the analytical results are verified and compared with other state-of-art techniques by applying them in a realistic smart grid simulations.}
}


@article{DBLP:journals/tifs/WuZLNF21,
	author = {Xiaojun Wu and
                  Jinghui Zhou and
                  Jun Liu and
                  Fangyi Ni and
                  Haoqiang Fan},
	title = {Single-Shot Face Anti-Spoofing for Dual Pixel Camera},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1440--1451},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3035879},
	doi = {10.1109/TIFS.2020.3035879},
	timestamp = {Thu, 16 Jun 2022 12:12:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuZLNF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, we propose a neural network-based face anti-spoofing algorithm using dual pixel (DP) sensor images. The proposed algorithm has two stages: depth reconstruction and depth classification. The first network takes a DP image pair as input and generates a depth map with a baseline of approximately 1 mm. Then, the classification network is trained to distinguish real individuals and planar attack shapes to produce a binary output. A DP image is utilized to estimate the depth map; thus, the proposed face anti-spoofing method is simple and robust. Experimental results demonstrate that the generated depth map helps distinguish real human faces from nonface attack, including images recaptured from photos or screens. The proposed algorithm achieves better anti-spoofing performance compared with other stereo and phase-based depth estimation schemes.}
}


@article{DBLP:journals/tifs/ZhongD21,
	author = {Yaoyao Zhong and
                  Weihong Deng},
	title = {Towards Transferable Adversarial Attack Against Deep Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1452--1466},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3036801},
	doi = {10.1109/TIFS.2020.3036801},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhongD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face recognition has achieved great success in the last five years due to the development of deep learning methods. However, deep convolutional neural networks (DCNNs) have been found to be vulnerable to adversarial examples. In particular, the existence of transferable adversarial examples can severely hinder the robustness of DCNNs since this type of attacks can be applied in a fully black-box manner without queries on the target system. In this work, we first investigate the characteristics of transferable adversarial attacks in face recognition by showing the superiority of feature-level methods over label-level methods. Then, to further improve transferability of feature-level adversarial examples, we propose DFANet, a dropout-based method used in convolutional layers, which can increase the diversity of surrogate models and obtain ensemble-like effects. Extensive experiments on state-of-the-art face models with various training databases, loss functions and network architectures show that the proposed method can significantly enhance the transferability of existing attack methods. Finally, by applying DFANet to the LFW database, we generate a new set of adversarial face pairs that can successfully attack four commercial APIs without any queries. This TALFW database is available to facilitate research on the robustness and defense of deep face recognition.}
}


@article{DBLP:journals/tifs/YinFLZ21,
	author = {Qihao Yin and
                  Jianjiang Feng and
                  Jiwen Lu and
                  Jie Zhou},
	title = {Joint Estimation of Pose and Singular Points of Fingerprints},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1467--1479},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3036803},
	doi = {10.1109/TIFS.2020.3036803},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YinFLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fingerprint pose estimation is a challenging problem since the pose is not defined by salient anatomical features and fingerprint images usually suffer from noise and small area. In this article, we proposed a method for joint estimation of pose and singular points of fingerprints, with the expectation that the pose and singular points can improve each other. By virtue of that singular points can be located accurately, we hope to improve the accuracy of pose estimation. Meanwhile, the robustness of pose estimation can improve the anti-noise performance of singular point detection. To achieve this, we propose a multi-task deep neural network, which contains a feature extraction body and two estimation heads for singular point and pose respectively. The proposed network can deal with various types of fingerprints, including plain, rolled and latent fingerprints. Experiments on four databases (NIST SD4, SD14, SD27 and FVC2004 DB1A) show that (1) the estimated poses and detected singular points are close to manual annotations despite of different image qualities; (2) the estimated poses for mated fingerprint pairs are consistent; and (3) the proposed pose estimation method outperforms state-of-the-art methods while utilized as pose constraint for a fingerprint indexing algorithm.}
}


@article{DBLP:journals/tifs/LiCTYQ21,
	author = {Huafeng Li and
                  Yiwen Chen and
                  Dapeng Tao and
                  Zhengtao Yu and
                  Guanqiu Qi},
	title = {Attribute-Aligned Domain-Invariant Feature Learning for Unsupervised
                  Domain Adaptation Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1480--1494},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3036800},
	doi = {10.1109/TIFS.2020.3036800},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiCTYQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain invariance and discrimination of learned features as two crucial factors affect the performance of unsupervised domain adaptation (UDA) person re-identification (Re-ID). Person attributes (such as “backpack”, “boots”, “handbag”, etc) remaining unchanged across multiple domains have been used as mid-level visual-semantic information in UDA person Re-ID. As two main challenges, both misalignment of attribute-related regions across multiple images and domain shift between source and target domains affect the learning of domain-invariant features (DIF). To address the above two challenges, this article proposes to take advantage of the stability of person attributes and the complementarity of person attributes and the corresponding low-level visual features to guide the learning of discriminative DIF. Specifically, the proposed solution contains the generation of latent attribute-correlated visual features (GLAVF), DIF learning under the guidance of person attributes, and the alignment of person attributes corresponding to the local regions of pedestrian images. Due to the gap between person attributes and visual features, person attributes are first converted into latent attribute-correlated visual features (LAVF) without any specific domain information in GLAVF, and then LAVF are used as the substitutions of person attributes to guide the learning of DIF. To enhance the discrimination of learned features, the proposed solution mainly explores the alignment between person attributes and corresponding local regions, and the alignment of the same person attributes across multiple pedestrian images. A fully connected layer is used to achieve the above two types of alignment in the proposed framework, which reduces the adverse impacts of inference information and ensures the semantic consistency between person attributes and corresponding local regions across multiple pedestrian images. The effectiveness of the proposed solution is confirmed on four existing datasets by comparative experiments.}
}


@article{DBLP:journals/tifs/ChoCC21,
	author = {Sunghwan Cho and
                  Gaojie Chen and
                  Justin P. Coon},
	title = {Zero-Forcing Beamforming for Active and Passive Eavesdropper Mitigation
                  in Visible Light Communication Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1495--1505},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3036806},
	doi = {10.1109/TIFS.2020.3036806},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChoCC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article proposes zero-forcing (ZF) beamforming strategies that can simultaneously deal with active and passive eavesdroppers in visible light communication (VLC) systems. First, we propose a ZF beamforming scheme that steers a transmission beam to the null space of active eavesdroppers' (AEDs) channel, while simultaneously considering the SNRs for a legitimate user (UE) and passive eavesdroppers (PEDs) residing at unknown locations. To find an eigenmode related to the optimal beamforming vector, we adopt an inverse free preconditioned Krylov subspace projection method. For unfavorable VLC secrecy environments, the proposed ZF beamformer appears to be incapable of effectively coping with the PEDs due to the strict condition that the data transmission must be in the null space of the AEDs' channel matrix. Hence, an alternative beamforming scheme is proposed by relaxing the constraint on the SNRs of the AEDs. The related optimization problem is formulated to reduce the secrecy outages caused by PEDs, while simultaneously satisfying the target constraints on the SNRs of the UE and the AEDs. To simplify the mathematical complexity of the approach, Lloyd's algorithm is employed to sample the SNR field, which in turn discretizes the problem, thus making it tractable for practical implementation. The numerical results show that both the exact and relaxed ZF beamforming methods achieve superior performance in the sense of secrecy outage relative to a benchmark ZF scheme. Moreover, the proposed relaxed ZF beamforming method is shown to cope with PEDs better than the exact ZF beamforming approach for unfavorable VLC environments.}
}


@article{DBLP:journals/tifs/SenigagliesiBG21,
	author = {Linda Senigagliesi and
                  Marco Baldi and
                  Ennio Gambi},
	title = {Comparison of Statistical and Machine Learning Techniques for Physical
                  Layer Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1506--1521},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3033454},
	doi = {10.1109/TIFS.2020.3033454},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SenigagliesiBG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article we consider authentication at the physical layer, in which the authenticator aims at distinguishing a legitimate supplicant from an attacker on the basis of the characteristics of a set of parallel wireless channels, which are affected by time-varying fading. Moreover, the attacker's channel has a spatial correlation with the supplicant's one. In this setting, we assess and compare the performance achieved by different approaches under different channel conditions. We first consider the use of two different statistical decision methods, and we prove that using a large number of references (in the form of channel estimates) affected by different levels of time-varying fading is not beneficial from a security point of view. We then consider classification methods based on machine learning. In order to face the worst case scenario of an authenticator provided with no forged messages during training, we consider one-class classifiers. When instead the training set includes some forged messages, we resort to more conventional binary classifiers, considering the cases in which such messages are either labelled or not. For the latter case, we exploit clustering algorithms to label the training set. The performance of both nearest neighbor (NN) and support vector machine (SVM) classification techniques is evaluated. Through numerical examples, we show that under the same probability of false alarm, one-class classification (OCC) algorithms achieve the lowest probability of missed detection when a small spatial correlation exists between the main channel and the adversary one, while statistical methods are advantageous when the spatial correlation between the two channels is large.}
}


@article{DBLP:journals/tifs/YouLO21,
	author = {Yang You and
                  Zuxing Li and
                  Tobias J. Oechtering},
	title = {Energy Management Strategy for Smart Meter Privacy and Cost Saving},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1522--1537},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3036247},
	doi = {10.1109/TIFS.2020.3036247},
	timestamp = {Tue, 11 Jul 2023 14:09:13 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YouLO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We design optimal privacy-enhancing and cost-efficient energy management strategies for consumers that are equipped with a rechargeable energy storage. The Kullback-Leibler divergence rate is used as privacy measure and the expected cost-saving rate is used as utility measure. The corresponding energy management strategy is designed by optimizing a weighted sum of both privacy and cost measures over a finite time horizon, which is achieved by formulating our problem into a belief-state Markov decision process problem. A computationally efficient approximated Q-learning method is proposed as a generalization to high-dimensional problems over an infinite time horizon. At last, we explicitly characterize a stationary policy that achieves the steady belief state over an infinite time horizon, which greatly simplifies the design of the privacy-preserving energy management strategy. The performance of the practical design approaches are finally illustrated in numerical experiments.}
}


@article{DBLP:journals/tifs/HeCZDX21,
	author = {Kun He and
                  Jing Chen and
                  Qinxi Zhou and
                  Ruiying Du and
                  Yang Xiang},
	title = {Secure Dynamic Searchable Symmetric Encryption With Constant Client
                  Storage Cost},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1538--1549},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3033412},
	doi = {10.1109/TIFS.2020.3033412},
	timestamp = {Sun, 22 Oct 2023 11:15:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HeCZDX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic Searchable Symmetric Encryption (DSSE) enables users to search on the encrypted database stored on a semi-trusted server while keeping the search and update information under acceptable leakage. However, most existing DSSE schemes are not efficient enough in practice due to the complex structures and cryptographic primitives. Moreover, the storage cost on the client side grows linearly with the number of keywords in the database, which induces unaffordable storage cost when the size of keyword set is large. In this article, we focus on secure dynamic searchable symmetric encryption with constant client storage cost. Our framework is boosted by fish-bone chain, a novel two-level structure which consists of Logical Keyword Index Chain (LoKIC) and Document Index Chain (DIC). To instantiate the proposed framework, we propose a forward secure DSSE scheme, called CLOSE-F, and a forward and backward secure DSSE scheme, called CLOSE-FB. Experiments showed that the computation cost of CLOSE-F and CLOSE-FB are as efficient as the state-of-the-art solutions, while the storage costs on the client side are constant in both CLOSE-F and CLOSE-FB, which are much smaller than existing schemes.}
}


@article{DBLP:journals/tifs/LiuYLFK21,
	author = {Chang Liu and
                  Yulin Yang and
                  Xingyan Liu and
                  Linpu Fang and
                  Wenxiong Kang},
	title = {Dynamic-Hand-Gesture Authentication Dataset and Benchmark},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1550--1562},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3036218},
	doi = {10.1109/TIFS.2020.3036218},
	timestamp = {Mon, 19 Apr 2021 17:01:04 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuYLFK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, biometrics have received considerable attention for its reliability and usability. Dynamic-hand-gesture is one of the representative biometric modalities, with advantages of safety and template-replaceability, has huge potential value. However, due to the lack of large-scale dataset and comprehensive evaluation methods, few researches are intended to study the dynamic-hand-gesture authentication method. In this article, we introduce a new dataset SCUT-DHGA, which is the first large-scale Dynamic-Hand-Gestures-Authentication dataset. SCUT-DHGA contains 29,160 dynamic-hand-gesture video sequences and more than 1.86 million frames for both color and depth modalities acquired from 193 volunteers. Six kinds of dynamic-hand-gestures are carefully designed for researching two types of authentication tasks: gesture-predefined authentication and gesture-free authentication. To investigate the hypothesis that users' gestures would be variant after time-span, which will degrade the performance of a dynamic-hand-gesture authentication system, two separate sessions' data were acquired from 50 volunteers with an average interval of one week. Beside the SCUT-DHGA dataset, we also benchmark this dataset with our proposed DHGA-net. By releasing such a large-scale dataset and benchmark, we expect dynamic-hand-gesture authentication methods to gain further improvement and generalization.}
}


@article{DBLP:journals/tifs/FengCXMLL21,
	author = {Ruitao Feng and
                  Sen Chen and
                  Xiaofei Xie and
                  Guozhu Meng and
                  Shang{-}Wei Lin and
                  Yang Liu},
	title = {A Performance-Sensitive Malware Detection System Using Deep Learning
                  on Mobile Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1563--1578},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3025436},
	doi = {10.1109/TIFS.2020.3025436},
	timestamp = {Fri, 15 Mar 2024 12:30:55 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FengCXMLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Currently, Android malware detection is mostly performed on server side against the increasing number of malware. Powerful computing resource provides more exhaustive protection for app markets than maintaining detection by a single user. However, apart from the applications (apps) provided by the official market (i.e., Google Play Store), apps from unofficial markets and third-party resources are always causing serious security threats to end-users. Meanwhile, it is a time-consuming task if the app is downloaded first and then uploaded to the server side for detection, because the network transmission has a lot of overhead. In addition, the uploading process also suffers from the security threats of attackers. Consequently, a last line of defense on mobile devices is necessary and much-needed. In this paper, we propose an effective Android malware detection system, MobiTive, leveraging customized deep neural networks to provide a real-time and responsive detection environment on mobile devices. MobiTive is a pre-installed solution rather than an app scanning and monitoring engine using after installation, which is more practical and secure. Although a deep learning-based approach can be maintained on server side efficiently for malware detection, original deep learning models cannot be directly deployed and executed on mobile devices due to various performance limitations, such as computation power, memory size, and energy. Therefore, we evaluate and investigate the following key points: (1) the performance of different feature extraction methods based on source code or binary code; (2) the performance of different feature type selections for deep learning on mobile devices; (3) the detection accuracy of different deep neural networks on mobile devices; (4) the real-time detection performance and accuracy on different mobile devices; (5) the potential based on the evolution trend of mobile devices' specifications; and finally we further propose a practical solution (MobiTive) to detect Android malware on mobile devices.}
}


@article{DBLP:journals/tifs/AlanisLDPM21,
	author = {Alejandro G{\'{o}}mez Alan{\'{\i}}s and
                  Jos{\'{e}} Andr{\'{e}}s Gonz{\'{a}}lez L{\'{o}}pez and
                  S. Pavankumar Dubagunta and
                  Antonio M. Peinado and
                  Mathew Magimai{-}Doss},
	title = {On Joint Optimization of Automatic Speaker Verification and Anti-Spoofing
                  in the Embedding Space},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1579--1593},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3039045},
	doi = {10.1109/TIFS.2020.3039045},
	timestamp = {Fri, 09 Apr 2021 18:32:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AlanisLDPM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biometric systems are exposed to spoofing attacks which may compromise their security, and voice biometrics based on automatic speaker verification (ASV), is no exception. To increase the robustness against such attacks, anti-spoofing systems have been proposed for the detection of replay, synthesis and voice conversion-based attacks. However, most proposed anti-spoofing techniques are loosely integrated with the ASV system. In this work, we develop a new integration neural network which jointly processes the embeddings extracted from ASV and anti-spoofing systems in order to detect both zero-effort impostors and spoofing attacks. Moreover, we propose a new loss function based on the minimization of the area under the expected (AUE) performance and spoofability curve (EPSC), which allows us to optimize the integration neural network on the desired operating range in which the biometric system is expected to work. To evaluate our proposals, experiments were carried out on the recent ASVspoof 2019 corpus, including both logical access (LA) and physical access (PA) scenarios. The experimental results show that our proposal clearly outperforms some well-known techniques based on the integration at the score- and embedding-level. Specifically, our proposal achieves up to 23.62% and 22.03% relative equal error rate (EER) improvement over the best performing baseline in the LA and PA scenarios, respectively, as well as relative gains of 27.62% and 29.15% on the AUE metric.}
}


@article{DBLP:journals/tifs/RahmanIMW21,
	author = {Mohammad Saidur Rahman and
                  Mohsen Imani and
                  Nate Mathews and
                  Matthew Wright},
	title = {Mockingbird: Defending Against Deep-Learning-Based Website Fingerprinting
                  Attacks With Adversarial Traces},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1594--1609},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3039691},
	doi = {10.1109/TIFS.2020.3039691},
	timestamp = {Mon, 29 Mar 2021 17:24:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/RahmanIMW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Website Fingerprinting (WF) is a type of traffic analysis attack that enables a local passive eavesdropper to infer the victim's activity, even when the traffic is protected by a VPN or an anonymity system like Tor. Leveraging a deep-learning classifier, a WF attacker can gain over 98% accuracy on Tor traffic. In this paper, we explore a novel defense, Mockingbird, based on the idea of adversarial examples that have been shown to undermine machine-learning classifiers in other domains. Since the attacker gets to design and train his attack classifier based on the defense, we first demonstrate that at a straightforward technique for generating adversarial-example based traces fails to protect against an attacker using adversarial training for robust classification. We then propose Mockingbird, a technique for generating traces that resists adversarial training by moving randomly in the space of viable traces and not following more predictable gradients. The technique drops the accuracy of the state-of-the-art attack hardened with adversarial training from 98% to 42-58% while incurring only 58% bandwidth overhead. The attack accuracy is generally lower than state-of-the-art defenses, and much lower when considering Top-2 accuracy, while incurring lower bandwidth overheads.}
}


@article{DBLP:journals/tifs/NieLLCCFT21,
	author = {Yulong Nie and
                  Xiaolong Lan and
                  Yong Liu and
                  Qingchun Chen and
                  Gaojie Chen and
                  Lisheng Fan and
                  Dong Tang},
	title = {Achievable Rate Region of Energy-Harvesting Based Secure Two-Way Buffer-Aided
                  Relay Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1610--1625},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3039047},
	doi = {10.1109/TIFS.2020.3039047},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/NieLLCCFT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considered an energy-harvesting based secure two-way relay (EH-STWR) network, where two users exchanged information with the assistance of one buffer-aided relay that harvested energy from two users. To realize the confidential message exchange between two users in the presence of a potential eavesdropper, a secure bidirectional relaying scheme based on time division broadcast (TDBC) was proposed, where one user sent artificial noise to suppress the eavesdropper and another user transmitted data to the relay. A secure sum-rate maximization problem was formulated subject to average and peak transmit power constraints, data buffer and energy storage causality, and transmission mode constraints. By employing the Lyapunov optimization framework, a security-aware adaptive transmission scheme was proposed to jointly adapt transmission mode selection, power allocation, and security rate allocation according to channel/buffer/energy state information (CSI/BSI/ESI). Analysis results showed that the average achievable secrecy rate region can be significantly improved and there exists an inherent trade-off among transmission delay, requirement of transmit power consumption, and achievable secure sum-rate. Moreover, the channel condition between the energy-constrained relay and the potential eavesdropper is a critical factor on the achievable long-term average secrecy rate performance.}
}


@article{DBLP:journals/tifs/ZhangBS21,
	author = {Jiexin Zhang and
                  Alastair R. Beresford and
                  Ian Sheret},
	title = {Factory Calibration Fingerprinting of Sensors},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1626--1639},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3039685},
	doi = {10.1109/TIFS.2020.3039685},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangBS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device fingerprinting aims to generate a distinctive signature, or fingerprint, that uniquely identifies individual computing devices. Fingerprints may be a privacy concern since apps and websites can use them to track user activity online. To protect user privacy, both Android and iOS have included a variety of measures to prevent such tracking. In this paper we present a new type of fingerprinting, factory calibration fingerprinting, that bypasses existing tracking protection. Our attack recovers embedded per-device factory calibration data from the accelerometer, gyroscope, and magnetometer sensors that are pervasive in modern smartphones by careful analysis of the sensor output alone. We discuss the factory calibration behaviour of each sensor and show that the calibration fingerprint is fast to generate, does not change over time or after a factory reset, and can be used to track users across apps and websites without any special permission from the user. We find the calibration fingerprint is very likely to be globally unique for iOS devices, with an estimated 67 bits of entropy for the iPhone 6S. In addition, we have analysed 146 Android device models from 11 vendors and found the attack also works on recent Google Pixel devices. For Pixel 4/4 XL, we estimate the calibration fingerprint provides about 57 bits of entropy. Following our disclosures, Apple deployed a mitigation in iOS 12.2 and Google in Android 11. We analyse Apple's fix and show that the mitigation is imperfect although it is likely to be sufficient in most threat models.}
}


@article{DBLP:journals/tifs/ZhengLZDL21,
	author = {Tong{-}Xing Zheng and
                  Hao{-}Wen Liu and
                  Ning Zhang and
                  Zhiguo Ding and
                  Victor C. M. Leung},
	title = {Secure Content Delivery in Two-Tier Cache-Enabled mmWave Heterogeneous
                  Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1640--1654},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3040877},
	doi = {10.1109/TIFS.2020.3040877},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhengLZDL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate secure content delivery in a two-tier cache-enabled millimeter wave (mmWave) heterogeneous network composed of a macro base station (MBS) and\nK\nsmall base stations (SBSs) with caching capabilities. We allocate finite cache units at the SBSs and MBS to pre-store files with high popularities, where the SBSs store the most popular files, and the MBS stores the less popular ones. To deliver the file requested by a legitimate user securely, two secure transmission schemes, namely, distributed beamforming and direct transmission, are employed at the SBSs and MBS, respectively. Moreover, artificial noise (AN) is combined with the above two transmission schemes to further improve transmission security. The connection outage probability, secrecy outage probability, and secrecy throughput for the proposed mmWave transmission schemes are obtained. Based on these results, we jointly design the transmission rates and the cache resource allocation between the SBSs and MBS to maximize the overall secrecy throughput. We also provide insights into how the overall secrecy throughput is influenced by various parameters, including transmission rates, power allocation ratio of the AN scheme, and cache allocation factor. Numerical results are eventually presented to validate our theoretical analysis and demonstrate the effectiveness of the proposed transmission schemes and cache resource allocation strategy.}
}


@article{DBLP:journals/tifs/ChuHXMLKKF21,
	author = {Zheng Chu and
                  Wanming Hao and
                  Pei Xiao and
                  De Mi and
                  Zilong Liu and
                  Mohsen Khalily and
                  James R. Kelly and
                  Alexandros P. Feresidis},
	title = {Secrecy Rate Optimization for Intelligent Reflecting Surface Assisted
                  {MIMO} System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1655--1669},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3038994},
	doi = {10.1109/TIFS.2020.3038994},
	timestamp = {Wed, 23 Mar 2022 09:35:31 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChuHXMLKKF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the impact of intelligent reflecting surface (IRS) enabled wireless secure transmission. Specifically, an IRS is deployed to assist multiple-input multiple-output (MIMO) secure system to enhance the secrecy performance, and artificial noise (AN) is employed to introduce interference to degrade the reception of the eavesdropper. To improve the secrecy performance, we aim to maximize the achievable secrecy rate, subject to the transmit power constraint, by jointly designing the precoding of the secure transmission, the AN jamming, and the reflecting phase shift of the IRS. We first propose an alternative optimization algorithm (i.e., block coordinate descent (BCD) algorithm) to tackle the non-convexity of the formulated problem. This is made by deriving the transmit precoding and AN matrices via the Lagrange dual method and the phase shifts by the Majorization-Minimization (MM) algorithm. Our analysis reveals that the proposed BCD algorithm converges in a monotonically non-decreasing manner which leads to guaranteed optimal solution. Finally, we provide numerical results to validate the secrecy performance enhancement of the proposed scheme in comparison to the benchmark schemes.}
}


@article{DBLP:journals/tifs/SchramlSK21,
	author = {Matthias G. Schraml and
                  Robert T. Schwarz and
                  Andreas Knopp},
	title = {Multiuser {MIMO} Concept for Physical Layer Security in Multibeam
                  Satellite Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1670--1680},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3040884},
	doi = {10.1109/TIFS.2020.3040884},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SchramlSK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In satellite communication downlinks, physical layer security is challenging to achieve due to their broadcasting nature and Line-of-Sight channel characteristics. This paper provides a precoding algorithm to secure the downlinks of multiple users against multiple eavesdroppers with optimization of the minimum secrecy capacity. By the use of artificial noise, a positive secrecy capacity is achievable even if the number of eavesdroppers is higher than the number of beams. We demonstrate that a multiple-reflector antenna design provides a significantly higher secrecy and throughput performance when compared to a single-reflector design due to additional degrees of freedom, exhibited by the signal phases. The total vulnerability region is introduced as a new figure of merit with respect to unidentified eavesdroppers.}
}


@article{DBLP:journals/tifs/WeiCXCZ21,
	author = {Lu Wei and
                  Jie Cui and
                  Yan Xu and
                  Jiujun Cheng and
                  Hong Zhong},
	title = {Secure and Lightweight Conditional Privacy-Preserving Authentication
                  for Securing Traffic Emergency Messages in VANETs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1681--1695},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3040876},
	doi = {10.1109/TIFS.2020.3040876},
	timestamp = {Wed, 16 Mar 2022 10:07:24 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WeiCXCZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Owing to the development of wireless communication technology and the increasing number of automobiles, vehicular ad hoc networks (VANETs) have become essential tools to secure traffic safety and enhance driving convenience. It is necessary to design a conditional privacy-preserving authentication (CPPA) scheme for VANETs because of their vulnerability and security requirements. Traditional CPPA schemes have two deficiencies. One is that the communication or storage overhead is not sufficiently low, but the traffic emergency message requires an ultra-low transmission delay. The other is that traditional CPPA schemes do not consider updating the system secret key (SSK), which is stored in an unhackable Tamper Proof Device (TPD), whereas side-channel attack methods and the wide usage of the SSK increase the probability of breaking the SSK. To solve the first issue, we propose a CPPA signature scheme based on elliptic curve cryptography, which can achieve message recovery and be reduced to elliptic curve discrete logarithm assumption, so that traffic emergency messages are secured with ultra-low communication overhead. To solve the second issue, we design an SSK updating algorithm, which is constructed on Shamir’s secret sharing algorithm and secure pseudo random function, so that the TPDs of unrevoked vehicles can update SSK securely. Formal security proof and analysis show that our proposed scheme satisfies the security and privacy requirements of VANETs. Performance analysis demonstrates that our proposed scheme requires less storage size and has a lower transmission delay compared with related schemes.}
}


@article{DBLP:journals/tifs/KumarYDHP21,
	author = {S. V. Aruna Kumar and
                  Ehsan Yaghoubi and
                  Abhijit Das and
                  B. S. Harish and
                  Hugo Proen{\c{c}}a},
	title = {The {P-DESTRE:} {A} Fully Annotated Dataset for Pedestrian Detection,
                  Tracking, and Short/Long-Term Re-Identification From Aerial Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1696--1708},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3040881},
	doi = {10.1109/TIFS.2020.3040881},
	timestamp = {Fri, 23 Apr 2021 09:00:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KumarYDHP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the years, unmanned aerial vehicles (UAVs) have been regarded as a potential solution to surveil public spaces, providing a cheap way for data collection, while covering large and difficult-to-reach areas. This kind of solutions can be particularly useful to detect, track and identify subjects of interest in crowds, for security/safety purposes. In this context, various datasets are publicly available, yet most of them are only suitable for evaluating detection, tracking and short-term re-identification techniques. This paper announces the free availability of the P-DESTRE dataset, the first of its kind to provide video/UAV-based data for pedestrian long-term re-identification research, with ID annotations consistent across data collected in different days. As a secondary contribution, we provide the results attained by the state-of-the-art pedestrian detection, tracking, short/long term re-identification techniques in well-known surveillance datasets, used as baselines for the corresponding effectiveness observed in the P-DESTRE data. This comparison highlights the discriminating characteristics of P-DESTRE with respect to similar sets. Finally, we identify the most problematic data degradation factors and co-variates for UAV-based automated data analysis, which should be considered in subsequent technologic/conceptual advances in this field. The dataset and the full specification of the empirical evaluation carried out are freely available at http://p-destre.di.ubi.pt/.}
}


@article{DBLP:journals/tifs/LiuQ21,
	author = {Manhua Liu and
                  Peng Qian},
	title = {Automatic Segmentation and Enhancement of Latent Fingerprints Using
                  Deep Nested UNets},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1709--1719},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3039058},
	doi = {10.1109/TIFS.2020.3039058},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Latent fingerprints are one of the most important evidences used to identify criminals in the law enforcement and forensic agencies. Automated recognition of latent fingerprints is still challenging due to their poor image quality caused by unclear ridge structure and various overlapping patterns. Segmentation and enhancement are important to identify valid fingerprint regions, reduce the noise and improve the clarity of ridge structure for more accurate fingerprint recognition. In this paper, we propose a deep convolutional neural network architecture with the nested UNets for automatic segmentation and enhancement of latent fingerprints. First, to prepare training data, we synthetically generate the latent fingerprints and their segmentation and enhancement ground truth data for training. Then, a deep architecture of nested UNets is proposed to transform low-quality latent image into the segmentation mask and high-quality fingerprint through the pixels-to-pixels and end-to-end training. Finally, the test latent fingerprint is segmented and enhanced with the deep nested UNets to improve the image quality in one shot. The enhancement network is optimized by combining the local and global losses, which not only helps reconstruct the global structure, but also enhance the local ridge details of latent fingerprints. The proposed network can make use of multi-level feature maps in a pyramid way of nested UNets for segmentation and enhancement. Experimental results and comparison on NIST SD27 and IIITD-MOLF latent fingerprint databases demonstrate the promising performance of the proposed method.}
}


@article{DBLP:journals/tifs/HeartfieldLBP21,
	author = {Ryan Heartfield and
                  George Loukas and
                  Anatolij Bezemskij and
                  Emmanouil Panaousis},
	title = {Self-Configurable Cyber-Physical Intrusion Detection for Smart Homes
                  Using Reinforcement Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1720--1735},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3042049},
	doi = {10.1109/TIFS.2020.3042049},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HeartfieldLBP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The modern Internet of Things (IoT)-based smart home is a challenging environment to secure: devices change, new vulnerabilities are discovered and often remain unpatched, and different users interact with their devices differently and have different cyber risk attitudes. A security breach's impact is not limited to cyberspace, as it can also affect or be facilitated in physical space, for example, via voice. In this environment, intrusion detection cannot rely solely on static models that remain the same over time and are the same for all users. We present MAGPIE, the first smart home intrusion detection system that is able to autonomously adjust the decision function of its underlying anomaly classification models to a smart home's changing conditions (e.g., new devices, new automation rules and user interaction with them). The method achieves this goal by applying a novel probabilistic cluster-based reward mechanism to non-stationary multi-armed bandit reinforcement learning. MAGPIE rewards the sets of hyperparameters of its underlying isolation forest unsupervised anomaly classifiers based on the cluster silhouette scores of their output. Experimental evaluation in a real household shows that MAGPIE exhibits high accuracy because of two further innovations: it takes into account both cyber and physical sources of data; and it detects human presence to utilise models that exhibit the highest accuracy in each case. MAGPIE is available in open-source format, together with its evaluation datasets, so it can benefit from future advances in unsupervised and reinforcement learning and be able to be enriched with further sources of data as smart home environments and attacks evolve.}
}


@article{DBLP:journals/tifs/GuoLLGHDB21,
	author = {Xiaojie Guo and
                  Zheli Liu and
                  Jin Li and
                  Jiqiang Gao and
                  Boyu Hou and
                  Changyu Dong and
                  Thar Baker},
	title = {VeriFL: Communication-Efficient and Fast Verifiable Aggregation for
                  Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1736--1751},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3043139},
	doi = {10.1109/TIFS.2020.3043139},
	timestamp = {Tue, 27 Sep 2022 17:30:05 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GuoLLGHDB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) enables a large number of clients to collaboratively train a global model through sharing their gradients in each synchronized epoch of local training. However, a centralized server used to aggregate these gradients can be compromised and forge the result in order to violate privacy or launch other attacks, which incurs the need to verify the integrity of aggregation. In this work, we explore how to design communication-efficient and fast verifiable aggregation in FL. We propose VeriFL, a verifiable aggregation protocol, with O(N) (dimension-independent) communication and O(N+ d) computation for verification in each epoch, where N is the number of clients and d is the dimension of gradient vectors. Since d can be large in some real-world FL applications (e.g., 100K), our dimension-independent communication is especially desirable for clients with limited bandwidth and high-dimensional gradients. In addition, the proposed protocol can be used in the FL setting where secure aggregation is needed or there is a subset of clients dropping out of protocol execution. Experimental results indicate that our protocol is efficient in these settings.}
}


@article{DBLP:journals/tifs/JinLSB21,
	author = {Ming Jin and
                  Javad Lavaei and
                  Somayeh Sojoudi and
                  Ross Baldick},
	title = {Boundary Defense Against Cyber Threat for Power System State Estimation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1752--1767},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3043065},
	doi = {10.1109/TIFS.2020.3043065},
	timestamp = {Thu, 11 Feb 2021 11:54:44 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JinLSB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The operation of power grids is becoming increasingly data-centric. While the abundance of data could improve system efficiency, it poses major reliability challenges. In particular, state estimation aims to find the operating state of a network from the telemetered data, but an undetected attack on the data could lead to making wrong operational decisions for the system and trigger a large-scale blackout. Nevertheless, understanding the vulnerability of state estimation with regards to cyberattacks, which is a special instance of graph-structured quadratic sensing problem, has been hindered by the lack of tools for studying the topological and data-analytic aspects of networks. Algorithmic robustness is critical in extracting reliable information from abundant but untrusted grid data. For a large-scale power grid, we quantify, analyze, and visualize the regions of the network that are not robust to cyberattacks in the sense that there exists a data manipulation strategy for each of those local regions that misleads the operator at the global scale and yields a wrong estimation of the state of the network at almost all buses. We also propose an optimization-based graphical boundary defense mechanism to identify the border of the geographical area in which data have been manipulated. The proposed method does not allow a local attack to have a global effect on the data analysis of the entire network, which enhances the situational awareness of the grid, especially in the face of adversity. The developed mathematical framework reveals key geometric and algebraic factors that can affect algorithmic robustness and is used to study the vulnerability of the U.S. power grid in this paper.}
}


@article{DBLP:journals/tifs/ImL21,
	author = {Hyeon{-}Seong Im and
                  Si{-}Hyeon Lee},
	title = {Mobility-Assisted Covert Communication Over Wireless Ad Hoc Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1768--1781},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3045132},
	doi = {10.1109/TIFS.2020.3045132},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ImL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the effect of node mobility on the throughput scaling of the covert communication over a wireless adhoc network. It is assumed that n mobile nodes want to communicate each other in a unit disk while keeping the presence of the communication secret from each of Θ(n s ) non-colluding wardens (s > 0). The wardens can be mobile or fixed. Our results show that the node mobility greatly improves the throughput scaling, compared to the case of fixed node location. In particular, for s ≤ 1, the aggregate throughput scaling, i.e., the maximally achievable throughput scaling of the total network when each source-destination pair communicates with the same rate, is shown to be arbitrarily close to linear in n when the number of channel uses l that each warden uses to judge the presence of communication is not too large compared to n. More specifically, the aggregate throughput scaling is arbitrarily close to linear when s ≤ 1 and l = O(n (α-2)(1-s) ), where α ≥ 2 denotes the path loss exponent. For the achievability, we modify the two-hop based scheme by Grossglauser and Tse (2002), which was proposed for a wireless ad hoc network without a covertness constraint, by introducing a preservation region around each warden in which the senders are not allowed to transmit and by carefully analyzing the effect of covertness constraint on the transmit power and the resultant transmission rates. This scheme is shown to be optimal for 0 <; s ≤ 1 under an assumption that each node outside preservation regions around wardens uses the same transmit power.}
}


@article{DBLP:journals/tifs/XiaoZL21,
	author = {Yue Xiao and
                  Peng Zhang and
                  Yuhong Liu},
	title = {Secure and Efficient Multi-Signature Schemes for Fabric: An Enterprise
                  Blockchain Platform},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1782--1794},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3042070},
	doi = {10.1109/TIFS.2020.3042070},
	timestamp = {Thu, 04 Aug 2022 11:33:22 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XiaoZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Digital signature is a major component of transactions on Blockchain platforms, especially in enterprise Blockchain platforms, where multiple signatures from a set of peers need to be produced to endorse a transaction. However, such process is often complex and time-consuming. Multi-signature, which can improve transaction efficiency by having a set of signers cooperate to produce a joint signature, has attracted extensive attentions. In this work, we propose two multi-signature schemes, GMS and AGMS, which are proved to be more secure and efficient than state-of-the-art multi-signature schemes. Besides, we implement the proposed schemes in a real Enterprise Blockchain platform, Fabric. Experiment results show that the proposed AGMS scheme helps achieve the goal of high transaction efficiency, low storage complexity, as well as high robustness against rogue-key attacks and k\n-sum problem attacks.}
}


@article{DBLP:journals/tifs/SongLCSLW21,
	author = {Qiyang Song and
                  Zhuotao Liu and
                  Jiahao Cao and
                  Kun Sun and
                  Qi Li and
                  Cong Wang},
	title = {{SAP-SSE:} Protecting Search Patterns and Access Patterns in Searchable
                  Symmetric Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1795--1809},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3042058},
	doi = {10.1109/TIFS.2020.3042058},
	timestamp = {Sun, 22 Oct 2023 11:15:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SongLCSLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searchable symmetric encryption (SSE) enables users to search over encrypted documents in untrusted clouds without leaking the search keywords to the clouds. Existing SSE schemes achieve high search efficiency at the expense of leaking access patterns and search patterns, where clouds can recover a large percentage of queried keywords using the leaked access patterns and search patterns. To prevent clouds from recovering users' keywords, researchers have proposed a number of solutions to protect either search patterns or access patterns. However, none of them can protect both access patterns and search patterns. Moreover, existing SSE schemes cannot work in the generic database setting that allows multiple users to write or read over encrypted documents. In this paper, we propose an efficient searchable symmetric encryption scheme, called SAP-SSE, which protects both access patterns and search patterns in the generic database setting. The main idea of protecting search patterns is to leverage re-encryption cryptosystems to shuffle index entries over multiple clouds. To protect access patterns, we distribute secure indexes to multiple clouds and then propose an index redistribution protocol that allows users to renew index entries in clouds. Furthermore, SAP-SSE provides a configurable security policy to balance security and efficiency. Formal security analysis and experimental evaluation show that SAP-SSE can prevent pattern leakage with low overhead.}
}


@article{DBLP:journals/tifs/ZhangZCXL21,
	author = {Jing Zhang and
                  Hong Zhong and
                  Jie Cui and
                  Yan Xu and
                  Lu Liu},
	title = {{SMAKA:} Secure Many-to-Many Authentication and Key Agreement Scheme
                  for Vehicular Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1810--1824},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3044855},
	doi = {10.1109/TIFS.2020.3044855},
	timestamp = {Sun, 25 Jul 2021 11:42:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZCXL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rising popularity of the Internet and communication technology, vehicles can analyze and judge the real-time data collected by various cloud service providers (CSPs) in a vehicular network. However, in a vehicular network environment, real-time data are transmitted via wireless channels, which can lead to security and privacy issues. To avoid illegal access by adversaries, vehicle authentication and key agreement mechanism has been considered as one of the promising security measures in vehicular network environments. Besides, most of the solutions focus on authentication between one vehicle and one CSP. In such strategies, the implementation of efficient authentication for multiple vehicles and CSPs simultaneously is usually challenging. Further, they are also subjected to performance limitations due to the overhead incurred. To solve these issues, we propose a many-to-many authentication and key agreement scheme for secure authentication between multiple vehicles and CSPs. The proposed scheme can prevent unauthorized access and provide SK-security even if temporary information is leaked. To improve the service, the CSP only needs to broadcast an anonymous message periodically instead of having to generate a unique anonymous message for each of vehicles. Similarly, when a vehicle wants to request the services of m CSPs, it only needs to send one request message instead of m. Therefore, the proposed scheme not only implements many-to-many communication but also significantly reduces the computation and communication overhead. Moreover, a thorough security analysis shows that the proposed scheme provides better security compared to other related schemes.}
}


@article{DBLP:journals/tifs/BarniPT21,
	author = {Mauro Barni and
                  Quoc{-}Tin Phan and
                  Benedetta Tondi},
	title = {Copy Move Source-Target Disambiguation Through Multi-Branch CNNs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1825--1840},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3045903},
	doi = {10.1109/TIFS.2020.3045903},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BarniPT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a method to identify the source and target regions of a copy-move forgery so allow a correct localisation of the tampered area. First, we cast the problem into a hypothesis testing framework whose goal is to decide which region between the two nearly-duplicate regions detected by a generic copy-move detector is the original one. Then we design a multi-branch CNN architecture that solves the hypothesis testing problem by learning a set of features capable to reveal the presence of interpolation artefacts and boundary inconsistencies in the copy-moved area. The proposed architecture, trained on a synthetic dataset explicitly built for this purpose, achieves good results on copy-move forgeries from both synthetic and realistic datasets. Based on our tests, the proposed disambiguation method can reliably reveal the target region even in realistic cases where an approximate version of the copy-move localization mask is provided by a state-of-the-art copy-move detection algorithm.}
}


@article{DBLP:journals/tifs/YangMWL21,
	author = {Chenzhao Yang and
                  Jun Ma and
                  Shilin Wang and
                  Alan Wee{-}Chung Liew},
	title = {Preventing DeepFake Attacks on Speaker Authentication by Dynamic Lip
                  Movement Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1841--1854},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3045937},
	doi = {10.1109/TIFS.2020.3045937},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangMWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research has demonstrated that lip-based speaker authentication systems can not only achieve good authentication performance but also guarantee liveness. However, with modern DeepFake technology, attackers can produce the talking video of a user without leaving any visually noticeable fake traces. This can seriously compromise traditional face-based or lip-based authentication systems. To defend against sophisticated DeepFake attacks, a new visual speaker authentication scheme based on the deep convolutional neural network (DCNN) is proposed in this paper. The proposed network is composed of two functional parts, namely, the Fundamental Feature Extraction network (FFE-Net) and the Representative lip feature extraction and Classification network (RC-Net). The FFE-Net provides the fundamental information for speaker authentication. As the static lip shape and lip appearance is vulnerable to DeepFake attacks, the dynamic lip movement is emphasized in the FFE-Net. The RC-Net extracts high-level lip features that discriminate against human imposters while capturing the client's talking style. A multi-task learning scheme is designed, and the proposed network is trained end-to-end. Experiments on the GRID and MOBIO datasets have demonstrated that the proposed approach is able to achieve an accurate authentication result against human imposters and is much more robust against DeepFake attacks compared to three state-of-the-art visual speaker authentication algorithms. It is also worth noting that the proposed approach does not require any prior knowledge of the DeepFake spoofing method and thus can be applied to defend against different kinds of DeepFake attacks.}
}


@article{DBLP:journals/tifs/ZhangWLW21,
	author = {Yunfan Zhang and
                  Lingfeng Wang and
                  Zhaoxi Liu and
                  Wei Wei},
	title = {A Cyber-Insurance Scheme for Water Distribution Systems Considering
                  Malicious Cyberattacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1855--1867},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3045902},
	doi = {10.1109/TIFS.2020.3045902},
	timestamp = {Mon, 04 Oct 2021 08:33:42 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangWLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As one of the national critical infrastructures, the water distribution system supports our daily life and economic growth, the failure of which may lead to catastrophic results. Besides the uncertainty from the system component failures, cyberattacks are vital to the secure system operation and have great impacts on the reliability of the water supply service. Malicious attackers may intrude into the supervisory control and data acquisition (SCADA) system of pump stations in the water distribution networks and interrupt the water supply to the customers. Cyber insurance is emerging as a promising financial tool in system risk management. In this paper, cyber insurance is proposed for the cyber risk management of the water distribution system. A semi-Markov process (SMP) model is devised to model the cyberattacks against pump stations in the water distribution system. Both the impacts of the independent cyber risks in the individual distribution network and the correlated cyber risks shared across different water distribution networks are evaluated and modeled. A sequential Monte Carlo Simulation (MCS) based algorithm is developed to evaluate the system loss. Cyber insurance premiums for the water distribution networks are designed based on the actuarial principles and potential system losses. Case studies are also performed on multiple representative water distribution networks, and the results demonstrate the validity of the proposed cyber insurance model.}
}


@article{DBLP:journals/tifs/LiuZSWZM21,
	author = {Yuejun Liu and
                  Yongbin Zhou and
                  Shuo Sun and
                  Tianyu Wang and
                  Rui Zhang and
                  Jingdian Ming},
	title = {On the Security of Lattice-Based Fiat-Shamir Signatures in the Presence
                  of Randomness Leakage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1868--1879},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3045904},
	doi = {10.1109/TIFS.2020.3045904},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuZSWZM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Leakages during the signing process, including partial key exposure and partial (or complete) randomness exposure, may be devastating for the security of digital signatures. In this work, we investigate the security of lattice-based Fiat-Shamir signatures in the presence of randomness leakage. To this end, we present a generic key recovery attack that relies on minimum leakage of randomness, and then theoretically connect it to a variant of Integer-LWE (ILWE) problem. The ILWE problem, introduced by Bootle et al. at Asiacrypt 2018, is to recover the secret vector s given polynomially many samples of the form $({\\text{a}}, \\langle {\\text{a}}, {\\text{s}} \\rangle + \\text {e}) \\in \\mathbb {Z}^{\\text {n}+1}$ , and it is solvable if the error $\\text {e} \\in \\mathbb {Z}$ is not superpolynomially larger than the inner product $\\langle {\\text{a}}, {\\text{s}} \\rangle $ . However, in our variant (we call the variant FS-ILWE problem in this paper), ${\\text{a}}\\in \\mathbb {Z}^{\\text {n}}$ is a sparse vector whose coefficients are NOT independent any more, and e is related to a and s as well. We prove that the FS-ILWE problem can be solved in polynomial time, and present an efficient algorithm to solve it. Our generic key recovery method directly implies that many lattice-based Fiat-Shamir signatures will be totally broken with one (deterministic or probabilistic) bit of randomness leakage per signature. Our attack has been validated by experiments on two NIST PQC signatures Dilithium and qTESLA. For example, as to Dilithium-III of 125-bit quantum security, the secret key will be recovered within 10 seconds over an ordinary PC desktop, with about one million signatures. Similarly, key recovery attacks on Dilithium under other parameters and qTESLA will be completed within 20 seconds and 31 minutes respectively. In addition, we also present a non-profiled attack to show how to obtain the required randomness bit in practice through power analysis attacks on a proof-of-concept implementation of polynomial addition. The experimental results confirm the practical feasibility of our method.}
}


@article{DBLP:journals/tifs/YanMYLG21,
	author = {Jing Yan and
                  Yuan Meng and
                  Xian Yang and
                  Xiaoyuan Luo and
                  Xinping Guan},
	title = {Privacy-Preserving Localization for Underwater Sensor Networks via
                  Deep Reinforcement Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1880--1895},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3045320},
	doi = {10.1109/TIFS.2020.3045320},
	timestamp = {Thu, 29 Sep 2022 08:39:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YanMYLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Underwater sensor networks (USNs) are envisioned to enable a large variety of marine applications. Such applications require accurate position information of sensor nodes. However, the openness and inhomogeneity characteristics of underwater medium make it much more challenging to solve the localization issue. This paper is concerned with a privacy-preserving localization issue for USNs in inhomogeneous underwater medium. An honest-but-curious model is considered to develop a privacy-preserving localization protocol. Based on this, a localization problem is constructed for sensor nodes to minimize the sum of all measurement errors, where a ray compensation strategy is incorporated to remove the localization bias from assuming the straight-line transmission. To make the above problem tractable, we consider the unsupervised, supervised and semisupervised scenarios, through which deep reinforcement learning (DRL) based localization estimators are utilized to estimate the positions of sensor nodes. It is noted that, the proposed localization solution in this paper can hide the private position information of USNs, and more importantly, it is robust to local optimum for nonconvex and nonsmooth localization problem in inhomogeneous underwater medium. Finally, simulation studies are given to show the position privacy can be preserved, while the localization accuracy can be enhanced as compared with the other existing works.}
}


@article{DBLP:journals/tifs/RajendranSLR21,
	author = {Sekhar Rajendran and
                  Zhi Sun and
                  Feng Lin and
                  Kui Ren},
	title = {Injecting Reliable Radio Frequency Fingerprints Using Metasurface
                  for the Internet of Things},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1896--1911},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3045318},
	doi = {10.1109/TIFS.2020.3045318},
	timestamp = {Sat, 30 Sep 2023 10:28:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/RajendranSLR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Internet of Things, where billions of devices with limited resources are communicating with each other, security has become a major stumbling block affecting the progress of this technology. Existing authentication schemes based on digital signatures have overhead costs associated with them in terms of computation time, battery power, bandwidth, memory, and related hardware costs. Radio frequency fingerprint (RFF), utilizing the unique device-based information, can be a promising solution for IoT. However, traditional RFFs have become obsolete because of low reliability and reduced user capability. Our proposed solution, Metasurface RF-Fingerprinting Injection (MeRFFI), is to inject a carefully-designed radio frequency fingerprint into the wireless physical layer that can increase the security of a stationary IoT device with minimal overhead. The injection of fingerprint is implemented using a low cost metasurface developed and fabricated in our lab, which is designed to make small but detectable perturbations in the specific frequency band in which the IoT devices are communicating. We have conducted comprehensive system evaluations including distance, orientation, multiple channels where the feasibility, effectiveness, and reliability of these fingerprints are validated. The proposed MeRFFI system can be easily integrated into the existing authentication schemes. The security vulnerabilities are analyzed for some of the most threatening wireless physical layer-based attacks.}
}


@article{DBLP:journals/tifs/MengXHMH21,
	author = {Zhaoyi Meng and
                  Yan Xiong and
                  Wenchao Huang and
                  Fuyou Miao and
                  Jianmeng Huang},
	title = {AppAngio: Revealing Contextual Information of Android App Behaviors
                  by API-Level Audit Logs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1912--1927},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3044867},
	doi = {10.1109/TIFS.2020.3044867},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MengXHMH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Android users are now suffering severe threats from unwanted behaviors of various apps. The analysis of apps' audit logs is one of the essential methods for the security analysts of various companies to unveil the underlying maliciousness within apps. We propose and implement AppAngio, a novel system that reveals contextual information in Android app behaviors by API-level audit logs. Our goal is to help security analysts understand how the target apps worked and facilitate the identification of the maliciousness within apps. The key module of AppAngio is identifying the path matched with the logs on the app's control-flow graphs (CFGs). The challenge, however, is that the limited-quantity logs may incur high computational complexity in the log matching, where there are a large number of candidates caused by the coupling relation of successive logs. To address the challenge, we propose a divide and conquer strategy that precisely positions the nodes matched with log records on the corresponding CFGs and connects the nodes with as few backtracks as possible. Our experiments show that AppAngio reveals contextual information of behaviors in real-world apps. Moreover, the revealed results assist the analysts in identifying the maliciousness of app behaviors and complement existing analysis schemes. Meanwhile, AppAngio incurs negligible performance overhead on the real device in the experiments.}
}


@article{DBLP:journals/tifs/LiuCZ21,
	author = {Wenye Liu and
                  Chip{-}Hong Chang and
                  Fan Zhang},
	title = {Stealthy and Robust Glitch Injection Attack on Deep Learning Accelerator
                  for Target With Variational Viewpoint},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1928--1942},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3046858},
	doi = {10.1109/TIFS.2020.3046858},
	timestamp = {Thu, 11 Feb 2021 11:54:44 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuCZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural network (DNN) accelerators overcome the power and memory walls for executing neural-net models locally on edge-computing devices to support sophisticated AI applications. The advocacy of “model once, run optimized anywhere” paradigm introduces potential new security threat to edge intelligence that is methodologically different from the well-known adversarial examples. Existing adversarial examples modify the input samples presented to an AI application either digitally or physically to cause a misclassification. Nevertheless, these input-based perturbations are not robust or surreptitious on multi-view target. To generate a good adversarial example for misclassifying a real-world target of variational viewing angle, lighting and distance, a decent number of target’s samples are required to extract the rare anomalies that can cross the decision boundary. The feasible perturbations are substantial and visually perceptible. In this paper, we propose a new glitch injection attack on DNN accelerator that is capable of misclassifying a target under variational viewpoints. The glitches injected into the computation clock signal induce transitory but disruptive errors in the intermediate results of the multiply-and-accumulate (MAC) operations. The attack pattern for each target of interest consists of sparse instantaneous glitches, which can be derived from just one sample of the target. Two modes of attack patterns are derived, and their effectiveness are demonstrated on four representative ImageNet models implemented on the Deep-learning Processing Unit (DPU) of FPGA edge and its DNN development toolchain. The attack success rates are evaluated on 118 objects in 61 diverse sensing conditions, including 25 viewing angles (−60° to 60°), 24 illumination directions and 12 color temperatures. In the covert mode, the success rates of our attack exceed existing stealthy adversarial examples by more than 16.3%, with only two glitches injected into ten thousands to a million cycles for one complete inference. In the robust mode, the attack success rates on all four DNNs are more than 96.2% with an average glitch intensity of 1.4% and a maximum glitch intensity of 10.2%.}
}


@article{DBLP:journals/tifs/WangYTTHFFBW21,
	author = {Huanting Wang and
                  Guixin Ye and
                  Zhanyong Tang and
                  Shin Hwei Tan and
                  Songfang Huang and
                  Dingyi Fang and
                  Yansong Feng and
                  Lizhong Bian and
                  Zheng Wang},
	title = {Combining Graph-Based Learning With Automated Data Collection for
                  Code Vulnerability Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1943--1958},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3044773},
	doi = {10.1109/TIFS.2020.3044773},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangYTTHFFBW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents FUNDED (Flow-sensitive vUl-Nerability coDE Detection), a novel learning framework for building vulnerability detection models. Funded leverages the advances in graph neural networks (GNNs) to develop a novel graph-based learning method to capture and reason about the program’s control, data, and call dependencies. Unlike prior work that treats the program as a sequential sequence or an untyped graph, Funded learns and operates on a graph representation of the program source code, in which individual statements are connected to other statements through relational edges. By capturing the program syntax, semantics and flows, Funded finds better code representation for the downstream software vulnerability detection task. To provide sufficient training data to build an effective deep learning model, we combine probabilistic learning and statistical assessments to automatically gather high-quality training samples from open-source projects. This provides many real-life vulnerable code training samples to complement the limited vulnerable code samples available in standard vulnerability databases. We apply Funded to identify software vulnerabilities at the function level from program source code. We evaluate Funded on large real-world datasets with programs written in C, Java, Swift and Php, and compare it against six state-of-the-art code vulnerability detection models. Experimental results show that Funded significantly outperforms alternative approaches across evaluation settings.}
}


@article{DBLP:journals/tifs/HuNWJT21,
	author = {Shuyan Hu and
                  Wei Ni and
                  Xin Wang and
                  Abbas Jamalipour and
                  Dean Ta},
	title = {Joint Optimization of Trajectory, Propulsion, and Thrust Powers for
                  Covert UAV-on-UAV Video Tracking and Surveillance},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1959--1972},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3047758},
	doi = {10.1109/TIFS.2020.3047758},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuNWJT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous tracking of suspicious unmanned aerial vehicles (UAVs) by legitimate monitoring UAVs (or monitors) can be crucial to public safety and security. It is non-trivial to optimize the trajectory of a monitor while conceiving its monitoring intention, due to typically non-convex propulsion and thrust power functions. This article presents a novel framework to jointly optimize the propulsion and thrust powers, as well as the 3D trajectory of a solar-powered monitor which conducts covert, video-based, UAV-on-UAV tracking and surveillance. A multi-objective problem is formulated to minimize the energy consumption of the monitor and maximize a weighted sum of distance keeping and altitude changing, which measures the disguising of the monitor. Based on the practical power models of the UAV propulsion, thrust and hovering, and the model of the harvested solar power, the problem is non-convex and intangible for existing solvers. We convexify the propulsion power by variable substitution, and linearize the solar power. With successive convex approximation, the resultant problem is then transformed with tightened constraints and efficiently solved by the proximal difference-of-convex algorithm with extrapolation in polynomial time. The proposed scheme can be also applied online. Extensive simulations corroborate the merits of the scheme, as compared to baseline schemes with partial or no disguising.}
}


@article{DBLP:journals/tifs/FernandoFDS21,
	author = {Tharindu Fernando and
                  Clinton Fookes and
                  Simon Denman and
                  Sridha Sridharan},
	title = {Detection of Fake and Fraudulent Faces via Neural Memory Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1973--1988},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3047768},
	doi = {10.1109/TIFS.2020.3047768},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FernandoFDS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advances in computer vision have brought us to the point where we have the ability to synthesise realistic fake content. Such approaches are seen as a source of disinformation and mistrust, and pose serious concerns to governments around the world. Convolutional Neural Networks (CNNs) demonstrate encouraging results when detecting fake images that arise from the specific type of manipulation they are trained on. However, this success has not transitioned to unseen manipulation types, resulting in a significant gap in the line-of-defense. We propose a Hierarchical Attention Memory Network (HAMN), motivated by the social cognition processes of the human brain, for the detection of fake faces. Through visual cues and by utilising knowledge stored in neural memories, we allow the network to reason about the perceived face and anticipate it's future semantic embeddings. This renders a generalisable face tampering detection framework. Experimental results demonstrate the proposed approach achieves superior performance for fake and fraudulent face detection.}
}


@article{DBLP:journals/tifs/SunZS21,
	author = {Li Sun and
                  Yong Zhang and
                  A. Lee Swindlehurst},
	title = {Alternate-Jamming-Aided Wireless Physical-Layer Surveillance: Protocol
                  Design and Performance Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {1989--2003},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3046880},
	doi = {10.1109/TIFS.2020.3046880},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SunZS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we develop an alternate-jamming-aided wireless physical-layer surveillance protocol where two devices (M 1 and M 2 ) work cooperatively to eavesdrop on and intervene in a suspicious transmission link from a source (S) to a destination (D). Unlike existing approaches which rely on the use of a multi-antenna full-duplex radio as the monitor, in our protocol, M 1 and M 2 are both single-antenna nodes operating in half-duplex mode, which alternately perform proactive eavesdropping and jamming to mimic the behavior of a full-duplex monitor. Within any time slot, M 1 sends a jamming signal to deteriorate the signal reception at D and M 2 eavesdrops on the transmission from S. During the next slot, M 1 overhears the signal sent from S, and M 2 forwards its received signal during the previous slot to realize jamming. In this manner, the jamming signal received at M 1 can be perfectly removed after self-interference cancellation, and the signals from S during the two consecutive slots are jointly decoded with high reliability, thus enabling successful surveillance. On the other hand, the detection performance at D is heavily degraded due to the injection of the jamming signal, thereby preventing information leakage from S to D. The performance of the proposed protocol is analyzed in terms of the eavesdropping non-outage probability, the surveillance success probability, as well as the symbol error probability. Theoretical analysis and simulation results demonstrate the superiority of our design compared to competing solutions in the literature.}
}


@article{DBLP:journals/tifs/CuiHJFY21,
	author = {Lei Cui and
                  Zhiyu Hao and
                  Yang Jiao and
                  Haiqiang Fei and
                  Xiaochun Yun},
	title = {VulDetector: Detecting Vulnerabilities Using Weighted Feature Graph
                  Comparison},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2004--2017},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3047756},
	doi = {10.1109/TIFS.2020.3047756},
	timestamp = {Mon, 28 Aug 2023 21:40:49 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CuiHJFY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Code similarity is one promising approach to detect vulnerabilities hidden in software programs. However, due to the complexity and diversity of source code, current methods suffer low accuracy, high false negative and poor performance, especially in analyzing a large program. In this paper, we propose to tackle these problems by presenting VulDetector, a static-analysis tool to detect C/C++ vulnerabilities based on graph comparison at the granularity of function. At the key of VulDetector is a weighted feature graph (WFG) model which characterizes function with a small yet semantically rich graph. It first pinpoints vulnerability-sensitive keywords to slice the control flow graph of a function, thereby reducing the graph size without compromising security-related semantics. Then, each sliced subgraph is characterized using WFG, which provides both syntactic and semantic features in varying degrees of security. As for graph comparison, we take full usage of vulnerability graph and patch graph to improve accuracy. In addition, we propose two optimization methods based on analysis of vulnerabilities. We have implemented VulDetector to automatically detect vulnerabilities in software programs with known vulnerabilities. The experimental results prove the effectiveness and efficiency of VulDetector.}
}


@article{DBLP:journals/tifs/AbrarPK21,
	author = {Alemayehu Solomon Abrar and
                  Neal Patwari and
                  Sneha Kumar Kasera},
	title = {Quantifying Interference-Assisted Signal Strength Surveillance of
                  Sound Vibrations},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2018--2030},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3045316},
	doi = {10.1109/TIFS.2020.3045316},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AbrarPK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A malicious attacker could, by taking control of internet-of-things devices, use them to capture received signal strength (RSS) measurements and perform surveillance on a person's vital signs, activities, and sound in their environment. This article considers an attacker who looks for subtle changes in the RSS in order to eavesdrop sound vibrations. The challenge to the adversary is that sound vibrations cause very low amplitude changes in RSS, and RSS is typically quantized with a significantly larger step size. This article contributes a lower bound on an attacker's monitoring performance as a function of the RSS step size and sampling frequency so that a designer can understand their relationship. Our bound considers the little-known and counter-intuitive fact that an adversary can improve their sinusoidal parameter estimates by making some devices transmit to add interference power into the RSS measurements. We demonstrate this capability experimentally. As we show, for typical transceivers, the RSS surveillance attacker can monitor sound vibrations with remarkable accuracy. New mitigation strategies will be required to prevent RSS surveillance attacks.}
}


@article{DBLP:journals/tifs/HuangCZS21,
	author = {Zhizhong Huang and
                  Shouzhen Chen and
                  Junping Zhang and
                  Hongming Shan},
	title = {{PFA-GAN:} Progressive Face Aging With Generative Adversarial Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2031--2045},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3047753},
	doi = {10.1109/TIFS.2020.3047753},
	timestamp = {Thu, 11 Feb 2021 11:54:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangCZS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face aging is to render a given face to predict its future appearance, which plays an important role in the information forensics and security field as the appearance of the face typically varies with age. Although impressive results have been achieved with conditional generative adversarial networks (cGANs), the existing cGANs-based methods typically use a single network to learn various aging effects between any two different age groups. However, they cannot simultaneously meet three essential requirements of face aging-including image quality, aging accuracy, and identity preservation-and usually generate aged faces with strong ghost artifacts when the age gap becomes large. Inspired by the fact that faces gradually age over time, this paper proposes a novel progressive face aging framework based on generative adversarial network (PFA-GAN) to mitigate these issues. Unlike the existing cGANs-based methods, the proposed framework contains several sub-networks to mimic the face aging process from young to old, each of which only learns some specific aging effects between two adjacent age groups. The proposed framework can be trained in an end-to-end manner to eliminate accumulative artifacts and blurriness. Moreover, this paper introduces an age estimation loss to take into account the age distribution for an improved aging accuracy, and proposes to use the Pearson correlation coefficient as an evaluation metric measuring the aging smoothness for face aging methods. Extensively experimental results demonstrate superior performance over existing (c)GANs-based methods, including the state-of-the-art one; e.g., PFA-GAN reduces the aging estimation errors by 0.23 and 0.35 and increases the identity preservation rates by 0.49 and 0.63 on two benchmarked datasets compared to the second best method for the challenging face aging from 30- to 51+. The source code is available at https://github.com/Hzzone/PFA-GAN.}
}


@article{DBLP:journals/tifs/ShenLZDH21,
	author = {Meng Shen and
                  Yiting Liu and
                  Liehuang Zhu and
                  Xiaojiang Du and
                  Jiankun Hu},
	title = {Fine-Grained Webpage Fingerprinting Using Only Packet Length Information
                  of Encrypted Traffic},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2046--2059},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3046876},
	doi = {10.1109/TIFS.2020.3046876},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShenLZDH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encrypted web traffic can reveal sensitive information of users, such as their browsing behaviors. Existing studies on encrypted traffic analysis focus on website fingerprinting. We claim that fine-grained webpage fingerprinting, which speculates specific webpages on a same website visited by a victim, allows exploiting more user private information, e.g., shopping interests in an online shopping mall. Since webpages from the same website usually have very similar traffic traces that make them indistinguishable, existing solutions may end up with low accuracy. In this paper, we propose FineWP, a novel fine-grained webpage fingerprinting method. We make an observation that the length information of packets in bidirectional client-server interactions can be distinctive features for webpage fingerprinting. The extracted features are then fed into traditional machine learning models to train classifiers, which achieve both high accuracy and low training overhead. We collect two real-world traffic datasets and construct closed- and open-world evaluations to verify the effectiveness of FineWP. The experimental results demonstrate that FineWP is superior to the state-of-the-art methods in terms of accuracy, time complexity and stability.}
}


@article{DBLP:journals/tifs/ZabirMCSH21,
	author = {Ishmam Zabir and
                  Ahmed Maksud and
                  Gaojie Chen and
                  Brian M. Sadler and
                  Yingbo Hua},
	title = {Secrecy of Multi-Antenna Transmission With Full-Duplex User in the
                  Presence of Randomly Located Eavesdroppers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2060--2075},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3047763},
	doi = {10.1109/TIFS.2020.3047763},
	timestamp = {Sun, 02 Oct 2022 15:51:01 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZabirMCSH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considers the secrecy performance of several schemes for multi-antenna transmission to single-antenna users with full-duplex (FD) capability against randomly distributed single-antenna eavesdroppers (EDs). These schemes and related scenarios include transmit antenna selection (TAS), transmit antenna beamforming (TAB), artificial noise (AN) from the transmitter, user selection based their distances to the transmitter, and colluding and non-colluding EDs. The locations of randomly distributed EDs and users are assumed to be distributed as Poisson Point Process (PPP). We derive closed form expressions for the secrecy outage probabilities (SOP) of all these schemes and scenarios. The derived expressions are useful to reveal the impacts of various environmental parameters and user's choices on the SOP, and hence useful for network design purposes. Examples of such numerical results are discussed.}
}


@article{DBLP:journals/tifs/ShayanBOSCK21,
	author = {Mohammed Shayan and
                  Sukanta Bhattacharjee and
                  Ajymurat Orozaliev and
                  Yong{-}Ak Song and
                  Krishnendu Chakrabarty and
                  Ramesh Karri},
	title = {Thwarting Bio-IP Theft Through Dummy-Valve-Based Obfuscation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2076--2089},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3047755},
	doi = {10.1109/TIFS.2020.3047755},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ShayanBOSCK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Researchers develop bioassays following rigorous experimentation in the lab that involves considerable fiscal and highly-skilled-person-hour investment. Previous work shows that a bioassay implementation can be reverse-engineered by using images or video and control signals of the biochip. Hence, techniques must be devised to protect the intellectual property (IP) rights of the bioassay developer. This study is the first step in this direction and it makes the following contributions: (1) it introduces the use of a dummy valve as a security primitive to obfuscate bioassay implementations; (2) it shows how dummy valves can be used to obscure biochip building blocks such as multiplexers and mixers; (3) it presents design rules and security metrics to design and measure obfuscation. In our preliminary work, we presented the concept through the use of sieve-valve as a dummy-valve. However, sieve-valves are difficult to fabricate. To overcome fabrication complexities, we propose a novel multi-height-valve as an obfuscation primitive. Moreover, we showcase the suitability of multi-height-valve for obfuscation through COMSOL simulations. We demonstrate the practicality of the proposal by fabricating an obfuscated biochip using multi-height valves. We assess the cost-security trade-offs associated with this solution and study the practical implications of dummy-valve based obfuscation on real-life biochips.}
}


@article{DBLP:journals/tifs/LiGHC21,
	author = {Qiongxiu Li and
                  Jaron Skovsted Gundersen and
                  Richard Heusdens and
                  Mads Gr{\ae}sb{\o}ll Christensen},
	title = {Privacy-Preserving Distributed Processing: Metrics, Bounds and Algorithms},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2090--2103},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050064},
	doi = {10.1109/TIFS.2021.3050064},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiGHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving distributed processing has recently attracted considerable attention. It aims to design solutions for conducting signal processing tasks over networks in a decentralized fashion without violating privacy. Many existing algorithms can be adopted to solve this problem such as differential privacy, secure multiparty computation, and the recently proposed distributed optimization based subspace perturbation algorithms. However, since each of them is derived from a different context and has different metrics and assumptions, it is hard to choose or design an appropriate algorithm in the context of distributed processing. In order to address this problem, we first propose general mutual information based information-theoretical metrics that are able to compare and relate these existing algorithms in terms of two key aspects: output utility and individual privacy. We consider two widely-used adversary models, the passive and eavesdropping adversary. Moreover, we derive a lower bound on individual privacy which helps to understand the nature of the problem and provides insights on which algorithm is preferred given different conditions. To validate the above claims, we investigate a concrete example and compare a number of state-of-the-art approaches in terms of the concerned aspects using not only theoretical analysis but also numerical validation. Finally, we discuss and provide principles for designing appropriate algorithms for different applications.}
}


@article{DBLP:journals/tifs/YeNR21,
	author = {Fangwei Ye and
                  Carolina Naim and
                  Salim El Rouayheb},
	title = {{ON-OFF} Privacy Against Correlation Over Time},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2104--2117},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050068},
	doi = {10.1109/TIFS.2021.3050068},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YeNR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the problem of ON-OFF privacy in which a user is interested in the latest message generated by one of n sources available at a server. The user has the choice to turn privacy ON or OFF depending on whether he wants to hide his interest at the time or not. The challenge of allowing the privacy to be toggled between ON and OFF is that the user's online behavior is correlated over time. Therefore, the user cannot simply ignore the privacy requirement when privacy is OFF. We represent the user's correlated requests by an n-state Markov chain. Our goal is to design ON-OFF privacy schemes with optimal download rate that ensure privacy for past and future requests. We devise a polynomial-time algorithm to construct an ON-OFF privacy scheme. Moreover, we present an upper bound on the achievable rate. We show that the proposed scheme is optimal and the upper bound is tight for some special families of Markov chains. We also give an implicit characterization of the optimal achievable rate as a linear programming (LP).}
}


@article{DBLP:journals/tifs/FarokhiWSK21,
	author = {Farhad Farokhi and
                  Nan Wu and
                  David B. Smith and
                  Mohamed Ali K{\^{a}}afar},
	title = {The Cost of Privacy in Asynchronous Differentially-Private Machine
                  Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2118--2129},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050603},
	doi = {10.1109/TIFS.2021.3050603},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FarokhiWSK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider training machine learning models using data located on multiple private and geographically-scattered servers with different privacy settings. Due to the distributed nature of the data, communicating with all collaborating private data owners simultaneously may prove challenging or altogether impossible. We consider differentially-private asynchronous algorithms for collaboratively training machine-learning models on multiple private datasets. The asynchronous nature of the algorithms implies that a central learner interacts with the private data owners one-on-one whenever they are available for communication without needing to aggregate query responses to construct gradients of the entire fitness function. Therefore, the algorithm efficiently scales to many data owners. We define the cost of privacy as the difference between the fitness of a privacy-preserving machine-learning model and the fitness of trained machine-learning model in the absence of privacy concerns. We demonstrate that the cost of privacy has an upper bound that is inversely proportional to the combined size of the training datasets squared and the sum of the privacy budgets squared. We validate the theoretical results with experiments on financial and medical datasets. The experiments illustrate that collaboration among more than 10 data owners with at least 10,000 records with privacy budgets greater than or equal to 1 results in a superior machine-learning model in comparison to a model trained in isolation on only one of the datasets, illustrating the value of collaboration and the cost of the privacy. The number of the collaborating datasets can be lowered if the privacy budget is higher.}
}


@article{DBLP:journals/tifs/LiZ21,
	author = {Wanda Li and
                  Jianping Zeng},
	title = {Leet Usage and Its Effect on Password Security},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2130--2143},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050066},
	doi = {10.1109/TIFS.2021.3050066},
	timestamp = {Mon, 28 Aug 2023 21:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text-based passwords have long acted as the dominating authentication method. Leet, as one of the significant components in password, has not been paid enough attention yet. In this paper, we systematically study the presence of Leet in passwords. We define single and pattern forms of Leet and propose a matching approach to check whether a user password contains Leet. We extract the most prevalent counterpart pairs of Leet manifestations. Afterward, we examine the effect of Leet in passwords by incorporating Leet transformation into the probabilistic context-free grammar(PCFG) method to crack passwords. We construct the first comprehensively analyzed dictionary of Leets for passwords, which is confirmed suitable for most datasets by user survey. Experiments on four leaked password sets demonstrate that distinguished Leet usage accumulates to account for around 1% of the total dataset. Only 5% of high-frequency Leets replacement could increase the cracking rate by 0.55%. For crackers, incorporating popular Leets aids to improve password cracking performance. For users, adopting low-frequency Leets could strengthen their passwords. This research provides a new perspective to investigate Leet transformations in passwords.}
}


@article{DBLP:journals/tifs/HuangHYSLWW21,
	author = {Jianjun Huang and
                  Songming Han and
                  Wei You and
                  Wenchang Shi and
                  Bin Liang and
                  Jingzheng Wu and
                  Yanjun Wu},
	title = {Hunting Vulnerable Smart Contracts via Graph Embedding Based Bytecode
                  Matching},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2144--2156},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050051},
	doi = {10.1109/TIFS.2021.3050051},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangHYSLWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart contract vulnerabilities have attracted lots of concerns due to the resultant financial losses. Matching-based detection methods extrapolating known vulnerabilities to unknown have proven to be effective in other platforms. However, directly adopting the technique to smart contracts is obstructed by two issues, i.e., diversity of bytecode generation resulting from the rapid evolution of compilers and interference of noise code easily caused by the homogeneous business logics. To address the problems, we propose contract bytecode-oriented normalization and slicing techniques to augment bytecode matching. Specifically, we conduct data- and instruction-level normalizations to uniform the bytecode generated by different compilers, and enforce contract-specific slicing by tracking data- and control-flows with simulated bytecode executions to prune the noise code as far as possible. Based on the above techniques, we design an unsupervised graph embedding algorithm to encode the code graphs into quantitatively comparable vectors. The potentially vulnerable smart contracts can be identified by measuring the similarities between their vectors and known vulnerable ones. Our evaluations have shown the efficiency (0.47 seconds per contract on average), effectiveness (160 verified true positives) and high precision (91.95% for top-ranked). It is worth noting that, we also identify dozens of honeypot contracts, further demonstrating the capability of our method.}
}


@article{DBLP:journals/tifs/Marteau21,
	author = {Pierre{-}Francois Marteau},
	title = {Random Partitioning Forest for Point-Wise and Collective Anomaly Detection
                  - Application to Network Intrusion Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2157--2172},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050605},
	doi = {10.1109/TIFS.2021.3050605},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Marteau21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose DiFF-RF, an ensemble approach composed of random partitioning binary trees to detect point-wise and collective (as well as contextual) anomalies. Thanks to a distance-based paradigm used at the leaves of the trees, this semi-supervised approach solves a drawback that has been identified in the isolation forest (IF) algorithm. Moreover, taking into account the frequencies of visits in the leaves of the random trees allows to significantly improve the performance of DiFF-RF when considering the presence of collective anomalies. DiFF-RF is fairly easy to train, and good performance can be obtained by using a simple semi-supervised procedure to setup the extra hyper-parameter that is introduced. We first evaluate DiFF-RF on a synthetic data set to i) verify that the limitation of the IF algorithm is overcome, ii) demonstrate how collective anomalies are actually detected and iii) to analyze the effect of the meta-parameters it involves. We assess the DiFF-RF algorithm on a large set of datasets from the UCI repository, as well as four benchmarks related to network intrusion detection applications. Our experiments show that DiFF-RF almost systematically outperforms the IF algorithm and one of its extended variant, but also challenges the one-class SVM baseline, deep learning variational auto-encoder and ensemble of auto-encoder architectures. Finally, DiFF-RF is computationally efficient and can be easily parallelized on multi-core architectures.}
}


@article{DBLP:journals/tifs/PerazzoneYSB21,
	author = {Jake Bailey Perazzone and
                  Paul L. Yu and
                  Brian M. Sadler and
                  Rick S. Blum},
	title = {Artificial Noise-Aided {MIMO} Physical Layer Authentication With Imperfect
                  {CSI}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2173--2185},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050599},
	doi = {10.1109/TIFS.2021.3050599},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/PerazzoneYSB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fingerprint embedding at the physical layer is a highly tunable authentication framework for wireless communication that achieves information-theoretic security by hiding a traditional HMAC tag in noise. In a multiantenna scenario, artificial noise (AN) can be transmitted to obscure the tag even further. The AN strategy, however, relies on perfect knowledge of the channel state information (CSI) between the legitimate users. When the CSI is not perfectly known, the added noise leaks into the receiver's observations. In this article, we explore whether AN still improves security in the fingerprint embedding authentication framework with only imperfect CSI available at the transmitter and receiver. Specifically, we discuss and design detectors that account for AN leakage and analyze the adversary's ability to recover the key from observed transmissions. We compare the detection and security performance of the optimal perfect CSI detector with the imperfect CSI robust matched filter test and a generalized likelihood ratio test (GLRT). We find that utilizing AN can greatly improve security, but suffers from diminishing returns when the quality of CSI knowledge is poor. In fact, we find that in some cases allocating additional power to AN can begin to decrease key security.}
}


@article{DBLP:journals/tifs/FangXXH21,
	author = {Zijian Fang and
                  Maochao Xu and
                  Shouhuai Xu and
                  Taizhong Hu},
	title = {A Framework for Predicting Data Breach Risk: Leveraging Dependence
                  to Cope With Sparsity},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2186--2201},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3051804},
	doi = {10.1109/TIFS.2021.3051804},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FangXXH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data breach is a major cybersecurity problem that has caused huge financial losses and compromised many individuals' privacy (e.g., social security numbers). This calls for deeper understanding about the data breach risk. Despite the substantial amount of attention that has been directed toward the issue, many fundamental problems are yet to be investigated. In this article, we initiate the study of modeling and predicting risk in enterprise-level data breaches. This problem is challenging because of the sparsity of breaches experienced by individual enterprises over time, which immediately disqualifies standard statistical models because there are not enough data to train such models. As a first step towards tackling the problem, we propose an innovative statistical framework to leverage the dependence between multiple time series. In order to validate the framework, we apply it to a dataset of enterprise-level breach incidents. Experimental results show its effectiveness in modeling and predicting enterprise-level breach incidents.}
}


@article{DBLP:journals/tifs/GiboulotCB21,
	author = {Quentin Giboulot and
                  R{\'{e}}mi Cogranne and
                  Patrick Bas},
	title = {Detectability-Based {JPEG} Steganography Modeling the Processing Pipeline:
                  The Noise-Content Trade-off},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2202--2217},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050063},
	doi = {10.1109/TIFS.2021.3050063},
	timestamp = {Tue, 23 Mar 2021 14:14:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GiboulotCB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The current art of steganography shows that schemes using a deflection criterion (such as MiPOD) for JPEG steganography are usually subpar with respect to distortion-based schemes. We link this lack of performance to a poor estimation of the variance of the model of the noise on the cover image. However, this statistically-based method provides a better assessment of the detectability of hidden data as well as theoretical guarantees under a given model. In this paper, we propose a method to obtain better estimates of the variances of DCT coefficients by taking into account the dependencies introduced by development pipeline on pixels. A second method, which is a side-informed extension of Gaussian Embedding in the JPEG domain using quantization error as side-information, is also formulated and shown to achieve state-of-the-art performances. Eventually, the trade-off between noise and content complexity in steganography is thoroughly analyzed through the lenses of these two new methods using a wide range of numerical experiments.}
}


@article{DBLP:journals/tifs/FuHWWZH21,
	author = {Chaoyou Fu and
                  Yibo Hu and
                  Xiang Wu and
                  Guoli Wang and
                  Qian Zhang and
                  Ran He},
	title = {High-Fidelity Face Manipulation With Extreme Poses and Expressions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2218--2231},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050065},
	doi = {10.1109/TIFS.2021.3050065},
	timestamp = {Fri, 26 Jan 2024 21:32:25 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FuHWWZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face manipulation has shown remarkable advances with the flourish of Generative Adversarial Networks. However, due to the difficulties of controlling structures and textures, it is challenging to model poses and expressions simultaneously, especially for the extreme manipulation at high-resolution. In this article, we propose a novel framework that simplifies face manipulation into two correlated stages: a boundary prediction stage and a disentangled face synthesis stage. The first stage models poses and expressions jointly via boundary images. Specifically, a conditional encoder-decoder network is employed to predict the boundary image of the target face in a semi-supervised way. Pose and expression estimators are introduced to improve the prediction performance. In the second stage, the predicted boundary image and the input face image are encoded into the structure and the texture latent space by two encoder networks, respectively. A proxy network and a feature threshold loss are further imposed to disentangle the latent space. Furthermore, due to the lack of high-resolution face manipulation databases to verify the effectiveness of our method, we collect a new high-quality Multi-View Face (MVF-HQ) database. It contains 120,283 images at 6000 × 4000 resolution from 479 identities with diverse poses, expressions, and illuminations. MVF-HQ is much larger in scale and much higher in resolution than publicly available high-resolution face manipulation databases. We will release MVF-HQ soon to push forward the advance of face manipulation. Qualitative and quantitative experiments on four databases show that our method dramatically improves the synthesis quality.}
}


@article{DBLP:journals/tifs/ZhangLYLCZW21,
	author = {Jiayu Zhang and
                  Min Li and
                  Shihao Yan and
                  Chunshan Liu and
                  Xihan Chen and
                  Min{-}Jian Zhao and
                  Philip Whiting},
	title = {Joint Beam Training and Data Transmission Design for Covert Millimeter-Wave
                  Communication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2232--2245},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050070},
	doi = {10.1109/TIFS.2021.3050070},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLYLCZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Covert communication prevents legitimate transmission from being detected by a warden while maintaining certain covert rate at the intended user. Prior works have considered the design of covert communication over conventional low-frequency bands, but few works so far have explored the higher-frequency millimeter-wave (mmWave) spectrum. The directional nature of mmWave communication makes it attractive for covert transmission. However, how to establish such directional link in a covert manner in the first place remains as a significant challenge. In this paper, we consider a covert mmWave communication system, where legitimate parties Alice and Bob adopt beam training approach for directional link establishment. Accounting for the training overhead, we develop a new design framework that jointly optimizes beam training duration, training power and data transmission power to maximize the effective throughput of Alice-Bob link while ensuring the covertness constraint at warden Willie is met. We further propose a dual-decomposition successive convex approximation algorithm to solve the problem efficiently. Numerical studies demonstrate interesting tradeoff among the key design parameters considered and also the necessity of joint design of beam training and data transmission for covert mmWave communication.}
}


@article{DBLP:journals/tifs/PangWCCW21,
	author = {Meng Pang and
                  Binghui Wang and
                  Yiu{-}ming Cheung and
                  Yiran Chen and
                  Bihan Wen},
	title = {{VD-GAN:} {A} Unified Framework for Joint Prototype and Representation
                  Learning From Contaminated Single Sample per Person},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2246--2259},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050055},
	doi = {10.1109/TIFS.2021.3050055},
	timestamp = {Mon, 04 Jul 2022 14:19:32 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PangWCCW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Single sample per person (SSPP) face recognition with a contaminated biometric enrolment database (SSPP-ce FR) is an emerging practical FR problem, where the SSPP in the enrolment database is no longer standard but contaminated by nuisance facial variations such as expression, lighting, pose, and disguise. In this case, the conventional SSPP FR methods, including the patch-based and generic learning methods, will suffer from serious performance degradation. Few recent methods were proposed to tackle SSPP-ce FR by either performing prototype learning on the contaminated enrolment database or learning discriminative representations that are robust against variation. Despite that, most of these approaches can only handle a specified single variation, e.g., pose, but cannot be extended to multiple variations. To address these two limitations, we propose a novel Variation Disentangling Generative Adversarial Network (VDGAN) to jointly perform prototype learning and representation learning in a unified framework. The proposed VD-GAN consists of an encoder-decoder structural generator and a multi-task discriminator to handle universal variations including single, multiple, and even mixed variations in practice. The generator and discriminator play an adversarial game such that the generator learns a discriminative identity representation and generates an identity-preserved prototype for each face image, while the discriminator aims to predict face identity label, distinguish real vs. fake prototype, and disentangle target variations from the learned representations. Qualitative and quantitative evaluations on various real-world face datasets containing single/multiple and mixed variations demonstrate the effectiveness of VD-GAN.}
}


@article{DBLP:journals/tifs/YangCZNYX21,
	author = {Kang Yang and
                  Liqun Chen and
                  Zhenfeng Zhang and
                  Christopher J. P. Newton and
                  Bo Yang and
                  Li Xi},
	title = {Direct Anonymous Attestation With Optimal {TPM} Signing Efficiency},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2260--2275},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3051801},
	doi = {10.1109/TIFS.2021.3051801},
	timestamp = {Wed, 15 Dec 2021 10:31:55 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangCZNYX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Direct Anonymous Attestation (DAA) is an anonymous signature scheme, which allows the Trusted Platform Module (TPM), a small chip embedded in a host computer, to attest to the state of the host system, while preserving the privacy of the user. DAA provides two signature modes: fully anonymous signatures and pseudonymous signatures. One main goal of designing DAA schemes is to reduce the TPM signing workload as much as possible, as the TPM has only limited resources. In an optimal DAA scheme, the signing workload on the TPM will be no more than that required for a normal signature like ECSchnorr. To date, no scheme has achieved the optimal signing efficiency for both signature modes. In this paper, we propose the first DAA scheme which achieves the optimal TPM signing efficiency for both signature modes. In this scheme, the TPM takes only a single exponentiation to generate a signature, and this single exponentiation can be pre-computed. Our scheme can be implemented using the existing TPM 2.0 commands, and thus is compatible with the TPM 2.0 specification. We benchmarked the TPM 2.0 commands needed for three DAA use cases on an Infineon TPM 2.0 chip, and also implemented the host signing and verification algorithm for our DAA scheme on a laptop with 1.80GHz Intel Core i7-8550U CPU. Our experimental results show that our DAA scheme obtains a total signing time of about 144 ms for either signature mode, while with pre-computation we can obtain a signing time of about 65 ms. Based on our benchmark results for the pseudonymous signature mode, our scheme is roughly\n2×\n(resp.,\n5×\n) faster than the existing DAA schemes supported by TPM 2.0 in terms of total (resp., online) signing efficiency.}
}


@article{DBLP:journals/tifs/EtesamiKLP21,
	author = {S. Rasoul Etesami and
                  Negar Kiyavash and
                  Vincent L{\'{e}}on and
                  H. Vincent Poor},
	title = {Optimal Adversarial Policies in the Multiplicative Learning System
                  With a Malicious Expert},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2276--2287},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3052360},
	doi = {10.1109/TIFS.2021.3052360},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/EtesamiKLP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a learning system based on the conventional multiplicative weight (MW) rule that combines experts' advice to predict a sequence of true outcomes. It is assumed that one of the experts is malicious and aims to impose the maximum loss on the system. The system's loss is naturally defined to be the aggregate absolute difference between the sequence of predicted outcomes and the true outcomes. We consider this problem under both offline and online settings. In the offline setting where the malicious expert must choose its entire sequence of decisions a priori, we show somewhat surprisingly that a simple greedy policy of always reporting false prediction is asymptotically optimal with an approximation ratio of 1+O√(ln N)/N, where N is the total number of prediction stages. In particular, we describe a policy that closely resembles the structure of the optimal offline policy. For the online setting where the malicious expert can adaptively make its decisions, we show that the optimal online policy can be efficiently computed by solving a dynamic program in O(N 3 ). We also discuss a generalization of our model to multi-expert settings. Our results provide a new direction for vulnerability assessment of commonly-used learning algorithms to internal adversarial attacks.}
}


@article{DBLP:journals/tifs/NiWLS21,
	author = {Yuqing Ni and
                  Junfeng Wu and
                  Li Li and
                  Ling Shi},
	title = {Multi-Party Dynamic State Estimation That Preserves Data and Model
                  Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2288--2299},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050621},
	doi = {10.1109/TIFS.2021.3050621},
	timestamp = {Mon, 28 Aug 2023 21:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NiWLS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper we focus on the dynamic state estimation which harnesses a vast amount of sensing data harvested by multiple parties and recognize that in many applications, to improve collaborations between parties, the estimation procedure must be designed with the awareness of protecting participants' data and model privacy, where the latter refers to the privacy of key parameters of observation models. We develop a state estimation paradigm for the scenario where multiple parties with data and model privacy concerns are involved. Multiple parties monitor a physical dynamic process by deploying their own sensor networks and update the state estimate according to the average state estimate of all the parties calculated by a cloud server and security module. The paradigm taps additively homomorphic encryption which enables the cloud server and security module to jointly fuse parties' data while preserving the data privacy. Meanwhile, all the parties collaboratively develop a stable (or optimal) fusion rule without divulging sensitive model information. For the proposed filtering paradigm, we analyze the stabilization and the optimality. First, to stabilize the multi-party state estimator while preserving observation model privacy, two stabilization design methods are proposed. For special scenarios, the parties directly design their estimator gains by the matrix norm relaxation. For general scenarios, after transforming the original design problem into a convex semi-definite programming problem, the parties collaboratively derive suitable estimator gains based on the alternating direction method of multipliers (ADMM). Second, an optimal collaborative gain design method with model privacy guarantees is provided, which results in the asymptotic minimum mean square error (MMSE) state estimation. Finally, numerical examples are presented to illustrate our design and theoretical findings.}
}


@article{DBLP:journals/tifs/HanWZQHSLY21,
	author = {Shangbin Han and
                  Qianhong Wu and
                  Han Zhang and
                  Bo Qin and
                  Jiankun Hu and
                  Xingang Shi and
                  Linfeng Liu and
                  Xia Yin},
	title = {Log-Based Anomaly Detection With Robust Feature Extraction and Online
                  Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2300--2311},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3053371},
	doi = {10.1109/TIFS.2021.3053371},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HanWZQHSLY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud technology has brought great convenience to enterprises as well as customers. System logs record notable events and are becoming valuable resources to track and investigate system status. Detecting anomaly from logs as fast as possible can improve the quality of service significantly. Although many machine learning algorithms (e.g., SVM, Logistic Regression) have high detection accuracy, we find that they assume data are clean and might have high training time. Facing these challenges, in this paper, we propose Robust Online Evolving Anomaly Detection (ROEAD) framework which adopts Robust Feature Extractor (RFE) to remove the effects of noise and Online Evolving Anomaly Detection (OEAD) to dynamic update parameters. We propose Online Evolving SVM (OES) algorithm as the example of online anomaly detection methods. We analyze the performance of OES in theory and prove the performance difference between OES and the best hypothesis tends to zero as time goes infinity. We compare the performance of ROEAD against state-of-the-art anomaly detection algorithms using public log datasets. The results demonstrate that ROEAD is able to remove the effects of noise and OES can improve the detection accuracy by more than 40%.}
}


@article{DBLP:journals/tifs/ZamaniOS21,
	author = {Amirreza Zamani and
                  Tobias J. Oechtering and
                  Mikael Skoglund},
	title = {A Design Framework for Strongly {\(\chi\)}{\({^2}\)}-Private Data
                  Disclosure},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2312--2325},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3053462},
	doi = {10.1109/TIFS.2021.3053462},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZamaniOS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study a stochastic disclosure control problem using information-theoretic methods. The useful data to be disclosed depend on private data that should be protected. Thus, we design a privacy mechanism to produce new data which maximizes the disclosed information about the useful data under a strong χ 2 -privacy criterion. For sufficiently small leakage, the privacy mechanism design problem can be geometrically studied in the space of probability distributions by a local approximation of the mutual information. By using methods from Euclidean information geometry, the original highly challenging optimization problem can be reduced to a problem of finding the principal right-singular vector of a matrix, which characterizes the optimal privacy mechanism. In two extensions we first consider a scenario where an adversary receives a noisy version of the user's message and then we look for a mechanism which finds U based on observing X, maximizing the mutual information between U and Y while satisfying the privacy criterion on U and Z under the Markov chain (Z, Y)-X-U.}
}


@article{DBLP:journals/tifs/GohariWHHT21,
	author = {Parham Gohari and
                  Bo Wu and
                  Calvin Hawkins and
                  Matthew T. Hale and
                  Ufuk Topcu},
	title = {Differential Privacy on the Unit Simplex via the Dirichlet Mechanism},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2326--2340},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3052356},
	doi = {10.1109/TIFS.2021.3052356},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GohariWHHT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As members of network systems share more information among agents and with network providers, sensitive data leakage raises privacy concerns. Motivated by such concerns, we introduce a novel mechanism that privatizes vectors belonging to the unit simplex. Such vectors can be found in many applications, such as privatizing a decision-making policy in a Markov decision process. We use differential privacy as the underlying mathematical framework for this work. The introduced mechanism is a probabilistic mapping that maps a vector within the unit simplex to the same domain using a Dirichlet distribution. We find the mechanism well-suited for inputs within the unit simplex because it always returns a privatized output that is also in the unit simplex. Therefore, no further projection back onto the unit simplex is required. We verify and quantify the privacy guarantees of the mechanism for three cases: identity queries, average queries, and general linear queries. We establish a trade-off between the level of privacy and the accuracy of the mechanism output, and we introduce a parameter to balance the trade-off between them. Numerical results illustrate the proposed mechanism.}
}


@article{DBLP:journals/tifs/LuoCMZH21,
	author = {Mandi Luo and
                  Jie Cao and
                  Xin Ma and
                  Xiaoyu Zhang and
                  Ran He},
	title = {{FA-GAN:} Face Augmentation {GAN} for Deformation-Invariant Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2341--2355},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3053460},
	doi = {10.1109/TIFS.2021.3053460},
	timestamp = {Fri, 26 Jan 2024 21:32:25 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LuoCMZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Substantial improvements have been achieved in the field of face recognition due to the successful application of deep neural networks. However, existing methods are sensitive to both the quality and quantity of the training data. Despite the availability of large-scale datasets, the long tail data distribution induces strong biases in model learning. In this paper, we present a Face Augmentation Generative Adversarial Network (FA-GAN) to reduce the influence of imbalanced deformation attribute distributions. We propose to decouple these attributes from the identity representation with a novel hierarchical disentanglement module. Moreover, Graph Convolutional Networks (GCNs) are applied to recover geometric information by exploring the interrelations among local regions to guarantee the preservation of identities in face data augmentation. Extensive experiments on face reconstruction, face manipulation, and face recognition demonstrate the effectiveness and generalization ability of the proposed method.}
}


@article{DBLP:journals/tifs/XieCH21,
	author = {Ning Xie and
                  Junjie Chen and
                  Lei Huang},
	title = {Physical-Layer Authentication Using Multiple Channel-Based Features},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2356--2366},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3054534},
	doi = {10.1109/TIFS.2021.3054534},
	timestamp = {Fri, 24 Feb 2023 18:00:35 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XieCH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper concerns the problem of authenticating the transmitter without a secret key. In comparison with traditional cryptographic-based authentication mechanisms, the Physical-Layer Authentication (PLA) has the following advantages: high security, low complexity, and high compatibility, since it exploits intrinsic and unique features of the physical layer to authenticate the transmitter rather than using a secret key. The prior channel-based PLA schemes use a quantization algorithm to deal with multiple channel-based features for simplicity. However, there are two main limitations in the prior schemes: performance loss due to quantization error and the difficulty of obtaining the optimal thresholds in closed-form. In this paper, we propose two multiple Channel Impulse Response (CIR) based PLA schemes to effectively overcome the aforementioned limitations of the prior schemes. The first scheme uses multiple CIRs to realize the PLA, which is named as the Multiple CIRs PLA (MCP) scheme. The MCP scheme has better authentication performance than the prior schemes, since it avoids to use a quantization algorithm. The second scheme further improves the authentication performance by exploiting the channel correlation coefficient, which is named as the Enhanced Multiple CIRs PLA (EMCP) scheme. We provide rigorous performance analysis of two proposed schemes. We implemented the proposed schemes and conducted extensive performance comparisons through simulations. Our experimental results show that the closed-form expressions of the theoretical results of the proposed schemes perfectly match the corresponding simulation results. The EMCP scheme has the best authentication performance and the MCP scheme is the second one, whereas the prior scheme is the worst one. As the SNR or the channel correlation coefficient declines, the performance gap among various schemes gradually increases.}
}


@article{DBLP:journals/tifs/ShenZZXD21,
	author = {Meng Shen and
                  Jinpeng Zhang and
                  Liehuang Zhu and
                  Ke Xu and
                  Xiaojiang Du},
	title = {Accurate Decentralized Application Identification via Encrypted Traffic
                  Analysis Using Graph Neural Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2367--2380},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050608},
	doi = {10.1109/TIFS.2021.3050608},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShenZZXD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized Applications (DApps) are increasingly developed and deployed on blockchain platforms such as Ethereum. DApp fingerprinting can identify users' visits to specific DApps by analyzing the resulting network traffic, revealing much sensitive information about the users, such as their real identities, financial conditions and religious or political preferences. DApps deployed on the same platform usually adopt the same communication interface and similar traffic encryption settings, making the resulting traffic less discriminative. Existing encrypted traffic classification methods either require hand-crafted and fine-tuning features or suffer from low accuracy. It remains a challenging task to conduct DApp fingerprinting in an accurate and efficient way. In this paper, we present GraphDApp, a novel DApp fingerprinting method using Graph Neural Networks (GNNs). We propose a graph structure named Traffic Interaction Graph (TIG) as an information-rich representation of encrypted DApp flows, which implicitly reserves multiple dimensional features in bidirectional client-server interactions. Using TIG, we turn DApp fingerprinting into a graph classification problem and design a powerful GNN-based classifier. We collect real-world traffic datasets from 1,300 DApps with more than 169,000 flows. The experimental results show that GraphDApp is superior to the other state-of-the-art methods in terms of classification accuracy in both closed- and open-world scenarios. In addition, GraphDApp maintains its high accuracy when being applied to the traditional mobile application classification.}
}


@article{DBLP:journals/tifs/FadulRLO21,
	author = {Mohamed K. M. Fadul and
                  Donald R. Reising and
                  T. Daniel Loveless and
                  Abdul R. Ofoli},
	title = {Nelder-Mead Simplex Channel Estimation for the {RF-DNA} Fingerprinting
                  of {OFDM} Transmitters Under Rayleigh Fading Conditions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2381--2396},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3054524},
	doi = {10.1109/TIFS.2021.3054524},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FadulRLO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is a collection of Internet connected devices capable of interacting with the physical world and computer systems. It is estimated that IoT will consist of more than seventy five billion devices by the year 2025. In addition to the sheer numbers, the need for IoT security is exacerbated by the fact that many of the edge devices employ weak to no encryption of the communication link. It has been estimated that almost 70% of IoT devices use no form of encryption. Previous research has suggested the use of Specific Emitter Identification (SEI), a physical layer technique, as a means of augmenting bit-level security mechanisms such as encryption. Radio Frequency-Distinct Native Attributes (RF-DNA) fingerprinting is an SEI technique that has demonstrated success in discriminating radios operating within a noise only channel. This work extends RF-DNA fingerprinting to the discrimination of radios operating under Rayleigh fading conditions through the use of a Nelder-Mead (N-M) simplex-based channel estimator. The N-M estimator estimates the multipath channel directly from the received waveform; thus, eliminating the need for demodulation that is required when using constellation-based estimators. N-M estimator proves superior to three alternative waveform-based estimation approaches under increasing fading paths/reflections and decreasing Signal-to-Noise Ratio (SNR). Radio discrimination performance is maximized through the assessment of: (i) RF-DNA fingerprints generated from the magnitude versus phase representation of the Gabor transform's coefficients, (ii) a statistic-based classifier versus a neural network-based classifier, and (iii) the size of patch used to subdivide the Gabor-based time-frequency response prior to calculation of the RF-DNA fingerprint features. The resulting RF-DNA fingerprinting process achieves an average percent correct classification of 92.3% or greater for Rayleigh fading channels consisting of: two, three, or five reflections/paths at SNR≥15 dB.}
}


@article{DBLP:journals/tifs/NisiotiLLP21,
	author = {Antonia Nisioti and
                  George Loukas and
                  Aron Laszka and
                  Emmanouil Panaousis},
	title = {Data-Driven Decision Support for Optimizing Cyber Forensic Investigations},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2397--2412},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3054966},
	doi = {10.1109/TIFS.2021.3054966},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NisiotiLLP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber attacks consisting of several attack actions can present considerable challenge to forensic investigations. Consider the case where a cybersecurity breach is suspected following the discovery of one attack action, for example by observing the modification of sensitive registry keys, suspicious network traffic patterns, or the abuse of legitimate credentials. At this point, the investigator can have multiple options as to what to check next to discover the rest, and will likely pick one based on experience and training. This will be the case at each new step. We argue that the efficiency of this aspect of the job, which is the selection of what next step to take, can have significant impact on its overall cost (e.g., the duration) of the investigation and can be improved through the application of constrained optimization techniques. Here, we present DISCLOSE, the first data-driven decision support framework for optimizing forensic investigations of cybersecurity breaches. DISCLOSE benefits from a repository of known adversarial tactics, techniques, and procedures (TTPs), for each of which it harvests threat intelligence information to calculate its probabilistic relations with the rest. These relations, as well as a proximity parameter derived from the projection of quantitative data regarding the adversarial TTPs on an attack life cycle model, are both used as input to our optimization framework. We show the feasibility of this approach in a case study that consists of 31 adversarial TTPs, data collected from 6 interviews with experienced cybersecurity professionals and data extracted from the MITRE ATT&CK STIX repository and the Common Vulnerability Scoring System (CVSS).}
}


@article{DBLP:journals/tifs/BabunAU21,
	author = {Leonardo Babun and
                  Hidayet Aksu and
                  A. Selcuk Uluagac},
	title = {{CPS} Device-Class Identification via Behavioral Fingerprinting: From
                  Theory to Practice},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2413--2428},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3054968},
	doi = {10.1109/TIFS.2021.3054968},
	timestamp = {Tue, 02 Mar 2021 11:26:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BabunAU21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-Physical Systems (CPS) utilize different devices to collect sensitive data, communicate with other systems, and monitor essential processes in critical infrastructure applications. However, in the ecosystem of CPS, unauthorized or spoofed devices may danger or compromise the performance and security of the critical infrastructure. The unauthorized and spoofed devices may include tampered pieces of software or hardware components that can negatively impact CPS operations or collect vital CPS metrics from the network. Such devices can be outsider or insider threats trying to impersonate other real CPS devices via spoofing their legitimate identifications to gain access to systems, steal information, or spread malware. Device fingerprinting techniques are promising approaches to identify unauthorized or illegitimate devices. However, current fingerprinting solutions are not suitable as they disrupt critical real-time operations in CPS due to the nature of their extensive data analysis or too much overhead on the devices' computational resources. To address these concerns, in this work, we propose STOP-AND- FRISK (S&F), a novel fingerprinting framework to identify CPS device classes and complement traditional security mechanisms in CPS. S&F is based on a secure challenge/response mechanism that analyzes the behavior of the CPS devices at both the hardware and OS/kernel levels. Specifically, the proposed novel mechanism combines system and function call tracing techniques, signal processing, and hardware performance analysis to create specific device-class signatures. Then, the signatures are correlated against known behavioral ground-truth to identify the device types. To test the efficacy of S&F extensively, we implemented a realistic testbed that included different classes of CPS devices with a variety of computing resources, architectures, and configurations. Our experimental results reveal an excellent rate on the CPS device-class identification. Finally, extensive performance analysis demonstrates that the use of S&F yields minimal overhead on the CPS devices' computing resources.}
}


@article{DBLP:journals/tifs/XuR21,
	author = {Dongyang Xu and
                  Pinyi Ren},
	title = {Quantum Learning Based Nonrandom Superimposed Coding for Secure Wireless
                  Access in 5G {URLLC}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2429--2444},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3056215},
	doi = {10.1109/TIFS.2021.3056215},
	timestamp = {Wed, 07 Apr 2021 16:01:12 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure wireless access in ultra-reliable low-latency communications (URLLC), which is a critical aspect of 5G security, has become increasingly important due to its potential support of grant-free configuration. In grant-free URLLC, precise allocation of different pilot resources to different users that share the same time-frequency resource is essential for the next generation NodeB (gNB) to exactly identify those users under access collision and to maintain precise channel estimation required for reliable data transmission. However, this process easily suffers from attacks on pilots. We in this article propose a quantum learning based nonrandom superimposed coding method to encode and decode pilots on multidimensional resources, such that the uncertainty of attacks can be learned quickly and eliminated precisely. Particularly, multiuser pilots for uplink access are encoded as distinguishable subcarrier activation patterns (SAPs) and gNB decodes pilots of interest from observed SAPs, a superposition of SAPs from access users, by joint design of attack mode detection and user activity detection though a quantum learning network (QLN). We found that the uncertainty lies in the identification process of codeword digits from the attacker, which can be always modelled as a black-box model, resolved by a quantum learning algorithm and quantum circuit. Novel analytical closed-form expressions of failure probability are derived to characterize the reliability of this URLLC system with short packet transmission. Simulations how that our method can bring ultra-high reliability and low latency despite attacks on pilots.}
}


@article{DBLP:journals/tifs/PuteauxP21,
	author = {Pauline Puteaux and
                  William Puech},
	title = {Rebuttal: On the Security of Reversible Data Hiding in Encrypted Images
                  by {MSB} Prediction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2445--2446},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3055630},
	doi = {10.1109/TIFS.2021.3055630},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PuteauxP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Prior to the publication of our article in 2018, to our knowledge, there were no methods of achieving a favourable trade-off between the payload in bits-per-pixel (bpp) and the quality of the reconstructed image in terms of PSNR or SSIM. Indeed, a high payload value would lead to a degradation of the reconstructed image’s quality. Moreover, it should also be noted that almost all of the other state-of-the-art methods at the time, were based on Least Significant Bit (LSB) substitution and made little use of the redundancy between pixels in the clear domain to realize the data embedding of a secret message. In our proposed work [2] , we have taken the opposing view by developing a Most Significant Bits (MSB) prediction-based reversible data hiding in encrypted images (RDHEI) method. In the EPE-HCRDH approach, the original image is encrypted without modification and information about the location of all pixels which cannot be correctly predicted is embedded by MSB substitution. In order to localize the prediction errors, flags of consecutive bits equal to 1 are used. With this information, the data hider can detect all the bits which can be marked and substitute them with bits of a secret message. In this case, the payload is slightly lower than 1 bpp, but perfect reversibility is achieved. So, the proposed EPE-HCRDH approach provides a high payload with a little complexity. But as highlighted by Dragoi and Coltuc [1] , the fact of using flags, so that the data hider can embed a secret message introduces security flaws in the method. Despite this, the method has attracted the attention of many researchers, with 100 citations (according to Google Scholar on November 9, 2020) in several peer-reviewed journals of excellent reputation (IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY [3] , IEEE TRANSACTIONS ON MULTIMEDIA [4] – [7] , IEEE ACCESS [8] , IEEE TRANSACTIONS ON SIGNAL PROCESSING, and IEEE TRANSACTION ON DEPENDABLE AND SECURE COMPUTING [9] . Today, we can say that high capacity RDHEI has become a hot topic.}
}


@article{DBLP:journals/tifs/LiQHQLD21,
	author = {Qian Li and
                  Yong Qi and
                  Qingyuan Hu and
                  Saiyu Qi and
                  Yun Lin and
                  Jin Song Dong},
	title = {Adversarial Adaptive Neighborhood With Feature Importance-Aware Convex
                  Interpolation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2447--2460},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3047752},
	doi = {10.1109/TIFS.2020.3047752},
	timestamp = {Wed, 07 Apr 2021 16:01:12 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiQHQLD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial Examples threaten to fool deep learning models to output erroneous predictions with high confidence. Optimization-based methods for constructing such samples have been extensively studied. While being effective in terms of aggression, they typically lack clear interpretation and constraint about their underlying generation process, which thus hinders us from leveraging the produced adversarial samples for model protection in the reverse direction. Hence, we expect them to repair bugs in the pre-trained models by produced additional training data equipped with strong attack ability rather than time-consuming full re-training from scratch. To address these issues, we first study the black-box behaviors and the intrinsic deficiency of neighborhood information in previous optimization-based adversarial attacks and defenses, respectively. Then we introduce a new method dubbed FeaCP, which uses correct predicted samples in disjoint classes to guide the generation of more explainable adversarial samples in the ambiguous region around the decision boundary instead of uncontrolled “blind spots”, via convex combination in a feature component-wise manner which takes the individual importance of feature ingredients into account. Our method incorporates the prior fact that for well-separated samples, the path connecting them would go through model's decision-boundary that lies in a low-density region, however, wherein adversarial examples are spread with high probability, thus having an impact on the ultimate trained model. In our work, the path is constructed by proposed inhomogeneous feature-wise convex interpolation rather than operating on sample-wise level, limiting the search space of FeaCP to obtain an adaptive neighborhood. Finally, we provide detailed insights and extend our method to adversarial fine-tuning using vicinity distribution to optimize the approximated decision boundary, and validate the significance of our FeaCP to model performance. The experimental results show that our method provides competitive performance on various datasets and networks.}
}


@article{DBLP:journals/tifs/UppalSGE21,
	author = {Hardik Uppal and
                  Alireza Sepas{-}Moghaddam and
                  Michael A. Greenspan and
                  Ali Etemad},
	title = {Depth as Attention for Face Representation Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2461--2476},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3053458},
	doi = {10.1109/TIFS.2021.3053458},
	timestamp = {Fri, 30 Apr 2021 09:35:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/UppalSGE21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face representation learning solutions have recently achieved great success for various applications such as verification and identification. However, face recognition approaches that are based purely on RGB images rely solely on intensity information, and therefore are more sensitive to facial variations, notably pose, occlusions, and environmental changes such as illumination and background. A novel depth-guided attention mechanism is proposed for deep multi-modal face recognition using low-cost RGB-D sensors. Our novel attention mechanism directs the deep network “where to look” for visual features in the RGB image by focusing the attention of the network using depth features extracted by a Convolution Neural Network (CNN). The depth features help the network focus on regions of the face in the RGB image that contain more prominent person-specific information. Our attention mechanism then uses this correlation to generate an attention map for RGB images from the depth features extracted by the CNN. We test our network on four public datasets, showing that the features obtained by our proposed solution yield better results on the Lock3DFace, CurtinFaces, IIIT-D RGB-D, and KaspAROV datasets which include challenging variations in pose, occlusion, illumination, expression, and time lapse. Our solution achieves average (increased) accuracies of 87.3% (+5.0%), 99.1% (+0.9%), 99.7% (+0.6%) and 95.3%(+0.5%) for the four datasets respectively, thereby improving the state-of-the-art. We also perform additional experiments with thermal images, instead of depth images, showing the high generalization ability of our solution when adopting other modalities for guiding the attention mechanism instead of depth information.}
}


@article{DBLP:journals/tifs/ChenYLWK21,
	author = {Baoliang Chen and
                  Wenhan Yang and
                  Haoliang Li and
                  Shiqi Wang and
                  Sam Kwong},
	title = {Camera Invariant Feature Learning for Generalized Face Anti-Spoofing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2477--2492},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3055018},
	doi = {10.1109/TIFS.2021.3055018},
	timestamp = {Sun, 25 Jul 2021 11:42:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenYLWK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There has been an increasing consensus in learning based face anti-spoofing that the divergence in terms of camera models is causing a large domain gap in real application scenarios. We describe a framework that eliminates the influence of inherent variance from acquisition cameras at the feature level, leading to the generalized face spoofing detection model that could be highly adaptive to different acquisition devices. In particular, the framework is composed of two branches. The first branch aims to learn the camera invariant spoofing features via feature level decomposition in the high frequency domain. Motivated by the fact that the spoofing features exist not only in the high frequency domain, in the second branch the discrimination capability of extracted spoofing features is further boosted from the enhanced image based on the recomposition of the high-frequency and low-frequency information. Finally, the classification results of the two branches are fused together by a weighting strategy. Experiments show that the proposed method can achieve better performance in both intra-dataset and cross-dataset settings, demonstrating the high generalization capability in various application scenarios.}
}


@article{DBLP:journals/tifs/BharatiMFRBS21,
	author = {Aparna Bharati and
                  Daniel Moreira and
                  Patrick J. Flynn and
                  Anderson de Rezende Rocha and
                  Kevin W. Bowyer and
                  Walter J. Scheirer},
	title = {Transformation-Aware Embeddings for Image Provenance},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2493--2507},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050061},
	doi = {10.1109/TIFS.2021.3050061},
	timestamp = {Wed, 07 Apr 2021 16:01:13 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BharatiMFRBS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A dramatic rise in the flow of manipulated image content on the Internet has led to a prompt response from the media forensics research community. New mitigation efforts leverage cutting-edge data-driven strategies and increasingly incorporate usage of techniques from computer vision and machine learning to detect and profile the space of image manipulations. This paper addresses Image Provenance Analysis, which aims at discovering relationships among different manipulated image versions that share content. One important task in provenance analysis, like most visual understanding problems, is establishing a visual description and dissimilarity computation method that connects images that share full or partial content. But the existing handcrafted or learned descriptors - generally appropriate for tasks such as object recognition - may not sufficiently encode the subtle differences between near-duplicate image variants, which significantly characterize the provenance of any image. This paper introduces a novel data-driven learning-based approach that provides the context for ordering images that have been generated from a single image source through various transformations. Our approach learns transformation-aware embeddings using weak supervision via composited transformations and a rank-based Edit Sequence Loss. To establish the effectiveness of the proposed approach, comparisons are made with state-of-the-art handcrafted and deep-learning-based descriptors, as well as image matching approaches. Further experimentation validates the proposed approach in the context of image provenance analysis and improves upon existing approaches.}
}


@article{DBLP:journals/tifs/AlrahisPKSMAS21,
	author = {Lilas Alrahis and
                  Satwik Patnaik and
                  Johann Knechtel and
                  Hani H. Saleh and
                  Baker Mohammad and
                  Mahmoud Al{-}Qutayri and
                  Ozgur Sinanoglu},
	title = {{UNSAIL:} Thwarting Oracle-Less Machine Learning Attacks on Logic
                  Locking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2508--2523},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3057576},
	doi = {10.1109/TIFS.2021.3057576},
	timestamp = {Wed, 07 Apr 2021 16:01:12 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AlrahisPKSMAS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Logic locking aims to protect the intellectual property (IP) of integrated circuit (IC) designs throughout the globalized supply chain. The SAIL attack, based on tailored machine learning (ML) models, circumvents combinational logic locking with high accuracy and is amongst the most potent attacks as it does not require a functional IC acting as an oracle. In this work, we propose UNSAIL, a logic locking technique that inserts key-gate structures with the specific aim to confuse ML models like those used in SAIL. More specifically, UNSAIL serves to prevent attacks seeking to resolve the structural transformations of synthesis-induced obfuscation, which is an essential step for logic locking. Our approach is generic; it can protect any local structure of key-gates against such ML-based attacks in an oracle-less setting. We develop a reference implementation for the SAIL attack and launch it on both traditionally locked and UNSAIL-locked designs. For SAIL, two ML models have been proposed (which we implement accordingly), namely a change-prediction model and a reconstruction model; the change-prediction model is used to determine which key-gate structures to restore using the reconstruction model. Our study on benchmarks ranging from the ISCAS-85 and ITC-99 suites to the OpenRISC Reference Platform System-on-Chip (ORPSoC) confirms that UNSAIL degrades the accuracy of the change-prediction model and the reconstruction model by an average of 20.13 and 17 percentage points (pp), respectively. When the aforementioned models are combined, which is the most powerful scenario for SAIL, UNSAIL reduces the attack accuracy of SAIL by an average of 11pp. We further demonstrate that UNSAIL thwarts other oracle-less attacks, i.e., SWEEP and the redundancy attack, indicating the generic nature and strength of our approach. Detailed layout-level evaluations illustrate that UNSAIL incurs minimal area and power overheads of 0.26% and 0.61%, respectively, on the million-gate ORPSoC design.}
}


@article{DBLP:journals/tifs/BiswasKW21,
	author = {Rajorshi Biswas and
                  Sungji Kim and
                  Jie Wu},
	title = {Sampling Rate Distribution for Flow Monitoring and DDoS Detection
                  in Datacenter},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2524--2534},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3054522},
	doi = {10.1109/TIFS.2021.3054522},
	timestamp = {Wed, 07 Apr 2021 16:01:13 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BiswasKW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Monitoring all the internal flows in a datacenter is important to protect a victim against internal distributed denial-of-service (DDoS) attacks. Unused virtual machines (VMs) in a datacenter are used as monitors and flows are copied to the monitors from software defined networking (SDN) switches by adding some special rules. In such a system, a VM runs a machine learning method to detect DDoS behavior but it can only process a limited number/amount of flows. When the amount of flows is beyond the capacities of all monitor VMs, the system sub-samples each flow probabilistically. The sampling rate affects the DDoS detection rate of the monitors. Besides, the DDoS detection rates of different types of flows are different for the same sampling rate. A uniform sampling rate might not produce a good overall DDoS detection rate. Assigning different sampling rates to different flows may produce the best result. In this paper, we propose a flow grouping approach based on behavioral similarity among the VMs followed by hierarchical clustering of VMs. The sampling rate is uniform among all the flows in a group. We investigate the relationship between the sampling rate and the DDoS detection rate. Then, we formulate an optimization problem for finding an optimal sampling rate distribution and solve it using mix-integer linear programming. We conduct extensive experiments with Hadoop and Spark and present results that support the feasibility of our model.}
}


@article{DBLP:journals/tifs/XiaoLXZD21,
	author = {Liang Xiao and
                  Xiaozhen Lu and
                  Tangwei Xu and
                  Weihua Zhuang and
                  Huaiyu Dai},
	title = {Reinforcement Learning-Based Physical-Layer Authentication for Controller
                  Area Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2535--2547},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3056206},
	doi = {10.1109/TIFS.2021.3056206},
	timestamp = {Wed, 07 Apr 2021 16:01:12 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XiaoLXZD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In controller area networks (CANs), electronic control units (ECUs) such as telematics ECUs and on-board diagnostic ports must protect the message exchange from spoofing attacks. In this paper, we propose a CAN bus authentication framework that exploits physical layer features of the messages, including message arrival intervals and signal voltages, and applies reinforcement learning to choose the authentication mode and parameter. By applying the Dyna architecture and using a double estimator, this scheme improves the utility in terms of authentication accuracy without changing the CAN bus protocol or the ECU components and requiring knowledge of the spoofing model. We also propose a deep learning version to further improve the authentication efficiency for the CAN bus. The learning scheme applies a hierarchical structure to reduce the exploration time, and uses two deep neural networks to compress the high-dimensional state space and to fully exploit the physical authentication experiences. We provide the computational complexity and the performance analysis. Experimental results verify the theoretical analysis and show that our proposed schemes significantly improve the authentication accuracy as compared with benchmark schemes.}
}


@article{DBLP:journals/tifs/KhanNLB21,
	author = {Nadir Khan and
                  Sven Nitzsche and
                  Asier Garciandia L{\'{o}}pez and
                  J{\"{u}}rgen Becker},
	title = {Utilizing and Extending Trusted Execution Environment in Heterogeneous
                  SoCs for a Pay-Per-Device {IP} Licensing Scheme},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2548--2563},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3058777},
	doi = {10.1109/TIFS.2021.3058777},
	timestamp = {Tue, 21 Mar 2023 21:13:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KhanNLB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A pay-per-use Intellectual Property (IP) licensing model that can protect IPs from multiple participants will benefit the FPGA IP market and Small to Medium Enterprises (SMEs). Existing protection solutions in modern FPGA devices rely on dedicated decryption engines that use cryptographic keys, which require programming them in a trusted environment. Since designs from multiple participants need protection in a typical licensing scenario, it requires a trusted third party for key programming and encryption tasks. These requirements led to the proposition of several licensing schemes; however, they do not address several security and flexibility challenges. Therefore, in this work, we propose a pay-per-device IP licensing scheme that is secure, less restrictive for the system developer and offers protection against malicious IP cores. The scheme relies on a Security Framework (SFW) that provides a Trusted Execution Environment (TEE), which handles key storage, cryptographic operations, and security monitoring. A device running the SFW can be considered a trusted platform that provides a direct secure path for the IP from its vendor to the device's TEE, where it is decrypted, analyzed and, then configured on the programmable logic.}
}


@article{DBLP:journals/tifs/LiZXC21,
	author = {Shiyu Li and
                  Yuan Zhang and
                  Chunxiang Xu and
                  Kefei Chen},
	title = {Cryptoanalysis of an Authenticated Data Structure Scheme With Public
                  Privacy-Preserving Auditing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2564--2565},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3059270},
	doi = {10.1109/TIFS.2021.3059270},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiZXC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this letter, we point out that the privacy-preserving adaptive trapdoor hash authentication tree scheme (published in IEEE TIFS, doi: 10.1109/TIFS.2020.2986879) can be invalidated by an adversarial cloud server: if the outsourced data is arbitrarily modified, the cloud server still can pass the third-party auditor's auditing.}
}


@article{DBLP:journals/tifs/WeerasingheAEL21,
	author = {Sandamal Weerasinghe and
                  Tansu Alpcan and
                  Sarah M. Erfani and
                  Christopher Leckie},
	title = {Defending Support Vector Machines Against Data Poisoning Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2566--2578},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3058771},
	doi = {10.1109/TIFS.2021.3058771},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WeerasingheAEL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Support Vector Machines (SVMs) are vulnerable to targeted training data manipulations such as poisoning attacks and label flips. By carefully manipulating a subset of training samples, the attacker forces the learner to compute an incorrect decision boundary, thereby causing misclassifications. Considering the increased importance of SVMs in engineering and life-critical applications, we develop a novel defense algorithm that improves resistance against such attacks. Local Intrinsic Dimensionality (LID) is a promising metric that characterizes the outlierness of data samples. In this work, we introduce a new approximation of LID called K-LID that uses kernel distance in the LID calculation, which allows LID to be calculated in high dimensional transformed spaces. We introduce a weighted SVM against such attacks using K-LID as a distinguishing characteristic that de-emphasizes the effect of suspicious data samples on the SVM decision boundary. Each sample is weighted on how likely its K-LID value is from the benign K-LID distribution rather than the attacked K-LID distribution. Experiments with benchmark data sets show that the proposed defense reduces classification error rates substantially (10% on average).}
}


@article{DBLP:journals/tifs/LanWLL21,
	author = {Caihui Lan and
                  Caifen Wang and
                  Haifeng Li and
                  Liangliang Liu},
	title = {Comments on "Attribute-Based Data Sharing Scheme Revisited in Cloud
                  Computing"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2579--2580},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3058758},
	doi = {10.1109/TIFS.2021.3058758},
	timestamp = {Mon, 28 Aug 2023 21:40:51 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LanWLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this letter, we discuss the security weakness of Wang et al. ’s attribute-based data sharing scheme, in IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY (TIFS) (DOI: 10.1109/TIFS.2016.2549004). Through designing two concrete attacks, we identify two serious security flaws in their scheme. 1) First, we show that their scheme is insecure because in their scheme any authenticated user can freely tamper with the weight of his own attribute to gain higher level decryption privilege to arbitrarily decrypt the ciphertext belonging to another user with higher weight of attribute. 2) Second, we further demonstrate that their scheme is trivial insecure because in their scheme even any malicious authenticated user’s attribute does not match the access policy of a ciphertext, he/she still has the power to decrypt the ciphertext, i.e., the decryption power is independent of attributes, thus, their scheme is not a rigorous attribute-based scheme. The two weaknesses discovered may hinder their scheme infeasible for practical deployment. Accordingly, we present a remedy solution to the issues while preserving all the security features of the original scheme. We hope that our cryptoanalysis and remedy scheme may contribute to avoiding similar design flaws in future designs.}
}


@article{DBLP:journals/tifs/ZhouZ21,
	author = {Jingbo Zhou and
                  Xinmiao Zhang},
	title = {Generalized SAT-Attack-Resistant Logic Locking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2581--2592},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3059271},
	doi = {10.1109/TIFS.2021.3059271},
	timestamp = {Wed, 07 Apr 2021 16:01:13 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Logic locking is used to protect integrated circuits (ICs) from piracy and counterfeiting. An encrypted IC implements the correct function only when the right key is input. Many existing logic-locking methods are subject to the powerful satisfiability (SAT)-based attack. Recently, an Anti-SAT scheme has been developed. By adopting two complementary logic blocks that consist of AND/NAND trees, it makes the number of iterations needed by the SAT attack exponential to the number of input bits. Nevertheless, the Anti-SAT scheme is vulnerable to the later AppSAT and removal attacks. This article proposes a generalized (G-)Anti-SAT scheme. Different from the Anti-SAT scheme, a variety of complementary or non-complementary functions can be adopted for the two blocks in our G-Anti-SAT scheme. The Anti-SAT scheme is just a special case of our proposed design. Our design can achieve higher output corruptibility, which is also tunable, so that better resistance to the AppSAT and removal attacks is achieved. Meanwhile, unlike existing AppSAT-resilient designs, our design does not sacrifice the resistance to the SAT attack.}
}


@article{DBLP:journals/tifs/FangXZHWBG21,
	author = {Yuchun Fang and
                  Zhengye Xiao and
                  Wei Zhang and
                  Yan Huang and
                  Liang Wang and
                  Nozha Boujemaa and
                  Donald Geman},
	title = {Attribute Prototype Learning for Interactive Face Retrieval},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2593--2607},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3059274},
	doi = {10.1109/TIFS.2021.3059274},
	timestamp = {Tue, 26 Oct 2021 12:53:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FangXZHWBG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interactive face retrieval aims at finding target subjects in face databases through human and machine interaction, which involves user feedback based on human perception and machine similarity measure in feature spaces. In this article, we propose an attribute prototype learning method to tackle the semantic gap between human and machine in face perception for fast interactive face retrieval. We reformulate the theoretical explanation of the interactive retrieval model and develop the algorithm of the heuristic solution of the model. Each module of the prototype model is learned with a set of identity-related facial attributes. The outputs of the prototype modules form the semantic representation. To adapt the prototype models across different databases, we propose a transfer selection algorithm based on the coherence measurements in interactive face retrieval. Coherence analysis proves that the proposed attribute prototype representation can effectively narrow down the semantic gap even in the case of cross-database transfer learning. The prototype representation can effectively reduce the feature dimension in the retrieval process. Real user retrieval with the Bayesian relevance feedback model shows that attribute prototype space is superior to low-level feature space and proves that interactive retrieval with attribute prototype representation can converge fast in large face databases.}
}


@article{DBLP:journals/tifs/MurguiaSFNP21,
	author = {Carlos Murguia and
                  Iman Shames and
                  Farhad Farokhi and
                  Dragan Nesic and
                  H. Vincent Poor},
	title = {On Privacy of Dynamical Systems: An Optimal Probabilistic Mapping
                  Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2608--2620},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3055022},
	doi = {10.1109/TIFS.2021.3055022},
	timestamp = {Wed, 07 Apr 2021 16:01:12 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MurguiaSFNP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We address the problem of maximizing privacy of stochastic dynamical systems whose state information is released through quantized sensor data. In particular, we consider the setting where information about the system state is obtained using noisy sensor measurements. This data is quantized and transmitted to a (possibly untrustworthy) remote station through a public/unsecured communication network. We aim at keeping (part of) the state of the system private; however, because the network (and/or the remote station) might be unsecure, adversaries might have access to sensor data, which can be used to estimate the system state. To prevent such adversaries from obtaining an accurate state estimate, before transmission, we randomize quantized sensor data using additive random vectors, and send the corrupted data to the remote station instead. We design the joint probability distribution of these additive vectors (over a time window) to minimize the mutual information (our privacy metric) between some linear function of the system state (a desired private output) and the randomized sensor data for a desired level of distortion-how different quantized sensor measurements and distorted data are allowed to be. We pose the problem of synthesising the joint probability distribution of the additive vectors as a convex program subject to linear constraints. Simulation experiments are presented to illustrate our privacy scheme.}
}


@article{DBLP:journals/tifs/ChaiWZ21,
	author = {Yun Chai and
                  Youguo Wang and
                  Liang Zhu},
	title = {Information Sources Estimation in Time-Varying Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2621--2636},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050604},
	doi = {10.1109/TIFS.2021.3050604},
	timestamp = {Wed, 07 Apr 2021 16:01:12 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChaiWZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identifying information sources plays a significant role in network science and engineering. However, existing source identification approaches generally focus on static networks without considering the temporal features of networks. To this end, we comprehensively study the problem of identifying single and multiple information sources in time-varying networks. Specifically, we first represent the time-varying networks by time aggregated graph (TAG), and employ a microcosmic susceptible-infected-recovered (SIR) model to characterize the diffusion dynamics of each node. Second, in the case of single-source, we exploit a TAG-based reverse infection (RI-TAG) algorithm to specify a set of suspect nodes, which not only reduces the scope of seeking the source but also ensures the feasibility of path calculation. Then, a novel computationally efficient algorithm is proposed to estimate the information source and diffusion time simultaneously. Subsequently, in the case of multi-source, we design a multi-source estimation algorithm, which divides the set of infected nodes into various partitions, and then runs our single-source estimation algorithm in each partition. Moreover, we present an effective algorithm to estimate the number of sources. Finally, experimental results on various synthetic and empirical time-varying networks demonstrate the effectiveness of the proposed algorithms.}
}


@article{DBLP:journals/tifs/DuranteSV21,
	author = {Luca Durante and
                  Lucia Seno and
                  Adriano Valenzano},
	title = {A Formal Model and Technique to Redistribute the Packet Filtering
                  Load in Multiple Firewall Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2637--2651},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3057552},
	doi = {10.1109/TIFS.2021.3057552},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DuranteSV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The dynamic redistribution of filtering rules between firewalls, which are located in the same network, is a technical solution that can cope with temporary changes in the traffic load processed by the firewalls themselves. This paper presents a novel formal model for networks including multiple cascaded firewalls, that can be leveraged to enable the transfer of a set of rules from a firewall to its downstream neighbors when the changes in the input traffic profile suggest to do so. With respect to other solutions appeared in the literature a formal approach, besides providing unambiguous specifications and mathematical proofs of correctness, also enables the computation of theoretical bounds for the expected performance before the proposed scheme is actually deployed in the target network. The underlying mechanism, on which our approach is based, is the reduction of the average number of rules checked per packet in order to increase the packet processing rate. Our network model takes into account both the system topology and firewall characteristics. A suitable transformation algorithm is then introduced, which is able to preserve the security integrity of the network while moving rules between cascaded firewalls and allowing tangible performance improvements in terms of packets processing rate for a given traffic profile. Correctness of the proposed solution has been formally proven and validated by means of simulation. Performance figures have also been obtained by running the proposed algorithm in a laboratory experimental test-bed.}
}


@article{DBLP:journals/tifs/QinELL21,
	author = {Huafeng Qin and
                  Mounim A. El{-}Yacoubi and
                  Yantao Li and
                  Chong{-}Wen Liu},
	title = {Multi-Scale and Multi-Direction {GAN} for CNN-Based Single Palm-Vein
                  Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2652--2666},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3059340},
	doi = {10.1109/TIFS.2021.3059340},
	timestamp = {Fri, 26 Apr 2024 07:58:46 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QinELL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite recent advances of deep neural networks in hand vein identification, the existing solutions assume the availability of a large and rich set of training image samples. These solutions, therefore, still lack the capability to extract robust and discriminative hand-vein features from a single training image sample. To overcome this problem, we propose a single-sample-per-person (SSPP) palm-vein identification approach, where only a single sample per class is enrolled in the gallery set for training. Our approach, named MSMDGAN + CNN, consists of a multi-scale and multi-direction generative adversarial network (MSMDGAN) for data augmentation and a convolutional neural network (CNN) for palm-vein identification. First, a novel data augmentation approach, MSMDGAN, is developed to learn the internal distribution of patches in a single image. The proposed MSMDGAN consists of multiple fully convolutional GANs, each of which is responsible for learning the patch distribution within an image at a different scale and at a different direction. Second, given the resulting augmented data by MSMDGAN, we design a CNN for single sample palm-vein recognition. The experimental results on two public hand-vein databases demonstrate that MSMDGAN is able to generate realistic and diverse samples, which, in turn, improves the stability of the CNN. In terms of accuracy, MSMDGAN + CNN outperforms other representative approaches and achieves state-of-the-art recognition results.}
}


@article{DBLP:journals/tifs/YangWCYL21,
	author = {Can Yang and
                  Lan Wang and
                  Houwei Cao and
                  Qihu Yuan and
                  Yong Liu},
	title = {User Behavior Fingerprinting With Multi-Item-Sets and Its Application
                  in {IPTV} Viewer Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2667--2682},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3055638},
	doi = {10.1109/TIFS.2021.3055638},
	timestamp = {Tue, 07 May 2024 20:18:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangWCYL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User activities in cyberspace leave unique traces for user identification (UI). Individual users can be identified by their frequent activity items through statistical feature matching. However, such approaches face the data sparsity problem. In this paper, we propose to address this problem by multi-item-set fingerprinting that identifies users not only based on their frequent individual activity items, but also their frequent consecutive item sequences with different lengths. We also propose a new similarity metric between fingerprint vectors that combines the advantages of Jaccard distance and relative entropy distance. Furthermore, we develop a fusion decision scheme by consolidating matching candidates generated by different similarity metrics. It improves the precision at the price of extra rejection. Our proposed approaches can be used in both one-by-one matching and bipartite graph group matching. Through extensive experiments on three real user datasets, in particular a large-scale Internet Protocol Television (IPTV) viewer dataset, we demonstrate that the proposed approaches outperform the state-of-the-art methods. The average matching precision reaches 93.8% for a dataset of 1,000 users and 100% for a dataset of 100 users. This work is of significance for information forensics and raises a new challenge for human privacy protection in cyberspace.}
}


@article{DBLP:journals/tifs/LiuLY21,
	author = {Si{-}Qi Liu and
                  Xiangyuan Lan and
                  Pong C. Yuen},
	title = {Multi-Channel Remote Photoplethysmography Correspondence Feature for
                  3D Mask Face Presentation Attack Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2683--2696},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3050060},
	doi = {10.1109/TIFS.2021.3050060},
	timestamp = {Fri, 12 May 2023 15:00:49 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advancement of 3D printing technologies, 3D mask presentation attack becomes a critical challenge in face recognition. To tackle the 3D mask presentation attack detection (PAD), remote Photoplethysmography (rPPG) is employed as an intrinsic detection cue which is independent of the mask material and appearance quality. Although the effectiveness of existing rPPG-based methods has been verified, they may not be robust enough when rPPG signals are contaminated by noise. To identify the heartbeat information from the noisy raw rPPG signals, we propose a new 3D mask PAD feature, multi-channel rPPG correspondence feature (MCCFrPPG) with the global noise-aware template learning and verification framework. To further boost the discriminability, temporal variation of the rPPG signal is considered and extracted through the multi-channel time-frequency analysis scheme. This paper also extends HKBU-MARs V2 dataset with more customized high-quality masks and increases the number of videos by two times. Comprehensive experiments were performed on existing 3D mask datasets and the extended HKBU-MARs V2+, which totally covers 3 types of masks, 12 different light settings and 6 cameras. The results not only justify the effectiveness and robustness of the proposed MCCFrPPG on 3D mask attacks but also indicate its potential on handling the replay attack with camera motion and dim light.}
}


@article{DBLP:journals/tifs/FaeziYBF21,
	author = {Sina Faezi and
                  Rozhin Yasaei and
                  Anomadarshi Barua and
                  Mohammad Abdullah Al Faruque},
	title = {Brain-Inspired Golden Chip Free Hardware Trojan Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2697--2708},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3062989},
	doi = {10.1109/TIFS.2021.3062989},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FaeziYBF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since 2007, the use of side-channel measurements for detecting Hardware Trojan (HT) has been extensively studied. However, the majority of works either rely on a golden chip, or they rely on methods that are not robust against subtle acceptable changes that would occur over the life-cycle of an integrated circuit (IC). In this paper, we propose using a brain-inspired architecture called Hierarchical Temporal Memory (HTM) for HT detection. Similar to the human brain, our proposed solution is resilient against natural changes that might happen in the side-channel measurements while being able to accurately detect abnormal behavior of the chip when the HT gets triggered. We use a self-referencing method for HT detection, which eliminates the need for the golden chip. The effectiveness of our approach is evaluated using TrustHub benchmarks, which shows 92.20% detection accuracy on average.}
}


@article{DBLP:journals/tifs/AprilPyoneK21,
	author = {MaungMaung AprilPyone and
                  Hitoshi Kiya},
	title = {Block-Wise Image Transformation With Secret Key for Adversarially
                  Robust Defense},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2709--2723},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3062977},
	doi = {10.1109/TIFS.2021.3062977},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AprilPyoneK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a novel defensive transformation that enables us to maintain a high classification accuracy under the use of both clean images and adversarial examples for adversarially robust defense. The proposed transformation is a block-wise preprocessing technique with a secret key to input images. The proposed defense obfuscates gradients in the absence of the secret key unlike previously defeated obfuscating defenses. We developed three algorithms to realize the proposed transformation: Pixel Shuffling, Bit Flipping, and FFX Encryption. Experiments were carried out on the CIFAR-10 and ImageNet datasets by using both black-box and white-box attacks with various metrics including adaptive ones. The results show that the proposed defense achieves high accuracy close to that of using clean images even under adaptive attacks for the first time. In the best-case scenario, a model trained by using images transformed by FFX Encryption (block size of 4) yielded an accuracy of 92.30% on clean images and 91.48% under PGD attack with a noise distance of 8/255, which is close to the non-robust accuracy (95.45%) for the CIFAR-10 dataset, and it yielded an accuracy of 72.18% on clean images and 71.43% under the same attack, which is also close to the standard accuracy (73.70%) for the ImageNet dataset. Overall, all three proposed algorithms are demonstrated to outperform state-of-the-art defenses including adversarial training whether or not a model is under attack.}
}


@article{DBLP:journals/tifs/Lamba21,
	author = {Subir Singh Lamba},
	title = {Comments on "Random Distance Method for Generating Unimodal and Multimodal
                  Cancelable Biometric Features"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2724--2726},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3062980},
	doi = {10.1109/TIFS.2021.3062980},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/Lamba21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article points out the fallacies in the theory and its implementation proposed by Kaur and Khanna. They have set out a cancelable biometric-based template protection method to address the security and privacy concerns emerging from the use of biometric systems. There are three major issues associated with the method proposed in their study. The first issue relates to the mathematical fallacy in the proof of the random distance method. The second issue concerns the claim of dimension-reduction by 50%, despite the fact that RDM does not preserve inter- and intra-user variations. The third issue is in salting the feature vectors using the OR operation between the feature vectors and random grid (RG), which is incorrect. As it will result in revealing partial information only and will not increase entropy. Furthermore, they have stated that their approach results in noninvertibility using the median filtering. However, its implementation is flawed.}
}


@article{DBLP:journals/tifs/ShenXX21,
	author = {Zhexian Shen and
                  Kui Xu and
                  Xiaochen Xia},
	title = {Beam-Domain Anti-Jamming Transmission for Downlink Massive {MIMO}
                  Systems: {A} Stackelberg Game Perspective},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2727--2742},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3063632},
	doi = {10.1109/TIFS.2021.3063632},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShenXX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, beam-domain (BD) anti-jamming transmission in a downlink massive multiple-input multiple-output (MIMO) system is investigated. A smart jammer with multiple antennas attempts to interfere with the signal reception of users with the desired energy efficiency (EE), whereas a base station (BS) tries to minimize the transmission cost while ensuring uninterrupted communication. A Bayesian Stackelberg game between the BS and jammer, where the jammer is the follower and the BS acts as the leader, is modeled. In the follower subgame, the optimal jamming precoding with a closed-form power solution is introduced. The optimal jamming power is proportional to the transmission power in the downlink, and thus, for the BS, the strategy of suppressing malicious attacks by increasing the transmission power fails. In the leader subgame, generalized zero-forcing (ZF), whose closed-form power solution constitutes the unique Stackelberg equilibrium (SE) with that of the jammer, is found to be the optimal anti-jamming precoding for robust transmission. The results show that there always exists a precoding solution for the BS that ensures reliable transmission when the SE is obtained. A proper increase in the minimum signal-to-interference-and-noise ratio (SINR) threshold or the BD channel approximation error helps the BS save power during the resistance against the jammer. Then, a simplified power solution without the instantaneous channel state information (CSI) of jamming channels is further introduced for practical implementation. Numerical results are provided to verify the proposed solutions.}
}


@article{DBLP:journals/tifs/ZivariFardBN21,
	author = {Hassan ZivariFard and
                  Matthieu R. Bloch and
                  Aria Nosratinia},
	title = {Two-Multicast Channel With Confidential Messages},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2743--2758},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3055031},
	doi = {10.1109/TIFS.2021.3055031},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZivariFardBN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Motivated in part by the problem of secure multicast distributed storage, we analyze secrecy rates for a channel in which two transmitters simultaneously multicast to two receivers in the presence of an eavesdropper. Achievable rates are calculated via extensions of a technique due to Chia and El Gamal and the method of output statistics of random binning. Outer bounds are derived for both the degraded and non-degraded versions of the channel, and examples are provided in which the inner and outer bounds meet. The inner bounds recover known results for the multiple-access wiretap channel, broadcast channel with confidential messages, and the compound MAC channel. An auxiliary result is also produced that derives an inner bound on the minimal randomness necessary to achieve secrecy in multiple-access wiretap channels.}
}


@article{DBLP:journals/tifs/LiuTWLLGL21,
	author = {Ajian Liu and
                  Zichang Tan and
                  Jun Wan and
                  Yanyan Liang and
                  Zhen Lei and
                  Guodong Guo and
                  Stan Z. Li},
	title = {Face Anti-Spoofing via Adversarial Cross-Modality Translation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2759--2772},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3065495},
	doi = {10.1109/TIFS.2021.3065495},
	timestamp = {Tue, 12 Apr 2022 15:00:36 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuTWLLGL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face Presentation Attack Detection (PAD) approaches based on multi-modal data have been attracted increasingly by the research community. However, they require multi-modal face data consistently involved in both the training and testing phases. It would severely limit the applicability due to the most Face Anti-spoofing (FAS) systems are only equipped with Visible (VIS) imaging devices, i.e., RGB cameras. Therefore, how to use other modality (i.e., Near-Infrared (NIR)) to assist the performance improvement of VIS-based PAD is significant for FAS. In this work, we first discuss the big gap of performances among different modalities even though the same backbone network is applied. Then, we propose a novel Cross-modal Auxiliary (CMA) framework for the VIS-based FAS task. The main trait of CMA is that the performance can be greatly improved with the help of other modality while no other modality is required in the testing stage. The proposed CMA consists of a Modality Translation Network (MT-Net) and a Modality Assistance Network (MA-Net). The former aims to close the visible gap between different modalities via a generative model that maps inputs from one modality (i.e., RGB) to another (i.e., NIR). The latter focuses on how to use the translated modality (i.e., target modality) and RGB modality (i.e., source modality) together to train a discriminative PAD model. Extensive experiments are conducted to demonstrate that the proposed framework can push the state-of-the-art (SOTA) performances on both multi-modal datasets (i.e., CASIA-SURF, CeFA, and WMCA) and RGB-based datasets (i.e., OULU-NPU, and SiW).}
}


@article{DBLP:journals/tifs/LinSQ21,
	author = {Xi Jun Lin and
                  Lin Sun and
                  Haipeng Qu},
	title = {Cryptanalysis of an Anonymous and Traceable Group Data Sharing in
                  Cloud Computing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2773--2775},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3065505},
	doi = {10.1109/TIFS.2021.3065505},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LinSQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In cloud environments, group data sharing has become a hot topic in recent years. How to share data securely and efficiently in cloud environments is an urgent problem to be solved. Recently, an anonymous and traceable group data sharing scheme was proposed by Shen et al. to address this issue. They constructed their scheme using a group signature scheme as the building block. In this comment, we discuss the security of their group signature scheme and point out that it does not achieve the anonymity which they claimed and give a corresponding attack.}
}


@article{DBLP:journals/tifs/LiuLST21,
	author = {Yunfan Liu and
                  Qi Li and
                  Zhenan Sun and
                  Tieniu Tan},
	title = {A\({}^{\mbox{3}}\)GAN: An Attribute-Aware Attentive Generative Adversarial
                  Network for Face Aging},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2776--2790},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3065499},
	doi = {10.1109/TIFS.2021.3065499},
	timestamp = {Fri, 24 May 2024 09:36:42 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLST21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face aging has received significant research attention in recent years. Although great progress has been achieved with the success of Generative Adversarial Networks (GANs) in synthesizing realistic images, most existing GAN-based face aging methods have two main problems: 1) unnatural changes of high-level semantic information due to the insufficient consideration of prior knowledge of input faces, and 2) distortions of low-level image content (e.g. modifications in age-irrelevant regions). In this article, we introduce A 3 GAN, an Attribute-Aware Attentive face aging model to address the above issues. Facial attribute vectors are regarded as the conditional information and embedded into both the generator and discriminator, encouraging synthesized faces to be faithful to attributes of corresponding inputs. To improve the visual fidelity of generation results, we leverage the attention mechanism to restrict modifications to age-related areas and preserve image details. Unlike previous works with attention modules, we introduce face parsing maps to help the generator distinguish image regions of interest and suppress attention activation elsewhere. Moreover, the wavelet packet transform is employed to capture textural features at multiple scales in the frequency space. Extensive experimental results demonstrate the effectiveness of our model in synthesizing photo-realistic aged face images and achieving state-of-the-art performance on popular datasets.}
}


@article{DBLP:journals/tifs/LiuW21,
	author = {Zhaoxi Liu and
                  Lingfeng Wang},
	title = {FlipIt Game Model-Based Defense Strategy Against Cyberattacks on {SCADA}
                  Systems Considering Insider Assistance},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2791--2804},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3065504},
	doi = {10.1109/TIFS.2021.3065504},
	timestamp = {Mon, 04 Oct 2021 08:33:42 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The industrial internet of things (IIoT) is emerging as a global trend to dramatically enhance the intelligence and efficiency of the industries in recent years. With the emphasis on data communication by IIoT, cyber vulnerabilities are introduced at the same time. As a key subsystem of the industrial automation systems, the supervisory control and data acquisition (SCADA) system is becoming one of the primary targets for cyberattacks in the IIoT paradigm. In this paper, the semi-Markov process (SMP) is employed to model and evaluate the cyberattacks against the SCADA systems considering the insider assistance. Based on the SMP model, the probability distribution of the time-to-compromise the system of the attacks is derived with the Monte Carlo simulation (MCS). Then, a FlipIt game model is developed to investigate the defense and attack strategies of the defender and attacker, and analyze the impacts of the insider assistance. Case studies were carried out to verify the proposed model. The results of the case studies show that the insider assistance will improve the payoff of the attacker and increase the defense action frequency of the system defender. With a high enough defense action frequency, the defender can force the attacker to drop out and eliminate the attack actions.}
}


@article{DBLP:journals/tifs/GaoWJZXJ21,
	author = {Yang Gao and
                  Wei Wang and
                  Yincheng Jin and
                  Chi Zhou and
                  Wenyao Xu and
                  Zhanpeng Jin},
	title = {ThermoTag: {A} Hidden {ID} of 3D Printers for Fingerprinting and Watermarking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2805--2820},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3065225},
	doi = {10.1109/TIFS.2021.3065225},
	timestamp = {Wed, 08 Feb 2023 16:50:48 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GaoWJZXJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To address the increasing challenges of counterfeit detection and IP protection for 3D printing, we propose that every 3D printer holds unique fingerprinting features characterized by the thermodynamic properties of the extruder hot-end and can be used as a new way of 3D watermarking. We prove that these physical fingerprints resulting from manufacturing imperfections and system variations exhibit distinct heating responses, namely “ThermoTag,” which can be represented as the distinguishable thermodynamic processes and, ultimately, the temperature readings during the preheating process. Experimental results show that, by only changing the hot-ends of the same model on the same 3D printer, we can achieve about 92% identification accuracy amongst 45 hot-ends. The permanence and robustness of ThermoTag for the same hot-end were examined, throughout a period of one month with hundreds of trials under different environmental temperature settings. Leveraging the hidden ThermoTag, an example of watermarking scheme in 3D printing is presented and evaluated.}
}


@article{DBLP:journals/tifs/JungL21,
	author = {Haejoon Jung and
                  In{-}Ho Lee},
	title = {Comments on "Fixed Region Beamforming Using Frequency Diverse Subarray
                  for Secure mmWave Wireless Communications"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2821--2822},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3066296},
	doi = {10.1109/TIFS.2021.3066296},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JungL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the above article, Hong et al. proposed a frequency region beamforming scheme exploiting frequency diverse subarray. We found that there is a mathematical flaw in precoding vector normalization in their sidelobe randomization scheme called the inverted subarray subset technique (ISST). We show that it is not only a matter of how to define and interpret the array factor, but it leads to the wrong performance optimization and misoperation of their own proposed scheme, which may cause detrimental security risks. Furthermore, to avoid any false conclusions in the future study caused by the irrational normalization, we also present the related techniques and their correct normalization.}
}


@article{DBLP:journals/tifs/WangTH21,
	author = {Shen Wang and
                  Ehsan Toreini and
                  Feng Hao},
	title = {Anti-Counterfeiting for Polymer Banknotes Based on Polymer Substrate
                  Fingerprinting},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2823--2835},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3067440},
	doi = {10.1109/TIFS.2021.3067440},
	timestamp = {Thu, 03 Nov 2022 17:11:01 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangTH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Polymer banknotes are the trend for printed currency and have been adopted by more than fifty countries worldwide. However, over the past years, the quantity of polymer counterfeits has been increasing, so has the quality of counterfeits. This shows that the initial advantage of bringing a new polymer technology to fight against counterfeiting is reducing. To maintain one step ahead of counterfeiters, we propose a novel anti-counterfeiting technique called Polymer Substrate Fingerprinting (PSF). Our technique is built based on the observation that the opacity coating, a critical step during the production of polymer notes, is a stochastic manufacturing process, leaving uneven thickness in the coating layer and the random dispersion of impurities from the ink. The imperfections in the coating layer result in random translucent patterns when a polymer banknote is back-lit by a light source. We show these patterns can be reliably captured by a commodity negative-film scanner and processed into a compact fingerprint to uniquely identify each banknote. Using an extensive dataset of 6,200 sample images collected from 340 UK banknotes, we show that our method can reliably authenticate banknotes, and is robust against rough daily handling of banknotes. Furthermore, we show the extracted fingerprints contain around 900 bits of entropy, which makes it extremely scalable to identify every polymer note circulated globally. As compared with previous or existing anti-counterfeiting mechanisms for banknotes, our method has a distinctive advantage: it ensures that even in the extreme case when counterfeiters have procured the same printing equipment and ink as used by a legitimate government, counterfeiting banknotes remains infeasible because of the difficulty to replicate a stochastic manufacturing process.}
}


@article{DBLP:journals/tifs/DesmedtMS21,
	author = {Yvo Desmedt and
                  Songbao Mo and
                  Arkadii M. Slinko},
	title = {Framing in Secret Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2836--2842},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3067468},
	doi = {10.1109/TIFS.2021.3067468},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DesmedtMS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secret sharing, a well-known cryptographic technique, introduced 40 years ago as a private and reliable variant of classical storage, has now become a major cryptographic primitive with numerous real-world applications. In this paper we consider the digital forensics aspects of secret sharing. We investigate the problem of framing which occurs when a coalition is able to calculate the share of a participant who does not belong to it. In the extreme case one authorized coalition can calculate shares of another authorized coalition and use the secret in some way blaming another authorized coalition for their action. In this context seniority plays an important role. We define seniority, which comes natural in the context of hierarchical access structures. Roughly speaking, our work shows that in an ideal secret sharing scheme an authorized coalition cannot frame participants who are less senior than all members of the coalition and is able to frame a participant who is more senior than at least one pivotal member of the coalition. We show that for any monotone access structure there exists a (non-ideal) frameproof secret sharing scheme.}
}


@article{DBLP:journals/tifs/SongLKJ21,
	author = {Byungkyu Song and
                  Sehee Lim and
                  Seung{-}Hyuk Kang and
                  Seong{-}Ook Jung},
	title = {Environmental-Variation-Tolerant Magnetic Tunnel Junction-Based Physical
                  Unclonable Function Cell With Auto Write-Back Technique},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2843--2853},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3067173},
	doi = {10.1109/TIFS.2021.3067173},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SongLKJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, with the increase in popularity of Internet of Things (IoT) devices, cryptographic protection techniques have become necessary for high-security applications. In general, IoT devices have strict power and area constraints. Thus, use of a physical unclonable function (PUF), which can generate a secret key at low cost, can be advantageous for high-security IoT devices. This paper presents a novel environmental-variation-tolerant (EVT) magnetic tunnel junction (MTJ)-based PUF that has a small area, high randomness, and low bit error rate (BER) compared to previous PUFs. The simulation results obtained using industry-compatible 65-nm model parameters indicate that the proposed PUF exhibits an inter-chip Hamming distance of 0.4901 and entropy of 0.9997, which proves the randomness of the PUF response. In addition, the proposed PUF exhibits the lowest BER across a wide voltage range (0.9 V-1.3 V) and temperature range (-25 °C - 75 °C) compared with previous PUFs.}
}


@article{DBLP:journals/tifs/HongGJH21,
	author = {Yuanquan Hong and
                  Hui Gao and
                  Xiaojun Jing and
                  Yuan He},
	title = {Rebuttal to "Comments on 'Fixed Region Beamforming Using Frequency
                  Diverse Subarray for Secure MmWave Wireless Communications"'},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2854--2855},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3067204},
	doi = {10.1109/TIFS.2021.3067204},
	timestamp = {Fri, 16 Sep 2022 15:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HongGJH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Concerns have been raised about our recently published article on the fixed region beamforming using frequency diverse subarray for secure mmWave wireless communications. In a comment, the authors thought our precoding vector normalization method of the sidelobe randomization scheme has a flaw and proposed a non-physical-layer-security-oriented (non-PLS-oriented) normalization method by keeping the norm of the steering vector as a unit. However, we believe our PLS-oriented normalization method of the transmit beamforming vector is correct and reasonable from the PLS perspective, i.e., we hope to keep the target use's beampattern gain unit. In this rebuttal, we further clarify and justify our scheme to show its correctness. In addition, we also present a generalized normalization method to compare our proposed PLS-oriented scheme and the non-PLS-oriented scheme in the comment to offer useful insights.}
}


@article{DBLP:journals/tifs/KumarNSM21,
	author = {Mari Ganesh Kumar and
                  Shrikanth Narayanan and
                  Mriganka Sur and
                  Hema A. Murthy},
	title = {Evidence of Task-Independent Person-Specific Signatures in {EEG} Using
                  Subspace Techniques},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2856--2871},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3067998},
	doi = {10.1109/TIFS.2021.3067998},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KumarNSM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Electroencephalography (EEG) signals are promising as alternatives to other biometrics owing to their protection against spoofing. Previous studies have focused on capturing individual variability by analyzing task/condition-specific EEG. This work attempts to model biometric signatures independent of task/condition by normalizing the associated variance. Toward this goal, the paper extends ideas from subspace-based text-independent speaker recognition and proposes novel modifications for modeling multi-channel EEG data. The proposed techniques assume that biometric information is present in the entire EEG signal and accumulate statistics across time in a high dimensional space. These high dimensional statistics are then projected to a lower dimensional space where the biometric information is preserved. The lower dimensional embeddings obtained using the proposed approach are shown to be task-independent. The best subspace system identifies individuals with accuracies of 86.4% and 35.9% on datasets with 30 and 920 subjects, respectively, using just nine EEG channels. The paper also provides insights into the subspace model's scalability to unseen tasks and individuals during training and the number of channels needed for subspace modeling.}
}


@article{DBLP:journals/tifs/QianQKHSH21,
	author = {Yunhan Qian and
                  Jie Qi and
                  Xiaoyan Kuai and
                  Guangjie Han and
                  Haixin Sun and
                  Shaohua Hong},
	title = {Specific Emitter Identification Based on Multi-Level Sparse Representation
                  in Automatic Identification System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2872--2884},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3068010},
	doi = {10.1109/TIFS.2021.3068010},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QianQKHSH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Illegally forged signals in automatic identification system (AIS) pose a threat to maritime traffic safety management. In this paper, a multi-level sparse representation based identification (MSRI) algorithm is proposed for specific emitter identification (SEI) in the AIS. The MSRI innovatively combines neural networks with sparse representation based classification (SRC). Channel attention mechanism is introduced to a multi-scale convolutional neural network (CNN) for extracting hidden features in the signal. These extracted features are divided into shallow and deep features according to the depth of the network layer they are extracted from. The original AIS signals and the two-level features are spliced together to form a multi-level dictionary. Subsequently, a sparse representation based identification is performed on the decorrelated multi-level dictionary using the principal components analysis (PCA) method. The proposed MSRI is evaluated on a dataset composed of real-world AIS signals, and compared with the state-of-the-art identification algorithms. The evaluation is based on several factors including computational complexity, number of training samples, and number of emitters. Numerical results indicate that the proposed algorithm can identify emitters with higher accuracy and requires lower training time compared to other methods. Given more than 15 training samples at each emitter, the MSRI can identify nine emitters with an accuracy higher than 90%.}
}


@article{DBLP:journals/tifs/LiLD21,
	author = {Tao Li and
                  Yongzhao Li and
                  Octavia A. Dobre},
	title = {Modulation Classification Based on Fourth-Order Cumulants of Superposed
                  Signal in {NOMA} Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2885--2897},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3068006},
	doi = {10.1109/TIFS.2021.3068006},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiLD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the automatic modulation classification in a non-orthogonal multiple access system. To mitigate the effect of interference, a likelihood-based algorithm and a fourth-order cumulant-based algorithm are proposed. Different from the maximum likelihood classifier for a single signal without interference, a likelihood function of the far and near users' signals is derived. Then, a marginal probability for the far user is obtained by using the Bayesian formula. Hence, the modulation type can be determined by maximizing the marginal probability. The high computational complexity of the likelihood-based algorithm renders it impractical; accordingly, it serves as a theoretical performance bound. On the other hand, we construct a feature vector through the estimated fourth-order cumulants of the received signal including the superposed signal and noise. For each modulation pair, using the mean and covariance matrix of the estimated feature vector, its probability density function can be obtained. Then, the key is to calculate the mean and covariance matrix of the estimated feature vector. To solve this problem, the moments of the superposed signal are derived. Therefore, modulation classification can be performed by maximizing the probability density function. Extensive simulations verify that the two proposed algorithms perform well under a wide range of signal-to-noise ratios and observation lengths.}
}


@article{DBLP:journals/tifs/AhujaMB21,
	author = {Bhawna Ahuja and
                  Deepak Mishra and
                  Ranjan Bose},
	title = {Fair Subcarrier Allocation for Securing {OFDMA} in IoT Against Full-Duplex
                  Hybrid Attacker},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2898--2911},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3067157},
	doi = {10.1109/TIFS.2021.3067157},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AhujaMB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure communication with low computational resources is a critical issue in the Internet-of-Things (IoT) implementations. It is more challenging in the presence of hybrid adversary enabled with full-duplex (FD) capability to perform eavesdropping and jamming simultaneously. In this work we aim to address this issue through optimal subcarrier allocation towards combating the FD hybrid attacker. We begin with secrecy performance analysis in a multi-user IoT system considering statistical channel state information only of all attacker links. Novel analytical expression for the exact intercept probability is derived and a closed-form approximation is also provided. We further propose an optimisation framework for fair subcarrier allocation with a novel objective of minimising maximum intercept probability among multiple users. Considering the proposed optimisation framework as a non-convex combinatorial, we propose a low-complexity sub-optimal solution by leveraging the integer linear program (ILP) structure of the problem. To reduce the complexity further, the original problem is mapped to the assignment model and solved by exploiting its special structure with graph theory tools providing an optimal solution in polynomial time. Comprehensive investigations, conducted to verify the analysis and quantify the secrecy performance, demonstrate that proposed optimal solutions yield significant enhancement in secrecy performance over relevant schemes.}
}


@article{DBLP:journals/tifs/XiongZYH21,
	author = {Lizhi Xiong and
                  Xinwei Zhong and
                  Ching{-}Nung Yang and
                  Xiao Han},
	title = {Transform Domain-Based Invertible and Lossless Secret Image Sharing
                  With Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2912--2925},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3065794},
	doi = {10.1109/TIFS.2021.3065794},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XiongZYH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secret Image Sharing (SIS) as a secure data sharing scheme in multiple cover images, has become an increasing researchers' concern. In traditional SIS, the cover image can't be recovered losslessly. The distorted cover images would reduce the practicability of the scheme, especially in medical and military images. The lossless recovery of cover images is required since all details of these images are very critical. In current Invertible SIS (ISIS), the secret image and the cover image may not be reconstructed losslessly. In addition, the authentication capability, visual quality of the stego cover image and embedding rate are limited in spatial domain-based ISIS. As an important carrier, the binary cover image is desired in real applications. Therefore, this paper proposes Transform domain-based Invertible and Lossless Secret Image Sharing schemes with Authentication (T-ILSISA), namely Integer Wavelet Transform-based ILSISA (IWT-ILSISA) and Binarization Transform-based ILSISA (BT-ILSISA) respectively. In (k,n) threshold IWT-ILSISA, the pixels of secret image and the data of cover image are regarded as the coefficients of the (k-1) degree polynomial. The values of generated share are embedded into IWT domain of the cover image. In BT-ILSISA, many different cover images are applied. The generated shares are transformed to the meaningful images since noise-like shares are easy to attract the attacker's attention, are suspected to censors and are difficult for identification and management. In the two schemes, the original secret image and the cover image can be recovered losslessly. The experimental results and theoretical analysis demonstrate that the performances of IWT-ILSISA are better than other similar schemes in the terms of embedding capacity, authentication capability and visual quality of the stego cover image. The BT-ILSISA has a lower computational complexity of the recovery.}
}


@article{DBLP:journals/tifs/TranH21,
	author = {Quang Nhat Tran and
                  Jiankun Hu},
	title = {A Multi-Filter Fingerprint Matching Framework for Cancelable Template
                  Design},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2926--2940},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3069170},
	doi = {10.1109/TIFS.2021.3069170},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TranH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the ubiquity in the use of biometrics due to its many advantages against traditional methods such as password or token, the emerging cancelable biometric methods, which are designed to protect the biometrics are still exposed to certain threats. Attack via Record Multiplicity (ARM) is one of those. In this paper, we propose a novel framework that possesses two layers of authentication to improve the matching performance of a fingerprint authentication system in the cancelable template setting. In addition, a multi-filter fingerprint matching scheme is devised to deal more effectively with low-quality fingerprint images. Two techniques that are capable of defending against the heinous ARM are also introduced. Security analysis on the system's capability against the hill-climb attack and pre-image attack is also provided. The proposed scheme has been evaluated over public datasets FVC2002-DB1, FVC2002-DB2, FVC2002-DB3, and FVC2004-DB2. It has achieved the best result compared with the state-of-art methods. The source code for this framework is available on demand.}
}


@article{DBLP:journals/tifs/HanKK21,
	author = {Mee Lan Han and
                  Byung Il Kwak and
                  Huy Kang Kim},
	title = {Event-Triggered Interval-Based Anomaly Detection and Attack Identification
                  Methods for an In-Vehicle Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2941--2956},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3069171},
	doi = {10.1109/TIFS.2021.3069171},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HanKK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicle communication technology has been steadily progressing alongside the convergence of the in-vehicle network (IVN) and wireless communication technology. The communication with various external networks further reinforces the connectivity between the inside and outside of a vehicle. However, this bears risks of malicious packet attacks on computer-assisted mechanical mechanisms that are capable of hijacking the vehicle's functions. The present study proposes a method to detect and identify abnormalities in vehicular networks based on the periodic event-triggered interval of the controller area network (CAN) messages. To this end, we first define four attack scenarios and then extract normal and abnormal driving data corresponding to these scenarios. Next, we analyze the CAN ID's event-triggered interval and measure statistical moments depending on the defined time-window. Finally, we conduct extensive evaluations of the proposed methods' performance by considering different attack scenarios and three types of machine learning models. The results demonstrate that the proposed method can effectively detect an abnormality in the IVN, with up to 99% accuracy. Our results suggest that when tree-based machine learning models are used as the classifier, the proposed method of attack identification can achieve more than 94% accuracy.}
}


@article{DBLP:journals/tifs/RodriguesSLRD21,
	author = {Caroline Mazini Rodrigues and
                  Aurea Soriano{-}Vargas and
                  Bahram Lavi and
                  Anderson Rocha and
                  Zanoni Dias},
	title = {Manifold Learning for Real-World Event Understanding},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2957--2972},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3070431},
	doi = {10.1109/TIFS.2021.3070431},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/RodriguesSLRD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information coming from social media is vital to the understanding of the dynamics involved in multiple events such as terrorist attacks and natural disasters. With the spread and popularization of cameras and the means to share content through social networks, an event can be followed through many different lenses and vantage points. However, social media data present numerous challenges, and frequently it is necessary a great deal of data cleaning and filtering techniques to separate what is related to the depicted event from contents otherwise useless. In a previous effort of ours, we decomposed events into representative components aiming at describing vital details of an event to characterize its defining moments. However, the lack of minimal supervision to guide the combination of representative components somehow limited the performance of the method. In this paper, we extend upon our prior work and present a learning-from-data method for dynamically learning the contribution of different components for a more effective event representation. The method relies upon just a few training samples (few-shot learning), which can be easily provided by an investigator. The obtained results on real-world datasets show the effectiveness of the proposed ideas.}
}


@article{DBLP:journals/tifs/WuZ21,
	author = {Haiwei Wu and
                  Jiantao Zhou},
	title = {Privacy Leakage of {SIFT} Features via Deep Generative Model Based
                  Image Reconstruction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2973--2985},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3070427},
	doi = {10.1109/TIFS.2021.3070427},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many practical applications, e.g., content based image retrieval and object recognition, heavily rely on the local features extracted from the query image. As these local features are usually exposed to untrustworthy parties, the privacy leakage problem of image local features has received increasing attention in recent years. In this work, we thoroughly evaluate the privacy leakage of Scale Invariant Feature Transform (SIFT), which is one of the most widely-used image local features. We first consider the case that the adversary can fully access the SIFT features, i.e., both the SIFT descriptors and the coordinates are available. We propose a novel end-to-end, coarse-to-fine deep generative model for reconstructing the latent image from its SIFT features. The designed deep generative model consists of two networks, where the first one attempts to learn the structural information of the latent image by transforming from SIFT features to Local Binary Pattern (LBP) features, while the second one aims to reconstruct the pixel values guided by the learned LBP. Compared with the state-of-the-art algorithms, the proposed deep generative model produces much improved reconstructed results over three public datasets. Furthermore, we address more challenging cases that only partial SIFT features (either SIFT descriptors or coordinates) are accessible to the adversary. It is shown that, if the adversary can only have access to the SIFT descriptors while not their coordinates, then the modest success of reconstructing the latent image might be achieved for highly-structured images (e.g., faces) and probably would fail in general settings. In addition, the latent image usually can be reconstructed with acceptable quality solely from the SIFT coordinates. Our results would suggest that the privacy leakage problem can be avoided to a certain extent if the SIFT coordinates can be well protected.}
}


@article{DBLP:journals/tifs/ZhuangLTLH21,
	author = {Peiyu Zhuang and
                  Haodong Li and
                  Shunquan Tan and
                  Bin Li and
                  Jiwu Huang},
	title = {Image Tampering Localization Using a Dense Fully Convolutional Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {2986--2999},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3070444},
	doi = {10.1109/TIFS.2021.3070444},
	timestamp = {Tue, 30 Jan 2024 17:50:18 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuangLTLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of powerful image editing software has substantially facilitated digital image tampering, leading to many security issues. Hence, it is urgent to identify tampered images and localize tampered regions. Although much attention has been devoted to image tampering localization in recent years, it is still challenging to perform tampering localization in practical forensic applications. The reasons include the difficulty of learning discriminative representations of tampering traces and the lack of realistic tampered images for training. Since Photoshop is widely used for image tampering in practice, this paper attempts to address the issue of tampering localization by focusing on the detection of commonly used editing tools and operations in Photoshop. In order to well capture tampering traces, a fully convolutional encoder-decoder architecture is designed, where dense connections and dilated convolutions are adopted for achieving better localization performance. In order to effectively train a model in the case of insufficient tampered images, we design a training data generation strategy by resorting to Photoshop scripting, which can imitate human manipulations and generate large-scale training samples. Extensive experimental results show that the proposed approach outperforms state-of-the-art competitors when the model is trained with only generated images or fine-tuned with a small amount of realistic tampered images. The proposed method also has good robustness against some common post-processing operations.}
}


@article{DBLP:journals/tifs/HeXW21,
	author = {Wenguang He and
                  Gangqiang Xiong and
                  Yaomin Wang},
	title = {Reversible Data Hiding Based on Adaptive Multiple Histograms Modification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3000--3012},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3069173},
	doi = {10.1109/TIFS.2021.3069173},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HeXW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pixel value ordering prediction has been verified as an effective mechanism to exploit image redundancy for reversible data hiding (RDH) and numerous extensions have been devised. However, their performance is still unsatisfactory since the error modification is generally fixed and independent of image content. In this paper, a new RDH scheme is proposed by incorporating pixel distance to realize adaptive multiple histograms modification (AMHM). During exploiting the correlation between the largest/smallest pixel and any other one in the scope of pixel block, we propose to process every two correlated pixels successively following the ascending order of their distance. Specifically, the generated errors with a given distance are collected and verified. If they are all shiftable errors, the follow-up errors would be collected into the next sub-histogram. In this way, a histogram sequence is adaptively generated such that different modification mechanisms can be taken for different sub-histograms to achieve adaptive embedding. Finally, AMHM for conventional prediction-error expansion (PEE) and AMHM for 2D PEE have been both realized in this paper. Experimental results show that AMHM is of great significance to better exploit pixel correlation and the proposed scheme outperforms a series of the latest schemes.}
}


@article{DBLP:journals/tifs/KimGK21,
	author = {Yongjune Kim and
                  Cyril Guyot and
                  Young{-}Sik Kim},
	title = {On the Efficient Estimation of Min-Entropy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3013--3025},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3070424},
	doi = {10.1109/TIFS.2021.3070424},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KimGK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The min-entropy is a widely used metric to quantify the randomness of generated random numbers in cryptographic applications; it measures the difficulty of guessing the most likely output. An important min-entropy estimator is the compression estimator of NIST Special Publication (SP) 800-90B, which relies on Maurer’s universal test. In this paper, we propose two kinds of min-entropy estimators to improve computational complexity and estimation accuracy by leveraging two variations of Maurer’s test: Coron’s test (for Shannon entropy) and Kim’s test (for Rényi entropy). First, we propose a min-entropy estimator based on Coron’s test. It is computationally more efficient than the compression estimator while maintaining the estimation accuracy. The secondly proposed estimator relies on Kim’s test that computes the Rényi entropy. This estimator improves estimation accuracy as well as computational complexity. We analytically characterize the bias-variance tradeoff, which depends on the order of Rényi entropy. By taking into account this tradeoff, we observe that the order of two is a proper assignment and focus on the min-entropy estimation based on the collision entropy (i.e., Rényi entropy of order two). The min-entropy estimation from the collision entropy can be described by a closed-form solution, whereas both the compression estimator and the proposed estimator based on Coron’s test do not have closed-form solutions. By leveraging the closed-form solution, we also propose a lightweight estimator that processes data samples in an online manner. Numerical evaluations demonstrate that the first proposed estimator achieves the same accuracy as the compression estimator with much less computation. The proposed estimator based on the collision entropy can even improve the accuracy and reduce the computational complexity.}
}


@article{DBLP:journals/tifs/MaZLLAZL21,
	author = {Shuai Ma and
                  Yunqi Zhang and
                  Hang Li and
                  Songtao Lu and
                  Naofal Al{-}Dhahir and
                  Sha Zhang and
                  Shiyin Li},
	title = {Robust Beamforming Design for Covert Communications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3026--3038},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3071602},
	doi = {10.1109/TIFS.2021.3071602},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MaZLLAZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider a common unicast beamforming network where Alice utilizes the communication to Carol as a cover and covertly transmits a message to Bob without being recognized by Willie. We investigate the beamformer design of Alice to maximize the covert rate to Bob when Alice has either perfect or imperfect knowledge about Willie's channel state information (WCSI). For the perfect WCSI case, the problem is formulated under the perfect covert constraint, and we develop a covert beamformer by applying semidefinite relaxation and the bisection method. Then, to reduce the computational complexity, we further propose a zero-forcing beamformer design with a single iteration processing. For the case of the imperfect WCSI, the robust beamformer is developed based on a relaxation and restriction approach by utilizing the property of Kullback-Leibler divergence. Furthermore, we derive the optimal decision threshold of Willie, and analyze the false alarm and the missed detection probabilities in this case. Finally, the performance of the proposed beamformer designs is evaluated through numerical experiments.}
}


@article{DBLP:journals/tifs/LiuW21a,
	author = {Runze Liu and
                  Chau{-}Wai Wong},
	title = {On Microstructure Estimation Using Flatbed Scanners for Paper Surface-Based
                  Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3039--3053},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3071585},
	doi = {10.1109/TIFS.2021.3071585},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuW21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Paper surfaces under the microscopic view are observed to be formed by intertwisted wood fibers. Such structures of paper surfaces are unique from one location to another and are almost impossible to duplicate. Previous work used microscopic surface normals to characterize such intrinsic structures as a “fingerprint” of paper for security and forensic applications. In this work, we examine several key research questions of feature extraction in both scientific and engineering aspects to facilitate the deployment of paper surface-based authentication when flatbed scanners are used as the acquisition device. We analytically show that, under the unique optical setup of flatbed scanners, the specular reflection does not play a role in norm map estimation. We verify, using a larger dataset than prior work, that the scanner-acquired norm maps, although blurred, are consistent with those measured by confocal microscopes. We confirm that, when choosing an authentication feature, high spatial-frequency subbands of the heightmap are more powerful than the norm map. Finally, we show that it is possible to empirically calculate the physical dimensions of the paper patch needed to achieve a certain authentication performance in equal error rate (EER). We analytically show that log(EER) is decreasing linearly in the edge length of a paper patch.}
}


@article{DBLP:journals/tifs/TandoganS21,
	author = {Sinan E. Tandogan and
                  Husrev Taha Sencar},
	title = {Estimating Uniqueness of I-Vector-Based Representation of Human Voice},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3054--3067},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3071574},
	doi = {10.1109/TIFS.2021.3071574},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TandoganS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the individuality of the human voice with respect to a widely used feature representation of speech utterances, namely, the i-vector model. As a first step toward this goal, we compare and contrast uniqueness measures proposed for different biometric modalities. Then, we introduce a new uniqueness measure that evaluates the entropy of i-vectors while taking into account speaker level variations. Our measure operates in the discrete feature space and relies on accurate estimation of the distribution of i-vectors. Therefore, i-vectors are quantized while ensuring that both the quantized and original representations yield similar speaker verification performance. Uniqueness estimates are obtained from two newly generated datasets and the public VoxCeleb dataset. The first custom dataset contains more than one and a half million speech samples of 20,741 speakers obtained from TEDx Talks videos. The second one includes over twenty one thousand speech samples from 1,595 actors that are extracted from movie dialogues. Using this data, we analyzed how several factors, such as the number of speakers, number of samples per speaker, sample durations, and diversity of utterances affect uniqueness estimates. Most notably, we determine that the discretization of i-vectors does not cause a reduction in speaker recognition performance. Our results show that the degree of distinctiveness offered by i-vector-based representation may reach 43-70 bits considering 5-second long speech samples; however, under less constrained variations in speech, uniqueness estimates are found to reduce by around 30 bits. We also find that doubling the sample duration increases the distinctiveness of the i-vector representation by around 20 bits.}
}


@article{DBLP:journals/tifs/XieGJ21,
	author = {Hongcheng Xie and
                  Yu Guo and
                  Xiaohua Jia},
	title = {A Privacy-Preserving Online Ride-Hailing System Without Involving
                  a Third Trusted Server},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3068--3081},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3065832},
	doi = {10.1109/TIFS.2021.3065832},
	timestamp = {Sun, 16 May 2021 00:14:14 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XieGJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing popularity of Online Ride-hailing (ORH) services has greatly facilitated our daily travel. It enables a rider to easily request the nearest driver through mobile devices in a short time. However, existing ORH systems require the collection of users' location information and thus raise critical privacy concerns. While several privacy-preserving solutions for ORH service have been proposed, most of existing schemes rely on an additional trusted party to compute the distance between a rider and a driver. Such a security assumption cannot fully address the privacy concerns for practical deployment. In this paper, we present a new ride-matching scheme for ORH systems, which allows privacy-preserving and effective distance calculation without involving a third-party server. Our proposed scheme enables ORH systems to securely compute the user distance while protecting the location privacy of both riders and drivers. Specifically, we resort to state-of-the-art distance calculation techniques based on Road Network Embedding (RNE), and show how to uniquely bridge cryptographic primitives like Property-preserving Hash (PPH) with RNE in depth to support privacy-preserving ride-matching services. Moreover, we also propose an optimized design to improve the matching efficiency. We formally analyze the security strengths and implement the system prototype. Evaluation results demonstrate that our design is secure and efficient for ORH systems.}
}


@article{DBLP:journals/tifs/GuoZLL21,
	author = {Jianzhu Guo and
                  Xiangyu Zhu and
                  Zhen Lei and
                  Stan Z. Li},
	title = {Decomposed Meta Batch Normalization for Fast Domain Adaptation in
                  Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3082--3095},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3073823},
	doi = {10.1109/TIFS.2021.3073823},
	timestamp = {Tue, 12 Apr 2022 15:00:36 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GuoZLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face recognition systems are sometimes deployed to a target domain with limited unlabeled samples available. For instance, a model trained on the large-scale webfaces may be required to adapt to a NIR-VIS scenario via very limited unlabeled faces. This situation poses a great challenge to Unsupervised Domain Adaptation with Limited samples for Face Recognition (UDAL-FR), which is less studied in previous works. In this paper, with deep learning methods, we propose a novel training remedy by decomposing the model into the weight parameters and the BN statistics in the training phase. Based on decomposing, we design a novel framework via meta-learning, called Decomposed Meta Batch Normalization (DMBN) for fast domain adaptation in face recognition. DMBN trains the network such that domain-invariant information is prone to store in the weight parameters and domain-specific knowledge tends to be represented by the BN statistics. Specifically, DMBN constructs distribution-shifted tasks via domain-aware sampling, on which several meta-gradients are obtained by optimizing discriminative representations across different BNs. Finally, the weight parameters are updated with these meta-gradients for better consistency across different BNs. With the learned weight parameters, the adaptation is very fast since only the BN updating on limited data is needed. We propose two UDAL-FR benchmarks to evaluate the domain-adaptive ability of a model with limited unlabeled samples. Extensive experiments validate the efficacy of our proposed DMBN.}
}


@article{DBLP:journals/tifs/SaeidianCOS21,
	author = {Sara Saeidian and
                  Giulia Cervia and
                  Tobias J. Oechtering and
                  Mikael Skoglund},
	title = {Quantifying Membership Privacy via Information Leakage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3096--3108},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3073804},
	doi = {10.1109/TIFS.2021.3073804},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SaeidianCOS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning models are known to memorize the unique properties of individual data points in a training set. This memorization capability can be exploited by several types of attacks to infer information about the training data, most notably, membership inference attacks. In this paper, we propose an approach based on information leakage for guaranteeing membership privacy. Specifically, we propose to use a conditional form of the notion of maximal leakage to quantify the information leaking about individual data entries in a dataset, i.e., the entrywise information leakage. We apply our privacy analysis to the Private Aggregation of Teacher Ensembles (PATE) framework for privacy-preserving classification of sensitive data and prove that the entrywise information leakage of its aggregation mechanism is Schur-concave when the injected noise has a log-concave probability density. The Schur-concavity of this leakage implies that increased consensus among teachers in labeling a query reduces its associated privacy cost. Finally, we derive upper bounds on the entrywise information leakage when the aggregation mechanism uses Laplace distributed noise.}
}


@article{DBLP:journals/tifs/SadeghzadehTJ21,
	author = {Amir Mahdi Sadeghzadeh and
                  Behrad Tajali and
                  Rasool Jalili},
	title = {{AWA:} Adversarial Website Adaptation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3109--3122},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3074295},
	doi = {10.1109/TIFS.2021.3074295},
	timestamp = {Sun, 16 May 2021 00:14:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SadeghzadehTJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the most important obligations of privacy-enhancing technologies is to bring confidentiality and privacy to users' browsing activities on the Internet. The website fingerprinting attack enables a local passive eavesdropper to predict the target user's browsing activities even she uses anonymous technologies, such as VPNs, IPsec, and Tor. Recently, the growth of deep learning empowers adversaries to conduct the website fingerprinting attack with higher accuracy. In this paper, we propose a new defense against website fingerprinting attack using adversarial deep learning approaches called Adversarial Website Adaptation (AWA). AWA creates a transformer set in each run so that each website has a unique transformer. Each transformer generates adversarial traces to evade the adversary's classifier. AWA has two versions, including Universal AWA (UAWA) and Non-Universal AWA (NUAWA). Unlike NUAWA, there is no need to access the entire trace of a website in order to generate an adversarial trace in UAWA. We accommodate secret random elements in the training phase of transformers in order for AWA to generate various sets of transformers in each run. We run AWA several times and create multiple sets of transformers. If an adversary and a target user select different sets of transformers, the accuracy of adversary's classifier is almost 19.52% and 31.94% with almost 22.28% and 26.28% bandwidth overhead in UAWA and NUAWA, respectively. If a more powerful adversary generates adversarial traces through multiple sets of transformers and trains a classifier on them, the accuracy of adversary's classifier is almost 49.10% and 25.93% with almost 62.52% and 64.33% bandwidth overhead in UAWA and NUAW, respectively.}
}


@article{DBLP:journals/tifs/HuangZL21,
	author = {Wen Huang and
                  Shijie Zhou and
                  Yongjian Liao},
	title = {Unexpected Information Leakage of Differential Privacy Due to the
                  Linear Property of Queries},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3123--3137},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3075843},
	doi = {10.1109/TIFS.2021.3075843},
	timestamp = {Wed, 22 Mar 2023 21:18:25 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differential privacy is a widely accepted concept of privacy preservation, and the Laplace mechanism is a famous instance of differentially private mechanisms used to deal with numerical data. In this paper, we find that differential privacy does not take the linear property of queries into account, resulting in unexpected information leakage. Specifically, the linear property makes it possible to divide one query into two queries, such as q(D)=q(D 1 )+q(D 2 ) if D=D 1 ∪D 2 and D 1 ∩D 2 =Ø. If attackers try to obtain an answer to q(D), they can not only issue the query q(D) but also issue q(D 1 ) and calculate q(D 2 ) by themselves as long as they know D 2 . Through different divisions of one query, attackers can obtain multiple different answers to the same query from differentially private mechanisms. However, from the attackers' perspective and differentially private mechanisms' perspective, the total consumed privacy budget is different if divisions are delicately designed. This difference leads to unexpected information leakage because the privacy budget is the key parameter for controlling the amount of information that is legally released from differentially private mechanisms. To demonstrate unexpected information leakage, we present a membership inference attack against the Laplace mechanism. Specifically, under the constraints of differential privacy, we propose a method for obtaining multiple independent identically distributed samples of answers to queries that satisfy the linear property. The proposed method is based on a linear property and some background knowledge of the attackers. When the background knowledge is sufficient, the proposed method can obtain a sufficient number of samples from differentially private mechanisms such that the total consumed privacy budget can be made unreasonably large. Based on the obtained samples, a hypothesis testing method is used to determine whether a target record is in a target dataset.}
}


@article{DBLP:journals/tifs/KimNLYPS21,
	author = {Jinwoo Kim and
                  Jaehyun Nam and
                  Suyeol Lee and
                  Vinod Yegneswaran and
                  Phillip A. Porras and
                  Seungwon Shin},
	title = {BottleNet: Hiding Network Bottlenecks Using SDN-Based Topology Deception},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3138--3153},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3075845},
	doi = {10.1109/TIFS.2021.3075845},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KimNLYPS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The robustness of a network's connectivity to other networks is often highly dependent on a few critical nodes and links that tie the network to the larger topology. The failure or degradation to such network bottlenecks can result in outages that may propagate throughout the network. Unfortunately, the presence of the bottlenecks also offers opportunities for targeted link flooding attacks (LFAs). Researchers have proposed a new and promising defense to counter LFAs, referred to as topology deception. This strategy centers on hindering the discovery of bottlenecks by presenting false trace responses to adversaries as they perform topological probing of the target network. Even though the goal of topology deception centers on obscuring critical links, node dependencies can be exploited by an adversary. However, current approaches do not consider a wide range of metrics that may reveal important and diverse aspects of network bottlenecks. Furthermore, existing approaches create a simple form of virtual topology, which is subject to relatively easy detection by the adversary, reducing its effectiveness. In this paper, we propose a comprehensive topology deception framework, which we refer to as BottleNet. Our suggested approach can analyze various network topology features both with respect to static and dynamic metrics and then use this information to identify bottlenecks, finally producing complex virtual topologies that are resilient to adversarial detection.}
}


@article{DBLP:journals/tifs/YuanWZ21,
	author = {Ye Yuan and
                  Liji Wu and
                  Xiangmin Zhang},
	title = {Gini-Impurity Index Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3154--3169},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3076932},
	doi = {10.1109/TIFS.2021.3076932},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YuanWZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the past few decades, DPA-based side-channel attack strategies, such as DPA and CPA, have shown strong ability to analyze the security of the cryptographic implementations. However, the unpredictability of the leakage model and the correspondence between leakage behavior of the target device and the hypothetical leakage value make it less-effective without prior knowledge. Therefore, in this paper, we present a novel generic side-channel analysis method called Gini-impurity Index Analysis (GIA), utilizing Gini-impurity Index as the distinguisher, which can perform well even without any leakage model and is not sensitive to the existing methods' restrictions about the leakage behavior. Firstly, we introduce the basic idea of GIA. According to the proposed GIA attack strategy, the Gini-impurity index for each key hypothesis should be calculated, determined by the clustered power consumption and the classified subsets based on the key dependent target function. Secondly, we verify the feasibility and evaluate the efficiency of GIA with different target functions by the practical experimental results against AES-128 implemented on an AT89S52 microcontroller. We present one possible multivariate extension of GIA and find the advantage of GIA on leakage information utilization. Thirdly, we present the results of comparisons. On the one hand, we compare GIA with three widely-used distinguishers under simulated traces in various leakage scenarios and practical traces with Hamming-weight-related leakage. Results confirm that GIA can always perform well with different leakage models in most situations. On the other hand, we analyze the relationship between GIA and Mutual Information Analysis (MIA). Theoretical and experimental results confirm that these two methods can obtain similar attack results. However, the guessing entropy of GIA is lower than MIA by up to 21%, and the averaged computational time overhead of GIA is lower than MIA by up to 13.3%, indicating that GIA is more efficient than MIA. Compared to traditional MIA, GIA is easier to operate and more flexible with noise. Therefore, GIA is an efficient and useful alternative to these existed strategies.}
}


@article{DBLP:journals/tifs/LaiJWT21,
	author = {Yen{-}Lung Lai and
                  Zhe Jin and
                  KokSheik Wong and
                  Massimo Tistarelli},
	title = {Efficient Known-Sample Attack for Distance-Preserving Hashing Biometric
                  Template Protection Schemes},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3170--3185},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3073802},
	doi = {10.1109/TIFS.2021.3073802},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LaiJWT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid deployment of biometric authentication systems raises concern over user privacy and security. A biometric template protection scheme emerges as a solution to protect individual biometric templates stored in a database. Among all available protection schemes, a template protection scheme that relies on distance-preserving hashing has received much attention due to its simplicity and efficiency in offering privacy protection while archiving decent authentication performance. In this work, we introduce an efficient attack called known sample attack and demonstrate that most state-of-art template protection schemes that utilize distance-preserving hashing can be compromised in practice (within few seconds), especially when the output is significantly smaller than the original input sample size. These findings further motivated our subsequent work in proposing a secure authentication mechanism to resist such an attack with proper study over the distribution of the input samples. Furthermore, we conducted revocability, unlinkability analysis to demonstrate the satisfactory of general biometric template protection requirements; and showed the resistance of various security and privacy attacks, i.e., false acceptance attack, and attack via record multiplicity.}
}


@article{DBLP:journals/tifs/LiZ21a,
	author = {Shuyi Li and
                  Bob Zhang},
	title = {Joint Discriminative Sparse Coding for Robust Hand-Based Multimodal
                  Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3186--3198},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3074315},
	doi = {10.1109/TIFS.2021.3074315},
	timestamp = {Sun, 13 Aug 2023 11:44:44 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiZ21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multimodal biometrics recognition has recently attracted much interest for its higher security and effectiveness compared with unimodal biometrics recognition. However, most of the conventional multimodal recognition approaches generally focus on extracting semantic information from different modalities independently, while ignoring the implicit correlations among inter-modality. In this paper, we propose a simple yet effective supervised multimodal feature learning method, called joint discriminative sparse coding (JDSC), which is applied for hand-based multimodal recognition including finger-vein and finger-knuckle-print fusion, palm-vein and palmprint fusion, as well as palm-vein and dorsal-hand-vein fusion. Considering that relevant samples from different modalities have semantic correlations, JDSC projects the raw data into a shared space in which the distance of the between-class is maximized and the distance of the within-class is minimized, at the same time, the correlation among the inter-modality of the within-class is maximized. Therefore, sparse binary codes quantified by the obtained projection matrix can have more discriminative power for multimodal recognition tasks. Thorough experiments on six commonly used multimodal datasets demonstrate the superiority of our proposed method over several state-of-the-art techniques.}
}


@article{DBLP:journals/tifs/SunBSBWQ21,
	author = {Zhi Sun and
                  Sarankumar Balakrishnan and
                  Lu Su and
                  Arupjyoti Bhuyan and
                  Pu Wang and
                  Chunming Qiao},
	title = {Who Is in Control? Practical Physical Layer Attack and Defense for
                  mmWave-Based Sensing in Autonomous Vehicles},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3199--3214},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3076287},
	doi = {10.1109/TIFS.2021.3076287},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SunBSBWQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the wide bandwidths in millimeter wave (mmWave) frequency band that results in unprecedented accuracy, mmWave sensing has become vital for many applications, especially in autonomous vehicles (AVs). In addition, mmWave sensing has superior reliability compared to other sensing counterparts such as camera and LiDAR, which is essential for safety-critical driving. Therefore, it is critical to understand the security vulnerabilities and improve the security and reliability of mmWave sensing in AVs. To this end, we perform the end-to-end security analysis of a mmWave-based sensing system in AVs, by designing and implementing practical physical layer attack and defense strategies in a state-of-the-art mmWave testbed and an AV testbed in real-world settings. Various strategies are developed to take control of the victim AV by spoofing its mmWave sensing module, including adding fake obstacles at arbitrary locations and faking the locations of existing obstacles. Five real-world attack scenarios are constructed to spoof the victim AV and force it to make dangerous driving decisions leading to a fatal crash. Field experiments are conducted to study the impact of the various attack scenarios using a Lincoln MKZ-based AV testbed, which validate that the attacker can indeed assume control of the victim AV to compromise its security and safety. To defend the attacks, we design and implement a challenge-response authentication scheme and a RF fingerprinting scheme to reliably detect aforementioned spoofing attacks.}
}


@article{DBLP:journals/tifs/WonHJBB21,
	author = {Yoo{-}Seung Won and
                  Xiaolu Hou and
                  Dirmanto Jap and
                  Jakub Breier and
                  Shivam Bhasin},
	title = {Back to the Basics: Seamless Integration of Side-Channel Pre-Processing
                  in Deep Neural Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3215--3227},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3076928},
	doi = {10.1109/TIFS.2021.3076928},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WonHJBB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning approaches have become popular for Side-Channel Analysis (SCA) in the recent years. Especially Convolutional Neural Networks (CNN) due to their natural ability to overcome jitter-based as well as masking countermeasures. Most of the recent works have been focusing on optimising the performance on given dataset, for example finding optimal architecture and using ensemble, and bypass the need for trace pre-processing. However, trace pre-processing is a long studied topic and several proven techniques exist in the literature. There is no straightforward manner to integrate those techniques into deep learning based SCA. In this paper, we propose a generic framework which allows seamless integration of multiple, user defined pre-processing techniques into the neural network architecture. The framework is based on Multi-scale Convolutional Neural Networks ( MCNN) that were originally proposed for time series analysis. MCNN are composed of multiple branches that can apply independent transformation to input data in each branch to extract the relevant features and allowing a better generalization of the model. In terms of SCA, these transformations can be used for integration of pre-processing techniques, such as phase-only correlation, principal component analysis, alignment methods, etc. We present successful results on generic network which generalizes to different publicly available datasets. Our findings show that it is possible to design a network that can be used in a more general way to analyze side-channel leakage traces and perform well across datasets.}
}


@article{DBLP:journals/tifs/ShengTNPD21,
	author = {Zhichao Sheng and
                  Hoang Duong Tuan and
                  Ali Arshad Nasir and
                  H. Vincent Poor and
                  Eryk Dutkiewicz},
	title = {Physical Layer Security Aided Wireless Interference Networks in the
                  Presence of Strong Eavesdropper Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3228--3240},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3076927},
	doi = {10.1109/TIFS.2021.3076927},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShengTNPD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Under both long (infinite) and short (finite) blocklength transmissions, this paper considers physical layer security for a wireless interference network of multiple transmitter-user pairs, which is overheard by multiple eavesdroppers (EVs). The EVs are assumed to have better channel conditions than the legitimate users (UEs), making the conventional transmission unsecured. The paper develops a novel time-fraction based transmission, under which the information is transmitted to the UEs within a fraction of the time slot and artificial noise (AN) is transmitted within the remaining fraction to counter the strong EVs' channels. Based on channel distribution information of UEs and EVs, the joint design of transmit beamforming, time fractions and AN power allocation to maximize the worst users' secrecy rate is formulated in terms of nonconvex problems. Path-following algorithms of low complexity and rapid convergence are proposed for their solution. Simulations are provided to demonstrate the viability of the proposed methodology.}
}


@article{DBLP:journals/tifs/LinHHC21,
	author = {Chao Lin and
                  Debiao He and
                  Xinyi Huang and
                  Kim{-}Kwang Raymond Choo},
	title = {{OBFP:} Optimized Blockchain-Based Fair Payment for Outsourcing Computations
                  in Cloud Computing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3241--3253},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3073818},
	doi = {10.1109/TIFS.2021.3073818},
	timestamp = {Thu, 24 Feb 2022 11:50:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LinHHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outsourcing computations have been widely used to meet the growing computing demands, although achieving trust in an untrusted (or a zero-trust) environment can be challenging in practice. Fair payment, a candidate solution, can potentially facilitate fair trading among outsourcing computation participants such as users and workers. However, most existing solutions including traditional e-cash-based or blockchain-based, may potentially compromise the worker's fairness (i.e., does not achieve robust fairness, since trusted third parties are required during the trading process), or involve heavy zero-knowledge proofs (ZKPs, with significant computation costs). To mitigate these limitations, we propose a system model of an optimized blockchain-based fair payment (OBFP) for outsourcing computations. Then, we construct a ZKP-free solution based on blockchain by combining any secure commitment, accumulator, and symmetric encryption schemes, as well as a hash function. To demonstrate the utility of our proposed OBFP system, we provide security analysis, performance evaluation and a comparison with existing popular solutions. Specifically, the cryptographic tools are instantiated as commitment (Perdesen commitment), accumulator (RSA-based accumulator), and symmetric encryption (a concrete scheme with the indistinguishability under chosen-plaintext attack (IND-CPA) security), and a hash function (Keccak-256). The prototype is implemented in COSBench and Remix to analyze cloud scalability and concurrency, as well as gas cost.}
}


@article{DBLP:journals/tifs/KulowSTS21,
	author = {Alexander Kulow and
                  Thomas Schamberger and
                  Lars Tebelmann and
                  Georg Sigl},
	title = {Finding the Needle in the Haystack: Metrics for Best Trace Selection
                  in Unsupervised Side-Channel Attacks on Blinded {RSA}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3254--3268},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3074884},
	doi = {10.1109/TIFS.2021.3074884},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KulowSTS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For asymmetric ciphers, such as RSA and ECC, side-channel attacks on the underlying exponentiation are mitigated by countermeasures like constant-time implementation and blinding. This restricts an attacker to a single side-channel trace for an attack as a different representation of the private key is used for each exponentiation. In this work, we propose an unsupervised machine learning framework for side-channel attacks on asymmetric cryptography that analyzes leakage in multiple side-channel traces, identifying the best trace for key retrieval. We apply Principal Component Analysis (PCA) preprocessing followed by a classification step that assigns segments of traces to elementary operations of the Square and Multiply exponentiation of RSA. In order to estimate the attack complexity for each trace in terms of key enumeration effort, we introduce two new metrics: The Entropy-based Cost Function (EBCF) is used to select a trace for the attack as well as bits which have to be brute-forced if not all bits can be determined correctly from this single trace. To reduce brute-force complexity further, we introduce Illegal Sequence Detection (ISD) to remove brute-force candidates which do not fit to the Square-and-Multiply scheme. We first provide a proof of concept for 320-bit key length traces and, moving towards a more realistic scenario, retrieve the key from a 1024-bit RSA implementation protected by message and exponent blinding. We are able to select the trace with the least remaining brute-force complexity from 1000 power measurements of the signature generation with randomized inputs and blinding values on a 32-bit ARM Cortex-M4 microcontroller.}
}


@article{DBLP:journals/tifs/MourisT21,
	author = {Dimitris Mouris and
                  Nektarios Georgios Tsoutsos},
	title = {Zilch: {A} Framework for Deploying Transparent Zero-Knowledge Proofs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3269--3284},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3074869},
	doi = {10.1109/TIFS.2021.3074869},
	timestamp = {Mon, 28 Aug 2023 21:40:49 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MourisT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As cloud computing becomes more popular, research has focused on usable solutions to the problem of verifiable computation (VC), where a computationally weak device (Verifier) outsources a program execution to a powerful server (Prover) and receives guarantees that the execution was performed faithfully. A Prover can further demonstrate knowledge of a secret input that causes the Verifier's program to satisfy certain assertions, without ever revealing which input was used. State-of-the-art Zero-Knowledge Proofs of Knowledge (ZKPK) methods encode a computation using arithmetic circuits and preserve the privacy of Prover's inputs while attesting the integrity of program execution. Nevertheless, developing, debugging, and optimizing programs as circuits remains a daunting task, as most users are unfamiliar with this programming paradigm. In this work, we present Zilch, a framework that accelerates and simplifies the deployment of VC and ZKPK for any application transparently, i.e., without the need of trusted setup. Zilch uses traditional instruction sequences rather than static arithmetic circuits that would need to be regenerated for each different computation. Towards that end, we have implemented Z MIPS: a MIPS-like processor model that allows verifying each instruction independently and compose a proof for the execution of the target application. To foster usability, Zilch incorporates a novel cross-compiler from an object-oriented Java-like language tailored to ZKPK and optimized our Z MIPS model, as well as a powerful API that enables integration of ZKPK within existing C/C++ programs. In our experiments, we demonstrate the flexibility of Zilch using two real-life applications, and evaluate Prover and Verifier performance on a variety of benchmarks.}
}


@article{DBLP:journals/tifs/AktukmakYU21,
	author = {Mehmet Aktukmak and
                  Yasin Yilmaz and
                  Ismail Uysal},
	title = {Sequential Attack Detection in Recommender Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3285--3298},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3076295},
	doi = {10.1109/TIFS.2021.3076295},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AktukmakYU21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems are widely used in electronic commerce, social media and online streaming services to provide personalized recommendations to the users by exploiting past ratings and interactions. This paper considers the security aspect with quick and accurate detection of attacks by observing the newly created profiles sequentially to prevent the damage which may be incurred by the injection of new profiles with dishonest ratings. The proposed framework consists of a latent variable model, which is trained by a variational EM algorithm, followed by a sequential detection algorithm. The latent variable model generates homogeneous representations of the users given their rating history and mixed data-type attributes such as age and gender. The representations are then exploited to generate univariate statistics to be efficiently used in a CUSUM-like sequential detection algorithm that can quickly detect persistent attacks while maintaining low false alarm rates. We apply our proposed framework to three different real-world datasets and exhibit superior performance in comparison to the existing baseline algorithms for both attack profile and sequential detection. Furthermore, we demonstrate robustness to different attack strategies and configurations.}
}


@article{DBLP:journals/tifs/TanK21,
	author = {Hanzhuo Tan and
                  Ajay Kumar},
	title = {Minutiae Attention Network With Reciprocal Distance Loss for Contactless
                  to Contact-Based Fingerprint Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3299--3311},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3076307},
	doi = {10.1109/TIFS.2021.3076307},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TanK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interoperability between contactless and conventional contact-based fingerprint recognition systems is fundamental for the success of emerging contactless fingerprint technologies which are highly sought, especially due to current pandemic. However, image formation differences and acquisition distortions between these two modalities pose significant challenges for such interoperability. In order to address these challenges, this paper presents a minutiae attention network with Siamese architecture and the reciprocal distance loss function to enable more accurate contactless to contact-based fingerprint identification. The proposed network contains two branches, a global-net branch to recover global features and a minutiae attention branch that focuses on the local minutiae areas. Attention mechanism is introduced to guide the minutiae attention branch to concentrate on distorted areas and recover minutiae/features correspondence for contactless and contact-based fingerprint images from the same fingers. Meanwhile, reciprocal distance loss is specifically designed to impose strong penalty towards contactless and contact-based fingerprint images from different fingers and guide the network to learn robust features for distinguishing identities. Experimental results on two publicly available databases illustrate significant performance improvements, over state-of-art methods in the literature, and validate the effectiveness of the proposed framework for the contactless to contact-based fingerprint identification.}
}


@article{DBLP:journals/tifs/ZhuWRXYLCLC21,
	author = {Tiantian Zhu and
                  Jiayu Wang and
                  Linqi Ruan and
                  Chunlin Xiong and
                  Jinkai Yu and
                  Yaosheng Li and
                  Yan Chen and
                  Mingqi Lv and
                  Tieming Chen},
	title = {General, Efficient, and Real-Time Data Compaction Strategy for {APT}
                  Forensic Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3312--3325},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3076288},
	doi = {10.1109/TIFS.2021.3076288},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuWRXYLCLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The damage caused by Advanced Persistent Threat (APT) attacks to governments and large enterprises is gradually escalating. Once an attack event is detected, forensic analysis will use the dependencies between system audit logs to rapidly locate intrusion points and determine the impact of the attacks. Due to the high persistence of APT attacks, huge amounts of data will be stored to meet the needs of forensic analysis, which not only brings great storage overhead, but also sharply increases the computing costs. To compact data without affecting forensic analysis, several methods have been proposed. However, in real-world scenarios, we meet the problems of weak cross-platform capability, large data processing overhead, and poor real-time performance, rendering existing data compaction methods difficult to meet the usability and universality requirements jointly. To overcome these difficulties, this paper proposes a general, efficient, and real-time data compaction method at the system log level; it does not involve internal analysis of the program or depend on the specific operating system type, and it includes two strategies: 1) data compaction of maintaining global semantics (GS), which determines and deletes redundant events that do not affect global dependencies, and 2) data compaction based on suspicious semantics (SS). Given that the purpose of forensic analysis is to restore the attack chain, SS performs context analysis on the remaining events from GS and further deletes the parts that are not related to the attack. The results of the real-world experiments show that the compaction ratios of our method to system events are as high as\n4.36×\nto\n13.18×\nand\n7.86×\nto\n26.99×\non GS and SS, respectively, which is better than state-of-the-art studies.}
}


@article{DBLP:journals/tifs/CaoZZH21,
	author = {Yun Cao and
                  Hong Zhang and
                  Xianfeng Zhao and
                  Xiaolei He},
	title = {Steganalysis of {H.264/AVC} Videos Exploiting Subtractive Prediction
                  Error Blocks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3326--3338},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3078822},
	doi = {10.1109/TIFS.2021.3078822},
	timestamp = {Sat, 30 Sep 2023 10:28:39 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CaoZZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To cope with the abuse of steganography using H.264 videos, i.e., the dominant video format, as the carrier, this paper presents a steganalytic method which works well even in the scenario where both the training data and the prior knowledge of the test data are limited. As a key feature of H.264, intra prediction is incorporated to remove redundancies within one single frame by predicting the current block using previously coded blocks. Unlike in JPEG domain, the quantized discrete cosine transform (QDCT) coefficients in H.264 videos come from the prediction error (residual) blocks (PEBs) instead of the original pixel block, hence we suggest shifting the focal point from the spatial domain to the prediction error domain, i.e., the PEB domain. According to the traits of video coding, 3 types of subtractive PEB (SPEB) are defined to capture the inconsistency between correlated PEBs, and the differences between correlated SPEBs are modeled by first-order Markov chain. Then the so-called SUPERB (SUbtractive Prediction ERror Block) features are engineered by subsets of sample transition probability matrices for a steganalyzer. What's more, the features derived from IPM (Intra Prediction Mode) transition probabilities are also merged into SUPERB to improve detection ability. Extensive experiments are carried out from different aspects. Performance results demonstrate the effectiveness of SUPERB, particularly its essence of general applicability when the training and test data are of quite different attributes, which is more favorable for real-world applications.}
}


@article{DBLP:journals/tifs/LeGWW21,
	author = {Ngoc Tuyen Le and
                  Duong Binh Giap and
                  Jing{-}Wein Wang and
                  Chih{-}Chiang Wang},
	title = {Tensor-Compensated Color Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3339--3354},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3078273},
	doi = {10.1109/TIFS.2021.3078273},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LeGWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Making face recognition more reliable under uncontrolled lighting conditions is one of the most important challenges for practical recognition systems. The reasons come from the need for automatic recognitions and security systems. To overcome this problem, we propose a novel illumination compensation method called adaptive high-order singular value decomposition to enhance face images at the preprocessing step of the face recognition system. First, we present an RGB color face image as a third-order tensor. Then, adaptive high-order singular value decomposition is proposed to adjust the core tensor automatically by multiplying three frontal slices of the core tensor with their corresponding compensation weight coefficients while keeping the third inverse factor fixed. The experiments performed on five of the most famous public color face databases, namely CMU-PIE, Color FERET, FEI, LFW, and IJB-C reveal that adaptive high-order singular value decomposition not only yields compensated images that are clear, natural, and smooth but also considerably improves the accuracy and computing time of face recognition.}
}


@article{DBLP:journals/tifs/CabanaYDLKAA21,
	author = {Olivier Cabana and
                  Amr M. Youssef and
                  Mourad Debbabi and
                  Bernard Lebel and
                  Marthe Kassouf and
                  Ribal Atallah and
                  Basile L. Agba},
	title = {Threat Intelligence Generation Using Network Telescope Data for Industrial
                  Control Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3355--3370},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3078261},
	doi = {10.1109/TIFS.2021.3078261},
	timestamp = {Tue, 07 May 2024 20:18:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CabanaYDLKAA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial Control Systems (ICSs) are cyber-physical systems that offer attractive targets to threat actors due to the scale of damages, both physical and cyber, that successful exploitation can cause. As such, ICSs often find themselves victims to reconnaissance campaigns - coordinated scanning activity that targets a wide subset of the Internet - that aim to discover vulnerable systems. As these campaigns likely scan broad netblocks of the Internet, some traffic is directed to network telescopes, which are routable, allocated, and unused IP space. In this paper, we explore the threat landscape of ICS devices by analyzing and investigating network telescope traffic. Our network traffic analysis tool takes darknet traffic and generates threat intelligence on scanning campaigns targeting ICSs in the form of campaign fragments, which we leverage in new ways to get more in-depth knowledge of the cybersecurity threats. We investigate the payloads of the identified campaigns using a custom Deep Packet Inspection (DPI) technique to dissect and analyze the packets. We found 13 distinct payload templates and deduced their purpose, and by extension the campaign goals. We use machine learning to classify the sources behind the campaigns and identify threat actors such as botnets, malicious attackers, or researchers, and establish a methodology to rank our campaigns to prioritize our analysis. To conduct our analysis of the threats targeting ICSs, we have leveraged 12.85 TB (330 days) of network traffic received by our observed darknet IP space. Combining these investigative threads, we provide a thorough overview of the threat landscape targeting ICS systems.}
}


@article{DBLP:journals/tifs/ZhaoLSJS21,
	author = {Shuangrui Zhao and
                  Jia Liu and
                  Yulong Shen and
                  Xiaohong Jiang and
                  Norio Shiratori},
	title = {Secure and Energy-Efficient Precoding for {MIMO} Two-Way Untrusted
                  Relay Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3371--3386},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3080088},
	doi = {10.1109/TIFS.2021.3080088},
	timestamp = {Wed, 18 Aug 2021 19:15:17 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoLSJS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper focuses on the multiple-input-multiple-output (MIMO) two-way relay system with an untrusted relay and investigates its secure and energy-efficient precoding design issue based on the physical layer security technology. We first provide theoretical modeling for the index of secrecy energy efficiency (SEE) and formulate the optimal precoding design for SEE maximization (SEEM) as a high-dimensional non-convex programming problem. By exploring the techniques like fractional programming, alternate optimization and semi-definite programming, we then develop a hierarchical theoretical framework to solve the SEEM problem and thus to identify the optimal precoding designs for the source and relay. Furthermore, we demonstrate the proposed theoretical framework is also applicable to the problem of precoding design for secrecy sum rate maximization. Finally, with the help of generalized singular value decomposition, we propose a sub-optimal relay precoding design scheme with significantly lower computational complexity. Extensive numerical results provided in the paper indicate that the proposed schemes can remarkably improve the SEE performance in MIMO two-way untrusted relay systems.}
}


@article{DBLP:journals/tifs/QinWZC21,
	author = {Yan Qin and
                  Weiping Wang and
                  Shigeng Zhang and
                  Kai Chen},
	title = {An Exploit Kits Detection Approach Based on {HTTP} Message Graph},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3387--3400},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3080082},
	doi = {10.1109/TIFS.2021.3080082},
	timestamp = {Tue, 15 Jun 2021 17:23:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QinWZC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The exploit kits (EKs) are used by attackers to distribute malware automatically and silently. Existing approaches to EKs detection usually need to perform dynamic analysis on the content contained in the network traffic, which requires dumping all the network traffic and thus causes high detection overhead. Although some approaches detect EKs based on static analysis, they usually fail to restore the complete attack path because of the obstruction set by the attackers. In this paper, we propose an approach that can detect EKs based on only information extracted by static analysis. Our method builds a graph for web sessions and extracts features from the graph to perform EKs detection. The built graph catches important structural characteristics of the interaction during EK attacks that were not revealed in existing methods, with which EKs can be detected with high accuracy. The experiments show that our method works well in both the ground-truth datasets and the latest practical cases. Our method can also identify the malicious websites concealed in EKs, which can further improve the efficiency of analysis.}
}


@article{DBLP:journals/tifs/HeLWW21,
	author = {Hongliang He and
                  Xizhao Luo and
                  Jian Weng and
                  Kaimin Wei},
	title = {Secure Transmission in Multiple Access Wiretap Channel: Cooperative
                  Jamming Without Sharing {CSI}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3401--3411},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3080499},
	doi = {10.1109/TIFS.2021.3080499},
	timestamp = {Tue, 15 Jun 2021 17:23:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HeLWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the secure transmission in multiple access wiretap channels, where multiple legitimate users transmit private information to an intended receiver in the presence of multiple eavesdroppers. In order to improve security, we propose a novel cooperative jamming scheme, in which users do not share channel state information (CSI) but the legitimate channels will not be degraded by the artificial noise. The basic idea is to make each user exploit its own CSI in two slots to design artificial noise, so that the intended receiver can eliminate all the artificial noise but the eavesdroppers cannot. In this process, the interference between users plays a key role to achieve security, because it guarantees that the artificial noise from different users helps each other. We consider the non-collusion and collusion of eavesdroppers and analyze the secrecy performance for both scenarios. We adopt the secrecy sum-rate as the main metric, and show that positive secrecy sum-rate can be achieved by using the proposed scheme. Especially, we observe that when eavesdroppers collude and their additive white Gaussian noise (AWGN) close to zero, the number of users must not be less than twice the number of eavesdroppers to ensure positive secrecy sum-rate. Finally, simulation results are provided to corroborate our theoretical findings.}
}


@article{DBLP:journals/tifs/ChenZZWL21,
	author = {Jian Chen and
                  Xuxin Zhang and
                  Rui Zhang and
                  Chen Wang and
                  Ling Liu},
	title = {De-Pois: An Attack-Agnostic Defense against Data Poisoning Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3412--3425},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3080522},
	doi = {10.1109/TIFS.2021.3080522},
	timestamp = {Mon, 05 Feb 2024 20:21:14 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenZZWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning techniques have been widely applied to various applications. However, they are potentially vulnerable to data poisoning attacks, where sophisticated attackers can disrupt the learning procedure by injecting a fraction of malicious samples into the training dataset. Existing defense techniques against poisoning attacks are largely attack-specific: they are designed for one specific type of attacks but do not work for other types, mainly due to the distinct principles they follow. Yet few general defense strategies have been developed. In this paper, we propose De-Pois, an attack-agnostic defense against poisoning attacks. The key idea of De-Pois is to train a mimic model the purpose of which is to imitate the behavior of the target model trained by clean samples. We take advantage of Generative Adversarial Networks (GANs) to facilitate informative training data augmentation as well as the mimic model construction. By comparing the prediction differences between the mimic model and the target model, De-Pois is thus able to distinguish the poisoned samples from clean ones, without explicit knowledge of any ML algorithms or types of poisoning attacks. We implement four types of poisoning attacks and evaluate De-Pois with five typical defense methods on different realistic datasets. The results demonstrate that De-Pois is effective and efficient for detecting poisoned data against all the four types of poisoning attacks, with both the accuracy and F1-score over 0.9 on average.}
}


@article{DBLP:journals/tifs/ChawlaKM21,
	author = {Nikhil Chawla and
                  Harshit Kumar and
                  Saibal Mukhopadhyay},
	title = {Machine Learning in Wavelet Domain for Electromagnetic Emission Based
                  Malware Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3426--3441},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3080510},
	doi = {10.1109/TIFS.2021.3080510},
	timestamp = {Tue, 15 Jun 2021 17:23:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChawlaKM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a signal processing and machine learning (ML) based methodology to leverage Electromagnetic (EM) emissions from an embedded device to remotely detect a malicious application running on the device and classify the application into a malware family. We develop Fast Fourier Transform (FFT) based feature extraction followed by Support Vector Machine (SVM) and Random Forest (RF) based ML models to detect a malware. We further propose methods to learn characteristic behavior of different malwares from EM traces to reveal similarities to known malware families and improve efficiency of malware analysis. We propose to use Discrete Wavelet Transform (DWT) based feature extraction from spectrograms of EM side-channel traces and perform ML on the extracted features to learn fine-grained patterns of malware families. The experimental demonstration on Open-Q 820 development platform demonstrate 0.99 F 1 score in detecting malware and 0.88 F 1 score in uniquely classifying malwares among 8 malware family evaluated using Support Vector Machines (SVM) and Random Forest (RF) Machine Learning(ML) models. We also demonstrate capability of proposed framework in identifying new unknown applications with 0.99 recall and unknown malware family with 0.87 recall.}
}


@article{DBLP:journals/tifs/DingWJHTG21,
	author = {Wenjie Ding and
                  Xing Wei and
                  Rongrong Ji and
                  Xiaopeng Hong and
                  Qi Tian and
                  Yihong Gong},
	title = {Beyond Universal Person Re-Identification Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3442--3455},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3081247},
	doi = {10.1109/TIFS.2021.3081247},
	timestamp = {Mon, 08 Jul 2024 18:04:41 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DingWJHTG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based person re-identification (Re-ID) has made great progress and achieved high performance recently. In this paper, we make the first attempt to examine the vulnerability of current person Re-ID models against a dangerous attack method, i.e. , the universal adversarial perturbation (UAP) attack, which has been shown to fool classification models with a little overhead. We propose a more universal adversarial perturbation (MUAP) method for both image-agnostic and model-insensitive person Re-ID attack. Firstly, we adopt a list-wise attack objective function to disrupt the similarity ranking list directly. Secondly, we propose a model-insensitive mechanism for cross-model attack. Extensive experiments show that the proposed attack approach achieves high attack performance and outperforms other state of the arts by large margin in cross-model scenario. The results also demonstrate the vulnerability of current Re-ID models to MUAP and further suggest the need of designing more robust Re-ID models.}
}


@article{DBLP:journals/tifs/ShehnepoorTLB21,
	author = {Saeedreza Shehnepoor and
                  Roberto Togneri and
                  Wei Liu and
                  Mohammed Bennamoun},
	title = {DFraud{\({^3}\)}: Multi-Component Fraud Detection Free of Cold-Start},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3456--3468},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3081258},
	doi = {10.1109/TIFS.2021.3081258},
	timestamp = {Sat, 09 Apr 2022 12:31:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShehnepoorTLB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fraud review detection is a hot research topic in recent years. The Cold-start is a particularly new but significant problem referring to the failure of a detection system to recognize the authenticity of a new user. State-of-the-art solutions employ a translational knowledge graph embedding approach (TransE) to model the interaction of the components of a review system. However, these approaches suffer from the limitation of TransE in handling N-1 relations and the narrow scope of a single classification task, i.e., detecting fraudsters only. In this paper, we model a review system as a Heterogeneous Information Network (HIN) which enables a unique representation to every component and performs graph inductive learning on the review data through aggregating features of nearby nodes. HIN with graph induction helps to address the camouflage issue (fraudsters with genuine reviews) which has shown to be more severe when it is coupled with cold-start, i.e., new fraudsters with genuine first reviews. In this research, instead of focusing only on one component, detecting either fraud reviews or fraud users (fraudsters), vector representations are learned for each component, enabling multi-component classification. In other words, we can detect fraud reviews, fraudsters, and fraud-targeted items, thus the name of our approach DFraud 3 . DFraud 3 demonstrates a significant accuracy increase of 13% over the state of the art on Yelp.}
}


@article{DBLP:journals/tifs/DemetrioBLRA21,
	author = {Luca Demetrio and
                  Battista Biggio and
                  Giovanni Lagorio and
                  Fabio Roli and
                  Alessandro Armando},
	title = {Functionality-Preserving Black-Box Optimization of Adversarial Windows
                  Malware},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3469--3478},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3082330},
	doi = {10.1109/TIFS.2021.3082330},
	timestamp = {Sat, 09 Apr 2022 12:31:44 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DemetrioBLRA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Windows malware detectors based on machine learning are vulnerable to adversarial examples, even if the attacker is only given black-box query access to the model. The main drawback of these attacks is that: ( i) they are query-inefficient, as they rely on iteratively applying random transformations to the input malware; and ( ii) they may also require executing the adversarial malware in a sandbox at each iteration of the optimization process, to ensure that its intrusive functionality is preserved. In this paper, we overcome these issues by presenting a novel family of black-box attacks that are both query-efficient and functionality-preserving, as they rely on the injection of benign content (which will never be executed) either at the end of the malicious file, or within some newly-created sections. Our attacks are formalized as a constrained minimization problem which also enables optimizing the trade-off between the probability of evading detection and the size of the injected payload. We empirically investigate this trade-off on two popular static Windows malware detectors, and show that our black-box attacks can bypass them with only few queries and small payloads, even when they only return the predicted labels. We also evaluate whether our attacks transfer to other commercial antivirus solutions, and surprisingly find that they can evade, on average, more than 12 commercial antivirus engines. We conclude by discussing the limitations of our approach, and its possible future extensions to target malware classifiers based on dynamic analysis.}
}


@article{DBLP:journals/tifs/NingZ21,
	author = {Zhenyu Ning and
                  Fengwei Zhang},
	title = {Corrections to "Hardware-Assisted Transparent Tracing and Debugging
                  on ARM"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3479},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3083357},
	doi = {10.1109/TIFS.2021.3083357},
	timestamp = {Mon, 28 Aug 2023 21:40:51 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NingZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the above article [1] , in the first-page footnote, the corresponding author should appear as: (Corresponding author: Dr. Fengwei Zhang) instead of (Corresponding author: Zhenyu Ning).}
}


@article{DBLP:journals/tifs/ZhangDSAN21,
	author = {Jiayi Zhang and
                  Hongyang Du and
                  Qiang Sun and
                  Bo Ai and
                  Derrick Wing Kwan Ng},
	title = {Physical Layer Security Enhancement With Reconfigurable Intelligent
                  Surface-Aided Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3480--3495},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3083409},
	doi = {10.1109/TIFS.2021.3083409},
	timestamp = {Mon, 21 Aug 2023 15:51:16 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangDSAN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reconfigurable intelligent surface (RIS)-aided wireless communications have drawn significant attention recently. We study the physical layer security of the downlink RIS-aided transmission framework for randomly located users in the presence of a multi-antenna eavesdropper. To show the advantages of RIS-aided networks, we consider two practical scenarios: Communication with and without RIS. In both cases, we apply the stochastic geometry theory to derive exact probability density function (PDF) and cumulative distribution function (CDF) of the received signal-to-interference-plus-noise ratio. Furthermore, the obtained PDF and CDF are exploited to evaluate important security performance of wireless communication including the secrecy outage probability, the probability of nonzero secrecy capacity, and the average secrecy rate. Monte-Carlo simulations are subsequently conducted to validate the accuracy of our analytical results. Compared with traditional MIMO systems, the RIS-aided system offers better performance in terms of physical layer security. In particular, the security performance is improved significantly by increasing the number of reflecting elements equipped in a RIS. However, adopting RIS equipped with a small number of reflecting elements cannot improve the system performance when the path loss of NLoS is small.}
}


@article{DBLP:journals/tifs/CeccatoFLT21,
	author = {Marco Ceccato and
                  Francesco Formaggio and
                  Nicola Laurenti and
                  Stefano Tomasin},
	title = {Generalized Likelihood Ratio Test for {GNSS} Spoofing Detection in
                  Devices With {IMU}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3496--3509},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3083414},
	doi = {10.1109/TIFS.2021.3083414},
	timestamp = {Fri, 13 Aug 2021 14:56:48 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CeccatoFLT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spoofing attacks in global navigation satellite systems (GNSSs) aim at inducing the estimation of a fake position at the victim receiver. Many devices, including smartphones, are nowadays equipped with both a GNSS receiver and an inertial measurement unit (IMU), which also provides location/movement information, while being immune from GNSS attacks. We propose a spoofing detection technique based on the comparison between GNSS and IMU measurements. The detection is performed through a generalized likelihood ratio test (GLRT), which is efficiently implemented by a matrix multiplication approach. In particular, the device a) estimates its orientation from magnetometer and gyroscope measurements, b) estimates its position, acceleration, and velocity by a maximum likelihood approach, and c) performs the GLRT for spoofing detection. The performance of the proposed GLRT is compared with the Kalman filter innovation test and with the direct comparison method (DCM), both in terms of false alarm/missed detection probabilities and computational complexity.}
}


@article{DBLP:journals/tifs/ZhouVOS21,
	author = {Linghui Zhou and
                  Minh Thanh Vu and
                  Tobias J. Oechtering and
                  Mikael Skoglund},
	title = {Privacy-Preserving Identification Systems With Noisy Enrollment},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3510--3523},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3078297},
	doi = {10.1109/TIFS.2021.3078297},
	timestamp = {Fri, 13 Aug 2021 14:56:48 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouVOS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study fundamental trade-offs in privacy-preserving biometric identification systems with noisy enrollment. The proposed identification systems include helper data, secret keys, and private keys. Helper data are stored in a public database and used for identification. Secret keys are either stored in a secure database or provided to the user, and can be used in a next step, e.g. for authentication. Private keys are provided by users, and are also used for identification. In this paper, we impose a noisy enrollment channel and an arbitrarily small privacy and secrecy leakage rate. We characterize the optimal trade-off among the identification, secret key, private key, and helper data rates. Depending on how secret keys are produced, we study two cases of the proposed privacy-preserving identification systems, where the secret keys are generated and chosen respectively. By introducing private keys, it is shown that the identification system achieves close to zero privacy leakage rate in both generated and chosen secret key settings. The results also show that the identification rate and the secret key rate can be enlarged by increasing the private key rate. This work provides a framework for analyzing privacy-preserving identification systems and an insight on the design of optimal systems.}
}


@article{DBLP:journals/tifs/AljasemIMSJMM21,
	author = {Muteb Aljasem and
                  Aun Irtaza and
                  Hafiz Malik and
                  Noushin Saba and
                  Ali Javed and
                  Khalid Mahmood Malik and
                  Mohammad Meharmohammadi},
	title = {Secure Automatic Speaker Verification {(SASV)} System Through sm-ALTP
                  Features and Asymmetric Bagging},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3524--3537},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3082303},
	doi = {10.1109/TIFS.2021.3082303},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AljasemIMSJMM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing number of voice-enabled devices and applications consider automatic speaker verification (ASV) a fundamental component. However, maximum outreach for ASV in critical domains e.g., financial services and health care, is not possible unless we overcome security breaches caused by voice cloning algorithms and replayed audios. Therefore, to overcome these vulnerabilities, a secure ASV (SASV) system based on the novel sign modified acoustic local ternary pattern (sm-ALTP) features and asymmetric bagging-based classifier-ensemble with enhanced attack vector is presented. The proposed audio representation approach clusters the high and low frequency components in audio frames by normally distributing frequency components against a convex function. Then, the neighborhood statistics are applied to capture the user specific vocal tract information. The proposed SASV system simultaneously verifies the bonafide speakers and detects the voice cloning attack, cloning algorithm used to synthesize cloned audio (in the defined settings), and voice-replay attacks over the ASVspoof 2019 dataset. In addition, the proposed method detects the voice replay and cloned voice replay attacks over the VSDC dataset. Both the voice cloning algorithm detection and cloned-replay attack detection are novel concepts introduced in this paper. The voice cloning algorithm detection module determines the voice cloning algorithm used to generate the fake audios. Whereas, the cloned voice replay attack detection is performed to determine the SASV behavior when audio samples are simultaneously contemplated with cloning and replay artifacts.}
}


@article{DBLP:journals/tifs/YangCCJT21,
	author = {Jian Yang and
                  Xiang Chen and
                  Shuangwu Chen and
                  Xiaofeng Jiang and
                  Xiaobin Tan},
	title = {Conditional Variational Auto-Encoder and Extreme Value Theory Aided
                  Two-Stage Learning Approach for Intelligent Fine-Grained Known/Unknown
                  Intrusion Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3538--3553},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3083422},
	doi = {10.1109/TIFS.2021.3083422},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangCCJT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Promptly discovering unknown network attacks is critical for reducing the risk of major loss imposed on organizations and information infrastructure. This paper aims at developing an intelligent intrusion detection system capable of classifying known attacks as well as inferring unknown ones. To achieve this, we formulate the problem of fine-grained known/unknown intrusion detection as a two-stage minimization problem, where the first stage is to seek a score measure for minimizing the empirical risk of misclassifying the known attacks, while the second stage is to find another score measure for minimizing the identification risk of inferring unknown attacks. The hierarchical nature of problem formulation allows us to employ the class conditioned auto-encoders to construct a hierarchical intrusion detection framework. Since the reconstruction errors of unknown attacks are generally higher than that of the known attacks, we further employ extreme value theory in the second stage to model the distribution of reconstruction errors for differentiating known/unknown attack. To further reduce the false positive rate, we add a benign clustering module for learning the multimodal distribution of benign traffic. We conduct an experiment on two widely used datasets for assessing intrusion detection. The results show that the proposed method improves the detection rate of unknown attacks while keeping a low false positive rate.}
}


@article{DBLP:journals/tifs/CirilloMMT21,
	author = {Michele Cirillo and
                  Mario Di Mauro and
                  Vincenzo Matta and
                  Marco Tambasco},
	title = {Botnet Identification in DDoS Attacks With Multiple Emulation Dictionaries},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3554--3569},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3082290},
	doi = {10.1109/TIFS.2021.3082290},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CirilloMMT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In a Distributed Denial of Service (DDoS) attack, a network (botnet) of dispersed agents (bots) sends requests to a website to saturate its resources. Since the requests are sent by automata, the typical way to detect them is to look for some repetition pattern or commonalities between requests of the same user or from different users. For this reason, recent DDoS variants exploit communication layers that offer broader possibility in terms of admissible request patterns, such as, e.g., the application layer. In this case, the malicious agents can pick legitimate messages from an emulation dictionary, and each individual agent sends a relatively low number of admissible requests, so as to make its activity non suspicious. This problem has been recently addressed under the assumption that all the members of the botnet use the same emulation dictionary. This situation is an idealization of what occurs in practice, since different clusters of agents are typically sharing only part of a global emulation dictionary. The diversity among the emulation dictionaries across different clusters introduces significant complexity in the botnet identification challenge. This work tackles this issue and provides the following main contributions. We obtain an analytical characterization of the message innovation rate of the DDoS attack with multiple emulation dictionaries. Exploiting this result, we design a botnet identification algorithm equipped with a cluster expurgation rule, which, under appropriate technical conditions, is shown to provide exact classification of bots and normal users as the observation window size increases. Then, an experimental campaign over real network traces is conducted to assess the validity of the theoretical analysis, as well as to examine the effect of a number of non-ideal effects that are unavoidably observed in practical scenarios.}
}


@article{DBLP:journals/tifs/KaurK21,
	author = {Harkeerat Kaur and
                  Pritee Khanna},
	title = {Rebuttal to "Comments on Random Distance Method Generating Unimodal
                  and Multimodal Cancelable Biometric Features"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3570--3572},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3081264},
	doi = {10.1109/TIFS.2021.3081264},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KaurK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This rebuttal highlights major flaws in the comments made by Lamba due to possible oversight in understanding the scheme given by Kaur and Khanna. Firstly, the random distance method (RDM) does not suffer from any mathematical fallacy. It is a unique technique to generate cancelable biometric templates. Secondly, the size of the original log-Gabor feature vector is reduced by half due to the inherent nature of the RDM scheme, and it does not affect the inter-and intra user variations in any adverse way. An experimental analysis is also performed to showcase that RDM maintains inter and intra-user variations. Thirdly, the comment correspondence author has not noticed that the sole purpose of using the random grid (RG) with OR operation is to increase the entropy of the log-Gabor features, which have a low dynamic range. The issue of partial information revelation is out of context here as salting is not used for hiding information. Finally, the author of comment correspondence has failed to understand that padding is used in the implementation of median filters, which is very common in the filtering process.}
}


@article{DBLP:journals/tifs/LiCWL21,
	author = {Wenting Li and
                  Haibo Cheng and
                  Ping Wang and
                  Kaitai Liang},
	title = {Practical Threshold Multi-Factor Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3573--3588},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3081263},
	doi = {10.1109/TIFS.2021.3081263},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiCWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-factor authentication (MFA) has been widely used to safeguard high-value assets. Unlike single-factor authentication (e.g., password-only login), t-factor authentication ( tFA) requires a user always to carry and present t specified factors so as to strengthen the security of login. Nevertheless, this may restrict user experience in limiting the flexibility of factor usage, e.g., the user may prefer to choose any factors at hand for login authentication. To bring back usability and flexibility without loss of security, we introduce a new notion of authentication, called (t,n) threshold MFA, that allows a user to actively choose t factors out of n based on preference. We further define the “most-rigorous” multi-factor security model for the new notion, allowing attackers to control public channels, launch active/passive attacks, and compromise/corrupt any subset of parties as well as factors. We state that the model can capture the most practical security needs in the literature. We design a threshold MFA key exchange (T-MFAKE) protocol built on the top of a threshold oblivious pseudorandom function and an authenticated key exchange protocol. Our protocol achieves the “highest-attainable” security against all attacking attempts in the context of parties/factors being compromised/corrupted. As for efficiency, our design only requires 4+t exponentiations, 2 multi-exponentiations and 2 communication rounds. Compared with existing tFA schemes, even the degenerated (t,t) version of our protocol achieves the strongest security (stronger than most schemes) and higher efficiency on computational and communication. We instantiate our design on real-world platform to highlight its practicability and efficiency.}
}


@article{DBLP:journals/tifs/DongLCLC21,
	author = {Cong Dong and
                  Zhigang Lu and
                  Zelin Cui and
                  Baoxu Liu and
                  Kai Chen},
	title = {MBTree: Detecting Encryption RATs Communication Using Malicious Behavior
                  Tree},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3589--3603},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3071595},
	doi = {10.1109/TIFS.2021.3071595},
	timestamp = {Wed, 28 Feb 2024 14:47:44 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DongLCLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network trace signature matching is one reliable approach to detect active Remote Control Trojan, (RAT). Compared to statistical-based detection of malicious network traces in the face of known RATs, the signature-based method can achieve more stable performance and thus more reliability. However, with the development of encrypted technologies and disguise tricks, current methods suffer inaccurate signature descriptions and inflexible matching mechanisms. In this paper, we propose to tackle above problems by presenting MBTree, an approach to detect encryption RATs Command and Control (C&C) communication based on host-level network trace behavior. MBTree first models the RAT network behaviors as the malicious set by automatically building the multiple level tree, MLTree from distinctive network traces of each sample. Then, MBTree employs a detection algorithm to detect malicious network traces that are similar to any MLTrees in the malicious set. To illustrate the effectiveness of our proposed method, we adopt theoretical analysis of MBTree from the probability perspective. In addition, we have implemented MBTree to evaluate it on five datasets which are reorganized in a sophisticated manner for comprehensive assessment. The experimental results demonstrate the accurate and robust of MBTree, especially in the face of new emerging benign applications.}
}


@article{DBLP:journals/tifs/AddessoBMM21,
	author = {Paolo Addesso and
                  Mauro Barni and
                  Mario Di Mauro and
                  Vincenzo Matta},
	title = {Adversarial Kendall's Model Towards Containment of Distributed Cyber-Threats},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3604--3619},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3082327},
	doi = {10.1109/TIFS.2021.3082327},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AddessoBMM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work examines propagation of cyber-threats over networks under an adversarial formulation. Exploiting Kendall's birth-death-immigration model, we propose an analytical framework to describe the stochastic dynamics of cyber-threat propagation in a collection of heterogeneous sub-networks characterized by different attributes. We propose two formalisations of the problem as zero-sum games involving two adversaries: an attacker, who launches cyber-threats across the distinct sub-networks; and a defender, who tries to mitigate the threats by delivering suitable countermeasures. According to the first formalisation, the interplay between the defender and the attacker is modelled as a Stackelberg leader-follower game, while the second formalisation considers a strategic game wherein the two contenders play simultaneously without knowing the choice of the other player. We derive the equilibrium strategies for both versions of the game, and discuss a number of insightful interplays and ramifications of the different equilibrium points for the problem at hand. The equilibrium strategies depend on three fundamental attributes: i) the available resource budget of the attacker and the defender; ii) the capacity of the legitimate nodes to (unintentionally) forward the threat across the network, after they have been compromised during the propagation of the threat; iii) the intrinsic characteristics of the sub-networks, namely, their immunity to the attacks, their inertia in responding to the countermeasures, and the importance of the individual sub-networks. The relevance of the proposed solution is illustrated through a series of examples and numerical simulations.}
}


@article{DBLP:journals/tifs/LiuJLW21,
	author = {Qianjun Liu and
                  Shouling Ji and
                  Changchang Liu and
                  Chunming Wu},
	title = {A Practical Black-Box Attack on Source Code Authorship Identification
                  Classifiers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3620--3633},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3080507},
	doi = {10.1109/TIFS.2021.3080507},
	timestamp = {Wed, 16 Mar 2022 23:54:26 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuJLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing researches have recently shown that adversarial stylometry of source code can confuse source code authorship identification (SCAI) models, which may threaten the security of related applications such as programmer attribution, software forensics, etc. In this work, we propose source code authorship disguise (SCAD) to automatically hide programmers' identities from authorship identification, which is more practical than the previous work that requires to known the output probabilities or internal details of the target SCAI model. Specifically, SCAD trains a substitute model and develops a set of semantically equivalent transformations, based on which the original code is modified towards a disguised style with small manipulations in lexical features and syntactic features. When evaluated under totally black-box settings, on a real-world dataset consisting of 1,600 programmers, SCAD induces state-of-the-art SCAI models to cause above 30% misclassification rates. The efficiency and utility-preserving properties of SCAD are also demonstrated with multiple metrics. Furthermore, our work can serve as a guideline for developing more robust identification methods in the future.}
}


@article{DBLP:journals/tifs/MuhammadWWZS21,
	author = {Jawad Muhammad and
                  Yunlong Wang and
                  Caiyong Wang and
                  Kunbo Zhang and
                  Zhenan Sun},
	title = {CASIA-Face-Africa: {A} Large-Scale African Face Image Database},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3634--3646},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3080496},
	doi = {10.1109/TIFS.2021.3080496},
	timestamp = {Thu, 02 Dec 2021 17:27:17 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MuhammadWWZS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face recognition is a popular and well-studied area with wide applications in our society. However, racial bias had been proven to be inherent in most State Of The Art (SOTA) face recognition systems. Many investigative studies on face recognition algorithms have reported higher false positive rates of African subjects cohorts than the other cohorts. Lack of large-scale African face image databases in public domain is one of the main restrictions in studying the racial bias problem of face recognition. To this end, we collect a face image database namely CASIA-Face-Africa which contains 38,546 images of 1,183 African subjects. Multi-spectral cameras are utilized to capture the face images under various illumination settings. Demographic attributes and facial expressions of the subjects are also carefully recorded. For landmark detection, each face image in the database is manually labeled with 68 facial keypoints. A group of evaluation protocols are constructed according to different applications, tasks, partitions and scenarios. The performances of SOTA face recognition algorithms without re-training are reported as baselines. The proposed database along with its face landmark annotations, evaluation protocols and preliminary results form a good benchmark to study the essential aspects of face biometrics for African subjects, especially face image preprocessing, face feature analysis and matching, facial expression recognition, sex/age estimation, ethnic classification, face image generation, etc. The database can be downloaded from our website.}
}


@article{DBLP:journals/tifs/SheidaniAE21,
	author = {Sorour Sheidani and
                  Ahmad Mahmoudi Aznaveh and
                  Ziba Eslami},
	title = {CPA-Secure Privacy-Preserving Reversible Data Hiding for {JPEG} Images},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3647--3661},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3080497},
	doi = {10.1109/TIFS.2021.3080497},
	timestamp = {Mon, 28 Aug 2023 21:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SheidaniAE21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Encrypted Image Reversible Data Hiding (EIRDH) is a hot area of research in multimedia outsourcing scenarios. In such a setting, a content owner possesses confidential images that he wants to upload to an untrusted server. The server is supposed to embed a secret message in the images before sending them to potential receivers, and the receivers expect to recover the original images without any distortion. EIRDH schemes are designed to meet reversible data hiding goals while preserving the confidentiality of the host images. Confidentiality is provided by means of encryption algorithms; however, these algorithms, in turn, introduce the challenge of dealing with ciphered images in both embedding and extraction phases. The current paper tries to propose a privacy-preserving reversible data hiding scheme for JPEG images without the need for any levels of decompression. We propose an elliptic curve-based asymmetric, commutative, and separable EIRDH method, in which no entities other than the sender and the eligible receiver of the hidden message (embedded in the encrypted image) are able to recognize its existence. In particular, even the server that performs the embedding remains completely unaware of the content of the images. An important security feature of our scheme involves the security of its multiple encryptions against Chosen-Plaintext Attack (CPA), which is an attack model that assumes the adversary can obtain the encryptions of the images on his choice to achieve possible extra information to attack. Experimental results show that our scheme achieves full reversibility and a satisfactory level of capacity, while it accurately extracts all the hidden bits.}
}


@article{DBLP:journals/tifs/ChenHL21,
	author = {Yiqi Chen and
                  Dan He and
                  Yuan Luo},
	title = {Strong Secrecy of Arbitrarily Varying Multiple Access Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3662--3677},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3087338},
	doi = {10.1109/TIFS.2021.3087338},
	timestamp = {Tue, 09 Nov 2021 13:25:06 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenHL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the strong secrecy capacity of the arbitrarily varying multiple access channel (AVMAC). First, Csiszár's almost independent coloring lemma is generalized to establish an achievable secrecy rate region of the AVMAC with an eavesdropper, which includes existing results on both the arbitrarily varying wiretap channel and the multiple access wiretap channel. We then determine the capacity for a special case named semi-noiseless wiretap channel. In addition, a multi-letter outer bound is also presented. Finally, the results of this paper are further explained via a binary example with a numerical inner bound.}
}


@article{DBLP:journals/tifs/BaeeSBFP21,
	author = {Mir Ali Rezazadeh Baee and
                  Leonie Simpson and
                  Xavier Boyen and
                  Ernest Foo and
                  Josef Pieprzyk},
	title = {On the Efficiency of Pairing-Based Authentication for Connected Vehicles:
                  Time is Not on Our Side!},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3678--3693},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3087359},
	doi = {10.1109/TIFS.2021.3087359},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BaeeSBFP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the near future, intelligent vehicles will be connected via wireless communication links, forming Vehicular Ad-hoc Networks (VANETs). This has potential to improve road safety and to optimize traffic. However, if the communications are not secure, VANETs are vulnerable to cyber attacks involving message manipulation. Research on this problem has produced multiple authentication protocols based on bilinear pairings (a variant of elliptic curve cryptography). The efficiency of such authentication schemes must be addressed before they can be used in real-world deployments. Standards bodies have begun standardizing various pairing-based schemes. The IEEE 1609.2 security standard has not yet selected any pairing-based scheme, leaving the settings related to pairing-based cryptography in the vehicular environments unspecified. In this work, we investigate the efficiency of pairing-based cryptographic primitives over the Barreto-Lynn-Scott and Barreto-Naehrig pairing friendly elliptic curves recommended in the IETF and ISO standards, to determine their suitability for practical application. We implement the algorithms and evaluate the effect of cryptographic pairings using theoretical and experimental analysis of four well-known pairing-based short signature schemes, including: Boneh-Lynn-Shacham, Boneh-Boyen, Zhang-Safavi-Susilo, and Boneh-Gentry-Lynn-Shacham. We use metrics including CPU clock cycles per operation, average computation time in milliseconds, and signature/public key size in bits to estimate the cost of implementing cryptographic pairings on modern processors. We demonstrate the effect of pairing-based cryptography on authentication in vehicular networks. We investigate a high-density highway scenario and show that a crash is possible, as a result of the evaluated authentication delay. We share our findings ahead of the IEEE 1609.2 recommendations for the use of cryptographic pairings.}
}


@article{DBLP:journals/tifs/JiangSTL21,
	author = {Bo Jiang and
                  Mohamed Seif and
                  Ravi Tandon and
                  Ming Li},
	title = {Context-Aware Local Information Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3694--3708},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3087350},
	doi = {10.1109/TIFS.2021.3087350},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangSTL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study Local Information Privacy (LIP). As a context-aware privacy notion, LIP relaxes the de facto standard privacy notion of local differential privacy (LDP) by incorporating prior knowledge and therefore achieving better utility. We study the relationships between LIP and some of the representative privacy notions including LDP, mutual information and maximal leakage. We show that LIP provides strong instance-wise privacy protection compared to other context-aware privacy notions. Moreover, we present some useful properties of LIP, including post-processing, linkage, composability, transferability and robustness to imperfect prior knowledge. Then we study a general utility-privacy tradeoff framework, under which we derive LIP based privacy-preserving mechanisms for both discrete and continuous-valued data. Three types of perturbation mechanisms are studied in this paper: 1) randomized response (RR), 2) random sampling (RS) and 3) additive noise (AN) (e.g., Gaussian mechanism). Our privacy mechanisms incorporate the prior knowledge into the perturbation parameters so as to enhance utility. Finally, we present a comprehensive set of experiments on real datasets to illustrate the advantage of context-awareness and compare the utility-privacy tradeoffs provided by different mechanisms.}
}


@article{DBLP:journals/tifs/WenZXOQ21,
	author = {Jialin Wen and
                  Benjamin Zi Hao Zhao and
                  Minhui Xue and
                  Alina Oprea and
                  Haifeng Qian},
	title = {With Great Dispersion Comes Greater Resilience: Efficient Poisoning
                  Attacks and Defenses for Linear Regression Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3709--3723},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3087332},
	doi = {10.1109/TIFS.2021.3087332},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WenZXOQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rise of third parties in the machine learning pipeline, the service provider in “Machine Learning as a Service” (MLaaS), or external data contributors in online learning, or the retraining of existing models, the need to ensure the security of the resulting machine learning models has become an increasingly important topic. The security community has demonstrated that without transparency of the data and the resulting model, there exist many potential security risks, with new risks constantly being discovered. In this paper, we focus on one of these security risks - poisoning attacks. Specifically, we analyze how attackers may interfere with the results of regression learning by poisoning the training datasets. To this end, we analyze and develop a new poisoning attack algorithm. Our attack, termed Nopt, in contrast with previous poisoning attack algorithms, can produce larger errors with the same proportion of poisoning data-points. Furthermore, we also significantly improve the state-of-the-art defense algorithm, termed TRIM, proposed by Jagielsk et al. (IEEE S&P 2018), by incorporating the concept of probability estimation of clean data-points into the algorithm. Our new defense algorithm, termed Proda, demonstrates an increased effectiveness in reducing errors arising from the poisoning dataset through optimizing ensemble models. We highlight that the time complexity of TRIM had not been estimated; however, we deduce from their work that TRIM can take exponential time complexity in the worst-case scenario, in excess of Proda's logarithmic time. The performance of both our proposed attack and defense algorithms is extensively evaluated on four real-world datasets of housing prices, loans, health care, and bike sharing services. We hope that our work will inspire future research to develop more robust learning algorithms immune to poisoning attacks.}
}


@article{DBLP:journals/tifs/AlaqlB21,
	author = {Abdulrahman Alaql and
                  Swarup Bhunia},
	title = {{SARO:} Scalable Attack-Resistant Logic Locking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3724--3739},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3092135},
	doi = {10.1109/TIFS.2021.3092135},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AlaqlB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intellectual property (IP) protection against piracy and reverse engineering (RE) has emerged as a critical area of research in the field of hardware security. Logic locking has been studied as a promising technique to provide robust protection against these attacks. However, a vast body of recent works has presented successful attacks to break existing locking methods in terms of retrieving the secret key and restoring the original functionality. In this paper, we propose SARO, a scalable attack-resistant logic locking that provides a robust functional and structural design transformation process. SARO treats the target circuit as a hypergraph (G), and performs partitioning of G to produce a set of sub-graphs, then applies an efficient Truth Table Transformation (T3) process to each partition. Further, to mitigate specific attacks (such as SAT-based analysis), SARO implements distributed attack resistance, which integrates random SAT-hard functions (obtained from an automatic function generator, RanSAT) into select partitions. RanSAT produces non-biased and non-deterministic design transformations, where added locking mechanisms are not distinguishable from the original circuit. Finally, it implements a concept of a derived key generation that simultaneously helps to minimize the required key size through judicious reuse of key bits, as well as enhancing the structural alterations. Unlike state-of-the-art logic locking solutions, which focus on primarily enhancing robustness against functional query-based attacks, the proposed transformation steps provide the following unique benefits: (1) high scalability to large designs obtained through partitioning; (2) high structural obfuscation leading to resistance to structural attacks; and (3) low key size, while maintaining strong resistance against functional attacks. To quantitatively represent the level of structural and functional transformation, we also propose the T3 metric . We evaluate SARO on ISCAS85 and EPFL benchmarks, and provide comprehensive security and performance analysis of our proposed framework.}
}


@article{DBLP:journals/tifs/MeftahTMAVC21,
	author = {Souhail Meftah and
                  Benjamin Hong Meng Tan and
                  Chan Fook Mun and
                  Khin Mi Mi Aung and
                  Bharadwaj Veeravalli and
                  Vijay Chandrasekhar},
	title = {DOReN: Toward Efficient Deep Convolutional Neural Networks with Fully
                  Homomorphic Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3740--3752},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3090959},
	doi = {10.1109/TIFS.2021.3090959},
	timestamp = {Mon, 28 Aug 2023 21:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MeftahTMAVC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fully homomorphic encryption (FHE) is a powerful cryptographic primitive to secure outsourced computations against an untrusted third-party provider. With the growing demand for AI and the usefulness of machine learning as a service (MLaaS), the need for secure training and inference of artificial neural networks is rising. However, the computational complexity of existing FHE schemes has been a strong deterrent to this. Prior works suffered from accuracy degradation, lack of scalability, and ciphertext expansion issues. In this paper, we take the first step towards the problem of space-efficiency in evaluating deep neural networks through designing DOReN: a low depth, batched neuron that can simultaneously evaluate multiple quantized ReLU-activated neurons on encrypted data without approximations. Our circuit design reduced the complexity of the accumulator circuit depth from O(logm ·logn) to O(logm + logn) for n bit integers. The experimental results show that the amortized processing time of our homomorphic neuron is approximately 1.26 seconds for 300 inputs and less than 0.13 seconds for 10 inputs at 80 bit security, which is a 20 fold improvement upon Lou and Jiang, NeurIPS 2019.}
}


@article{DBLP:journals/tifs/QuZXLL21,
	author = {Zhe Qu and
                  Shangqing Zhao and
                  Jie Xu and
                  Zhuo Lu and
                  Yao Liu},
	title = {How to Test the Randomness From the Wireless Channel for Security?},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3753--3766},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3092051},
	doi = {10.1109/TIFS.2021.3092051},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QuZXLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We revisit the traditional framework of wireless secret key generation, where two parties leverage the wireless channel randomness to establish a secret key. The essence in the framework is to quantify channel randomness into bit sequences for key generation. Conducting randomness tests on such bit sequences has been a common practice to provide the confidence to validate whether they are random. Interestingly, despite different settings in the tests, existing studies interpret the results the same: passing tests means that the bit sequences are indeed random. In this paper, we investigate how to properly test the wireless channel randomness to ensure enough security strength and key generation efficiency. In particular, we define an adversary model that leverages the imperfect randomness of the wireless channel to search the generated key, and create a guideline to set up randomness testing and privacy amplification to eliminate security loss and achieve efficient key generation rate. We use theoretical analysis and comprehensive experiments to reveal that common practice misuses randomness testing and privacy amplification: (i) no security insurance of key strength, (ii) low efficiency of key generation rate. After revision by our guideline, security loss can be eliminated and key generation rate can be increased significantly.}
}


@article{DBLP:journals/tifs/ChenNCLG21,
	author = {Juncheng Chen and
                  Jun{-}Sheng Ng and
                  Kwen{-}Siong Chong and
                  Zhiping Lin and
                  Bah{-}Hwee Gwee},
	title = {A Novel Normalized Variance-Based Differential Power Analysis Against
                  Masking Countermeasures},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3767--3779},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3093783},
	doi = {10.1109/TIFS.2021.3093783},
	timestamp = {Tue, 19 Sep 2023 13:04:04 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenNCLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose two normalization techniques to reduce the ghost peaks occurring in Differential Power Analysis (DPA). Ghost peaks can be defined as the DPA output generated by the wrong key guesses, having higher amplitudes than the DPA output generated by the correct key guess. We further propose variance-based Differential Power Analysis (vDPA) to attack masked crypto devices. The proposed normalization techniques and vDPA constitute four contributions. First, based on the side-channel signal modeling with the linear coefficient representing the strength of the linear component in a side-channel signal, we formulate the condition function of linear coefficients for the appearance of ghost peaks in DPA. Second, we propose pre-normalization in DPA and mathematically analyze how it can reduce ghost peaks by modulating the strength of the linear components in side-channel signals. Third, we propose post-normalization and mathematically analyze how it can reduce ghost peaks by de-correlating the strength of the linear components in side-channel signals with the condition function for the appearance of ghost peaks. Fourth, we propose vDPA to apply simultaneously with either one of the proposed normalization techniques to effectively attack masked crypto devices. Based on the experiments, we show that the proposed basic vDPA (without normalization), pre-normalized vDPA and post-normalized vDPA are all able to reveal the secret key from ASCAD data set. The pre- and post-normalized vDPAs require up to 18× and 14× fewer traces than the basic vDPA respectively. While attacking ASCAD data set, the proposed pre- and post-normalized vDPAs are both 13, 095× faster than the reported 2nd order CPA, and reveal the key-bytes successfully with only half of side-channel traces required by the reported Zero-offset DPA.}
}


@article{DBLP:journals/tifs/Tarrias-MunozMR21,
	author = {Antonio Tarr{\'{\i}}as{-}Mu{\~{n}}oz and
                  Jos{\'{e}} Luis Matez{-}Bandera and
                  Pablo Ram{\'{\i}}rez{-}Espinosa and
                  Francisco Javier L{\'{o}}pez{-}Mart{\'{\i}}nez},
	title = {Effect of Correlation Between Information and Energy Links in Secure
                  Wireless Powered Communications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3780--3789},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3090937},
	doi = {10.1109/TIFS.2021.3090937},
	timestamp = {Mon, 26 Sep 2022 12:22:17 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/Tarrias-MunozMR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate the impact of correlation between the energy and information links in wireless power transfer systems, from a physical layer security perspective. With that aim, we first determine how correlation can affect system capacity in practical energy harvesting set-ups. We quantify that even though link correlation improves the average signal-to-noise ratio (SNR) for a fixed transmit power, it also increases its variance, which ultimately degrades capacity. Based on this observation, we show that correlation between the energy and information links may be detrimental for the secrecy capacity in the legitimate high SNR regime, but beneficial in the low-SNR regime, whenever such correlation affects the legitimate user. Conversely, we also point out that when link correlation between the energy and wiretap links is rigorously accounted for, it barely affects secrecy performance, causing only a minor degradation in some instances.}
}


@article{DBLP:journals/tifs/ItoSUH21,
	author = {Akira Ito and
                  Kotaro Saito and
                  Rei Ueno and
                  Naofumi Homma},
	title = {Imbalanced Data Problems in Deep Learning-Based Side-Channel Attacks:
                  Analysis and Solution},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3790--3802},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3092050},
	doi = {10.1109/TIFS.2021.3092050},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ItoSUH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the threat of profiling attacks using deep learning has emerged. Successful attacks have been demonstrated against various types of cryptographic modules. However, the application of deep learning to side-channel attacks (SCAs) is often not adequately assessed because the labels that are widely used in SCAs, such as the Hamming weight (HW) and Hamming distance (HD), follow an imbalanced distribution. This study analyzes and solves the problems caused by dataset imbalance during training and inference. First, we state the reasons for the negative effect of data imbalance in classification for deep-learning-based SCAs and introduce the Kullback-Leibler (KL) divergence as a metric to measure this effect. Using the KL divergence, we demonstrate through analysis how the recently reported cross-entropy ratio loss function can solve the problem of imbalanced data. We further propose a method to solve dataset imbalance at the inference phase, which utilizes a likelihood function based on the key value instead of the HW/HD. The proposed method can be easily applied in deep-learning-based SCAs because it only needs an extra multiplication of the inverted binomial coefficients and inference results (i.e., the output probabilities) from the conventionally trained model. The proposed solution corresponds to data-augmentation techniques at the training phase, and furthermore, it better estimates the keys because the probability distributions of the training and test data are preserved. We demonstrate the validity of our analysis and the effectiveness of our solution through extensive experiments on two public databases.}
}


@article{DBLP:journals/tifs/KhatunDSF21,
	author = {Amena Khatun and
                  Simon Denman and
                  Sridha Sridharan and
                  Clinton Fookes},
	title = {End-to-End Domain Adaptive Attention Network for Cross-Domain Person
                  Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3803--3813},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3088012},
	doi = {10.1109/TIFS.2021.3088012},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KhatunDSF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Person re-identification (re-ID) remains challenging in a real-world scenario, as it requires a trained network to generalise to totally unseen target data in the presence of variations across domains. Recently, generative adversarial models have been widely adopted to enhance the diversity of training data. These approaches, however, often fail to generalise to other domains, as existing generative person re-identification models have a disconnect between the generative component and the discriminative feature learning stage. To address the on-going challenges regarding model generalisation, we propose an end-to-end domain adaptive attention network to jointly translate images between domains and learn discriminative re-id features in a single framework. To address the domain gap challenge, we introduce an attention module for image translation from source to target domains without affecting the identity of a person. More specifically, attention is directed to the background instead of the entire image of the person, ensuring identifying characteristics of the subject are preserved. The proposed joint learning network results in a significant performance improvement over state-of-the-art methods on several challenging benchmark datasets.}
}


@article{DBLP:journals/tifs/MuelichMOF21,
	author = {Sven M{\"{u}}elich and
                  Holger Mandry and
                  Maurits Ortmanns and
                  Robert F. H. Fischer},
	title = {A Multilevel Coding Scheme for Multi-Valued Physical Unclonable Functions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3814--3827},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3089883},
	doi = {10.1109/TIFS.2021.3089883},
	timestamp = {Wed, 15 Dec 2021 10:31:55 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MuelichMOF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical unclonable functions (PUFs) produce responses by exploiting randomness that intrinsically occurs in integrated circuits due to uncontrollable variations in the manufacturing process of physical items. It is common practice that PUFs generate binary responses. Recently, it has been proposed to extract symbols from a higher-order alphabet in order to increase the length of the final response. In this paper, coding for this concept of multi-valued PUFs (MV-PUFs) is derived from the analogy to pulse-amplitude modulation in digital communications. To that end, based on ROPUF measurement data, we replace the classical binary symmetric channel model by a suited additive white Gaussian noise model. Consequently, the hard-input binary channel coding scheme is replaced by methods from coded modulation, utilizing the soft output. In addition, the functionality of helper data, which are required to stabilize noisy PUF responses, is transferred to the multi-valued case. By applying the designed methods to the available measurement data we eventually show that imagining the analog PUF output as\nM\n-ary amplitude-shift keying symbols observed over an AWGN channel, both the extracted entropy per response symbol and the reliability of the final key can be increased.}
}


@article{DBLP:journals/tifs/ChakrabortyCAB21,
	author = {Prabuddha Chakraborty and
                  Jonathan Cruz and
                  Abdulrahman Alaql and
                  Swarup Bhunia},
	title = {{SAIL:} Analyzing Structural Artifacts of Logic Locking Using Machine
                  Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3828--3842},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3096028},
	doi = {10.1109/TIFS.2021.3096028},
	timestamp = {Wed, 01 Feb 2023 21:19:32 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChakrabortyCAB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Obfuscation or Logic locking (LL) is a technique for protecting hardware intellectual property (IP) blocks against diverse threats, including IP theft, reverse engineering, and malicious modifications. State-of-the-art locking techniques primarily focus on securing a design from unauthorized usage by disabling correct functionality – they often do not directly address hiding design intent through structural transformations. They rely on the synthesis tool to introduce structural changes. We observe that this process is insufficient as the resulting changes in circuit topology are: (1) local and (2) predictable. In this paper, we analyze the structural transformations introduced by LL and introduce a potential attack, called SAIL, that can exploit structural artifacts introduced by LL. SAIL uses machine learning (ML) guided structural recovery that exposes a critical vulnerability in these techniques. Through this attack, we demonstrate that the gate-level structure of a locked design can be retrieved in most parts through a systematic set of steps. The proposed attack is applicable to most forms of logic locking, and significantly more powerful than existing attacks, e.g., SAT-based attacks, since it does not require the availability of golden functional responses (e.g., an unlocked IC). Evaluation on benchmark circuits shows that we can recover an average of about 92%, up to 97%, transformations (Top-10 R-Metric) introduced by logic locking. We show that this attack is scalable, flexible, and versatile. Additionally, to evaluate the SAIL attack resilience of a locked design, we present the SIVA-Metric that is fast in terms of computation speed and does not require any training. We also propose possible mitigation steps for incorporating SAIL resilience into a locked design.}
}


@article{DBLP:journals/tifs/WangIHC21,
	author = {Xin Wang and
                  Hideaki Ishii and
                  Jianping He and
                  Peng Cheng},
	title = {Dynamic Privacy-Aware Collaborative Schemes for Average Computation:
                  {A} Multi-Time Reporting Case},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3843--3858},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3096121},
	doi = {10.1109/TIFS.2021.3096121},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangIHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative computing is efficient to conduct large-scale computation tasks, especially with the surge in data volume. However, when the data contains sensitive information, privacy has to be attached significant attention during the execution of computation tasks. In this paper, based on a two-step average computation framework, we first propose three different privacy-aware schemes, where noises are carefully designed to be injected into the distributed computing process. The challenging issue is to guarantee the privacy loss in each iteration to be controllable and quantifiable, which we call the dynamic privacy-preserving collaborative computing problem. By employing Kullback-Leibler differential privacy, we obtain the privacy preserving levels in different iterations regarding the three schemes, followed by the analysis of their convergence performances. Further, we devise an approach to balance the privacy loss and the computation accuracy, whose challenge lies in how to motivate data contributors (DCs) to report more accurate data without providing them with monetized payments. This is done by allowing DCs to report data multiple times, and we obtain the optimal reporting times for each DC. Finally, extensive numerical experiments are performed to validate the obtained theoretical results.}
}


@article{DBLP:journals/tifs/CamtepeDMMNPP21,
	author = {Seyit Camtepe and
                  Jarek Duda and
                  Arash Mahboubi and
                  Pawel Morawiecki and
                  Surya Nepal and
                  Marcin Pawlowski and
                  Josef Pieprzyk},
	title = {Compcrypt-Lightweight ANS-Based Compression and Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3859--3873},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3096026},
	doi = {10.1109/TIFS.2021.3096026},
	timestamp = {Mon, 27 Nov 2023 13:31:32 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CamtepeDMMNPP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Compression is widely used in Internet applications to save communication time, bandwidth and storage. Recently invented by Jarek Duda asymmetric numeral system (ANS) offers an improved efficiency and a close to optimal compression. The ANS algorithm has been deployed by major IT companies such as Facebook, Google and Apple. Compression by itself does not provide any security (such as confidentiality or authentication of transmitted data). An obvious solution to this problem is an encryption of compressed bitstream. However, it requires two algorithms: one for compression and the other for encryption. In this work, we investigate natural properties of ANS that allow to incorporate authenticated encryption using as little cryptography as possible. We target low-level security communication and storage such as transmission of data from IoT devices/sensors. In particular, we propose three solutions for joint compression and encryption (compcrypt). The solutions offer different tradeoffs between security and efficiency assuming a slight compression deterioration. All of them use a pseudorandom bit generator (PRBG) based on lightweight stream ciphers. The first solution is close to original ANS and applies state jumps controlled by PRBG. The second one employs two copies of ANS, where compression is switched between the copies. The switch is controlled by a PRBG bit. The third compcrypt modifies the encoding function of ANS depending on PRBG bits. Security and efficiency of the proposed compcrypt algorithms are evaluated. The first compcrypt is the most efficient with a slight loss of compression quality. The second one consumes more storage but the loss of compression quality is negligible. The last compcrypt offers the best security but is the least efficient.}
}


@article{DBLP:journals/tifs/HuaLZYM21,
	author = {Guang Hua and
                  Han Liao and
                  Haijian Zhang and
                  Dengpan Ye and
                  Jiayi Ma},
	title = {Robust {ENF} Estimation Based on Harmonic Enhancement and Maximum
                  Weight Clique},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3874--3887},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3099697},
	doi = {10.1109/TIFS.2021.3099697},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuaLZYM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The electric network frequency (ENF) is an important and extensively researched forensic criterion to authenticate digital recordings, but currently it is still challenging to extract reliable ENF traces from recordings in uncontrollable environments. In this paper, we present a framework for robust ENF extraction from real-world audio recordings, featuring multi-tone harmonic ENF enhancement and graph-based harmonic selection. We first extend the recently developed single-tone robust filtering algorithm (RFA) to the multi-tone scenario and propose a harmonic robust filtering algorithm (HRFA). It can enhance each harmonic component without cross-component interference, thus alleviating the effects of unwanted noise and audio content. In addition, considering the fact that some harmonic components could still be severely corrupted after the HRFA, interfering rather than facilitating ENF estimation, we propose a graph-based harmonic selection algorithm (GHSA), which finds a subset of harmonic components having the overall highest mutual cross-correlation. Noticeably, the harmonic selection problem is found to be equivalent to the maximum weight clique problem in graph theory, and the Bron-Kerbosch algorithm is adopted in the GHSA. With the enhanced and carefully selected harmonic components, both the existing maximum likelihood estimator (MLE) and weighted MLE are incorporated to yield the final ENF estimation results. The proposed framework is evaluated using both synthetic signals and the ENF-WHU dataset consisting of 130 real-world audio recordings, demonstrating its advantages over both the existing single- and multi-tone competitors. This work further improves the applicability of the ENF as a forensic criterion in real-world situations.}
}


@article{DBLP:journals/tifs/FengSXW21,
	author = {Xia Feng and
                  Qichen Shi and
                  Qingqing Xie and
                  Liangmin Wang},
	title = {{P2BA:} {A} Privacy-Preserving Protocol With Batch Authentication
                  Against Semi-Trusted RSUs in Vehicular Ad Hoc Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3888--3899},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3098971},
	doi = {10.1109/TIFS.2021.3098971},
	timestamp = {Wed, 25 Jan 2023 09:56:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FengSXW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular Ad-hoc Networks (VANETs) supporting the seamless operation of autonomous vehicles introduce various network-connected devices. The widespread devices are engaged in VANETs so that users can enjoy advantageous computing and reliable services. The combination brings in massive real-time message propagation and dissemination, which would be leveraged by the adversaries to perform data association, integration analysis and privacy mining. To address such challenges, existing authentication schemes use n pseudonym certificates for pre-defined k times and try to keep the vehicles anonymous. These schemes require fresh certificates for each authentication process, which cost more communication and storage resources. In this paper, we propose a novel privacy-preserving authentication protocol (P2BA) in bilinear groups, where a registered vehicle signs a traffic-related message and sends it to the nearby Road-side Unit (RSU) together with its blinded certificate. The RSU is able to independently check the message for validity based on a non-interactive zero-knowledge proof protocol. In this way, the computation time has been reduced from O (n) to O (1) while the storage overhead from O (nk) to O (n) compared to anonymous authentication protocols. Moreover, our scheme provides privacy properties such as anonymity and unlinkability. The simulations show that the message authentication can be processed by individual RSUs within 1 ms under the batch-enabled scheme, which outperforms the existing schemes in terms of computation overhead and latency.}
}


@article{DBLP:journals/tifs/DuttaBV21,
	author = {Arijit Dutta and
                  Suyash Bagad and
                  Saravanan Vijayakumaran},
	title = {MProve+: Privacy Enhancing Proof of Reserves Protocol for Monero},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3900--3915},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3088035},
	doi = {10.1109/TIFS.2021.3088035},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DuttaBV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proof of reserves protocols enable cryptocurrency exchanges to prove solvency, i.e. prove that they have enough reserves to meet their liabilities towards their customers. MProve (EuroS&PW, 2019) was the first proof of reserves protocol for Monero which provided some privacy to the exchanges' addresses. As the key images and the addresses are inherently linked in the MProve proof, an observer could easily recognize the exchange-owned address when a transaction spending from it appears on the blockchain. This is detrimental for an exchange's privacy and becomes a natural reason for exchanges to not adopt MProve. To this end, we propose MProve+, a Bulletproofs-based (S&P, 2018) NIZK protocol, which unlinks the key images and the addresses, thus alleviating the drawback of MProve. Furthermore, MProve+ presents a promising alternative to MProve due to an order of magnitude smaller proof sizes along with practical proof generation and verification times.}
}


@article{DBLP:journals/tifs/WangSHZCY21,
	author = {Shengling Wang and
                  Lina Shi and
                  Qin Hu and
                  Junshan Zhang and
                  Xiuzhen Cheng and
                  Jiguo Yu},
	title = {Privacy-Aware Data Trading},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3916--3927},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3099699},
	doi = {10.1109/TIFS.2021.3099699},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangSHZCY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing threat of personal data breach in data trading pinpoints an urgent need to develop countermeasures for preserving individual privacy. The state-of-the-art work either endows the data collector with the responsibility of data privacy or reports only a privacy-preserving version of the data. The basic assumption of the former approach that the data collector is trustworthy does not always hold true in reality, whereas the latter approach reduces the value of data. In this paper, we investigate the privacy leakage issue from the root source. Specifically, we take a fresh look to reverse the inferior position of the data provider by making her dominate the game with the collector to solve the dilemma in data trading. To that aim, we propose the noisy-sequentially zero-determinant (NSZD) strategies by tailoring the classical zero-determinant strategies, originally designed for the simultaneous-move game, to adapt to the noisy sequential game. NSZD strategies can empower the data provider to unilaterally set the expected payoff of the data collector or enforce a positive relationship between her and the data collector's expected payoffs. Both strategies can stimulate a rational data collector to behave honestly, boosting a healthy data trading market. Numerical simulations are used to examine the impacts of key parameters and the feasible region where the data provider can be an NSZD player. Finally, we prove that the data collector cannot employ NSZD to further dominate the data market for deteriorating privacy leakage.}
}


@article{DBLP:journals/tifs/TianXLLXLZW21,
	author = {Hangyu Tian and
                  Kaiping Xue and
                  Xinyi Luo and
                  Shaohua Li and
                  Jie Xu and
                  Jianqing Liu and
                  Jun Zhao and
                  David S. L. Wei},
	title = {Enabling Cross-Chain Transactions: {A} Decentralized Cryptocurrency
                  Exchange Protocol},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3928--3941},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3096124},
	doi = {10.1109/TIFS.2021.3096124},
	timestamp = {Thu, 21 Dec 2023 15:38:27 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TianXLLXLZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inspired by Bitcoin, many different kinds of cryptocurrencies based on blockchain technology have turned up on the market. Due to the special structure of the blockchain, it has been deemed impossible to directly trade between traditional currencies and cryptocurrencies or between different types of cryptocurrencies. Generally, trading between different currencies is conducted through a centralized third-party platform. However, it has the problem of a single point of failure, which is vulnerable to attacks and thus affects the security of the transactions. In this paper, we propose a distributed cryptocurrency trading scheme to solve the problem of centralized exchanges, which can achieve secure trading between different types of cryptocurrencies. Our scheme is implemented with smart contracts on an Ethereum blockchain and deployed on an Ethereum test network. In addition to implementing transactions between individual users, our scheme also allows transactions among multiple users. The experimental result proves that the cost of our scheme is acceptable.}
}


@article{DBLP:journals/tifs/TerhorstFKDKK21,
	author = {Philipp Terh{\"{o}}rst and
                  Daniel F{\"{a}}hrmann and
                  Jan Niklas Kolf and
                  Naser Damer and
                  Florian Kirchbuchner and
                  Arjan Kuijper},
	title = {MAAD-Face: {A} Massively Annotated Attribute Dataset for Face Images},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3942--3957},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3096120},
	doi = {10.1109/TIFS.2021.3096120},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TerhorstFKDKK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Soft-biometrics play an important role in face biometrics and related fields since these might lead to biased performances, threaten the user's privacy, or are valuable for commercial aspects. Current face databases are specifically constructed for the development of face recognition applications. Consequently, these databases contain a large number of face images but lack in the number of attribute annotations and the overall annotation correctness. In this work, we propose a novel annotation-transfer pipeline that allows to accurately transfer attribute annotations from multiple source datasets to a target dataset. The transfer is based on a massive attribute classifier that can accurately state its prediction confidence. Using these prediction confidences, a high correctness of the transferred annotations is ensured. Applying this pipeline to the VGGFace2 database, we propose the MAAD-Face annotation database. It consists of 3.3M faces of over 9k individuals and provides 123.9M attribute annotations of 47 different binary attributes. Consequently, it provides 15 and 137 times more attribute annotations than CelebA and LFW. Our investigation on the annotation quality by three human evaluators demonstrated the superiority of the MAAD-Face annotations over existing databases. Additionally, we make use of the large number of high-quality annotations from MAAD-Face to study the viability of soft-biometrics for recognition, providing insights into which attributes support genuine and imposter decisions. The MAAD-Face annotations dataset is publicly available.}
}


@article{DBLP:journals/tifs/ZhangHWLGZ21,
	author = {Yin Zhang and
                  Zhangqing He and
                  Meilin Wan and
                  Jiuyang Liu and
                  Haoshuang Gu and
                  Xuecheng Zou},
	title = {A {SC} {PUF} Standard Cell Used for Key Generation and Anti-Invasive-Attack
                  Protection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3958--3973},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3089854},
	doi = {10.1109/TIFS.2021.3089854},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangHWLGZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By using metal blocks as the protective coating, placing the sensitive signals in last but second metal (LSM), integrating a low-cost one-time programming (OTP) cell in each PUF unit, the proposed switched-capacitor (SC) PUF can both provide sensitive anti-invasive-attack protective coating and stable key for the security chip. Moreover, the circuit parameters and the layout implementation of the SC PUF unit are all compatible with other digital standard cells, which greatly facilitates the integration of SC PUF unit in the security chip by using digital design flow when its function, timing, power, and layout views are characterized using commercial timing and layout extraction tools. The anti-invasive-attack ability, stability, and digital design flow compatibility of the proposed SC PUF standard cell are verified in a security chip by using a standard 0.18- μm CMOS process. The measured bit error rate, bias, average intra-die HD, and average inter-die HD of output keys after OTP is <; 10 -4 , 46.72%, 0%, and 50.38% respectively. Finally, the failed probing and destruction attack attempts to the coating also verify the invasive-attack-resistant property of the proposed SC PUF standard cell. With the help of SC PUF standard cell, the whole security chip can easily obtain stable keys and sensitive anti-invasive-attack ability by using digital design flow.}
}


@article{DBLP:journals/tifs/ZhangWSVMC21,
	author = {Junqing Zhang and
                  Roger F. Woods and
                  Magnus Sandell and
                  Mikko Valkama and
                  Alan Marshall and
                  Joseph R. Cavallaro},
	title = {Radio Frequency Fingerprint Identification for Narrowband Systems,
                  Modelling and Classification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3974--3987},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3088008},
	doi = {10.1109/TIFS.2021.3088008},
	timestamp = {Wed, 16 Mar 2022 23:54:26 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangWSVMC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device authentication is essential for securing Internet of things. Radio frequency fingerprint identification (RFFI) is an emerging technique that exploits intrinsic and unique hardware impairments as the device identifier. The existing RFFI literature focuses on experimental exploration but comprehensive modelling is missing. This paper systematically models impairments of transmitter and receiver in narrowband systems and carries out extensive experiments and simulations to evaluate their effects on RFFI. The modelled impairments include oscillator imperfections, imbalance of inphase (I) and quadrature (Q) branches of mixers and power amplifier (PA) nonlinearity. We then propose a convolutional neural network-based RFFI protocol. We carry out experimental measurements over three months and demonstrate that oscillator imperfections are not suitable for RFFI due to their unpredictable time variation caused by temperature change. Our simulation results show that our protocol can classify 50 and 200 devices with uniformly and randomly distributed IQ imbalances and PA nonlinearities with high accuracy, namely 99% and 89%, respectively. We also show that the RFFI has some tolerance on different receiver imbalances during training and classification. Specifically, the accuracy is shown to degrade less than 20% when the residual receiver's gain and phase imbalances are small. Based on the experimental and simulation results, we made recommendations for designing a robust RFFI protocol, namely compensate carrier frequency offset and calibrate IQ imbalances of receivers.}
}


@article{DBLP:journals/tifs/GaoZWDEMLW21,
	author = {Lili Gao and
                  Fangyu Zheng and
                  Rong Wei and
                  Jiankuo Dong and
                  Niall Emmart and
                  Yuan Ma and
                  Jingqiang Lin and
                  Charles C. Weems},
	title = {{DPF-ECC:} {A} Framework for Efficient {ECC} With Double Precision
                  Floating-Point Computing Power},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {3988--4002},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3098987},
	doi = {10.1109/TIFS.2021.3098987},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GaoZWDEMLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Used ubiquitously in a huge amount of security protocols or applications, elliptic curve cryptography (ECC) is one of the most important cryptographic primitives, featuring efficiency and short key size compared with other public-key cryptosystems such as DSA and RSA. However, as a computation-intensive public-key cryptographic primitive, ECC arithmetic is still the bottleneck that restrains the overall performance of the end applications. In this paper, instead of the conventional and straightforward integer-based methods, we present a general framework to accelerate ECC schemes over prime field, called DPF-ECC, that deeply exploits double precision floating-point (DPF) computing power. The DPF-ECC framework finely manages each bit of the DPF numbers and minimizes the overhead brought by additional data format conversion, by making use of the DPF representation, the rounding operations, and fused multiply-add instruction supported by the IEEE 754 floating point standard. We also conduct two comprehensive case studies on Crandall primes and Solinas primes to demonstrate how the DPF-ECC framework is applied to the prevailing ECC schemes. To evaluate the proposed DPF-ECC framework in the real world, leveraging the floating-point computing power of GPUs, we implement Curve25519/448 and Edwards25519/448, the popular ECC schemes widely used in TLS 1.3, SSH, etc. The experimental result in Tesla P100 achieves a record-setting performance that outperforms the existing fastest integer work with 2x to 3x throughput. With dependency only on the very commonly supported IEEE 754 floating point standard, DPF-ECC framework can be a very competent and promising candidate for ECC implementation in most of general-purpose platforms.}
}


@article{DBLP:journals/tifs/CohenCG21,
	author = {Alejandro Cohen and
                  Asaf Cohen and
                  Omer Gurewitz},
	title = {Secure Group Testing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4003--4018},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029877},
	doi = {10.1109/TIFS.2020.3029877},
	timestamp = {Mon, 28 Aug 2023 21:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CohenCG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The principal goal of Group Testing (GT) is to identify a small subset of “defective” items from a large population, by grouping items into as few test pools as possible. The test outcome of a pool is positive if it contains at least one defective item, and is negative otherwise. GT algorithms are utilized in numerous applications, and in many of them maintaining the privacy of the tested items, namely, keeping secret whether they are defective or not, is critical. In this paper, we consider a scenario where there is an eavesdropper (Eve) who is able to observe a subset of the GT outcomes (pools). We propose a new non-adaptive Secure Group Testing (SGT) scheme based on information-theoretic principles. The new proposed test design keeps the eavesdropper ignorant regarding the items’ status. Specifically, when the fraction of tests observed by Eve is 0 \\leq \\delta < 1\n, we prove that with the naive Maximum Likelihood (ML) decoding algorithm the number of tests required for both correct reconstruction at the legitimate user (with high probability) and negligible information leakage to Eve is \\frac {1}{1-\\delta }\ntimes the number of tests required with no secrecy constraint for the fixed K\nregime. By a matching converse, we completely characterize the Secure GT capacity. Moreover, we consider the Definitely Non-Defective (DND) computationally efficient decoding algorithm, proposed in the literature for non-secure GT. We prove that with the new secure test design, for \\delta < 1/2\n, the number of tests required, without any constraint on K\n, is at most \\frac {1}{1/2-\\delta }\ntimes the number of tests required with no secrecy constraint.}
}


@article{DBLP:journals/tifs/KongSWCH21,
	author = {Zhengmin Kong and
                  Jing Song and
                  Chao Wang and
                  Hongyang Chen and
                  Lajos Hanzo},
	title = {Hybrid Analog-Digital Precoder Design for Securing Cognitive Millimeter
                  Wave Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4019--4034},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3039697},
	doi = {10.1109/TIFS.2020.3039697},
	timestamp = {Mon, 28 Aug 2023 21:40:51 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KongSWCH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Millimeter wave (mmWave) communications and cognitive radio technologies constitute key technologies of improving the spectral efficiency of communications. Hence, we conceive a hybrid secure precoder for enhancing the physical layer security of a cognitive mmWave wiretap channel, where a secondary transmitter broadcasts confidential information signals to multiple secondary users under the interference temperature constraint of the primary user (PU). The optimization problem is formulated as jointly optimizing the analog and digital precoder for maximizing the minimum secrecy rate of all the secondary users under practical constraints. In particular, our design satisfies the constraint on the maximum interference power received by multiple PUs, as well as the secondary users' minimum quality-of-service (Qos), and the unit-modulus constraint on the analog precoder. Due to the non-convexity of the resultant objective function and owing to the coupling between the analog and digital precoder, the optimization problem formulated is nonconvex and nonlinear, hence it is very challenging to solve directly. Hence, we first transform it into a tractable form, and develop a penalty dual decomposition (PDD) based iterative algorithm to locate its Karush-Kuhn-Tucker (KKT) solution. Finally, we generalize the proposed PDD algorithm to a secure hybrid precoder design relying on practical finite-resolution phase shifters and show that the proposed PDD algorithm can be straightforwardly adapted to handle the scenario, where each PU is equipped with multiple antennas and the CSI of multiple eavesdroppers (Eves) is imperfectly known. Our simulation results validate the efficiency of the proposed iterative algorithm.}
}


@article{DBLP:journals/tifs/TalukderFR21,
	author = {Bashir M. Sabquat Bahar Talukder and
                  Farah Ferdaus and
                  Md. Tauhidur Rahman},
	title = {Memory-Based PUFs are Vulnerable as Well: {A} Non-Invasive Attack
                  Against {SRAM} PUFs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4035--4049},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3101045},
	doi = {10.1109/TIFS.2021.3101045},
	timestamp = {Wed, 15 Feb 2023 22:11:05 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TalukderFR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Memory-based physical unclonable functions (mPUFs) are widely accepted as highly secure because of the unclonable and immutable nature of manufacturer process variations. Although numerous successful attacks have been proposed against PUFs, mPUFs are resistant to non-invasive attacks as the mPUF does not support the open-access protocol. Hence, existing attacks against mPUFs mostly rely on invasive/semi-invasive techniques or at least require physical access to the target device, which is not always feasible. In this paper, we experimentally demonstrate that signatures generated from two memory chips may have highly correlated properties if they possess the same set of specifications and a similar manufacturing facility, which is used to mount a non-invasive attack against memory-based PUFs. Our proposed technique shows that if an attacker has access to a device similar to the victim's one, the attacker might be able to guess up to ~45% of the challenge-response pairs of a 64-bit SRAM PUF.}
}


@article{DBLP:journals/tifs/WangHLXMS21,
	author = {Yuanhao Wang and
                  Qiong Huang and
                  Hongbo Li and
                  Meiyan Xiao and
                  Sha Ma and
                  Willy Susilo},
	title = {Private Set Intersection With Authorization Over Outsourced Encrypted
                  Datasets},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4050--4062},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3101059},
	doi = {10.1109/TIFS.2021.3101059},
	timestamp = {Wed, 20 Sep 2023 13:32:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangHLXMS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Thanks to its convenience and cost-savings feature, cloud computing ushers a new era. Yet its security and privacy issues must not be neglected. Private set intersection (PSI) is useful and important in many cloud computing applications, such as document similarity, genetic paternity and data mining. The cloud server performs intersection operations on two outsourced encrypted datasets of data owners. In the existing protocols, however, data owners cannot decide whether to use all or part of their encrypted data to compute the intersection, nor can they specify whom to compare with. In this paper, we introduce an enhanced notion of outsourced PSI, called authorized PSI (APSI), which supports flexible authorization and cross-type authorized comparison of datasets. To demonstrate this notion, we propose a concrete APSI protocol, and prove it to be secure in the random oracle model based on simple number-theoretic assumptions. Experimental results show that our APSI protocol has performance comparable with existing related outsourced PSI protocols.}
}


@article{DBLP:journals/tifs/ShenYZXLH21,
	author = {Meng Shen and
                  Hao Yu and
                  Liehuang Zhu and
                  Ke Xu and
                  Qi Li and
                  Jiankun Hu},
	title = {Effective and Robust Physical-World Attacks on Deep Learning Face
                  Recognition Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4063--4077},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3102492},
	doi = {10.1109/TIFS.2021.3102492},
	timestamp = {Fri, 12 May 2023 15:00:49 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShenYZXLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) have been increasingly used in face recognition (FR) systems. Recent studies, however, show that DNNs are vulnerable to adversarial examples, which potentially mislead DNN-based FR systems in the physical world. Existing attacks either generate perturbations working merely in the digital world, or rely on customized equipment to generate perturbations that are not robust in the ever-changing physical environment. In this paper, we propose FaceAdv, a physical-world attack that crafts adversarial stickers to deceive FR systems. It mainly consists of a sticker generator and a convertor, where the former can craft several stickers with different shapes while the latter aims to digitally attach stickers to human faces and provide feedback to the generator to improve the effectiveness. We conduct extensive experiments to evaluate the effectiveness of FaceAdv on attacking three typical FR systems (i.e., ArcFace, CosFace and FaceNet). The results show that compared with a state-of-the-art attack, FaceAdv can significantly improve the success rates of both dodging and impersonating attacks. We also conduct comprehensive evaluations to demonstrate the robustness of FaceAdv.}
}


@article{DBLP:journals/tifs/ZhouC21,
	author = {Lin Zhou and
                  Daming Cao},
	title = {Privacy-Utility Tradeoff for Hypothesis Testing Over a Noisy Channel},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4078--4091},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3087357},
	doi = {10.1109/TIFS.2021.3087357},
	timestamp = {Wed, 01 Sep 2021 12:46:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study a hypothesis testing problem with a privacy constraint over a noisy channel and derive the performance of optimal tests under the Neyman-Pearson criterion. The fundamental limit of interest is the privacy-utility tradeoff (PUT) between the exponent of the type-II error probability and the leakage of the information source subject to a constant constraint on the type-I error probability. We provide an exact characterization of the asymptotic PUT for any non-vanishing type-I error probability. Our result implies that tolerating a larger type-I error probability cannot improve the PUT. Such a result is known as a strong converse or strong impossibility theorem. To prove the strong converse theorem, we apply the recently proposed technique in (Tyagi and Watanabe, 2020) and further demonstrate its generality. The strong converse theorems for several problems, such as hypothesis testing against independence over a noisy channel (Sreekumar and Gündüz, 2020) and hypothesis testing with communication and privacy constraints (Gilani et al., 2020), are established or recovered as special cases of our result.}
}


@article{DBLP:journals/tifs/DesaiN21,
	author = {S. Sundeep Desai and
                  Manisha J. Nene},
	title = {Multihop Trust Evaluation Using Memory Integrity in Wireless Sensor
                  Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4092--4100},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3101051},
	doi = {10.1109/TIFS.2021.3101051},
	timestamp = {Wed, 01 Sep 2021 12:46:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DesaiN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Research efforts in trust evaluation has evolved to provide security in Wireless Sensor Networks (WSNs), while being dependent on external parameters and network topology. Existing node level trust evaluation in WSNs evaluate trust over 1-hop assuring trustworthiness of an immediate node. This paper proposes trust evaluation using the intrinsic property of a node memory over a multihop scenario which also evaluates the route. The work proposes a multihop trust evaluation protocol using TEAM and TEAP algorithms. Two proposed trust evaluation models each are proposed using normative and empirical methods in multihop algorithms. The proposed methodology establishes a trusted destination node along with trusted nodes in the route. The efficacy of the proposed work and its implementation is demonstrated using extensive experiments and the results illustrate consistency and resilience against node memory tampering.}
}


@article{DBLP:journals/tifs/HuangCW21,
	author = {Chong Huang and
                  Gaojie Chen and
                  Kai{-}Kit Wong},
	title = {Multi-Agent Reinforcement Learning-Based Buffer-Aided Relay Selection
                  in IRS-Assisted Secure Cooperative Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4101--4112},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3103062},
	doi = {10.1109/TIFS.2021.3103062},
	timestamp = {Wed, 01 Sep 2021 12:46:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangCW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a multi-agent deep reinforcement learning-based buffer-aided relay selection scheme for an intelligent reflecting surface (IRS)-assisted secure cooperative network in the presence of an eavesdropper. We consider a practical phase model where both phase shift and reflection amplitude are discrete variables to vary the reflection coefficients of the IRS. Furthermore, we introduce the buffer-aided relay to enhance the secrecy performance, but the use of the buffer leads to the cost of delay. Thus, we aim to maximize either the average secrecy rate with a delay constraint or the throughput with both delay and secrecy constraints, by jointly optimizing the buffer-aided relay selection and the IRS reflection coefficients. To obtain the solution of these two optimization problems, we divide each of the problems into two sub-tasks and then develop a distributed multi-agent reinforcement learning scheme for the two cooperative sub-tasks, each relay node represents an agent in the distributed learning. We apply the distributed reinforcement learning scheme to optimize the IRS reflection coefficients, and then utilize an agent on the source to learn the optimal relay selection based on the optimal IRS reflection coefficients in each iteration. Simulation results show that the proposed learning-based scheme uses an iterative approach to learn from the environment for approximating an optimal solution via the exploration of multiple agents, which outperforms the benchmark schemes.}
}


@article{DBLP:journals/tifs/PengZK21,
	author = {Su Peng and
                  Liang Zhao and
                  Neeraj Kumar},
	title = {Comments on "Efficient Public Verification of Data Integrity for Cloud
                  Storage Systems From Indistinguishability Obfuscation"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4113--4116},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3102413},
	doi = {10.1109/TIFS.2021.3102413},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PengZK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, Zhang et al. proposed a novel public data integrity verification scheme for the cloud storage using indistinguishability obfuscation ( iO\n), and extend it to support batch verification and data dynamic operations ( IEEE Transactions on Information Forensics and Security , vol. 12, no. 3, pp. 676–688, Mar. 2017). However, we find that the scheme has two flaws: (a) the self-checking of the uploaded blocks and tags in Store phase is not reliable, i.e., it is easy to generate invalid block-tag pairs without being detected; (b) the extended scheme for data dynamic operations suffers from a chosen message attack, i.e., if some uploaded blocks match a certain pattern, the cloud storage is able to replace any existing block by a forged one without being detected, which violates the scheme’s security model. Then, we provide solutions to these problems while preserving all the desirable features of the original scheme.}
}


@article{DBLP:journals/tifs/FanSXLL21,
	author = {Ming Fan and
                  Ziliang Si and
                  Xiaofei Xie and
                  Yang Liu and
                  Ting Liu},
	title = {Text Backdoor Detection Using an Interpretable {RNN} Abstract Model},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4117--4132},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3103064},
	doi = {10.1109/TIFS.2021.3103064},
	timestamp = {Thu, 23 Jun 2022 20:01:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FanSXLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) are known to be inherently vulnerable to malicious attacks such as the adversarial attack and the backdoor attack. The former is crafted by adding small perturbations to benign inputs so as to fool a DNN. The latter generally embeds a hidden pattern in a DNN by poisoning the dataset during the training process, which causes the infected model to misbehave on predefined inputs with a specific trigger and normally perform for others. Much work has been conducted on defending against the adversarial samples, while the backdoor attack received much less attention, especially in recurrent neural networks (RNNs), which play an important role in the text processing field. Two main limitations make it hard to directly apply existing image backdoor detection approaches to RNN-based text classification systems. First, a layer in an RNN does not preserve the same feature latent space function for different inputs, making it impossible to map the inserted specific pattern with the neural activations. Second, the text data is inherently discrete, making it hard to optimize the text like image pixels. In this work, we propose a novel backdoor detection approach named InterRNN for RNN-based text classification systems from the interpretation perspective. Specifically, we first propose a novel RNN interpretation technique by constructing a nondeterministic finite automaton (NFA) based abstract model, which can effectively reduce the analysis complexity of an RNN while preserving its original logic rules. Then, based on the abstract model, we can obtain interpretation results that explain the fundamental reason behind the decision for each input. We then detect trigger words by leveraging the differences between the behaviors in the backdoor sentences and those in the normal sentences. The extensive experiment results on four benchmark datasets demonstrate that our approach can generate better interpretation results compared to state-of-the-art approaches and effectively detect backdoors in RNNs.}
}


@article{DBLP:journals/tifs/JedhOAB21,
	author = {Mubark Jedh and
                  Lotfi Ben Othmane and
                  Noor Ahmed and
                  Bharat K. Bhargava},
	title = {Detection of Message Injection Attacks Onto the {CAN} Bus Using Similarities
                  of Successive Messages-Sequence Graphs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4133--4146},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3098162},
	doi = {10.1109/TIFS.2021.3098162},
	timestamp = {Mon, 18 Mar 2024 14:47:24 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JedhOAB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The smart features of modern cars are enabled by a number of Electronic Control Units (ECUs) components that communicate through an in-vehicle network, known as Controller Area Network (CAN) bus. The fundamental challenge is the security of the communication link where an attacker can inject messages (e.g., increase the speed) that may impact the safety of the driver. Most of existing practical IDS solutions rely on the knowledge of the identity of the ECUs, which is proprietary information. This paper proposes a message injection attack detection solution that is independent of the IDs of the ECUs. First, we represent the sequencing of the messages in a given time-interval as a direct graph and compute the similarities of the successive graphs using the cosine similarity and Pearson correlation. Then, we apply threshold, change point detection, and Long Short-Term Memory (LSTM)-Recurrent Neural Network (RNN) to detect and predict malicious message injections into the CAN bus. The evaluation of the methods using a dataset collected from a moving vehicle under malicious RPM and speed reading message injections show a detection accuracy of 97.32% and detection speed of 2.5 milliseconds when using a threshold method. The performance metrics makes the IDS suitable for real-time control mechanisms for vehicle resiliency to cyber-attacks.}
}


@article{DBLP:journals/tifs/MedenRTDKSRPS21,
	author = {Blaz Meden and
                  Peter Rot and
                  Philipp Terh{\"{o}}rst and
                  Naser Damer and
                  Arjan Kuijper and
                  Walter J. Scheirer and
                  Arun Ross and
                  Peter Peer and
                  Vitomir Struc},
	title = {Privacy-Enhancing Face Biometrics: {A} Comprehensive Survey},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4147--4183},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3096024},
	doi = {10.1109/TIFS.2021.3096024},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MedenRTDKSRPS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biometric recognition technology has made significant advances over the last decade and is now used across a number of services and applications. However, this widespread deployment has also resulted in privacy concerns and evolving societal expectations about the appropriate use of the technology. For example, the ability to automatically extract age, gender, race, and health cues from biometric data has heightened concerns about privacy leakage. Face recognition technology, in particular, has been in the spotlight, and is now seen by many as posing a considerable risk to personal privacy. In response to these and similar concerns, researchers have intensified efforts towards developing techniques and computational models capable of ensuring privacy to individuals, while still facilitating the utility of face recognition technology in several application scenarios. These efforts have resulted in a multitude of privacy-enhancing techniques that aim at addressing privacy risks originating from biometric systems and providing technological solutions for legislative requirements set forth in privacy laws and regulations, such as GDPR. The goal of this overview paper is to provide a comprehensive introduction into privacy-related research in the area of biometrics and review existing work on Biometric Privacy-Enhancing Techniques (B-PETs) applied to face biometrics. To make this work useful for as wide of an audience as possible, several key topics are covered as well, including evaluation strategies used with B-PETs, existing datasets, relevant standards, and regulations and critical open issues that will have to be addressed in the future.}
}


@article{DBLP:journals/tifs/KellerOD21,
	author = {Danny Keller and
                  Margarita Osadchy and
                  Orr Dunkelman},
	title = {Inverting Binarizations of Facial Templates Produced by Deep Learning
                  (and Its Implications)},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4184--4196},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3103056},
	doi = {10.1109/TIFS.2021.3103056},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KellerOD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We focus on attacks against a biometric authentication system aimed at reconstructing a biometric sample of the subject from the protected template. Such systems include three blocks: feature extraction, binarization, and protection. We propose a new white-box reversing attack on the binarization block that approximates a biometric template given the binary string obtained by the binarization block. The experiments show that the proposed attack reconstructs very accurate approximations that pass the verification threshold when compared to templates produced from the same and different samples of the subject. We then integrate this attack with known attacks on the other two blocks, namely, a variant of a guessing attack to extract the binary string and biometric inversion attack to reconstruct a sample from its template. We instantiate this end-to-end attack on a face authentication system using fuzzy commitments for protection. Facial images reconstructed by the end-to-end attack greatly resemble the original ones. In the simplest attack scenario, more than 83% of these reconstructed templates succeed in unlocking an account (when the system is configured to 0.1% FMR). Even in the “hardest” settings (in which we take a reconstructed image from one system and use it in a different system, with a different feature extraction process) the reconstructed image offers 170 to 210 times higher success rates than the system's FMR.}
}


@article{DBLP:journals/tifs/DongPZ21,
	author = {Guannan Dong and
                  Chi{-}Man Pun and
                  Zheng Zhang},
	title = {Deep Collaborative Multi-Modal Learning for Unsupervised Kinship Estimation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4197--4210},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3098165},
	doi = {10.1109/TIFS.2021.3098165},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DongPZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Kinship verification is a long-standing research challenge in computer vision. The visual differences presented to the face have a significant effect on the recognition capabilities of the kinship systems. We argue that aggregating multiple visual knowledge can better describe the characteristics of the subject for precise kinship identification. Typically, the age-invariant features can represent more natural facial details. Such age-related transformations are essential for face recognition due to the biological effects of aging. However, the existing methods mainly focus on employing the single-view image features for kinship identification, while more meaningful visual properties such as race and age are directly ignored in the feature learning step. To this end, we propose a novel deep collaborative multi-modal learning (DCML) to integrate the underlying information presented in facial properties in an adaptive manner to strengthen the facial details for effective unsupervised kinship verification. Specifically, we construct a well-designed adaptive feature fusion mechanism, which can jointly leverage the complementary properties from different visual perspectives to produce composite features and draw greater attention to the most informative components of spatial feature maps. Particularly, an adaptive weighting strategy is developed based on a novel attention mechanism, which can enhance the dependencies between different properties by decreasing the information redundancy in channels in a self-adaptive manner. Moreover, we propose to use self-supervised learning to further explore the intrinsic semantics embedded in raw data and enrich the diversity of samples. As such, we could further improve the representation capabilities of kinship feature learning and mitigate the multiple variations from original visual images. To validate the effectiveness of the proposed method, extensive experimental evaluations conducted on four widely-used datasets show that our DCML method is always superior to some state-of-the-art kinship verification methods.}
}


@article{DBLP:journals/tifs/FazilSA21,
	author = {Mohd Fazil and
                  Amit Kumar Sah and
                  Muhammad Abulaish},
	title = {DeepSBD: {A} Deep Neural Network Model With Attention Mechanism for
                  SocialBot Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4211--4223},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3102498},
	doi = {10.1109/TIFS.2021.3102498},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FazilSA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online Social Networks (OSNs) are witnessing sophisticated cyber threats, that are generally conducted using fake or compromised profiles. Automated agents (aka socialbots), a category of sophisticated and modern threat entities, are the native of the social media platforms and responsible for various modern weaponized information-related attacks, such as astroturfing, misinformation diffusion, and spamming. Detecting socialbots is a challenging and vital task due to their deceiving character of imitating human behavior. To this end, this paper presents an attention-aware deep neural network model, DeepSBD, for detecting socialbots on OSNs. The DeepSBD models users' behavior using profile, temporal, activity, and content information. It jointly models OSN users' behavior using Bidirectional Long Short Term Memory (BiLSTM) and Convolutional Neural Network (CNN) architectures. It models profile, temporal, and activity information as sequences, which are fed to a two-layers stacked BiLSTM, whereas content information is fed to a deep CNN. We have evaluated DeepSBD over five real-world benchmark datasets and found that it performs significantly better in comparison to the state-of-the-arts and baseline methods. We have also analyzed the efficacy of DeepSBD at different ratios of socialbots and benign users and found that an imbalanced dataset moderately affects the classification accuracy. Finally, we have analyzed the discrimination power of different behavioral components, and it is found that both profile characteristics and content behavior are most impactful, whereas diurnal temporal behavior is the least effective for detecting socialbots on OSNs.}
}


@article{DBLP:journals/tifs/LiLGLC21,
	author = {Wei Li and
                  Jiayao Li and
                  Dawu Gu and
                  Chaoyun Li and
                  Tianpei Cai},
	title = {Statistical Fault Analysis of the Simeck Lightweight Cipher in the
                  Ubiquitous Sensor Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4224--4233},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3102485},
	doi = {10.1109/TIFS.2021.3102485},
	timestamp = {Thu, 23 Jun 2022 20:01:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiLGLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of wireless technology, the ubiquitous sensor networks have a profound effect on the way human interacts with computers, devices and environment. In order to reduce the potentially serious risks in the interaction, applying lightweight ciphers is effective to balance security, efficiency and convenience. Simeck is such a lightweight cipher that provides data confidentiality, authentication and integrity. It is significant to explore whether Simeck remains robust security. Up to now, the attacking assumptions of the previous security analysis of Simeck focus on the known-plaintext attack and the chosen-plaintext attack. There is no literature about Simeck against the ciphertext-only attack, which represents the weakest attacking capability of the attackers. On the assumption of the ciphertext-only attack, this paper proposes the security analysis of Simeck against the statistical fault analysis with a series of novel distinguishers of KDE, MME and MME-GF. The experimental results show that the proposed distinguishers can recover the secret key of Simeck in both decreasing faults and increasing reliability and accuracy. Thus, Simeck cannot resist against the statistical fault analysis with the proposed distinguishers. Furthermore, the good performance of these novel distinguishers can be applied on the PRESENT lightweight cipher. It offers the valuable reference for the design and analysis of the lightweight ciphers in the ubiquitous sensor networks.}
}


@article{DBLP:journals/tifs/YangLXLG21,
	author = {Jiachen Yang and
                  Aiyun Li and
                  Shuai Xiao and
                  Wen Lu and
                  Xinbo Gao},
	title = {MTD-Net: Learning to Detect Deepfakes Images by Multi-Scale Texture
                  Difference},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4234--4245},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3102487},
	doi = {10.1109/TIFS.2021.3102487},
	timestamp = {Thu, 16 Sep 2021 18:05:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangLXLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of face manipulation technology, it is difficult for human eyes to distinguish fake face images. On the contrary, Convolutional Neural Network (CNN) discriminators can quickly reach high accuracy in identifying fake/real face images. In this study, we explore the behavior of CNN models in distinguish fake/real faces. We find multi-scale texture difference information plays an important role in face forgery detection. Motivated by the above observation, we propose a new Multi-scale Texture Difference model coined as MTD-Net for robust face forgery detection, which leverages central difference convolution (CDC) and atrous spatial pyramid pooling (ASPP). CDC combines the pixel intensity information and the pixel gradient information to give a stationary description of texture difference information. Simultaneously, based on the ASPP, multi-scale information fusion can keep the texture features from being destroyed. Experimental results on several databases, Faceforensics++, DeeperForensics-1.0, Celeb-DF and DFDC prove that our MTD-Net outperforms existing approaches. The MTD-Net is more robust to image distortion, e.g., JPEG compression and blur, which is urgently needed in the wild world.}
}


@article{DBLP:journals/tifs/WuJXC21,
	author = {Yangyang Wu and
                  Changsong Jiang and
                  Chunxiang Xu and
                  Kefei Chen},
	title = {Security Analysis of a Path Validation Scheme With Constant-Size Proof},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4246--4248},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3101043},
	doi = {10.1109/TIFS.2021.3101043},
	timestamp = {Thu, 16 Sep 2021 18:05:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuJXC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We analyze a path validation scheme with constant-size proof (published in IEEE Transactions on Information Forensics and Security) and demonstrate that this scheme fails to achieve unforgeability. An adversary can forge a valid proof with a non-negligible probability.}
}


@article{DBLP:journals/tifs/DelcourtB21,
	author = {Marguerite Delcourt and
                  Jean{-}Yves Le Boudec},
	title = {{TDOA} Source-Localization Technique Robust to Time-Synchronization
                  Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4249--4264},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3001741},
	doi = {10.1109/TIFS.2020.3001741},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DelcourtB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we focus on the localization of a passive source from time difference of arrival (TDOA) measurements. TDOA values are computed with respect to pairs of fixed sensors that are required to be accurately time-synchronized. This constitutes a weakness as all synchronization techniques are vulnerable to delay injections. Attackers are able either to spoof the signal or to inject asymmetric delays in the communication channel. By nature, TDOA measurements are highly sensitive to time-synchronization offsets between sensors. We first illustrate that time-synchronization attacks can severely affect the localization process. With a delay of a few microseconds injected on one sensor, the resulting estimate might be several kilometers away from the true location of the unknown source. We show that residual analysis does not enable the detection and identification of time-synchronization attacks. Our main contribution is then to propose a two-step TDOA-localization technique that is robust against time-synchronization attacks. It uses a known source to define a weight for each pair of sensors, reflecting the confidence in their time synchronization. Our solution then uses the weighted least-squares estimator with the newly created weights and the TDOA measurements received from the unknown source. As a result, our method either identifies the network as being too corrupt to localize, or gives a corrected estimate of the unknown position along with a confidence metric. Numerical results illustrate the performance of our technique.}
}


@article{DBLP:journals/tifs/ZhangLSJ21,
	author = {Pinchang Zhang and
                  Jun Liu and
                  Yulong Shen and
                  Xiaohong Jiang},
	title = {Exploiting Channel Gain and Phase Noise for PHY-Layer Authentication
                  in Massive {MIMO} Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4265--4279},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3029894},
	doi = {10.1109/TIFS.2020.3029894},
	timestamp = {Mon, 20 Sep 2021 09:50:39 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLSJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By exploiting two intrinsic physical (PHY)-layer features in terms of location-specific channel gain and transmitter-specific phase noise, this paper proposes a new PHY-layer authentication scheme for massive multiple-input multiple-output (MIMO) systems. In particular, we apply the linear minimum mean square error technique to estimate the time-varying channel gain and adopt extended Kalman filtering to track the time-varying phase noise. Based on the estimation error covariance matrices of channel gain and phase noise, we then formulate the PHY-layer authentication as a composite hypothesis testing problem. With the help of tools from statistical signal processing, matrix analysis, and composite hypothesis testing, we develop theoretical models to capture the false alarm and detection probability performances of the proposed scheme. Finally, we provide extensive numerical results to validate these theoretical models and to illustrate the efficiency of the proposed authentication scheme.}
}


@article{DBLP:journals/tifs/WangSXFW21,
	author = {Yahang Wang and
                  Xiaoning Song and
                  Tianyang Xu and
                  Zhen{-}Hua Feng and
                  Xiaojun Wu},
	title = {From {RGB} to Depth: Domain Transfer Network for Face Anti-Spoofing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4280--4290},
	year = {2021},
	timestamp = {Fri, 17 Sep 2021 14:46:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangSXFW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development in face recognition, most of the existing systems can perform very well in unconstrained scenarios. However, it is still a very challenging task to detect face spoofing attacks, thus face anti-spoofing has become one of the most important research topics in the community. Though various anti-spoofing models have been proposed, the generalisation capability of these models usually degrades for unseen attacks in the presence of challenging appearance variations, <italic>e.g.</italic>, background, illumination, diverse spoofing materials and low image quality. To address this issue, we propose to use a Generative Adversarial Network (GAN) that transfers an input face image from the RGB domain to the depth domain. The generated depth clue enables biometric preservation against challenging appearance variations and diverse image qualities. To be more specific, the proposed method has two main stages. The first one is a GAN-based domain transfer module that converts an input image to its corresponding depth map. By design, a live face image should be transferred to a depth map whereas a spoofing face image should be transferred to a plain (black) image. The aim is to improve the discriminative capability of the proposed system. The second stage is a classification model that determines whether an input face image is live or spoofing. Benefit from the use of the GAN-based domain transfer module, the latent variables can effectively represent the depth information, complementarily enhancing the discrimination of the original RGB features. The experimental results obtained on several benchmarking datasets demonstrate the effectiveness of the proposed method, with superior performance over the state-of-the-art methods. The source code of the proposed method is publicly available at <uri>https://github.com/coderwangson/DFA</uri>.}
}


@article{DBLP:journals/tifs/DaiLCLZJ21,
	author = {Weiqi Dai and
                  Yan Lv and
                  Kim{-}Kwang Raymond Choo and
                  Zhongze Liu and
                  Deqing Zou and
                  Hai Jin},
	title = {{CRSA:} {A} Cryptocurrency Recovery Scheme Based on Hidden Assistance
                  Relationships},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4291--4305},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3104142},
	doi = {10.1109/TIFS.2021.3104142},
	timestamp = {Mon, 20 Sep 2021 09:50:39 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DaiLCLZJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As cryptocurrency and blockchain-related assets become more common in our digital society, there is a corresponding need to secure our digital assets, including the private keys used to secure access to such assets (e.g., due to loss or corruption of the data storage medium). However, there are limitations in existing blockchain-related asset management and recovery methods. Therefore, we use zero-knowledge proof to design a cryptocurrency recovery scheme based on hidden assisting relationships (hereafter referred to as the CRSA scheme) to facilitate the recovery of blockchain assets. Specifically, when the user's private key is lost, and access to the assets cannot be obtained, the user leverages information such as the pre-defined list of assistants to authenticate himself/herself on the blockchain. Once the assistants have confirmed the legitimacy of the user's authentication request, the asset will be transferred from the old address to the new address. During the (identity) proof process, the zero-knowledge proof is used to ensure that the identification of assistants is not leaked to other nodes, assistants, and the adversary. We provide the formal definition of the above scheme and the security proof of the construction. We also implement a prototype of the system and evaluate its performance. Evaluations indicate that the time required for the zero-knowledge proof is less than 10s, and the block verification time is less than 100ms.}
}


@article{DBLP:journals/tifs/MoTLH21,
	author = {Xianbo Mo and
                  Shunquan Tan and
                  Bin Li and
                  Jiwu Huang},
	title = {MCTSteg: {A} Monte Carlo Tree Search-Based Reinforcement Learning
                  Framework for Universal Non-Additive Steganography},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4306--4320},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3104140},
	doi = {10.1109/TIFS.2021.3104140},
	timestamp = {Mon, 20 Sep 2021 09:50:39 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MoTLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research has shown that non-additive image steganographic frameworks effectively improve security performance through adjusting distortion distribution. However, as far as we know, all of the existing non-additive proposals are based on handcrafted policies, and can only be applied to a specific image domain, which heavily prevent non-additive steganography from releasing its full potentiality. In this paper, we propose an automatic non-additive steganographic distortion learning framework called MCTSteg to remove the above restrictions. Guided by the reinforcement learning paradigm, we combine Monte Carlo Tree Search (MCTS) and steganalyzer-based environmental model to build MCTSteg. MCTS makes sequential decisions to adjust distortion distribution without human intervention. Our proposed environmental model is used to obtain feedbacks from each decision. Due to its self-learning characteristic and domain-independent reward function, MCTSteg has become the first reported universal non-additive steganographic framework which can work in both spatial and JPEG domains. Extensive experimental results show that MCTSteg can effectively withstand the detection of both hand-crafted feature-based and deep-learning-based steganalyzers. In both spatial and JPEG domains, the security performance of MCTSteg steadily outperforms the state of the art by a clear margin under different scenarios.}
}


@article{DBLP:journals/tifs/GruberPKSTTS21,
	author = {Michael Gruber and
                  Matthias Probst and
                  Patrick Karl and
                  Thomas Schamberger and
                  Lars Tebelmann and
                  Michael Tempelmeier and
                  Georg Sigl},
	title = {DOMREP-An Orthogonal Countermeasure for Arbitrary Order Side-Channel
                  and Fault Attack Protection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4321--4335},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3089875},
	doi = {10.1109/TIFS.2021.3089875},
	timestamp = {Mon, 20 Sep 2021 09:50:39 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GruberPKSTTS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Protection against physical attacks is a major requirement for cryptographic implementations on devices which can be accessed by attackers. Side-channel and fault injection attacks are the most common types of physical attacks. In this work we present a novel generic solution for simultaneous protection against side-channel and fault attacks with arbitrary order. We combine domain oriented masking and repetition codes in an orthogonal way and call this approach DOMREP. The resistance against side-channel attacks and fault attacks can be scaled independently of each other, for the protection against higher-order side-channel analysis and the injection of multiple faults including SIFA. We develop the generic concept of orthogonal protection, and implement the DOMREP concept on GIMLI, a round two NIST LWC competition candidate, on a Xilinx Artix-7 FPGA. Our implementation of GIMLI is verified to be resistant against univariate first-order side-channel attacks by TVLA. The resistance against SIFA is verified by means of fault emulation of single as well as multiple bit faults. Our implementation of GIMLI achieves the expected security level according to these measurements. We also provide numbers for the area overhead for our protected implementation of GIMLI.}
}


@article{DBLP:journals/tifs/RajaFFSBWGSFVSL21,
	author = {Kiran B. Raja and
                  Matteo Ferrara and
                  Annalisa Franco and
                  Luuk J. Spreeuwers and
                  Illias Batskos and
                  Florens de Wit and
                  Marta Gomez{-}Barrero and
                  Ulrich Scherhag and
                  Daniel Fischer and
                  Sushma Venkatesh and
                  Jag Mohan Singh and
                  Guoqiang Li and
                  Lo{\"{\i}}c Bergeron and
                  Sergey Isadskiy and
                  Raghavendra Ramachandra and
                  Christian Rathgeb and
                  Dinusha Frings and
                  Uwe Seidel and
                  Fons Knopjes and
                  Raymond N. J. Veldhuis and
                  Davide Maltoni and
                  Christoph Busch},
	title = {Morphing Attack Detection-Database, Evaluation Platform, and Benchmarking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4336--4351},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2020.3035252},
	doi = {10.1109/TIFS.2020.3035252},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/RajaFFSBWGSFVSL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Morphing attacks have posed a severe threat to Face Recognition System (FRS). Despite the number of advancements reported in recent works, we note serious open issues such as independent benchmarking, generalizability challenges and considerations to age, gender, ethnicity that are inadequately addressed. Morphing Attack Detection (MAD) algorithms often are prone to generalization challenges as they are database dependent. The existing databases, mostly of semi-public nature, lack in diversity in terms of ethnicity, various morphing process and post-processing pipelines. Further, they do not reflect a realistic operational scenario for Automated Border Control (ABC) and do not provide a basis to test MAD on unseen data, in order to benchmark the robustness of algorithms. In this work, we present a new sequestered dataset for facilitating the advancements of MAD where the algorithms can be tested on unseen data in an effort to better generalize. The newly constructed dataset consists of facial images from 150 subjects from various ethnicities, age-groups and both genders. In order to challenge the existing MAD algorithms, the morphed images are with careful subject pre-selection created from the contributing images, and further post-processed to remove morphing artifacts. The images are also printed and scanned to remove all digital cues and to simulate a realistic challenge for MAD algorithms. Further, we present a new online evaluation platform to test algorithms on sequestered data. With the platform we can benchmark the morph detection performance and study the generalization ability. This work also presents a detailed analysis on various subsets of sequestered data and outlines open challenges for future directions in MAD research.}
}


@article{DBLP:journals/tifs/YeCCC21,
	author = {Feng Ye and
                  Zheyuan Cheng and
                  Xianghui Cao and
                  Mo{-}Yuen Chow},
	title = {A Random-Weight Privacy-Preserving Algorithm With Error Compensation
                  for Microgrid Distributed Energy Management},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4352--4362},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3106161},
	doi = {10.1109/TIFS.2021.3106161},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YeCCC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, collaborative distributed energy management systems (CoDEMS) have emerged as an effective solution to manage distributed energy resources in microgrid. In CoDEMS, devices collaborate in a distributive manner over communication networks to meet electrical loads and supply balance at minimum cost. However, mutual information exchanges among the devices in CoDEMS may leak important information about the devices states. In this paper, we investigate the challenging problem of how to achieve optimality while preserving the privacy of CoDEMS at relatively low cost. Unlike many previous works that preserve the privacy by using additive noises, we propose a novel random-weight privacy-preserving algorithm with error compensation, termed as REP-CoDEMS, for CoDEMS. In the proposal, each distributed device generates two random weights each time and it communicates with its neighbor conveying values based on the weights, incremental cost estimation and power imbalance estimation information along with a novel error compensation term to eliminate the error induced by the random weights. We theoretically prove that the proposed REP-CoDEMS algorithm converges and preserves the privacy of all devices. We also derive analytical expressions of the maximum privacy disclosure probability for initial and final states of the CoDEMS. In addition, we conduct extensive simulations and the results demonstrate the effectiveness of the proposed algorithm.}
}


@article{DBLP:journals/tifs/IrshadCGYLPJKXZ21,
	author = {Hassaan Irshad and
                  Gabriela F. Ciocarlie and
                  Ashish Gehani and
                  Vinod Yegneswaran and
                  Kyu Hyung Lee and
                  Jignesh M. Patel and
                  Somesh Jha and
                  Yonghwi Kwon and
                  Dongyan Xu and
                  Xiangyu Zhang},
	title = {{TRACE:} Enterprise-Wide Provenance Tracking for Real-Time {APT} Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4363--4376},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3098977},
	doi = {10.1109/TIFS.2021.3098977},
	timestamp = {Mon, 03 Jan 2022 07:47:03 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/IrshadCGYLPJKXZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present TRACE, a comprehensive provenance tracking system for scalable, real-time, enterprise-wide APT detection. TRACE uses static analysis to identify program unit structures and inter-unit dependences, such that the provenance of an output event includes the input events within the same unit. Provenance collected from individual hosts are integrated to facilitate construction of a distributed enterprise-wide causal graph. We describe the evolution of TRACE over a four-year period, during which our improvements to the system focused on performance, scalability, and fidelity. In this time span, the system call coverage increased (from 47 to 66) while the time and space overhead reduced by over one and two orders of magnitude, respectively. We also provide results from five adversarial engagements where an independent team of system evaluators conducted APT attacks and assessed system performance. The input from our system was used by three other teams to implement real-time APT detection logic. Retrospective analysis revealed that TRACE provided sufficient evidence to detect over 80% of the attack stages across all evaluations. By the last engagement, temporal and spatial overhead had been reduced significantly to 18% and 10%, respectively.}
}


@article{DBLP:journals/tifs/ZhangYCLF21,
	author = {Yicheng Zhang and
                  Rozhin Yasaei and
                  Hao Chen and
                  Zhou Li and
                  Mohammad Abdullah Al Faruque},
	title = {Stealing Neural Network Structure Through Remote {FPGA} Side-Channel
                  Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4377--4388},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3106169},
	doi = {10.1109/TIFS.2021.3106169},
	timestamp = {Mon, 20 Sep 2021 09:50:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangYCLF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Neural Network (DNN) models have been extensively developed by companies for a wide range of applications. The development of a customized DNN model with great performance requires costly investments, and its structure (layers and hyper-parameters) is considered intellectual property and holds immense value. However, in this paper, we found the model secret is vulnerable when a cloud-based FPGA accelerator executes it. We demonstrate an end-to-end attack based on remote power side-channel analysis and machine-learning-based secret inference against different DNN models. The evaluation result shows that an attacker can reconstruct the layer and hyper-parameter sequence at over 90% accuracy using our method, which can significantly reduce her model development workload. We believe the threat presented by our attack is tangible, and new defense mechanisms should be developed against this threat.}
}


@article{DBLP:journals/tifs/HongKCLC21,
	author = {Seungwan Hong and
                  Seunghong Kim and
                  Jiheon Choi and
                  Younho Lee and
                  Jung Hee Cheon},
	title = {Efficient Sorting of Homomorphic Encrypted Data With k-Way Sorting
                  Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4389--4404},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3106167},
	doi = {10.1109/TIFS.2021.3106167},
	timestamp = {Mon, 28 Aug 2023 21:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HongKCLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, we propose an efficient sorting method for encrypted data using fully homomorphic encryption (FHE). The proposed method extends the existing 2-way sorting method by applying the k-way sorting network for any prime k to reduce the depth in terms of comparison operation from O(log 2 2 n) to O(klog k 2 n), thereby improving performance for k slightly larger than 2, such as k=5. We apply this method to approximate FHE which is widely used due to its efficiency of homomorphic arithmetic operations. In order to build up the k-way sorting network, the k-sorter, which sorts k-numbers with a minimal comparison depth, is used as a building block. The approximate homomorphic comparison, which is the only type of comparison working on approximate FHE, cannot be used for the construction of the k-sorter as it is because the result of the comparison is not binary, unlike the comparison in conventional bit-wise FHEs. To overcome this problem, we propose an efficient k-sorter construction utilizing the features of approximate homomorphic comparison. Also, we propose an efficient construction of a k-way sorting network using cryptographic SIMD operations. To use the proposed method most efficiently, we propose an estimation formula that finds the appropriate k that is expected to reduce the total time cost when the parameters of the approximating comparisons and the performance of the operations provided by the approximate FHE are given. We also show the implementation results of the proposed method, and it shows that sorting 5 6 = 15625 data using 5-way sorting network can be about 23.3% faster than sorting 2 14 = 16384 data using 2-way.}
}


@article{DBLP:journals/tifs/YilmazAS21,
	author = {Selim Yilmaz and
                  Emre Aydogan and
                  Sevil Sen},
	title = {A Transfer Learning Approach for Securing Resource-Constrained IoT
                  Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4405--4418},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3096029},
	doi = {10.1109/TIFS.2021.3096029},
	timestamp = {Mon, 20 Sep 2021 09:50:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YilmazAS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, Internet of Things (IoT) security has attracted significant interest by researchers due to new characteristics of IoT such as heterogeneity of devices, resource constraints, and new types of attacks targeting IoT. Intrusion detection, which is an indispensable part of a security system, is also included in these studies. In order to explore the complex characteristics of IoT, machine learning methods, which rely on long training time to generate intrusion detection models, are proposed in the literature. Furthermore, these systems need to learn a new/fresh model from scratch when the environment changes. This study explores the use of transfer learning in order to generate intrusion detection algorithms for such dynamically changing IoT. Transfer learning is an approach that stores knowledge learned from a problem domain/task and applies that knowledge to another problem domain/task. Here, it is employed in the following two settings: transferring knowledge for generating suitable intrusion algorithms for new devices, transferring knowledge for detecting new types of attacks. In this study, Routing Protocol for Low-Power and Lossy Network (RPL), a routing protocol for resource-constrained wireless networks, is used as an exemplar protocol and specific attacks against RPL are targeted. The experimental results show that the transfer learning approach gives better performance than the traditional approach. Moreover, the proposed approach significantly reduces learning time, which is an important factor for putting devices/networks in operation in a timely manner. Even though transfer learning has been considered a potential candidate for improving IoT security, to the best of our knowledge, this is the first application of transfer learning under these two settings in RPL-based IoT networks.}
}


@article{DBLP:journals/tifs/BertoccoAR21,
	author = {Gabriel Bertocco and
                  Fernanda A. Andal{\'{o}} and
                  Anderson Rocha},
	title = {Unsupervised and Self-Adaptative Techniques for Cross-Domain Person
                  Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4419--4434},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3107157},
	doi = {10.1109/TIFS.2021.3107157},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BertoccoAR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Person Re-Identification (ReID) across non-overlapping cameras is a challenging task, and most works in prior art rely on supervised feature learning from a labeled dataset to match the same person in different views. However, it demands the time-consuming task of labeling the acquired data, prohibiting its fast deployment in forensic scenarios. Unsupervised Domain Adaptation (UDA) emerges as a promising alternative, as it performs feature adaptation from a model trained on a source to a target domain without identity-label annotation. However, most UDA-based methods rely upon a complex loss function with several hyper-parameters, hindering the generalization to different scenarios. Moreover, as UDA depends on the translation between domains, it is crucial to select the most reliable data from the unseen domain, avoiding error propagation caused by noisy examples on the target data - an often overlooked problem. In this sense, we propose a novel UDA-based ReID method that optimizes a simple loss function with only one hyper-parameter and takes advantage of triplets of samples created by a new offline strategy based on the diversity of cameras within a cluster. This new strategy adapts and regularizes the model, avoiding overfitting the target domain. We also introduce a new self-ensembling approach, which aggregates weights from different iterations to create a final model, combining knowledge from distinct moments of the adaptation. For evaluation, we consider three well-known deep learning architectures and combine them for the final decision. The proposed method does not use person re-ranking nor any identity label on the target domain and outperforms state-of-the-art techniques, with a much simpler setup, on the Market to Duke, the challenging Market1501 to MSMT17, and Duke to MSMT17 adaptation scenarios.}
}


@article{DBLP:journals/tifs/XieXCYHNS21,
	author = {Renjie Xie and
                  Wei Xu and
                  Yanzhi Chen and
                  Jiabao Yu and
                  Aiqun Hu and
                  Derrick Wing Kwan Ng and
                  A. Lee Swindlehurst},
	title = {A Generalizable Model-and-Data Driven Approach for Open-Set {RFF}
                  Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4435--4450},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3106166},
	doi = {10.1109/TIFS.2021.3106166},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XieXCYHNS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio-frequency fingerprints (RFFs) are promising solutions for realizing low-cost physical layer authentication. Machine learning-based methods have been proposed for RFF extraction and discrimination. However, most existing methods are designed for the closed-set scenario where the set of devices is remains unchanged. These methods cannot be generalized to the RFF discrimination of unknown devices. To enable the discrimination of RFF from both known and unknown devices, we propose a new end-to-end deep learning framework for extracting RFFs from raw received signals. The proposed framework comprises a novel preprocessing module, called neural synchronization (NS), which incorporates the data-driven learning with signal processing priors as an inductive bias from communication-model based processing. Compared to traditional carrier synchronization techniques, which are static, this module estimates offsets by two learnable deep neural networks jointly trained by the RFF extractor. Additionally, a hypersphere representation is proposed to further improve the discrimination of RFF. Theoretical analysis shows that such a data-and-model framework can better optimize the mutual information between device identity and the RFF, which naturally leads to better performance. Experimental results verify that the proposed RFF significantly outperforms purely data-driven DNN-design and existing handcrafted RFF methods in terms of both discrimination and network generalizability.}
}


@article{DBLP:journals/tifs/WangC21,
	author = {Sen Wang and
                  J. Morris Chang},
	title = {Privacy-Preserving Boosting in the Local Setting},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4451--4465},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3097822},
	doi = {10.1109/TIFS.2021.3097822},
	timestamp = {Sat, 08 Jan 2022 02:24:02 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In machine learning, boosting is one of the most popular methods that is designed to combine multiple base learners into a superior one. The well-known Boosted Decision Tree classifier has been widely adopted in data mining and pattern recognition. With the emerging challenge in privacy, the personal images, browsing history, and financial reports, which are held by individuals and entities are more likely to contain sensitive information. The privacy concern is intensified when the data leaves the hand of owners and is used for further mining. Such privacy issues demand that the machine learning algorithms should be privacy-aware. Recently, Local Differential Privacy has been proposed as an effective privacy protection approach, which allows data owners to perturb the data before any release. In this paper, we propose a distributed privacy-preserving boosting algorithm that can be applied to various types of classifiers. By adopting LDP as a building block, the proposed boosting algorithm leverages the aggregation of the perturbed data shares to build the base learner, which ensures that privacy is well preserved for the participated data owners. Our experiments demonstrate that the proposed algorithm effectively boosts various classifiers and the boosted classifiers maintain a high utility.}
}


@article{DBLP:journals/tifs/LiLGT21,
	author = {Yanbin Li and
                  Zhe Liu and
                  Sylvain Guilley and
                  Ming Tang},
	title = {Analysis of Multiplicative Low Entropy Masking Schemes Against Correlation
                  Power Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4466--4481},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3096130},
	doi = {10.1109/TIFS.2021.3096130},
	timestamp = {Mon, 20 Sep 2021 09:50:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiLGT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Low Entropy Masking Schemes (LEMS) had been proposed to mitigate the high-performance overhead results from the Full Entropy Masking Schemes (FEMS) while offering good protection against side-channel attacks. The masking schemes usually rely on Boolean masking, however, splitting sensitive variables in a multiplicative way is more amenable to non-linear functions and it had been applied to both software and hardware with a competitive alternative to state-of-the-art masked design. Compared to the comprehensive analysis done for Boolean LEMS, the specific leakage characteristics of Multiplicative LEMS have not yet been analyzed. In this paper, we introduce security models for LEMS to characterize the balance of the mask set. Based on the security model, we present an inherent weakness of Multiplicative LEMS. We prove that this defect of Multiplicative LEMS cannot be compensated by choosing a proper mask set, and the security of FEMS is guaranteed thanks to the Dirac function which is used to resist zero-value attack. Then, we exhibit the leakages in the implementation of Multiplicative LEMS. In particular, we propose a new attack against Multiplicative LEMS more efficient by utilizing the distribution of masked intermediate values. The feasibility of the attack is verified by both simulation and practical experiments.}
}


@article{DBLP:journals/tifs/ZhangCJ21,
	author = {Jiyan Zhang and
                  Ting Cui and
                  Chenhui Jin},
	title = {{ICT:} {A} Cryptanalysis Toolbox for Block Cipher Structure With Secret
                  Components},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4482--4493},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3108435},
	doi = {10.1109/TIFS.2021.3108435},
	timestamp = {Mon, 28 Aug 2023 21:40:49 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangCJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present a new technique for recovering the secret inner components of block cipher structures. This technique does not simply distinguish a block cipher structure from a random permutation but recovers the secret inner components. In addition, our technique is more general than ad hoc structural cryptanalysis for specific structures. A new tool, the Inequality Constraints Table ( ICT), is introduced to characterize the constraint relation of the secret inner components. If a complete ICT can be constructed, the secret components will be determined by a recursive algorithm. Based on the fundamental structure, an iterative method is proposed to construct an equivalent structure to simplify the initial guess regarding the secret components. Finally, we apply the new technique to several block cipher structures and obtain the secret component recovery results for the 5-round MISTY structure, 23- and 25- round Skipjack structure. To the best of our knowledge, this is the first time to present the structural cryptanalysis against the 5-round MISTY structure, 23- and 25-round Skipjack structure.}
}


@article{DBLP:journals/tifs/GaoOY21,
	author = {Si Gao and
                  Elisabeth Oswald and
                  Yan Yan},
	title = {Neyman's Smoothness Test: {A} Trade-Off Between Moment-Based and Distribution-Based
                  Leakage Detections},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4494--4506},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3108570},
	doi = {10.1109/TIFS.2021.3108570},
	timestamp = {Fri, 04 Aug 2023 08:25:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GaoOY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Leakage detection tests have become an indispensable tool for testing implementations featuring side channel countermeasures such as masking. Whilst moment-based techniques such as the Welch's t-test are universally powerful if there is leakage in a central moment, they naturally fail if this is not the case. Distribution-based techniques such as the χ 2 -test then come to the rescue, but they have shown not to be robust with regards to noise. In this paper, we propose a novel leakage detection technique based on Neyman's smoothness test. We find that our new test is robust with respect to noise (similar to the merit of Welch's t-test), and can pick up on leakage that is not located in central moments (similar to the merit of the χ 2 -test). We also find that there is a sweet-spot where Neyman's test outperforms both the t-test and the χ 2 -test. Realistic measurements confirm that such a sweet-spot is relevant in practice for detecting implementation flaws.}
}


@article{DBLP:journals/tifs/XuNMHD21,
	author = {Shengmin Xu and
                  Jianting Ning and
                  Jinhua Ma and
                  Xinyi Huang and
                  Robert H. Deng},
	title = {K-Time Modifiable and Epoch-Based Redactable Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4507--4520},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3107146},
	doi = {10.1109/TIFS.2021.3107146},
	timestamp = {Thu, 24 Feb 2022 11:50:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XuNMHD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an immutable append-only distributed ledger, blockchain allows a group of participants to reach a consensus in an untrustworthy ecosystem. Immutability is a blockchain feature that persists data forever, but it is no longer legal in reality. Blockchain has unchangeable improper contents that violate laws. Moreover, data regulation toward “the right to be forgotten” requires blockchain must be modifiable. To address this problem, redactable blockchain has been introduced to relax immutability in a controlled way. However, once a participant is authorized, she/he can rewrite any content and no penalty for the malicious behavior that hinders the wide deployment of redactable blockchain in practice. In this paper, we introduce a new notion, dubbed k-time modifiable and epoch-based redactable blockchain (KERB) with a monetary penalty to control rewriting privileges and penalize malicious behaviors. Our solution is built up from simple building blocks: digital signatures and chameleon hashes. We give a formal definition and security models of KERB, and present a generic construction along with formal proofs. The extensive comparison and experimental analysis illustrate that our solution enjoys superior functionalities and performances than the state-of-the-art solutions.}
}


@article{DBLP:journals/tifs/EdrakiKRMS21,
	author = {Marzieh Edraki and
                  Nazmul Karim and
                  Nazanin Rahnavard and
                  Ajmal Mian and
                  Mubarak Shah},
	title = {Odyssey: Creation, Analysis and Detection of Trojan Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4521--4533},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3108407},
	doi = {10.1109/TIFS.2021.3108407},
	timestamp = {Mon, 20 Sep 2021 09:50:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/EdrakiKRMS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Along with the success of deep neural network (DNN) models, rise the threats to the integrity of these models. A recent threat is the Trojan attack where an attacker interferes with the training pipeline by inserting triggers into some of the training samples and trains the model to act maliciously only for samples that contain the trigger. Since the knowledge of triggers is privy to the attacker, detection of Trojan networks is challenging. Existing Trojan detectors make strong assumptions about the types of triggers and attacks. We propose a detector that is based on the analysis of the intrinsic DNN properties; that are affected due to the Trojan insertion process. For a comprehensive analysis, we develop Odyssey, the most diverse dataset to date with over 3,000 clean and Trojan models. Odyssey covers a large spectrum of attacks; generated by leveraging the versatility in trigger designs and source to target class mappings. Our analysis results show that Trojan attacks affect the classifier margin and shape of decision boundary around the manifold of clean data. Exploiting these two factors, we propose an efficient Trojan detector that operates without any knowledge of the attack and significantly outperforms existing methods. Through a comprehensive set of experiments we demonstrate the efficacy of the detector on cross model architectures, unseen Triggers and regularized models.}
}


@article{DBLP:journals/tifs/WangG21,
	author = {Qiangchang Wang and
                  Guodong Guo},
	title = {DSA-Face: Diverse and Sparse Attentions for Face Recognition Robust
                  to Pose Variation and Occlusion},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4534--4543},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3109463},
	doi = {10.1109/TIFS.2021.3109463},
	timestamp = {Mon, 20 Sep 2021 09:50:39 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learning local representations is important for face recognition (FR). Recent attention-based networks emphasize few facial parts, while ignoring other potentially discriminative ones. This is more serious when there are large pose variations, occlusions (e.g. face masks), or other image quality changes. To address this, we propose Diverse and Sparse Attentions, called DSA-Face. First, a divergence loss is designed to explicitly encourage the diversity among multiple attention maps by maximizing the Euclidean distance between every pair attention maps. As a result, a Pairwise Self-Contrastive Attention (PSCA) is developed to locate diverse facial parts which provide comprehensive descriptions. Second, an Attention Sparsity Loss (ASL) is proposed to encourage sparse responses in attention maps where only discriminative parts are emphasized while distracted regions (e.g. background or face masks) are discouraged. Built upon the PSCA and ASL, the DSA-Face model is developed to learn diverse and sparse attentions, which can extract diverse discriminative local representations and suppress the focus on noisy regions. Due to the pandemic of the COVID-19, the task of masked face matching is now very important, and our model can handle this much better than previous methods, demonstrating its effectiveness and usefulness. Moreover, our model outperforms the state-of-the-art methods on several other FR benchmarks, showing that it is also general to address various challenges in FR.}
}


@article{DBLP:journals/tifs/HuNZH21,
	author = {Xianglei Hu and
                  Jiangqun Ni and
                  Weizhe Zhang and
                  Jiwu Huang},
	title = {Efficient {JPEG} Batch Steganography Using Intrinsic Energy of Image
                  Contents},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4544--4558},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3109464},
	doi = {10.1109/TIFS.2021.3109464},
	timestamp = {Mon, 20 Sep 2021 09:50:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuNZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Batch steganography aims at properly allocating a large payload to multiple covers, so as to keep the whole covert communication at a satisfactory level of security. JPEG is currently one of the most widely used formats for image storage and transmission. This paper presents an efficient JPEG batch steganographic scheme, which allocates the payload in a linear manner w.r.t. a new heuristic measure - the intrinsic energy of JPEG image contents, in which more concerns are with the high frequency components, and the proposed measure could also be easily generalized to cover selection in batch steganographic applications. And a calibration strategy is elaborately designed to balance the security level when JPEG covers of various QFs are involved in JPEG batch steganography. In this way, the proposed scheme can effectively resolve the problem that the statistical undetectability fluctuates dramatically w.r.t. the size and quality factor when the batch set is involved with various image parameters, and consequently maintains the overall security of the practical JPEG batch steganographic system. Experimental results show that the proposed method exhibits security performance superior or comparable to the state-of-the-art batch schemes while maintaining a low computational cost.}
}


@article{DBLP:journals/tifs/NieXJLLMWFWJZ21,
	author = {Pengli Nie and
                  Guangquan Xu and
                  Litao Jiao and
                  Shaoying Liu and
                  Jian Liu and
                  Weizhi Meng and
                  Hongyue Wu and
                  Meiqi Feng and
                  Weizhe Wang and
                  Zhengjun Jing and
                  Xi Zheng},
	title = {Sparse Trust Data Mining},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4559--4573},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3109412},
	doi = {10.1109/TIFS.2021.3109412},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NieXJLLMWFWJZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As recommendation systems continue to evolve, researchers are using trust data to improve the accuracy of recommendation prediction and help users find relevant information. However, large recommendation systems with trust data suffer from the sparse trust problem, which leads to grade inflation and severely affects the reliability of trust propagation. This paper presents a novel research on sparse trust data mining, which includes the new concept of sparse trust, a sparse trust model, and a trust mining framework. It lays a foundation for the trust-related research in large recommended systems. The new trust mining framework is based on customized normalization functions and a novel transitive gossip trust model, which discovers potential trust information between entities in a large-scale user network and applies it to a recommendation system. We conducts a comprehensive performance evaluation on both real-world and synthetic datasets. The results confirm that our framework mines new trust and effectively ameliorates sparse trust problem.}
}


@article{DBLP:journals/tifs/LiuLXCHL21,
	author = {Xiaoyuan Liu and
                  Hongwei Li and
                  Guowen Xu and
                  Zongqi Chen and
                  Xiaoming Huang and
                  Rongxing Lu},
	title = {Privacy-Enhanced Federated Learning Against Poisoning Adversaries},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4574--4588},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3108434},
	doi = {10.1109/TIFS.2021.3108434},
	timestamp = {Tue, 14 May 2024 13:59:20 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLXCHL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL), as a distributed machine learning setting, has received considerable attention in recent years. To alleviate privacy concerns, FL essentially promises that multiple parties jointly train the model by exchanging gradients rather than raw data. However, intrinsic privacy issue still exists in FL, e.g., user’s training samples could be revealed by solely inferring gradients. Moreover, the emerging poisoning attack also poses a crucial security threat to FL. In particular, due to the distributed nature of FL, malicious users may submit crafted gradients during the training process to undermine the integrity and availability of the model. Furthermore, there exists a contradiction in simultaneously addressing two issues, that is, privacy-preserving FL solutions are dedicated to ensuring gradients indistinguishability, whereas the defenses against poisoning attacks tend to remove outliers based on their similarity. To solve such a dilemma, in this paper, we aim to build a bridge between the two issues. Specifically, we present a privacy-enhanced FL (PEFL) framework that adopts homomorphic encryption as the underlying technology and provides the server with a channel to punish poisoners via the effective gradient data extraction of the logarithmic function. To the best of our knowledge, the PEFL is the first effort to efficiently detect the poisoning behaviors in FL under ciphertext. Detailed theoretical analyses illustrate the security and convergence properties of the scheme. Moreover, the experiments conducted on real-world datasets show that the PEFL can effectively defend against label-flipping and backdoor attacks, two representative poisoning attacks in FL.}
}


@article{DBLP:journals/tifs/DingWZCJ21,
	author = {Xiaofeng Ding and
                  Zuan Wang and
                  Pan Zhou and
                  Kim{-}Kwang Raymond Choo and
                  Hai Jin},
	title = {Efficient and Privacy-Preserving Multi-Party Skyline Queries Over
                  Encrypted Data},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4589--4604},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3109459},
	doi = {10.1109/TIFS.2021.3109459},
	timestamp = {Thu, 20 Jun 2024 15:06:43 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DingWZCJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One existing challenge associated with large scale skyline queries on cloud services, particularly when dealing with private information such as biomedical data, is supporting multi-party queries with curious-but-honest parties on encrypted data. In addition, existing solutions designed for performing secure skyline queries incur significant communication and computation costs due to ciphertext calculation. Thus, in this paper, we demonstrate the potential of supporting privacy-preserving multi-party skyline queries on encrypted data using additive homomorphic and proxy re-encryption cryptosystems. However, the secure computation based on these cryptosystems will further slow down query efficiency. To improve the efficiency of comparison on encrypted data, we redesign two lightweight secure comparison protocols. Meanwhile, we present an efficient method named “blind-reading” to securely obtain the skyline point. We also propose a novel method, Privacy Matrix, designed to reduce the scale of the dataset so that the computational cost is significantly decreased without privacy leakage. Then, we construct our secure skyline query protocol by integrating lightweight secure comparison protocols, “blind-reading” and Privacy Matrix techniques. Finally, we evaluate the security of our protocol, where we show it is secure without leaking information. The performance evaluation also shows that our proposed approach significantly improves the efficiency (at least ×4.5 faster) compared to the-state-of-art and has the scalability of query processing under large datasets.}
}


@article{DBLP:journals/tifs/WangB21,
	author = {Shi{-}Yuan Wang and
                  Matthieu R. Bloch},
	title = {Covert {MIMO} Communications Under Variational Distance Constraint},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4605--4620},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3110048},
	doi = {10.1109/TIFS.2021.3110048},
	timestamp = {Mon, 20 Sep 2021 09:50:39 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of covert communication over Multiple-Input Multiple-Output (MIMO) Additive White Gaussian Noise (AWGN) channels is investigated, in which a transmitter attempts to reliably communicate with a legitimate receiver while avoiding detection by a passive adversary. The covert capacity of the MIMO AWGN channel is characterized under a variational distance covertness constraint when the MIMO channel matrices are static and known. The characterization of the covert capacity is also extended to a class of channels in which the legitimate channel matrix is known but the adversary’s channel matrix is only known up to a rank and a spectral norm constraint.}
}


@article{DBLP:journals/tifs/LiuLZH21,
	author = {Minglin Liu and
                  Weiqi Luo and
                  Peijia Zheng and
                  Jiwu Huang},
	title = {A New Adversarial Embedding Method for Enhancing Image Steganography},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4621--4634},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3111748},
	doi = {10.1109/TIFS.2021.3111748},
	timestamp = {Tue, 18 Oct 2022 21:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image steganography aims to embed secret messages into cover images in an imperceptible manner. While steganalysis tries to identify stegos from covers, which is a special binary classification problem. Recently, some literatures show that the adversarial embedding can mislead the advanced steganalyzers based on convolutional neural network (CNN), and thus enhance the steganography security. Since adding perturbations to stegos may lead to messages extraction failure due to properties of syndrome-trellis codes (STC), the existing adversarial examples are derived from covers or their enhanced versions, while those stegos are not fully utilized. In this paper, we propose a new adversarial embedding scheme for image steganography. Unlike those related works, we first combine multiple gradients of cover and generated stegos to determine the directions of cost modifications. Next, instead of adjusting all or a random part of embedding costs in existing works, we carefully select the candidate costs according to the amplitudes of cover gradients and their costs. Extensive experimental results demonstrate that by adjusting a tiny part of embedding costs (less than 5% in most cases), the proposed method can significantly improve the security of five modern steganographic methods evaluated on both re-trained CNN-based and traditional steganalyzers, and achieve much better security performances compared with related methods. In addition, the security performances evaluated on different image database show that the generalization of the proposed method is good.}
}


@article{DBLP:journals/tifs/Arashloo21,
	author = {Shervin Rahimzadeh Arashloo},
	title = {Matrix-Regularized One-Class Multiple Kernel Learning for Unseen Face
                  Presentation Attack Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4635--4647},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3111766},
	doi = {10.1109/TIFS.2021.3111766},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Arashloo21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The functionality of face biometric systems is severely challenged by presentation attacks (PA’s), and especially those attacks that have not been available during the training phase of a PA detection (PAD) subsystem. Among other alternatives, the one-class classification (OCC) paradigm is an applicable strategy that has been observed to provide good generalisation against unseen attacks. Following an OCC approach for the unseen face PAD from RGB images, this work advocates a matrix-regularised multiple kernel learning algorithm to make use of several sources of information each constituting a different view of the face PAD problem. In particular, drawing on the one-class null Fisher classification principle, we characterise different deep CNN representations as kernels and propose a multiple kernel learning (MKL) algorithm subject to an (\nr,p\n)-norm (\n1≤r,p\n) matrix regularisation constraint. The propose MKL algorithm is formulated as a saddle point Lagrangian optimisation task for which we present an effective optimisation algorithm with guaranteed convergence. An evaluation of the proposed one-class MKL algorithm on both general object images in an OCC setting as well as on different face PAD datasets in an unseen zero-shot attack detection setting illustrates the merits of the proposed method compared to other one-class multiple kernel and deep end-to-end CNN-based methods.}
}


@article{DBLP:journals/tifs/LiHCDJXY21,
	author = {Bo Li and
                  Qiang He and
                  Feifei Chen and
                  Haipeng Dai and
                  Hai Jin and
                  Yang Xiang and
                  Yun Yang},
	title = {Cooperative Assurance of Cache Data Integrity for Mobile Edge Computing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4648--4662},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3111747},
	doi = {10.1109/TIFS.2021.3111747},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiHCDJXY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The new mobile edge computing (MEC) paradigm fundamentally changes the data caching technique by allowing data to be cached on edge servers attached to base stations within hundreds of meters from users. It provides a bounded latency guarantee for latency-sensitive applications, e.g., interactive AR/VR applications, online gaming, etc. However, in the highly distributed MEC environment, cache data is subject to corruption and their integrity must be ensured. Existing centralized data integrity assurance schemes are rendered obsolete by the unique characteristics of MEC, i.e., unlike cloud servers, edge servers have only limited computing and storage resources and they are deployed massively and distributed geographically. Thus, it is a new and significant challenge to ensure cache data integrity over tremendous geographically-distributed resource-constrained edge servers. This paper proposes the CooperEDI scheme to guarantee the edge data integrity in a distributed manner. CooperEDI employs a distributed consensus mechanism to form a self-management edge caching system. In the system, edge servers cooperatively ensure the integrity of cached replicas and repair corrupted ones. We experimentally evaluate its performance against three representative schemes. The results demonstrate that CooperEDI can effectively and efficiently ensure cache data integrity in the MEC environment.}
}


@article{DBLP:journals/tifs/BianKHLS21,
	author = {Song Bian and
                  Dur{-}e{-}Shahwar Kundi and
                  Kazuma Hirozawa and
                  Weiqiang Liu and
                  Takashi Sato},
	title = {{APAS:} Application-Specific Accelerators for RLWE-Based Homomorphic
                  Linear Transformations},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4663--4678},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3114032},
	doi = {10.1109/TIFS.2021.3114032},
	timestamp = {Mon, 17 Jun 2024 15:19:49 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BianKHLS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the application of multi-party secure computing schemes based on homomorphic encryption in the field of machine learning attracts attentions across the research fields. Previous studies have demonstrated that secure protocols adopting packed additive homomorphic encryption (PAHE) schemes based on the ring learning with errors (RLWE) problem exhibit significant practical merits, and are particularly promising in enabling efficient secure inference in machine-learning-as-a-service applications. In this work, we introduce a new technique for performing homomorphic linear transformation (HLT) over PAHE ciphertexts. Using the proposed HLT technique, homomorphic convolutions and inner products can be executed without the use of number theoretic transform and the rotate-and-add algorithms that were proposed in existing works. To maximize the efficiency of the HLT technique, we propose APAS, a hardware-software co-design framework consisting of approximate arithmetic units for the hardware acceleration of HLT. In the experiments, we use actual neural network architectures as benchmarks to show that APAS can improve the computational and communicational efficiency of homomorphic convolution by\n8×\nand\n3×\n, respectively, with an energy reduction of up to\n26×\nas compared to the ASIC implementations of existing methods.}
}


@article{DBLP:journals/tifs/SunPHS21,
	author = {Haomiao Sun and
                  Hongyu Pan and
                  Hu Han and
                  Shiguang Shan},
	title = {Deep Conditional Distribution Learning for Age Estimation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4679--4690},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3114066},
	doi = {10.1109/TIFS.2021.3114066},
	timestamp = {Wed, 03 Nov 2021 08:27:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SunPHS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Age estimation is a challenging task not only because face appearance is affected by illumination, pose, and expression, but also because there exists age label ambiguity among different demographic groups. In this work, we first revisit different label distribution learning (LDL) based age estimation methods and propose a more general formulation, which can unify individual LDL-based age estimation methods, as well as the traditional regression, classification, and ranking based age estimation methods. Based on such a general formulation, we propose a novel deep conditional distribution learning (DCDL) method, which can flexibly leverage a varying number of auxiliary face attributes to achieve adaptive age-related feature learning and improve age estimation robustness against the challenges above. Experimental results on multiple age estimation datasets (MORPH II, AgeDB, FG-NET, MegaAge-Asian, CLAP2016, UTK-Face, and LFW+) show that the proposed approach outperforms the state-of-the-art age estimation methods by a large margin. In addition, the proposed approach can generalize well to other human attributes estimation tasks, like height, weight, and body mass index (BMI) estimation.}
}


@article{DBLP:journals/tifs/HuCZL21,
	author = {Zhisheng Hu and
                  Ping Chen and
                  Minghui Zhu and
                  Peng Liu},
	title = {A Co-Design Adaptive Defense Scheme With Bounded Security Damages
                  Against Heartbleed-Like Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4691--4704},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3113512},
	doi = {10.1109/TIFS.2021.3113512},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuCZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a co-design adaptive defense scheme against a class of zero-day buffer over-read attacks that follow unknown stationary probability distributions. In particular, the co-design scheme integrates an improved UCB algorithm and a customized server. The improved UCB algorithm adaptively allocates guard pages on a heap based on induced damage of the guard pages so as to minimize the accumulated damage over time. The security damages of the improved UCB algorithm are proven to be always below a temporal bound without knowing which attack is launched when the buffer allocation follows a certain stationary probability distribution. Then an efficient server modification is introduced to randomly allocate buffers. Moreover, the damages of our scheme asymptotically converge to those of the optimal defense policy where the launched attacks and their distributions are known in advance. Further, the co-design scheme is evaluated with several real-world Heartbleed attacks. The experiment results demonstrate the validity of the upper bound and show that the adaptive defense is effective against all the attacks of interest with runtime overheads as low as 5%.}
}


@article{DBLP:journals/tifs/YangGWWPD21,
	author = {Yang Yang and
                  Zhangshuang Guan and
                  Zhiguo Wan and
                  Jian Weng and
                  HweeHwa Pang and
                  Robert H. Deng},
	title = {PriScore: Blockchain-Based Self-Tallying Election System Supporting
                  Score Voting},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4705--4720},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3108494},
	doi = {10.1109/TIFS.2021.3108494},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangGWWPD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Election and voting play crucial roles in democratic society for an elactorate to make a collective decision. E-voting is one of the most challenging problems in cryptographic research to provide multiple dimensions security assurances. In this paper, we study an important voting paradigm, score voting, with privacy protection, which has not been investigated in previous work. We propose a blockchain based self-tallying election system to support score voting, dubbed “PriScore”, where the ballots are recorded on blockchain to prevent vote forgery or tampering. PriScore makes it possible for each voter to assign different evaluation scores (within a certain range) for the candidates as ranked-choice, where the sum of the scores in each ballot should be a predefined constant, and the evaluation scores are encrypted to maintain confidentiality. A major challenge in score voting is to simultaneously prove two constraint conditions: range proof and sum proof. We introduce a new technique, called dual zero-knowledge proof (dual-ZKP), to prove the scores satisfying two crucial requirements, which integrates “1-out-of-\nK\n” proof and distributed ElGamal crypto in a non-trivial way. The self-tallying mechanism in PriScore enables any party in the system to calculate and verify the election result, which provides fairness, dispute-freeness. The security analysis demonstrates that PriScore achieves completeness, soundness, eligibility, universal/individual verifiability and multiple-voting detection. We evaluate the performance of PriScore on modern workbench to test the performance, and also on a blockchain platform to measure the resource consumption. The experiments show that PriScore preserves privacy of score voting with reasonable overheads.}
}


@article{DBLP:journals/tifs/HuWZSC21,
	author = {Ronghua Hu and
                  Tian Wang and
                  Yi Zhou and
                  Hichem Snoussi and
                  Abel Cherouat},
	title = {FT-MDnet: {A} Deep-Frozen Transfer Learning Framework for Person Search},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4721--4732},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3113517},
	doi = {10.1109/TIFS.2021.3113517},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuWZSC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Matching manually cropped pedestrian images between queries and candidates, termed as person re-identification, has achieved significant progress with deep convolutional neural networks. Recently, a topic called ‘person search’ is proposed for the end-to-end application of re-identification technologies. It integrates object detection and person re-identification and aims to both locate and match pedestrians on a gallery of raw images. However, the design and implementation of such kind of hybrid network are difficult and computationally consuming in real practical situations. In order to fasten the design and ease the implementation, this paper proposes a deep-frozen transfer learning framework, named FT-MDnet, to extract re-identification features from a pre-trained detection network in two steps. First, using a channel-wise attention mechanism, a network called adaptive transfer learning network (ATLnet) is used to convert the sharing data of the underlying detection network to a re-identification feature map. Then, a multi-branch feature representation network called multiple descriptor network (MDnet) is proposed to extract re-identification features from the re-identification feature map. Our proposed solution has been verified on different types of mainstream detection networks, including YOLOv3, YOLOv4, Mask RCNN, and CenterNet. The experimental results show that our solution outperforms all other person search solutions by a large margin. It proves that the feature representations of detection networks are highly compatible with re-identification, and the proposed framework effectively extracts these features out. To encourage further research, we have made our framework open source.}
}


@article{DBLP:journals/tifs/ShangXLLSG21,
	author = {Fanhua Shang and
                  Tao Xu and
                  Yuanyuan Liu and
                  Hongying Liu and
                  Longjie Shen and
                  Maoguo Gong},
	title = {Differentially Private {ADMM} Algorithms for Machine Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4733--4745},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3113768},
	doi = {10.1109/TIFS.2021.3113768},
	timestamp = {Mon, 28 Aug 2023 21:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShangXLLSG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study efficient differentially private alternating direction methods of multipliers (ADMM) via gradient perturbation for many centralized machine learning problems. For smooth convex loss functions with (non)-smooth regularization, we propose the first differentially private ADMM (DP-ADMM) algorithm with the performance guarantee of (\\epsilon,\\delta)\n-differential privacy ( (\\epsilon,\\delta)\n-DP). From the viewpoint of theoretical analysis, we use the Gaussian mechanism and the conversion relationship between Rényi Differential Privacy (RDP) and DP to perform a comprehensive privacy analysis for our algorithm. Then we establish a new criterion to prove the convergence of the proposed algorithms including DP-ADMM. We also give the utility analysis of our DP-ADMM. Moreover, we propose a new accelerated DP-ADMM (DP-AccADMM) algorithm with the Nesterov’s acceleration technique. Finally, we conduct numerical experiments on many real-world datasets to show the privacy-utility tradeoff of the two proposed algorithms, and all the comparative analysis shows that DP-AccADMM converges faster and has a better utility than DP-ADMM, when the privacy budget \\epsilon\nis larger than a threshold.}
}


@article{DBLP:journals/tifs/XuNHZD21,
	author = {Shengmin Xu and
                  Jianting Ning and
                  Xinyi Huang and
                  Jianying Zhou and
                  Robert H. Deng},
	title = {Server-Aided Bilateral Access Control for Secure Data Sharing With
                  Dynamic User Groups},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4746--4761},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3113516},
	doi = {10.1109/TIFS.2021.3113516},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuNHZD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a versatile technique, cloud-fog computing extends the traditional cloud server to offer various on-demand data services. Maintaining data confidentiality is one of the most crucial requirements for data services, many cryptosystems have been proposed to reserve information privacy against such an untrusted environment. However, in cloud-fog computing, how to confidentially and efficiently share data and fetch desirable data without expensive data decryption for resource-constrained end-devices is challenging. In this paper, we propose a cloud-fog system for the Internet-of-Things (IoT) ecosystem by introducing a cryptographic primitive called server-aided revocable bilateral attribute-based encryption (SRB-ABE). Our solution is a secure and lightweight bilateral access control system with dynamic user groups, including (1) fine-grained data user and data owner access control simultaneously; (2) outsourced data source identification; (3) server-aided user revocation with publicly updatable ciphertexts; and (4) lightweight data decryption mechanism with one exponentiation computation. We present the formal definition and concrete construction of SRB-ABE with security proofs to build cloud-fog systems. The extensive comparison and experimental analysis demonstrate that our construction has superior functionality and comparable performance than the most relevant solutions.}
}


@article{DBLP:journals/tifs/KoumpouziSD21,
	author = {Chryssalenia Koumpouzi and
                  Predrag Spasojevic and
                  Fikadu T. Dagefu},
	title = {Improved {LPD} Characteristics for {QS-DS-CDMA} Employing Randomization
                  Techniques},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4762--4771},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3114065},
	doi = {10.1109/TIFS.2021.3114065},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KoumpouziSD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Easily and flexibly deployable ad-hoc communication networks emerging in tactical military or even civilian contexts, frequently suffer from poor synchronization due to lack of coordinating infrastructure. In addition to synchronization issues, and especially in military settings, security from the aspect of detectability is also of crucial importance. Imperfect synchronization can be dealt with by making use of Quasi-Synchronous Code Division Multiple Access (QS-CDMA), relying on Loosely Synchronous Codes to maintain orthogonality in the presence of limited time delays. Security, in terms of low probability of detection (LPD) from the standpoint of a malicious adversary, can be improved (reduced detection) by employing randomization techniques that disrupt the inherent structure of the transmitted QS-CDMA signals. This is based on the fact that QS-CDMA signals are Cyclostationary, having (almost) periodic Auto-Correlation functions (ACF) due to eminent signal periodicities (such as spreading code repetition). In this paper, we propose techniques to disturb the ACF and equivalently the Spectral Correlation function, and reduce the Degree of Cyclostationarity (DCS), our LPD measure. Specifically, we investigate randomization via 1) random per symbol time dithering and 2) random selection of spreading sequences, as well as a hybrid approach combining time dithering and code randomization. In all proposed techniques knowledge of the randomization pattern is not required at the legitimate receiver. We derive the Spectral Correlation function of the QS-CDMA signal under the proposed randomization schemes and compare it to simulations. We show through analysis and extensive numerical simulations that the proposed technique can reduce the DCS by almost two orders of magnitude. We also show that enhanced LPD can be achieved using the proposed techniques while sacrificing a part of the reduced time synchronization requirement. We further analyze the implications of the friendly receiver not knowing the randomization pattern and present results on the resulting communication performance.}
}


@article{DBLP:journals/tifs/WangSLMJ21,
	author = {Yue Wang and
                  Esha Sarkar and
                  Wenqing Li and
                  Michail Maniatakos and
                  Saif Eddin Jabari},
	title = {Stop-and-Go: Exploring Backdoor Attacks on Deep Reinforcement Learning-Based
                  Traffic Congestion Control Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4772--4787},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3114024},
	doi = {10.1109/TIFS.2021.3114024},
	timestamp = {Tue, 02 Aug 2022 16:40:55 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangSLMJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent work has shown that the introduction of autonomous vehicles (AVs) in traffic could help reduce traffic jams. Deep reinforcement learning methods demonstrate good performance in complex control problems, including autonomous vehicle control, and have been used in state-of-the-art AV controllers. However, deep neural networks (DNNs) render automated driving vulnerable to machine learning-based attacks. In this work, we explore the backdooring/trojanning of DRL-based AV controllers. We develop a trigger design methodology that is based on well-established principles of traffic physics. The malicious actions include vehicle deceleration and acceleration to cause stop-and-go traffic waves to emerge (congestion attacks) or AV acceleration resulting in the AV crashing into the vehicle in front (insurance attack). We test our attack on single-lane and two-lane circuits. Our experimental results show that the backdoored model does not compromise normal operation performance, with the maximum decrease in cumulative rewards being 1%. Still, it can be maliciously activated to cause a crash or congestion when the corresponding triggers appear.}
}


@article{DBLP:journals/tifs/ZhangCZWL21,
	author = {Xuxin Zhang and
                  Jian Chen and
                  Rui Zhang and
                  Chen Wang and
                  Ling Liu},
	title = {Attacking Recommender Systems With Plausible Profile},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4788--4800},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3117078},
	doi = {10.1109/TIFS.2021.3117078},
	timestamp = {Mon, 05 Feb 2024 20:21:14 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangCZWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems (RS) have become an essential component of web services due to their excellent performance. Despite their great success, RS have proved to be vulnerable to data poisoning attacks, which inject well-crafted fake profiles into RS, so that the target items can be maliciously recommended. In this paper, we first reveal that existing poisoning attacks in RS can be detected effortlessly, as the features of the generated fake profiles cannot be inconsistent with those of normal profiles all the time. We further propose RecUP, a poisoning attack in RS that can generate plausible profiles whose features stay almost the same as the normal ones, based on Generative Adversarial Networks (GAN). To tailor GAN for poisoning in RS, we develop HRGAN and devise a loss function to guide the training of the generator, along with a masking operation with selected potentially powerful profiles, so that the final generated profiles can perform malicious recommendations as expected. Evaluations against various defense methods using three real-world datasets show that, RecUP can generate the most plausible profiles while maintaining comparable attacking performance compared with state-of-the-art attacks.}
}


@article{DBLP:journals/tifs/Szalachowski21,
	author = {Pawel Szalachowski},
	title = {Password-Authenticated Decentralized Identities},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4801--4810},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3116429},
	doi = {10.1109/TIFS.2021.3116429},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/Szalachowski21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Password-authenticated identities, where users establish username-password pairs with individual servers and use them later on for authentication, is the most widespread user authentication method over the Internet. Although they are simple, user-friendly, and broadly adopted, they offer insecure authentication and position server operators as trusted parties, giving them full control over users’ identities. To mitigate these limitations, many identity systems have embraced public-key cryptography and the concept of decentralization. All these systems; however, require users to create and manage public-private keypairs. Unfortunately, users usually do not have the required knowledge and resources to properly handle cryptographic secrets, which arguably contributed to the failures of many end-user public-key infrastructures (PKIs). In fact, as of today, no end-user PKI, able to authenticate users to web servers, has a significant adoption rate. In this paper, we propose Password-authenticated Decentralized Identities (PDIDs), an identity and authentication framework where users can register their self-sovereign username-password pairs and use them as universal credentials. Our system provides a global namespace, human-meaningful usernames, and resilience against username collision attacks. A user’s identity can be used to authenticate the user to any server without revealing that server anything about the password, such that no offline dictionary attacks are possible against the password. We analyze PDIDs and implement it using existing infrastructures and tools. We report on our implementation and evaluation.}
}


@article{DBLP:journals/tifs/JoshiVZMD21,
	author = {Sonal Joshi and
                  Jes{\'{u}}s Villalba and
                  Piotr Zelasko and
                  Laureano Moro{-}Vel{\'{a}}zquez and
                  Najim Dehak},
	title = {Study of Pre-Processing Defenses Against Adversarial Attacks on State-of-the-Art
                  Speaker Recognition Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4811--4826},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3116438},
	doi = {10.1109/TIFS.2021.3116438},
	timestamp = {Wed, 26 Oct 2022 13:15:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JoshiVZMD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial examples are designed to fool the speaker recognition (SR) system by adding a carefully crafted human-imperceptible noise to the speech signals. Posing a severe security threat to state-of-the-art SR systems, it becomes vital to deep-dive and study their vulnerabilities. Moreover, it is of greater importance to propose countermeasures that can protect the systems against these attacks. Addressing these concerns, we first investigated how state-of-the-art x-vector based SR systems are affected by white-box adversarial attacks, i.e., when the adversary has full knowledge of the system. x-Vector based SR systems are evaluated against white-box adversarial attacks common in the literature like fast gradient sign method (FGSM), basic iterative method (BIM)–a.k.a. iterative-FGSM–, projected gradient descent (PGD), and Carlini-Wagner (CW) attack. To mitigate against these attacks, we investigated four pre-processing defenses which do not need adversarial examples during training. The four pre-processing defenses–viz. randomized smoothing, DefenseGAN, variational autoencoder (VAE), and Parallel WaveGAN vocoder (PWG) are compared against the baseline defense of adversarial training. Performing powerful adaptive white-box adversarial attack (i.e., when the adversary has full knowledge of the system, including the defense), our conclusions indicate that SR systems were extremely vulnerable under BIM, PGD, and CW attacks. Among the proposed pre-processing defenses, PWG combined with randomized smoothing offers the most protection against the attacks, with accuracy averaging 93% compared to 52% in the undefended system and an absolute improvement >90% for BIM attacks with\nL\n∞\n>0.001\nand CW attack.}
}


@article{DBLP:journals/tifs/YanWLLG21,
	author = {Zhicong Yan and
                  Jun Wu and
                  Gaolei Li and
                  Shenghong Li and
                  Mohsen Guizani},
	title = {Deep Neural Backdoor in Semi-Supervised Learning: Threats and Countermeasures},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4827--4842},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3116431},
	doi = {10.1109/TIFS.2021.3116431},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YanWLLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Semi-Supervised Learning (SSL) is a powerful derivative for humans to discover the hidden knowledge, and will be a great substitute for data taggers. Although the availability of unlabeled data rises up a huge passion to SSL, the untrustness of unlabeled data leads to many unknown security risks. In this paper, we first identify an insidious backdoor threat of SSL where unlabeled training data are poisoned by backdoor methods migrated from supervised settings. Then, to further exploit this threat, a Deep Neural Backdoor (DeNeB) scheme is proposed, which requires less data poisoning budgets and produces stronger backdoor effectiveness. By poisoning a fraction of our unlabeled training data, the DeNeB achieves the illegal manipulation on the trained model without modifying the training process. Finally, an efficient detection-and-purification defense (DePuD) framework is proposed to thwart the proposed scheme. In DePuD, we construct a deep detector to locate trigger patterns in the unlabeled training data, and perform secured SSL training with purified unlabeled data where the detected trigger patterns are obfuscated. Extensive experiments based on benchmark datasets are performed to demonstrate the huge threatening of DeNeB and the effectiveness of DePuD. To the best of our knowledge, this is the first work to achieve the backdoor and its defense in semi-supervised learning.}
}


@article{DBLP:journals/tifs/HuangZ21,
	author = {Linan Huang and
                  Quanyan Zhu},
	title = {Duplicity Games for Deception Design With an Application to Insider
                  Threat Mitigation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4843--4856},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3118886},
	doi = {10.1109/TIFS.2021.3118886},
	timestamp = {Wed, 03 Nov 2021 08:27:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent incidents such as the Colonial Pipeline ransomware attack and the SolarWinds hack have shown that traditional defense techniques are becoming insufficient to deter adversaries of growing sophistication. Proactive and deceptive defenses are an emerging class of methods to defend against zero-day and advanced attacks. This work develops a new game-theoretic framework called the duplicity game to design deception mechanisms that consist of a generator, an incentive modulator, and a trust manipulator, referred to as the GMM mechanism. We formulate a mathematical programming problem to compute the optimal GMM mechanism, quantify the upper limit of enforceable security policies, and characterize conditions on user’s identifiability and manageability for cyber attribution and user management. We develop a separation principle that decouples the design of the modulator from the GMM mechanism and an equivalence principle that turns the joint design of the generator and the manipulator into the single design of the manipulator. A case study of dynamic honeypot configurations is presented to mitigate insider threats. The numerical experiments corroborate the results that the optimal GMM mechanism can elicit desirable actions from both selfish and adversarial insiders and consequently improve the security posture of the insider network. In particular, a proper modulator can reduce the incentive misalignment between the players and achieve win-win situations for the selfish insider and the defender. Meanwhile, we observe that the defender always benefits from faking the percentage of honeypots when the optimal generator is presented.}
}


@article{DBLP:journals/tifs/AltinisikS21a,
	author = {Enes Altinisik and
                  H{\"{u}}srev T. Sencar},
	title = {Automatic Generation of {H.264} Parameter Sets to Recover Video File
                  Fragments},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4857--4868},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3118876},
	doi = {10.1109/TIFS.2021.3118876},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AltinisikS21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We address the problem of decoding video file fragments when the necessary encoding parameters are missing. With this objective, we propose a method that automatically generates H.264 video headers containing these parameters and extracts coded pictures in the partially available compressed video data. To accomplish this, we examined a very large corpus of videos to learn patterns of encoding settings commonly used by encoders and created a parameter dictionary. Further, to facilitate a more efficient search our method identifies characteristics of a coded bitstream to discriminate the entropy coding mode. It also utilizes the application logs created by the decoder to identify correct parameter values. Evaluation of the effectiveness of the proposed method on more than 55K videos with diverse provenance shows that it can generate valid headers on average in 11.3 decoding trials per video. This result represents an improvement by more than a factor of 10 over the conventional approach of video header stitching to recover video file fragments.}
}


@article{DBLP:journals/tifs/YangYWHY21,
	author = {Lu Yang and
                  Gongping Yang and
                  Kuikui Wang and
                  Fanchang Hao and
                  Yilong Yin},
	title = {Finger Vein Recognition via Sparse Reconstruction Error Constrained
                  Low-Rank Representation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4869--4881},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3118894},
	doi = {10.1109/TIFS.2021.3118894},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangYWHY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vein pattern-based methods have powerfully promoted the performance of finger vein recognition. However, it is not easy to precisely extract vein patterns from images, especially from low-quality images, and the non-vein area have been proved to be helpful for recognition. This paper proposes to use low-rank representation to extract as much noiseless discriminative information as possible from finger vein images. However, image deformation and image quality variations weaken the correlation of genuine images, and therefore damage the low-rank linear representation. To further deal with this problem, the class labels of training images and the local geometric structure between testing images and training images, reflected by sparse reconstruction errors of testing images, are used as constraints of low-rank coefficients. In particular, vein backbone decomposition based sparse representation is proposed to fast compute the deformation-robust reconstruction errors of each testing image. The reconstruction error on sub-backbones of one training image are used and modified as the constraint of the low-rank coefficient on this training image. We evaluate the proposed method on three widely used finger vein databases, and experimental results show that the proposed method performs well in finger vein recognition.}
}


@article{DBLP:journals/tifs/WangLDZW21,
	author = {An Wang and
                  Yuan Li and
                  Yaoling Ding and
                  Liehuang Zhu and
                  Yongjuan Wang},
	title = {Efficient Framework for Genetic Algorithm-Based Correlation Power
                  Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4882--4894},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3117091},
	doi = {10.1109/TIFS.2021.3117091},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangLDZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Various Artificial Intelligence (AI) techniques are combined with classic side-channel methods to improve the efficiency of attacks. Among them, Genetic-Algorithms-based Correlation Power Analysis (GA-CPA) is proposed to launch attacks on hardware cryptosystems to extract the secret key efficiently. However, the convergence efficiency of GA-CPA is unsatisfactory due to two problems: the randomly generated initial population generally have low fitness, and the mutation operation in each iteration hardly produces high-quality individuals because of the confusion and diffusion characteristics of S-boxes. In this paper, we propose an analysis framework of GA-CPA which focuses on solving these two problems. First, we explore the list of candidate key bytes which is the result of Correlation Power Analysis (CPA) on a limited number of power traces, so that the population can be initialized with high quality candidates. Second, we improve the mutation operation by guiding the candidate key to mutate in a higher-fitness direction instead of randomly. Third, we make full use of the fitness calculation method and combine it with key enumeration algorithms to further improve the efficiency of key recovery. Simulation experimental results show that our method reduces the number of traces by 33.3% and 43.9% compared to CPA with key enumeration and GA-CPA respectively when the success rate is fixed to 90%. Real experiments performed on SAKURA-G confirm that the number of traces required in our method is much less than the numbers of traces required in CPA and GA-CPA. Besides, we adjust our method to deal with DPA contest v1 dataset, and achieve a better result of 40.76 traces than the winning proposal of 42.42 traces. The computation cost of our proposal is nearly 16.7% of the winner.}
}


@article{DBLP:journals/tifs/ShimizuS21,
	author = {Kosuke Shimizu and
                  Taizo Suzuki},
	title = {Finely Tunable Bitcuboid-Based Encryption With Exception-Free Signed
                  Binarization for {JPEG} Standard},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4895--4908},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3113510},
	doi = {10.1109/TIFS.2021.3113510},
	timestamp = {Sun, 22 Oct 2023 11:15:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShimizuS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a finely tunable JPEG format-compliant perceptual encryption (FE) with two novel strategies: (i) bitcuboid-based encryption (BE) and (ii) exception-free signed binarization (ESB). BE is an intra- and inter-bitplane encryption technique that provides finely tunable perceptual degradation by encrypting constrained subspaces (‘bitcubes’) of a cuboid-shaped bit set (‘bitcuboid’). ESB is a binarization technique that redecimalizes encrypted binary sequences into signed decimal coefficients without any exception-handling by shifting the negative binary sequences one-by-one. BE with ESB (BEESB) is applied to the quantized discrete cosine transform (QDCT) domain in JPEG compression. The results of our first experiment show that the BE attains fine tunability, which means scalability of the perceptual degradation level with a single encryption method, by encrypting bitcubes of various types and sizes combinatorially. The results of our second experiment show that the BEESB suppresses the bitrate overheads and that BEESB with one of the most secure options suppresses approximately 0.80-187.58 % more of the bitrate overheads in terms of Bjøntegaard delta (BD)-rate compared with conventional methods except for some ones. The results of our third experiment show that BEESB has high resilience against attacks.}
}


@article{DBLP:journals/tifs/WangMLLMD21,
	author = {Xiangyu Wang and
                  Jianfeng Ma and
                  Feng Li and
                  Ximeng Liu and
                  Yinbin Miao and
                  Robert H. Deng},
	title = {Enabling Efficient Spatial Keyword Queries on Encrypted Data With
                  Strong Security Guarantees},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4909--4923},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3118880},
	doi = {10.1109/TIFS.2021.3118880},
	timestamp = {Tue, 16 Jan 2024 21:02:51 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangMLLMD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Structured Encryption (STE), which allows a server to provide secure search services on encrypted data structures, has been widely investigated in recent years. To meet expressive search requirements in practical applications, a large number of STE constructions have been proposed either on textual keywords or spatial data. However, STE on spatio-textual data, which are widely used in location-based services, has not been fully investigated. In this paper, we formally define the notion of Spatial Keyword Structured Encryption (SKSE) and propose several concrete SKSE constructions with various efficiency-security trade-offs. Firstly, we propose a basic construction with linear search complexity, which only leaks the private files matching both spatial range query and all query keywords. Then, to improve the search efficiency on large-scale datasets, we present a novel tree-based construction with sub-linear search complexity. Finally, we introduce a post-validation approach to remove false positives and further improve storage and search performance. Our constructions are general in the sense that they can be constructed from any hidden vector encryption schemes, including public-key setting and symmetric-key setting, which can meet different sharing requirements. Our rigorous security analysis and comprehensive performance evaluation demonstrate that the proposed constructions are secure and outperform the start-of-the-art solutions.}
}


@article{DBLP:journals/tifs/KuppaL21,
	author = {Aditya Kuppa and
                  Nhien{-}An Le{-}Khac},
	title = {Adversarial {XAI} Methods in Cybersecurity},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4924--4938},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3117075},
	doi = {10.1109/TIFS.2021.3117075},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KuppaL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning methods are playing a vital role in combating ever-evolving threats in the cybersecurity domain. Explanation methods that shed light on the decision process of black-box classifiers are one of the biggest drivers in the successful adoption of these models. Explaining predictions that address ‘Why?/Why Not?’ questions help users/stakeholders/analysts understand and accept the predicted outputs with confidence and build trust. Counterfactual explanations are gaining popularity as an alternative method to help users to not only understand the decisions of black-box models (why?) but also to provide a mechanism to highlight mutually exclusive data instances that would change the outcomes (why not?). Recent Explainable Artificial Intelligence literature has focused on three main areas: (a) creating and improving explainability methods that help users better understand how the internal of ML models work as well as their outputs; (b) attacks on interpreters with a white-box setting; (c) defining the relevant properties, metrics of explanations generated by models. Nevertheless, there is no thorough study of how the model explanations can introduce new attack surfaces to the underlying systems. A motivated adversary can leverage the information provided by explanations to launch membership inference, and model extraction attacks to compromise the overall privacy of the system. Similarly, explanations can also facilitate powerful evasion attacks such as poisoning and back door attacks. In this paper, we cover this gap by tackling various cybersecurity properties and threat models related to counterfactual explanations. We propose a new black-box attack that leverages Explainable Artificial Intelligence (XAI) methods to compromise the confidentiality and privacy properties of underlying classifiers. We validate our approach with datasets and models used in the cyber security domain to demonstrate that our method achieves the attacker’s goal under threat models which reflect the real-world settings.}
}


@article{DBLP:journals/tifs/KimL21,
	author = {Sang Wu Kim and
                  Xudong Liu},
	title = {Crypto-Aided {MAP} Test for Low-Latency Detection of False Data in
                  Short Packets},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4939--4949},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3118887},
	doi = {10.1109/TIFS.2021.3118887},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KimL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptography has been used as the first line of defense to ensure data integrity. However, it incurs a significant overhead for short packets which represent the most common form of traffic in emerging applications, such as the Internet of Things. In this paper, we propose an interdisciplinary framework for detecting false data in short packets that are collected from multiple sources through a relay. The proposed scheme performs a lightweight cryptographic integrity check that employs a short message authentication code, thereby reducing the overhead for data integrity, followed by the maximum a posteriori (MAP) test at the physical layer that detects any remaining false data that the cryptographic integrity check misses. This interdisciplinary approach interplays between the cryptographic integrity check and the physical-layer integrity check to assure the data integrity of short packets with reduced overhead and low latency. The proposed scheme can also provide a significant reduction in the average probability of detection error over the traditional cryptographic integrity check.}
}


@article{DBLP:journals/tifs/YueLWW21,
	author = {Meng Yue and
                  Jing Li and
                  Zhijun Wu and
                  Minxiao Wang},
	title = {High-Potency Models of LDoS Attack Against {CUBIC} + {RED}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4950--4965},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3117066},
	doi = {10.1109/TIFS.2021.3117066},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YueLWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A TCP-targeted Low-rate denial of service (LDoS) attack exploits the vulnerabilities of TCP congestion control mechanism. CUBIC is the most widely used TCP congestion control algorithm today. CUBIC TCP increases the resilience against LDoS over traditional TCP. This paper explores high-potency patterns of the LDoS attack against CUBIC TCP under RED queue management scenario, and accordingly develops two attack models referring to maximizing attack potency. Theoretical analyses and extensive experiments are conducted to validate the proper function of the two models and evaluate their performance. Test results show that the two attack models can effectively throttle CUBIC TCP throughput. Under standard-configured network parameters, the number of TCP units damaged by one attack unit are up to about 21 and 26 respectively for our proposed two models, which represents an increase in attack potency of about 20%. And, our proposed models outperform the traditional attack model in terms of attack potency by at least 250%. In addition, with variations in different network parameters, these two models are still efficient and alternatively maximize the attack potency. Finally, an outline for the attack countermeasure is discussed. The present study offers a basis to explore new attack manners which may be exploited by attackers and excites defenders to develop new measurements against such attack.}
}


@article{DBLP:journals/tifs/Gkoulalas-Divanis21,
	author = {Aris Gkoulalas{-}Divanis and
                  Dinusha Vatsalan and
                  Dimitrios Karapiperis and
                  Murat Kantarcioglu},
	title = {Modern Privacy-Preserving Record Linkage Techniques: An Overview},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4966--4987},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3114026},
	doi = {10.1109/TIFS.2021.3114026},
	timestamp = {Wed, 03 Nov 2021 08:27:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Gkoulalas-Divanis21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Record linkage is the challenging task of deciding which records, coming from disparate data sources, refer to the same entity. Established back in 1946 by Halbert L. Dunn, the area of record linkage has received tremendous attention over the years due to its numerous real-world applications, and has led to a plethora of technologies, methods, metrics, and systems. A major direction in record linkage regards methods for linking records in a privacy-preserving manner, where sensitive and personally identifiable information in the records is not leaked as part of the linkage process. In this article, we provide an overview of the large body of research literature in privacy-preserving record linkage, discuss the different generations of techniques that have been proposed, their advantages and limitations, and present a taxonomy as well as an extensive survey on the latest generation of methods. We conclude this work with a roadmap to the new generation of analytics-driven techniques that aims to address some of the major challenges in the field.}
}


@article{DBLP:journals/tifs/DongJDW21,
	author = {Qiying Dong and
                  Chunfu Jia and
                  Fei Duan and
                  Ding Wang},
	title = {{RLS-PSM:} {A} Robust and Accurate Password Strength Meter Based on
                  Reuse, Leet and Separation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {4988--5002},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3107147},
	doi = {10.1109/TIFS.2021.3107147},
	timestamp = {Mon, 28 Aug 2023 21:40:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DongJDW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Password strength meters (PSMs) are being widely used, but they often give conflicting, inaccurate and misleading feedback, which defeats their purpose. Except for fuzzyPSM, all PSMs assume passwords are newly constructed, which is not true in reality. FuzzyPSM considers password reuse, six major leet transformations and initial capitalization, and performs the best as evaluated by Golla and Dürmuth at ACM CCS’18. On the basis of fuzzyPSM, we propose a new PSM based on R euse, L eet and S eparation, namely RLS-PSM. First, we classify password reuse behaviors into capitalization and those that use special characters for leet or separation, and calculate the corresponding probabilities. Then, to balance efficiency and precision, we use Long Short-Term Memory to calculate the probabilities of alphanumeric strings. Besides, we propose to use benchmark passwords to show the relative strength of a password. Due to the varied impacts of different service types and diversified economic value of websites, we consider parameter settings of RLS-PSM under six different service types. Finally, we use the Monte Carlo method and weighted Spearman coefficient to measure and compare the robustness and accuracy of RLS-PSM, leading PSMs (including Markov-based PSM, PCFG-based PSM, fuzzyPSM, RNN, and Zxcvbn), and password cracking tools (including JtR and Hashcat). We find that the robustness of RLS-PSM is significantly higher than all counterparts when evaluating attempts > 10 4 (e.g., on average, Fraction of Successfully Evaluated passwords of RLS-PSM is 18.9% higher than fuzzyPSM). The accuracy of RLS-PSM is also better than other mainstream PSMs used for comparison in this paper, except for fuzzyPSM.}
}


@article{DBLP:journals/tifs/LuoMLCH21,
	author = {Mandi Luo and
                  Xin Ma and
                  Zhihang Li and
                  Jie Cao and
                  Ran He},
	title = {Partial {NIR-VIS} Heterogeneous Face Recognition With Automatic Saliency
                  Search},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5003--5017},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3122072},
	doi = {10.1109/TIFS.2021.3122072},
	timestamp = {Fri, 26 Jan 2024 21:32:25 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LuoMLCH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Near-infrared-visual (NIR-VIS) heterogeneous face recognition (HFR) aims to match NIR face images with the corresponding VIS ones. It is a challenging task due to the sensing gaps among different modalities. Occlusions in the input face images make the task extremely complex. To tackle these problems, we present a Saliency Search Network (SSN) to extract domain-invariant identity features. We propose to automatically search the efficient parts of face images in a modality-aware manner, and remove redundant information. Moreover, the searching process is guided by an information bottleneck network, which mitigates the overfitting problems caused by small datasets. Extensive experiments on both complete and partial NIR-VIS HFR on multiple datasets demonstrate the effectiveness and robustness of the proposed method to modality discrepancy and occlusions.}
}


@article{DBLP:journals/tifs/BastamiLMABH21,
	author = {Hamed Bastami and
                  Mehdi Letafati and
                  Majid Moradikia and
                  Ahmed Abdelhadi and
                  Hamid Behroozi and
                  Lajos Hanzo},
	title = {On the Physical Layer Security of the Cooperative Rate-Splitting-Aided
                  Downlink in {UAV} Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5018--5033},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3122989},
	doi = {10.1109/TIFS.2021.3122989},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BastamiLMABH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned Aerial Vehicles (UAVs) have found compelling applications in intelligent logistics, search and rescue as well as in air-borne Base Station (BS). However, their communications are prone to both channel errors and eavesdropping. Hence, we investigate the max-min secrecy fairness of UAV-aided cellular networks, in which Cooperative Rate-Splitting (CRS) aided downlink transmissions are employed by each multi-antenna UAV Base Station (UAV-BS) to safeguard the downlink of a two-user Multi-Input Single-Output (MISO) system against an external multi-antenna Eavesdropper ( $Eve$ ). Realistically, only Imperfect Channel State Information (ICSI) is assumed to be available at the transmitter. Additionally, we consider a realistic total power constraint and guarantee the specific Quality of Service (QoS) requirements of the legitimate users. To handle the worst-case channel uncertainty of the legitimate users and an external $Eve$ , we conceive a robust secure resource allocation algorithm, which maximizes the minimum worst-case secrecy rate of the legitimate users. Based on the CRS principle, the transmitter splits and encodes the messages of legitimate users into common as well as private streams and the user having stronger CSI is asked to help the cell-edge user by opportunistically forwarding its decoded common message. In contrast to the existing schemes adopted in the literature for ensuring secure transmission of the first cooperative phase only, in our proposed solution the common message has a twin-fold mission. Explicitly, apart from serving as the desired message, it also acts as Artificial Noise (AN) for drowning out $Eve$ without consuming extra power. This is in stark contrast to the conventional AN designs. In the second phase, the pure AN is directed towards the $Eve$ , deploying a robust Maximum Ratio Transmitter (MRT) beamformer at the UAV-BS. To solve the resultant non-convex optimization problem we resort to the Sequential Parametric Convex Approximation (SPCA) method together with a bespoke initialization algorithm to avoid any failure due to infeasibility. Our simulation results confirm that the proposed secure transmission scheme outperforms the existing cooperative benchmarkers.}
}


@article{DBLP:journals/tifs/KrishnanTM21,
	author = {Arya Krishnan and
                  Tony Thomas and
                  Deepak Mishra},
	title = {Finger Vein Pulsation-Based Biometric Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5034--5044},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3122073},
	doi = {10.1109/TIFS.2021.3122073},
	timestamp = {Wed, 15 Dec 2021 10:31:55 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KrishnanTM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finger vein has become an appealing biometric trait due to its intrinsic nature, contactless acquisition and anti-spoofing capability when compared to other dominant biometric traits. The state-of-the-art intrinsic recognition derives vein patterns based on either curvature values, line tracking or deep neural networks. However, these methods extract artifacts such as noise, breaks and texture along with veins due to the problems such as irregular shading, poor contrast and blurriness in NIR images which affect the recognition accuracy. To deal with these issues, we propose a novel acquisition mechanism for vein patterns based on the pulsation of the veins. We propose to capture the pulsations from vein videos to accurately isolate the vein patterns. Besides, the proposed framework has an inherent method of detecting liveness along with recognition of the finger vein. To the best of our knowledge, this is the first work that utilizes the finger vein pulsations for biometric recognition. We acquired a finger vein video dataset, from 320 subjects, to evaluate the proposed method. The experimental results indicate that the proposed approach has a better recognition performance compared to the existing image-based approaches with an EER (%) of 0.8 and a recognition accuracy of 96.35%.}
}


@article{DBLP:journals/tifs/BassitHPKVP21,
	author = {Amina Bassit and
                  Florian Hahn and
                  Joep Peeters and
                  Tom Kevenaar and
                  Raymond N. J. Veldhuis and
                  Andreas Peter},
	title = {Fast and Accurate Likelihood Ratio-Based Biometric Verification Secure
                  Against Malicious Adversaries},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5045--5060},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3122823},
	doi = {10.1109/TIFS.2021.3122823},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BassitHPKVP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biometric verification has been widely deployed in current authentication solutions as it proves the physical presence of individuals. Several solutions have been developed to protect the sensitive biometric data in such systems that provide security against honest-but-curious (a.k.a. semi-honest) attackers. However, in practice, attackers typically do not act honestly and multiple studies have shown severe biometric information leakage in such honest-but-curious solutions when considering dishonest, malicious attackers. In this paper, we propose a provably secure biometric verification protocol to withstand malicious attackers and prevent biometric data from any leakage. The proposed protocol is based on a homomorphically encrypted log likelihood-ratio (HELR) classifier that supports any biometric modality (e.g., face, fingerprint, dynamic signature, etc.) encoded as a fixed-length real-valued feature vector. The HELR classifier performs an accurate and fast biometric recognition. Furthermore, our protocol, which is secure against malicious adversaries, is designed from a protocol secure against semi-honest adversaries enhanced by zero-knowledge proofs. We evaluate both protocols for various security levels and record a sub-second speed (between 0.37s and 0.88s) for the protocol secure against semi-honest adversaries and between 0.95s and 2.50s for the protocol secure against malicious adversaries.}
}


@article{DBLP:journals/tifs/WangB21a,
	author = {Zisheng Wang and
                  Rick S. Blum},
	title = {Algorithms and Analysis for Optimizing the Tracking Performance of
                  Cyber Attacked Sensor-Equipped Connected Vehicle Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5061--5076},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3122070},
	doi = {10.1109/TIFS.2021.3122070},
	timestamp = {Mon, 28 Aug 2023 21:40:51 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangB21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sensor-equipped connected vehicle networks (SECVNs) have the potential to enable substantially safer driving by improved object tracking, which is an important basic building block in SECVNs. Unfortunately, cyber-attacks on SECVNs pose a very serious threat which could lead to unacceptable outcomes, including fatalities. Recently there has been increasing focus on malicious attack detection and mitigation in SECVNs, and some of this work has considered attacks on sensor data to impact object tracking. Unfortunately, low complexity mitigation approaches which do not compromise performance are lacking. This paper describes an efficient machine-learning enhanced approach for tracking under cyber-attacks. By proper selection of some variances related to the sensor and prior probability density functions, under some assumptions the performance can be made as close as desired to a bound on the best possible performance. However, the complexity of this new approach is dramatically lower than the best existing published low complexity approach, which provides performance which is substantially inferior to that provided by the new approach. The new approach also provides much better scaling with the size of the SECVN. In particular, the complexity increases linearly in the number of sensors, while the best low complexity published approach has a complexity which grows quadratically in the number of sensors. The new approach is also applicable to other tracking applications.}
}


@article{DBLP:journals/tifs/GohilTSPR21,
	author = {Vasudev Gohil and
                  Mark Tressler and
                  Kevin Sipple and
                  Satwik Patnaik and
                  Jeyavijayan Rajendran},
	title = {Games, Dollars, Splits: {A} Game-Theoretic Analysis of Split Manufacturing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5077--5092},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3122827},
	doi = {10.1109/TIFS.2021.3122827},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GohilTSPR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Split manufacturing has been proposed as a defense to prevent threats like intellectual property (IP) piracy and illegal overproduction of integrated circuits (ICs). Over the last few years, researchers have developed a plethora of attack and defense techniques, creating a cat-and-mouse game between defending designers and attacking foundries. In this paper, we take an orthogonal approach to this ongoing research in split manufacturing; rather than developing an attack or a defense technique, we propose a means to analyze different attack and defense techniques. To that end, we develop a game-theoretic framework that helps researchers evaluate their new and existing attack and defense techniques. We model two attack scenarios using two different types of games and obtain the optimal defense strategies. We perform extensive simulations with our proposed framework, using nine different attacks and a class of placement and routing-based defense techniques on various benchmarks to gain deeper insights into split manufacturing. For instance, our framework indicates that the optimal defense techniques in the two attack scenarios are the same. Moreover, larger benchmarks are secure by naïve split manufacturing and do not require any additional defense technique under our cost model and considered attacks. We also uncover a counter-intuitive finding—an attacker using the network-flow attack should not use all the hints; instead, she should use only a subset.}
}


@article{DBLP:journals/tifs/YuHYK21,
	author = {Jian Yu and
                  Yuewang He and
                  Qiben Yan and
                  Xiangui Kang},
	title = {SpecView: Malware Spectrum Visualization Framework With Singular Spectrum
                  Transformation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5093--5107},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3124725},
	doi = {10.1109/TIFS.2021.3124725},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YuHYK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of automation tools including polymorphic and metamorphic engines, generic packers, and genetic programming, many variants of malware have emerged, which pose a significant threat to the Internet security. To effectively detect malware variants, researchers have developed visualization-based approaches that can visualize malware adaptations for in-depth malware analysis. However, most existing visualization approaches rely on the binary image of a malware sample, which fail to provide an effective texture feature representation and thus often result in low efficiency in coping with challenging malware samples. In this paper, we propose SpecView , a malware spectrum visualization framework with singular spectrum transformation. SpecView converts malware binary code into one-dimensional time series spectrum data, and leverages the singular spectrum transformation method to obtain the structural changes preserved in the time series spectrum data. Then, we utilize the particle swarm optimization algorithm to optimize the singular spectrum transformation performance in SpecView. We apply SpecView in the task of malware classification. Extensive experimental results show that SpecView is effective and efficient in malware classification on the Malimg, Malheur, Drebin, and PRAGuard Malgenome Class Encryption datasets, with classification accuracy exceeding 99%, and it can effectively identify malware variants that use evasive techniques such as packer and encryption obfuscation. The proposed method outperforms the state-of-the-art methods on all datasets and the classification accuracy reaches 100% for 5 malware families packed by the UPX packer on the Malimg dataset, as well as 9 malware families that use Class Encryption obfuscation techniques on the PRAGuard Malgenome Class Encryption datasets.}
}


@article{DBLP:journals/tifs/ArribasZN21,
	author = {Victor Arribas and
                  Zhenda Zhang and
                  Svetla Nikova},
	title = {{LLTI:} Low-Latency Threshold Implementations},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5108--5123},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3123527},
	doi = {10.1109/TIFS.2021.3123527},
	timestamp = {Sun, 02 Oct 2022 15:51:00 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ArribasZN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the enormous increase in portable cryptographic devices, physical attacks are becoming similarly popular. One of the most common physical attacks is Side-Channel Analysis (SCA), extremely dangerous due to its non-invasive nature. Threshold Implementations (TI) was proposed as the first countermeasure to provide provable security in masked hardware implementations. While most works on hardware masking are focused on optimizing the area requirements, with the newer and smaller technologies area is taking a backseat, and low-latency is gaining importance. In this work, we revisit the scheme proposed by Arribas et al. in TCHES 2018 to secure unrolled implementations. We formalize and expand this methodology, to devise a masking scheme, derived from TI, designed to secure hardware implementations optimized for latency named Low-Latency Threshold Implementations (LLTI). By applying the distributive property and leveraging a divide-and-conquer strategy, we split a non-linear operation in layers which are masked separately. The result is a more efficient scheme than the former TI for any operation of algebraic degree greater than two, achieving great optimizations both in terms of speed and area. We compare the performance of first-order LLTI with first-order TI in securing a cubic gate and a degree-7 AND gate without using any registers in between. We achieve a 137% increase in maximum frequency and a 60% reduction in area for the cubic gate, and 3131 times reduction in area in the case of a degree-7 AND gate compared to TI. To further illustrate the power of our scheme we take a low-latency PRINCE implementation from the literature and, by simply changing the secure S-box with the LLTI version, we achieve a 46% max. frequency improvement and a 38% area reduction. Moreover, we apply LLTI to a secure a low-latency AES implementation and compare it with the TI version, achieving a 6.9 times max. freq. increase and a 47.2% area reduction.}
}


@article{DBLP:journals/tifs/HwangTH21,
	author = {Dae Yon Hwang and
                  Bilal Taha and
                  Dimitrios Hatzinakos},
	title = {{PBGAN:} Learning {PPG} Representations From {GAN} for Time-Stable
                  and Unique Verification System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5124--5137},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3122817},
	doi = {10.1109/TIFS.2021.3122817},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HwangTH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Photoplethysmography (PPG) is a non-invasive physiological signal that captures the changes in blood volume resulted from heart activity. It carries unique person-specific characteristics that can be utilized for biometric systems. Currently, the use of a biometric system is paramount to ensure the security of the user’s identity. Due to the high sensitivity of the PPG signal, it suffers from extreme variations within the same subject when obtained at different time instances. These variations impose a challenge to employ the PPG signal and hinder the algorithm generalization for many applications including verification and identification systems. In this work, we propose a PPG Biometric Generative Adversarial Network (PBGAN) to create synthetic person-specific and time-stable PPG signals for genuine samples. Two types of classification models are employed with the PBGAN where the focus is on verification scenarios. In addition, we expand our previously recorded PPG dataset from 100 to 170 participants where the new size guarantees the generalization capability of the proposed system. This database and another three public ones are employed to evaluate the performances in terms of uniqueness and time stability. Furthermore, we consider three different training strategies to simulate practical scenarios. The best results acquired from our collected database in terms of Equal Error Rate (EER) is 1.3% for the single-session and 11.5% for the two-sessions scenarios which demonstrate the effectiveness of the proposed method in improving the verification system’s performance. Compared to our previous work, we achieve 1.3% and 1.4% EER improvements in two-sessions’ databases with small computational times which reveals the superiority of our proposed approach for real applications. Later, the code and dataset can be accessed in https://github.com/eoduself .}
}


@article{DBLP:journals/tifs/CuiHCL21,
	author = {Aijiao Cui and
                  Chengkang He and
                  Chip{-}Hong Chang and
                  Hao Lu},
	title = {Identification of {FSM} State Registers by Analytics of Scan-Dump
                  Data},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5138--5153},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3123534},
	doi = {10.1109/TIFS.2021.3123534},
	timestamp = {Mon, 28 Aug 2023 21:40:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CuiHCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Big data analytics have gained tremendous successes in mining valuable information in various fields. However, its potential to solve complex problems in hardware security has not been adequately tapped. This paper presents a non-invasive approach to identify the state registers of a finite state machine (FSM) in an integrated chip. The state registers of the FSM are mined from the scan-dump data by exploiting the strongly connected property and chronologically correlated state codes of the FSM. The sequence of data scanned out of each scan register is partitioned into non-overlapping strings of high weighted frequencies by a string-matching algorithm. A coherency between a pair of registers is defined and computed based on the partitioned strings. The dimension of the coherency matrix is first reduced by pruning some registers of low influence by a regression analysis. The registers are then clustered to minimize the within-cluster variances based on their coherency values. The proposed scheme is applied to some IP cores from OpenCores. The experimental results show that our scheme can correctly identify the FSM state registers in most designs with high hit rate.}
}


@article{DBLP:journals/tifs/LiuZZH21,
	author = {Yi Liu and
                  Dingwen Zhang and
                  Qiang Zhang and
                  Jungong Han},
	title = {Integrating Part-Object Relationship and Contrast for Camouflaged
                  Object Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5154--5166},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3124734},
	doi = {10.1109/TIFS.2021.3124734},
	timestamp = {Mon, 30 Jan 2023 08:27:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuZZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Object detectors that solely rely on image contrast are struggling to detect camouflaged objects in images because of the high similarity between camouflaged objects and their surroundings. To address this issue, in this paper, we investigate the role of the part-object relationship for camouflaged object detection. Specifically, we propose a Part-Object relationship and Contrast Integrated Network (POCINet) covering both search and identification stages, where each stage adopts an appropriate scheme to engage the contrast information and part-object relational knowledge for camouflaged pattern decoding. Besides, we bridge these two stages via a Search-to-Identification Guidance (SIG) module, in which the search result, as well as decoded semantic knowledge, jointly enhances the features encoding ability of the identification stage. Experimental results demonstrate the superiority of our algorithm on three datasets. Notably, our algorithm raises\nF\nβ\nof the best existing method by approximately 17 points on the CPD1K dataset. The source code will be released soon.}
}


@article{DBLP:journals/tifs/ZhangHCWGWLNX21,
	author = {Zhi Zhang and
                  Wei He and
                  Yueqiang Cheng and
                  Wenhao Wang and
                  Yansong Gao and
                  Minghua Wang and
                  Kang Li and
                  Surya Nepal and
                  Yang Xiang},
	title = {BitMine: An End-to-End Tool for Detecting Rowhammer Vulnerability},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5167--5181},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3124728},
	doi = {10.1109/TIFS.2021.3124728},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangHCWGWLNX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rowhammer is a destructive software-induced DRAM fault, which an attacker can leverage to break system security. Both individual customers and enterprise users (e.g., cloud providers) might refrain from using a computing system if it is vulnerable to rowhammer vulnerability. In this paper, we provide the first end-to-end tool, coined BitMine, that systematically assesses a DRAM chip’s vulnerability to rowhammer bit flips. BitMine is an extension of DRAMDig. As DRAM address mappings are proprietary techniques and critical in inducing rowhammer bit flips, DRAMDig, our prior work, leverages domain knowledge to efficiently and deterministically reverse-engineer DRAM address mappings on Intel machines. By incorporating DRAMDig, BitMine configures three key parameters, i.e., hammer methods , hammer patterns , data patterns , on the effectiveness of finding rowhammer bit flips. BitMine by default implements 13 hammer methods, 4 hammer patterns and 16 data patterns and is extensible to support more. We evaluate DRAMDig and BitMine against multiple machine models that combine different DRAM chips and Intel microarchitectures. Our experiment results show that DRAMDig efficiently uncovers a deterministic DRAM address mapping for each machine model, and every implemented parameter in BitMine has its distinct effectiveness in triggering bit flips for different machine models.}
}


@article{DBLP:journals/tifs/ShaoZ21,
	author = {Huikai Shao and
                  Dexing Zhong},
	title = {Learning With Partners to Improve the Multi-Source Cross-Dataset Palmprint
                  Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5182--5194},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3125612},
	doi = {10.1109/TIFS.2021.3125612},
	timestamp = {Mon, 28 Aug 2023 21:40:49 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShaoZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Benefiting from the advantages of safety and reliability, deep learning-based palmprint recognition has attracted widespread attention. However, previous methods are mainly focused on palmprint recognition in a single dataset. In some realistic applications, a certain number of palmprint images collected from multiple devices under different conditions may be available. Due to the existing gaps between different datasets, how to efficiently use them to obtain satisfactory performance is an important and challenging issue. In this paper, we propose a novel Learning with Partners (LWP) framework to improve the multi-source cross-dataset palmprint recognition. Multiple labeled source datasets and an unlabeled dataset are selected as partners to train two feature extractors F_{S}\nand F_{T}\n. Firstly, F_{S}\nis trained as a teacher using labeled source samples to help learn F_{T}\n. Then, adaptation loss is introduced to constrain the discrepancy between source and target datasets. To alleviate the negative impact of unlabeled target samples on the model, consistency loss including two distance losses are further proposed to correct the misleading in time. Finally, F_{T}\ncan extract adaptive features to match the target with sources. Extensive experiments are conducted on several benchmark palmprint databases and the results demonstrate that our proposed LWP can outperform other comparative baselines by a large margin. The codes are publicly available at http://gr.xjtu.edu.cn/web/bell .}
}


@article{DBLP:journals/tifs/YousefTB21,
	author = {Waleed A. Yousef and
                  Issa Traor{\'{e}} and
                  William Briguglio},
	title = {{UN-AVOIDS:} Unsupervised and Nonparametric Approach for Visualizing
                  Outliers and Invariant Detection Scoring},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5195--5210},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3125608},
	doi = {10.1109/TIFS.2021.3125608},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YousefTB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The visualization and detection of anomalies (outliers) are of crucial importance to many fields, particularly cybersecurity. Several approaches have been proposed in these fields, yet to the best of our knowledge, none of them has fulfilled both objectives, simultaneously or cooperatively, in one coherent framework. Moreover, the visualization methods of these approaches were introduced for explaining the output of a detection algorithm, not for data exploration that facilitates a standalone visual detection. This is our point of departure in introducing UN-AVOIDS, an unsupervised and nonparametric approach for both visualization (a human process) and detection (an algorithmic process) of outliers, that assigns invariant anomalous scores (normalized to [0, 1]), rather than hard binary-decision. The main aspect of novelty of UN-AVOIDS is that it transforms data into a new space, which is introduced in this paper as neighborhood cumulative density function (NCDF), in which both visualization and detection are carried out. In this space, outliers are remarkably visually distinguishable, and therefore the anomaly scores assigned by the detection algorithm achieved a high area under the ROC curve (AUC). We assessed UN-AVOIDS on both simulated and two recently published cybersecurity datasets, and compared it to three of the most successful anomaly detection methods: LOF, IF, and FABOD. In terms of AUC, UN-AVOIDS was almost an overall winner with a margin that varied between −0.028 and 0.125, depending on the data. The article concludes by providing a preview of new theoretical and practical avenues for UN-AVOIDS. Among them is designing a visualization aided anomaly detection (VAAD), a type of software that aids analysts by providing UN-AVOIDS’ detection algorithm (running in a back engine), NCDF visualization space (rendered to plots), along with other conventional methods of visualization in the original feature space, all of which are linked in one interactive environment.}
}


@article{DBLP:journals/tifs/hammeAPJ21,
	author = {Tim Van hamme and
                  Enrique Argones{-}R{\'{u}}a and
                  Davy Preuveneers and
                  Wouter Joosen},
	title = {On the Security of Biometrics and Fuzzy Commitment Cryptosystems:
                  {A} Study on Gait Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5211--5224},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3124735},
	doi = {10.1109/TIFS.2021.3124735},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/hammeAPJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As biometric templates consist of highly correlated features, the real security level offered by biometric authentication systems remains an open research question. In this work we provide new approximations and a lower bound of the security offered by fuzzy commitment schemes. Fuzzy commitment cryptosystems and in general biometric template protection schemes play an important role in allowing for remote storage and processing of biometric data, as they mitigate the threat of biometric template leakage. The use of such schemes would alleviate some of the usability constraints imposed by the state-of-practice local use of biometrics. As such we conduct an in-depth security analysis for IMU based gait authentication systems, where we evaluate the effectiveness of attacks within the scope of two well-defined threat models that target both unprotected and protected systems. A pivotal enabler of our analysis is the development of nine different approaches to gait authentication, which allows us to perform intramodal fusion on these distinct, yet highly correlated biometric templates, and to protect them with a strengthened fuzzy commitment scheme. Our analysis clearly demonstrates the high correlation between the different biometric templates, which, among others, further showcases the threat of biometric template leakage. Furthermore, as our analysis incorporates a threat model that assumes biometric template leakage, it provides metrics for the security provided by the biometric modality itself.}
}


@article{DBLP:journals/tifs/ShamsiJ21,
	author = {Kaveh Shamsi and
                  Yier Jin},
	title = {In Praise of Exact-Functional-Secrecy in Circuit Locking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5225--5238},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3125242},
	doi = {10.1109/TIFS.2021.3125242},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ShamsiJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many logic locking schemes have been proposed and subsequently broken in recent years most notably by oracle-guided SAT-solver-based attacks. This has in part been due to a lack of formal definitions of security. Recent work has however taken the first steps towards this by defining some notions of security. One such notion, exact-functional-secrecy (EFS) is satisfied as soon as the attacker is not able to learn the precise functionality of the original circuit. This is less stringent than the approximate-functional-secrecy (AFS) notion of security which captures approximation-resiliency. This paper focuses on EFS. We present first a novel SAT-based attack that can automatically divide the deobfuscation of a locked circuit into two different processes: a) deobfuscating high-activity/entropy nets which contribute to AFS and are best handled by a few queries and heavy SAT-solving, and b) deobfuscating low-activity nets which require many useless queries in search of a few rare informative queries. The attack, called the rare-fast-querying (RFQ) SAT attack, guarantees key-correctness for logic outside of low-activity cones, and is not exclusive to a specific low-activity locking scheme. We show how the RFQ attack can under some conditions, avoid exponential querying altogether. Given the insight from this attack, we then present a deeper look into EFS and discuss simple techniques to achieve always-exponential EFS with bearable overhead. We show how one can take advantage of the abundance of comparator logic at the RT-level of control-oriented designs to achieve EFS with even less overhead via absorbing existing structures.}
}


@article{DBLP:journals/tifs/ChenDLWZ21,
	author = {Yuling Chen and
                  Sen Dong and
                  Tao Li and
                  Yilei Wang and
                  Huiyu Zhou},
	title = {Dynamic Multi-Key {FHE} in Asymmetric Key Setting From {LWE}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5239--5249},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3127023},
	doi = {10.1109/TIFS.2021.3127023},
	timestamp = {Fri, 19 Jan 2024 08:33:23 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenDLWZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-key Fully homomorphic encryption (MFHE) schemes allow computation on the encrypted data under different keys. However, traditional multi-key FHE schemes based on Learning with errors (LWE) have the undesirable property that is the number of keys has to be fixed in advance. A dynamic multi-key FHE scheme is the most versatile variant which the information about the participants is not required before key generation. To support further homomorphic computation on extended ciphertexts and ciphertexts encrypted under additional keys, Peikert and Shiehian (TCC ’16) proposed a leveled dynamic multi-key FHE scheme. Nevertheless, it introduces the circular-security assumption for the LWE parameters to ensure its security, which provides weaker security to the scheme. The problem of how to construct a LWE-based dynamic multi-key FHE scheme is still open. To address the above problem, in this work, we present a dynamic multi-key FHE scheme based on the LWE assumption in public key setting. The ciphertext can be extended and performed homomorphic evaluation with the ciphertexts encrypted under additional keys. Compared with current constructions, our proposed method requires fewer “ local ” memory and the process of ciphertext extension is distributed. Our proposed method provides a new way to extend the ciphertext such that the ciphertext homomorphism computation is more efficient. Our scheme is proven to be secure under standard LWE assumptions without using the circular-security assumption.}
}


@article{DBLP:journals/tifs/YanT21,
	author = {Qifa Yan and
                  Daniela Tuninetti},
	title = {Key Superposition Simultaneously Achieves Security and Privacy in
                  Cache-Aided Linear Function Retrieval},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5250--5263},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3127018},
	doi = {10.1109/TIFS.2021.3127018},
	timestamp = {Thu, 27 Jul 2023 08:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YanT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work investigates the problem of cache-aided content Secure and demand Private Linear Function Retrieval (SP-LFR), where three constraints are imposed on the system: (a) each user is interested in retrieving an arbitrary linear combination of the files in the server’s library; (b) the content of the library must be kept secure from a wiretapper who obtains the signal sent by the server; and (c) no subset of colluding users together can obtain information about the demands of the remaining users. A procedure is proposed to derive an SP-LFR scheme from a given Placement Delivery Array (PDA), which is known to give coded caching schemes with low subpacketization for systems with neither security nor privacy constraints. This procedure uses the superposition of security keys and privacy keys, in both the cache placement and transmitted signal, to guarantee content security and demand privacy, respectively. In particular, among all PDA-based SP-LFR schemes, the memory-load pairs achieved by the PDA describing the Maddah-Ali and Niesen’s scheme are Pareto optimal and have the lowest subpacketization. Moreover, the achieved load-memory tradeoff is optimal to within a constant multiplicative gap, except for the small memory regime (i.e., when the cache size is between 1 and 2) and the number of files is smaller than the number of users. Remarkably, the memory-load tradeoff does not worsen compared to the best known schemes that guarantee either only content security in all regimes or only demand privacy in the regime mentioned above.}
}


@article{DBLP:journals/tifs/LiXXJH21,
	author = {Guyue Li and
                  Yinghao Xu and
                  Wei Xu and
                  Eduard A. Jorswieck and
                  Aiqun Hu},
	title = {Robust Key Generation With Hardware Mismatch for Secure {MIMO} Communications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5264--5278},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3127021},
	doi = {10.1109/TIFS.2021.3127021},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiXXJH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In practical implementations, physical-layer key generation (PKG) encounters the bottlenecks of imperfect channel reciprocity, nearby attack, and high temporal auto-correlation. Existing One-Band Multiple-Antenna Loop-bAck key generation (OB-MALA) schemes try to address these challenges through establishing bi-directional channels via echoing rotated received signals. However, we find that OB-MALA schemes can be vulnerable to a multiply-divide (MD) attack, as they echo the received signals through the same band with the pilot signals. To overcome this deficiency, we propose a new method, named Two-Band Multiple-Antenna Loop-bAck key generation (TB-MALA), which exploits two separate bands for pilot transmission and echo reception. The TB-MALA is proved to be robust to the imperfect channel reciprocity caused by radio frequency (RF) front-ends and can resist both the nearby attack and the MD attack. It also reduces the auto-correlation of effective channels with the help of a rotation matrix. The secret key rate of TB-MALA is analyzed and the closed-form of a lower bound is derived for the worst case. Numerical results demonstrate that the proposed TB-MALA protects against these attacks and achieves performance comparable to the ideal case with the perfect reciprocity of RF front-ends. It can thus be used to form a robust, fast, and secure key generation in a multiple-input and multiple-output (MIMO) system.}
}


@article{DBLP:journals/tifs/XuXRCYJLW21,
	author = {Yifan Xu and
                  Yuhua Xu and
                  Guochun Ren and
                  Jin Chen and
                  Changhua Yao and
                  Luliang Jia and
                  Dianxiong Liu and
                  Ximing Wang},
	title = {Play it by Ear: Context-Aware Distributed Coordinated Anti-Jamming
                  Channel Access},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5279--5293},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3128249},
	doi = {10.1109/TIFS.2021.3128249},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XuXRCYJLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the anti-jamming problems in wireless communication networks. In these networks consisted of multiple devices (users), there exist two critical problems. On the one hand, users with various transmission requirements should coordinate their channel selection strategies distributedly to avoid spectrum conflicts and satisfy transmission demands. On the other hand, they also need to fully consider how to eliminate the effects of malicious attacks. To cope with the internal coordination and external confrontation challenges and accommodate the dynamic changing jamming attacks, a context-aware distributed coordinated anti-jamming channel access mechanism is proposed, which means for different cases of jamming attacks, different access strategies are adopted. In detail, to reflect the heterogeneous communication demands of users, the transmission satisfaction function is firstly introduced. Then, the multi-user anti-jamming scenario is modeled as a context-aware multi-pattern dynamic anti-jamming game, which can be decomposed into two sub-games. Here, for the case that the control channel is available, a local altruistic sub-game is introduced. While for the case that the control channel has been jammed, an anti-jamming congestion sub-game is designed. Besides, the existence of Nash Equilibriums is demonstrated. To obtain NEs, a context-aware distributed channel access (CDCA) algorithm is designed. Through game-theoretic analysis and distributed learning, global transmission satisfaction can be improved under the dynamic jamming environment. Furthermore, the fairness of the network can also be guaranteed.}
}


@article{DBLP:journals/tifs/ShomajiGGWF21,
	author = {Sumaiya Shomaji and
                  Pallabi Ghosh and
                  Fatemeh Ganji and
                  Damon L. Woodard and
                  Domenic Forte},
	title = {An Analysis of Enrollment and Query Attacks on Hierarchical Bloom
                  Filter-Based Biometric Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5294--5309},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3128821},
	doi = {10.1109/TIFS.2021.3128821},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ShomajiGGWF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A Hierarchical Bloom Filter (HBF)-based biometric framework was recently proposed to provide compact storage, noise tolerance, and fast query processing for resource-constrained environments, e.g., Internet of things (IoT). While security and privacy were also touted as features of the HBF, it was not thoroughly evaluated. Compared to the classical BFs, the HBF uses a threshold parameter to make robust authentication decisions when the HBF encounters noise in the biometric input which one would think might lead to security issues. In this paper, the attack vectors that could compromise the HBF security by increasing the false positive authentication of non-members and by leaking soft information about enrolled members are explored. With quantitative analyses, HBF-based biometric system security under these well-defined attack vectors is evaluated and it is concluded that the framework is more difficult to attack than the classical Bloom Filter. Further, experimental results show that soft biometric information is also kept private.}
}


@article{DBLP:journals/tifs/XuDZYW21,
	author = {Lei Xu and
                  Huayi Duan and
                  Anxin Zhou and
                  Xingliang Yuan and
                  Cong Wang},
	title = {Interpreting and Mitigating Leakage-Abuse Attacks in Searchable Symmetric
                  Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5310--5325},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3128823},
	doi = {10.1109/TIFS.2021.3128823},
	timestamp = {Sun, 22 Oct 2023 11:15:07 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuDZYW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searchable symmetric encryption (SSE) enables users to make confidential queries over always encrypted data while confining information disclosure to pre-defined leakage profiles. Despite the well-understood performance and potentially broad applications of SSE, recent leakage-abuse attacks (LAAs) are questioning its real-world security implications. They show that a passive adversary with certain prior information of a database can recover queries by exploiting the legitimately admitted leakage. While several countermeasures have been proposed, they are insufficient for either security, i.e., handling only specific leakage like query volume, or efficiency, i.e., incurring large storage and bandwidth overhead. We aim to fill this gap by advancing the understanding of LAAs from a fundamental algebraic perspective. Our investigation starts by revealing that the index matrices of a plaintext database and its encrypted image can be linked by linear transformation. The invariant characteristics preserved under the transformation encompass and surpass the information exploited by previous LAAs. They allow one to unambiguously link encrypted queries with corresponding keywords, even with only partial knowledge of the database. Accordingly, we devise a new powerful attack and conduct a series of experiments to show its effectiveness. In response, we propose a new security notion to thwart LAAs in general, inspired by the principle of local differential privacy (LDP). Under the notion, we further develop a practical countermeasure with tunable privacy and efficiency guarantee. Experiment results on representative real-world datasets show that our countermeasure can reduce the query recovery rate of LAAs, including our own.}
}


@article{DBLP:journals/tifs/HolzbaurKFW21,
	author = {Lukas Holzbaur and
                  Stanislav Kruglik and
                  Alexey A. Frolov and
                  Antonia Wachter{-}Zeh},
	title = {Secure Codes With Accessibility for Distributed Storage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5326--5337},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3128822},
	doi = {10.1109/TIFS.2021.3128822},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HolzbaurKFW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A distributed storage system must support efficient access to stored data while ensuring recovery of temporally unavailable nodes. Another important aspect of a distributed storage system is security. In this paper, we bring these features together and investigate the problem of efficient access to stored data in presence of a passive eavesdropper with access to limited number of nodes. The access efficiency is measured in two different terms, namely, the number of accessed nodes and the volume of generated network traffic. These quantities possess a natural connection to locality and repair bandwidth in distributed storage system. For each of them we derive bounds on parameters and provide explicit constructions based on maximum distance separable codes. Motivated by practical perspectives we propose the techniques to ensure the same workload on each node as well as constructions over small fields based on subfield subcodes, Euclidean geometry codes and Reed-Muller codes. Finally, we derive an asymptotic random coding bound on parameters of a secure distributed storage system and propose further research directions.}
}


@article{DBLP:journals/tifs/MichelettoMOR21,
	author = {Marco Micheletto and
                  Gian Luca Marcialis and
                  Giulia Orr{\`{u}} and
                  Fabio Roli},
	title = {Fingerprint Recognition With Embedded Presentation Attacks Detection:
                  Are We Ready?},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5338--5351},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3121201},
	doi = {10.1109/TIFS.2021.3121201},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MichelettoMOR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The diffusion of fingerprint verification systems for security applications makes it urgent to investigate the embedding of software-based presentation attack detection algorithms (PAD) into such systems. Companies and institutions need to know whether such integration would make the system more “secure” and whether the technology available is ready, and, if so, at what operational working conditions. Despite significant improvements, especially by adopting deep learning approaches to fingerprint PAD, current research did not state much about their effectiveness when embedded in fingerprint verification systems. We believe that the lack of works is explained by the lack of instruments to investigate the problem, that is, modeling the cause-effect relationships when two non-zero error-free systems work together. Accordingly, this paper explores the fusion of PAD into verification systems by proposing a novel investigation instrument: a performance simulator based on the probabilistic modeling of the relationships among the Receiver Operating Characteristics (ROC) of the two individual systems when PAD and verification stages are implemented sequentially. As a matter of fact, this is the most straightforward, flexible, and widespread approach. We carry out simulations on the PAD algorithms’ ROCs submitted to the most recent editions of LivDet (2017-2019), the state-of-the-art NIST Bozorth3, and the top-level Veryfinger 12 matchers. Reported experiments explore significant scenarios to get the conditions under which fingerprint matching with embedded PAD can improve, rather than degrade, the overall personal verification performance.}
}


@article{DBLP:journals/tifs/ZhouLGLLL21,
	author = {Lifang Zhou and
                  Jun Luo and
                  Xinbo Gao and
                  Weisheng Li and
                  Bangjun Lei and
                  Jiaxu Leng},
	title = {Selective Domain-Invariant Feature Alignment Network for Face Anti-Spoofing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5352--5365},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3125603},
	doi = {10.1109/TIFS.2021.3125603},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouLGLLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One primary challenge in face anti-spoofing refers to suffering a sharp performance drop in cross-domain scenes, where training and testing images are collected from different datasets. Recent methods have achieved promising results by aligning the features of all images among the available source domains. However, due to significant distribution discrepancies among non-face regions of all images, it is challenging to capture domain-invariant features for these regions. In this paper, we propose a novel Selective Domain-invariant Feature Alignment Network (SDFANet) for cross-domain face anti-spoofing, which aims to seek common feature representations by fully exploring the generalization of different regions of images. Different from previous works that align the whole features directly, the proposed SDFANet leverages multiple domain discriminators with the same architecture to balance the generalization of different regions of the all images. Specifically, we firstly design a multi-grained feature alignment network composed of a local-region and global-image alignment subnetworks to learn more generalized feature space for real faces. Besides, the domain adapter module, which aims to alleviate the large domain discrepancy with the help of the domain attention strategy, is adopted to facilitate the learning of our multi-grained feature alignment network. In addition, a multi-scale attention fusion module is designed in our feature generator to refine the different levels of features effectively. Experimental results show that the proposed SDFANet can greatly improve the generalization ability of face anti-spoofing, and that is superior to the existing methods.}
}


@article{DBLP:journals/tifs/ZhouCY21,
	author = {Yuyang Zhou and
                  Guang Cheng and
                  Shui Yu},
	title = {An SDN-Enabled Proactive Defense Framework for DDoS Mitigation in
                  IoT Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5366--5380},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3127009},
	doi = {10.1109/TIFS.2021.3127009},
	timestamp = {Fri, 30 Dec 2022 14:18:08 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouCY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is becoming truly ubiquitous in every domain of human lives, and a large number of objects can be connected and enabled to communicate with cloud servers at any time. However, complex connections and vulnerabilities of IoT devices introduce inevitable security threats, in which distributed denial-of-service (DDoS) attacks usually incur catastrophic results. Unfortunately, the existing DDoS mitigation methods cannot provide effective protection. Moreover, the amplifying complexity and increasing delay incurred by defense greatly affect the stability of IoT networks. To tackle these problems, we present a novel framework that can proactively adapt the attack surface of IoT networks, dynamically optimize defense strategies, and rapidly deploy the corresponding defense mechanisms. In particular, we establish hybrid proactive defense mechanisms combining Moving Target Defense (MTD) techniques with cyber deception to spread camouflage information to confuse attackers. Based on these mechanisms, we introduce a defender-led signaling game model to formalize defense scenarios and depict the interactions between the defender and the attacker. Besides, we present an optimal algorithm to solve decision problems and optimize defense implementation in a cost-effective manner. Our extensive experiments demonstrate that the proposed approach can effectively mitigate DDoS attacks and maintain a high level of performance in IoT networks with acceptable overhead.}
}


@article{DBLP:journals/tifs/TianZH21,
	author = {Xianhao Tian and
                  Peijia Zheng and
                  Jiwu Huang},
	title = {Robust Privacy-Preserving Motion Detection and Object Tracking in
                  Encrypted Streaming Video},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5381--5396},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3128817},
	doi = {10.1109/TIFS.2021.3128817},
	timestamp = {Mon, 28 Aug 2023 21:40:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TianZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video privacy leakage is becoming an increasingly severe public problem, especially in cloud-based video surveillance systems. It leads to the new need for secure cloud-based video applications, where the video is encrypted for privacy protection. Despite some methods that have been proposed for encrypted video moving object detection and tracking, none has robust performance against complex and dynamic scenes. In this paper, we propose an efficient and robust privacy-preserving motion detection and multiple object tracking scheme for encrypted surveillance video bitstreams. By analyzing the properties of the video codec and format-compliant encryption schemes, we propose a new compressed-domain feature to capture motion information in complex surveillance scenarios. Based on this feature, we design an adaptive clustering algorithm for moving object segmentation with an accuracy of\n4×4\npixels. We then propose a multiple object tracking scheme that uses Kalman filter estimation and adaptive measurement refinement. The proposed scheme does not require video decryption or full decompression and has a very low computation load. The experimental results demonstrate that our scheme achieves the best detection and tracking performance compared with existing works in the encrypted and compressed domain. Our scheme can be effectively used in complex surveillance scenarios with different challenges, such as camera movement/jitter, dynamic background, and shadows.}
}


@article{DBLP:journals/tifs/NiuTZNB21,
	author = {Yakun Niu and
                  Benedetta Tondi and
                  Yao Zhao and
                  Rongrong Ni and
                  Mauro Barni},
	title = {Image Splicing Detection, Localization and Attribution via {JPEG}
                  Primary Quantization Matrix Estimation and Clustering},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5397--5412},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3129654},
	doi = {10.1109/TIFS.2021.3129654},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/NiuTZNB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detection of inconsistencies of double JPEG artifacts across different image regions is often used to detect local image manipulations, like image splicing, and to localize them. In this paper, we move one step further, proposing an end-to-end system that, in addition to detecting and localizing spliced regions, can also distinguish regions coming from different donor images. We assume that both the spliced regions and the background image have undergone a double JPEG compression, and use a local estimate of the primary quantization matrix to distinguish between spliced regions taken from different sources. To do so, we cluster the image blocks according to the estimated primary quantization matrix and refine the result by means of morphological reconstruction. The proposed method can work in a wide variety of settings including aligned and non-aligned double JPEG compression, and regardless of whether the second compression is stronger or weaker than the first one. We validated the proposed approach by means of extensive experiments showing its superior performance with respect to baseline methods working in similar conditions.}
}


@article{DBLP:journals/tifs/ZhangBJXZ21,
	author = {Hui Zhang and
                  Weixin Bian and
                  Biao Jie and
                  Deqin Xu and
                  Jun Zhao},
	title = {A Complete User Authentication and Key Agreement Scheme Using Cancelable
                  Biometrics and {PUF} in Multi-Server Environment},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5413--5428},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3128826},
	doi = {10.1109/TIFS.2021.3128826},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangBJXZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the current development and popularization of biometrics recognition technology, our biometrics and other identity information may be illegal bulk scalping, and there is the possibility of being used for false enrolment, network fraud and other illegal criminal activities. Although some network platforms based on biometrics recognition adopt multi-identity authentication, network hacking technology is also improving constantly. Therefore, we must not ignore the importance of biometrics data protection. To this end, we propose a complete user authentication protocol and key agreement scheme based on cancelable biometrics and physical unclonable function (PUF). Firstly, cancelable biometrics are generated by efficient biometrics fusion processing which called “PUF-TTM” (Template Transformation Method) using a PUF embedded into the device. Then based on Biometrics-as-a-Service (BaaS) model and secret sharing technology, a complete authentication protocol in multi-server environment is designed, and the robustness, effectiveness and security of our proposed scheme are ensured from the perspective of performance and security analysis.}
}


@article{DBLP:journals/tifs/WangL21,
	author = {Silei Wang and
                  Qiang Li},
	title = {Distributionally Robust Secure Multicast Beamforming With Intelligent
                  Reflecting Surface},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5429--5441},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3130440},
	doi = {10.1109/TIFS.2021.3130440},
	timestamp = {Wed, 15 Dec 2021 10:31:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the intelligent reflecting surfaces (IRSs)-aided wireless transmission has drawn considerable attention. This paper investigates the use of IRS in enhancing the physical-layer security of the multiuser multiple-input single-output (MU-MISO) broadcast system, where a base station (BS) transmits a common data stream to multiple legitimate receivers in the presence of multiple eavesdroppers (Eves). The BS is assumed to have only some erroneous channel state information (CSI) of the Eves. The CSI error is modeled by a moment-based random error model, in which the BS only knows the first- and second-order statistics of the error, but not the exact distribution. Under this CSI error model, we investigate the joint robust design of the secure beamforming at the BS and the phase shift at the IRS to maximize the worst legitimate user’s SNR, while keeping the Eves’ SNR below certain threshold with high probability, evaluated with respect to any distribution fulfilling the given first and second-order statistics. This robust secure transmission design problem is a semi-infinite chance-constrained problem, which is in general intractable. We show that the considered problem admits an equivalent conic reformulation, which can be handled by alternately optimizing the beamformer at the BS and the phase shift at the IRS via semidefinite relaxation (SDR) and penalty convex-concave procedure (CCP), respectively. To further improve the secrecy performance, we also study another rank-two beamformed Alamouti transmission scheme at the BS, which can be seen as a generalization of conventional rank-one beamforming. Simulation results demonstrate that the proposed designs are robust against the error distribution, and that the inclusion of IRS is not only helpful for enhancing the security, but also useful for promoting a low-rank SDR solution.}
}


@article{DBLP:journals/tifs/DegardinLP21,
	author = {Bruno Degardin and
                  Vasco Lopes and
                  Hugo Proen{\c{c}}a},
	title = {{REGINA} - Reasoning Graph Convolutional Networks in Human Action
                  Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5442--5451},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3130437},
	doi = {10.1109/TIFS.2021.3130437},
	timestamp = {Sat, 25 Dec 2021 15:52:14 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DegardinLP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is known that the kinematics of the human body skeleton reveals valuable information in action recognition. Recently, modeling skeletons as spatio-temporal graphs with Graph Convolutional Networks (GCNs) has been reported to solidly advance the state-of-the-art performance. However, GCN-based approaches exclusively learn from raw skeleton data, and are expected to extract the inherent structural information on their own. This paper describes REGINA , introducing a novel way to RE asoning G raph convolutional networks IN Human A ction recognition. The rationale is to provide to the GCNs additional knowledge about the skeleton data, obtained by handcrafted features, in order to facilitate the learning process, while guaranteeing that it remains fully trainable in an end-to-end manner. The challenge is to capture complementary information over the dynamics between consecutive frames, which is the key information extracted by state-of-the-art GCN techniques. Moreover, the proposed strategy can be easily integrated in the existing GCN-based methods, which we also regard positively. Our experiments were carried out in well-known action recognition datasets and enabled to conclude that REGINA contributes for solid improvements in performance when incorporated to other GCN-based approaches, without any other adjustment regarding the original method. For reproducibility, the REGINA code and all the experiments carried out will be publicly available at https://github.com/DegardinBruno .}
}


@article{DBLP:journals/tifs/Marin-JimenezCD21,
	author = {Manuel J. Mar{\'{\i}}n{-}Jim{\'{e}}nez and
                  Francisco M. Castro and
                  Rub{\'{e}}n Delgado{-}Esca{\~{n}}o and
                  Vicky Kalogeiton and
                  Nicol{\'{a}}s Guil},
	title = {UGaitNet: Multimodal Gait Recognition With Missing Input Modalities},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {16},
	pages = {5452--5462},
	year = {2021},
	url = {https://doi.org/10.1109/TIFS.2021.3132579},
	doi = {10.1109/TIFS.2021.3132579},
	timestamp = {Mon, 03 Jan 2022 22:10:35 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Marin-JimenezCD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gait recognition systems typically rely solely on silhouettes for extracting gait signatures. Nevertheless, these approaches struggle with changes in body shape and dynamic backgrounds; a problem that can be alleviated by learning from multiple modalities. However, in many real-life systems some modalities can be missing, and therefore most existing multimodal frameworks fail to cope with missing modalities. To tackle this problem, in this work, we propose UGaitNet, a unifying framework for gait recognition, robust to missing modalities. UGaitNet handles and mingles various types and combinations of input modalities, i.e. pixel gray value, optical flow, depth maps, and silhouettes, while being camera agnostic. We evaluate UGaitNet on two public datasets for gait recognition: CASIA-B and TUM-GAID, and show that it obtains compact and state-of-the-art gait descriptors when leveraging multiple or missing modalities. Finally, we show that UGaitNet with optical flow and grayscale inputs achieves almost perfect (98.9%) recognition accuracy on CASIA-B (same-view “normal”) and 100% on TUM-GAID (“ellapsed time”). Code will be available at https://github.com/avagait/ugaitnet}
}
