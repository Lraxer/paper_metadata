@article{DBLP:journals/tifs/SongHHCLHS24,
	author = {Xu Song and
                  Saihui Hou and
                  Yan Huang and
                  Chunshui Cao and
                  Xu Liu and
                  Yongzhen Huang and
                  Caifeng Shan},
	title = {Gait Attribute Recognition: {A} New Benchmark for Learning Richer
                  Attributes From Human Gait Patterns},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1--14},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318934},
	doi = {10.1109/TIFS.2023.3318934},
	timestamp = {Sun, 10 Dec 2023 17:00:16 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SongHHCLHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Compared to gait recognition, Gait Attribute Recognition (GAR) is a seldom-investigated problem. However, since gait attribute recognition can provide richer and finer semantic descriptions, it is an indispensable part of building intelligent gait analysis systems. Nonetheless, the types of attributes considered in the existing datasets are very limited. This paper contributes a new benchmark dataset for gait attribute recognition named Multi-Attribute Gait (MA-Gait). Our MA-Gait contains 95 subjects recorded from 12 camera views, resulting in more than 13000 sequences, with 16 attributes labeled, including six attributes that have never been considered in the literature. Moreover, we propose a Multi-Scale Motion Encoder (MSME) to extract robust motion features, and an Attribute-Guided Feature Selection Module (AGFSM) to adaptively capture the most discriminative attribute features from static appearance features and dynamic motion features for different attributes. Our method achieves the best GAR accuracy on the new dataset. Comprehensive experiments show the effectiveness of the proposed method through both quantitative and qualitative evaluations.}
}


@article{DBLP:journals/tifs/HuangLLTH24,
	author = {Dongxia Huang and
                  Weiqi Luo and
                  Minglin Liu and
                  Weixuan Tang and
                  Jiwu Huang},
	title = {Steganography Embedding Cost Learning With Generative Multi-Adversarial
                  Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {15--29},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318939},
	doi = {10.1109/TIFS.2023.3318939},
	timestamp = {Sun, 10 Dec 2023 17:00:16 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangLLTH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since the generative adversarial network (GAN) was proposed by Ian Goodfellow et al. in 2014, it has been widely used in various fields. However, there are only a few works related to image steganography so far. Existing GAN-based steganographic methods mainly focus on the design of generator, and just assign a relatively poorer steganalyzer in discriminator, which inevitably limits the performances of their models. In this paper, we propose a novel Steganographic method based on Generative Multi-Adversarial Network (Steg-GMAN) to enhance steganography security. Specifically, we first employ multiple steganalyzers rather than a single steganalyzer like existing methods to enhance the performance of discriminator. Furthermore, in order to balance the capabilities of the generator and the discriminator during training stage, we propose an adaptive way to update the parameters of the proposed GAN model according to the discriminant ability of different steganalyzers. In each iteration, we just update the poorest one among all steganalyzers in discriminator, while update the generator with the gradients derived from the strongest one. In this way, the performance of generator and discriminator can be gradually improved, so as to avoid training failure caused by gradient vanishing. Extensive comparative results show that the proposed method can achieve state-of-the-art results compared with the traditional steganography and the modern GAN-based steganographic methods. In addition, a large number of ablation experiments verify the rationality of the proposed model.}
}


@article{DBLP:journals/tifs/ZhouWZLS24,
	author = {Qiang Zhou and
                  Liangmin Wang and
                  Huijuan Zhu and
                  Tong Lu and
                  Victor S. Sheng},
	title = {WF-Transformer: Learning Temporal Features for Accurate Anonymous
                  Traffic Identification by Using Transformer Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {30--43},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318966},
	doi = {10.1109/TIFS.2023.3318966},
	timestamp = {Sun, 10 Dec 2023 17:00:16 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouWZLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Website Fingerprinting (WF) is a network traffic mining technique for anonymous traffic identification, which enables a local adversary to identify the target website that an anonymous network user is browsing. WF attacks based on deep convolutional neural networks (CNN) get the state-of-the-art anonymous traffic classification performance. However, due to the locality restriction of CNN architecture for feature extraction on sequence data, these methods ignore the temporal feature extraction in the anonymous traffic analysis. In this paper, we present Website Fingerprinting Transformer (WF-Transformer), a novel anonymous network traffic analysis method that leverages Transformer networks for temporal feature extraction of traffic traces and improves the classification performance of Tor encrypted traffic. The architecture of WF-Transformer is specially designed for traffic trace processing and can classify anonymous traffic effectively. Furthermore, we evaluate the performance of WF-Transformer in both closed-world and open-world scenarios. In the closed-world scenario, WF-Transformer attains 99.1% accuracy on Tor traffic without defenses, better than state-or-the-art attacks, and archives 92.1% accuracy on the traces defended by WTF-PAD method. In the open-world scenario, WF-Transformer has better precision and recall on both defended and non-defended traces. Furthermore, WF-Transformer with a short input length (2000 cells) outperforms the DF method with a long input length (5000 cells).}
}


@article{DBLP:journals/tifs/JiaMLWD24,
	author = {Ju Jia and
                  Siqi Ma and
                  Yang Liu and
                  Lina Wang and
                  Robert H. Deng},
	title = {A Causality-Aligned Structure Rationalization Scheme Against Adversarial
                  Biased Perturbations for Graph Neural Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {59--73},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318936},
	doi = {10.1109/TIFS.2023.3318936},
	timestamp = {Fri, 15 Dec 2023 14:50:52 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiaMLWD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The graph neural networks (GNNs) are susceptible to adversarial perturbations and distribution biases, which pose potential security concerns for real-world applications. Current endeavors mainly focus on graph matching, while the subtle relationships between the nodes and structures of graph-structured data remain under-explored. Accordingly, two fundamental challenges arise as follows: 1) the intricate connections among nodes may induce the distribution shift of graph samples even under the same scenario, and 2) the perturbations of inherent graph-structured representations can introduce spurious shortcuts, which lead to GNN models relying on biased data to make unstable predictions. To address these problems, we propose a novel causality-aligned structure rationalization (CASR) scheme to construct invariant rationales by probing the coherent and causal patterns, which facilitates GNN models to make stable and reliable predictions in case of adversarial biased perturbations. Specifically, the initial graph samples across domains are leveraged to boost the diversity of datasets and perceive the interaction between shortcuts. Subsequently, the causal invariant rationales can be obtained during the interventions. This allows the GNN model to extrapolate risk variations from a single observed environment to multiple unknown environments. Moreover, the query feedback mechanism can progressively promote the consistency-driven optimal rationalization by reinforcing real essences and eliminating spurious shortcuts. Extensive experiments demonstrate the effectiveness of our scheme against adversarial biased perturbations from data manipulation attacks and out-of-distribution (OOD) shifts on various graph-structured datasets. Notably, we reveal that the capture of distinctive rationales can greatly reduce the dependence on shortcut cues and improve the robustness of OOD generalization.}
}


@article{DBLP:journals/tifs/SunARC24,
	author = {Guoxin Sun and
                  Tansu Alpcan and
                  Benjamin I. P. Rubinstein and
                  Seyit Camtepe},
	title = {To Act or Not to Act: An Adversarial Game for Securing Vehicle Platoons},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {163--177},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3320610},
	doi = {10.1109/TIFS.2023.3320610},
	timestamp = {Sun, 10 Dec 2023 17:00:16 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SunARC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicle platooning systems are vulnerable to malicious attacks that exploit vehicle-to-vehicle (V2V) communication, causing potential instability and increased collision risks. Conventional machine learning (ML) detection methods show promise but can be circumvented by intelligent adversaries. In this paper, we present a novel, end-to-end attack detection and mitigation approach that uniquely incorporates advancements in (adversarial) machine learning, control theory, and game theory. We employ a non-cooperative security game with imperfect information to model complex attack/defense interactions. This aids in making informed decisions regarding detector deployment and attack mitigation, even amidst possibly misleading attack detection reports. We model our control system reconfiguration attack mitigation approach as a switched system and provide a n in-depth stability analysis. The simulations conducted in a sophisticated simulator demonstrate our approach’s potential for real-world online deployment. Our game-based defense formulation significantly improves inter-vehicle distance and defense utilities against both cyber-physical and adversarially-masked attacks while reducing the distance disturbance caused by the ambient traffic by up to 87% compared to baseline defense approaches.}
}


@article{DBLP:journals/tifs/DengJWWX24,
	author = {Jiangyi Deng and
                  Xiaoyu Ji and
                  Beibei Wang and
                  Bin Wang and
                  Wenyuan Xu},
	title = {Dr. Defender: Proactive Detection of Autopilot Drones Based on {CSI}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {194--206},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3311964},
	doi = {10.1109/TIFS.2023.3311964},
	timestamp = {Sun, 10 Dec 2023 17:00:16 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DengJWWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The market for consumer drones is growing and drones are becoming ever more pervasive than before in our life. However, drones have also brought about severe privacy violations and even safety issues. Especially, drones with cameras can snap pictures or take private videos. Researchers have designed drone detection mechanisms by passively inspecting the radio frequency (RF) signal in the communication channel between a drone and its controller. However, passive detection solutions shall fail when drones are in autopilot mode without control signals from controllers. In this paper, we seek to detect autopilot drones that transmit no RF signals by developing a proactive detection system named Dr. Defender. To this end, we resort to the Wi-Fi signals prevalent at each house and propose a proactive drone detection mechanism. To facilitate the detection of drones with Wi-Fi, we first study the motion characteristics of drones, including the shifting, moving, and spinning of propellers that can uniquely represent a drone. Then we investigate the physical layer information of Wi-Fi signals, i.e., the channel state information (CSI), to reveal specific motions of a drone. Finally, we implement our CSI-based proactive drone detection system, which requires no signal transmission from a drone or its controller. We extensively validate the feasibility and performance of our solution under different distances and directions of drones relative to a window. Results show that Dr. Defender can accurately detect drones 10 meters away.}
}


@article{DBLP:journals/tifs/TangGCL24,
	author = {Xinyu Tang and
                  Cheng Guo and
                  Kim{-}Kwang Raymond Choo and
                  Yi{-}Ning Liu},
	title = {An Efficient and Dynamic Privacy-Preserving Federated Learning System
                  for Edge Computing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {207--220},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3320611},
	doi = {10.1109/TIFS.2023.3320611},
	timestamp = {Fri, 21 Feb 2025 14:30:14 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TangGCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has been used to enhance privacy protection in edge computing systems. However, attacks on uploaded model gradients may lead to private data leakage, and edge devices frequently joining and leaving will impact the system running. In this paper, we propose a dynamic and flexible federated edge learning (FEL) scheme that can defend against malicious edge servers and edge devices to recover sensitive data and efficiently manage edge devices. A heterogeneity-aware scheduling strategy is designed to take into account the different impacts of heterogeneous edge devices on global model performance. The strategy determines the order of devices participation in each round based on the relative contribution level of the online edge device model, and the edge device with the highest contribution level is selected first. Numerical experiments show that our system improves test accuracy and time, and the security analyses show that our scheme meets the security requirements.}
}


@article{DBLP:journals/tifs/DingWQZZQC24,
	author = {Yi Ding and
                  Zi Wang and
                  Zhen Qin and
                  Erqiang Zhou and
                  Guobin Zhu and
                  Zhiguang Qin and
                  Kim{-}Kwang Raymond Choo},
	title = {Backdoor Attack on Deep Learning-Based Medical Image Encryption and
                  Decryption Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {280--292},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3322315},
	doi = {10.1109/TIFS.2023.3322315},
	timestamp = {Sun, 10 Dec 2023 17:00:16 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DingWQZZQC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medical images often contain sensitive information, and one typical security measure is to encrypt medical images prior to storage and analysis. A number of solutions, such as those utilizing deep learning, have been proposed for medical image encryption and decryption. However, our research shows that deep learning-based encryption models can potentially be vulnerable to backdoor attacks. In this paper, a backdoor attack paradigm for encryption and decryption network is proposed and corresponding attacks are respectively designed for encryption and decryption scenarios. For attacking the encryption model, a backdoor discriminator is adopted, which is randomly trained with the normal discriminator to confuse the encryption process. In the decryption scenario, a number of subnetwork parameters are replaced and the subnetwork can be activated when detecting the trigger embedded into the input (encrypted image) to degrade the decryption performance. Considering the model performance degradation due to parameter replacement, the model pruning is also adopted to further strengthen the attacking performance. Furthermore, the image steganography is adopted to generate invisible triggers for each image; subsequently, improving the stealthiness of backdoor attacks. Our research on designing backdoor attacks for encryption and decryption network can serve as an attacking mode for such networks, and provides another research direction for improving the security of such models. This research is also one of the earliest works to realize the backdoor attack on the deep learning based medical encryption and decryption network to evaluate the security performance of these networks. Extensive experimental results show that the proposed method can effectively threaten the security performance both for the encryption and decryption network.}
}


@article{DBLP:journals/tifs/XuCLLW24,
	author = {Dandan Xu and
                  Kai Chen and
                  Miaoqian Lin and
                  Chaoyang Lin and
                  Xiaofeng Wang},
	title = {AutoPwn: Artifact-Assisted Heap Exploit Generation for {CTF} {PWN}
                  Competitions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {293--306},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3322319},
	doi = {10.1109/TIFS.2023.3322319},
	timestamp = {Mon, 22 Jul 2024 08:24:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuCLLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Capture-the-flag (CTF) competitions have become highly successful in security education, and heap corruption is considered one of the most difficult and rewarding challenges due to its complexity and real-world impact. However, developing a heap exploit is a challenging task that often requires significant human involvement to manipulate memory layouts and bypass security checks. To facilitate the exploitation of heap corruption, existing solutions develop automated systems that rely on manually crafted patterns to generate exploits. Such manual patterns tend to be specific, which limits their flexibility to cope with the evolving exploit techniques. To address this limitation, we explore the problem of the automatic summarization of exploit patterns. We leverage an observation that public attack artifacts provide key insights into heap exploits. Based upon this observation, we develop AutoPwn, the first artifact-assisted AEG system that automatically summarizes exploit patterns from artifacts of known heap exploits and uses them to guide the exploitation of new programs. Considering the diversity of programs and exploits, we propose to use a novel Exploitation State Machine (ESM), with generic states and transitions to model the exploit patterns, and then efficiently construct it through combining the dynamic monitoring of exploits and the semantic analysis of their text descriptions. We implement a prototype of AutoPwn and evaluate it on 96 testing CTF binaries. The results show that AutoPwn produces 22 successful exploits and 13 partial exploits, preliminarily demonstrating its efficacy.}
}


@article{DBLP:journals/tifs/WeiXC24,
	author = {Xiangye Wei and
                  Liming Xiu and
                  Yimao Cai},
	title = {A Perspective of Using Frequency-Mixing as Entropy in Random Number
                  Generation for Portable Hardware Cybersecurity {IP}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {320--333},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3322602},
	doi = {10.1109/TIFS.2023.3322602},
	timestamp = {Sun, 10 Dec 2023 17:00:16 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WeiXC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {True random number generator (TRNG) is a crucial component in security. In typical TRNGs, entropy comes directly from device noises. In this work, an improved method of using frequency-mixing as means for enriching entropy is implemented. A group of electromagnetic waves are mixed to create an irregular waveform that is then sampled to generate a random bitstream. Some part of the bitstream is fed back to the system for influencing the future frequencies of the sourcing waves, making it a chaotic system. The circuit-level support for this TRNG is the TAF-DPS (Time-Average-Frequency Direct Period Synthesis) technology. It can be digitally implemented, making the TRNG a portable IP. The merits of this TRNG include no need of special device, no post-processing, free of bias, programmable throughput, and hard-to-recognize spectrum. Those features make the TRNG suitable for a large array of applications, particularly for security in cyberspace. This TRNG is validated by a silicon chip on a 180 nm process, also on a FPGA.}
}


@article{DBLP:journals/tifs/SuiDZ24,
	author = {Xiao Sui and
                  Sisi Duan and
                  Haibin Zhang},
	title = {{BG:} {A} Modular Treatment of {BFT} Consensus Toward a Unified Theory
                  of {BFT} Replication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {44--58},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318943},
	doi = {10.1109/TIFS.2023.3318943},
	timestamp = {Tue, 07 May 2024 20:18:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SuiDZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We provide an expressive framework that allows analyzing and generating provably secure, state-of-the-art Byzantine fault-tolerant (BFT) protocols over graph of nodes, a notion formalized in the HotStuff protocol. Our framework is hierarchical, including three layers. The top layer is used to model the message pattern and abstract core functions on which BFT algorithms can be built. The intermediate layer provides the core functions with high-level properties sufficient to prove the security of the top-layer algorithms. The bottom layer presents operational realizations for the core functions. Using our framework, designing a BFT protocol is reduced to instantiating two core functions together with their specific properties. Unlike prior BFT frameworks, our framework can analyze and recast BFT protocols in an exceedingly fine-grained manner. More importantly, our framework can readily generate new BFT protocols. In this paper, we show that the framework allows us to fully specify and formally prove the security for a family of BFT protocols, including known protocols such as HotStuff, Fast-HotStuff, and SBFT. Additionally, we show that our framework can generate four new protocols outperforming existing ones, including 1) two protocols with 5f+1\nreplicas achieving optimal message complexity; 2) the first BFT protocol achieving optimal message complexity with 4f+1\nreplicas; and 3) a two-phase protocol with 3f+1\nreplicas achieving linear authenticator complexity in the fast path.}
}


@article{DBLP:journals/tifs/XueXZLZSL24,
	author = {Rui Xue and
                  Kaiping Xue and
                  Bin Zhu and
                  Xinyi Luo and
                  Tianwei Zhang and
                  Qibin Sun and
                  Jun Lu},
	title = {Differentially Private Federated Learning With an Adaptive Noise Mechanism},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {74--87},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318944},
	doi = {10.1109/TIFS.2023.3318944},
	timestamp = {Tue, 17 Dec 2024 16:57:28 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XueXZLZSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) enables multiple distributed clients to collaboratively train a model with owned datasets. To avoid the potential privacy threat in FL, researchers propose the DP-FL strategy, which utilizes differential privacy (DP) to add elaborate noise to the exchanged parameters to hide privacy information. DP-FL guarantees the privacy of FL at the cost of model performance degradation. To balance the trade-off between model accuracy and security, we propose a differentially private federated learning scheme with an adaptive noise mechanism. This is challenging, as the distributed nature of FL makes it difficult to appropriately estimate sensitivity, where sensitivity is a concept in DP that determines the scale of noise. To resolve this, we design a generic method for sensitivity estimates based on local and global historical information. We also provide instances on four commonly used optimizers to verify its effectiveness. The experiments on MNIST, FMNIST and CIFAR-10 convincingly prove that our proposed scheme achieves higher accuracy while keeping high-level privacy protection compared to prior works.}
}


@article{DBLP:journals/tifs/RenLWWLWC24,
	author = {Qian Ren and
                  Yue Li and
                  Yingjun Wu and
                  Yuchen Wu and
                  Hong Lei and
                  Lei Wang and
                  Bangdao Chen},
	title = {DeCloak: Enable Secure and Cheap Multi-Party Transactions on Legacy
                  Blockchains by a Minimally Trusted {TEE} Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {88--103},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318935},
	doi = {10.1109/TIFS.2023.3318935},
	timestamp = {Wed, 01 May 2024 10:27:39 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/RenLWWLWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The crucial blockchain privacy and scalability demand has boosted off-chain contract execution frameworks for years. Some have recently extended their capabilities to transition blockchain states by off-chain multi-party computation while ensuring public verifiability. This new capability is defined as acrfull mpt. However, existing MPT solutions lack at least one of the following properties crucially valued by communities: data availability, financial fairness, delivery fairness, and delivery atomicity. This paper proposes a novel MPT-enabled off-chain contract execution framework, Decloak. Using TEEs, Decloak solves identified properties with lower gas costs and a weaker assumption. Notably, Decloak is the first to achieve data availability and also achieve all of the above properties. This achievement is coupled with its ability to tolerate all-but-one Byzantine parties and TEE executors. Evaluating 10 MPTs in different businesses, Decloak reduces the gas cost of the SOTA, Cloak, by 65.6%. This efficiency advantage further amplifies with an increasing number of MPT’s parties. Consequently, we establish an elevated level of secure and cheap MPT, being the first to demonstrate the feasibility of achieving gas costs comparable to Ethereum transactions while evaluating MPTs.}
}


@article{DBLP:journals/tifs/LiMZGAXFZAA24,
	author = {Yinshan Li and
                  Hua Ma and
                  Zhi Zhang and
                  Yansong Gao and
                  Alsharif Abuadbba and
                  Minhui Xue and
                  Anmin Fu and
                  Yifeng Zheng and
                  Said F. Al{-}Sarawi and
                  Derek Abbott},
	title = {{NTD:} Non-Transferability Enabled Deep Learning Backdoor Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {104--119},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3312973},
	doi = {10.1109/TIFS.2023.3312973},
	timestamp = {Wed, 16 Oct 2024 16:36:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiMZGAXFZAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To mitigate recent insidious backdoor attacks on deep learning models, advances have been made by the research community. Nonetheless, state-of-the-art defenses are either limited to specific backdoor attacks (i.e., source-agnostic attacks) or non-user-friendly in that machine learning expertise and/or expensive computing resources are required. This work observes that all existing backdoor attacks have an inadvertent and inevitable intrinsic weakness, termed as non-transferability —that is, a trigger input hijacks a backdoored model but is not effective in another model that has not been implanted with the same backdoor. With this key observation, we propose non-transferability enabled backdoor detection to identify trigger inputs for a model-under-test during run-time. Specifically, our detection allows a potentially backdoored model-under-test to predict a label for an input. Moreover, our detection leverages a feature extractor to extract feature vectors for the input and a group of samples randomly picked from its predicted class label, and then compares the similarity between the input and the samples in the feature extractor’s latent space to determine whether the input is a trigger input or a benign one. The feature extractor can be provided by a reputable party or is a free pre-trained model privately reserved from any open platform (e.g., ModelZoo, GitHub, Kaggle) by a user and thus our detection does not require the user to have any machine learning expertise or perform costly computations. Extensive experimental evaluations on four common tasks affirm that our detection scheme has high effectiveness (low false acceptance rate) and usability (low false rejection rate) with low detection latency against different types of backdoor attacks.}
}


@article{DBLP:journals/tifs/HeCWLWJD24,
	author = {Shuting He and
                  Weihua Chen and
                  Kai Wang and
                  Hao Luo and
                  Fan Wang and
                  Wei Jiang and
                  Henghui Ding},
	title = {Region Generation and Assessment Network for Occluded Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {120--132},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318956},
	doi = {10.1109/TIFS.2023.3318956},
	timestamp = {Thu, 29 Feb 2024 09:17:09 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HeCWLWJD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Person Re-identification (ReID) plays a more and more crucial role in recent years with a wide range of applications. Existing ReID methods are suffering from the challenges of misalignment and occlusions, which degrade the performance dramatically. Most methods tackle such challenges by utilizing external tools to locate body parts or exploiting matching strategies. Nevertheless, the inevitable domain gap between the datasets utilized for external tools and the ReID datasets and the complicated matching process make these methods unreliable and sensitive to noises. In this paper, we propose a Region Generation and Assessment Network (RGANet) to effectively and efficiently detect the human body regions and highlight the important regions. In the proposed RGANet, we first devise a Region Generation Module (RGM) which utilizes the pre-trained CLIP to locate the human body regions using semantic prototypes extracted from text descriptions. Learnable prompt is designed to eliminate domain gap between CLIP datasets and ReID datasets. Then, to measure the importance of each generated region, we introduce a Region Assessment Module (RAM) that assigns confidence scores to different regions and reduces the negative impact of the occlusion regions by lower scores. The RAM consists of a discrimination-aware indicator and an invariance-aware indicator, where the former indicates the capability to distinguish from different identities and the latter represents consistency among the images of the same class of human body regions. Extensive experimental results for six widely-used benchmarks including three tasks (occluded, partial, and holistic) demonstrate the superiority of RGANet against state-of-the-art methods.}
}


@article{DBLP:journals/tifs/YuanGZZXW24,
	author = {Qingjun Yuan and
                  Gaopeng Gou and
                  Yanbei Zhu and
                  Yuefei Zhu and
                  Gang Xiong and
                  Yongjuan Wang},
	title = {MCRe: {A} Unified Framework for Handling Malicious Traffic With Noise
                  Labels Based on Multidimensional Constraint Representation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {133--147},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318962},
	doi = {10.1109/TIFS.2023.3318962},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YuanGZZXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the limitations of the existing annotation methods, the prevalence of label noise can be caused in realistic malicious traffic datasets, which has a significant impact on the training and evaluation of deep learning-based intrusion detection models. Recently, various methods have been proposed to deal with noise-containing labeled datasets, and they can be roughly divided into two categories: data cleaning and robust training. However, the different processing ideas lead these two types of methods to ignore the information in different components of the dataset, resulting in a cliff-like drop in performance under high noise conditions. To this end, this study proposes a unified framework for handling noise malicious traffic based on the multidimensional constrained representations named MCRe, which unifies data cleaning and robust training into an ideal representation function approximation. According to the properties of the ideal representation function, information integrity constraints, cluster separability constraints and core proximity constraints are defined to drive MCRe to approximate the ideal representation during iteration. These constraints led MCRe to learn the individual, intra-class, and global levels of distributed knowledge, thus avoiding irrational domain knowledge extraction and ensuring strong label noise robustness of the representation network. We validated MCRe on a dataset that includes 22 types of realistic malicious traffic. Experimental results show that MCRe can outperform the state-of-the-art methods in both data cleaning and robust training downstream tasks, achieving 85% pure sample rate and 82% classification accuracy even under the condition of up to 90% noise labels. In addition, the generalizability of MCRe was verified on several public datasets. Finally, MCRe was also well-extended to enhance other data cleaning and robust training approaches.}
}


@article{DBLP:journals/tifs/WuZZTS24,
	author = {Haiwei Wu and
                  Jiantao Zhou and
                  Xinyu Zhang and
                  Jinyu Tian and
                  Weiwei Sun},
	title = {Robust Camera Model Identification Over Online Social Network Shared
                  Images via Multi-Scenario Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {148--162},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318968},
	doi = {10.1109/TIFS.2023.3318968},
	timestamp = {Wed, 06 Nov 2024 15:46:13 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WuZZTS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Camera model identification (CMI) can be widely used in image forensics such as authenticity determination, copyright protection, forgery detection, etc. Meanwhile, with the vigorous development of the Internet, online social networks (OSNs) have become the dominant channels for image sharing and transmission. However, the inevitable lossy operations on OSNs, such as compression and post-processing, impose great challenges to the existing CMI schemes, as they severely destroy the camera traces left in the images under investigation. In this work, we propose a novel CMI method that is robust against the lossy operations of various OSN platforms. Specifically, it is observed that a camera trace extractor can be easily trained on a single degradation scenario (e.g., one specific OSN platform); while much more difficult on mixed degradation scenarios (e.g., multiple OSN platforms). Inspired by this observation, we design a new multi-scenario learning (MSL) strategy, enabling us to extract robust camera traces across different OSNs. Furthermore, noticing that image smooth regions incur less distortions by OSN and less interference by image signal itself, we suggest a SmooThness-Aware Trace Extractor (STATE) that can adaptively extract camera traces according to the smoothness of the input image. The superiority of our method is verified by comparative experiments with four state-of-the-art methods, especially under various OSN transmission scenarios. Particularly, for the open-set camera model verification task, we greatly surpass the second-place by 15.30% in AUC on the FODB dataset; while for the close-set camera model classification task, we are significantly ahead of the second-place by 34.51% in F1 on the SIHDR dataset. The code of our proposed method is available at https://github.com/HighwayWu/CameraTraceOSN.}
}


@article{DBLP:journals/tifs/YuanFYZD24,
	author = {Haoheng Yuan and
                  Yanghe Feng and
                  Chuanchuan Yang and
                  Zhuojun Zhuang and
                  Bin Dai},
	title = {Two-User Gaussian Broadcast Wiretap Channel With Common Message and
                  Feedback: Revisit},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {178--193},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318948},
	doi = {10.1109/TIFS.2023.3318948},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YuanFYZD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The two-user Gaussian broadcast wiretap channel with common message and feedback (GBC-WTC-CM-F) is revisited. Traditionally, achievable secrecy rate of this model is achieved by combining Marton’s coding scheme for the two-user broadcast channel (BC) and the secret-key based feedback scheme, where both of the two feedback links are used to transmit secret keys shared between the transceivers. Recently, it has been shown that for the Gaussian wiretap channel with feedback, the Schalkwijk-Kailath (SK) feedback scheme achieves its secrecy capacity. Then it is natural to ask: can we do better when applying the SK-type scheme to the GBC-WTC-CM-F? In this paper, we answer this question by proposing two kinds of SK-type schemes. Specifically, first, we propose a hybrid scheme where one feedback link is used to transmit a secret key, and the other one is used for SK-type coding. We show that this hybrid scheme may perform better than the existing one in some cases. Next, we show that Ozarow’s extended SK scheme for the two-user Gaussian BC with feedback, where both feedback links are used for SK-type coding, is self-secure (satisfying perfect weak secrecy constraint by itself) and may perform the best. We further show that Ozarow’s scheme is in fact a secure finite blocklength coding scheme, and extend it to the static fading SISO and SIMO cases. Finally, the results of this paper are further explained by numerical examples.}
}


@article{DBLP:journals/tifs/ZhangMWGJ24,
	author = {Chen Zhang and
                  Yulong Ming and
                  Mingyue Wang and
                  Yu Guo and
                  Xiaohua Jia},
	title = {Encrypted and Compressed Key-Value Store With Pattern-Analysis Security
                  in Cloud Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {221--234},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3320612},
	doi = {10.1109/TIFS.2023.3320612},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangMWGJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing concern about data privacy and data explosion, some encrypted and compressed key-value (KV) stores have been proposed. A remarkable way to combine encryption and compression is to pack KV pairs into packs, and then compress and encrypt each pack separately. Recent research has shown that even if the data is encrypted, adversaries can still use the leaked information about data length and access frequency to launch pattern-analysis attacks. For this problem, some schemes have been proposed to protect the length and frequency distribution of packs. However, existing solutions protect such information at the cost of high storage and bandwidth overhead. In this paper, we propose an encrypted and compressed KV store with pattern-analysis security, which can resist pattern-analysis attacks with minimal overhead. We first devise a secure KV pair packing scheme, which guarantees pack length security with bounded storage overhead. Then we propose a K -indistinguishable pack frequency smoothing scheme. It can protect the distribution of pack frequency with minimal bandwidth overhead. We formally analyze the security of our design and implement our proposed secure KV storage system on Redis and RocksDB. Performance evaluation results demonstrate that our design minimizes the overhead of achieving pattern-analysis security.}
}


@article{DBLP:journals/tifs/QuanDWY24,
	author = {Weize Quan and
                  Pengfei Deng and
                  Kai Wang and
                  Dong{-}Ming Yan},
	title = {CGFormer: ViT-Based Network for Identifying Computer-Generated Images
                  With Token Labeling},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {235--250},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3322083},
	doi = {10.1109/TIFS.2023.3322083},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/QuanDWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advanced graphics rendering techniques and image generation algorithms significantly improve the visual quality of computer-generated (CG) images, and this makes it more challenging to distinguish between CG images and natural images (NIs) for a forensic detector. For the identification of CG images, human beings often need to inspect and evaluate the entire image and its local region as well. In addition, we observe that the distributions of both near and far patch-wise correlation have differences between CG images and NIs. Current mainstream methods adopt the CNN-based architecture with the classical cross entropy loss, however, there are several limitations: 1) the weakness of long-distance relationship modeling of image content due to the local receptive field of CNN; 2) the pixel sensitivity due to the convolutional computation; 3) the insufficient supervision due to the training loss on the whole image. In this paper, we propose a novel vision transformer (ViT)-based network with token labeling for CG image identification. Our network, called CGFormer, consists of patch embedding, feature modeling, and token prediction. We apply patch embedding to sequence the input image and weaken the pixel sensitivity. Stacked multi-head attention-based transformer blocks are utilized to model the patch-wise relationship and introduce a certain level of adaptability. Besides the conventional classification loss on class token of the whole image, we additionally introduce a soft cross entropy loss on patch tokens to comprehensively exploit the supervision information from local patches. Extensive experiments demonstrate that our method achieves the state-of-the-art forensic performance on six publicly available datasets in terms of classification accuracy, generalization, and robustness. Code is available at https://github.com/feipiefei/CGFormer.}
}


@article{DBLP:journals/tifs/YangTH24,
	author = {Ningbin Yang and
                  Chunming Tang and
                  Debiao He},
	title = {A Lightweight Certificateless Multi-User Matchmaking Encryption for
                  Mobile Devices: Enhancing Security and Performance},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {251--264},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3321961},
	doi = {10.1109/TIFS.2023.3321961},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangTH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The technology for securely sharing data has grown extensively in recent years. Many users are willing to share their lightweight mobile device data via social networks or the cloud. A novel matchmaking encryption primitive was proposed in CRYPTO’19, whose potential for privacy protection and data sharing security was introduced. However, matchmaking encryption technology faces challenges in flexibly realizing critical functions, such as one-to-many non-interactive scenarios, no key escrow problem, stronger security, lightweight computation and low communication overheads for mobile devices, which impede their widespread application. To achieve the above functions, we present a lightweight certificateless multi-user matchmaking encryption (LC-MUME) for mobile devices, which enhances security flexibly and performance based on standard hard assumptions and low-consumption pairing-free technology, while also avoiding one-by-one encryption for each user. The proposed LC-MUME scheme enjoys minor computation and communication overheads in a one-to-many non-interactive certificateless cryptosystem. We prove that our scheme achieves indistinguishability-based chosen-ciphertext attack (IND-CCA) security, the existential unforgeability under a chosen message attack (EU-CMA) security and anonymity-CCA security under the random oracle model. Our LC-MUME scheme outperforms the state-of-the-art schemes regarding efficiency and flexibility, as demonstrated by the performance comparison and analysis, and therefore is a practical solution for resource-constrained mobile devices.}
}


@article{DBLP:journals/tifs/ZhaoZGSZL24,
	author = {Weisong Zhao and
                  Xiangyu Zhu and
                  Kaiwen Guo and
                  Haichao Shi and
                  Xiaoyu Zhang and
                  Zhen Lei},
	title = {Masked Face Transformer},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {265--279},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3322600},
	doi = {10.1109/TIFS.2023.3322600},
	timestamp = {Fri, 09 Aug 2024 10:24:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoZGSZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The COVID-19 pandemic makes wearing masks mandatory. Existing CNN-based face recognition (FR) systems suffer from severe performance degradation as masks occlude the vital facial regions. Recently, Vision Transformers have shown promising performance in various vision tasks with quadratic computation costs. Swin Transformer first proposes a successive window attention mechanism allowing the cross-window connection and more computational efficiency. Despite its potential, the deployment of Swin Transformer in masked face recognition encounters two challenges: 1) the attention range is insufficient to capture locally compatible face regions. 2) Masked face recognition can be defined as an occlusion-robust classification task with a known occlusion position, i.e., the position of the mask is minor-varying, which is overlooked but efficient in improving the model’s recognition accuracy. To alleviate the above problem, we propose a Masked Face Transformer (MFT) with Masked Face-compatible Attention (MFA). The proposed MFA 1) introduces two additional window partition configurations, e.g., row shift and column shift, to enlarge the attention range in Swin with invariant computation costs, and 2) suppresses the interaction between the masked and non-masked regions to retain their discrepancies. Additionally, as mask occlusion leads to a separation between the masked and non-masked samples of the same identity, we propose to explore the relationship between them by a ClassFormer module to enhance intra-class aggregation. Extensive experiments show that MFT outperforms state-of-the-art masked face recognition methods in both simulated and real masked face testing datasets.}
}


@article{DBLP:journals/tifs/SunJDLMDZ24,
	author = {Wenli Sun and
                  Xinyang Jiang and
                  Shuguang Dou and
                  Dongsheng Li and
                  Duoqian Miao and
                  Cheng Deng and
                  Cairong Zhao},
	title = {Invisible Backdoor Attack With Dynamic Triggers Against Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {307--319},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3322659},
	doi = {10.1109/TIFS.2023.3322659},
	timestamp = {Mon, 29 Jul 2024 21:17:52 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SunJDLMDZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, person Re-IDentification (ReID) has rapidly progressed with wide real-world applications but is also susceptible to various forms of attack, including proven vulnerability to adversarial attacks. In this paper, we focus on the backdoor attack on deep ReID models. Existing backdoor attack methods follow an all-to-one or all-to-all attack scenario, where all the target classes in the test set have already been seen in the training set. However, ReID is a much more complex fine-grained open-set recognition problem, where the identities in the test set are not contained in the training set. Thus, previous backdoor attack methods for classification are not applicable to ReID. To ameliorate this issue, we propose a novel backdoor attack on deep ReID under a new all-to-unknown scenario, called Dynamic Triggers Invisible Backdoor Attack (DT-IBA). Instead of learning fixed triggers for the target classes from the training set, DT-IBA can dynamically generate new triggers for any unknown identities. Specifically, an identity hashing network is proposed to first extract target identity information from a reference image, which is then injected into the benign images by image steganography. We extensively validate the effectiveness and stealthiness of the proposed attack on benchmark datasets and evaluate the effectiveness of several defense methods against our attack.}
}


@article{DBLP:journals/tifs/LiPCM24,
	author = {Meng Li and
                  Zheng Pei and
                  Yong Chen and
                  Zhenhai Miao},
	title = {Fuzzy Linguistic Knowledge Reasoning-Based Secure Control for Connected
                  Nonlinear Servosystem},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {334--343},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324396},
	doi = {10.1109/TIFS.2023.3324396},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiPCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, the issue of tracking control for connected servosystems with coupling input and false data injection (FDI) attacks is studied. A fuzzy linguistic knowledge reasoning-based secure control scheme is proposed. Firstly, the dynamic model of connected nonlinear servosystems suffer from coupling input and FDI attacks is modeled. Then, a fuzzy linguistic estimator based on experimental observation and human knowledge is proposed to approximate the nonlinear function. Furthermore, an observer depended on the fuzzy linguistic estimator is designed to observe the system state. Thirdly, to achieve the tracking control of connected nonlinear servosystems, a fuzzy linguistic knowledge reasoning-based secure control algorithm is presented. Finally, simulation and experiment results demonstrate the effectiveness of the algorithm.}
}


@article{DBLP:journals/tifs/XieCWY24,
	author = {Yuankun Xie and
                  Haonan Cheng and
                  Yutian Wang and
                  Long Ye},
	title = {Domain Generalization via Aggregation and Separation for Audio Deepfake
                  Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {344--358},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324724},
	doi = {10.1109/TIFS.2023.3324724},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XieCWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose an Aggregation and Separation Domain Generalization (ASDG) method for Audio DeepFake Detection (ADD). Fake speech generated from different methods exhibits varied amplitude and frequency distributions rather than genuine speech. In addition, the spoofing attacks in training sets may not keep pace with the evolving diversity of real-world deepfake distributions. In light of this, we attempt to learn an ideal feature space that can aggregate real speech and separate fake speech to achieve better generalizability in the detection of unseen target domains. Specifically, we first propose a feature generator based on Lightweight Convolutional Neural Networks (LCNN), which is employed for generating a feature space and categorizing the feature into real and fake. Meanwhile, single-side domain adversarial learning is leveraged to make only the real speech from different domains indistinguishable, which enables the distribution of real speech to be aggregated in the feature space. Furthermore, a triplet loss is adopted to separate the distribution of fake speech while aggregating the distribution of real speech. Finally, in order to test the generalizability of the model, we train it with three different English datasets and evaluate in harsh conditions: cross-language and noisy datasets. The extensive experiments show that ASDG outperforms the baseline models in cross-domain tasks and decreases Equal Error Rate (EER) by up to 39.24% when compared to that of RawNet2. It is proved that the proposed Aggregation and Separation Domain Generalization method can be an effective strategy to improve the model generalizability.}
}


@article{DBLP:journals/tifs/AbdolinezhadZS24,
	author = {Saeed Abdolinezhad and
                  Lukas Zimmermann and
                  Axel Sikora},
	title = {Output Positioning to Derive Maximum Entropy From Physical Unclonable
                  Functions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {359--371},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3320608},
	doi = {10.1109/TIFS.2023.3320608},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AbdolinezhadZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical unclonable functions (PUFs) are increasingly generating attention in the field of hardware-based security for the Internet of Things (IoT). A PUF, as its name implies, is a physical element with a special and unique inherent characteristic and can act as the security anchor for authentication and cryptographic applications. Keeping in mind that the PUF outputs are prone to change in the presence of noise and environmental variations, it is critical to derive reliable keys from the PUF and to use the maximum entropy at the same time. In this work, the PUF output positioning (POP) method is proposed, which is a novel method for grouping the PUF outputs in order to maximize the extracted entropy. To achieve this, an offset data is introduced as helper data, which is used to relax the constraints considered for the grouping of PUF outputs, and deriving more entropy, while reducing the secret key error bits. To implement the method, the key enrollment and key generation algorithms are presented. Based on a theoretical analysis of the achieved entropy, it is proven that POP can maximize the achieved entropy, while respecting the constraints induced to guarantee the reliability of the secret key. Moreover, a detailed security analysis is presented, which shows the resilience of the method against cyber-security attacks. The findings of this work are evaluated by applying the method on a hybrid printed PUF, where it can be practically shown that the proposed method outperforms other existing group-based PUF key generation methods.}
}


@article{DBLP:journals/tifs/XuZZ24,
	author = {Min Xu and
                  Ximiao Zhang and
                  Xiuzhuang Zhou},
	title = {Confidence-Calibrated Face and Kinship Verification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {372--384},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318957},
	doi = {10.1109/TIFS.2023.3318957},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XuZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate the problem of prediction confidence in face and kinship verification. Most existing face and kinship verification methods focus on accuracy performance while ignoring confidence estimation for their prediction results. However, confidence estimation is essential for modeling reliability and trustworthiness in such high-risk tasks. To address this, we introduce an effective confidence measure that allows verification models to convert a similarity score into a confidence score for any given face pair. We further propose a confidence-calibrated approach, termed Angular Scaling Calibration (ASC). ASC is easy to implement and can be readily applied to existing verification models without model modifications, yielding accuracy-preserving and confidence-calibrated probabilistic verification models. In addition, we introduce the uncertainty in the calibrated confidence to boost the reliability and trustworthiness of the verification models in the presence of noisy data. To the best of our knowledge, our work presents the first comprehensive confidence-calibrated solution for modern face and kinship verification tasks. We conduct extensive experiments on four widely used face and kinship verification datasets, and the results demonstrate the effectiveness of our proposed approach. Code and models are available at https://github.com/cnulab/ASC.}
}


@article{DBLP:journals/tifs/MontibellerP24,
	author = {Andrea Montibeller and
                  Fernando P{\'{e}}rez{-}Gonz{\'{a}}lez},
	title = {An Adaptive Method for Camera Attribution Under Complex Radial Distortion
                  Corrections},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {385--400},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318933},
	doi = {10.1109/TIFS.2023.3318933},
	timestamp = {Fri, 08 Mar 2024 13:21:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MontibellerP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radial distortion correction, applied by in-camera or out-camera software/firmware alters the supporting grid of the image so as to hamper PRNU-based camera attribution. Existing solutions to deal with this problem try to invert/estimate the correction using radial transformations parameterized with few variables in order to restrain the computational load; however, with ever more prevalent complex distortion corrections their performance is unsatisfactory. In this paper we propose an adaptive algorithm that by dividing the image into concentric annuli is able to deal with sophisticated corrections like those applied out-camera by third party software like Adobe Lightroom, Photoshop, Gimp and PT-Lens. We also introduce a statistic called cumulative peak of correlation energy (CPCE) that allows for an efficient early stopping strategy. Experiments on a large dataset of in-camera and out-camera radially corrected images and on a in-the-wild dataset of images from smartphones show that our solution improves the state of the art in terms of both accuracy and computational cost.}
}


@article{DBLP:journals/tifs/GuoJWWYK24,
	author = {Zhiqing Guo and
                  Zhenhong Jia and
                  Liejun Wang and
                  Dewang Wang and
                  Gaobo Yang and
                  Nikola K. Kasabov},
	title = {Constructing New Backbone Networks via Space-Frequency Interactive
                  Convolution for Deepfake Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {401--413},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324739},
	doi = {10.1109/TIFS.2023.3324739},
	timestamp = {Sun, 19 Jan 2025 14:20:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GuoJWWYK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The serious concerns over the negative impacts of Deepfakes have attracted wide attentions in the community of multimedia forensics. The existing detection works achieve deepfake detection by improving the traditional backbone networks to capture subtle manipulation traces. However, there is no attempt to construct new backbone networks with different structures for Deepfake detection by improving the internal feature representation of convolution. In this work, we propose a novel Space-Frequency Interactive Convolution (SFIConv) to efficiently model the manipulation clues left by Deepfake. To obtain high-frequency features from tampering traces, a Multichannel Constrained Separable Convolution (MCSConv) is designed as the component of the proposed SFIConv, which learns space-frequency features via three stages, namely generation, interaction and fusion. In addition, SFIConv can replace the vanilla convolution in any backbone networks without changing the network structure. Extensive experimental results show that seamlessly equipping SFIConv into the backbone network greatly improves the accuracy for Deepfake detection. In addition, the space-frequency interaction mechanism does benefit to capturing common artifact features, thus achieving better results in cross-dataset evaluation. Our code will be available at https://github.com/EricGzq/SFIConv.}
}


@article{DBLP:journals/tifs/ZhuCXWZ24,
	author = {Youwen Zhu and
                  Yiran Cao and
                  Qiao Xue and
                  Qihui Wu and
                  Yushu Zhang},
	title = {Heavy Hitter Identification Over Large-Domain Set-Valued Data With
                  Local Differential Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {414--426},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324726},
	doi = {10.1109/TIFS.2023.3324726},
	timestamp = {Tue, 08 Oct 2024 15:40:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuCXWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Set-valued data are widely used to represent information in the real word, such as individual daily behaviors, items in shopping carts and web browsing history. By collecting set-valued data and identifying heavy hitters, service providers (i.e., the collector) can learn usage preferences of costumers (i.e., users), and improve the quality of their services by the learned information. However, the collection of raw data would bring privacy risks to users. Recently, local differential privacy (LDP) has emerged as a rigorous privacy framework for user private data collection. At the same time, many LDP schemes have been designed to achieve heavy hitters, but most of them are limited by the large data domain due to the huge computation cost. In this paper, we propose an LDP framework: PemSet, to efficiently identify heavy hitters from set-valued data with a large domain. In PemSet, users mainly focus on the prefix of each item (i.e., the first few bits of the binary expression of each item), and only perturb and report prefixes to reduce computation cost. Sometimes the prefixes of different items are the same, so the reported set-valued data could be a multiset, i.e., a set including multiple same items. As such, we design four LDP protocols MOLH, MOLH-S, MPCKV, MWheel to estimate frequencies of items in the multiset setting, and compare their performance under PemSet framework by experiments. Experimental results demonstrate that MOLH can perform the best in a high privacy region, i.e., \\epsilon < 1\n, while MWheel can obtain the highest utility when privacy budget is large, i.e., \\epsilon \\geqslant 1\n.}
}


@article{DBLP:journals/tifs/LiuXZWWL24,
	author = {Gaoyang Liu and
                  Tianlong Xu and
                  Rui Zhang and
                  Zixiong Wang and
                  Chen Wang and
                  Ling Liu},
	title = {Gradient-Leaks: Enabling Black-Box Membership Inference Attacks Against
                  Machine Learning Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {427--440},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324772},
	doi = {10.1109/TIFS.2023.3324772},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuXZWWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) techniques have been applied to many real-world applications to perform a wide range of tasks. In practice, ML models are typically deployed as the black-box APIs to protect the model owner’s benefits and/or defend against various privacy attacks. In this paper, we present Gradient-Leaks as the first evidence showcasing the possibility of performing membership inference attacks (MIAs), with mere black-box access, which aim to determine whether a data record was utilized to train a given target ML model or not. The key idea of Gradient-Leaks is to construct a local ML model around the given record which locally approximates the target model’s prediction behavior. By extracting the membership information of the given record from the gradient of the substituted local model using an intentionally modified autoencoder, Gradient-Leaks can thus breach the membership privacy of the target model’s training data in an unsupervised manner, without any priori knowledge about the target model’s internals or its training data. Extensive experiments on different types of ML models with real-world datasets have shown that Gradient-Leaks can achieve a better performance compared with state-of-the-art attacks.}
}


@article{DBLP:journals/tifs/ZhouK24,
	author = {Zhenyu Zhou and
                  Ajay Kumar},
	title = {Finger-Knuckle Assisted Slap Fingerprint Identification System for
                  Higher Security and Convenience},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {441--454},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318938},
	doi = {10.1109/TIFS.2023.3318938},
	timestamp = {Mon, 11 Nov 2024 16:51:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Every day, billions of fingerprint images are captured worldwide through the extensive deployment of slap-fingerprint acquisition devices, serving e-governance programs and bolstering national border security. Several studies from national ID programs, like UIDAI and NIST, have indicated that about 2% of the user population may lack usable fingerprints. Finger knuckle patterns are inherently presented during such slap-fingerprint acquisition and can be simultaneously acquired without imposing any additional inconvenience on the users. Leveraging these finger knuckle patterns can enable not only significant improvement in identification accuracy but also enhance overall protection and facilitates smoother traffic flow. This paper develops the first such finger-knuckle-assisted fingerprint identification system for real-world applications. We systematically develop automated finger knuckle detection and segmentation algorithms, for multiple knuckles and under complex illumination, for such contactless images from the deployed slap fingerprint devices. Currently, available algorithms offer limited performance for such images, and therefore this paper proposes a new approach to more accurately match such knuckle images. Our experimental results illustrate the significant performance improvement over existing knuckle matching algorithms, and further by incorporating dynamic fusion capabilities. This paper also introduces the first joint finger-knuckle and fingerprint database, from 120 different subjects, in the public domain to advance further research and development efforts needed in this area.}
}


@article{DBLP:journals/tifs/QiuMZAKFG24,
	author = {Huming Qiu and
                  Hua Ma and
                  Zhi Zhang and
                  Alsharif Abuadbba and
                  Wei Kang and
                  Anmin Fu and
                  Yansong Gao},
	title = {Toward a Critical Evaluation of Robustness for Deep Learning Backdoor
                  Countermeasures},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {455--468},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324318},
	doi = {10.1109/TIFS.2023.3324318},
	timestamp = {Wed, 07 Aug 2024 17:31:11 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QiuMZAKFG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since Deep Learning (DL) backdoor attacks have been revealed as one of the most insidious adversarial attacks, a number of countermeasures have been developed with certain assumptions defined in their respective threat models. However, their robustness is currently inadvertently ignored, which can introduce severe consequences, e.g., a countermeasure can be misused and result in a false implication of backdoor detection. For the first time, we critically examine the robustness of existing backdoor countermeasures. As an initial study, we first identify five potential non-robust failure factors including binary classification, poison rate, model complexity, single-model justification, and hyperparameter sensitivity. As exhaustively examining defenses is infeasible, we instead focus on influential backdoor detection-based countermeasures consisting of model-inspection ones including Neural Cleanse (S&P’19), ABS (CCS’19), and MNTD (S&P’21), and data-inspection ones including SCAn (USENIX SECURITY’21) to examine their failure cases under one or more of these factors. Although these investigated countermeasures claim that they work well under their respective threat models, they have inherent unexplored non-robust cases, which are not even rooted from delicate adaptive attacks. We demonstrate how to trivially bypass them aligned with their respective threat models by simply varying the aforementioned factors. Particularly, for each defense, formal proofs or empirical studies are used to reveal its non-robust cases where it is not as robust as it claims or expects. This work highlights the necessity of thoroughly evaluating the robustness of backdoor countermeasures to avoid their misleading security implications in unknown non-robust cases.}
}


@article{DBLP:journals/tifs/SongXZL24,
	author = {Yaqing Song and
                  Chunxiang Xu and
                  Yuan Zhang and
                  Shiyu Li},
	title = {Hardening Password-Based Credential Databases},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {469--484},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324326},
	doi = {10.1109/TIFS.2023.3324326},
	timestamp = {Wed, 11 Dec 2024 17:20:51 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SongXZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a protection mechanism for password-based credential databases maintained by service providers against leakage, dubbed PCDL. In PCDL, each authentication credential is derived from a user’s password and a salt, where a service provider employs a set of key servers to share the salt in a threshold way. With PCDL, an external adversary cannot derive any information about the underlying passwords from a compromised credential database, even if he can compromise some of the key servers. The most prominent manifestation of PCDL is transparency: integrating PCDL with existing password-based authentication schemes does not require users to perform any additional operation (and thereby does not change users’ interaction patterns), yet enhances the security guarantee significantly. PCDL serves as an independent component only deployed on the service provider side to harden the credential database. As such, PCDL is well compatible with existing password-based authentication schemes. We analyze the security of PCDL and conduct a performance evaluation, which shows that PCDL is secure and efficient.}
}


@article{DBLP:journals/tifs/HeTLLCL24,
	author = {Junjiang He and
                  Cong Tang and
                  Wenshan Li and
                  Tao Li and
                  Li Chen and
                  Xiaolong Lan},
	title = {{BR-HIDF:} An Anti-Sparsity and Effective Host Intrusion Detection
                  Framework Based on Multi-Granularity Feature Extraction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {485--499},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324388},
	doi = {10.1109/TIFS.2023.3324388},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HeTLLCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Host-based intrusion detection systems (HIDS) have been widely acknowledged as an effective approach for detecting and mitigating malicious activities. Among various data sources utilized in HIDS, system call traces have gained significant popularity due to their inherent advantage of providing fine-grained information. Nevertheless, conventional feature extraction techniques relying on system calls tend to overlook the issue of high-dimensional sparse feature space. In this paper, we conduct a theoretical analysis to investigate the underlying causes of the sparsity problem. Subsequently, we propose an anti-sparse theory (anti-ST) as a solution to address this issue. Then, we design a multi-granularity feature extraction method (MGFE), which also meets the prerequisite mathematical conditions of the anti-ST. By applying this method, we effectively reduce the size of the feature space and minimize the number of generated features, thus mitigating sparsity. Furthermore, leveraging this approach, we propose a robust and anti-sparsity host intrusion detection framework, known as the MGFE-based Host Intrusion Detection Framework (BR-HIDF). A series of experiments were conducted to evaluate the proposed framework and compare it with the state-of-the-art method. The results demonstrate that our framework achieves impressive accuracy (97.26%), precision (97.62%), recall (96.85%), and F1 score (97.23%) in the intrusion detection task, surpassing existing frameworks. Moreover, the proposed framework significantly reduces the time overhead by 38.80%, exhibiting the highest AUC value of 0.992. Furthermore, we enhance the robustness of the detection system by integrating host-based and network-based detection, which provides greater flexibility in identifying various types of attacks.}
}


@article{DBLP:journals/tifs/LiuFWGLLZG24,
	author = {Chao Liu and
                  Xue Fu and
                  Yu Wang and
                  Lantu Guo and
                  Yuchao Liu and
                  Yun Lin and
                  Haitao Zhao and
                  Guan Gui},
	title = {Overcoming Data Limitations: {A} Few-Shot Specific Emitter Identification
                  Method Using Self-Supervised Learning and Adversarial Augmentation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {500--513},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324394},
	doi = {10.1109/TIFS.2023.3324394},
	timestamp = {Mon, 22 Jul 2024 08:25:38 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuFWGLLZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Specific emitter identification (SEI) based on radio frequency fingerprinting (RFF) is a physical layer authentication method in the field of wireless network security. RFFs are unique features embedded in the electromagnetic waves, which come from the hard imperfections in the wireless devices. Deep learning has been applied to many SEI tasks due to its powerful feature extraction capabilities. However, the success of most methods hinges on massive and labeled samples, and few methods focus on a realistic scenario, where few samples are available and labeled. In this paper, to overcome data limitations, we propose a few-shot SEI (FS-SEI) method based on self-supervised learning and adversarial augmentation (SA2SEI). Specifically, to overcome the limitation of label dependence for auxiliary dataset, a novelty adversarial augmentation (Adv-Aug)-powered self-supervised learning is designed to pre-train a RFF extractor using unlabeled auxiliary dataset. Subsequently, to overcome the limitation of sample dependence, knowledge transfer is introduced to fine-tune the extractor and a classifier with target dataset including few samples (5-30 samples per emitter in this paper) and corresponding labels. In addition, auxiliary dataset and target dataset are come from different emitters. An open-source large-scale real-world automatic-dependent surveillance-broadcast (ADS-B) dataset and a Wi-Fi dataset are used to evaluate the proposed SA2SEI method. The simulation results show that the proposed method can extract more discriminative RFF features and obtain higher identification performance in the FS-SEI. Specifically, when there are only 5 samples per Wi-Fi device, it can achieve 83.40\\% identification accuracy, in which 38.63\\% identification accuracy improvement comes from the Adv-Aug of pre-training process. The codes are available at https://github.com/LIUC-000/SA2SEI.}
}


@article{DBLP:journals/tifs/HajraASPM24,
	author = {Suvadeep Hajra and
                  Manaar Alam and
                  Sayandeep Saha and
                  Stjepan Picek and
                  Debdeep Mukhopadhyay},
	title = {On the Instability of Softmax Attention-Based Deep Learning Models
                  in Side-Channel Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {514--528},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326667},
	doi = {10.1109/TIFS.2023.3326667},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HajraASPM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In side-channel analysis (SCA), Points-of-Interest (PoIs), i.e., the informative sample points remain sparsely scattered across the whole side-channel trace. Several works in the SCA literature have demonstrated that the attack efficacy could be significantly improved by combining information from the sparsely occurring PoIs. In Deep Learning (DL), a common approach for combining the information from the sparsely occurring PoIs is softmax attention. This work studies the training instability of the softmax attention-based CNN models on long traces. We show that the softmax attention-based CNN model incurs an unstable training problem when applied to longer traces (e.g., traces having a length greater than 10K sample points). We also explore the use of batch normalization and multi-head softmax attention to make the CNN models stable. Our results show that the use of a large number of batch normalization layers and/or multi-head softmax attention (replacing the vanilla softmax attention) can make the models significantly more stable, resulting in better attack efficacy. Moreover, we found our models to achieve similar or better results (up to 85% reduction in the minimum number of the required traces to reach the guessing entropy 1) than the state-of-the-art results on several synchronized and desynchronized datasets. Finally, by plotting the loss surface of the DL models, we demonstrate that using multi-head softmax attention instead of vanilla softmax attention in the CNN models can make the loss surface significantly smoother.}
}


@article{DBLP:journals/tifs/ColtucC24,
	author = {Dinu Coltuc and
                  Henri George Coanda},
	title = {Reversible Contrast Enhancement by Histogram Specification and Very
                  Low Distortion Data Hiding},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {529--539},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326662},
	doi = {10.1109/TIFS.2023.3326662},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ColtucC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper deals with reversible contrast enhancement (RCE). Image enhancement is achieved by histogram specification, the most popular contrast enhancement technique. A low bitrate procedure for inverting histogram specification is developed. The data for original image recovery is reversibly embedded into the contrast enhanced version. Very low distortion RDH schemes that exploit the sparse histogram of the contrast enhanced images are also proposed. Their major novelties are: embedding only into the histogram bins that provide room without any pixel shifting or overflow/underflow control, and encoding of embedded data sequence with fewer bits of “1”. The newly proposed RDH can exceed 1 bpp at average square errors per embedded bit between 0.375 and 0.5. It should be stressed that one gets reversibility at the distortion of least significant bit substitution algorithms. Experimental results are presented. With the proposed RCE-HS, reversibility is obtained without any visual distortion.}
}


@article{DBLP:journals/tifs/GeZ24,
	author = {Yunfei Ge and
                  Quanyan Zhu},
	title = {{GAZETA:} GAme-Theoretic ZEro-Trust Authentication for Defense Against
                  Lateral Movement in 5G IoT Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {540--554},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326975},
	doi = {10.1109/TIFS.2023.3326975},
	timestamp = {Fri, 08 Mar 2024 13:21:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GeZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing connectivity in the 5G Internet of Things networks has enlarged the attack surface and made the traditional security defense inadequate for sophisticated attackers, who can move laterally from node to node with stored credentials once build a foothold in the network. There is a need to shift from the perimeter-based defense to a zero-trust security framework that focuses on agent-centric trust evaluation and access policies to identify malicious attackers, and proactively delay their lateral movement while ensuring system performance. In this work, we propose a GAme-theoretic ZEro-Trust Authentication framework, known as GAZETA, to design interdependent trust evaluation and authentication policies using dynamic game models. The stealthy and dynamic behaviors of the agent are captured by a Markov game with one-sided incomplete information. We provide a quantitative trust evaluation mechanism for the agent and update the trust score continuously based on observations. The analysis of the equilibrium not only provides a way to quantitatively assess the security posture of the network but also enables a formal method to design zero-trust authentication policies. We propose a moving-horizon computational method to enable online decisions and rapid responses to environmental changes. This online computation also enables a dynamic trust evaluation that integrates multiple sources of security evidence. We use a case study to illustrate the resilience, robustness, and efficiency of the proposed zero-trust approach.}
}


@article{DBLP:journals/tifs/PengLZ24,
	author = {Baihao Peng and
                  Junfeng Liu and
                  Jun Zeng},
	title = {Dynamic Analysis of Multiplex Networks With Hybrid Maintenance Strategies},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {555--570},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324386},
	doi = {10.1109/TIFS.2023.3324386},
	timestamp = {Wed, 17 Jul 2024 17:18:22 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PengLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advent of smart terminals and the IOT era has prompted the emergence of the multiplex network system. With the rapid information transmission in multiplex networks, security incidents caused by malicious attackers occur frequently. In light of the foregoing, this paper concentrates on modeling and analyzing the propagation process of multiplex networks. Particularly, this paper proposes an epidemic-based RCMO (Running- Confined- Malfuntioned- Overhauled) model after considering the operating state of equipment and a class of visibility-aware malware. After that, the stability analysis of the equilibria is performed to verify the effectiveness of the propagation threshold obtained in RCMO. Then, we introduce static controls including unique control, target control, acquaintance control, and pulse control, as well as dynamic controls including continuous-time and pulsed forms to the suppression strategies for preventing the spread of malware. Furthermore, the control strategies are cross-combined into 6\\times 6\nhybrid maintenance strategies (HMS), and the simulation analysis is performed from three perspectives: evolution of state variables, accumulation of revenue, and change of controls. We discovered through experimental results that the optimal HMS to inhibit the propagation of malware and the HMS with the highest revenue are always different under various network topologies, but they are all hybrid combinations of continuous-time and pulse controls. To some extent, dynamic control can reduce discrepancies between the HMS and generate approximate returns. Finally, we propose a few cyber defense recommendations for network administrators.}
}


@article{DBLP:journals/tifs/MadhusudhananJSM24,
	author = {Sheema Madhusudhanan and
                  Arun Cyril Jose and
                  Jayakrushna Sahoo and
                  Reza Malekian},
	title = {PRIM{\unicode{1013}}: Novel Privacy-Preservation Model With Pattern
                  Mining and Genetic Algorithm},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {571--585},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324769},
	doi = {10.1109/TIFS.2023.3324769},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MadhusudhananJSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a novel agglomerated privacy-preservation model integrated with data mining and evolutionary Genetic Algorithm (GA). Privacy-pReservIng with Minimum Epsilon (PRIM \\epsilon ) delivers minimum privacy budget ( \\epsilon ) value to protect personal or sensitive data during data mining and publication. In this work, the proposed Pattern identification in the Locale of Users with Mining (PLUM) algorithm, identifies frequent patterns from dataset containing users’ sensitive data. \\epsilon -allocation by Differential Privacy (DP) is achieved in PRIM \\epsilon with GA _{\\textbf {PRIM$\\epsilon $}} , yielding a quantitative measure of privacy loss ( \\epsilon ) ranging from 0.0001 to 0.045. The proposed model maintains the trade-off between privacy and data utility with an average relative error of 0.109 on numerical data and an Earth Mover’s Distance (EMD) metric in the range between [0.2,1.3] on textual data. PRIM \\epsilon model is verified with Probabilistic Computational Tree Logic (PCTL) and proved to accept DP data only when \\epsilon \\le 0.5 . The work demonstrated resilience of model against background knowledge, membership inference, reconstruction, and privacy budget attack. PRIM \\epsilon is compared with existing techniques on DP and is found to be linearly scalable with worst time complexity of \\mathcal {O} (n log n).}
}


@article{DBLP:journals/tifs/GrujicV24,
	author = {Milos Grujic and
                  Ingrid Verbauwhede},
	title = {Optimizing Linear Correctors: {A} Tight Output Min-Entropy Bound and
                  Selection Technique},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {586--600},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326986},
	doi = {10.1109/TIFS.2023.3326986},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GrujicV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Post-processing of the raw bits produced by a true random number generator (TRNG) is always necessary when the entropy per bit is insufficient for security applications. In this paper, we derive a tight bound on the output min-entropy of the algorithmic post-processing module based on linear codes, known as linear correctors. Our bound is based on the codes’ weight distributions, and we prove that it holds even for the real-world noise sources that produce independent but not identically distributed bits. Additionally, we present a method for identifying the optimal linear corrector for a given input min-entropy rate that maximizes the throughput of the post-processed bits while simultaneously achieving the needed security level. Our findings show that for an output min-entropy rate of 0.999, the extraction efficiency of the linear correctors with the new bound can be up to \\mathbf {130.56\\, \\%} higher when compared to the old bound, with an average improvement of \\mathbf {41.2\\, \\%} over the entire input min-entropy range. On the other hand, the required min-entropy of the raw bits for the individual correctors can be reduced by up to \\mathbf {61.62\\, \\%} .}
}


@article{DBLP:journals/tifs/DuCSZH24,
	author = {Hanbiao Du and
                  Zheng Che and
                  Meng Shen and
                  Liehuang Zhu and
                  Jiankun Hu},
	title = {Breaking the Anonymity of Ethereum Mixing Services Using Graph Feature
                  Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {616--631},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326984},
	doi = {10.1109/TIFS.2023.3326984},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DuCSZH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the property of helping users further enhance the anonymity of transactions, mixing services in blockchain have gained wide popularity in recent years. However, the strong untraceability offered by mixing services has led to the abuse of them by criminals for money laundering and committing fraud. These illegal actions pose significant threats to the blockchain ecosystem and financial order. In this paper, we focus on the problem of correlating the addresses of mixing transactions in Tornado Cash, a widely-used mixing service on Ethereum. We propose a graph neural network framework named MixBroker, which aims to break the anonymity of Tornado Cash by correlate mixing addresses from the perspective of node-pair link prediction. Specifically, we construct a Mixing Interaction Graph (MIG) using raw Ethereum mixing transaction data that can be used for subsequent analysis. To better represent the properties of mixing account nodes, we extract features from account nodes in the MIG from multiple perspectives. Furthermore, we design a GNN-based link prediction mechanism to serve as the backbone of MixBroker. This mechanism captures the interconnected nature of nodes within the MIG and calculates the probability of correlation between account nodes through node embeddings. In addition, to solve the problem of lacking ground-truth, we collect a large number of real mixing transactions of Ethereum in Tornado Cash and construct a ground-truth dataset by combining the principles of Ethereum Name Service (ENS). We conduct extensive experiments on the datasets, and the results demonstrate that MixBroker has a superior performance over other state-of-the-art methods on the address correlation problem in Ethereum mixing transactions.}
}


@article{DBLP:journals/tifs/BeigizadSZR24,
	author = {Ali Asghar Beigizad and
                  Hadi Soleimany and
                  Sara Zarei and
                  Hamed Ramzanipour},
	title = {Linked Fault Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {632--645},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327658},
	doi = {10.1109/TIFS.2023.3327658},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BeigizadSZR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Numerous fault models with distinct characteristics and effects have been developed. The costs, repeatability, and practicability of these models should be assessed. Moreover, there must be effective ways to use the injected fault to retrieve the secret key, particularly if the implementation includes any countermeasures. In this paper, we introduce a new fault analysis called “linked fault analysis” (LFA), a more powerful technique than other well-known fault attacks against implementations of symmetric primitives, especially in software implementations. For known fault analysis, the basis for the fault model is either the bias over the faulty value or the relationship between the correct value and the faulty one. In the LFA, however, a single fault involves two intermediate values. The faulty target variable, u' , is linked to a second variable, v , such that a particular relation holds: u'=l(v) . LFA lets the attacker perform fault attacks without the input control, using far fewer data than previously introduced fault attacks in the same class. We show the utilization of LFA in the presence or absence of typical redundancy-based countermeasures by introducing “Linked Differential Fault Analysis” (LDFA) and “Linked Ineffective Fault Analysis” (LIFA). We also demonstrate that, under specific circumstances, LFA is still effective even when masking protections are in place. We have performed our attacks against the public implementation of AES and PRESENT in ATMEGA328p to show the feasibility of LFA in the real world. The practical results and simulations validate our theoretical models as well.}
}


@article{DBLP:journals/tifs/BriguglioYTM24,
	author = {William Briguglio and
                  Waleed A. Yousef and
                  Issa Traor{\'{e}} and
                  Mohammad Mamun},
	title = {Federated Supervised Principal Component Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {646--660},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326981},
	doi = {10.1109/TIFS.2023.3326981},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BriguglioYTM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In federated learning, standard machine learning (ML) techniques are modified so they can be applied to data held by separate participants without the need for exchanging said data and while preserving privacy. Other data modelling techniques, such as singular value decomposition, have been similarly federated, enabling federated principal component analysis (PCA), which is a popular preprocessing step for ML tasks. Supervised PCA improves on standard PCA by using labeled data to retain more relevant information for supervised ML problems. However, a federated version of supervised PCA does not exist in the literature. In this paper, we propose a federated version of supervised PCA and its dual and kernel variations, called FeS-PCA, dual FeS-PCA, and FeSK-PCA, respectively. We used random orthogonal matrix masking to keep FeS-PCA and dual FeS-PCA private, while FeSK-PCA was kept private using an approximation of the standard approach. We tested our proposed approaches by recreating visualization, classification, and regression experiments from the original unfederated supervised PCA paper. We further added a real-world federated dataset to test the scalability and fidelity of our approach. Our analysis and results indicate that FeS-PCA and dual FeS-PCA are faithful, lossless, and private versions of their unfederated counterparts. Furthermore, despite being an approximation, FeSK-PCA achieves nearly identical performance to standard kernel SPCA in many cases. This is in addition to the added benefit of a reduced runtime and smaller memory footprint.}
}


@article{DBLP:journals/tifs/DengLXQ24,
	author = {Zhouyan Deng and
                  Jiajia Liu and
                  Yijie Xun and
                  Junman Qin},
	title = {IdentifierIDS: {A} Practical Voltage-Based Intrusion Detection System
                  for Real In-Vehicle Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {661--676},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327026},
	doi = {10.1109/TIFS.2023.3327026},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DengLXQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As innovative technologies such as autonomous driving, over-the-air technology, and vehicle-to-everything are widely applied to intelligent connected vehicles, people can gain a more convenient and safer driving experience. Although the application of these technologies facilitates our lives, they also bring a series of vulnerable interfaces (such as 5G, Bluetooth, and WiFi), which pose a significant security threat to existing in-vehicle networks. To address these threats, researchers have proposed two mainstream schemes, including message authentication and intrusion detection system (IDS), where the scheme of message authentication needs to occupy the limited bandwidth of controller area network (CAN) bus. Furthermore, most IDSs either cannot locate the sender of the attack, fail to detect aperiodic malicious frames, or require prior knowledge of which CAN identifiers (IDs) belong to which electronic control units (ECUs). To address these weaknesses, we propose a practical voltage-based IDS named IdentifierIDS for real in-vehicle networks. To the best of our knowledge, it is the first scheme to detect intrusions by establishing a voltage fingerprint for each ID without the need for prior knowledge. This allows IdentifierIDS to detect both periodic and aperiodic malicious frames without occupying the limited bandwidth of the CAN bus. As a self-learning IDS, it can adapt to different in-vehicle networks without the need for customization for them. Experiments on three real vehicles demonstrate the robustness of our scheme in different in-vehicle networks.}
}


@article{DBLP:journals/tifs/XiaOGXZAA24,
	author = {Qi Xia and
                  Isaac Amankona Obiri and
                  Jianbin Gao and
                  Hu Xia and
                  Xiaosong Zhang and
                  Kwame Omono Asamoah and
                  Sandro Amofa},
	title = {{PRIDN:} {A} Privacy Preserving Data Sharing on Named Data Networking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {677--692},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327660},
	doi = {10.1109/TIFS.2023.3327660},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XiaOGXZAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Named Data Networking (NDN) architecture is a futuristic internet infrastructure that aims to deliver content efficiently. However, NDN is faced with the challenge of ensuring the privacy of both content and names. Traditional solutions have focused on encrypting and signing content before injecting the resultant ciphertext into the NDN platform to provide confidentiality and integrity. However, these solutions fail to protect content name privacy in critical applications such as the military and healthcare. To address this challenge, we propose Privacy-Preserving Data Sharing on Named Data Networking (PRIDN), which employs a combination of proxy re-encryption and symmetric mechanisms to secure both content and names. PRIDN offers several advantages over existing solutions. Firstly, it eliminates the need for subscribers to communicate with content publishers for decryption keys, reducing communication overhead and ensuring that content publishers do not need to be online all the time to respond to key generation requests. Second, the proxy re-encryption mechanism prevents replication of ciphertexts, thus avoiding multiple instances of the same content in the network. Lastly, PRIDN also protects sensitive information in content names, preventing user profiling and censorship. Simulation results from ndnSIM and MIRACL libraries demonstrate that PRIDN reduces content retrieval time on NDN. A crypto-verification tool, Verifpal, shows that the proposed protocols are secure for real-world deployment.}
}


@article{DBLP:journals/tifs/ChenYFLD24,
	author = {Zekai Chen and
                  Shengxing Yu and
                  Mingyuan Fan and
                  Ximeng Liu and
                  Robert H. Deng},
	title = {Privacy-Enhancing and Robust Backdoor Defense for Federated Learning
                  on Heterogeneous Data},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {693--707},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326983},
	doi = {10.1109/TIFS.2023.3326983},
	timestamp = {Mon, 26 Aug 2024 16:11:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenYFLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) allows multiple clients to train deep learning models collaboratively while protecting sensitive local datasets. However, FL has been highly susceptible to security for federated backdoor attacks (FBA) through injecting triggers and privacy for potential data leakage from uploaded models in practical application scenarios. FBA defense strategies consider specific and limited attacker models, and a sufficient amount of noise injected can only mitigate rather than eliminate the attack. To address these deficiencies, we introduce a Robust Federated Backdoor Defense Scheme (RFBDS) and Privacy-preserving RFBDS (PrivRFBDS) to ensure the elimination of adversarial backdoors. Our RFBDS to overcome FBA consists of amplified magnitude sparsification, adaptive OPTICS clustering, and adaptive clipping. The experimental evaluation of RFBDS is conducted on three benchmark datasets and an extensive comparison is made with state-of-the-art studies. The results demonstrate the promising defense performance from RFBDS, moderately improved by 31.75% ~ 73.75% in clustering defense methods, and 0.03% ~ 56.90% for Non-IID to the utmost extent for the average FBA success rate over MNIST, FMNIST, and CIFAR10. Besides, our privacy-preserving shuffling in PrivRFBDS maintains is 7.83e^{-5}\\,\\,\\sim \\,\\,0.42\\times that of state-of-the-art works.}
}


@article{DBLP:journals/tifs/GuoZHWJ24,
	author = {Yu Guo and
                  Yu Zhao and
                  Saihui Hou and
                  Cong Wang and
                  Xiaohua Jia},
	title = {Verifying in the Dark: Verifiable Machine Unlearning by Using Invisible
                  Backdoor Triggers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {708--721},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3328269},
	doi = {10.1109/TIFS.2023.3328269},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GuoZHWJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine unlearning as a fundamental requirement in Machine-Learning-as-a-Service (MLaaS) has been extensively studied with increasing concerns about data privacy. It requires MLaaS providers should delete training data upon user requests. Unfortunately, none of the existing studies can efficiently achieve machine unlearning validation while preserving the retraining efficiency and the service quality after data deletion. Besides, how to craft the validation scheme to prevent providers from spoofing validation by forging proofs remains under-explored. In this paper, we introduce a backdoor-assisted validation scheme for machine unlearning. The proposed design is built from the ingenious combination of backdoor triggers and incremental learning to assist users in verifying proofs of machine unlearning without compromising performance and service quality. We propose to embed invisible markers based on backdoor triggers into privacy-sensitive data to prevent MLaaS providers from distinguishing poisoned data for validation spoofing. Users can use prediction results to determine whether providers comply with data deletion requests. Besides, we incorporate our validation scheme into an efficient incremental learning approach via our index structure to further facilitate the performance of retraining after data deletion. Evaluation results on real-world datasets confirm the efficiency and effectiveness of our proposed verifiable machine unlearning scheme.}
}


@article{DBLP:journals/tifs/HanGMLXBNMM24,
	author = {Ruidong Han and
                  Huihui Gong and
                  Siqi Ma and
                  Juanru Li and
                  Chang Xu and
                  Elisa Bertino and
                  Surya Nepal and
                  Zhuo Ma and
                  Jianfeng Ma},
	title = {A Credential Usage Study: Flow-Aware Leakage Detection in Open-Source
                  Projects},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {722--734},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326985},
	doi = {10.1109/TIFS.2023.3326985},
	timestamp = {Thu, 13 Feb 2025 09:21:00 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HanGMLXBNMM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Authentication and cryptography are critical security functions and, thus, are very often included as part of code. These functions require using credentials, such as passwords, security tokens, and cryptographic keys. However, developers often incorrectly implement/use credentials in their code because of a lack of secure coding skills. This paper analyzes open-source projects concerning the correct use of security credentials. We developed a semantic-rich, language-independent analysis approach for analyzing many projects automatically. We implemented a detection tool, SEAGULL, to automatically check open-source projects based on string literal and code structure information. Instead of analyzing the entire project code, which might result in path explosion when constructing data and control dependencies, SEAGULL pinpoints all literal constants to identify credential candidates and then analyzes the code snippets correlated to these candidates. SEAGULL accurately identifies the leaked credentials by obtaining semantic and syntax information about the code. We applied SEAGULL to 377 open-source projects. SEAGULL successfully reported 19 real-world credential leakages out of those projects. Our analysis shows that some developers protected or erased the credentials in the current project versions, but previously used credentials can still be extracted from the project’s historical versions. Although the implementations of credential leakages seem to be fixed in the current projects, attackers could successfully log into accounts if developers keep using the same credentials as before. Additionally, we found that such credential leakages still affect some projects. By exploiting leaked credentials, attackers can log into particular accounts.}
}


@article{DBLP:journals/tifs/LiuGPWL24,
	author = {Decheng Liu and
                  Xinbo Gao and
                  Chunlei Peng and
                  Nannan Wang and
                  Jie Li},
	title = {Universal Heterogeneous Face Analysis via Multi-Domain Feature Disentanglement},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {735--747},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327666},
	doi = {10.1109/TIFS.2023.3327666},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuGPWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous face analysis is an important and challenge problem in face recognition community, because of the large modality discrepancy between heterogeneous face images. Existing methods either focus on transforming heterogeneous faces into the same style via face synthesis process, or intend to directly recognize heterogeneous face via modality invariant descriptors. However, the tasks of cross modality face synthesis and face recognition share a common purpose, which is to disentangle an inherent explainable representation. To this end, we propose a novel universal heterogenous face analysis method via multi-domain feature disentanglement, which does not need any face domain label. The proposed method explores to disentangle factors of variations of cross modality faces in an unsupervised manner. Then we could translate cross modality faces through modifying semantic factors, and the extracted inherent explainable representation still maintains being discriminative for heterogeneous face recognition. Experimental results on multiple cross modality face databases demonstrate the effectiveness of the proposed method. These experimental results also inspire us that the unsupervised disentangled module could help to analyze the interpretability of heterogenous face representation.}
}


@article{DBLP:journals/tifs/HeSHDNTHLZ24,
	author = {Ying He and
                  Zhili Shen and
                  Jingyu Hua and
                  Qixuan Dong and
                  Jiacheng Niu and
                  Wei Tong and
                  Xu Huang and
                  Chen Li and
                  Sheng Zhong},
	title = {Backdoor Attack Against Split Neural Network-Based Vertical Federated
                  Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {748--763},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327853},
	doi = {10.1109/TIFS.2023.3327853},
	timestamp = {Sun, 10 Dec 2023 17:00:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HeSHDNTHLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vertical federated learning (VFL) is being used more and more widely in industry. One of its most common application scenarios is a two-party setting: a participant (i.e., the host), who exclusively owns the labels but possesses insufficient number of features, wants to improve its model performance by combining features from another participant (i.e., the client) of a different business group. The best deep ML architecture suits for this scenario is considered to be Split Neural Network (SplitNN), in which each participant runs a self-defined bottom model to learn the hidden representations (i.e., the local embeddings) of its local data and then forwards them to the host, who runs a top model to aggregate both the local embeddings to produce the final predicts. In this paper, we assume the client is malicious and demonstrate that she/he could inject a stealthy backdoor into the top model during the training to misclassify any sample to a pre-selected target class with a high probability by just replacing its local embedding with a special trigger vector regardless of the host-side embedding. This task is non-trivial because existing data poison attacks for backdoor injection in traditional models usually require to modify the labels of a set of trigger-tagged samples of non-target classes, which is impossible here as the client has no rights to access or modify the labels exclusively owned by the host. Targeting this challenge, we propose a SplitNN-dedicated data poison attack which does not require to modify any labels but just replaces the local embeddings of a very small number of target-class samples with a carefully constructed trigger vector during training. The experiments on four datasets show that our attack can achieve an attack rate as high as 94%, while bringing negligible side-effects to the model accuracy. Moreover, it is stealthy enough to resist various anomaly detection methods.}
}


@article{DBLP:journals/tifs/ZhangLGBXHL24,
	author = {Menghao Zhang and
                  Guanyu Li and
                  Cheng Guo and
                  Han Bao and
                  Mingwei Xu and
                  Hongxin Hu and
                  Fenghua Li},
	title = {IMap: Toward a Fast, Scalable and Reconfigurable In-Network Scanner
                  With Programmable Switches},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {601--615},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327665},
	doi = {10.1109/TIFS.2023.3327665},
	timestamp = {Mon, 11 Nov 2024 16:51:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLGBXHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network scanning has been a standard measurement technique to understand a network’s security situations, e.g., revealing security vulnerabilities, monitoring service deployments. However, probing a large-scale scanning space with existing network scanners is both difficult and slow, since they are all implemented on commodity servers and deployed at the network edge. To address this, we introduce IMap, a fast, scalable and reconfigurable in-network scanner based on programmable switches. In designing IMap, we overcome key restrictions posed by computation models and memory resources of programmable switches, and devise numerous techniques and optimizations, including an address-random and rate-adaptive probe packet generation mechanism, and a correct and efficient response packet processing scheme, to turn a switch into a practical runtime-reconfigurable high-speed network scanner. We implement an open-source prototype of IMap, and evaluate it with extensive testbed experiments and real-world deployments in our campus network. Evaluation results show that even with one switch port enabled, IMap can survey all ports of our campus network (i.e., a total of up to 25 billion scanning space) in 8 minutes. This demonstrates a nearly 4 times faster scanning speed and 1.5 times higher scanning accuracy than the state of the art, which shows that IMap has great potentials to be the next-generation terabit network scanner with all switch ports enabled. Besides, our experiments also show that IMap supports the reconfiguration of scanning tasks at runtime, without incurring switch downtime. Leveraging IMap, we also discover several potential security threats in our campus network, and report them to our network administrators responsibly.}
}


@article{DBLP:journals/tifs/YuanLWWWLMP24,
	author = {Xiaohan Yuan and
                  Jiqiang Liu and
                  Bin Wang and
                  Wei Wang and
                  Bin Wang and
                  Tao Li and
                  Xiaobo Ma and
                  Witold Pedrycz},
	title = {FedComm: {A} Privacy-Enhanced and Efficient Authentication Protocol
                  for Federated Learning in Vehicular Ad-Hoc Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {777--792},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3324747},
	doi = {10.1109/TIFS.2023.3324747},
	timestamp = {Fri, 13 Dec 2024 07:52:49 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YuanLWWWLMP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In vehicular ad-hoc networks (VANET), federated learning enables vehicles to collaboratively train a global model for intelligent transportation without sharing their local data. However, due to dynamic network structure and unreliable wireless communication of VANET, various potential risks (e.g., identity privacy leakage, data privacy inference, model integrity compromise, and data manipulation) undermine the trustworthiness of intermediate model parameters necessary for building the global model. While existing cryptography techniques and differential privacy provide provable security paradigms, the practicality of secure federated learning in VANET is hindered in terms of training efficiency and model performance. Therefore, developing a secure and efficient federated learning in VANET remains a challenge. In this work, we propose a privacy-enhanced and efficient authentication protocol for federated learning in VANET, called FedComm. Unlike existing solutions, FedComm addresses the above challenge through user anonymity. First, FedComm enables vehicles to participate in training with unlinkable pseudonyms, ensuring both privacy preservation and efficient collaboration. Second, FedComm incorporates an efficient authentication protocol to guarantee the authenticity and integrity of model parameters originated from anonymous vehicles. Finally, FedComm accurately identifies and completely eliminates malicious vehicles in anonymous communication. Security analysis and verification with ProVerif demonstrate that FedComm enhances privacy and reliability of intermediate model parameters. Experimental results show that FedComm reduces the overhead of proof generation and verification by 67.38% and 67.39%, respectively, compared with the state-of-the-art authentication protocols used in federated learning.}
}


@article{DBLP:journals/tifs/LiuWSRL24,
	author = {Hui Liu and
                  Wenya Wang and
                  Hao Sun and
                  Anderson Rocha and
                  Haoliang Li},
	title = {Robust Domain Misinformation Detection via Multi-Modal Feature Alignment},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {793--806},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326368},
	doi = {10.1109/TIFS.2023.3326368},
	timestamp = {Fri, 15 Nov 2024 15:28:13 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuWSRL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social media misinformation harms individuals and societies and is potentialized by fast-growing multi-modal content (i.e., texts and images), which accounts for higher “credibility” than text-only news pieces. Although existing supervised misinformation detection methods have obtained acceptable performances in key setups, they may require large amounts of labeled data from various events, which can be time-consuming and tedious. In turn, directly training a model by leveraging a publicly available dataset may fail to generalize due to domain shifts between the training data (a.k.a. source domains) and the data from target domains. Most prior work on domain shift focuses on a single modality (e.g., text modality) and ignores the scenario where sufficient unlabeled target domain data may not be readily available in an early stage. The lack of data often happens due to the dynamic propagation trend (i.e., the number of posts related to fake news increases slowly before catching the public attention). We propose a novel robust domain and cross-modal approach (RDCM) for multi-modal misinformation detection. It reduces the domain shift by aligning the joint distribution of textual and visual modalities through an inter-domain alignment module and bridges the semantic gap between both modalities through a cross-modality alignment module. We also propose a framework that simultaneously considers application scenarios of domain generalization (in which the target domain data is unavailable) and domain adaptation (in which unlabeled target domain data is available). Evaluation results on two public multi-modal misinformation detection datasets (Pheme and Twitter Datasets) evince the superiority of the proposed model.}
}


@article{DBLP:journals/tifs/VedadiKS24,
	author = {Elahe Vedadi and
                  Yasaman Keshtkarjahromi and
                  Hulya Seferoglu},
	title = {Efficient Coded Multi-Party Computation at Edge Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {807--820},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326970},
	doi = {10.1109/TIFS.2023.3326970},
	timestamp = {Fri, 08 Mar 2024 13:21:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/VedadiKS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-party computation (MPC) is promising for designing privacy-preserving machine learning algorithms at edge networks. An emerging approach is coded-MPC (CMPC), which advocates the use of coded computation to improve the performance of MPC in terms of the required number of workers involved in computations. The current approach for designing CMPC algorithms is to merely combine efficient coded computation constructions with MPC. We show that this approach fails short of being efficient; e.g., entangled polynomial codes are not necessarily better than PolyDot codes in MPC setting, while they are always better for coded computation. Motivated by this observation, we propose a new construction; Adaptive Gap Entangled (AGE) polynomial codes for MPC. We show through analysis and simulations that MPC with AGE codes always perform better than existing CMPC algorithms in terms of the required number of workers as well as computation, storage, and communication overhead.}
}


@article{DBLP:journals/tifs/ZhangMLD24,
	author = {Yuqing Zhang and
                  Zhaofeng Ma and
                  Shoushan Luo and
                  Pengfei Duan},
	title = {Dynamic Trust-Based Redactable Blockchain Supporting Update and Traceability},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {821--834},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326379},
	doi = {10.1109/TIFS.2023.3326379},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangMLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain, as an emerging technology, is constantly evolving due to its remarkable advantages but is also subject to its unalterability, which leads to the misuse of blockchain storage and causes adverse effects. Hence, the redactable blockchain was proposed, which can alleviate the above issues in a controlled manner. However, a situation exists in which the modifiers specified by customized identities or attributes in the existing schemes may be malicious, which can easily lead to malicious modification events. Evaluating, filtering, and limiting malicious modifiers in advance may be a feasible solution to the situation. Hence, we propose an efficient dynamic trust-based redactable blockchain supporting update and traceability, which offers full-process security with pre-modification pre-evaluation, modification privilege restrictions, and post-modification traceability. Firstly, we consider the user’s various behaviors and multiple factors and customize a dynamic trust evaluation model for redactable blockchain to comprehensively evaluate the reliability of the user. Then, we combine the user’s trust worthiness, dynamic proactive secret sharing( \\mathcal {DPSS} ), chameleon hash( \\mathcal {CH} ), and digital signature ( \\mathcal {DS} ) to design a dynamic trust-based chameleon hash supporting update and traceability, called \\mathcal {DTCH} , to realize full-process security, and prove its security. Thirdly, we construct the \\mathcal {DTCH} -based redactable blockchain supporting update and traceability, demonstrate its security and further apply it to consortium blockchain. Finally, we evaluate the performance of the constructed model and scheme, and the evaluation results illuminate that they are not only effective but also possess better performance.}
}


@article{DBLP:journals/tifs/WangLXRWZC24,
	author = {Qiuhua Wang and
                  Chengyu Li and
                  Tianyu Xia and
                  Yizhi Ren and
                  Dong Wang and
                  Guoyan Zhang and
                  Kim{-}Kwang Raymond Choo},
	title = {Optimal Selfish Mining-Based Denial-of-Service Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {835--850},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326386},
	doi = {10.1109/TIFS.2023.3326386},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangLXRWZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, Bitcoin has become one of the most popular cryptocurrencies. The most significant mechanism of Bitcoin is PoW (Proof-of-Work), but it also brings opportunities for mining attacks. In our last study, we proposed a Selfish Mining-based Denial-of-Service Attack (SDoS), which can cause serious threats to the Bitcoin system. On this basis, we further put forward three greedier SDoS attack strategies: a competitive greedy SDoS attack strategy ESDoS, a trail greedy SDoS attack strategy TSDoS, a hybrid greedy SDoS attack strategy ETSDoS, and a more public SDoS attack strategy PSDoS. Besides, we also study the adversary’s optimal strategies under different conditions. The experimental results show that if the adversary adopts the SDoS optimal strategy, his revenue increase rate will be further improved and significantly higher than the other existing mining attacks. If the adversary masters 14% of the total mining power, he has a chance to improve his revenue (25% in Selfish Mining, 19.6% in SDoS), and if the adversary masters 15% of the total mining power, he is capable of launching a 51% attack.}
}


@article{DBLP:journals/tifs/LongZWJS24,
	author = {Xingming Long and
                  Jie Zhang and
                  Shuzhe Wu and
                  Xin Jin and
                  Shiguang Shan},
	title = {Dual Sampling Based Causal Intervention for Face Anti-Spoofing With
                  Identity Debiasing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {851--862},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326370},
	doi = {10.1109/TIFS.2023.3326370},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LongZWJS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Improving generalization to unseen scenarios is one of the greatest challenges in Face Anti-spoofing (FAS). Most previous FAS works focus on domain debiasing to eliminate the distribution discrepancy between training and test data. However, a crucial but usually neglected bias factor is the face identity. Generally, the identity distribution varies across the FAS datasets as the participants in these datasets are from different regions, which will lead to serious identity bias in the cross-dataset FAS tasks. In this work, we resort to causal learning and propose Dual Sampling based Causal Intervention (DSCI) for face anti-spoofing, which improves the generalization of the FAS model by eliminating the identity bias. DSCI treats the bias as a confounder and applies the backdoor adjustment through the proposed dual sampling on the face identity and the FAS feature. Specifically, we first sample the data uniformly on the identity distribution that is obtained by a pretrained face recognition model. By feeding the sampled data into a network, we can get an estimated FAS feature distribution and sample the FAS feature on it. Sampling the FAS feature from a complete estimated distribution can include potential counterfactual features in the training, which effectively expands the training data. The dual sampling process helps the model learn the real causality between the FAS feature and the input liveness, allowing the model to perform more stably across various identity distributions. Extensive experiments demonstrate our proposed method outperforms the state-of-the-art methods on both intra- and cross-dataset evaluations.}
}


@article{DBLP:journals/tifs/ShaoLLZ24,
	author = {Huikai Shao and
                  Chengcheng Liu and
                  Xiaojiang Li and
                  Dexing Zhong},
	title = {Privacy Preserving Palmprint Recognition via Federated Metric Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {878--891},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327667},
	doi = {10.1109/TIFS.2023.3327667},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ShaoLLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based palmprint recognition methods have made good progress and obtained promising performance. However, most of them are mainly focused on continuously improving the recognition accuracy, while ignore the privacy preserving, which is also extremely significant. In this paper, we propose a novel Federated Metric Learning (FedML) method to address the issue of data privacy and data islands in palmprint recognition. There are several clients with different structures deployed in communities, which cannot access the private data of others. The key is to improve the accuracy of each client by generating understandable knowledge and transferring it to each other but without explicitly sharing its private data or model architecture. A public dataset is introduced and several effective communication losses are constructed at both instance level and relation level to help clients to learn from each other. Furthermore, transfer learning is applied to close the gap between private and public data. Extensive experiments are conducted on eighteen constrained and unconstrained palmprint benchmark datasets. The results demonstrate that FedML can outperform other methods by a large margin and obtain promising performance.}
}


@article{DBLP:journals/tifs/YangHZLW24,
	author = {Yunchao Yang and
                  Miao Hu and
                  Yipeng Zhou and
                  Xuezheng Liu and
                  Di Wu},
	title = {{CSRA:} Robust Incentive Mechanism Design for Differentially Private
                  Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {892--906},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3329441},
	doi = {10.1109/TIFS.2023.3329441},
	timestamp = {Thu, 13 Feb 2025 15:46:14 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangHZLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The differentially private federated learning (DPFL) paradigm emerges to firmly preserve data privacy from two perspectives. First, decentralized clients merely exchange model updates rather than raw data with a parameter server (PS) over multiple communication rounds for model training. Secondly, model updates to be exposed to the PS will be distorted by clients with differentially private (DP) noises. To incentivize clients to participate in DPFL, various incentive mechanisms have been proposed by existing works which reward participating clients based on their data quality and DP noise scales assuming that all clients are honest and genuinely report their DP noise scales. However, the PS cannot directly measure or observe DP noise scales leaving the vulnerability that clients can boost their rewards and lower DPFL utility by dishonestly reporting their DP noise scales. Through a quantitative study, we validate the adverse influence of dishonest clients in DPFL. To overcome this deficiency, we propose a robust incentive mechanism called client selection with reverse auction (CSRA) for DPFL. We prove that CSRA satisfies the properties of truthfulness, individual rationality, budget feasibility and computational efficiency. Besides, CSRA can prevent dishonest clients with two steps in each communication round. First, CSRA compares the variance of exposed model updates and claimed DP noise scale for each individual to identify suspicious clients. Second, suspicious clients will be further clustered based on their model updates to finally identify dishonest clients. Once dishonest clients are identified, CSRA will not only remove them from the current round but also lower their probability of being selected in subsequent rounds. Extensive experimental results demonstrate that CSRA can provide robust incentive against dishonest clients in DPFL and significantly outperform other baselines on three real public datasets.}
}


@article{DBLP:journals/tifs/XueWJZWP24,
	author = {Yiming Xue and
                  Jiaxuan Wu and
                  Ronghua Ji and
                  Ping Zhong and
                  Juan Wen and
                  Wanli Peng},
	title = {Adaptive Domain-Invariant Feature Extraction for Cross-Domain Linguistic
                  Steganalysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {920--933},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3328455},
	doi = {10.1109/TIFS.2023.3328455},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XueWJZWP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing linguistic steganalysis methods require the training and testing datasets to be independent and identically distributed (i.i.d). However, in real-world scenarios, various types of text and steganographic algorithms are employed to generate steganographic text, making it challenging to fulfill the requirement of independent and identical distribution between training and test datasets. This issue, known as the domain mismatch problem, significantly diminishes the detection performance. Thus, it is reasonable to consider domain adaptation by reducing the distribution discrepancy of different domains. However, how to measure and minimize the discrepancy for linguistic steganalysis remains a big challenge. In this paper, we put forward a cross-domain linguistic steganalysis architecture based on a new domain distance metric and adaptive weight selection network. Concretely, a novel steganographic domain distance metric (SDDM) is first proposed, which can effectively characterize the overall distribution discrepancy and capture the weak noise introduced by the information embedding process. Additionally, an adaptive weight selection network with a switching-path structure is designed to calculate domain-specific attention weights, facilitating the model to adapt to various discrepancies scenarios and enhancing its domain-invariant feature representation capability. Extensive experiments show that the proposed method achieves state-of-the-art performance for cross-domain linguistic steganalysis.}
}


@article{DBLP:journals/tifs/XinWWLG24,
	author = {Jingwei Xin and
                  Zikai Wei and
                  Nannan Wang and
                  Jie Li and
                  Xinbo Gao},
	title = {Large Pose Face Recognition via Facial Representation Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {934--946},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3329686},
	doi = {10.1109/TIFS.2023.3329686},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XinWWLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Overcoming image acquisition perspectives and face pose variations is a key problem in unconstrained face recognition tasks. One of the practical approaches is by reconstructing the face with extreme pose into a version that is more easily recognized by the discriminator, such as a frontal face. Often, existing methods attempt to balance the accuracy of downstream tasks with human visual perception, but ignore the differences in propensity between the two. Besides, large-scale datasets of profile-frontal paired face images are absent, which further hinders the training of models. In this work, we investigate a variety of face reconstruction approaches and propose a very simple, but very effective method to match face images across different scenes, named facial representation learning (FRL). The core idea of FRL is to introduce a representation generator in front of a pre-trained face recognition model, which can extract face representations from arbitrary faces that are more suitable for recognition model discrimination. In particular, the representation generator reconstructs the facial representation by minimising identity differences from the frontal face and adds pixel-level and adversarial constraints to cater for discriminator preferences. Extensive benchmark experiments show that the proposed method not only achieves better performance than state-of-the-art methods, but also can further squeeze the inference potential of existing face recognition models.}
}


@article{DBLP:journals/tifs/Gaeta24,
	author = {Rossano Gaeta},
	title = {An Accurate and Efficient Algorithm to Identify Malicious Nodes of
                  a Graph},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {947--958},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3328211},
	doi = {10.1109/TIFS.2023.3328211},
	timestamp = {Sun, 17 Dec 2023 20:56:52 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Gaeta24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The identification of misbehaving elements in a distributed system is an important task in many diverse settings that can be represented as graphs; this problem can be cast as the computation of a subset of the graph nodes by exploiting a pre-determined detection mechanism. In this paper we propose a simple yet accurate algorithm to compute the set of nodes of a graph suspected to be malicious that is based on the so called comparison detection model. In this framework, a node can play the role of the comparator for two of its neighbors and can provide a boolean result based on the actual status of both. The algorithm we propose has low computational complexity and linear space complexity; furthermore, it only requires one parameter to trade accuracy against computational cost. We also show it outperforms the state-of-the-art and performs equally very well on both synthetic and real world graphs.}
}


@article{DBLP:journals/tifs/LiMZZW24,
	author = {Shuyi Li and
                  Ruijun Ma and
                  Jianhang Zhou and
                  Bob Zhang and
                  Lifang Wu},
	title = {Joint Discriminative Analysis With Low-Rank Projection for Finger
                  Vein Feature Extraction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {959--969},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326364},
	doi = {10.1109/TIFS.2023.3326364},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiMZZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the last decades, finger vein biometric recognition has generated increasing attention because of its high security, accuracy, and natural anti-counterfeiting. However, most of the existing finger vein recognition approaches rely on image enhancement or require much prior knowledge, which limits their generalization ability to different databases and different scenarios. Additionally, these methods rarely take into account the interference of noise elements in feature representation, which is detrimental to the final recognition results. To tackle these problems, we propose a novel jointly embedding model, called Joint Discriminative Analysis with Low-Rank Projection (JDA-LRP), to simultaneously extract noise component and salient information from the raw image pixels. Specifically, JDA-LRP decomposes the input image into noise and clean components via low-rank representation and transforms the clean data into a subspace to adaptively learn salient features. To further extract the most representative features, the proposed JDA-LRP enforces the discriminative class-induced constraint of the training samples as well as the sparse constraint of the embedding matrix to aggregate the embedded data of each class in their respective subspace. In this way, the discriminant ability of the jointly embedding model is greatly improved, such that JDA-LRP can be adapted to multiple scenarios. Comprehensive experiments conducted on three commonly used finger vein databases and four palm-based biometric databases illustrate the superiority of our proposed model in recognition accuracy, computational efficiency, and domain adaptation.}
}


@article{DBLP:journals/tifs/GuoTB24,
	author = {Wei Guo and
                  Benedetta Tondi and
                  Mauro Barni},
	title = {Universal Detection of Backdoor Attacks via Density-Based Clustering
                  and Centroids Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {970--984},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3329426},
	doi = {10.1109/TIFS.2023.3329426},
	timestamp = {Fri, 08 Mar 2024 13:21:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GuoTB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a Universal Defence against backdoor attacks based on Clustering and Centroids Analysis (CCA-UD). The goal of the defence is to reveal whether a Deep Neural Network model is subject to a backdoor attack by inspecting the training dataset. CCA-UD first clusters the samples of the training set by means of density-based clustering. Then, it applies a novel strategy to detect the presence of poisoned clusters. The proposed strategy is based on a general misclassification behaviour observed when the features of a representative example of the analysed cluster are added to benign samples. The capability of inducing a misclassification error is a general characteristic of poisoned samples, hence the proposed defence is attack-agnostic. This marks a significant difference with respect to existing defences, that, either can defend against only some types of backdoor attacks, or are effective only when some conditions on the poisoning ratio or the kind of triggering signal used by the attacker are satisfied. Experiments carried out on several classification tasks and network architectures, considering different types of backdoor attacks (with either clean or corrupted labels), and triggering signals, including both global and local triggering signals, as well as sample-specific and source-specific triggers, reveal that the proposed method is very effective to defend against backdoor attacks in all the cases, always outperforming the state of the art techniques.}
}


@article{DBLP:journals/tifs/WangGBJ24,
	author = {Haodi Wang and
                  Yu Guo and
                  Rongfang Bie and
                  Xiaohua Jia},
	title = {Verifiable Arbitrary Queries With Zero Knowledge Confidentiality in
                  Decentralized Storage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1071--1085},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3330305},
	doi = {10.1109/TIFS.2023.3330305},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangGBJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain-based data storage has become an emerging paradigm, providing a fair and transparent data platform for decentralized applications. However, how to achieve secure on-chain verification for arbitrary SQL queries in such a decentralized storage remains under-explored. Due to the limitations of authenticated data structure (ADS), existing works either do not consider arbitrary query verification issue or fail to achieve practical gas consumption efficiency. In this paper, we present a novel arbitrary query verification scheme for decentralized storage. The proposed scheme, named \\mathsf {zkQuery}\n, enables efficient public verification for arbitrary queries with zero-knowledge confidentiality. \\mathsf {zkQuery}\nis built from the ingenious synergy of techniques from both zero-knowledge proof and smart contract technology. The core idea is to delegate smart contracts to fairly execute results verification and utilize our tailored zero-knowledge proof protocol to facilitate arbitrary computation in a privacy-preserving manner. The verification protocols of \\mathsf {zkQuery}\nare highly customized for decentralized storage, where the complexity of on-chain verification can be completed in logarithmic time, significantly decreasing gas consumption. We rigorously provide security analysis and complete the prototype implementation. The extensive experiments over the NEAR blockchain show that \\mathsf {zkQuery}\ncan gain at least 2\\times\nbetter performance than the baseline approach on all metrics.}
}


@article{DBLP:journals/tifs/LuoKHHKK24,
	author = {Anwei Luo and
                  Chenqi Kong and
                  Jiwu Huang and
                  Yongjian Hu and
                  Xiangui Kang and
                  Alex C. Kot},
	title = {Beyond the Prior Forgery Knowledge: Mining Critical Clues for General
                  Face Forgery Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1168--1182},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3332218},
	doi = {10.1109/TIFS.2023.3332218},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LuoKHHKK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face forgery detection is essential in combating malicious digital face attacks. Previous methods mainly rely on prior expert knowledge to capture specific forgery clues, such as noise patterns, blending boundaries, and frequency artifacts. However, these methods tend to get trapped in local optima, resulting in limited robustness and generalization capability. To address these issues, we propose a novel Critical Forgery Mining (CFM) framework, which can be flexibly assembled with various backbones to boost their generalization and robustness performance. Specifically, we first build a fine-grained triplet and suppress specific forgery traces through prior knowledge-agnostic data augmentation. Subsequently, we propose a fine-grained relation learning prototype to mine critical information in forgeries through instance and local similarity-aware losses. Moreover, we design a novel progressive learning controller to guide the model to focus on principal feature components, enabling it to learn critical forgery features in a coarse-to-fine manner. The proposed method achieves state-of-the-art forgery detection performance under various challenging evaluation settings. The source code is available at: https://github.com/LoveSiameseCat/CFM.}
}


@article{DBLP:journals/tifs/ZengLG24,
	author = {Xiao Mei Zeng and
                  Qing Liu and
                  Chee Lip Gan},
	title = {A Comprehensive Data Retrieval and Correction Approach From 40-nm
                  Flash Memory With Selective Chemical Engraving},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1031--1040},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327857},
	doi = {10.1109/TIFS.2023.3327857},
	timestamp = {Tue, 21 May 2024 17:42:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZengLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Floating gate-based flash memory is a widely used storage medium for sensitive data that may be relevant to forensic investigations. For various data extraction techniques, the accuracy of the recovered data is critical to ensuring the integrity of information as forensic evidence. In cases where the devices are physically or digitally damaged, invasive data extraction techniques serve as a last resort, and can directly extract binary from individual memory cells. Here we introduce a new invasive data extraction technique called selective chemical engraving. This electrochemical-based approach could systematically imprint the data of ‘0’ and ‘1’ as cavities on memory surfaces, which can subsequently be imaged with an optical microscope and SEM. This technique is capable of extracting data stored in embedded flash memory in microcontrollers of 40 nm technology node with a high accuracy of 99.66%. The error correction code (ECC) stored in the flash memory was also extracted together with the data. By analysing the extracted ECC, we were able to accurately derive the error correction algorithm of single error correction-double error detection (SEC-DED). The reconstructed SEC-DED code was then used to correct all 0.34% of errors. The high data retrieval accuracy (99.66%) together with the error correction capability led to a 100% accuracy of recovered data. This selective chemical engraving approach offers a comprehensive solution for the lowest-level data retrieval and correction from 40 nm technology flash memory, providing a new avenue for forensic data extraction.}
}


@article{DBLP:journals/tifs/QiHC24,
	author = {Xinyu Qi and
                  Aiqun Hu and
                  Tianshu Chen},
	title = {Lightweight Radio Frequency Fingerprint Identification Scheme for
                  {V2X} Based on Temporal Correlation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1056--1070},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3329683},
	doi = {10.1109/TIFS.2023.3329683},
	timestamp = {Sun, 06 Oct 2024 21:41:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QiHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio frequency fingerprinting identification (RFFI) is a promising physical layer authentication technique based on the inherent hardware defects of transmitters, yet there are bottlenecks in its application to vehicular networks. In this paper, we focus on the concerns of data dependency, channel effects, signal representation, and model efficiency to propose a lightweight RFFI scheme for vehicle-to-everything (V2X) communication based on temporal correlation. Specifically, modified gramian angular filed (MAGF) and Markov probability transition matrix with temporal dependency (MTTD) are proposed for signal representation to mine the temporal information related to device identity in terms of angular variation trajectory and first-order Markov transition probabilities, respectively. Due to the superiority of the proposed signal representation, paired with the customized pre-processing design, a lightweight feature extractor can achieve satisfactory RFFI performance in a very short time. We performed a comprehensive complexity analysis of existing models in the field and validated the proposed scheme using thirteen V2X devices in real wireless environments. In addition, the generalizability of the proposed pre-processing and representation method is demonstrated by testing on different deep learning models.}
}


@article{DBLP:journals/tifs/ChenZLSC24,
	author = {Chen Chen and
                  Junqing Zhang and
                  Tianyu Lu and
                  Magnus Sandell and
                  Liquan Chen},
	title = {Secret Key Generation for IRS-Assisted Multi-Antenna Systems: {A}
                  Machine Learning-Based Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1086--1098},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3331588},
	doi = {10.1109/TIFS.2023.3331588},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenZLSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical-layer key generation (PKG) based on wireless channels is a lightweight technique to establish secure keys between legitimate communication nodes. Recently, intelligent reflecting surfaces (IRSs) have been leveraged to enhance the performance of PKG in terms of secret key rate (SKR), as it can reconfigure the wireless propagation environment and introduce more channel randomness. In this paper, we investigate an IRS-assisted PKG system, taking into account the channel spatial correlation at both the base station (BS) and the IRS. Based on the considered system model, the closed-form expression of SKR is derived analytically considering correlated eavesdropping channels. Aiming to maximize the SKR, a joint design problem of the BS’s precoding matrix and the IRS’s phase shift vector is formulated. To address this high-dimensional non-convex optimization problem, we propose a novel unsupervised deep neural network (DNN)-based algorithm with a simple structure. Different from most previous works that adopt iterative optimization to solve the problem, the proposed DNN-based algorithm directly obtains the BS precoding and IRS phase shifts as the output of the DNN. Simulation results reveal that the proposed DNN-based algorithm outperforms the benchmark methods with regard to SKR.}
}


@article{DBLP:journals/tifs/WangZTY24,
	author = {Weiqi Wang and
                  Chenhan Zhang and
                  Zhiyi Tian and
                  Shui Yu},
	title = {Machine Unlearning via Representation Forgetting With Parameter Self-Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1099--1111},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3331239},
	doi = {10.1109/TIFS.2023.3331239},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangZTY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine unlearning enables data owners to remove the contribution of their specified samples from trained models. However, existing methods fail to strike an optimal balance between erasure effectiveness and model utility preservation. Previous studies focused on removing the impact of user-specified data from the model as much as possible to implement unlearning. These methods usually result in significant model utility degradation, commonly called catastrophic unlearning. To address the issue, we systematically consider machine unlearning and formulate it as a two-objective optimization problem that involves forgetting the erased data and retaining the previously learned knowledge, highlighting accuracy preservation during the unlearning process. We propose an unlearning method called representation-forgetting unlearning with parameter self-sharing (RFU-SS) to achieve the two-objective unlearning goal. Firstly, we design a representation-forgetting unlearning (RFU) method that aims to remove the contribution of specified samples from a trained representation by minimizing the mutual information between the representation and the erased data. The representation is learned using the information bottleneck (IB) method. RFU is tailored to the IB structure models for ease of introduction. Secondly, we customize a parameter self-sharing structural optimization method for RFU (i.e., RFU-SS) to simultaneously optimize the forgetting and retention objectives to find the optimal balance. Extensive experimental results demonstrate a significant effectiveness improvement of RFU-SS over the state-of-the-art methods. RFU-SS almost eliminates catastrophic unlearning, reducing model accuracy degradation from over 6% to less than 0.2% on the MNIST dataset with an even better removal effect. The source code is available at https://github.com/wwq5-code/RFU-SS.git.}
}


@article{DBLP:journals/tifs/HeKYL24,
	author = {Yuewang He and
                  Xiangui Kang and
                  Qiben Yan and
                  Enping Li},
	title = {ResNeXt+: Attention Mechanisms Based on ResNeXt for Malware Detection
                  and Classification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1142--1155},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3328431},
	doi = {10.1109/TIFS.2023.3328431},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HeKYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware detection and classification are crucial for protecting digital devices and information systems. Accurate identification of malware enables researchers and incident responders to take prompt measures against malware and mitigate its damage. With the development of attention mechanisms in the field of computer vision, attention mechanism-based malware detection techniques are also rapidly evolving. The essence of the attention mechanism is to focus on the information of interest and suppress the useless information. In this paper, we develop different plug-and-play attention mechanisms based on the ResNeXt tagging model, where the designed model is trained to focus on the malware features by capturing the malware image channel perception field of view and is also able to provide more helpful and flexible information than other methods. We have named this designed neural network ResNeXt+, and its core modules are built with different plug-and-play attention mechanisms. Extensive experimental results show that ResNeXt+ is effective and efficient in malware detection and classification with high classification accuracy. The proposed methods outperform the state-of-the-art techniques with seven benchmark datasets. Cross-dataset experiments conducted on the Windows and Android datasets, with an accuracy of 90.64% on cross-dataset detection of the android. Ablation experiments are also conducted on seven datasets, which demonstrate that attention mechanisms can improve malware detection and classification accuracy.}
}


@article{DBLP:journals/tifs/WongHGSC24,
	author = {Guo{-}Wei Wong and
                  Yi{-}Ting Huang and
                  Ying{-}Ren Guo and
                  Yeali S. Sun and
                  Meng Chang Chen},
	title = {Attention-Based {API} Locating for Malware Techniques},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1199--1212},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3330337},
	doi = {10.1109/TIFS.2023.3330337},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WongHGSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents APILI, an innovative approach to behavior-based malware analysis that utilizes deep learning to locate the API calls corresponding to discovered malware techniques in dynamic execution traces. APILI defines multiple attentions between API calls, resources, and techniques, incorporating MITRE ATT&CK framework, adversary tactics, techniques and procedures, through a neural network. We employ fine-tuned BERT for arguments/resources embedding, SVD for technique representation, and several design enhancements, including layer structure and noise addition, to improve the locating performance. To the best of our knowledge, this is the first attempt to locate low-level API calls that correspond to high-level malicious behaviors (that is, techniques). Our evaluation demonstrates that APILI outperforms other traditional and machine learning techniques in both technique discovery and API locating. These results indicate the promising performance of APILI, thus allowing it to reduce the analysis workload.}
}


@article{DBLP:journals/tifs/WangCMHWJ24,
	author = {Mingyue Wang and
                  Zizhuo Chen and
                  Yinbin Miao and
                  Hejiao Huang and
                  Cong Wang and
                  Xiaohua Jia},
	title = {Cross-User Leakage Mitigation for Authorized Multi-User Encrypted
                  Data Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1213--1226},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3333244},
	doi = {10.1109/TIFS.2023.3333244},
	timestamp = {Tue, 07 May 2024 20:18:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangCMHWJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud computing has been a research focus in both academic and industrial communities for decades. Along with this trend, Searchable Encryption (SE) technology emerged and developed as data privacy concerns increased. Many schemes are proposed to solve the privacy-preserving data-sharing problem in multi-user scenarios. Most existing solutions are based on the assumption that all users are trusted. However, there will be cross-user leakage when there are malicious or compromised ones. This is because of the inherent linkability of authorization information and the search result when multiple users request data from the same database. To this end, we propose a cross-user leakage mitigation scheme for authorized encrypted data sharing in a two-server model. We utilize a blinding factor to delink authorizations based on Symmetric Multi-Key Searchable Encryption (SMKSE). To break the linkability of query results, we combine the zero-sum garbled Bloom filter with the oblivious transfer technique, where each of the two servers can only know partial information. We devise a group-based Bloom filter structure in indices to improve efficiency. We perform formal security analysis and also demonstrate the efficiency through comparative experiments.}
}


@article{DBLP:journals/tifs/ZhaoXWK24,
	author = {Shao{-}Chuan Zhao and
                  Tianyang Xu and
                  Xiaojun Wu and
                  Josef Kittler},
	title = {Pluggable Attack for Visual Object Tracking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1227--1240},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3331899},
	doi = {10.1109/TIFS.2023.3331899},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoXWK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Performing adversarial attacks on a visual tracker aims to drift the apparent target to the background by adding malicious perturbations to the source images. Demonstrating convincingly their ability to decrease accuracy, existing tracking attackers mislead the target predictions at the decision level, but this is tracker design specific, narrowing their applicability to other tracking approaches. In contrast, we advocate that attacks be performed by corrupting the feature-level clues, i.e., the feature representations extracted by deep networks. The proposed approach provides a general attacking framework for backbone-head tracking architectures. Motivated by the knowledge that the quality of intermediate-level features strongly influences the decision making, four intermediate-level attack methods are proposed to maximise the difference between the feature distributions of natural and adversarial samples, thus decoupling the attack strategies from the form of the output of specific victim trackers. Interestingly, our intermediate-level attacks are compatible with existing decision-level attacks, thus a joint optimisation of these two kinds of adversarial objective functions has the potential to achieve better attacking performance. Hence, the proposed adversarial attack methodology can be used in conjunction with several mainstream tracking paradigms (Discriminative correlation filters, Siamese networks, and Transformer trackers), demonstrating its pluggability. The experimental results on four popular benchmarks, e.g., OTB100, UAV123, LaSOT, and TLP, verify that our method can produce impressive and consistent accuracy degeneration.}
}


@article{DBLP:journals/tifs/ZhanLLZLW24,
	author = {Mengqi Zhan and
                  Yang Li and
                  Bo Li and
                  Jinchao Zhang and
                  Chuanrong Li and
                  Weiping Wang},
	title = {Toward Automated Field Semantics Inference for Binary Protocol Reverse
                  Engineering},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {764--776},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3326666},
	doi = {10.1109/TIFS.2023.3326666},
	timestamp = {Fri, 17 Jan 2025 11:21:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhanLLZLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network protocol reverse engineering is the basis for many security applications. A common class of protocol reverse engineering methods is based on the analysis of network message traces. After performing message field identification by segmenting messages into multiple fields, a key task is to infer the semantics of the fields. One of the limitations of existing field semantics inference methods is that they usually infer semantics for only a few fields and often require a lot of manual effort. In this paper, we propose an automated field semantics inference method for binary protocol reverse engineering (FSIBP). FSIBP aims to automatically learn semantics inference knowledge from known protocols and use it to infer the semantics of any field of an unknown protocol. To achieve this goal, we design a feature extraction method that can extract features of the field itself and of the field context. We also propose a semantic category aggregation method that abstracts the fine-grained semantics of all fields of known protocols into aggregated semantic categories. Moreover, we make FSIBP infer semantics based on the similarity of fields to semantic categories. The above design enables FSIBP to utilize the semantic knowledge of all fields of known protocols and infer the semantics of any fields of unknown protocols. The whole process of FSIBP does not require any expert knowledge or manual parameter setting. We conduct extensive experiments to demonstrate the effectiveness of FSIBP. Moreover, we find a utility for FSIBP besides field semantics inference, its output can help to detect the mis-segmented fields generated during the message field identification.}
}


@article{DBLP:journals/tifs/CasulaOMGMS24,
	author = {Roberto Casula and
                  Giulia Orr{\`{u}} and
                  Stefano Marrone and
                  Umberto Gagliardini and
                  Gian Luca Marcialis and
                  Carlo Sansone},
	title = {Realistic Fingerprint Presentation Attacks Based on an Adversarial
                  Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {863--877},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327663},
	doi = {10.1109/TIFS.2023.3327663},
	timestamp = {Fri, 08 Mar 2024 13:21:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CasulaOMGMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern Fingerprint Presentation Attack Detection (FPAD) modules have been particularly successful in avoiding attacks exploiting artificial fingerprint replicas against Automated Fingerprint Identification Systems (AFISs). As for several other domains, Machine and Deep Learning strongly contributed to this success, with all recent state-of-the-art detectors leveraging learning-based approaches. An insidious flip side is represented by adversarial attacks, namely, procedures intended to mislead a target detector. Indeed, despite this type of attack has been considered unrealistic, as it presupposes access to the communication channel between the sensor and the detector, in a recent work, we have highlighted the possibility of transferring a fingerprint adversarial attack from the digital domain to the physical one. In this work, we take a step further by introducing a new procedure designed to make the physical adversarial presentation attack i) more robust to the physical crafting of the PAI by exploiting explainability techniques, ii) easier to adapt to different fingerprint scanners and adversarial algorithms, and iii) usable in a black-box scenario. To quantify the impact of these novel adversarial presentation attacks family, designed to be robust to the physical crafting process, we assess the performance of both state-of-the-art PAD modules alone and integrated AFISs. Results highlight the approach’s feasibility, opening a new series of threats in the context of fingerprint PAD.}
}


@article{DBLP:journals/tifs/LaiZFZZ24,
	author = {Yuni Lai and
                  Yulin Zhu and
                  Wenqi Fan and
                  Xiaoge Zhang and
                  Kai Zhou},
	title = {Toward Adversarially Robust Recommendation From Adaptive Fraudster
                  Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {907--919},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327876},
	doi = {10.1109/TIFS.2023.3327876},
	timestamp = {Mon, 22 Jan 2024 12:10:32 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LaiZFZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The robustness of recommender systems under node injection attacks has garnered significant attention. Recently, GraphRfi, a Graph-Neural-Network-based (GNN-based) recommender system, was proposed and shown to effectively mitigate the impact of injected fake users. However, we demonstrate that GraphRfi remains vulnerable to attacks due to the supervised nature of its fraudster detection component, where obtaining clean labels is challenging in practice. In particular, we propose a powerful poisoning attack, MetaC, against both GNN-based and Martix-Faxtorization-based recommender systems. Furthermore, we analyze why GraphRfi fails under such an attack. Then, based on our insights obtained from vulnerability analysis, we design an adaptive fraudster detection module that explicitly considers label uncertainty. This module can serve as a plug-in for different recommender systems, resulting in a robust framework named Posterior-Detection Recommender (PDR). Comprehensive experiments show that our defense approach outperforms other benchmark methods under attacks. Overall, our research presents an effective framework for integrating fraudster detection into recommendation systems to achieve adversarial robustness.}
}


@article{DBLP:journals/tifs/XuYCYLW24,
	author = {Peng Xu and
                  Jun Yang and
                  Gaojie Chen and
                  Zheng Yang and
                  Yong Li and
                  Moe Z. Win},
	title = {Physical-Layer Secret and Private Key Generation in Wireless Relay
                  Networks With Correlated Eavesdropping Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {985--1000},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3329740},
	doi = {10.1109/TIFS.2023.3329740},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XuYCYLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the performance of key generation between two nodes assisted by a relay in the presence of correlated eavesdropping channels. A cooperative jamming scheme is utilized to impose superimposed channel measurements on the relay and eavesdropper. Both lower and upper bounds on key capacities for both secret key (SK) and private key (PK) generation are evaluated, where the lower bounds are derived by using minimum mean square error and zero forcing methods for channel estimation, and the upper bounds are derived by formulating several enhanced discrete memoryless source (DMS) models. The analytical expressions are further simplified in the high signal-to-noise ratio (SNR) regime. We discover that one of the two legitimate channels should specialize in playing a role of jamming the relay or eavesdropper. We also demonstrate that the derived lower and upper bounds are tight when the eavesdropping channels are lowly or highly correlated. When the eavesdropping channels are uncorrelated, the SK and PK capacities can be determined since the corresponding upper and lower bounds are equal. Moreover, at high SNRs, a constant gap exists between the SK/PK upper and lower bounds as the correlation coefficient becomes one.}
}


@article{DBLP:journals/tifs/MaoJZ24,
	author = {Wenze Mao and
                  Peng Jiang and
                  Liehuang Zhu},
	title = {Locally Verifiable Batch Authentication in IoMT},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1001--1014},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3330577},
	doi = {10.1109/TIFS.2023.3330577},
	timestamp = {Wed, 04 Sep 2024 21:09:35 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MaoJZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Medical Things (IoMT) technology has gained a lot of attention. In the IoMT system, IoT devices collect and upload patient data through sensors, and doctors treat them remotely. In this process, doctors need to verify the correctness of the patient’s body data in bulk, a function that requires aggregated signature technology to achieve. However, due to the limitation that traditional verification of aggregated signatures requires access to all messages, doctors cannot efficiently verify the correctness of a particular piece of data. This will result in a significant additional verification overhead. Therefore, the efficiency problem of data batch authentication remains unsolved but imperative. In this paper, we propose an identity-based locally verifiable aggregated signature, (ID-LVEAS), that enables efficient local verification of patient data in IoMT. Building on top of both hybrid hash and inverse framework, we instantiate an ID-LVEAS scheme and prove its security in the EU-CMA security model. Based on ID-LVEAS, we further propose ID-based locally verifiable signcryption (ID-LVASC) that supports both confidentiality and integrity. We also present an instantiation and an application into IoMT from the proposed ID-LVASC. We conduct extensive experiments on the ID-LVEAS and ID-LVASC design. The results show that both cost constantly 0.01s for the verification, independent of the number of messages, which means our research has great promise for application in IoMT.}
}


@article{DBLP:journals/tifs/WangYZWSS24,
	author = {Taiyu Wang and
                  Qinglin Yang and
                  Kaiming Zhu and
                  Junbo Wang and
                  Chunhua Su and
                  Kento Sato},
	title = {{LDS-FL:} Loss Differential Strategy Based Federated Learning for
                  Privacy Preserving},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1015--1030},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3322328},
	doi = {10.1109/TIFS.2023.3322328},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangYZWSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has attracted extraordinary attention from the industry and academia due to its advantages in privacy protection and collaboratively training on isolated datasets. Since machine learning algorithms usually try to find an optimal hypothesis to fit the training data, attackers also can exploit the shared models and reversely analyze users’ private information. However, there is still no good solution to solve the privacy-accuracy trade-off, by making information leakage more difficult and meanwhile can guarantee the convergence of learning. In this work, we propose a Loss Differential Strategy (LDS) for parameter replacement in FL. The key idea of our strategy is to maintain the performance of the Private Model to be preserved through parameter replacement with multi-user participation, while the efficiency of privacy attacks on the model can be significantly reduced. To evaluate the proposed method, we have conducted comprehensive experiments on four typical machine learning datasets to defend against membership inference attack. For example, the accuracy on MNIST is near 99%, while it can reduce the accuracy of attack by 10.1% compared with FedAvg. Compared with other traditional privacy protection mechanisms, our method also outperforms them in terms of accuracy and privacy preserving.}
}


@article{DBLP:journals/tifs/MalhotraVSMN24,
	author = {Aakarsh Malhotra and
                  Mayank Vatsa and
                  Richa Singh and
                  Keith B. Morris and
                  Afzel Noore},
	title = {Multi-Surface Multi-Technique {(MUST)} Latent Fingerprint Database},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1041--1055},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3280742},
	doi = {10.1109/TIFS.2023.3280742},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MalhotraVSMN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Latent fingerprint recognition involves acquisition and comparison of latent fingerprints with an exemplar gallery of fingerprints. The diversity in the type of surface leads to different procedures to recover the latent fingerprint. The appearance of latent fingerprints vary significantly due to the development techniques, leading to large intra-class variation. Due to lack of large datasets acquired using multiple mechanisms and surfaces, existing algorithms for latent fingerprint enhancement and comparison may perform poorly. In this study, we propose a Multi-Surface Multi-Technique (MUST) Latent Fingerprint Database. The database consists of more than 16,000 latent fingerprint impressions from 120 unique classes (120 fingers from 12 participants). Including corresponding exemplar fingerprints (livescan and rolled) and extended gallery, the dataset has nearly 21,000 impressions. It has latent fingerprints acquired under 35 different scenarios and additional four subsets of exemplar prints captured using live scan sensor and inked-rolled prints. With 39 different subsets, the database illustrates intra-class variations in latent fingerprints. The database has a potential usage towards building robust algorithms for latent fingerprint enhancement, segmentation, comparison, and multi-task learning. We also provide annotations for manually marked minutiae, acquisition Pixel Per Inch (PPI), and semantic segmentation masks. We also present the experimental protocol and the baseline results for the proposed dataset. The availability of the proposed database can encourage research in handling intra-class variation in latent fingerprint recognition.}
}


@article{DBLP:journals/tifs/FengXZWZ24,
	author = {Weiwei Feng and
                  Nanqing Xu and
                  Tianzhu Zhang and
                  Baoyuan Wu and
                  Yongdong Zhang},
	title = {Robust and Generalized Physical Adversarial Attacks via Meta-GAN},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1112--1125},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3288426},
	doi = {10.1109/TIFS.2023.3288426},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FengXZWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks are known to be vulnerable to adversarial examples, where adding carefully crafted adversarial perturbations to the inputs can mislead the DNN model. However, it is challenging to generate effective adversarial examples in the physical world due to many uncontrollable physical dynamics, which pose security and safety threats in the real world. Current physical attack methods aim to generate robust physical adversarial examples by simulating all possible physical dynamics. If attacking a new image or a new DNN model, they require expensive manual efforts for simulating physical dynamics or considerable time for iteratively optimizing. To tackle these limitations, we propose a robust and generalized physical adversarial attack method with Meta-GAN (Meta-GAN Attack), which is able to not only generate robust physical adversarial examples, but also generalize to attacking novel images and novel DNN models by accessing a few digital and physical images. First, we propose to craft robust physical adversarial examples with a generative attack model via simulating color and shape distortions. Second, we formulate the physical attack as a few-shot learning problem and design a novel class-agnostic and model-agnostic meta-learning algorithm to solve this problem. Extensive experiments on two benchmark datasets with four challenging experimental settings verify the superior robustness and generalization of our method by comparing to state-of-the-art physical attack methods. The source code is released at github.}
}


@article{DBLP:journals/tifs/ChatterjeePHRM24,
	author = {Durba Chatterjee and
                  Kuheli Pratihar and
                  Aritra Hazra and
                  Ulrich R{\"{u}}hrmair and
                  Debdeep Mukhopadhyay},
	title = {Systematically Quantifying Cryptanalytic Nonlinearities in Strong
                  PUFs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1126--1141},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3329438},
	doi = {10.1109/TIFS.2023.3329438},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChatterjeePHRM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physically Unclonable Functions (PUFs) with large challenge space (also called Strong PUFs) are promoted for usage in authentications and various other cryptographic and security applications. In order to qualify for these cryptographic applications, the Boolean functions realized by PUFs need to possess a high nonlinearity (NL). However, with a large challenge space (usually \\geq 64\nbits), measuring NL by classical techniques like the Walsh transformation is computationally infeasible. In this paper, we propose the usage of a heuristic-based measure called the non-homomorphicity test which estimates the cryptographic NL of Boolean functions with high accuracy in spite of not needing access to the entire challenge-response set. We also combine our analysis with a technique used in linear cryptanalysis, called Piling-up lemma, to measure the NL of popular PUF compositions. As a demonstration to justify the soundness of the metric, we perform extensive experimentation by first estimating the NL of constituent Arbiter/Bistable Ring PUFs using the non-homomorphicity test, and then applying them to quantify the same for their XOR compositions namely XOR Arbiter PUFs and XOR Bistable Ring PUF. Our findings show that the metric explains the impact of various parameter choices of these PUF compositions on the NL obtained and thus promises to be used as an important objective criterion for future efforts to evaluate PUF designs. While the framework is not representative of the machine learning robustness of PUFs, it can be a useful complementary tool to analyze the cryptanalytic strengths of PUF primitives.}
}


@article{DBLP:journals/tifs/DingSHSC24,
	author = {Hongwei Ding and
                  Yu Sun and
                  Nana Huang and
                  Zhidong Shen and
                  Xiaohui Cui},
	title = {{TMG-GAN:} Generative Adversarial Networks-Based Imbalanced Learning
                  for Network Intrusion Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1156--1167},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3331240},
	doi = {10.1109/TIFS.2023.3331240},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DingSHSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) devices are large in number, widely distributed, weak in protection ability, and vulnerable to various malicious attacks. Intrusion detection technology can provide good protection for network equipment. However, the normal traffic and abnormal traffic in the network are usually imbalanced. Imbalanced samples will seriously affect the performance of machine learning detection algorithm. Therefore, this paper proposes an intrusion detection method based on data augmentation, namely TMG-IDS. We name the proposed data augmentation model TMG-GAN, which is a data augmentation method based on generative adversarial networks (GAN). First, TMG-GAN has a multi-generator structure, which can be used to generate different types of attack data simultaneously. Second, we increase the classifier structure, which can optimize the generator and discriminator more efficiently based on the classification loss. Third, we calculate the cosine similarity between the generated samples and the original samples and other types of generated samples as a generator loss, which can further improve the quality of generated samples and reduce the class overlap area between the distributions of various generated samples. We conduct extensive experiments on two intrusion detection datasets, CICIDS2017 and UNSW-NB15. The experimental results show that compared with the advanced oversampling algorithm and the latest intrusion detection algorithm, the proposed TMG-IDS method has a good detection effect under the three indicators of Precision, Recall and F1-score.}
}


@article{DBLP:journals/tifs/ZhanDHLGP24,
	author = {Dazhi Zhan and
                  Yexin Duan and
                  Yue Hu and
                  Weili Li and
                  Shize Guo and
                  Zhisong Pan},
	title = {MalPatch: Evading DNN-Based Malware Detection With Adversarial Patches},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1183--1198},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3333567},
	doi = {10.1109/TIFS.2023.3333567},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhanDHLGP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Static analysis is a crucial protection layer that enables modern antivirus systems to address the rampant proliferation of malware. These systems are increasingly relying on deep neural networks (DNNs) to automatically extract reliable features and achieve outstanding detection accuracy. Since DNNs are known to be vulnerable to adversarial examples, several studies have proposed practical evasion attacks to generate adversarial perturbations that can evade malware detectors. These attacks, however, require specific designs for the given input sample, prohibiting them from large-scale deployment. Therefore, it is more practical to generate sample-agnostic perturbations that do not involve recalculations regardless of the input malware sample. To this end, we leverage an adversarial patch attack, which is a special type of adversarial attack that dose not know the sample being modified during the attack construction process. In particular, we propose a new adversarial attack against malware detection systems called MalPatch. It locates the nonfunctional part of malware for adversarial patch injection to protect its executability while generating adversarial examples based on different strategies. The generated patch can be injected into any malware sample, fooling the detector into classifying it as benign. Experimental results demonstrate that MalPatch is effective under different attack settings. In the white-box setting, MalPatch achieves 69%-78% success rates against DNN detectors based on raw byte features and 47%-96% success rates against four grayscale detectors based on image features. In the black-box setting, the success rates of MalPatch against the same models reach 54%-74% and 27%-42%, respectively. We conclude by discussing several of its potential countermeasures and the generality of our approach.}
}


@article{DBLP:journals/tifs/ChenLPLCJ24,
	author = {Yuanchao Chen and
                  Yuwei Li and
                  Zulie Pan and
                  Yuliang Lu and
                  Juxing Chen and
                  Shouling Ji},
	title = {URadar: Discovering Unrestricted File Upload Vulnerabilities via Adaptive
                  Dynamic Testing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1251--1266},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3335885},
	doi = {10.1109/TIFS.2023.3335885},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenLPLCJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unrestricted file upload (UFU) vulnerabilities, especially unrestricted executable file upload (UEFU) vulnerabilities, pose severe security risks to web servers. For instance, attackers can leverage such vulnerabilities to execute arbitrary code to gain the control of a whole web server. Therefore, it is significant to develop effective and efficient methods to detect UFU and UEFU vulnerabilities. Towards this, most state-of-the-art methods are designed based on dynamic testing. Nevertheless, they still entail two critical limitations. 1) They heavily rely on manual efforts, which are error-prone and have poor adaptability. 2) They seldom leverage effective information to guide the testing, resulting in generating a large number of invalid test cases. Such limitations severely hinder the performance of UFU vulnerability detection. In this paper, we propose URadar, an adaptive dynamic testing-based method for detecting UFU and UEFU vulnerabilities. There are three core designs in URadar, including file upload interface identification, file type restriction inference, and invalid mutation combination filtration, which can effectively solve the two limitations of existing methods. To evaluate the performance of URadar, we conduct extensive experiments and compare URadar with state-of-the-art methods (e.g., FUSE, RIPS). In testing 18 web applications, URadar discovers 26 UEFU vulnerabilities, where 8 are new, and 6 have been assigned new CVE/CNNVD IDs. By contrast, FUSE and RIPS find 14 and 2 UEFU vulnerabilities, respectively. To discover the same number of UFU vulnerabilities, FUSE needs to send 73,261 request packets with a time cost of 2,791.1s on average, 23.43 and 20.53 times of the requirements for URadar. The above results demonstrate that URadar significantly outperforms the state-of-the-art methods. In addition, we have open-sourced URadar to facilitate future research on UFU vulnerability detection.}
}


@article{DBLP:journals/tifs/ChenLCZH24,
	author = {Changsheng Chen and
                  Bokang Li and
                  Rizhao Cai and
                  Jishen Zeng and
                  Jiwu Huang},
	title = {Distortion Model-Based Spectral Augmentation for Generalized Recaptured
                  Document Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1283--1298},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3333548},
	doi = {10.1109/TIFS.2023.3333548},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenLCZH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Document recapturing is a presentation attack that covers the forensic traces in the digital domain. Document presentation attack detection (DPAD) is an important step in the document authentication pipeline. Existing DPAD methods suffer from low generalization performance under the cross-domain scenario with different types of documents. Data augmentation is a de facto technique to reduce the risk of overfitting the training data and improve the generalizability of a trained model. In this work, we improve the generalization performance of DPAD approaches by addressing two important limitations of the existing frequency domain augmentation (FDA) methods. First, contrary to the existing FDA methods that treat different spectral bands equally, we establish a band-of-interest localization (BOIL) method that locates the spectral band-of-interest (BOI) related to the recapturing operation by domain knowledge from the theoretical distortion models. Second, we propose a frequency-domain halftoning augmentation (FHAG) strategy that enhances the halftoning features in the BOI with considerations of different halftoning distortions. To evaluate the generalization performance of our FHAG with BOIL method on different types of document images, we have constructed a diverse recaptured document image dataset with 162 types of documents (RDID162), consisting of 5346 samples. The proposed method has been evaluated on the generic deep learning models and a state-of-the-art DPAD approach under both cross-device and cross-domain protocols for the DPAD task. Compared to the existing FDA methods, our method has improved the models with ResNet50 backbone by reducing more than 25% or 5 percentage points in EERs. The source code and data in this work is available at https://github.com/chenlewis/FHAG-with-BOIL.}
}


@article{DBLP:journals/tifs/GongGGGSWC24,
	author = {Bei Gong and
                  Chong Guo and
                  Chong Guo and
                  Chen Guo and
                  Yao Sun and
                  Muhammad Waqas and
                  Sheng Chen},
	title = {{SLIM:} {A} Secure and Lightweight Multi-Authority Attribute-Based
                  Signcryption Scheme for IoT},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1299--1312},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3331566},
	doi = {10.1109/TIFS.2023.3331566},
	timestamp = {Mon, 11 Dec 2023 16:08:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GongGGGSWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although attribute-based signcryption (ABSC) offers a promising technology to ensure the security of IoT data sharing, it faces a two-fold challenge in practical implementation, namely, the linearly increasing computation and communication costs and the heavy load of single authority based key management. To this end, we propose a Secure and Lightweight Multi-authority ABSC scheme called SLIM in this paper. The signcryption and de-signcryption costs of devices are reduced to a small constant by offloading most of the computation to the edge server. To minimize communication and storage costs, a short and constant-size ciphertext is designed. Moreover, we adopt a hierarchical multi-authority architecture, setting up multiple attribute authorities that manage keys independently to prevent the bottleneck. Rigorous security analysis proves that the SLIM scheme can resist adaptive chosen ciphertext attacks and adaptive chosen message attacks under the standard model. Simulation experiments demonstrate the correctness of our theoretical derivations and the cost reduction of the SLIM scheme in computation, communication and storage.}
}


@article{DBLP:journals/tifs/DuLZDS24,
	author = {Yunhao Du and
                  Cheng Lei and
                  Zhicheng Zhao and
                  Yuan Dong and
                  Fei Su},
	title = {Video-Based Visible-Infrared Person Re-Identification With Auxiliary
                  Samples},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1313--1325},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3337972},
	doi = {10.1109/TIFS.2023.3337972},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DuLZDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visible-infrared person re-identification (VI-ReID) aims to match persons captured by visible and infrared cameras, allowing person retrieval and tracking in 24-hour surveillance systems. Previous methods focus on learning from cross-modality person images in different cameras. However, temporal information and single-camera samples tend to be neglected. To crack this nut, in this paper, we first contribute a large-scale VI-ReID dataset named BUPTCampus. Different from most existing VI-ReID datasets, it 1) collects tracklets instead of images to introduce rich temporal information, 2) contains pixel-aligned cross-modality sample pairs for better modality-invariant learning, 3) provides one auxiliary set to help enhance the optimization, in which each identity only appears in a single camera. Based on our constructed dataset, we present a two-stream framework as baseline and apply Generative Adversarial Network (GAN) to narrow the gap between the two modalities. To exploit the advantages introduced by the auxiliary set, we propose a curriculum learning based strategy to jointly learn from both primary and auxiliary sets. Moreover, we design a novel temporal k-reciprocal re-ranking method to refine the ranking list with fine-grained temporal correlation cues. Experimental results demonstrate the effectiveness of the proposed methods. We also reproduce 9 state-of-the-art image-based and video-based VI-ReID methods on BUPTCampus and our methods show substantial superiority to them. The codes and dataset are available at: https://github.com/dyhBUPT/BUPTCampus.}
}


@article{DBLP:journals/tifs/ZoisTK24,
	author = {Elias N. Zois and
                  Dimitrios Tsourounis and
                  Dimitrios Kalivas},
	title = {Similarity Distance Learning on {SPD} Manifold for Writer Independent
                  Offline Signature Verification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1342--1356},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3333681},
	doi = {10.1109/TIFS.2023.3333681},
	timestamp = {Sun, 31 Dec 2023 19:06:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZoisTK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identifying the existence or approval of a human in a number of past, recent and present day activities with the use of a handwritten signature is a captivating biometric challenge. Several engineering branches such as computer vision, pattern recognition and quite recently data-driven machine learning algorithms are combined in a multi-disciplined signature verification framework in order to deliver an equivalent and efficient e-assistance to manually executed duties, which usually demand knowledge and skills. In this work, we propose, for the first time, the use of a learnable Symmetric Positive Definite manifold distance framework in offline signature verification literature in order to build a global writer-independent signature verification classifier. The key building block of the framework relies on the use of regional covariance matrices of handwritten signature images as visual descriptors, which maps them into the Symmetric Positive Definite manifold. The learning and verification protocol explores both blind intra and blind inter transfer learning frameworks with the use of four popular signature datasets of Western and Asian origin. Experiments strongly indicate that the learnable SPD manifold similarity distance can be highly efficient for offline writer independent signature verification.}
}


@article{DBLP:journals/tifs/GongSZZWBX24,
	author = {Zirui Gong and
                  Liyue Shen and
                  Yanjun Zhang and
                  Leo Yu Zhang and
                  Jingwei Wang and
                  Guangdong Bai and
                  Yong Xiang},
	title = {AgrAmplifier: Defending Federated Learning Against Poisoning Attacks
                  Through Local Update Amplification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1241--1250},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3333555},
	doi = {10.1109/TIFS.2023.3333555},
	timestamp = {Mon, 03 Mar 2025 22:25:01 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GongSZZWBX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The collaborative nature of federated learning (FL) poses a major threat in the form of manipulation of local training data and local updates, known as the Byzantine poisoning attack. To address this issue, many Byzantine-robust aggregation rules (AGRs) have been proposed to filter out or moderate suspicious local updates uploaded by Byzantine participants. This paper introduces a novel approach called AGRAMPLIFIER, aiming to simultaneously improve robustness, fidelity, and efficiency of the existing AGRs. The core idea of AGRAMPLIFIER is to amplify the “morality” of local updates by identifying the most repressive features of each gradient update, which provides a clearer distinction between malicious and benign updates, consequently improving the detection effect. To achieve this objective, two approaches, namely AGRMP and AGRXAI, are proposed. AGRMP organizes local updates into patches and extracts the largest value from each patch, while AGRXAI leverages explainable AI methods to extract the gradient of the most activated features. By equipping AGRAMPLIFIER with the existing Byzantine-robust mechanisms, we successfully enhance the model robustness, maintaining its fidelity and improving overall efficiency. AGRAMPLIFIER is universally compatible with the existing Byzantine-robust mechanisms. The paper demonstrates its effectiveness by integrating it with all mainstream AGR mechanisms. Extensive evaluations conducted on seven datasets from diverse domains against seven representative poisoning attacks consistently show enhancements in robustness, fidelity, and efficiency, with average gains of 40.08%, 39.18%, and 10.68%, respectively.}
}


@article{DBLP:journals/tifs/GaoBWYX24,
	author = {Kuofeng Gao and
                  Jiawang Bai and
                  Baoyuan Wu and
                  Mengxi Ya and
                  Shu{-}Tao Xia},
	title = {Imperceptible and Robust Backdoor Attack in 3D Point Cloud},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1267--1282},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3333687},
	doi = {10.1109/TIFS.2023.3333687},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GaoBWYX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the thriving of deep learning in processing point cloud data, recent works show that backdoor attacks pose a severe security threat to 3D vision applications. The attacker injects the backdoor into the 3D model by poisoning a few training samples with trigger, such that the backdoored model performs well on clean samples but behaves maliciously when the trigger pattern appears. Existing attacks often insert some additional points into the point cloud as the trigger, or utilize a linear transformation (e.g., rotation) to construct the poisoned point cloud. However, the effects of these poisoned samples are likely to be weakened or even eliminated by some commonly used pre-processing techniques for 3D point cloud, e.g., outlier removal or rotation augmentation. In this paper, we propose a novel imperceptible and robust backdoor attack (IRBA) to tackle this challenge. We utilize a nonlinear and local transformation, called weighted local transformation (WLT), to construct poisoned samples with unique transformations. As there are several hyper-parameters and randomness in WLT, it is difficult to produce two similar transformations. Consequently, poisoned samples with unique transformations are likely to be resistant to aforementioned pre-processing techniques. Besides, the distortion caused by a fixed WLT is both controllable and smooth, resulting in the generated poisoned samples that are imperceptible to human inspection. Extensive experiments on three benchmark datasets and four models show that IRBA achieves 80\\%+ attack success rate (ASR) in most cases even with pre-processing techniques, which is significantly higher than previous state-of-the-art attacks. Our code is available at https://github.com/KuofengGao/IRBA.}
}


@article{DBLP:journals/tifs/LiWZZL24,
	author = {Zhi Li and
                  Hao Wang and
                  Songnian Zhang and
                  Wenying Zhang and
                  Rongxing Lu},
	title = {SecKNN: FSS-Based Secure Multi-Party {KNN} Classification Under General
                  Distance Functions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1326--1341},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3337940},
	doi = {10.1109/TIFS.2023.3337940},
	timestamp = {Thu, 20 Feb 2025 19:07:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiWZZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a practical machine learning method, the K-nearest neighbors (KNN) classification has received widespread attention. The achievement of the KNN classification relies heavily on a large amount of labeled data. However, in the real world, data is often held by different data owners. How to realize efficient joint computing among multiple data owners under the premise of protecting data security and privacy is an urgent problem to be solved. In this paper, we construct a secure multi-party KNN classification scheme (SecKNN) based on function secret sharing (FSS) technology, which is a novel cryptographic primitive and can achieve cheap communication and computation costs for secure computation. Compared with the existing works, our scheme dramatically reduces computational overhead and runs roughly 50.8 times faster than the state-of-the-art approach. Furthermore, our scheme supports the secure KNN classification under general distance functions such as Euclidean distance, Manhattan distance, and Hamming distance. To implement our SecKNN scheme, we design two efficient FSS schemes for Hamming distance function, which implements secure two-party and multi-party Hamming distance computation in a single round. They can be considered as independent research results. Finally, we give formal security proofs for the proposed protocols and validate the effectiveness and efficiency of our protocols through experiments.}
}


@article{DBLP:journals/tifs/GongZZW24,
	author = {Jiajun Gong and
                  Wuqi Zhang and
                  Charles Zhang and
                  Tao Wang},
	title = {WFDefProxy: Real World Implementation and Evaluation of Website Fingerprinting
                  Defenses},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1357--1371},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3327662},
	doi = {10.1109/TIFS.2023.3327662},
	timestamp = {Wed, 10 Apr 2024 21:01:57 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GongZZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tor, an onion-routing anonymity network, can be attacked by Website Fingerprinting (WF), which de-anonymizes encrypted web browsing traffic by analyzing its unique sequence characteristics. Although many defenses have been proposed, few have been implemented and tested in the real world; most state-of-the-art defenses were only simulated. Simulations fail to capture the real performance of these defenses as they make simplifying assumptions about the protocol stack and network conditions. To allow WF defenses to be analyzed as real implementations, we create WFDefProxy, the first general platform for WF defense implementation on Tor as pluggable transports. We implement three state-of-the-art WF defenses: FRONT, Tamaraw, and RegulaTor. We evaluate each defense extensively by directly collecting defended datasets under WFDefProxy. Our results show that simulation can be inaccurate in many cases. Specifically, Tamaraw’s time overhead was underestimated by 22% in one setting and overestimated by 24% in another. RegulaTor’s time overhead was underestimated by 30–40%. We find that a major source of simulation inaccuracy is that they cannot incorporate how packets depend on each other. We also find that adverse network conditions (which are ignored in simulation), especially congestion, can affect the evaluated overhead of defenses. These results show that it is important to evaluate defenses as implementations instead of only simulations to avoid errors in evaluation.}
}


@article{DBLP:journals/tifs/SongSZLX24,
	author = {Qige Song and
                  Yafei Sang and
                  Yongzheng Zhang and
                  Shuhao Li and
                  Xiaolin Xu},
	title = {SepBIN: Binary Feature Separation for Better Semantic Comparison and
                  Authorship Verification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1372--1387},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3331895},
	doi = {10.1109/TIFS.2023.3331895},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SongSZLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Binary semantic comparison and authorship verification are critical in many security applications. They respectively focus on the functional semantic features and developers’ programming style features of binary code, which are usually mixed without clear demarcation. Recently, researchers have proposed learning-based approaches for intelligent binary analysis. They generally addressed single tasks with hand-crafted feature sets or neural binary encoders, which suffer performance bottlenecks due to the noise in mixed features. This paper proposes SepBIN, a novel neural network framework that exploits the intrinsic correlation of binary semantic comparison and authorship verification tasks and automatically separates semantic and stylistic binary features. We first construct a strong backbone binary encoder, then utilize preliminary decomposition subnets and the flexible gating-based feature fusion mechanism to distill pure semantic-related and style-related binary representations, and further improve their quality by a feature reconstruction module. The overall SepBIN model is optimized by a multi-objective joint optimization strategy. We conduct extensive experiments on Google Code Jam (GCJ) datasets in different languages and scales. Results show that SepBIN simultaneously benefits binary semantic comparison and authorship verification tasks through the effective binary semantic-style feature separation mechanism, and provides multi-perspectives interpretability for the performance gains. For state-of-the-art approaches with different binary encoders, SepBIN can adaptively improve them with the designed separation modules. Furthermore, we adopt a pretraining-finetuning strategy to effectively transfer SepBIN’s separation capability in real-world applications, including APT malware homology detection and binary semantic comparison against code obfuscations.}
}


@article{DBLP:journals/tifs/ChengM24,
	author = {Leixiao Cheng and
                  Fei Meng},
	title = {Server-Aided Public Key Authenticated Searchable Encryption With Constant
                  Ciphertext and Constant Trapdoor},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1388--1400},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3336160},
	doi = {10.1109/TIFS.2023.3336160},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChengM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Public key authenticated encryption with keyword search (PAEKS) is an advanced asymmetric searchable encryption technique secure against inside keyword guessing attacks. A common application of PAEKS is searching for encrypted Electronic Health Records (EHR) within a healthcare cloud. Nevertheless, the standard PAEKS necessitates the sender (e.g., doctor) to separately encrypt the same keyword with each receiver’s public key to enable multiple researchers to search for the encrypted EHR. Similarly, to search for encrypted EHRs from multiple senders, a receiver (e.g., researcher) must create distinct trapdoors for the same keyword, using each sender’s public key separately. These features render the standard PAEKS impractical for use in multi-user scenarios. To resolve this challenge, we introduce the server-aided public key authenticated encryption with keyword search (SA-PAEKS) scheme, the novelty of which lies in the incorporation of two additional servers, specifically a sender server and a receiver server. With the help of these two servers, the sender encrypts the keyword just once, allowing any receiver to search for his encrypted EHR, and the receiver creates a single trapdoor to search for the encrypted EHR of any sender. When multiple sender servers and receiver servers are introduced in the system, our scheme is scalable in the sense that the size of the ciphertext and trapdoor remains constant. Furthermore, we provide a generic approach to achieve ciphertext deduplication and fast search, enhancing the overall efficiency. This approach is compatible with any PAEKS scheme and may be of independent interest. Finally, we provide both theoretical and experimental evaluations of our scheme, demonstrating its competitive performance.}
}


@article{DBLP:journals/tifs/DongXZX24,
	author = {Yong Dong and
                  Yinfei Xu and
                  Tong Zhang and
                  Yili Xia},
	title = {Optimality of the Proper Gaussian Signal in Complex {MIMO} Wiretap
                  Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1401--1414},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3337719},
	doi = {10.1109/TIFS.2023.3337719},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DongXZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The multiple-input multiple-output (MIMO) wiretap channel (WTC) serves as a fundamental model for exploring information-theoretic secrecy in wireless communication systems, involving a transmitter, a legitimate user, and an eavesdropper. This paper investigates the optimality of proper complex signals in complex WTCs. Our primary contribution lies in the derivation of a determinant inequality, which establishes that the secrecy rate of degraded complex MIMO WTCs is maximized when the signal is proper, meaning that its pseudo-covariance matrix is a zero matrix. Remarkably, we extend this result beyond the degraded scenario to the general complex WTC by leveraging a min-max reformulation of the secrecy capacity. Thus, we demonstrate that focusing on proper signals is sufficient when examining the secrecy capacity of the complex WTC. Overall, this work highlights the significance of the determinant inequality we derive and its implications for optimizing secrecy rates in the complex WTC.}
}


@article{DBLP:journals/tifs/XuLGX24,
	author = {Yinfei Xu and
                  Jian Lu and
                  Xuan Guang and
                  Wei Xu},
	title = {Information Embedding With Stegotext Reconstruction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1415--1428},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3337947},
	doi = {10.1109/TIFS.2023.3337947},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XuLGX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider stegotext reconstruction problem in information embedding. By adding the requirement of restoring the stegotext under certain fidelity criterion, we generalize the concept of reversible/irreversible information embedding. We focus on the stegotext reconstruction in a discrete memoryless host dependent attack channel, which can be regarded as a generalized Gel’fand-Pinsker problem with an input reconstruction constraint. For this problem, we prove an upper bound and a lower bound on its embedding capacity-distortion function, which is defined to describe the tradeoff between embedding information rate, host composition loss, and stegotext reconstruction distortion. In particular, our upper and lower bounds thus obtained match each other for the binary XOR attack channel with Hamming distortion and Costa’s additive Gaussian attack channel with quadratic loss. We further consider a variant of this problem, where host signal is available at the encoder in a causal way. For this case, we completely characterize its capacity-distortion function.}
}


@article{DBLP:journals/tifs/SadeghzadehSDJ24,
	author = {Amir Mahdi Sadeghzadeh and
                  Amir Mohammad Sobhanian and
                  Faezeh Dehghan and
                  Rasool Jalili},
	title = {{HODA:} Hardness-Oriented Detection of Model Extraction Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1429--1439},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3320609},
	doi = {10.1109/TIFS.2023.3320609},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SadeghzadehSDJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model extraction attacks exploit the target model’s prediction API to create a surrogate model, allowing the adversary to steal or reconnoiter the functionality of the target model in the black-box setting. Several recent studies have shown that a data-limited adversaries with no or limited access to the samples from the target model’s training data distribution, can employ synthesized or semantically similar samples to conduct model extraction attacks. In this paper, we introduce the concept of hardness degree to characterize sample difficulty based on the concept of learning speed. The hardness degree of a sample depends on the epoch number at which the predicted label for that sample converges. We investigate the hardness degree of samples and demonstrate that the hardness degree histogram of a data-limited adversary’s sample sequence is differs significantly from that of benign users’ sample sequences. We propose Hardness-Oriented Detection Approach (HODA) to detect the sample sequences of model extraction attacks. Our results indicate that HODA can effectively detect model extraction attack sequences with a high success rate, using only 100 monitored samples. It outperforms all previously proposed methods for model extraction detection.}
}


@article{DBLP:journals/tifs/LiHZYXD24,
	author = {Xiaoguo Li and
                  Zixi Huang and
                  Bowen Zhao and
                  Guomin Yang and
                  Tao Xiang and
                  Robert H. Deng},
	title = {{STDA:} Secure Time Series Data Analytics With Practical Efficiency
                  in Wide-Area Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1440--1454},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3336512},
	doi = {10.1109/TIFS.2023.3336512},
	timestamp = {Sun, 06 Oct 2024 21:41:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiHZYXD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series data analytics technology significantly benefits modern scientific research, especially in fields such as medical health, financial investment, and transportation. Unfortunately, privacy issues hinder people from handing over the data to a third party for various analytical tasks; because the data may reveal much more individual sensitive information, e.g., disease information from medical data, investment tendency from financial data, or the daily trajectory from transportation data. To break down this barrier, secure computation approaches have shown their importance in processing sensitive data, and have attracted much attention from the industry and research communities. However, when considering the case of secure time-series data analytics (e.g., DTW similarity), we are still far from achieving high efficiency due to high round complexity in communication or expensive computational complexity. We observe that DTW involves a lot of comparison operations and existing approaches in dealing with the comparison require higher communication costs. To this end, this paper studies secure DTW-based analytics with practical efficiency over time series data. Specifically, we propose the framework of secure time series data analytics (STDA) and formulate the problem of top- k\nquery for outsourced time series data. Based on threshold Paillier encryption, we present a top- k\nquery protocol utilizing the DTW distance as a metric and its security analysis, optimizations, and performance evaluation. The experimental results demonstrate that in a wide-area network with a 10 ms latency, our top- k\napproach outperforms the state-of-the-art by 3x times, while DTW calculation outperforms by 9x times. Correspondingly, the optimized \\mathcal {F}_{\\text {DTW}}\nachieves 17x times better, and optimized top- k\nachieves 4-10x times better.}
}


@article{DBLP:journals/tifs/LuW24,
	author = {Tingting Lu and
                  Junfeng Wang},
	title = {{DOMR:} Toward Deep Open-World Malware Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1455--1468},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3338469},
	doi = {10.1109/TIFS.2023.3338469},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LuW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning has been widely used for Android malware family recognition, but current deep learning-based approaches make the closed-world assumption that malware families encountered during testing are available at training phase. Unfortunately, this assumption is often violated in practice due to the constant emergence of novel categories and the huge cost of collecting abundant training classes, causing serious failures to the existing approaches. Accordingly, a new problem setting for Android malware family recognition is introduced, i.e., deep open-world malware recognition that poses two critical tasks: 1) Open recognition, aiming to not only classify malware from known families (present in training) but detect malware from unknown families (absent in training); 2) Incremental update, aiming to learn about the detected unknown/new categories without retraining from scratch and catastrophically forgetting the previously learned known/old classes. This paper formalizes the problem and proposes a novel solution called DOMR to address the above two tasks in a unified framework. The core of DOMR is an episode-based representation learning scheme that mimics the open-world setting through episodic training to learn a generalizable representation. The key insight is that the training process following the open-world setting forces the representation to accumulate experience in open recognition, thereby facilitating both the classification of known family instances and the detection of unknown family instances at inference. Given this representation, multiple one-vs-rest classifiers are subsequently built to make the final recognition decision through an aggregative strategy. Comparative experiments show that DOMR outperforms start-of-the-art methods, with macro-averaged F1-scores obtained on two datasets reaching 80.88% and 56.17% in the open case, and 79.34% and 49.55% in the incremental case, respectively. Ablation studies further analyze the effectiveness of DOMR in achieving the open recognition and incremental update goals.}
}


@article{DBLP:journals/tifs/LeeYLH24,
	author = {Jinyoung Lee and
                  Hyeonsik Yeom and
                  Si{-}Hyeon Lee and
                  Jeongseok Ha},
	title = {Channel Correlation in Multi-User Covert Communication: Friend or
                  Foe?},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1469--1482},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3338421},
	doi = {10.1109/TIFS.2023.3338421},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LeeYLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we study a covert communication scheme in which some users are opportunistically selected to emit interference signals for the purpose of hiding the communication of a covert user. This work reveals interesting facts that the channel correlation is beneficial to the throughput of the covert communication but detrimental to the energy efficiency, which has never been discussed before. The study is conducted in a generic setup where the channels between pairs of entities in the scheme are correlated. For the setup, we discover that the optimal power profile of the interference signals from the selected users turns out to be the equal power transmission at their maximum transmit power level. In addition, we optimize system parameters of the scheme for maximizing throughput and energy efficiency utilizing Q -learning, which however is plagued with long learning time and large storage space when the dimension of state gets large and/or a fine resolution of reward function value is necessary. To resolve the technical challenge, we propose a scalable Q -learning which recursively narrows down the discretization level of the continuous state in an iterative fashion. To confirm the results in this work, the system parameters are evaluated with theoretical results for independent channels and compared with the ones from the proposed scalable Q -learning.}
}


@article{DBLP:journals/tifs/ChenC24,
	author = {Niusen Chen and
                  Bo Chen},
	title = {HiPDS: {A} Storage Hardware-Independent Plausibly Deniable Storage
                  System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1483--1495},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3338528},
	doi = {10.1109/TIFS.2023.3338528},
	timestamp = {Tue, 30 Apr 2024 15:13:21 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A plausibly deniable storage (PDS) system not only conceals the plaintext of sensitive data, but also hides their very existence. It can essentially mitigate a novel coercive attack, in which the adversary captures both a victim and his/her device, and coerces the victim to disclose the sensitive data. A rich number of PDS systems have been designed in the literature. However, all of them are specifically designed for a certain type of storage hardware. In this work, we have designed {\\sf HiPDS} , the first storage Hardware-independent Plausibly Deniable Storage system. {\\sf HiPDS} can defend against a multi-snapshot adversary which can have access to both the external storage and the internal memory at multiple checkpoints over time. By leveraging our adapted chameleon hash, we encode the sensitive data into the non-sensitive cover data in a fine-grained manner, so that both the existence and the access of the sensitive data on the external storage device can be plausibly denied. In addition, to prevent the sensitive data from being compromised in the memory, the encoding/decoding process is run in a secure memory region isolated by the trusted execution environment. A salient feature of {\\sf HiPDS} is that it can ensure deniability on any types of storage media, which is essentially important for users who may change the external storage devices over time. Security analysis and experimental evaluation confirm that {\\sf HiPDS} can ensure deniability against the multi-snapshot adversary at the cost of an acceptable overhead.}
}


@article{DBLP:journals/tifs/ZhangYQGLZW24,
	author = {Hengmin Zhang and
                  Jian Yang and
                  Jianjun Qian and
                  Guangwei Gao and
                  Xiangyuan Lan and
                  Zhiyuan Zha and
                  Bihan Wen},
	title = {Efficient Image Classification via Structured Low-Rank Matrix Factorization
                  Regression},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1496--1509},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3337717},
	doi = {10.1109/TIFS.2023.3337717},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangYQGLZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In real-world applications involving sparse coding and low-rank matrix recovery problems, linear regression methods usually struggle to effectively capture the structured correlations present in data matrices. This limitation arises from representation approaches that treat images as vectors and handle testing samples individually, overlooking these correlations. To address these challenges, we propose a novel approach that leverages the low-rank property to capture the global and intrinsic structure of residual and coefficient matrices, departing from the assumption of independent and identically distributed (I.I.D) data. Our method introduces nonconvex and nonsmooth low-rank matrix regression models guided by the extended matrix variate power exponential distribution (M.P.E.D). By incorporating factorization strategies into the regression coefficient matrix and utilizing the Schatten- p norm with three distinct values of p , we enhance computational efficiency. Our formulation enables efficient subproblem solving through the introduction of auxiliary variables and the use of singular value threshold operators. We achieve closed-form solutions using the proposed multi-variable alternating direction method of multipliers (ADMM). Theoretical analysis establishes the local convergence properties and computational complexity of our optimization algorithm. Furthermore, we conduct numerical experiments on various image datasets, including face, object, and digital, to demonstrate the superior performance and computational efficiency of our methods compared to several related regression approaches. The source codes for our method are available at https://github.com/ZhangHengMin/TIFS_SLRMFR.}
}


@article{DBLP:journals/tifs/LiuLWZW24,
	author = {Yang Liu and
                  Guangbo Liang and
                  Xi Wang and
                  Peican Zhu and
                  Zhen Wang},
	title = {Diffusion Containment in Complex Networks Through Collective Influence
                  of Connections},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1510--1524},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3338423},
	doi = {10.1109/TIFS.2023.3338423},
	timestamp = {Mon, 05 Feb 2024 17:23:49 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLWZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the containment of diffusion in a network immunization perspective, whose solution also plays fundamental roles in scenarios such as the inference of rumor sources and the control of malicious viral marketings. In general, the network immunization aims to suppress the giant connected component of a network by removing as fewer nodes as possible, so that the intervention of the transmission could be achieved by only a few resources. Here, rather than that and based on the fact that removing edges might be cheaper and more applicable in some scenarios, we investigate which group of edges whose removal could boost the performance of an immunization strategy more effectively. We consider both cases that the network topology is known and unknown, and thus two approaches are accordingly developed based on the Edge RelationShip (ERS) and Explosive Percolation over Partial (EPP) information. We evaluate the performance of ERS by comparing it with strategies based on the edge betweenness, the product of eigenvector centralities of the nodes connected by edges, the epidemic link equations, etc. Results on over 30 real networks show that ERS could effectively acquire far better solutions by much less computing time. We also demonstrate the performance of EPP in the circumstances of decentralized, centralized, and delayed cases. We find that the performance of EPP would be in a degree degraded by the uncertainty of inferences from individuals, inaccuracy of predictions, and delay of reactions. But in almost all cases, the developed approach can more effectively suppress a diffusion compared to the currently random strategy, especially when a tough restriction is needed or a combination with the acquaintance immunization is conducted.}
}


@article{DBLP:journals/tifs/YangGFS24,
	author = {Ni Yang and
                  Ruiyi Gao and
                  Youzhi Feng and
                  Huan Su},
	title = {Event-Triggered Impulsive Control for Complex Networks Under Stochastic
                  Deception Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1525--1534},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3336078},
	doi = {10.1109/TIFS.2023.3336078},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangGFS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article studies exponential synchronization of complex networks under deception attacks via event-triggered impulsive control. A new event-triggered mechanism is proposed to avoid Zeno behavior based on the topology of the networks and the Lyapunov function of the subsystem. Using a combination of the Lyapunov method and graph theory, several criteria for synchronization of complex networks under attacks are given, which are related to the event-triggered parameters, the topology of the network, and the attack signal sent by enemies. Given the prevalence of delays, we also extend the obtained results to delayed deception attacks, where malicious attackers modify state data from past moments. Finally, the theory applies to circuit systems under deception attacks and delayed deception attacks, respectively, and numerical simulations are given to verify the effectiveness and practicality of our results.}
}


@article{DBLP:journals/tifs/FangLWEZZLL24,
	author = {Hao Fang and
                  Ajian Liu and
                  Jun Wan and
                  Sergio Escalera and
                  Chenxu Zhao and
                  Xu Zhang and
                  Stan Z. Li and
                  Zhen Lei},
	title = {Surveillance Face Anti-Spoofing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1535--1546},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3337970},
	doi = {10.1109/TIFS.2023.3337970},
	timestamp = {Mon, 11 Nov 2024 09:38:53 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FangLWEZZLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face Anti-spoofing (FAS) is essential to secure face recognition systems from various physical attacks. However, recent research generally focuses on short-distance applications (i.e., phone unlocking) while lacking consideration of long-distance scenes (i.e., surveillance security checks). In order to promote relevant research and fill this gap in the community, we collect a large-scale Su rveillance Hi gh-Fi delity Mask (SuHiFiMask) dataset captured under 40 surveillance scenes, which has 101 subjects from different age groups with 232~3\\text{D} attacks (high-fidelity masks), 200~2\\text{D} attacks (posters, portraits, and screens), and 2 adversarial attacks. In this scene, low image resolution and noise interference are new challenges faced in surveillance FAS. Together with the SuHiFiMask dataset, we propose a Contrastive Quality-Invariance Learning (CQIL) network to alleviate the performance degradation caused by image quality from three aspects: 1) An Image Quality Variable module (IQV) is introduced to recover image information associated with discrimination by combining the super-resolution network. 2) Using generated sample pairs to simulate quality variance distributions to help contrastive learning strategies obtain robust feature representation under quality variation. 3) A Separate Quality Network (SQN) is designed to learn discriminative features independent of image quality. Finally, a large number of experiments verify the quality of the SuHiFiMask dataset and the superiority of the proposed CQIL.}
}


@article{DBLP:journals/tifs/ChenCXZYS24,
	author = {Jiefu Chen and
                  Tong Chen and
                  Xing Xu and
                  Jingran Zhang and
                  Yang Yang and
                  Heng Tao Shen},
	title = {Coreset Learning-Based Sparse Black-Box Adversarial Attack for Video
                  Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1547--1560},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3333556},
	doi = {10.1109/TIFS.2023.3333556},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenCXZYS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, researchers have explored the use of sparse black-box video adversarial attacks, which involve selecting keyframes to reduce computational complexity and improve efficiency in generating perturbations. However, the current sparse strategy is not optimized for attack and detection steps, resulting in inaccurate frame selection. Some researchers have used reinforcement learning to train an agent to select keyframes, but this method requires additional training. To address these challenges, we propose a plug-and-play black-box sparse attack algorithm called CLVA based on the coreset concept of active learning. Our algorithm treats a video as a mini-dataset and employs the K-Center-Greedy algorithm to compute the distances between frames. We then select the frame that meets the distance condition as the key frame. We conducted extensive experiments using two attack algorithms on five mainstream recognition models and three video recognition datasets. Our results demonstrate that CLVA significantly accelerates the black-box video attack algorithm while achieving state-of-the-art performance in sparsity, time, and success rate compared to recent sparse attack algorithms. The implementation code of our CLVA method is available at https://github.com/machineNo6/CLVA.}
}


@article{DBLP:journals/tifs/EsmaeiliERMS24,
	author = {Ashkan Esmaeili and
                  Marzieh Edraki and
                  Nazanin Rahnavard and
                  Ajmal Mian and
                  Mubarak Shah},
	title = {Low-Rank and Sparse Decomposition for Low-Query Decision-Based Adversarial
                  Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1561--1575},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3275737},
	doi = {10.1109/TIFS.2023.3275737},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/EsmaeiliERMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning models are susceptible to contrived adversarial examples, even in the decision-based black-box setting where the attacker has access to the model’s decisions only. Developing more efficient and practical attacks help in better understanding the limitations of deep models. It is important that attacks are crafted with limited queries to avoid suspicion. Since the required number of queries increase with dimensions, low-dimensional embeddings are attractive. This low query budget constraint is a bottleneck for learning-based and data-driven attacks which rely heavily on querying the model. We propose LSDAT, an image-agnostic non-data-driven decision-based black-box attack that exploits low-rank and sparse decomposition (LSD) of images to dramatically reduce the queries and improve fooling rates compared to existing methods. LSDAT crafts perturbations in the low-dimensional subspace formed by the sparse component of the input image and that of a target adversarial image to obtain query-efficiency. A viable perturbation is obtained by traversing the path between the input and adversarial sparse components. Theoretical analyses are provided to justify the functionality of LSDAT. Unlike other competitors (e.g., FFT), LSD works directly in the image domain to guarantee that non-\nℓ\n2\nconstraints, such as sparsity, are satisfied. LSDAT offers better control over the number of queries and is computationally efficient as it performs sparse decomposition of the input and adversarial images only once to generate all queries. Four variants of LSDAT are presented for different scenarios including a pure black-box attack where no queries are allowed. We demonstrate\nℓ\n0\n,\nℓ\n2\nand\nℓ\n∞\nbounded attacks with LSDAT to evince its efficiency compared to baseline attacks in diverse low-query budget scenarios. LSDAT obtains 15 to 20% improvement in fooling ResNet-50 while using far fewer queries than competing methods in a similar set...}
}


@article{DBLP:journals/tifs/HaoLDHX24,
	author = {Xiaohan Hao and
                  Chao Lin and
                  Wenhan Dong and
                  Xinyi Huang and
                  Hui Xiong},
	title = {Robust and Secure Federated Learning Against Hybrid Attacks: {A} Generic
                  Architecture},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1576--1588},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3336521},
	doi = {10.1109/TIFS.2023.3336521},
	timestamp = {Sun, 06 Oct 2024 21:41:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HaoLDHX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) enables multiple clients to collaboratively train a model without sharing their private data. However, the deployment of FL in real-world applications is vulnerable to various attacks from both malicious servers and clients. While cryptographic methods are effective in resisting server-side attacks, they undermine the capability of client-side defenses that rely on plaintext updates. Several valuable defenses targeting hybrid attacks have been devised to address this challenge, concentrating on specific client-side threats. To improve scalability, we continue this research line to introduce a generic architecture covering more client-side attacks. In this paper, we propose a general architecture to enhance client-side defenses from plaintext to ciphertext domains. This architecture not only supports the server-side defenses, but also accommodates a broader range of client-side defenses, including Norm-based, Krum-based, and Cosine-based strategies. The core of our architecture is generic detection under ciphertext, which tackles the following conflict of integrating server-side and client-side defenses. That is, the former aims to protect parameters from exposure while the latter demands plaintext updates. We prove the security of our architecture through the Universal Composability framework. Additionally, we provide a comprehensive instantiation and extensive evaluations to demonstrate the effectiveness and robustness of our approach. Our experiments show that our architecture can maintain the effectiveness of current client-side defenses when parameters are encrypted, thus effectively resisting hybrid attacks.}
}


@article{DBLP:journals/tifs/JiangLZ24,
	author = {Peng Jiang and
                  Qi Liu and
                  Liehuang Zhu},
	title = {SanIdea: Exploiting Secure Blockchain-Based Access Control via Sanitizable
                  Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1589--1600},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340066},
	doi = {10.1109/TIFS.2023.3340066},
	timestamp = {Wed, 04 Sep 2024 21:09:35 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptographic access control guarantees that authorized users can access data while unauthorized get nothing. Such an all-or-nothing access mode achieves secrecy but does not fit strong-privacy scenarios. FE-based access control breaks it and reaches a balance between data privacy and data utilization. To resist malicious senders, Damgard et al. introduced sanitizable functional encryption that enables a bi-directional control to both senders and receivers. However, its centralized structure means that the compromise of the authority incurs massive secret leakage and undermines the system’s reliability. In this work, we present SanIdea, a sanitizable, decentralized and privacy-preserving access control framework which embraces a sanitizer in the distributed-authority-domain access control setting. We instantiate it by proposing a cryptographic primitive named sMABE, which adds a \\mathsf {Sanitize} algorithm over multi-authority attribute-based encryption. We formally prove its security in the IND-CPA model and the Sanitization Security model under the DBDH assumption. We demonstrate its reasonable efficiency through algorithm simulation, where the sanitization time is less than 0.1s with the configuration of 5 attribute authorities and 25 user attributes. We design an SABC system by integrating SanIdea with the blockchain, where SABC uses a smart contract to ensure the correctness of the distributed secret key parts. We implement SABC in an Ethereum testbed and the experiment results show that the \\mathsf {upload} algorithm costs about 163000 user gas and the \\mathsf {download} algorithm costs about 84000 user gas, which is cost-reasonable.}
}


@article{DBLP:journals/tifs/JmalHBIKW24,
	author = {Houssem Jmal and
                  Firas Ben Hmida and
                  Nardine Basta and
                  Muhammad Ikram and
                  Mohamad Ali K{\^{a}}afar and
                  Andy Walker},
	title = {{SPGNN-API:} {A} Transferable Graph Neural Network for Attack Paths
                  Identification and Autonomous Mitigation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1601--1613},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3338965},
	doi = {10.1109/TIFS.2023.3338965},
	timestamp = {Thu, 12 Sep 2024 20:54:18 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JmalHBIKW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attack paths are the potential chain of malicious activities an attacker performs to compromise network assets and acquire privileges through exploiting network vulnerabilities. Attack path analysis helps organizations to identify new/unknown chains of attack vectors exposing critical assets, as opposed to individual attack vectors in signature-based attack analysis. Timely identification of attack paths enables proactive mitigation of threats. Nevertheless, manual analysis of complex network configurations, vulnerabilities, and security events to identify attack paths is rarely feasible. This work proposes a novel transferable graph neural network-based model for shortest path identification. The shortest path, integrated with a novel holistic model for identifying potential network vulnerabilities interactions, is then utilized to detect network attack paths. Our framework automates the risk assessment of attack paths indicating the propensity of the paths to enable the compromise of highly-critical assets (e.g., databases). The proposed framework, named SPGNN-API, incorporates automated threat mitigation through a proactive timely tuning of the network firewall rules and Zero-Trust (ZT) policies to break critical attack paths and bolster cyber defenses. Our evaluation process is twofold; evaluating the performance of the shortest path identification and assessing the attack path detection accuracy. Our results show that SPGNN-API largely outperforms the baseline model for shortest path identification with an average accuracy \\geq95 % and successfully detects 100% of the potentially compromised assets, outperforming the attack graph baseline by 47%.}
}


@article{DBLP:journals/tifs/PeiDTLX24,
	author = {Xinjun Pei and
                  Xiaoheng Deng and
                  Shengwei Tian and
                  Jianqing Liu and
                  Kaiping Xue},
	title = {Privacy-Enhanced Graph Neural Network for Decentralized Local Graphs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1614--1629},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3329971},
	doi = {10.1109/TIFS.2023.3329971},
	timestamp = {Sun, 04 Aug 2024 19:49:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PeiDTLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the ever-growing interest in modeling complex graph structures, graph neural networks (GNN) provide a generalized form of exploiting non-Euclidean space data. However, the global graph may be distributed across multiple data centers, which makes conventional graph-based models incapable of modeling a complete graph structure. This also brings an unprecedented challenge to user privacy protection in distributed graph learning. Due to privacy requirements of legal policies, existing graph-based solutions are difficult to deploy in practice. In this paper, we propose a privacy-preserving graph neural network based on local graph augmentation, named LGA-PGNN, which preserves user privacy by enforcing local differential privacy (LDP) noise into the decentralized local graphs held by different data holders. Moreover, we perform local neighborhood augmentation on low-degree vertices to enhance the expressiveness of the learned model. Specifically, we propose two graph privacy attacks, namely attribute inference attack and link stealing attack, which aim at compromising user privacy. The experimental results demonstrate that LGA-PGNN can effectively mitigate these two attacks and provably avoid potential privacy leakage while ensuring the utility of the learning model.}
}


@article{DBLP:journals/tifs/GronowskiPAGB24,
	author = {Adam Gronowski and
                  William Paul and
                  Fady Alajaji and
                  Bahman Gharesifard and
                  Philippe Burlina},
	title = {Classification Utility, Fairness, and Compactness via Tunable Information
                  Bottleneck and R{\'{e}}nyi Measures},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1630--1645},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340094},
	doi = {10.1109/TIFS.2023.3340094},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GronowskiPAGB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Designing machine learning algorithms that are accurate yet fair, not discriminating based on any sensitive attribute, is of paramount importance for society to accept AI for critical applications. In this article, we propose a novel fair representation learning method termed the Rényi Fair Information Bottleneck Method (RFIB) which incorporates constraints for utility, fairness, and compactness (compression) of representation, and apply it to image and tabular data classification. A key attribute of our approach is that we consider - in contrast to most prior work - both demographic parity and equalized odds as fairness constraints, allowing for a more nuanced satisfaction of both criteria. Leveraging a variational approach, we show that our objectives yield a loss function involving classical Information Bottleneck (IB) measures and establish an upper bound in terms of two Rényi measures of order \\boldsymbol {\\alpha } on the mutual information IB term measuring compactness between the input and its encoded embedding. We study the influence of the \\boldsymbol {\\alpha } parameter as well as two other tunable IB parameters on achieving utility/fairness trade-off goals, and show that the \\boldsymbol {\\alpha } parameter gives an additional degree of freedom that can be used to control the compactness of the representation. Experimenting on three different image datasets (EyePACS, CelebA, and FairFace) and two tabular datasets (Adult and COMPAS), using both binary and categorical sensitive attributes, we show that on various utility, fairness, and compound utility/fairness metrics RFIB outperforms current state-of-the-art approaches.}
}


@article{DBLP:journals/tifs/TanCWLP24,
	author = {Weihang Tan and
                  Sin{-}Wei Chiu and
                  Antian Wang and
                  Yingjie Lao and
                  Keshab K. Parhi},
	title = {PaReNTT: Low-Latency Parallel Residue Number System and NTT-Based
                  Long Polynomial Modular Multiplication for Homomorphic Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1646--1659},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3338553},
	doi = {10.1109/TIFS.2023.3338553},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TanCWLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-speed long polynomial multiplication is important for applications in homomorphic encryption (HE) and lattice-based cryptosystems. This paper addresses low-latency hardware architectures for long polynomial modular multiplication using the number-theoretic transform (NTT) and inverse NTT (iNTT). Parallel NTT and iNTT architectures are proposed to reduce the number of clock cycles to process the polynomials. Chinese remainder theorem (CRT) is used to decompose the modulus into multiple smaller moduli. Our proposed architecture, namely PaReNTT, makes three novel contributions. First, cascaded parallel NTT and iNTT architectures are proposed such that any buffer requirement for permuting the product of the NTTs before it is input to the iNTT is eliminated. This is achieved by using different folding sets for the NTTs and iNTT. Second, a novel approach to expand the set of feasible special moduli is presented where the moduli can be expressed in terms of a few signed power-of-two terms. Third, novel architectures for pre-processing for computing residual polynomials using the CRT and post-processing for combining the residual polynomials are proposed. These architectures significantly reduce the area consumption of the pre-processing and post-processing steps. The proposed long modular polynomial multiplications are ideal for applications that require low latency and high sample rate such as in the cloud, as these feed-forward architectures can be pipelined at arbitrary levels. Pipelining and latency tradeoffs are also investigated. Compared to a prior design, the proposed architecture reduces latency by a factor of 49.2, and the area-time products (ATP) for the lookup table and DSP, ATP(LUT) and ATP(DSP), respectively, by 89.2% and 92.5%. Specifically, we show that for $n=4096$ and a 180-bit coefficient, the proposed 2-parallel architecture requires 6.3 Watts of power while operating at 240 MHz, with 6 moduli, each of length 30 bits, using Xilinx Virtex Ultrascale+ FPGA.}
}


@article{DBLP:journals/tifs/FengCM24,
	author = {Kai Feng and
                  Marco M. Cook and
                  Angelos K. Marnerides},
	title = {Sizzler: Sequential Fuzzing in Ladder Diagrams for Vulnerability Detection
                  and Discovery in Programmable Logic Controllers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1660--1671},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340615},
	doi = {10.1109/TIFS.2023.3340615},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FengCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Programmable Logic Controllers (PLCs) constitute the basis of Industrial Control Systems (ICSs) underpinning sectors ranging from nuclear, up to energy and manufacturing. Currently, PLC vulnerability assessment practices employed by ICS operators are limited due to their reliance on empirical observations of visible code crashes prompted by PLC compilers. In parallel, the prevalent PLC firmware dependency on proprietary vendor routines restricts the composition of generic vulnerability detection or discovery schemes for zero-day threat vectors. In this work, we propose Sizzler: a novel vendor-independent vulnerability discovery framework specific to PLC applications operating with logic realised through ladder diagrams. Sizzler extends the current state of the art by proposing the optimal synergy of a mutation-based fuzzing strategy using Sequential Generative Adversarial Network (SeqGAN). By virtue of critical vendor restrictions on emulating PLC firmware, we also refine the Quick Emulator (QEMU)’s General Purpose I/O (GPIO) and the Inter-Integrated Circuit (I2C) protocols to evaluate and compare Sizzler across 30 PLC ladder diagram programs compiled from LDmicro and OpenPLC projects over five widely used Micro-Controller Units (MCUs). It is noteworthy that Sizzler has successfully identified vulnerabilities in ladder diagrams within a relatively short time frame based on our proprietary dataset and secured a CVE-ID. Moreover, through a comparison of Sizzler with prevalent fuzzing techniques over the commonly used Magma and LAVA-M datasets we exhibit its wider applicability on embedded systems and identify its limitations.}
}


@article{DBLP:journals/tifs/KimHKSH24,
	author = {Hodong Kim and
                  Changhee Hahn and
                  Hyunwoo J. Kim and
                  Youngjoo Shin and
                  Junbeom Hur},
	title = {Deep Learning-Based Detection for Multiple Cache Side-Channel Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1672--1686},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340088},
	doi = {10.1109/TIFS.2023.3340088},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KimHKSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A cache side-channel attack retrieves victim’s sensitive information from a system by exploiting shared cache of CPUs. Since conventional cache side-channel attacks such as FLUSH+RELOAD and PRIME+PROBE are likely to incur numerous cache events, such as cache hits and misses, many previous strategies have focused on monitoring cache events for attack detection. However, as recently proposed attacks such as PRIME+ABORT have exploited the other events as side-channels, it has become challenging to detect them by monitoring only cache events. In this paper, we investigate PRIME+ABORT attack and identifies Intel TSX hardware events are tightly coupled with it as well as cache events. Based on our finding, we propose a novel deep learning-based cache side-channel attack detection method called FRIME. It can concurrently detect not only the conventional attacks such as FLUSH+RELOAD, PRIME+PROBE, but also PRIME+ABORT by leveraging both event types. In order to demonstrate the efficacy of our cache side-channel attack detection scheme in diverse workload conditions in the real world, we implement it using MLP, RNN, and LSTM deep learning models, demonstrating LSTM-based method outperforms the other implementations in terms of detection accuracy.}
}


@article{DBLP:journals/tifs/QuanLL24,
	author = {Junyu Quan and
                  Qin Li and
                  Lvzhou Li},
	title = {Verifiable Blind Quantum Computation With Identity Authentication
                  for Multi-Type Clients},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1687--1698},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340859},
	doi = {10.1109/TIFS.2023.3340859},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/QuanLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blind quantum computation (BQC) provides a solution for clients with limited quantum capabilities to delegate their quantum computational tasks to remote quantum servers while keeping their own data private. In this paper, we first propose three multi-party verifiable blind quantum computation (MPVBQC) protocols, each of which can handle one type of clients with certain simple quantum capabilities such as making single-qubit measurements, preparing single qubits, or performing a few single-qubit gates. Then a flexible and hybrid MPVBQC framework for multi-type clients in quantum networks is given by combining the three proposed MPVBQC protocols. It simultaneously allows at least three types of clients in quantum networks to achieve BQC depending on their own quantum devices. Furthermore, all the proposed protocols can achieve identity authentication, resist both insider and outsider attacks, and be verifiable which means that the clients can verify the correctness of their computational results.}
}


@article{DBLP:journals/tifs/QinFDLEZ24,
	author = {Huafeng Qin and
                  Chao Fan and
                  Shaojiang Deng and
                  Yantao Li and
                  Mounim A. El{-}Yacoubi and
                  Gang Zhou},
	title = {{AG-NAS:} An Attention GRU-Based Neural Architecture Search for Finger-Vein
                  Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1699--1713},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340915},
	doi = {10.1109/TIFS.2023.3340915},
	timestamp = {Fri, 26 Apr 2024 07:58:46 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QinFDLEZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finger-vein recognition has attracted extensive attention due to its exceptional level of security and privacy. Recently, deep neural networks (DNNs), such as convolutional neural networks (CNNs) showing robust capacity for feature representation, have been proposed for vein recognition. The architectures of these DNNs, however, have primarily been manually designed based on human prior knowledge, which is both time-consuming and error-prone. To overcome these problems, we propose AG-NAS, an Attention Gated recurrent unit-based Neural Architecture Search to automatically search for the optimal network architecture, thereby improving the recognition performance for different finger-vein recognition tasks. First, we combine the self-attention mechanism and gated recurrent unit (GRU) to propose an attention GRU module employed as a controller to generate the architectural hyperparameters of candidate neural networks automatically. Second, we investigate a parameter-sharing supernet policy to reduce the search space, computation, and time costs. Finally, we conduct rigorous experiments on our finger-vein database and two public finger-vein databases. The experimental results demonstrate that the proposed AG-NAS outperforms the representative approaches and achieves state-of-the-art recognition accuracy.}
}


@article{DBLP:journals/tifs/LiQHDS24,
	author = {Dingzhao Li and
                  Jie Qi and
                  Shaohua Hong and
                  Pengfei Deng and
                  Haixin Sun},
	title = {A Class-Incremental Approach With Self-Training and Prototype Augmentation
                  for Specific Emitter Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1714--1727},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3343193},
	doi = {10.1109/TIFS.2023.3343193},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiQHDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Specific emitter identification (SEI) is a non-cryptographic authentication technique to provide an extra security layer for wireless devices, which has promising applications. However, the traditional methods of SEI are only available in limited equipments. In actual application scenarios, new devices (as new classes) are constantly appearing. In this paper, an effective class incremental learning (CIL) method is proposed for SEI, named class-incremental with self-training and prototype augmentation (CISP). It is a teacher-student network. Firstly, the teacher network trained by the old-class data is utilized to instruct the student network to adapt the new classes while retaining the old-class knowledge through the knowledge distillation (KD) techniques. Secondly, in order to mitigate the problem of favoring the new classes, weight aligning (WA) method is introduced to balance the weights of the new-class and old-class classification layers in the student network. Lastly, the old-class samples are recalled from the unlabeled dataset by the student network and input into the teacher network. Then the feature prototypes of the old classes are constructed and augmented. This would further ease the imbalance between the old and new classes and alleviate the problem of noisy pseudo-labels. Experiment results on the real AIS-100 dataset and ADS-B-100 dataset with the number of the initial classes being 20 and 20 classes per incremental step demonstrate that the proposed method can achieve an average accuracy of 95.29% and 95.84%, respectively. It effectively mitigates the catastrophic forgetting of the model and is superior to the state-of-the-art incremental learning approaches of not saving the old-class samples.}
}


@article{DBLP:journals/tifs/ShateriMLP24,
	author = {Mohammadhadi Shateri and
                  Francisco Messina and
                  Fabrice Labeau and
                  Pablo Piantanida},
	title = {Preserving Privacy in GANs Against Membership Inference Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1728--1743},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3342654},
	doi = {10.1109/TIFS.2023.3342654},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ShateriMLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generative Adversarial Networks (GANs) have been widely used for generating synthetic data for cases where there is a limited size real-world data set or when data holders are unwilling to share their data samples. Recent works showed that GANs, due to overfitting and memorization, might leak information regarding their training data samples. This makes GANs vulnerable to Membership Inference Attacks (MIAs). Several defense strategies have been proposed in the literature to mitigate this privacy issue. Unfortunately, defense strategies based on differential privacy are proven to reduce extensively the quality of the synthetic data points. On the other hand, more recent frameworks such as PrivGAN and PAR-GAN are not suitable for small-size training data sets. In the present work, the overfitting in GANs is studied in terms of the discriminator, and a more general measure of overfitting based on the Bhattacharyya coefficient is defined. Then, inspired by Fano’s inequality, our first defense mechanism against MIAs is proposed. This framework, which requires only a simple modification in the loss function of GANs, is referred to as the maximum entropy GAN or MEGAN and significantly improves the robustness of GANs to MIAs. As a second defense strategy, a more heuristic model based on minimizing the information leaked from the generated samples about the training data points is presented. This approach is referred to as mutual information minimization GAN (MIMGAN) and uses a variational representation of the mutual information to minimize the information that a synthetic sample might leak about the whole training data set. Applying the proposed frameworks to some commonly used data sets against state-of-the-art MIAs reveals that the proposed methods can reduce the accuracy of the adversaries to the level of random guessing accuracy with a small reduction in the quality of the synthetic data samples.}
}


@article{DBLP:journals/tifs/SharmaAW24,
	author = {Chandra Sharma and
                  George T. Amariucai and
                  Shuangqing Wei},
	title = {The Economics of Privacy and Utility: Investment Strategies},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1744--1755},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3341008},
	doi = {10.1109/TIFS.2023.3341008},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SharmaAW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The inevitable leakage of privacy as a result of unrestrained disclosure of personal information has motivated extensive research on robust privacy-preserving mechanisms. However, existing research is mostly limited to solving the problem in a static setting with disregard for the privacy leakage over time. Unfortunately, this treatment of privacy is insufficient in practical settings where users continuously disclose their personal information over time resulting in an accumulated leakage of the users’ sensitive information. In this paper, we consider privacy leakage over a finite time horizon and investigate optimal strategies to maximize the utility of the disclosed data while limiting the finite-horizon privacy leakage. We consider a simple privacy mechanism that involves compressing the user’s data before each disclosure to meet the desired constraint on future privacy. We further motivate several algorithms to optimize the dynamic privacy-utility tradeoff and evaluate their performance via extensive synthetic performance tests.}
}


@article{DBLP:journals/tifs/TianLLSZ24,
	author = {Yangguang Tian and
                  Bowen Liu and
                  Yingjiu Li and
                  Pawel Szalachowski and
                  Jianying Zhou},
	title = {Accountable Fine-Grained Blockchain Rewriting in the Permissionless
                  Setting},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1756--1766},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340917},
	doi = {10.1109/TIFS.2023.3340917},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TianLLSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain rewriting with fine-grained access control allows a user to create a transaction associated with a set of attributes, while a modifier who possesses sufficient rewriting privileges from a trusted authority satisfying the attribute set can anonymously rewrite the transaction. However, it lacks accountability and is not designed for open blockchains that require no centralized trust authority. In this work, we introduce accountable fine-grained blockchain rewriting in a permissionless setting. The property of accountability allows the modifier’s identity and their rewriting privileges to be held accountable for the modified transactions in case of malicious rewriting. Our contributions are three-fold. First, we present a generic framework for secure blockchain rewriting in the permissionless setting. Second, we present an instantiation of our framework and show its practicality through evaluation analysis. Last, we demonstrate that our proof-of-concept implementation can be effectively integrated into open blockchains.}
}


@article{DBLP:journals/tifs/YangCCY24,
	author = {Bin Yang and
                  Jun Chen and
                  Cuiqun Chen and
                  Mang Ye},
	title = {Dual Consistency-Constrained Learning for Unsupervised Visible-Infrared
                  Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1767--1779},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3341392},
	doi = {10.1109/TIFS.2023.3341392},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangCCY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised visible-infrared person re-identification (US-VI-ReID) aims at learning a cross-modality matching model under unsupervised conditions, which is an extremely important task for practical nighttime surveillance to retrieve a specific identity. Previous advanced US-VI-ReID works mainly focus on associating the positive cross-modality identities to optimize the feature extractor by off-line manners, inevitably resulting in error accumulation of incorrect off-line cross-modality associations in each training epoch due to the intra-modality and inter-modality discrepancies. They ignore the direct cross-modality feature interaction in the training process, i.e., the on-line representation learning and updating. Worse still, existing interaction methods are also susceptible to inter-modality differences, leading to unreliable heterogeneous neighborhood learning. To address the above issues, we propose a dual consistency-constrained learning framework (DCCL) simultaneously incorporating off-line cross-modality label refinement and on-line feature interaction learning. The basic idea is that the relations between cross-modality instance-instance and instance-identity should be consistent. More specifically, DCCL constructs an instance memory, an identity memory, and a domain memory for each modality. At the beginning of each training epoch, DCCL explores the off-line consistency of cross-modality instance-instance and instance-identity similarities to refine the reliable cross-modality identities. During the training, DCCL finds credible homogeneous and heterogeneous neighborhoods with on-line consistency between query-instance similarity and query-instance domain probability similarities for feature interaction in one batch, enhancing the robustness against intra-modality and inter-modality variations. Extensive experiments validate that our method significantly outperforms existing works, and even surpasses some supervised counterparts. The source code is available at https://github.com/yangbincv/DCCL.}
}


@article{DBLP:journals/tifs/LiGLH24,
	author = {Qiongxiu Li and
                  Jaron Skovsted Gundersen and
                  Milan Lopuha{\"{a}}{-}Zwakenberg and
                  Richard Heusdens},
	title = {Adaptive Differentially Quantized Subspace Perturbation {(ADQSP):}
                  {A} Unified Framework for Privacy-Preserving Distributed Average Consensus},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1780--1793},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3343599},
	doi = {10.1109/TIFS.2023.3343599},
	timestamp = {Mon, 05 Feb 2024 20:21:14 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiGLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving distributed average consensus has received significant attention recently due to its wide applicability. Based on the achieved performances, existing approaches can be broadly classified into perfect accuracy-prioritized approaches such as secure multiparty computation (SMPC), and worst-case privacy-prioritized approaches such as differential privacy (DP). Methods of the first class achieve perfect output accuracy but reveal some private information, while methods from the second class provide privacy against the strongest adversary at the cost of a loss of accuracy. In this paper, we propose a general approach named adaptive differentially quantized subspace perturbation (ADQSP) which combines quantization schemes with so-called subspace perturbation. Although not relying on cryptographic primitives, the proposed approach enjoys the benefits of both accuracy-prioritized and privacy-prioritized methods and is able to unify them. More specifically, we show that by varying a single quantization parameter the proposed method can vary between SMPC-type performances and DP-type performances. Our results show the potential of exploiting traditional distributed signal processing tools for providing cryptographic guarantees. In addition to a comprehensive theoretical analysis, numerical validations are conducted to substantiate our results.}
}


@article{DBLP:journals/tifs/DipuATF24,
	author = {Nusrat Farzana Dipu and
                  Avinash Ayalasomayajula and
                  Mark M. Tehranipoor and
                  Farimah Farahmandi},
	title = {{AGILE:} Automated Assertion Generation to Detect Information Leakage
                  Vulnerabilities},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1794--1809},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3343970},
	doi = {10.1109/TIFS.2023.3343970},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DipuATF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The globalization of the System-on-Chip (SoC) design process has made hardware designs prone to many security vulnerabilities. One of the most critical security vulnerabilities is information leakage (IL), which allows an attacker to gain access to a design’s secret information. IL vulnerabilities can result from unintended design flaws or the intentional insertion of malicious functionality into the design. Such vulnerabilities should be identified at the early design stages to secure a hardware design. Property-driven security verification has emerged as a promising method of verifying that such security vulnerabilities do not exist. This verification technique requires developing an appropriate set of assertions to formally represent the properties. However, forming a comprehensive set of assertions that can cover all potential vulnerabilities in design is challenging. Assertion generation cannot be done manually due to the large complexity of designs, lack of security experts as well as the existence of untrusted observable points in the design. In this work, we propose AGILE, a framework to automatically generate security assertions for property-driven verification to identify IL-based vulnerabilities. The experimental results show that the assertions provided by AGILE can detect both intentional and unintentional IL paths in the input design. We demonstrate the effectiveness of AGILE on the NIST standard, Trust-Hub, and OpenCores benchmarks. Moreover, we use code coverage analysis to evaluate the accessibility of the generated assertions to the source code. The analytical result indicates that by utilizing the assertions generated by AGILE, security coverage of the design under verification (DUV) can be improved significantly.}
}


@article{DBLP:journals/tifs/ZhuDZMZ24,
	author = {Boyu Zhu and
                  Changyu Dong and
                  Yuan Zhang and
                  Yunlong Mao and
                  Sheng Zhong},
	title = {Toward Universal Detection of Adversarial Examples via Pseudorandom
                  Classifiers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1810--1825},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340889},
	doi = {10.1109/TIFS.2023.3340889},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuDZMZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial examples that can fool neural network classifiers have attracted much attention. Existing approaches to detect adversarial examples leverage a supervised scheme in generating attacks (either targeted or non-targeted) for training the detectors, which means the detectors are geared to the attacks chosen at the training time and could be circumvented if the adversary does not act as expected. In this paper, we borrow ideas from cryptography and present a novel approach called pseudorandom classifier. In a nutshell, a pseudorandom classifier is a classifier equipped with a mapping to encode the category labels into random multi-bit labels, and a keyed pseudorandom injective function to transform the input to the classifier. The multi-bit labels enable attack-independent and probabilistic detection if the input sample is adversarial. The pseudorandom injection makes the existing white-box adversarial example generation methods, largely based on back-propagation, no longer applicable. We empirically evaluate our method on MNIST, CIFAR10, Imagenette, CIFAR100, and GTSRB. The results suggest that its performance against adversarial examples is comparable to the state-of-the-art.}
}


@article{DBLP:journals/tifs/GongZGQWWZ24,
	author = {Maoguo Gong and
                  Yuanqiao Zhang and
                  Yuan Gao and
                  A. Kai Qin and
                  Yue Wu and
                  Shanfeng Wang and
                  Yihong Zhang},
	title = {A Multi-Modal Vertical Federated Learning Framework Based on Homomorphic
                  Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1826--1839},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340994},
	doi = {10.1109/TIFS.2023.3340994},
	timestamp = {Wed, 31 Jul 2024 21:35:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GongZGQWWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning has gained prominence as an effective solution for addressing data silos, enabling collaboration among multiple parties without sharing their data. However, existing federated learning algorithms often neglect the challenge posed by multi-modal data distribution. Moreover, previous pioneering work face limitations in encrypting the exponential and logarithmic operations of the objective function with multiple independent variables, and they rely on a third-party cooperator for encryption. To address these limitations, this paper introduces a universal multi-modal vertical federated learning framework. To tackle the data distribution challenge, we propose a two-step multi-modal transformer model that captures cross-domain semantic features effectively. For encryption, where traditional additively homomorphic encryption algorithms fall short by supporting only addition and multiplication, we employ bivariate Taylor series expansion to transform the objective function. Integrating these components, we present a comprehensive training and transmission protocol that eliminates the need for a third-party cooperator during the encryption process. Extensive experiments conducted on diverse video-text and image-text datasets validate the superior performance of our framework compared to state-of-the-art approaches, affirming its effectiveness in multi-modal vertical federated learning settings.}
}


@article{DBLP:journals/tifs/KarunanayakeJAJ24,
	author = {Ishan Karunanayake and
                  Jiaojiao Jiang and
                  Nadeem Ahmed and
                  Sanjay K. Jha},
	title = {Exploring Uncharted Waters of Website Fingerprinting},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1840--1854},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3342607},
	doi = {10.1109/TIFS.2023.3342607},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KarunanayakeJAJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Amidst the rapid technological advancements of today, privacy and anonymity are facing increasing threats. Tor, one of the most widely used anonymity networks, enables users to browse the Internet without their activities being tracked. Extensive research has been conducted on both attacking and defending the anonymity of Tor users. Website Fingerprinting (WF) is one of the popular de-anonymisation techniques employed against Tor users. This paper presents two novel WF techniques based on Graph Neural Networks (GNNs) to explore two relatively understudied avenues of WF: the fingerprintability of Decentralised Applications (DApps) and the impact of reload traffic on WF. Due to the lack of publicly available datasets for DApp traffic and reload traffic suitable for WF, we collected five new datasets for our experiments. Our findings reveal that GNN-based techniques surpass the performance of state-of-the-art WF techniques when reload traffic is used. Meanwhile, certain high-performing state-of-the-art techniques exhibit a significant reduction in accuracy, more than 40%, when reload traffic is used instead of homepage traffic. Additionally, we identify that DApps are less susceptible to fingerprinting than conventional websites, leading to a 25% decrease in accuracy in some state-of-the-art WF techniques. While confirming prior research findings that GNN-based techniques can outperform existing techniques when accessing DApps via Chrome, we further demonstrate that using Tor to access DApps makes them even more difficult to fingerprint. Finally, we expect our datasets, four of which lack publicly available alternatives, will prove invaluable for future research.}
}


@article{DBLP:journals/tifs/YangL24,
	author = {Xuan Yang and
                  Dongming Li},
	title = {{LED-RFF:} {LTE} DMRS-Based Channel Robust Radio Frequency Fingerprint
                  Identification Scheme},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1855--1869},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3343079},
	doi = {10.1109/TIFS.2023.3343079},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In physical-layer security schemes, radio frequency fingerprint (RFF) identification is vulnerable to the channel variations, and the identification of the long term evolution (LTE) mobile devices deserves further investigation. In this paper, we propose an RFF extraction method based on the LTE demodulation reference signal (DMRS) processing which can mitigate the channel impairments during the RFF extraction process. First, we analyze the impacts of RFF and the multipath channel on the DMRS in the LTE physical uplink shared channel and take the flexible time-frequency resource block allocations into account. Then, we propose an RFF extraction method based on the wavelet decomposition and reconstruction of the DMRS signals. It is found that the in-phase/quadrature (IQ) direct current offset and the frequency-dependent IQ imbalance mainly affect high-frequency components of the frequency domain DMRS signals, while the power amplifier memory nonlinearity and the channel effects mainly influence the low-frequency components. By removing the low-frequency components of the frequency domain DMRS signals, the proposed method is robust to the channel impairments. Finally, the simulation and experimental results show that our method can effectively reduce the channel impacts and retain the device RFF. The effectiveness of this method is verified via different classification tasks. The classification accuracy can reach 98.5% and 93.9% in the stationary and mobile scenarios, respectively. Meanwhile, by combining the training sets collected in the static and the moving scenarios together in the training process, the model can achieve better classification performance.}
}


@article{DBLP:journals/tifs/YinZSG24,
	author = {Zhenqin Yin and
                  Xinmin Zhang and
                  Zhihuan Song and
                  Zhiqiang Ge},
	title = {Adversarial Learning From Imbalanced Data: {A} Robust Industrial Fault
                  Classification Method},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1870--1882},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3343073},
	doi = {10.1109/TIFS.2023.3343073},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YinZSG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data-driven models are revealed to be vulnerable to adversarial examples, so improving the model’s adversarial robustness has attracted extensive research. However, in real-world industrial processes, the difficulty of collecting data for different fault types varies, leading to imbalanced data, which poses significant obstacles to adversarial robust learning. Furthermore, it results in inaccurate boundary learning, poor robustness, and overfitting to the majority class in common empirical adversarial training methods. To overcome these problems, we propose a balanced adversarial learning strategy. On the one hand, the balanced generalization processing penalizes the imbalance in the generation of adversarial variant in inner training, and calibrates the confidence using the class-aware label smoothing in outer training, so as to learn more accurate boundaries with better game relations. On the other hand, it involves robust regularization processing, which adopts the smooth augmentation of adversarial examples in the input and the addition of data-related soft label regularization to learn good generalization with enriched information. The proposed method is validated on two industrial fault classification benchmarks with imbalanced data, and comparisons with related methods demonstrate that our approach achieves better standard and robust performance.}
}


@article{DBLP:journals/tifs/BiLHNWW24,
	author = {Siguo Bi and
                  Kai Li and
                  Shuyan Hu and
                  Wei Ni and
                  Cong Wang and
                  Xin Wang},
	title = {Detection and Mitigation of Position Spoofing Attacks on Cooperative
                  {UAV} Swarm Formations},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1883--1895},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3341398},
	doi = {10.1109/TIFS.2023.3341398},
	timestamp = {Sat, 13 Jan 2024 17:35:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BiLHNWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting spoofing attacks on the positions of unmanned aerial vehicles (UAVs) within a swarm is challenging. Traditional methods relying solely on individually reported positions and pairwise distance measurements are ineffective in identifying the misbehavior of malicious UAVs. This paper presents a novel systematic structure designed to detect and mitigate spoofing attacks in UAV swarms. We formulate the problem of detecting malicious UAVs as a localization feasibility problem, leveraging the reported positions and distance measurements. To address this problem, we develop a semidefinite relaxation (SDR) approach, which reformulates the non-convex localization problem into a convex and tractable semidefinite program (SDP). Additionally, we propose two innovative algorithms that leverage the proximity of neighboring UAVs to identify malicious UAVs effectively. Simulations demonstrate the superior performance of our proposed approaches compared to existing benchmarks. Our methods exhibit robustness across various swarm networks, showcasing their effectiveness in detecting and mitigating spoofing attacks. Specifically, the detection success rate is improved by up to 65%, 55%, and 51% against distributed, collusion, and mixed attacks, respectively, compared to the benchmarks.}
}


@article{DBLP:journals/tifs/JingHGWHW24,
	author = {Tao Jing and
                  Hongyan Huang and
                  Qinghe Gao and
                  Yue Wu and
                  Yan Huo and
                  Yawei Wang},
	title = {Multi-User Physical Layer Authentication Based on {CSI} Using ResNet
                  in Mobile IIoT},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1896--1907},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340090},
	doi = {10.1109/TIFS.2023.3340090},
	timestamp = {Tue, 16 Jan 2024 20:23:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JingHGWHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the context of the industrial Internet of Things (IIoT), communication devices are typically mobile, increasing the complexity and diversity of channels due to metal device occlusion. A crucial aspect of this intricate environment is the development of an authentication scheme based on physical layer channel characteristics. One approach to achieving this is through deep learning, which is a hot topic in physical layer authentication. However, designing a network that is suitable for channel classification tasks and establishing a reasonable training procedure that leads to high authentication accuracy can be challenging. To address the physical layer authentication of mobile devices in IIoT, we implement ResNet to extract channel features of Channel State Information (CSI) from different transmitters and classify them at the network output layer, enabling authentication decisions based on classification results. To improve accuracy and speed up network convergence, we utilize the exponentially averaging data augmentation algorithm and parameter-based transfer learning strategy during the training procedure. Simulation results demonstrate that multi-user physical layer authentication based on ResNet can achieve higher authentication accuracy as the number of network layers increases. The data augmentation and transfer learning are proved to improve the authentication accuracy. Numerical results on NIST industrial datasets reveal that the authentication scheme based on ResNet50 can achieve 99.64% authentication accuracy in scenarios with four users present, which is 32.68% higher than existing algorithm.}
}


@article{DBLP:journals/tifs/SuoCCPXL24,
	author = {Yuhan Suo and
                  Senchun Chai and
                  Runqi Chai and
                  Zhong{-}Hua Pang and
                  Yuanqing Xia and
                  Guo{-}Ping Liu},
	title = {Security Defense of Large-Scale Networks Under False Data Injection
                  Attacks: An Attack Detection Scheduling Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1908--1921},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340098},
	doi = {10.1109/TIFS.2023.3340098},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SuoCCPXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In large-scale networks, communication links between nodes are easily injected with false data by adversaries. This paper proposes a novel security defense strategy from the perspective of attack detection scheduling to ensure the security of the network. Based on the proposed strategy, each sensor can directly exclude suspicious sensors from its neighboring set. First, the problem of selecting suspicious sensors is formulated as a combinatorial optimization problem, which is non-deterministic polynomial-time hard (NP-hard). To solve this problem, the original function is transformed into a submodular function. Then, we propose an attack detection scheduling algorithm based on the sequential submodular optimization theory, which incorporates expert problem to better utilize historical information to guide the sensor selection task at the current moment. For different attack strategies, theoretical results show that the average optimization rate of the proposed algorithm has a lower bound, and the error expectation is bounded. In addition, under two kinds of insecurity conditions, the proposed algorithm can guarantee the security of the entire network from the perspective of the augmented estimation error. Finally, the effectiveness of the developed method is verified by the numerical simulation and practical experiment.}
}


@article{DBLP:journals/tifs/LiuXWZ24,
	author = {Jiawei Liu and
                  Jingyi Xie and
                  Yang Wang and
                  Zheng{-}Jun Zha},
	title = {Adaptive Texture and Spectrum Clue Mining for Generalizable Face Forgery
                  Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1922--1934},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3344293},
	doi = {10.1109/TIFS.2023.3344293},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuXWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although existing face forgery detection methods achieve satisfactory performance under closed within-dataset scenario where training and testing sets are created by the same manipulation technique, they are vulnerable to samples created by unseen manipulation techniques under cross-dataset scenario. To solve this problem, in this work, we propose a novel adaptive texture and spectral clue mining (ATSC) approach for generalizable face forgery detection. It adaptively adjusts the parameters depended on input images to mine specific intrinsic forgery clues on both spatial and frequency domains. Specifically, ATSC customizes a Texture Clue Mining Module and a Spectrum Clue Selecting Module. The former module exploits instance-aware dynamic convolution on spatial domain to dynamically assemble multiple parallel convolutional kernels based on the learned image-dependent attention maps for effectively capturing subtle texture artifacts on spatial domain. A customized attention loss is also applied to the attention maps as supervision to precisely localize forgery artifacts whilst retain useful background information from suspicious and non-suspicious regions, which drives the module to explore all potential crucial clues and learning robust texture-related forgery feature. Moreover, the latter module applies adaptive frequency filtering mechanism on DCT-based frequency signals, which selects frequency information of interest to capture refined spectrum clues on frequency domain in an input-adaptive manner. Equipped with the above two modules, ATSC can learn more generalizable forgery features for face forgery detection. Extensive experimental results demonstrate the superior generalization ability of the proposed ATSC over various state-of-the-art methods on the challenging benchmarks.}
}


@article{DBLP:journals/tifs/MaoTLZC24,
	author = {Junlong Mao and
                  Huiyi Tang and
                  Shanxiang Lyu and
                  Zhengchun Zhou and
                  Xiaochun Cao},
	title = {Content-Aware Quantization Index Modulation: Leveraging Data Statistics
                  for Enhanced Image Watermarking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1935--1947},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3342612},
	doi = {10.1109/TIFS.2023.3342612},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MaoTLZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image watermarking techniques have continuously evolved to address new challenges and incorporate advanced features. The advent of data-driven approaches has enabled the processing and analysis of large volumes of data, extracting valuable insights and patterns. In this paper, we propose two content-aware quantization index modulation (QIM) algorithms: Content-Aware QIM (CA-QIM) and Content-Aware Minimum Distortion QIM (CAMD-QIM). These algorithms aim to improve the embedding distortion of QIM-based watermarking schemes by considering the statistics of the cover signal vectors and messages. CA-QIM introduces a canonical labeling approach, where the closest coset to each cover vector is determined during the embedding process. An adjacency matrix is constructed to capture the relationships between the cover vectors and messages. CAMD-QIM extends the concept of minimum distortion (MD) principle to content-aware QIM. Instead of quantizing the carriers to lattice points, CAMD-QIM quantizes them to close points in the correct decoding region. Canonical labeling is also employed in CAMD-QIM to enhance its performance. Both schemes can be categorized as (key-aided) semi-blind watermarking. Simulation results demonstrate the effectiveness of CA-QIM and CAMD-QIM in reducing embedding distortion compared to traditional QIM. The combination of canonical labeling and the minimum distortion principle proves to be powerful, minimizing the need for changes to most cover vectors/carriers. These content-aware QIM algorithms provide improved performance and robustness for watermarking applications.}
}


@article{DBLP:journals/tifs/ChenLYBLR24,
	author = {Meng Chen and
                  Li Lu and
                  Jiadi Yu and
                  Zhongjie Ba and
                  Feng Lin and
                  Kui Ren},
	title = {AdvReverb: Rethinking the Stealthiness of Audio Adversarial Examples
                  to Human Perception},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1948--1962},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3345639},
	doi = {10.1109/TIFS.2023.3345639},
	timestamp = {Wed, 30 Oct 2024 17:26:00 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenLYBLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As one of the most representative applications built on deep learning, audio systems, including keyword spotting, automatic speech recognition, and speaker identification, have recently been demonstrated to be vulnerable to adversarial examples, which have already raised general concerns in both academia and industry. Existing attacks follow the same adversarial example generation paradigm from computer vision, i.e., overlaying the optimized additive perturbations on original voices. However, due to the additive perturbations’ nature on human audibility, balancing the stealthiness and attack capability remains a challenging problem. In this paper, we rethink the stealthiness of audio adversarial examples and turn to introduce another kind of audio distortion, i.e., reverberation, as a new perturbation format for stealthy adversarial example generation. Such convolutional adversarial perturbations are crafted as real-world impulse responses and behave as a natural reverberation for deceiving humans. Based on this idea, we propose AdvReverb to construct, optimize, and deliver phoneme-level convolutional adversarial perturbations on both speech and music carriers with a well-designed objective. Experimental results demonstrate that AdvReverb could realize high attack success rates over 95% on three audio-domain tasks while achieving superior perceptual quality and keeping stealthy from human perception in over-the-air and over-the-line delivery scenarios.}
}


@article{DBLP:journals/tifs/WangSBXDL24,
	author = {Yuntao Wang and
                  Zhou Su and
                  Abderrahim Benslimane and
                  Qichao Xu and
                  Minghui Dai and
                  Ruidong Li},
	title = {Collaborative Honeypot Defense in {UAV} Networks: {A} Learning-Based
                  Game Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1963--1978},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318942},
	doi = {10.1109/TIFS.2023.3318942},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangSBXDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of unmanned aerial vehicles (UAVs) opens up new opportunities for on-demand service provision anywhere and anytime, but also exposes UAVs to a variety of cyber threats. Low/medium interaction honeypots offer a promising lightweight defense for actively protecting mobile Internet of things, particularly UAV networks. While previous research has primarily focused on honeypot system design and attack pattern recognition, the incentive issue for motivating UAVs’ participation (e.g., sharing trapped attack data in honeypots) to collaboratively resist distributed and sophisticated attacks remains unexplored. This paper proposes a novel game-theoretical collaborative defense approach to address optimal, fair, and feasible incentive design, in the presence of network dynamics and UAVs’ multi-dimensional private information (e.g., valid defense data (VDD) volume, communication delay, and UAV cost). Specifically, we first develop a honeypot game between UAVs and the network operator under both partial and complete information asymmetry scenarios. The optimal VDD-reward contract design problem with partial information asymmetry is then solved using a contract-theoretic approach that ensures budget feasibility, truthfulness, fairness, and computational efficiency. In addition, under complete information asymmetry, we devise a distributed reinforcement learning algorithm to dynamically design optimal contracts for distinct types of UAVs in the time-varying UAV network. Extensive simulations demonstrate that the proposed scheme can motivate UAV’s cooperation in VDD sharing and improve defensive effectiveness, compared with conventional schemes.}
}


@article{DBLP:journals/tifs/ZhangXWLYZ24,
	author = {Chuan Zhang and
                  Haojun Xuan and
                  Tong Wu and
                  Ximeng Liu and
                  Guomin Yang and
                  Liehuang Zhu},
	title = {Blockchain-Based Dynamic Time-Encapsulated Data Auditing for Outsourcing
                  Storage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1979--1993},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3338485},
	doi = {10.1109/TIFS.2023.3338485},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangXWLYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outsourcing storage has emerged as an effective solution to manage the increasing volume of data. With the popularity of pay-as-you-go payment models in outsourcing storage, data auditing schemes that prioritize timeliness can be valuable evidence for elastic bill settlement. Unfortunately, existing data auditing schemes do not sufficiently consider timeliness during auditing. Furthermore, practical data auditing schemes should have the capability to check the integrity of scalable data. In this paper, we propose a blockchain-based dynamic data auditing scheme with strong timeliness to ensure that data stored in outsourcing storage systems remain intact. Our scheme encapsulates timestamps into homomorphic verifiable tags to simultaneously check data integrity and timestamp validity. To achieve dynamicity, we utilize the Merkle hash tree to store the tags, allowing for block-level dynamic operations. Additionally, by leveraging the transparency, non-repudiation, and tamper resistance of blockchain technology, we design a blockchain-based data auditing framework to prevent malicious behavior from all entities. We then formally prove the soundness and privacy of our scheme. Finally, we conduct theoretical analysis and experimental evaluation to demonstrate that the performance of our scheme is of acceptable efficiency to existing works in terms of computation cost, communication overhead, and storage overhead.}
}


@article{DBLP:journals/tifs/WuLFYCZS24,
	author = {Jiajing Wu and
                  Dan Lin and
                  Qishuang Fu and
                  Shuo Yang and
                  Ting Chen and
                  Zibin Zheng and
                  Bowen Song},
	title = {Toward Understanding Asset Flows in Crypto Money Laundering Through
                  the Lenses of Ethereum Heists},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {1994--2009},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3346276},
	doi = {10.1109/TIFS.2023.3346276},
	timestamp = {Sun, 06 Oct 2024 21:41:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuLFYCZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the overall momentum of the blockchain industry, financial crimes related to blockchain crypto-assets are becoming increasingly prevalent. After committing a crime, the main goal of cybercriminals is to obfuscate the source of the illicit funds in order to convert them into cash and get away with it. Many studies have analyzed money laundering (ML) in the field of the traditional financial sector. However, in terms of the emerging blockchain crypto-asset ecosystem, there is currently only one public anti-money laundering (AML) dataset for Bitcoin– the Elliptic dataset, whose binary labels (licit vs. illicit transactions) cannot cover the ML behaviors in the evergrowing crypto-asset market. To fill this gap, in this paper, we propose a framework named XBlockFlow which identifies ML addresses starting from Ethereum heist incidents and obtains the first detailed Ethereum ML dataset named \\textit {EthereumHeist} , and then conducts a comprehensive feature and evolution analysis on the \\textit {EthereumHeist} dataset according to the three main phases of ML. We first search for the source cybercriminal accounts including exchange hackers, DeFi exploiters, and scammers. Then, employing the idea of taint analysis, we track the diverse downstream transactions and addresses layer by layer. At the end of tracking, we identify and categorize service providers, and go a step further to investigate advanced ML methods that do not exist in the Bitcoin scenario, e.g. token swap and counterfeit token creation. Based on the ML identification results, we obtain many interesting findings about crypto-asset money laundering, observing the escalating money laundering methods such as creating counterfeit tokens and masquerading as speculators.}
}


@article{DBLP:journals/tifs/OzfaturaOKG24,
	author = {Kerem Ozfatura and
                  Emre Ozfatura and
                  Alptekin K{\"{u}}p{\c{c}}{\"{u}} and
                  Deniz G{\"{u}}nd{\"{u}}z},
	title = {Byzantines Can Also Learn From History: Fall of Centered Clipping
                  in Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2010--2022},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3345171},
	doi = {10.1109/TIFS.2023.3345171},
	timestamp = {Mon, 05 Feb 2024 20:21:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/OzfaturaOKG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing popularity of the federated learning (FL) framework due to its success in a wide range of collaborative learning tasks also induces certain security concerns. Among many vulnerabilities, the risk of Byzantine attacks is of particular concern, which refers to the possibility of malicious clients participating in the learning process. Hence, a crucial objective in FL is to neutralize the potential impact of Byzantine attacks and to ensure that the final model is trustable. It has been observed that the higher the variance among the clients’ models/updates, the more space there is for Byzantine attacks to be hidden. As a consequence, by utilizing momentum, and thus, reducing the variance, it is possible to weaken the strength of known Byzantine attacks. The centered clipping (CC) framework has further shown that the momentum term from the previous iteration, besides reducing the variance, can be used as a reference point to neutralize Byzantine attacks better. In this work, we first expose vulnerabilities of the CC framework, and introduce a novel attack strategy that can circumvent the defences of CC and other robust aggregators and reduce their test accuracy up to %33 on best-case scenarios in image classification tasks. Then, we propose a new robust and fast defence mechanism that is effective against the proposed and other existing Byzantine attacks.}
}


@article{DBLP:journals/tifs/LiuLZFLL24,
	author = {Chen Liu and
                  Bo Li and
                  Jun Zhao and
                  Weiwei Feng and
                  Xudong Liu and
                  Chunpei Li},
	title = {{A2-CLM:} Few-Shot Malware Detection Based on Adversarial Heterogeneous
                  Graph Augmentation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2023--2038},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3345640},
	doi = {10.1109/TIFS.2023.3345640},
	timestamp = {Wed, 14 Aug 2024 08:24:55 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLZFLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware attacks, especially “few-shot” malware, have profoundly harmed the cyber ecosystem. Recently, malware detection models based on graph neural networks have achieved remarkable success. However, these efforts over-rely on sufficient labeled data for model training and thus may be brittle in few-shot malware detection because of the label scarcity. To this end, we propose a self-supervised malware detection framework based on graph contrastive learning and adversarial augmentation, termed A2-CLM, to address the challenge of few-shot malware detection. Particularly, A2-CLM first depicts the malware execution context with a sensitivity heterogeneous graph by assessing the security semantic of each behavior. Afterwards, A2-CLM designs multiple adversarial attacks to generate more practical contrastive pairs, including the PGD attack, attribute masking attack, meta-graph-guide sampling attack, direct system calls attack, and obfuscation attack, which is beneficial to strengthening the model’s effectiveness and robustness. To alleviate the training workload of contrastive learning, we introduce a momentum strategy to train the multiple graph encoders in A2-CLM. Especially on 1-shot detection tasks, A2-CLM achieves performance gains of up to 24.63% and 4.58% against supervised and self-supervised detection methods, respectively.}
}


@article{DBLP:journals/tifs/CrosaraATL24,
	author = {Laura Crosara and
                  Francesco Ardizzon and
                  Stefano Tomasin and
                  Nicola Laurenti},
	title = {Worst-Case Spoofing Attack and Robust Countermeasure in Satellite
                  Navigation Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2039--2050},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3340061},
	doi = {10.1109/TIFS.2023.3340061},
	timestamp = {Fri, 08 Mar 2024 13:21:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CrosaraATL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The threat of signal spoofing attacks against global navigation satellite system (GNSS) has grown in recent years and has motivated the study of anti-spoofing techniques. However, defense methods have been designed only against specific attacks. This paper introduces a general model of the spoofing attack framework in GNSS, from which optimal attack and defense strategies are derived. We consider a scenario with a legitimate receiver (Bob) testing if the received signals come from multiple legitimate space vehicles (Alice) or from an attack device (Eve). We first derive the optimal attack strategy against a Gaussian transmission from Alice, by minimizing an outer bound on the achievable error probability region of the spoofing detection test. Then, framing the spoofing and its detection as an adversarial game, we show that the Gaussian transmission and the corresponding optimal attack constitute a Nash equilibrium. Lastly, we consider the case of practical modulation schemes for Alice and derive the generalized likelihood ratio test. Numerical results validate the analytical derivations and show that the bound on the achievable error region is representative of the actual performance.}
}


@article{DBLP:journals/tifs/HuSV24,
	author = {Fanliang Hu and
                  Jian Shen and
                  Pandi Vijayakumar},
	title = {Side-Channel Attacks Based on Multi-Loss Regularized Denoising AutoEncoder},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2051--2065},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3343947},
	doi = {10.1109/TIFS.2023.3343947},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuSV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, researchers have leveraged the Denoising AutoEncoder (DAE) to reduce the noise in side-channel acquisitions (a.k.a. traces) that reduces the effectiveness of key recovery. Taking the {L}2\nLoss (Mean Square Error, MSE) as the objective function of the DAE, it only aims to lessen the Euclidean Distance (ED) between the input and output, overlooking the Intra-Data Correlation (IDC) of the trace which includes the timing information. This paper proposes the Multi-Loss Regularized Denoising AutoEncoder (ML-DAE) framework to improve the generalization capability of the DAE. This framework consists of a shared DAE and Multiple Loss (ML) functions that aim to reduce the noise while preserving the excellent IDC of the output. During the training phase, to avoid issues of overfitting and a high number of training parameters, we pre-train the DAE using MSE and then initiate the ML-DAE which contains a multicore Partial Loss (PL) function with parameters transferred from the pre-trained DAE. During the testing phase, the outputs from the multicore PL are fused using an average pooling layer to yield the final predictions. The experiments on highly noisy datasets (XMEGA_ME, DPA_V2, and AES_GPU) and the masked dataset ASCAD demonstrate that ML-DAE achieves an SNR gain of at least four times, hence Deep-Learning based Side-Channel Attacks (DLSCAs) and Template Attacks (TA) with denoising pre-processing reduce of the number of traces needed to recover the key in the attack phase by more than 55%.}
}


@article{DBLP:journals/tifs/DanieliGAL24,
	author = {Erez Danieli and
                  Menachem Goldzweig and
                  Moshe Avital and
                  Itamar Levi},
	title = {Revealing the Secrets of Radio Embedded Systems: Extraction of Raw
                  Information via {RF}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2066--2081},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3345131},
	doi = {10.1109/TIFS.2023.3345131},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DanieliGAL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article discusses the critical issue of the remote extraction of information from radio-enabled embedded systems, and focuses on sources emanating from micrometer wavelengths. These sources include intra-chip or inter-device buses and board-level routing traces, within tens of centimeters of the system’s transmission antenna or front end (FE). Traditionally, side-channel analysis (SCA) attacks center on micrometer-level signal that emanate direct near-field information detectable within centimeters. Simple power analysis (SPA) attacks focus similarly over stronger signals and fewer statistics. Here, however, we turn to typically larger elements corresponding to larger wavelengths than previously reported. Recent discoveries reveal that radio-enabled systems can transmit data over far-field distances, which can be analyzed via SCA-like methods. Studies have also described direct data extraction from centimeter to tens of centimeters-scale sources such as SATA, USB, and others. These sources act as substantial transmission antennas. This article differs considerably from these works, since it targets intermediate wavelengths which find their way to leak into the RF-FE. We document a significant security challenge: nearly all signals within embedded systems, even serial ports, DMA-controlled memory access, and others, leak what can be considered to practically be raw information with high-SNR over tens of centimeters to the RF-FE. This has strong implications for signal integrity, security, and standards related to electromagnetic compatibility (EMC), signal shielding, and interference (EMI, RFI). We show that onboard signals with galvanic connections to the RF-FE-chip and onboard signals without galvanic connections to the RF-FE-chip are coupled, amplified and transmitted with high SNR, which enables quasi-raw extraction. We further demonstrate how sophisticated adversaries can build code-injection gadgets that can carry sensitive data and modulate the stream to be optimally extracted by the RF-channel. Practical demonstrations using commercial and low-cost equipment reinforce our claims. Specifically, we show that without concrete interference and isolation standards designed with security in mind, mitigating these leakages remains a challenge.}
}


@article{DBLP:journals/tifs/BazziC24,
	author = {Ahmad Bazzi and
                  Marwa Chafii},
	title = {Secure Full Duplex Integrated Sensing and Communications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2082--2097},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3346696},
	doi = {10.1109/TIFS.2023.3346696},
	timestamp = {Tue, 07 May 2024 20:18:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BazziC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The following paper models a secure full duplex (FD) integrated sensing and communication (ISAC) scenario, where malicious eavesdroppers aim at intercepting the downlink (DL) as well as the uplink (UL) information exchanged between the dual functional radar and communication (DFRC) base station (BS) and a set of communication users. The DFRC BS, on the other hand, aims at illuminating radar beams at the eavesdroppers in order to sense their physical parameters, while maintaining high UL/DL secrecy rates. Based on the proposed model, we formulate a power efficient secure ISAC optimization framework design, which is intended to guarantee both UL and DL secrecy rates requirements, while illuminating radar beams towards eavesdroppers. The framework exploits artificial noise (AN) generation at the DFRC BS, along with UL/DL beamforming design and UL power allocation. We propose a beamforming design solution to the secure ISAC optimization problem. Finally, we corroborate our findings via simulation results and demonstrate the feasibility, as well as the superiority of the proposed algorithm, under different situations. We also reveal insightful trade-offs achieved by our approach.}
}


@article{DBLP:journals/tifs/UddinYJO24,
	author = {Kutub Uddin and
                  Yoonmo Yang and
                  Tae Hyun Jeong and
                  Byung Tae Oh},
	title = {A Robust Open-Set Multi-Instance Learning for Defending Adversarial
                  Attacks in Digital Image},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2098--2111},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3346211},
	doi = {10.1109/TIFS.2023.3346211},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/UddinYJO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent times, digital image forensics is gaining increased attention in multimedia forensics owing to the widespread scam alertness. Several forensic methods have been studied to establish the integrity of digital images by disclosing manipulation fingerprints. Anti-forensic (AF) attacks on manipulated images, particularly deep learning-based adversarial attacks using generative adversarial network (GAN), have been successfully applied to delude forensic methods. Consequently, an efficacious, efficient, and robust counter-AF (CAF) method is required to secure the integrity of digital images. In this study, we propose a robust open-set multi-instance learning approach for exposing GAN-based AF on manipulated images by introducing additional GAN-based operations. First, we generate multiple real instances from real images using multiple additional generators. Then we train an embedding network collaboratively with multiple real instances in an open-set fashion. During training, the embedding network learns only real images and has no prior knowledge regarding AF images. In the testing phase, real and AF images are processed for detection. The proposed open-set CAF method can effectively detect AF images and is more robust against transferable updating.}
}


@article{DBLP:journals/tifs/YangHH24,
	author = {Yiming Yang and
                  Weipeng Hu and
                  Haifeng Hu},
	title = {Unsupervised {NIR-VIS} Face Recognition via Homogeneous-to-Heterogeneous
                  Learning and Residual-Invariant Enhancement},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2112--2126},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3346176},
	doi = {10.1109/TIFS.2023.3346176},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Near-Infrared and Visible light (NIR-VIS) face recognition methods have achieved remarkable success in the fields of security surveillance, criminal investigation, and multimedia information retrieval. But the existing methods heavily rely on carefully annotated labels, leading to expensive manual labelling consumption and deployment flexibility. This motivates us to design unsupervised methods to address NIR-VIS recognition without relying on label information. To this end, we propose a novel homogeneous-to-HEterogeneous learning and Residual-invariant Enhancement (HERE) network for Unsupervised NIR-VIS Heterogeneous Face Recognition (NIR-VIS-UHFR). As the name suggests, the optimization of HERE follow a ”homogeneous-to-heterogeneous learning” strategy to fully explore complementary and common semantic information across different modalities. During the homogeneous learning phase, Modality-Adversarial Contrastive Learning (MACL) leverages the collaboration of modality contrastive learning and adversarial learning. On the one hand, MACL learns compact and discriminative intra-modal representations for NIR and VIS data, respectively. On the other hand, MACL guarantees that NIR-VIS data conform to the common feature distribution in a shared feature space, effectively reducing modal differences even in the absence of identity information between modalities. In the heterogeneous learning phase, K-reciprocal-Encoding-based Cross-modal Labeling (KECL) is introduced as robust pseudo label estimation to fully explore cross-modal relationships and group cross-modal features into clusters. With the pseudo labels provided by KECL, Refined cross-modal Contrastive Learning (RCL) is developed with modality-invariant averaging initialization and dynamic focus weighting strategies to extract modality-invariant features. Finally, Residual-invariant Representations Enhancement (RRE) mines partial features under the cross-modal face for robust matching. Compared to supervised methods, our unsupervised HERE demonstrates comparable performance on multiple datasets, greater scalability and practicality in deployment by reducing data acquisition requirements and costs.}
}


@article{DBLP:journals/tifs/FanHSFYL24,
	author = {Linkun Fan and
                  Fazhi He and
                  Tongzhen Si and
                  Rubin Fan and
                  Chuanlong Ye and
                  Bing Li},
	title = {{MBA:} Backdoor Attacks Against 3D Mesh Classifier},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2127--2142},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3346644},
	doi = {10.1109/TIFS.2023.3346644},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FanHSFYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {3D mesh classification deep neural network (3D DNN) has been widely applied in many safety-critical domains. Backdoor attack is a serious threat that occurs during the training stage. Previous backdoor attacks from 2D image and 3D point cloud domains are not suitable for 3D mesh due to data structure restrictions. Therefore, in a pioneering effort, this paper presents two types of backdoor attacks on 3D mesh. Specifically, the first attack is a Mesh Geometrical Feature guided 3D Mesh Backdoor Attack named MGF-MBA. Most 3D DNNs have to convert 3D mesh to a regular matrix (mesh geometrical feature), which is a refinement of the input 3D mesh. The 3D DNN directly learns the 3D shape from the mesh geometrical feature, which enables attackers to implant backdoor through it. Hence, the proposed MGF-MBA generates a backdoored 3D mesh under the guidance of mesh geometrical feature. The second attack is a Remeshing based 3D Mesh Backdoor Attack named ReMBA. The quality of samples backdoored by exiting backdoor attacks always decrease. Although many efforts have been made to reduce the descent in quality in return for stealthiness, the descent persists. For better stealthiness, we regard the backdoor implantation process as a way to increase the quality of backdoored sample rather than a way to reduce it. Specifically, ReMBA designs a new isotropic remeshing method that attempts to represent a 3D mesh by equilateral triangles while keeping the number of vertices, edges and faces unchanged. Numerous experimental results show that both MGF-MBA and ReMBA achieve guaranteed attack performance on 3D DNNs. Furthermore, transferability experiments demonstrate that ReMBA can even attack 3D point cloud networks with an increased ability to resist defenses.}
}


@article{DBLP:journals/tifs/FangS24,
	author = {Shengbang Fang and
                  Matthew C. Stamm},
	title = {Attacking Image Splicing Detection and Localization Algorithms Using
                  Synthetic Traces},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2143--2156},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3346312},
	doi = {10.1109/TIFS.2023.3346312},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FangS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in deep learning have enabled forensics researchers to develop a new class of image splicing detection and localization algorithms. These algorithms identify spliced content by detecting localized inconsistencies in forensic traces using Siamese neural networks, either explicitly during analysis or implicitly during training. At the same time, deep learning has enabled new forms of anti-forensic attacks, such as adversarial examples and generative adversarial network (GAN) based attacks. Thus far, however, no anti-forensic attack has been demonstrated against image splicing detection and localization algorithms. In this paper, we propose a new GAN-based anti-forensic attack that is able to fool state-of-the-art splicing detection and localization algorithms such as EXIF-Net, Noiseprint, and Forensic Similarity Graphs. This attack operates by adversarially training an anti-forensic generator against a set of Siamese neural networks so that it is able to create synthetic forensic traces. Under analysis, these synthetic traces appear authentic and are self-consistent throughout an image. Through a series of experiments, we demonstrate that our attack is capable of fooling forensic splicing detection and localization algorithms without introducing visually detectable artifacts into an attacked image. Additionally, we demonstrate that our attack outperforms existing alternative attack approaches.}
}


@article{DBLP:journals/tifs/TangZLDL24,
	author = {Wenbing Tang and
                  Yuan Zhou and
                  Yang Liu and
                  Zuohua Ding and
                  Jing Liu},
	title = {Robust Motion Planning for Multi-Robot Systems Against Position Deception
                  Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2157--2170},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3346647},
	doi = {10.1109/TIFS.2023.3346647},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TangZLDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep reinforcement learning (DRL) is widely applied in motion planning for multi-robot systems as DRL leverages the offline training process to improve the real-time computation efficiency. In DRL-based methods, the DRL models compute an action for a robot based on the states of its surrounding obstacles, including other robots in the system. They always assume that the number of obstacles is fixed and the obtained obstacles’ states are reliable. However, in the real world, a multi-robot system may suffer from various attacks, such as remote control attacks and network attacks, that cause wrong positions of the surrounding obstacles received by a robot. In this paper, we propose a robust motion planning method DAE-Crit-LSTM, integrating a denoising autoencoder (DAE) with DRL models, to mitigate such position deception attacks in environments with a different number of obstacles. DAE-Crit-LSTM shows the following two advantages. First, DAE-Crit-LSTM can be applied in benign and attacked scenarios and thus does not require any detector. It learns an encoder and a decoder to approximate the accurate positions of the obstacles, no matter under attack or not. Second, DAE-Crit-LSTM applies an LSTM (Long Short-Term Memory)-based DRL model to deal with a variable number of obstacles in the environment. It is worth noting that DAE-Crit-LSTM is method-agnostic and can be easily implemented in state-of-the-art motion planning methods. Comprehensive experiments show that DAE-Crit-LSTM can mitigate position deception attacks and guarantee safe motion. We also demonstrate the effectiveness and generalization of DAE-Crit-LSTM.}
}


@article{DBLP:journals/tifs/XiangLBLYLRC24,
	author = {Yuexin Xiang and
                  Yuchen Lei and
                  Ding Bao and
                  Tiantian Li and
                  Qingqing Yang and
                  Wenmao Liu and
                  Wei Ren and
                  Kim{-}Kwang Raymond Choo},
	title = {{BABD:} {A} Bitcoin Address Behavior Dataset for Pattern Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2171--2185},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3347894},
	doi = {10.1109/TIFS.2023.3347894},
	timestamp = {Sun, 19 Jan 2025 14:20:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XiangLBLYLRC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptocurrencies have dramatically increased adoption in mainstream applications in various fields such as financial and online services, however, there are still a few amounts of cryptocurrency transactions that involve illicit or criminal activities. It is essential to identify and monitor addresses associated with illegal behaviors to ensure the security and stability of the cryptocurrency ecosystem. In this paper, we propose a framework to build a dataset comprising Bitcoin transactions between 12 July 2019 and 26 May 2021. This dataset (hereafter referred to as BABD-13) contains 13 types of Bitcoin addresses, 5 categories of indicators with 148 features, and 544,462 labeled data, which is the largest labeled Bitcoin address behavior dataset publicly available to our knowledge. We also propose a novel and efficient subgraph generation algorithm called BTC-SubGen to extract a {k}\n-hop subgraph from the entire Bitcoin transaction graph constructed by the directed heterogeneous multigraph starting from a specific Bitcoin address node. We then conduct 13-class classification tasks on BABD-13 by five machine learning models namely {k}\n-nearest neighbors algorithm, decision tree, random forest, multilayer perceptron, and XGBoost, the results show that the accuracy rates are between 93.24% and 97.13%. In addition, we study the relations and importance of the proposed features and analyze how they affect the effect of machine learning models. Finally, we conduct a preliminary analysis of the behavior patterns of different types of Bitcoin addresses using concrete features and find several meaningful and explainable modes.}
}


@article{DBLP:journals/tifs/WeiYWG24,
	author = {Ziyu Wei and
                  Xi Yang and
                  Nannan Wang and
                  Xinbo Gao},
	title = {Dual-Adversarial Representation Disentanglement for Visible Infrared
                  Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2186--2200},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3344289},
	doi = {10.1109/TIFS.2023.3344289},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WeiYWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous pedestrian images are captured by visible and infrared cameras with different spectrums, which play an important role in night-time video surveillance. However, visible infrared person re-identification (VI-REID) is still a challenging problem due to the considerable cross-modality discrepancies. To extract modality-invariant features which are discriminative for the person identity, recent studies are inclined to regard modality-specific features as noise and discard them. Actually, the modality-specific characteristics containing background and color information are indispensable for learning modality-shared features. In this paper, we propose a novel Dual-Adversarial Representation Disentanglement (DARD) model to separate modality-specific features from tangled pedestrian representations and effectively learn the robust modality-invariant representations. Specifically, our method employs dual-adversarial learning, incorporating image-level channel exchange and feature-level magnitude change to introduce variations in modality-specific representations. This deliberate perturbation raises the learning difficulty for the model to learn modality-shared features. Simultaneously, to control the changing scope of modality-specific features, bi-constrained noise alleviation is introduced during adversarial learning, keeping the balance of feature generation and adversary. The proposed dual-adversarial learning methodology enhances the robustness against cross-modality visual discrepancy and strengthens the discriminative power of the learned modality-shared representations without introducing additional network parameters. This improvement further elevates the retrieval performance of VI-REID. Extensive experiments with insightful analysis on two cross-modality re-identification datasets verify the effectiveness and superiority of the proposed DARD method.}
}


@article{DBLP:journals/tifs/LingTCSXLTHQ24,
	author = {Guowei Ling and
                  Fei Tang and
                  Chaochao Cai and
                  Jinyong Shan and
                  Haiyang Xue and
                  Wulu Li and
                  Peng Tang and
                  Xinyi Huang and
                  Weidong Qiu},
	title = {P{\({^2}\)}FRPSI: Privacy-Preserving Feature Retrieved Private Set
                  Intersection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2201--2216},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3343973},
	doi = {10.1109/TIFS.2023.3343973},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LingTCSXLTHQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private Set Intersection (PSI) protocols can securely compute the intersection of the private sets on the server and the client without revealing additional data. This work introduces the concept of Privacy-Preserving Feature Retrieved Private Set Intersection ( \\mathsf {P^{2}FRPSI} ). In \\mathsf {P^{2}FRPSI} protocols, the client can obtain the intersection that satisfies a given predicate without revealing the predicate and additional data. We formally define the \\mathsf {P^{2}FRPSI} protocol, including its inputs, outputs, functionality, and security. To achieve the privacy guarantee in \\mathsf {P^{2}FRPSI} protocols, a new two-party protocol is designed, namely Secure Secret Shared Retrieval ( \\mathsf {S^{3}R} ), which can be used to securely determine whether each item on the server satisfies the predicate. We construct an \\mathsf {S^{3}R} protocol and prove its security in the semi-honest model. On the basis of this, we design an efficient OT-based \\mathsf {P^{2}FRPSI} protocol and an easy-to-implement DH-based \\mathsf {P^{2}FRPSI} protocol and prove that they are secure in the semi-honest model. Our implementation shows that the OT-based \\mathsf {P^{2}FRPSI} protocol can perform the matching for about 1000K items in 3.8 seconds with a single thread. Moreover, the DH-based \\mathsf {P^{2}FRPSI} can perform the matching for about 7000K items in one hour with four threads, with communication totaling 1456 MB, while the OT-based \\mathsf {P^{2}FRPSI} protocol requires 1673 MB.}
}


@article{DBLP:journals/tifs/LiDWZMZZL24,
	author = {Meng Li and
                  Hanni Ding and
                  Qing Wang and
                  Mingwei Zhang and
                  Weizhi Meng and
                  Liehuang Zhu and
                  Zijian Zhang and
                  Xiaodong Lin},
	title = {Decentralized Threshold Signatures With Dynamically Private Accountability},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2217--2230},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3347968},
	doi = {10.1109/TIFS.2023.3347968},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiDWZMZZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Threshold signature is a fundamental cryptographic primitive used in many practical applications. As proposed by Boneh and Komlo (CRYPTO’22), TAPS is a threshold signature that is a hybrid of privacy and accountability. It enables a combiner to combine t signature shares while revealing nothing about the threshold t or signing quorum to the public and asks a tracer to track a signature to the quorum that generates it. However, TAPS has three disadvantages: it 1) structures upon a centralized model, 2) assumes that both combiner and tracer are honest, and 3) leaves the tracing unnotarized and static. In this work, we introduce Decentralized, Threshold, dynamically Accountable and Private Signature (DeTAPS) that provides decentralized combining and tracing, enhanced privacy against untrusted combiners (tracers), and notarized and dynamic tracing. Specifically, we adopt Dynamic Threshold Public-Key Encryption (DTPKE) to dynamically notarize the tracing process, design non-interactive zero knowledge proofs to achieve public verifiability of notaries, and utilize the Key-Aggregate Searchable Encryption to bridge TAPS and DTPKE so as to awaken the notaries securely and efficiently. In addition, we formalize the definitions and security requirements for DeTAPS. Then we present a concrete construction and formally prove its security and privacy. To evaluate the performance, we build a prototype based on SGX2 and Ethereum.}
}


@article{DBLP:journals/tifs/HanSLH24,
	author = {Jinguang Han and
                  Willy Susilo and
                  Nan Li and
                  Xinyi Huang},
	title = {{OLBS:} Oblivious Location-Based Services},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2231--2243},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3347874},
	doi = {10.1109/TIFS.2023.3347874},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HanSLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the growing use of mobile devices, location-based services (LBS) are becoming increasingly popular. BLS deliver accurate services to individuals according to their geographical locations, but privacy issues have been the primary concerns of users. Privacy-preserving LBS (PPLBS) were proposed to protect location privacy, but there are still some problems: 1) a semi-trusted third party (STTP) is required to blur users’ locations; 2) both the computation and communication costs of generating a query are linear with the size of queried areas; 3) the schemes were not formally treated, in terms of definition, security model, security proof, etc. In this paper, to protect location privacy and improve query efficiency, an oblivious location-based services (OLBS) scheme is proposed. Our scheme captures the following features: 1) an STTP is not required; 2) users can query services without revealing their exact location information; 3) the service provider only knows the size of queried areas and nothing else; and 4) both the computation and communication costs of generating a query is constant, instead of linear with the size of queried areas. We formalise both the definition and security model of our OLBS scheme, and propose a concrete construction. Furthermore, the implementation is conducted to show its efficiency. The security of our scheme is reduced to well-known complexity assumptions. The novelty is to reduce the computation and communication costs of generating a query and enable the service provider to obliviously generate decrypt keys for queried services. This contributes to the growing work of formalising PPLBS schemes and improving query efficiency.}
}


@article{DBLP:journals/tifs/GuoLLZLHZ24,
	author = {Zhenyu Guo and
                  Xin Li and
                  Jiamou Liu and
                  Zijian Zhang and
                  Meng Li and
                  Jingjing Hu and
                  Liehuang Zhu},
	title = {Graph-Based Covert Transaction Detection and Protection in Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2244--2257},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3347895},
	doi = {10.1109/TIFS.2023.3347895},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GuoLLZLHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Covert communication is an method that plays an important role in secure data transmission. The technology embeds covert information into data and propagates it through covert channels. The communication quality depends on the choice of channel and data embedding techniques. Recently, blockchain has emerged to become the preferred channel to carry out covert communication for its decentralization and anonymity features. Existing covert transaction methods are constructed transaction-by-transaction, which makes them immune to text analysis-based detection methods. However, it is easy to expose their features on the transaction graph level. Unfortunately, there is yet no method to detect covert transactions by the features of transaction graph. In this paper, we propose a covert transaction detection method based on graph structure. By analyzing the statistical features of graph structure for addresses, we can infer whether they are the participants of covert transactions. Furthermore, we design a protection method of covert transactions based on graph generation networks. By adjusting the structural features between different addresses, our method enhances the security of multiple interrelated covert transactions. Experimental analysis on the Bitcoin Testnet verifies the security and the efficiency of the proposed methods.}
}


@article{DBLP:journals/tifs/ZhangYZZWM24,
	author = {Fahong Zhang and
                  Chen Yang and
                  Rui Zong and
                  Xinran Zheng and
                  Jianfei Wang and
                  Yishuo Meng},
	title = {An Efficient and Scalable FHE-Based {PDQ} Scheme: Utilizing {FFT}
                  to Design a Low Multiplication Depth Large-Integer Comparison Algorithm},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2258--2272},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3348246},
	doi = {10.1109/TIFS.2023.3348246},
	timestamp = {Sun, 06 Oct 2024 21:41:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangYZZWM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing number of data privacy breaches and associated financial losses have driven the demand for private database queries. Clients typically submit queries that involve both search and computation operations, such as counting students under a certain age or calculating the BMI of employees above a specific age. Existing protocols often face limitations due to reliance on specific-purpose encryption schemes or multiple communication rounds between clients and servers. In this work, we present a unified framework utilizing fully homomorphic encryption techniques to efficiently and privately process queries with search and computation operations. Our contributions include a homomorphic encryption-based private comparison algorithm, called the layered comparison algorithm, which achieves a 2.6-6.6X performance improvement compared to algorithms from prior work; a fast Fourier transform-based preprocessing method enabling accurate large integer arithmetic operations in the encrypted domain; and a scalable database encoding method. Evaluation results demonstrate the practicality of our system, as it processes an aggregated query for a 1k-row encrypted database in approximately 4.53 seconds.}
}


@article{DBLP:journals/tifs/SunRHLZ24,
	author = {Zongkun Sun and
                  Yanzhen Ren and
                  Yihuan Huang and
                  Wuyang Liu and
                  Hongcheng Zhu},
	title = {{AFPM:} {A} Low-Cost and Universal Adversarial Defense for Speaker
                  Recognition Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2273--2287},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3348232},
	doi = {10.1109/TIFS.2023.3348232},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SunRHLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Speaker recognition systems (SRSs) are commonly used for biometric identification. However, these systems are vulnerable to adversarial attacks. Several defenses have been proposed but they require high costs in terms of additional data and computational resources to ensure robustness. To address these issues, this paper proposes a low-cost input reconstruction defense method called adaptive F-ratio-based partial masking (AFPM), which utilizes a robust feature extraction process to guarantee high defensibility. The underlying distribution of non-robust features is explored and filtered out by partial masking (PM), which helps maintain a low defense construction cost. An F-ratio-based PM (FPM) defense strategy is proposed by integrating the F-ratio, which reflects the weight of each frequency band for distinguishing between speakers, to balance classification accuracy and defensiveness. AFPM, which introduces an adaptive threshold calculation algorithm to FPM, is proposed to achieve further improved defensiveness and flexibility. Comparative experimental results show that AFPM is low-cost, highly defensive and universal. The construction process of AFPM does not involve training and its implementation does not require the protected SRSs to be retrained, only fine-tuned. While maintaining the classification accuracy at 99.42%, the average defense capability of AFPM against five white-box adaptive attacks is 90.89%, which is 9.23% better than that of the low-cost input reconstruction defense method and 3.77% better than that of the high-cost Parallel WaveGAN (PWG) defense approach. Against grey- and black-box adaptive attacks, FAKEBOB and Kenansville, AFPM reaches maximum defense effects of 96.01% and 74.49%, respectively, surpassing PWG by 4.5% and 65.82%. Furthermore, AFPM is universal and capable of protecting various SRSs against different attack strengths.}
}


@article{DBLP:journals/tifs/LaiSDG24,
	author = {Jianchang Lai and
                  Willy Susilo and
                  Robert H. Deng and
                  Fuchun Guo},
	title = {{SDSS:} Sequential Data Sharing System in IoT},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2288--2299},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3348229},
	doi = {10.1109/TIFS.2023.3348229},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LaiSDG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {E-healthcare as a significant facet of the Internet of Things (IoT) relies on wearable devices to continuously monitor users’ vital signals for health-related purposes. The sensitive and vast nature of the collected data necessitate secure encryption and storage on the cloud. Simultaneously, there is a need to share these data for healthcare purposes. How to balance the privacy and usability of these data is a challenging problem in the e-healthcare applications. A central problem arose from the continuous data collection is how to effectively share the data collected in one specific time period when users are unwell. We formalize it as the sequential data sharing problem. This problem appears in various IoT applications apart from e-healthcare, such as video surveillance. In this paper, we explain why all existing solutions cannot address the above problem. Then, we propose a novel sequential data sharing system (SDSS), where the data encrypted at any specific time period can be efficiently shared. We first present a practical construction of SDSS that supports securely sharing data within one specific time period in a symmetric manner. The decryption key are retrieved sequentially by utilizing the shared key and hash function. All involved calculations in the system are lightweight. Data pertaining to other non-selected time periods remain unknown. We then extend the SDSS to a multiple-range version, enabling simultaneous sharing data for multiple specific time periods, and show an example. We formalize the definition of security models and analyze the security of our systems. Finally, we evaluate the performance of our systems using SHA-256 and AES-256. Experimental results demonstrate that our systems are highly efficient. It takes less than 1 millisecond to encrypt 100KB data and less than 0.4 milliseconds to decrypt the corresponding cipher data. Our proposed systems provide a solution to balance the privacy and usability in the context of sequentially collected data. We believe that this work will enhance the adoption and practicality of IoT applications.}
}


@article{DBLP:journals/tifs/GuoJCW24,
	author = {Liang Guo and
                  Jie Jia and
                  Jian Chen and
                  Xingwei Wang},
	title = {Secure Communication Optimization in {NOMA} Systems With UAV-Mounted
                  {STAR-RIS}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2300--2314},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3348242},
	doi = {10.1109/TIFS.2023.3348242},
	timestamp = {Tue, 03 Dec 2024 17:09:08 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GuoJCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs), as a revolutionary technique, can boost transmission security by controlling unfavorable environments for signal eavesdropping and reducing interference. Integrating unmanned aerial vehicles (UAVs) with STAR-RISs has generated considerable interest due to its enhanced deployment flexibility. However, developing secure communication capabilities using flying STAR-RIS remains an open issue. Therefore, this work investigates the secrecy energy efficiency (SEE) maximization problem for the uplink non-orthogonal multiple access (NOMA) systems, where the UAV-mounted STAR-RIS is employed against the eavesdroppers. Specifically, we consider the joint optimization of the power control, the transmission/reflection coefficients, and the UAV/STAR-RIS’s placement for static and mobile scenarios. The problems are also subject to the minimum data rate requirements and the safety flight region. To tackle the intractable problems, we first adopt the iterative-based method to solve the problem under the static scenario. After that, we invoke the fractional programming and successive convex approximation methods to get the power control scheme, the semidefinite relaxation method to get the transmission/reflection (T/R) coefficients design, and the search-based method to obtain the UAV/STAR-RIS position. Extending to the mobile scenario, we adopt the double deep Q-network (DDQN) algorithm to learn the online UAV trajectory design policy from a long-term perspective. Numerical results unveil that: 1) the proposed iterative-based joint optimization algorithm for static scenarios achieves a near-optimal solution; 2) the NOMA communications aided by the UAV-mounted STAR-RIS achieve significant SEE gain over the conventional reflection-only RIS and the fixed STAR-RIS cases; 3) the DDQN-based algorithm for mobile scenario achieves a near-optimal solution and obtains a valuable performance gain over the short-sighted greedy algorithm.}
}


@article{DBLP:journals/tifs/GaoHSZ24,
	author = {Rui Gao and
                  Jiangshuai Huang and
                  Xiaojie Su and
                  Ling Zhao},
	title = {Adaptive Control of Strict-Feedback Nonlinear Systems Under Denial-of-Service:
                  {A} Synthetic Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2315--2327},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3347969},
	doi = {10.1109/TIFS.2023.3347969},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GaoHSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the adaptive control for a class of uncertain nonlinear systems under denial-of-service (DoS) attacks. We analyze the closed-loop system stability under DoS attacks in terms of attack duration, attack frequency and resting time duration respectively. Three scenarios of DoS attacks against the system stability are considered. Firstly, it is shown that if the duration of each attack is less than a given constant, asymptotical convergence of system output is still preserved. Secondly, if the bounds on the frequency and duration of attacks with respect to overall intervals meet certain conditions, the proposed event-triggered control scheme guarantees that all the closed-loop signals are globally bounded and the stabilization error converges to a ball with a radius arbitrarily small. Thirdly, if resting time duration meets certain conditions after an arbitrarily long attack, closed-loop boundedness is still preserved. Simulation results are shown to illustrate the effectiveness of the proposed control schemes.}
}


@article{DBLP:journals/tifs/LiuMZZ24,
	author = {Weidong Liu and
                  Xiaojun Mao and
                  Xiaofei Zhang and
                  Xin Zhang},
	title = {Efficient Sparse Least Absolute Deviation Regression With Differential
                  Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2328--2339},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3349054},
	doi = {10.1109/TIFS.2023.3349054},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuMZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, privacy-preserving machine learning algorithms have attracted increasing attention because of their important applications in many scientific fields. However, in the literature, most privacy-preserving algorithms demand learning objectives to be strongly convex and Lipschitz smooth, which thus cannot cover a wide class of robust loss functions (e.g., quantile/least absolute loss). In this work, we aim to develop a fast privacy-preserving learning solution for a sparse robust regression problem. Our learning loss consists of a robust least absolute loss and an \\ell _{1}\nsparse penalty term. To fast solve the non-smooth loss under a given privacy budget, we develop a Fast Robust And Privacy-Preserving Estimation (FRAPPE) algorithm for least absolute deviation regression. Our algorithm achieves a fast estimation by reformulating the sparse LAD problem as a penalized least square estimation problem and adopts a three-stage noise injection to guarantee the (\\epsilon,\\delta)\n-differential privacy. We show that our algorithm can achieve better privacy and statistical accuracy trade-off compared with the state-of-the-art privacy-preserving regression algorithms. In the end, we conduct experiments to verify the efficiency of our proposed FRAPPE algorithm.}
}


@article{DBLP:journals/tifs/LiZLTR24,
	author = {Yanbin Li and
                  Jiajie Zhu and
                  Zhe Liu and
                  Ming Tang and
                  Shougang Ren},
	title = {Deep Learning Gradient Visualization-Based Pre-Silicon Side-Channel
                  Leakage Location},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2340--2355},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350375},
	doi = {10.1109/TIFS.2024.3350375},
	timestamp = {Sat, 11 Jan 2025 00:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiZLTR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While side-channel attacks (SCAs) have become a significant threat to cryptographic algorithms, masking is considered as an effective countermeasure against SCAs. On the one hand, securely implementing the scheme is a challenging and error-prone task. It is essential to detect leakage in a complicated cryptographic circuit. However, the traditional method of leakage detection is always inaccuracy or time consumption. On the other hand, the deep learning-based power attacks have shown their threat to the masking without combining functions. Compared to the leakage detection done under the traditional provable security framework, the security evaluation against deep learning-based attacks at the pre-silicon stage has not been discussed. To this end, this paper investigates the strategies of leveraging the deep learning techniques to achieve an efficient leakage location method. In this paper, we present the first approach utilizing deep learning-based leakage location for both unprotected and protected implementations at the pre-silicon stage. Firstly, we propose the leakage location method named Gradient Visualization-based location (GVL), which provides leakage location at the different levels of design. Gradient visualization is known as a sensitivity analysis method to understand better how a natural network can learn to predict the sensitive label based on the input. We theoretically show how the gradient visualization can be used to locate leakage components in the netlist efficiently. Moreover, we link the result with the metric in deep learning-based leakage assessment, which fills the lack of leakage evaluation at the pre-silicon stage against deep learning-based SCAs. We further confirm the effectiveness of the proposed method on unprotected implementation, low entropy masked implementation, and provable secure masked implementation. The results show that the proposed methodology outperforms the traditional location methods in the masked cases, where the time consumption is reduced by about 2x to 10x with fewer false negatives and no false positives.}
}


@article{DBLP:journals/tifs/DouDXWXCJ24,
	author = {Haochen Dou and
                  Zhenwu Dan and
                  Peng Xu and
                  Wei Wang and
                  Shuning Xu and
                  Tianyang Chen and
                  Hai Jin},
	title = {Dynamic Searchable Symmetric Encryption With Strong Security and Robustness},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2370--2384},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350330},
	doi = {10.1109/TIFS.2024.3350330},
	timestamp = {Fri, 08 Mar 2024 13:21:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DouDXWXCJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic Searchable Symmetric Encryption (DSSE) is a prospective technique in the field of cloud storage for secure search over encrypted data. A DSSE client can issue update queries to an honest-but-curious server for adding or deleting his ciphertexts to or from the server and delegate keyword search over those ciphertexts to the server. Numerous investigations focus on achieving strong security, like forward-and-Type-I−-backward security, to reduce the information leakage of DSSE to the server as much as possible. However, the existing DSSE with such strong security cannot keep search correctness and stable security (or robustness, in short) if irrational queries are issued by the client, like duplicate add or delete queries and the delete queries for removing non-existed entries, to the server unintentionally. Hence, this work proposes two new DSSE schemes, named \\mathtt {SR-DSSE}_{a} and \\mathtt {SR-DSSE}_{b} , respectively. Both two schemes achieve forward-and-Type-I−-backward security while keeping robustness when irrational queries are issued. In terms of performance, \\mathtt {SR-DSSE}_{a} has more efficient communication costs and roundtrips than \\mathtt {SR-DSSE}_{b} . In contrast, \\mathtt {SR-DSSE}_{b} has a more efficient search performance than \\mathtt {SR-DSSE}_{a} . Its search performance is close to the existing DSSE scheme with the same security but fails to achieve robustness.}
}


@article{DBLP:journals/tifs/CuiMYZZJ24,
	author = {Ting Cui and
                  Yiming Mao and
                  Yang Yang and
                  Yi Zhang and
                  Jiyan Zhang and
                  Chenhui Jin},
	title = {Congruent Differential Cluster for Binary {SPN} Ciphers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2385--2397},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350374},
	doi = {10.1109/TIFS.2024.3350374},
	timestamp = {Wed, 30 Oct 2024 16:03:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CuiMYZZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study is focused on the differential clustering effect of the SPN block cipher, which employs a binary matrix as its diffusion layer. We present a novel strategy for differential estimation, named the congruent differential cluster. This method does not guarantee the optimization of each single differential characteristic but gathers a large number of characteristics satisfying a specific condition, i.e., the output differences of active S-boxes are equal. Given a binary SPN cipher, the exact probability of the congruent differential cluster can be obtained with negligible computational resources. Moreover, we consider a popular instance, binary AES-like ciphers, since the processing of their column-mixing layer can be divided into several independent parts. Therefore, if we set the output differences of the active S-boxes in the same partition to be equal, we can obtain more differential characteristics in the cluster, known as a semicongruent differential cluster. To demonstrate the application of the proposed method, we apply it to several block ciphers, i.e., Midori-64, CRAFT-64, SKINNY-64 and their variants proposed in Todo and Sasaki (2022). Compared with the active S-box counting method, the congruent differential clusters have considerably higher probabilities for most instances. In addition, we find a 7-round semicongruent differential cluster for Midori-64 with probability 2−52.25, an 8-round semicongruent differential cluster for SKINNY-64 with probability 2−50.72 and a 10-round semicongruent differential cluster for CRAFT-64 with probability 2−42.32. To the best of our knowledge, the semicongruent differential clusters we identify for 7-round Midori-64, 8-round SKINNY-64 and 10-round CRAFT-64 have the highest probabilities thus far among the existing differential clusters with the same rounds. Therefore, we believe that the proposed method is a valuable tool for evaluating the differential security of associated block ciphers.}
}


@article{DBLP:journals/tifs/HuLZZWZD24,
	author = {Xiaoxue Hu and
                  Geling Liu and
                  Baolin Zheng and
                  Lingchen Zhao and
                  Qian Wang and
                  Yufei Zhang and
                  Minxin Du},
	title = {FastTextDodger: Decision-Based Adversarial Attack Against Black-Box
                  {NLP} Models With Extremely High Efficiency},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2398--2411},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350376},
	doi = {10.1109/TIFS.2024.3350376},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuLZZWZD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, achieving query-efficient adversarial example attacks targeting black-box natural language models has attracted widespread attention from researchers. This task is considered difficult due to the discrete nature of texts, limited knowledge of the target model, and strict query access limitations in real-world systems. However, existing attacks often require a large number of queries or result in low attack success rates, having not met practical requirements. To address this, we propose FastTextDodger, a simple and compact decision-based black-box textual adversarial attack that generates grammatically correct adversarial texts with high attack success rates and few queries. Experimental results show that FastTextDodger achieves an impressive 97.4% attack success rate on benchmark datasets and models, and only needs about 200 queries. Compared to state-of-the-art attacks, FastTextDodger only requires one-tenth of the number of queries in text classification and entailment tasks while maintaining comparable attack success rates and perturbed word rates.}
}


@article{DBLP:journals/tifs/ChenGLAW24,
	author = {Jian Chen and
                  Yuan Gao and
                  Gaoyang Liu and
                  Ahmed M. Abdelmoniem and
                  Chen Wang},
	title = {Manipulating Pre-Trained Encoder for Targeted Poisoning Attacks in
                  Contrastive Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2412--2424},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350389},
	doi = {10.1109/TIFS.2024.3350389},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenGLAW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, contrastive learning has become very powerful for representation learning using large-scale unlabeled data, by involving pre-trained encoders to fine-tune downstream classifiers. However, the latest research indicates that contrastive learning can potentially suffer from the risks of data poisoning attacks, where the attacker injects maliciously crafted poisoned samples into the unlabeled pre-training data. To step forward, in this paper, we present a more stealthy poisoning attack dubbed PA-CL to directly poison the pre-trained encoder, such that the downstream classifier’s behavior on a single target instance to the attacker-desired class can be manipulated without affecting the overall downstream classification performance. We observe that a high similarity exists between the feature representation generated by the poisoned pre-trained encoder for the target sample and samples from the attacker-desired class. This leads to the downstream classifier misclassifying the target sample with the attacker-desired class. Therefore, we formulate our attack as an optimization problem, and design two novel loss functions, namely, the target effectiveness loss to effectively poison the pre-trained encoder, and the model utility loss to maintain the downstream classification performance. Experimental results on four real-world datasets demonstrate that the attack success rate of the proposed attack is 40% higher on average than that of the three baseline attacks, and the fluctuation of the downstream classifier’s prediction accuracy is within 5%.}
}


@article{DBLP:journals/tifs/DaiLZCXZJ24,
	author = {Weiqi Dai and
                  Jinkai Liu and
                  Yang Zhou and
                  Kim{-}Kwang Raymond Choo and
                  Xia Xie and
                  Deqing Zou and
                  Hai Jin},
	title = {{PRBFPT:} {A} Practical Redactable Blockchain Framework With a Public
                  Trapdoor},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2425--2437},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3349855},
	doi = {10.1109/TIFS.2024.3349855},
	timestamp = {Fri, 08 Mar 2024 13:21:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DaiLZCXZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While blockchain is known to support open and transparent data exchange, partly due to its nontamperability property, it can also be (ab)used to facilitate the spreading of fake and misleading information or information that was subsequently discredited. Hence, this paper proposes a practical, redactable blockchain framework with a public trapdoor (hereafter referred to as PRBFPT). PRBFPT comprises an editing scheme for adding blocks using a new type of blockchain with a chameleon hash. Specifically, PRBFPT is able to involve all nodes in the blockchain in the editing operations by means of a public trapdoor, without requiring additional trapdoor management by predefined nodes or organizations. PRBFPT is also designed to audit and record the content of each editing operation. In other words, after editing and deleting the original data, PRBFPT can still verify its legitimacy. We also propose a contract-based locked voting scheme to better support voting. We then evaluate the prototype implementation of PRBFPT, whose findings show that the total time consumption of adding modules is at the millisecond level, with a negligible impact on the performance of the original system. In addition, the evaluation findings show that the cost of initiating the special transactions is comparable to the consumption of normal Ethereum transactions and is within a manageable range.}
}


@article{DBLP:journals/tifs/WangLHH24,
	author = {Xiaohu Wang and
                  Chao Lin and
                  Xinyi Huang and
                  Debiao He},
	title = {Anonymity-Enhancing Multi-Hop Locks for Monero-Enabled Payment Channel
                  Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2438--2453},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3346177},
	doi = {10.1109/TIFS.2023.3346177},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangLHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Payment Channel Networks (PCNs) are innovative second-layer scaling technologies that aim to improve transaction rates, reduce on-chain storage costs, and enable efficient atomic swaps for blockchain-based cryptocurrencies. Despite offering features like relationship anonymity, scriptless script, and cross-chain fairness, current PCNs encounter challenges in achieving identity anonymity and maintaining the fungibility of cryptocurrency units. PayMo, proposed in ESORICS’22, addresses payment anonymity but is limited to Monero, posing difficulties in extending it to a PCN framework. In response, this paper presents a novel Anonymity-Enhancing Multi-Hop Locks (AEMHL) mechanism for Monero-enabled PCNs. The AEMHL mechanism leverages our generic Linkable Ring Adaptor Signature (LRAS) construction and a minimalist PCN framework called anonymous multi-hop locks. This approach effectively combines privacy protection and simplicity while ensuring Monero’s fungibility without the need for specialized scripting support. Security properties, including atomicity, consistency, and anonymity-enhancement, are demonstrated using a universal composability model. Additionally, two optimized LRAS-based schemes are proposed to accommodate multi-hop locks construction in diverse scenarios. Through rigorous security analysis and performance evaluation, we confirm that AEMHL meets essential security objectives and provides efficient and practical solutions for privacy-conscious users within PCNs.}
}


@article{DBLP:journals/tifs/WangZWGFL24,
	author = {Na Wang and
                  Wen Zhou and
                  Jingjing Wang and
                  Yifan Guo and
                  Junsong Fu and
                  Jianwei Liu},
	title = {Secure and Efficient Similarity Retrieval in Cloud Computing Based
                  on Homomorphic Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2454--2469},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350909},
	doi = {10.1109/TIFS.2024.3350909},
	timestamp = {Mon, 30 Sep 2024 07:53:48 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangZWGFL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of cloud computing, massive amounts of data are uploaded to cloud servers for storage. For privacy protection, sensitive data should be encrypted before outsourcing, and ciphertext retrieval technologies based on similarity come into being. In cloud computing with massive data, the efficiency and accuracy of retrieval are crucial. However, most of the current similarity retrieval schemes do not perform well in these two aspects. Therefore, we propose SESR scheme, a secure and efficient similarity retrieval scheme based on homomorphic encryption. Firstly, we use Hamming distance to calculate the similarity between the feature vector of the data and query vector from the data user. Secondly, the homomorphic encryption algorithm is used to encrypt data to protect data privacy. Furthermore, we creatively design a BK-KD tree structure that hierarchically implements similarity search and fine-grained access control, thereby speeding up the retrieval efficiency. In addition, we design a two-cloud-server cooperative retrieval model and a message authentication scheme, which ensure access pattern privacy security and the integrity of the transmitted data simultaneously. We also propose an improved SESR scheme. In this scheme, we use Simhash algorithm to generate feature vectors and query vectors, which reduces storage overhead. Finally, the security of SESR is formally proved and the simulation results show the efficiency and accuracy of the retrieval scheme.}
}


@article{DBLP:journals/tifs/LiWYYZ24,
	author = {Jiajun Li and
                  Pu Wang and
                  Zheng Yan and
                  Yishan Yang and
                  Kai Zeng},
	title = {BGKey: Group Key Generation for Backscatter Communications Among Multiple
                  Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2470--2486},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3345650},
	doi = {10.1109/TIFS.2023.3345650},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiWYYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Backscatter communication (BC) is an emerging radio technology for achieving sustainable wireless communications. However, the literature still lacks an effective secret group key generation scheme for safeguarding communications among multiple resource-constrained backscatter devices (BDs). In this paper, we propose a novel physical layer group key generation framework, BGKey, for securing backscatter communications among multiple BDs. BGKey contains three schemes: Centralized Group Key Generation (CGKG), Decentralized Group Key Generation (DGKG), and Decentralized Hierarchical Group Key Generation (DHGKG). Each scheme has its own advantages, applicable in different scenarios. We analyze the performance of BGKey schemes regarding computation and communication complexity and security under eavesdropping and three active attacks. We conduct extensive simulations with different system parameters to evaluate their performance. CGKG is the most efficient and accurate for generating a group key, but it depends on a trusted radio frequency source (RFS) and is the least secure under eavesdropping and three active attacks among three schemes. DGKG exhibits better security and higher key generation rate (KGR) against eavesdropping and three active attacks compared with CGKG. However, the bit disagreement ratio (BDR) of group key increases when the size of BD group increases. DHGKG dramatically enhances the performance of group key generation compared with DGKG and retains its excellent security against eavesdropping and three active attacks.}
}


@article{DBLP:journals/tifs/JeonJBJ24,
	author = {Jueun Jeon and
                  Byeonghui Jeong and
                  Seungyeon Baek and
                  Young{-}Sik Jeong},
	title = {Static Multi Feature-Based Malware Detection Using Multi SPP-net in
                  Smart IoT Environments},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2487--2500},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350379},
	doi = {10.1109/TIFS.2024.3350379},
	timestamp = {Fri, 26 Jan 2024 07:55:46 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JeonJBJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the steady increase in the demand for Internet of Things (IoT) devices in diverse industries, such as manufacturing, medical care, and transportation infrastructure, the production of malware tailored for Smart IoT environments is also increasing. Accordingly, various malware detection studies are being conducted to detect not only known malware but also variant malware. However, it is difficult to detect malware transformed in a way that hides malicious behavior by changing and deleting bytes or modifying the assembly code. Therefore, in this study, we propose a malware detection for static security service (Mal3S) scheme that provides a secure Smart IoT environment by accurately detecting various types of malware. Mal3S extracts bytes, opcodes, API calls, strings, and dynamic link libraries (DLLs) through static analysis and then generates five types of images. Images of various sizes are trained on a multi spatial pyramid pooling network (SPP-net) model to detect malware. When evaluating the performance of Mal3S using three malware datasets, the average detection accuracy was 98.02% and the classification accuracy was 98.43%, showing better performance than existing malware detection techniques. In addition, Mal3S has demonstrated effective generalization capabilities for various types of malware.}
}


@article{DBLP:journals/tifs/WeiJWHDLCPW24,
	author = {Yu Wei and
                  Jingyu Jia and
                  Yuduo Wu and
                  Changhui Hu and
                  Changyu Dong and
                  Zheli Liu and
                  Xiaofeng Chen and
                  Yun Peng and
                  Shaowei Wang},
	title = {Distributed Differential Privacy via Shuffling Versus Aggregation:
                  {A} Curious Study},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2501--2516},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3351474},
	doi = {10.1109/TIFS.2024.3351474},
	timestamp = {Wed, 18 Dec 2024 13:51:13 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WeiJWHDLCPW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How to achieve distributed differential privacy (DP) without a trusted central party is of great interest in both theory and practice. Recently, the shuffle model has attracted much attention. Unlike the local DP model in which the users send randomized data directly to the data collector/analyzer, in the shuffle model an intermediate untrusted shuffler is introduced to randomly permute the data, which have already been randomized by the users, before they reach the analyzer. The most appealing aspect is that while shuffling does not explicitly add more noise to the data, it can make privacy better. The privacy amplification effect in consequence means the users need to add less noise to the data than in the local DP model, but can achieve the same level of differential privacy. Thus, protocols in the shuffle model can provide better accuracy than those in the local DP model. What looks interesting to us is that the architecture of the shuffle model is similar to private aggregation, which has been studied for more than a decade. In private aggregation, locally randomized user data are aggregated by an intermediate untrusted aggregator. Thus, our question is whether aggregation also exhibits some sort of privacy amplification effect? And if so, how good is this “aggregation model” in comparison with the shuffle model. We conducted the first comparative study between the two, covering privacy amplification, functionalities, protocol accuracy, and practicality. The results as yet suggest that the new shuffle model does not have obvious advantages over the old aggregation model. On the contrary, protocols in the aggregation model outperform those in the shuffle model, sometimes significantly, in many aspects.}
}


@article{DBLP:journals/tifs/ZhangSXCCCL24,
	author = {Xiaoli Zhang and
                  Wenxiang Sun and
                  Zhicheng Xu and
                  Hongbing Cheng and
                  Chengjun Cai and
                  Helei Cui and
                  Qi Li},
	title = {EVM-Shield: In-Contract State Access Control for Fast Vulnerability
                  Detection and Prevention},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2517--2532},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3349852},
	doi = {10.1109/TIFS.2024.3349852},
	timestamp = {Wed, 04 Sep 2024 21:09:35 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangSXCCCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, smart contracts have been widely applied in security-sensitive fields yet are fragile to various vulnerabilities and attacks. Regarding this, existing research efforts either statically scrutinize smart contracts’ code or detect suspicious transaction execution flows. However, they either fail to timely protect contracts or only handle a small subset of well-known vulnerabilities. In the paper, we propose \\mathtt {EVM} - \\mathtt {Shield} that secures vulnerable smart contracts in real-time via fine-grained access control over sensitive states. The behind rationale is most of attacks aim to manipulate money-related states (e.g., tokens) for profits. Specifically, transaction-level state access control policies are first defined by developers and then translated into EVM-level policies with contract-aware function-level state access permissions. In policy enforcement, \\mathtt {EVM} - \\mathtt {Shield} introduces a hybrid storage analyzer to accurately identify (dynamic-allocated) storage locations for policy-involved states and a multi-stage cache based filter to fast revert bad transactions with unexpected state access behaviors. Finally, we conduct thorough experiments using 12 types of real-world contract vulnerabilities and all open-source smart contracts on the first 8M blocks of Ethereum. The results demonstrate that \\mathtt {EVM} - \\mathtt {Shield} outperforms two state-of-the-art runtime analysis tools in terms of attack detection. Extensive performance evaluations with 185M real-world transactions show that \\mathtt {EVM} - \\mathtt {Shield} can block 100% unexpected state accesses at the cost of 8% throughput degradation (compared with the native EVM).}
}


@article{DBLP:journals/tifs/PengQMWFAAG24,
	author = {Huaibing Peng and
                  Huming Qiu and
                  Hua Ma and
                  Shuo Wang and
                  Anmin Fu and
                  Said F. Al{-}Sarawi and
                  Derek Abbott and
                  Yansong Gao},
	title = {On Model Outsourcing Adaptive Attacks to Deep Learning Backdoor Defenses},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2356--2369},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3349869},
	doi = {10.1109/TIFS.2024.3349869},
	timestamp = {Thu, 08 Aug 2024 07:48:11 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PengQMWFAAG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning models with backdoors act maliciously when triggered but seem normal otherwise. This risk, often increased by model outsourcing, challenges their secure use. Although countermeasures exist, their defense against adaptive attacks is under-examined, possibly leading to security misjudgments. This study is the first intricate examination illustrating the difficulty of detecting backdoors in outsourced models, especially when attackers adjust their strategies, even if their capabilities are significantly limited. It is relatively straightforward for attackers to circumvent detection by trivially violating its threat model (e.g., using advanced backdoor types or trigger designs not covered by the detection). However, this research highlights that various leading detection defenses can simultaneously be evaded using simple adaptive strategies, even under their defined threat models and with limited adversary capabilities (e.g., using easily detectable triggers while maintaining a high attack success rate). To be more specific, this study introduces a novel methodology that employs trigger specificity enhancement and training regulation in a symbiotic manner. This approach allows us to evade multiple backdoor detection defenses simultaneously, including Neural Cleanse (Oakland 19’), ABS (CCS 19’), and MNTD (Oakland 21’). These were the detection tools selected for the Evasive Trojans Track of the 2022 NeurIPS Trojan Detection Challenge. Even when applied in conjunction with these defenses under stringent conditions, such as a high attack success rate (> 97%) and the restricted use of the simplest trigger (small white square), our straightforward method garnered the second prize in NeurIPS Trojan Detection Challenge. Notably, for the first time, our adaptive attack successfully evaded other recent state-of-the-art defenses, including FeatureRE (NeurIPS 22’) and Beatrix (NDSS 23’). This study suggests that existing model outsourcing backdoor defenses remain vulnerable to adaptive attacks, and thus, the use of third-party models should be avoided whenever possible.}
}


@article{DBLP:journals/tifs/ZhaoluWW24,
	author = {Tianyu Zhaolu and
                  Zhiguo Wan and
                  Huaqun Wang},
	title = {Division of Regulatory Power: Collaborative Regulation for Privacy-Preserving
                  Blockchains},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2533--2548},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3348268},
	doi = {10.1109/TIFS.2023.3348268},
	timestamp = {Thu, 29 Feb 2024 20:53:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoluWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized anonymous payment schemes may be exploited for illicit activities, such as money laundering, bribery and blackmail. To address this issue, several regulatory-friendly decentralized anonymous payment schemes have been proposed. However, most of these solutions lack restrictions on the regulator’s authority, which could potentially result in power abuse and privacy breaches. In this paper, we present a decentralized anonymous payment scheme with collaborative regulation (DAPCR). Unlike existing solutions, DAPCR reduces the risk of power abuse by distributing regulatory authority to two entities: Filter and Supervisor, neither of which can decode transactions to access transaction privacy without the assistance of the other one. Our scheme enjoys three major advantages over others: 1) Universality, achieved by using zk-SNARK to extend privacy-preserving transactions for regulation. 2) Collaborative regulation, attained by adding the ring signature with controllable linkability to the transaction. 3) Efficient aggregation of payment amounts, achieved through amount tags. As a key technology for realizing collaborative regulation in DAPCR, the ring signature with controllable linkability (CLRS) is proposed, where a user needs to specify a linker and an opener to generate a signature. The linker can extract pseudonyms from signatures and link signatures submitted by the same signer based on pseudonyms, without leaking the signer’s identity. The opener can recover the signer’s identity from a given pseudonym. The experimental results reflect the efficiency of DAPCR. The time overhead for transaction generation is 1231.2ms, representing an increase of less than 50% compared to ZETH. Additionally, the time overhead for transaction verification is only 1.2ms.}
}


@article{DBLP:journals/tifs/JiaCHSWD24,
	author = {Meng Jia and
                  Jing Chen and
                  Kun He and
                  Min Shi and
                  Yuanzheng Wang and
                  Ruiying Du},
	title = {Generic Construction of Threshold Credential Management With User-Autonomy
                  Aggregation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2549--2564},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3347897},
	doi = {10.1109/TIFS.2023.3347897},
	timestamp = {Thu, 29 Feb 2024 20:53:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiaCHSWD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Credential management is widely used in online services such as electronic identity cards, e-health, and e-voting, in which users prove their identity or attributes with credentials issued by authorities. Under some circumstances, a user needs to prove her/his identity or attributes in multiple credentials to a verifier. In existing credential management systems, a user either proves her/his credentials one by one or requests new credentials from authorities with the original ones, and they are inefficient in practice. Moreover, existing decentralized credential management systems either rely on multiple single parties or do not support attribute revocation. In this paper, we present a threshold credential management system with threshold issuance and revocation and user-autonomy aggregation. Specifically, we design a decentralized credential management architecture where multiple authorities form an alliance and manage credentials collaboratively. Then, we propose a threshold credential management scheme, where user issuance and revocation must be approved by multiple credential managers, and a user can aggregate her/his credentials and prove them to a verifier simultaneously. We conduct experiments on our system and the results demonstrate that it is suitable in practice.}
}


@article{DBLP:journals/tifs/HuangHQWG24,
	author = {Lifeng Huang and
                  Qiong Huang and
                  Peichao Qiu and
                  Shuxin Wei and
                  Chengying Gao},
	title = {{FASTEN:} Fast Ensemble Learning for Improved Adversarial Robustness},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2565--2580},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3336527},
	doi = {10.1109/TIFS.2023.3336527},
	timestamp = {Thu, 29 Feb 2024 20:53:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangHQWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent works show that adversarial attacks threaten the security of deep neural networks (DNNs). To tackle this issue, ensemble learning methods have been proposed to train multiple sub-models and improve adversarial resistance without compromising accuracy. However, these methods often come with high computational costs, including multi-step optimization to generate high-quality augmentation data and additional network passes to optimize complicated regularization. In this paper, we present the FAST ENsemble learning method (FASTEN) to significantly reduce training costs in terms of data and optimization. Firstly, FASTEN employs a single-step technique to initialize poor augmentation data and recycles optimization knowledge to enhance data quality, which considerably reduces the data generation budget. Secondly, FASTEN introduces a low-cost regularizer to increase intra-model similarity and inter-model diversity, with most of the regularization components computed without network passes, further decreasing training costs. Empirical results on various datasets and networks demonstrate that FASTEN achieves higher robustness while requiring significantly fewer resources than current methods. For example, a 5-member FASTEN speeds up the optimization process by 7\\times and 28\\times compared to state-of-the-art DVERGE and TRS, respectively. Moreover, FASTEN outperforms the stronger of the two methods by 26.3% and 6.1% under black-box and white-box attacks, respectively. FASTEN is also compatible with existing fast adversarial training techniques, making it an advantageous choice for enhancing robustness without incurring excessive costs. The source code is publicly available at https://github.com/mesunhlf/FASTEN.}
}


@article{DBLP:journals/tifs/LinLLH24,
	author = {Guoyuan Lin and
                  Weiqi Luo and
                  Da Luo and
                  Jiwu Huang},
	title = {One-Class Neural Network With Directed Statistics Pooling for Spoofing
                  Speech Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2581--2593},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352429},
	doi = {10.1109/TIFS.2024.3352429},
	timestamp = {Thu, 29 Feb 2024 20:53:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LinLLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing deep learning models for spoofing speech detection often struggle to effectively generalize to unseen spoofing attacks that were not present during the training stage. Moreover, the presence of class imbalance further compounds this issue by biasing the learning process towards seen attack samples. To address these challenges, we present an innovative end-to-end model called One-Class Neural Network with Directed Statistics Pooling (OCNet-DSP). Our model incorporates a feature cropping operation to attenuate high-frequency components, mitigating the risk of overfitting. Additionally, leveraging the time-frequency characteristics of speech signals, we introduce a directed statistics pooling layer that extracts more effective features for distinguishing between bonafide and spoofing classes. We also propose the Threshold One-class Softmax loss, which mitigates class imbalance by reducing the optimization weight of spoofing samples during training. Extensive comparative results demonstrate that the proposed model outperforms all existing single models, achieving an equal error rate of 0.44% and a minimum detection cost function of 0.0145 for the ASVspoof 2019 logical access database. Moreover, the proposed ensemble version, which accommodates speech inputs of varying lengths in each submodel, maintains state-of-the-art performance among reproducible ensemble models. Additionally, numerous ablation experiments, along with a cross-dataset experiment, are conducted to validate the rationality and effectiveness of the proposed model.}
}


@article{DBLP:journals/tifs/LiWZXX24,
	author = {Jianhao Li and
                  Jiabei Wang and
                  Rui Zhang and
                  Yansen Xin and
                  Wenhan Xu},
	title = {{NEMO:} Practical Distributed Boolean Queries With Minimal Leakage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2594--2608},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3351433},
	doi = {10.1109/TIFS.2024.3351433},
	timestamp = {Thu, 29 Feb 2024 20:53:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiWZXX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searchable symmetric encryption (SSE) schemes allow a client to store encrypted data with a storage provider and retrieve corresponding documents without revealing the content or search keywords to the provider. However, achieving efficient SSE schemes often comes at the cost of statistical information leakage, including search, access and size patterns. The known solutions from fully homomorphic encryption or oblivious RAM often admit poor performances due to significant computational and communication overheads. Additionally, the demand for rich search expressiveness, such as Boolean queries, further complicates the design. In this paper, we introduce NEMO, a novel SSE achieving a good balance between efficiency, security and query expressiveness. NEMO utilizes function secret sharing (FSS) and replicated secret sharing-based multi-party computation (MPC) protocol, but is highly optimized for large database. For functionality, NEMO supports arbitrary Boolean queries and enables dynamic updates in a multi-user setting. For security, NEMO achieves minimal leakage by eliminating all search, access, and size patterns, while only allowing the leakage of Boolean formulas in queries. Regarding efficiency, we propose a new FSS for multi-point functions, effectively batching multiple distributed point functions, and an infix-to-postfix conversion algorithm for Boolean formula to reduce the communication rounds in the MPC protocol. A proof-of-concept implementation of NEMO demonstrates its efficiency, with a search latency of approximately 622 ms for a conjunction query with 8 keywords, even with a dataset exceeding 1 million documents.}
}


@article{DBLP:journals/tifs/LiuKLXT24,
	author = {Jian Liu and
                  Jiachen Ke and
                  Jinliang Liu and
                  Xiangpeng Xie and
                  Engang Tian},
	title = {Outlier-Resistant Non-Fragile Control of Nonlinear Networked Systems
                  Under DoS Attacks and Multi-Variable Event-Triggered {SC} Protocol},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2609--2622},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352404},
	doi = {10.1109/TIFS.2024.3352404},
	timestamp = {Wed, 02 Oct 2024 16:53:16 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuKLXT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, the outlier-resistant (OR) observer-based secure control problem is investigated for nonlinear networked systems under randomly activated denial-of-service (RADoS) attacks and stochastic communication (SC) protocol. In virtue of zero-order holder (ZOH) technique, an attack compensation scheme is adopted to alleviate the adverse effects brought by RADoS attacks. By introducing multiple internal dynamic variables (MIDVs), a novel multi-variable event-triggered stochastic communication (MVET-SC) protocol is put forward to enhance the design flexibility and prevent the occurrence of data conflicts. Moreover, the non-fragile fuzzy controller is applied due to the inaccuracies in practical applications. Comprehensively taking the above factors into account, the asymptotic stability of the augmented fuzzy system can be ensured under the presented sufficient criteria. Meanwhile, the parameters of the OR observer-based secure controller are derived according to the obtained design conditions. In the end, a simulation example of mass-spring-damping system (MSDS) demonstrates the validity of the non-fragile secure control approach with OR observer.}
}


@article{DBLP:journals/tifs/QuLWCJW24,
	author = {Zhenqing Qu and
                  Xiang Ling and
                  Ting Wang and
                  Xiang Chen and
                  Shouling Ji and
                  Chunming Wu},
	title = {AdvSQLi: Generating Adversarial {SQL} Injections Against Real-World
                  WAF-as-a-Service},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2623--2638},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350911},
	doi = {10.1109/TIFS.2024.3350911},
	timestamp = {Mon, 16 Sep 2024 10:28:05 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QuLWCJW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the first defensive layer that attacks would hit, the web application firewall (WAF) plays an indispensable role in defending against malicious web attacks like SQL injection (SQLi). With the development of cloud computing, WAF-as-a-service, as one kind of Security-as-a-service, has been proposed to facilitate the deployment, configuration, and update of WAFs in the cloud. Despite its tremendous popularity, the security vulnerabilities of WAF-as-a-service are still largely unknown, which is highly concerning given its massive usage. In this paper, we propose a general and extendable attack framework, namely AdvSQLi, in which a minimal series of transformations are performed on the hierarchical tree representation of the original SQLi payload, such that the generated SQLi payloads can not only bypass WAF-as-a-service under black-box settings but also keep the same functionality and maliciousness as the original payload. With AdvSQLi, we make it feasible to inspect and understand the security vulnerabilities of WAFs automatically, helping vendors make products more secure. To evaluate the attack effectiveness and efficiency of AdvSQLi, we first employ two public datasets to generate adversarial SQLi payloads, leading to a maximum attack success rate of 100% against state-of-the-art ML-based SQLi detectors. Furthermore, to demonstrate the immediate security threats caused by AdvSQLi, we evaluate the attack effectiveness against 7 WAF-as-a-service solutions from mainstream vendors and find all of them are vulnerable to AdvSQLi. For instance, AdvSQLi achieves an attack success rate of over 79% against the F5 WAF. Through in-depth analysis of the evaluation results, we further condense out several general yet severe flaws of these vendors that cannot be easily patched.}
}


@article{DBLP:journals/tifs/ZhangZZLGS24,
	author = {Yibin Zhang and
                  Qianyun Zhang and
                  Haitao Zhao and
                  Yun Lin and
                  Guan Gui and
                  Hikmet Sari},
	title = {Multisource Heterogeneous Specific Emitter Identification Using Attention
                  Mechanism-Based {RFF} Fusion Method},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2639--2650},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3353594},
	doi = {10.1109/TIFS.2024.3353594},
	timestamp = {Tue, 12 Mar 2024 14:33:18 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZZLGS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber security has always been an important issue in the Internet of Everything topic. In the physical layer of the Internet, specific emitter identification (SEI) technology is widely researched as a simple and effective intrusion prevention technology. Existing SEI research only focused on radio frequency (RF) signals from a single receiver. However, in real scenes such as the Industrial Internet of Things (IIoT), vehicle-to-everything applications, and intelligent sensing systems, etc., RF signals are received from different types of sensors deployed at different locations. Therefore, this paper proposes a multisource heterogeneous SEI (MH-SEI) method and proposes a multi-source heterogeneous attention-based feature fusion network (MHAFFN) to achieve excellent identification performance. The proposed MHAFFN utilizes a multi-channel convolutional network as the RF fingerprinting (RFF) extraction module for multisource heterogeneous RF signals and equips an attention-based RFF fusion module to obtain mixed RFF for the automatic classifier. The experimental results show that the identification accuracy of MHAFFN is 99.196% in a perfect environment. Furthermore, robustness verification has proved that MHAFFN keeps advantages in noisy environments. Through fault tolerance mechanism verification experiment, it is proved that MHAFFN is able to work stably in real-world complex scenarios.}
}


@article{DBLP:journals/tifs/AmihoodC24,
	author = {Barak Amihood and
                  Asaf Cohen},
	title = {Covertly Controlling a Linear System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2651--2663},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3342637},
	doi = {10.1109/TIFS.2023.3342637},
	timestamp = {Thu, 29 Feb 2024 20:53:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AmihoodC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Consider the problem of covertly controlling a linear system. In this problem, Alice desires to control (stabilize or change the behavior of) a linear system, while keeping an observer, Willie, unable to decide if the system is indeed being controlled or not. We formally define the problem, under a model where Willie can only observe the system’s output. Focusing on AR(1) systems, we show that when Willie observes the system’s output through a clean channel, an inherently unstable linear system cannot be covertly stabilized. However, under some conditions on the parameters and observation time, an inherently stable linear system can be covertly controlled, in the sense of covertly changing its parameter or resetting its memory. Moreover, we give positive and negative results for two important controllers: a minimal-information controller, where Alice is allowed to use only 1 bit per sample, and a maximal-information controller, where Alice is allowed to view the real-valued output. The results reveal an interesting interplay in covert control, between the amount of information used by the c ontroller, control performance and covertness.}
}


@article{DBLP:journals/tifs/DassanayakeGB24,
	author = {Janith Kavindu Dassanayake and
                  Dulaj Gunasinghe and
                  Gayan Amarasuriya Aruma Baduge},
	title = {Secrecy Rate Analysis and Active Pilot Attack Detection for IRS-Aided
                  Massive {MIMO} Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2664--2679},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3318941},
	doi = {10.1109/TIFS.2023.3318941},
	timestamp = {Thu, 29 Feb 2024 20:53:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DassanayakeGB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The active pilot contamination attacks in intelligent reflecting surface (IRS) aided massive multiple-input multiple-output systems are investigated. By proposing a statistical channel state information based IRS phase-shift optimization technique, an achievable secrecy rate is derived in the presence of practical impediments, including erroneously estimated composite channels via linear minimum mean square error estimation criterion, residual interference due to active pilot contamination, artificial noise (AN) generation, and spatially correlated fading at the base-station antennas and IRS elements. A transmit power allocation technique is also proposed. Two active pilot attack detectors are designed based on the Neyman-Pearson and generalized likelihood ratio test criteria. The performance of these detectors is investigated by deriving the probability of detection, probability of false alarm, and receiver operating characteristics. Our secrecy rate analysis reveals that the rate leaked into the eavesdroppers by active pilot contamination attacks can be considerably high. The proposed power allocation algorithm jointly assigns transmit powers for the legitimate signals and AN sequences for maximizing the minimum secrecy rate of the weakest legitimate user to ensure user-fairness. The proposed detectors of active pilot attacks may be useful in designing remedial techniques to mitigate detrimental effects of active eavesdropping.}
}


@article{DBLP:journals/tifs/ZhaoMSSO24,
	author = {Raymond K. Zhao and
                  Sarah McCarthy and
                  Ron Steinfeld and
                  Amin Sakzad and
                  M{\'{a}}ire O'Neill},
	title = {Quantum-Safe {HIBE:} Does It Cost a Latte?},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2680--2695},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3347880},
	doi = {10.1109/TIFS.2023.3347880},
	timestamp = {Sat, 16 Mar 2024 15:10:13 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoMSSO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The United Kingdom (UK) government is considering advanced primitives such as identity-based encryption (IBE) for adoption as they transition their public-safety communications network from TETRA to an LTE-based service. However, the current LTE standard relies on elliptic-curve-based IBE, which will be vulnerable to quantum computing attacks, expected within the next 20–30 years. Lattices can provide quantum-safe alternatives for IBE. These schemes have shown promising results in terms of practicality. To date, several IBE schemes over lattices have been proposed, but there has been little in the way of practical evaluation. This paper provides the first complete optimised practical implementation and benchmarking of Latte, a promising Hierarchical IBE (HIBE) scheme proposed by the UK National Cyber Security Centre (NCSC) in 2017 and endorsed by European Telecommunications Standards Institute (ETSI). We propose optimisations for the KeyGen, Delegate, Extract and Gaussian sampling components of Latte, to increase attack costs, reduce decryption key lengths by 2x–3x, ciphertext sizes by up to 33%, and improve speed. In addition, we conduct a precision analysis, bounding the Rényi divergence of the distribution of the real Gaussian sampling procedures from the ideal distribution in corroboration of our claimed security levels. Our resulting implementation of the Delegate function takes 0.4 seconds at 80-bit security level on a desktop machine at 4.2GHz, significantly faster than the order of minutes estimated in the ETSI technical report. Furthermore, our optimised Latte Encrypt/Decrypt implementation reaches speeds up to 9.7x faster than the ETSI implementation.}
}


@article{DBLP:journals/tifs/CuiZP24,
	author = {Zhenyu Cui and
                  Jiahuan Zhou and
                  Yuxin Peng},
	title = {{DMA:} Dual Modality-Aware Alignment for Visible-Infrared Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2696--2708},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352408},
	doi = {10.1109/TIFS.2024.3352408},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CuiZP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visible-infrared person re-identification (VI-ReID) aims to identify the same person across visible and infrared images. Its main challenge is how to extract modality-irrelevant person identity information. To alleviate cross-modality discrepancies, existing methods typically follow two paradigms: 1) Transform visible images into gray-scale color space and map them into the infrared domain. 2) Stack infrared images into RGB color space and map them into the visible domain. However, limited by different optical properties of visible and infrared waves, such mapping commonly leads to information asymmetry. Although some efforts prevent such discrepancies by data-level alignment, they typically meanwhile introduce misleading information and bring extra divergence. Therefore, existing methods fail on effectively eliminating the modality discrepancies. In this paper, we first analyze the essential factors to the generation of modality discrepancies. Secondly, we propose a novel Dual Modality-aware Alignment (DMA) model for VI-ReID, which can preserve discriminative identity information and suppress the misleading information within a uniform scheme. Particularly, based on the intrinsic optical properties of both modalities, a Dual Modality Transfer (DMT) module is proposed to perform compensation for the information asymmetry in HSV color space, thereby effectively alleviating cross-modality discrepancies and better preserving discriminative identity features. Further, an Intra-local Alignment (IA) module is proposed to suppress the misleading information, where a fine-grained local consistency objective function is designed to achieve more compact intra-class representations. Extensive experiments on several benchmark datasets demonstrate the effectiveness of our method and competitive performance with state-of-the-art methods. The source code of this paper is available at https://github.com/PKU-ICST-MIPL/DMA_TIFS2023.}
}


@article{DBLP:journals/tifs/LiZWMN24,
	author = {Shuyi Li and
                  Bob Zhang and
                  Lifang Wu and
                  Ruijun Ma and
                  Xin Ning},
	title = {Robust and Sparse Least Square Regression for Finger Vein and Finger
                  Knuckle Print Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2709--2719},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352389},
	doi = {10.1109/TIFS.2024.3352389},
	timestamp = {Thu, 14 Nov 2024 10:59:37 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiZWMN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to their high reliability, security, and anti-counterfeiting, finger-based biometrics (such as finger vein and finger knuckle print) have recently received considerable attention. Despite recent advances in finger-based biometrics, most of these approaches leverage much prior information and are non-robust for different modalities or different scenarios. To address this problem, we propose a structured Robust and Sparse Least Square Regression (RSLSR) framework to adaptively learn discriminative features for personal identification. To achieve the powerful representation capacity of the input data, RSLSR synchronously integrates robust projection learning, noise decomposition, and discriminant sparse representation into a unified learning framework. Specifically, RSLSR jointly learns the most discriminative information from the original pixels of the finger images by introducing the l_{2,1}\nnorm. A sparse transformation matrix and reconstruction error are simultaneously enforced to enhance its robustness to noise, thus making RSLSR adaptable to multi-scenarios. Extensive experiments on five contact-based and contactless-based finger databases demonstrate the clear superiority of the proposed RSLSR in terms of recognition accuracy and computational efficiency.}
}


@article{DBLP:journals/tifs/WangTCGWZX24,
	author = {Haotian Wang and
                  Jun Tao and
                  Dingwen Chi and
                  Yu Gao and
                  Zuyan Wang and
                  Dika Zou and
                  Yifan Xu},
	title = {A Preference-Driven Malicious Platform Detection Mechanism for Users
                  in Mobile Crowdsensing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2720--2731},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352412},
	doi = {10.1109/TIFS.2024.3352412},
	timestamp = {Thu, 02 Jan 2025 19:03:15 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangTCGWZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Exploiting mobile crowdsensing to conduct data collection and analysis brings unprecedented opportunities to promote the development of the Internet of Things(IoT). However, malicious platforms may provide untrusted data or illegally leak users’ information, which leads users in crowdsensing networks to be reluctant to participate in sensing activities. Besides, users are unwilling to report malicious platforms without sufficient incentives. To tackle the problem, a new incentive mechanism is proposed by modeling users’ preferences in this paper. Specifically, two scenarios are considered to detect malicious platforms when users join sensing activities according to the system grasps user’s information, i.e., complete information scenario and partial information scenario. Different incentive algorithms are designed for each scenario to optimize the systems incentive cost. In the complete information scenario, we minimize the total incentive cost by ranking users’ preferences. In the partial information scenario, uniform Distribution and Laplace Distribution are employed to model the distribution of users’ preferences to find the optimal cost. Specifically, we incorporate the concept of non-convexity into design the incentive mechanism, when user preferences obey the Laplace Distribution. By conducting an in-depth exploration the properties of Laplace Distribution, we can transform it into a convex problem to solve it efficiently. The analysis based on these mechanisms lays a theoretical foundation on the detection of malicious platforms. Furthermore, the soundness of modeling and the accuracy of analysis are verified through extensive simulation, which also guides the design of more sophisticated incentive schemes for the detection of malicious platforms.}
}


@article{DBLP:journals/tifs/ZhaoZGQ24,
	author = {Jun Zhao and
                  Kai Zhang and
                  Junqing Gong and
                  Haifeng Qian},
	title = {Lavida: Large-Universe, Verifiable, and Dynamic Fine-Grained Access
                  Control for E-Health Cloud},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2732--2745},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3350925},
	doi = {10.1109/TIFS.2024.3350925},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoZGQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Electronic healthcare (E-health) cloud system enables electronic health records (EHRs) sharing and improves efficiency of diagnosis and treatment. In order to address EHRs confidentiality and authorized user access control in E-health cloud, attribute-based proxy re-encryption (ABPRE) has been widely employed which provides dynamic fine-grained access control over encrypted EHRs. Unfortunately, existing ABPRE schemes still have the following defects: 1) capacity of attribute-universe is defined at setup; 2) verifiable mechanism for re-encryption reveals EHRs about patients; 3) traditional access policy reveals sensitive information pertaining to patients. This paper focuses on these issues and presents large-universe, verifiable and privacy-preserving dynamic fine-grained access control scheme for E-health cloud. More details, we solve limitation of attribute-universe to large-universe, which means that attributes aren’t required to be enumerated at setup. Considering disclosure of underlying EHRs in verifiable mechanism, scheme introduces non-interactive zero-knowledge proof as verifiable mechanism that supports public validation and doesn’t leak EHRs of patients. Furthermore, partially hidden policy is employed to protect privacy of patients in policy, which divides attribute into attribute name and attribute value, displaying attribute name and hiding attribute value. Finally, experimental evaluation is given that demonstrates the more comprehensive functionality of our scheme without sacrificing significant computational overhead.}
}


@article{DBLP:journals/tifs/TongLMWLD24,
	author = {Qiuyun Tong and
                  Xinghua Li and
                  Yinbin Miao and
                  Yunwei Wang and
                  Ximeng Liu and
                  Robert H. Deng},
	title = {Beyond Result Verification: Efficient Privacy-Preserving Spatial Keyword
                  Query With Suppressed Leakage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2746--2760},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3354414},
	doi = {10.1109/TIFS.2024.3354414},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TongLMWLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Boolean range query (BRQ) is a typical type of spatial keyword query that is widely used in geographic information systems, location-based services and other applications. It retrieves the objects inside the query range and containing all query keywords. Many privacy-preserving BRQ schemes have been proposed to support BRQ over encrypted data. However, most of them fail to achieve efficient retrieval and lightweight result verification while suppressing access and search pattern leakage. Thus, in this paper, we propose an efficient verifiable privacy-preserving Boolean range query with suppressed leakage. Firstly, we convert BRQ into multi-keyword query by using Gray code and Bloom filter. Then, we achieve efficient oblivious multi-keyword query by combining distributed point function and PRP-based Cuckoo hashing, which protects the access and search patterns. Moreover, we support lightweight and oblivious result verification based on oblivious query, aggregate MAC, keyed-hashing MAC and XOR-homomorphic pseudorandom function. It enables query users to verify the result integrity with a proof whose size is independent of the size of the outsourced dataset. Finally, formal security analysis and extensive experiments demonstrate that our proposed scheme is adaptively secure and efficient for practical applications, respectively.}
}


@article{DBLP:journals/tifs/JiangLSD24,
	author = {Mei Jiang and
                  Yannan Li and
                  Willy Susilo and
                  Dung Hoang Duong},
	title = {Quantum-Safe Puncturable Signatures With Their Application in Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2761--2770},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3353074},
	doi = {10.1109/TIFS.2024.3353074},
	timestamp = {Sun, 19 Jan 2025 14:20:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiangLSD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Energy-efficient proof-of-stake (PoS) consensus protocols in blockchain have gained much attention from academia and industry recently. Despite their potential advantages, PoS protocols have not been extensively deployed in the existing digital currency market due to inherent security concerns, e.g., long-range attacks. Such attacks enable an adversary to rewrite the entire transaction history of a blockchain, severely compromising its immutability. The puncturable signature provides an efficient solution against long-range attacks due to secret key leakage. More specifically, a signer can update the secret key with chosen messages selectively, while the public key is unchanged. Unfortunately, the existing puncturable signature schemes suffer from either updating the public key repeatedly or large key sizes, which makes them unsuitable for PoS protocols. To resolve these drawbacks, we adopt a delegated approach to performing key puncture operations and propose a generic puncturable signature construction from delegated (key-policy) constrained signatures. We present a concrete puncturable signature scheme over lattices that is proven secure based on the short integer solution (SIS) assumption in the standard model.}
}


@article{DBLP:journals/tifs/AzarKFT24,
	author = {Kimia Zamiri Azar and
                  Hadi Mardani Kamali and
                  Farimah Farahmandi and
                  Mark M. Tehranipoor},
	title = {Improving Bounded Model Checkers Scalability for Circuit De-Obfuscation:
                  An Exploration},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2771--2785},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3357286},
	doi = {10.1109/TIFS.2024.3357286},
	timestamp = {Sun, 19 Jan 2025 14:20:39 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AzarKFT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the globalization and distribution of the semiconductor supply chain, intellectual property (IP) protection has become a necessity. Recent years have witnessed a surge of interest in logic locking as a proactive IP protection solution. However, in recent years, we also have seen an increase in logic/circuit de-obfuscation attacks that put the strength of logic locking at risk. One of these attacks on locked circuits is the bounded-model-checker (BMC)-based attack, where the adversary has limited access to the design-for-testability (DFT) (known as scan chain). While the BMC-based attack is widely known as an algorithmic attack, numerous studies show that the attack lacks scalability since it has two unrolling factors: sequential unrolling and miter duplication. Inspired by straightforward heuristics widely used for satisfiability problems in the computer science SAT community, in this paper, we will explore a set of methodologies that can have a significant impact on mitigating the BMC attack’s scalability issue. For this purpose, through the BMC attack process, we explore the efficacy of “restart” and “initialization” on the attack performance, in which we apply some modification on the locked design before (“initialization”) or within (“restart”) the BMC execution. By applying “restart” and “initialization” in numerous different configurations, our experimental results show >85% consistent improvement in the BMC attack that can lead to a stronger algorithmic attack scenario on logic locking.}
}


@article{DBLP:journals/tifs/CohenCG24,
	author = {Alejandro Cohen and
                  Asaf Cohen and
                  Omer Gurewitz},
	title = {Secure Adaptive Group Testing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2786--2799},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3354188},
	doi = {10.1109/TIFS.2024.3354188},
	timestamp = {Sun, 19 Jan 2025 14:20:39 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CohenCG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Group Testing (GT) addresses the problem of identifying a small subset of defective items from a large population, by grouping items into as few test pools as possible. In Adaptive GT (AGT), outcomes of previous tests can influence the makeup of future tests. Using an information theoretic point of view, Aldridge 2012 showed that in the regime of a few defectives, adaptivity does not help much, as the number of tests required is essentially the same as for non-adaptive GT. Secure GT considers a scenario where there is an eavesdropper who may observe on average a fraction \\delta\nof the tests results, yet should not be able to infer the status of the items. In the non-adaptive scenario, the number of tests required is 1/(1-\\delta)\ntimes the number of tests without the secrecy constraint. In this paper, we consider Secure Adaptive GT. Specifically, when during the makeup of the pools one has access to a private feedback link from the lab, of rate R_{f}\n. We prove that the number of tests required for both correct reconstruction at the legitimate lab, with high probability, and negligible mutual information at the eavesdropper is 1/min\\{1,1-\\delta +R_{f}\\}\ntimes the number of tests required with no secrecy constraint. Thus, unlike non-secure GT, where an adaptive algorithm has only a mild impact, under a security constraint it can significantly boost performance. A key insight is that not only the adaptive link should disregard the actual test results and simply send keys, these keys should be enhanced through a “secret sharing” scheme before usage. We derive sufficiency and necessity bounds that completely characterizes the Secure Adaptive GT capacity. Moreover, we consider additional models of Secure Adaptive GT, where we make a clear distinction between the lab performing the tests, and the doctor analyzing the results. Specifically, we consider curious but non-malicious, non-cooperating labs. Each lab gets a fraction \\delta\nof pool-tests to perform. Yet, we want to keep each lab ignorant regarding the status of the items. In contrast, the doctor who gets all outcomes, should successfully decode. When there is a feedback from each lab, we show that even if a curious lab obviously sees its own feedback (i.e., it is locally-public to Eve), secure adaptive GT is still possible, and at a rate that can be equal to the one without a security constraint at all, by an application of the Leftover Hash Lemma, using the data of one lab to protect against another.}
}


@article{DBLP:journals/tifs/SunCZXG24,
	author = {Rui Sun and
                  Long Chen and
                  Lei Zhang and
                  Ruirui Xie and
                  Jun Gao},
	title = {Robust Visible-Infrared Person Re-Identification Based on Polymorphic
                  Mask and Wavelet Graph Convolutional Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2800--2813},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3354377},
	doi = {10.1109/TIFS.2024.3354377},
	timestamp = {Sun, 19 Jan 2025 14:20:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SunCZXG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When deploying re-identification (ReID) models in the field of public safety, understanding the robustness of models to various types of corrupted images is crucial. Unfortunately, in the real world, images are always contaminated (e.g., noise, blur, and weather changes), which is ignored by existing visible-infrared person re-identification (VI-ReID) models. The performance of existing models tested in corrupted scenes is severely degraded. Therefore, learning corruption-invariant representations for corrupted images in VI-ReID is valuable and deserves further investigation. We design a polymorphic masked wavelet graph convolutional network for VI-ReID under corrupted scenes. Firstly, a cross-modality data augmentation algorithm is designed to construct a mixed image set that merges multi-modality attributes to improve robustness against interference. Secondly, a dual-branch network consisting of a global branch and a graph structure branch is designed. The global branch extracts overall information. While the graph structure branch is a wavelet-based graph convolutional module that utilizes the robustness of human structural information to corruptions and modalities, it can filter noise and extract discriminative features specifically targeted for cross-modality scenes. Finally, the global branch and the graph structure branch are integrated, and modality consistency loss is designed to match the branches with hetero-center triplet loss. Experiments show that our method can effectively alleviate degradation problems under corrupted environments such as noise, blur, digitization, and weather changes, and achieve state-of-the-art on corrupted datasets. Besides, it still maintains good performance on clean datasets, facilitating the reliable deployment of VI-ReID in real-world scenarios.}
}


@article{DBLP:journals/tifs/TangZLCH24,
	author = {Weixuan Tang and
                  Zhili Zhou and
                  Bin Li and
                  Kim{-}Kwang Raymond Choo and
                  Jiwu Huang},
	title = {Joint Cost Learning and Payload Allocation With Image-Wise Attention
                  for Batch Steganography},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2826--2839},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3354411},
	doi = {10.1109/TIFS.2024.3354411},
	timestamp = {Sun, 19 Jan 2025 14:20:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TangZLCH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, although cost learning methods have made great progress in single-image steganography, its development in batch steganography is relatively slower, which is a more practical communication scenario in the real world. The difficulties are capturing the full view of the image batch and building connections between cost learning and payload allocation by neural networks. To address the issues, this paper proposes a cost learning framework for batch steganography called JoCoP (Joint Cost Learning and Payload Allocation), wherein the policy network is designed to learn the optimal embedding policies for a batch of images via the collaboration between a cost learning module and a payload allocation module. In specific layers of the policy network, in the cost learning module, the intermediate feature maps of embedding costs are extracted for different images independently, which are sent to the payload allocation module. In the payload allocation module, to implement implicit payload allocation, the feature maps corresponding to different images within the same batch are adjusted by an image-wise attention mechanism. Afterwards, these adjusted feature maps are returned to the cost learning module for subsequent feature extraction in the next layer. Owing to the collaboration between the two modules and the batch-level receptive field in the image-wise attention mechanism, the embedding costs and the payload allocation can be jointly optimized in an end-to-end manner. Experimental results show that the proposed JoCoP outperforms existing methods against both single-image steganalyzers and pooled steganalyzers based on feature extraction and convolutional neural networks.}
}


@article{DBLP:journals/tifs/YeSZYD24,
	author = {Mang Ye and
                  Wei Shen and
                  Junwu Zhang and
                  Yao Yang and
                  Bo Du},
	title = {SecureReID: Privacy-Preserving Anonymization for Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2840--2853},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356233},
	doi = {10.1109/TIFS.2024.3356233},
	timestamp = {Mon, 17 Feb 2025 20:20:14 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YeSZYD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymization methods have gained widespread use in safeguarding privacy. However, conventional anonymization solutions inevitably lead to the loss of semantic information, resulting in limited data utility. Besides, existing deep learning-based anonymization strategies inadvertently alter the identities of pedestrians, rendering them unsuitable for re-identification (Re-ID) tasks. Beyond these limitations, we propose a joint learning reversible anonymization framework that can reversibly generate full-body anonymized images with little performance drop on Re-ID tasks. Despite these advancements, we reveal that the anonymization methods are vulnerable to model attacks, where attackers can utilize the anonymization model and public data to perform recovery and Re-ID tasks on anonymized images. To defend against the potential attack, we introduce the identity-specific encrypt-decrypt (ISED) architecture for enhanced security, where the anonymized images are encrypted using the specific key for each identity. It renders the images computationally inaccessible to attackers while allowing for seamless reversal without loss using the corresponding keys. Extensive experiments demonstrate that the anonymization framework can guarantee Re-ID performance while protecting pedestrian privacy. In addition, we provide both empirical and theoretical evidence to demonstrate the feasibility of model attacks and the effectiveness of our ISED strategy. Code is available at https://github.com/shentt67/SecureReID.}
}


@article{DBLP:journals/tifs/NicolauPFP24,
	author = {Adri{\'{a}}n Tobar Nicolau and
                  Javier Parra{-}Arnau and
                  Jordi Forn{\'{e}} and
                  Esteve Pallar{\`{e}}s},
	title = {m-Eligibility With Minimum Counterfeits and Deletions for Privacy
                  Protection in Continuous Data Publishing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2854--2864},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3354557},
	doi = {10.1109/TIFS.2024.3354557},
	timestamp = {Sun, 19 Jan 2025 14:20:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/NicolauPFP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous data publishing consists in the republication of updating microdata. The most relevant syntactic notions in continuous data publishing are based on m-invariance. This notion enforces that no user can be distinguished among, at least, m-1\nother users, each with distinct secret data. To achieve m-invariance, the existing methods must first alter the dataset to satisfy a property called m-eligibility. Essentially, a dataset can be made m-invariant if and only if it satisfies the m-eligibility constraint. Although guaranteeing the m-eligibility property is a crucial step, no theoretical study of the best strategies to achieve it has been carried out. This paper performs such a study by giving strategies and demonstrating their optimality under two approaches: insertion of counterfeit tuples and partial publication. The empirical evaluation of our proposal shows a significant reduction on the number of modifications needed to enforce m-eligbility of up to 41% with respect to the literature.}
}


@article{DBLP:journals/tifs/ZhangZWZ24,
	author = {Rui Zhang and
                  Lei Zhang and
                  Qian Wu and
                  Jianying Zhou},
	title = {Secure Channel Establishment Scheme for Task Delivery in Vehicular
                  Cloud Computing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2865--2880},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356809},
	doi = {10.1109/TIFS.2024.3356809},
	timestamp = {Sun, 19 Jan 2025 14:20:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular cloud computing (VCC) is a network architecture that allows a group of entities (i.e., vehicles/roadside infrastructures) to share their resources with other entities. Task delivery in VCC involves the delegation of computation/storage task from a cloud user to some or all the cloud members within a vehicular cloud (VC) for processing. This process inevitably raises concerns regarding how to protect the confidentiality of the task content and the privacy of vehicles. To tackle these challenges, the establishment of a secure channel for task delivery becomes essential. However, the existing secure channel establishment schemes for task delivery in VCC suffer from a few problems including the reliance on a trusted dealer, sender restriction, recipient un-flexibility, or the ignorance of recipient privacy. In this paper, we propose a novel secure channel establishment scheme for task delivery in VCC. It allows a group of entities close to each other to form a VC dynamically without a trusted dealer and allows any entity to be a cloud user who can flexibly select favorable cloud members within a VC to handle its task. The secure channel established by our scheme not only protects the confidentiality of the content of the task but also the privacy of vehicles. Formal security analysis and simulation validate the security and efficiency of our scheme.}
}


@article{DBLP:journals/tifs/LiuLCT24,
	author = {Junlin Liu and
                  Xinchen Lyu and
                  Qimei Cui and
                  Xiaofeng Tao},
	title = {Similarity-Based Label Inference Attack Against Training and Inference
                  of Split Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2881--2895},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356821},
	doi = {10.1109/TIFS.2024.3356821},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLCT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Split learning is a promising paradigm for privacy-preserving distributed learning. The learning model can be cut into multiple portions to be collaboratively trained at the participants by exchanging only the intermediate results at the cut layer. It is crucial to understand the security performance of split learning, particularly for various privacy-sensitive applications. This paper shows that the exchanged intermediate results, including the smashed data (i.e., extracted features from the raw data) and gradients during training and inference of split learning, can already reveal the private labels. We mathematically analyze the potential label leakages and propose the cosine and Euclidean similarity measurements for gradients and smashed data. The two similarity measurements are shown to be unified in Euclidean space. Leveraging the similarity metric, we design three label inference attacks to efficiently recover the private labels during both the training and inference phases. Experimental results validate that the proposed attacks can achieve close to 100% accuracy of label attacks. Furthermore, our proposed attacks can remain effective against various state-of-the-art defense mechanisms, including DP-SGD, label differential privacy, gradient compression, and Marvell.}
}


@article{DBLP:journals/tifs/NguyenTSF24,
	author = {Huy Nguyen and
                  Kien Nguyen Thanh and
                  Sridha Sridharan and
                  Clinton Fookes},
	title = {AG-ReID.v2: Bridging Aerial and Ground Views for Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2896--2908},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3353078},
	doi = {10.1109/TIFS.2024.3353078},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/NguyenTSF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Aerial-ground person re-identification (Re-ID) presents unique challenges in computer vision, stemming from the distinct differences in viewpoints, poses, and resolutions between high-altitude aerial and ground-based cameras. Existing research predominantly focuses on ground-to-ground matching, with aerial matching less explored due to a dearth of comprehensive datasets. To address this, we introduce AG-ReID.v2, a dataset specifically designed for person Re-ID in mixed aerial and ground scenarios. This dataset comprises 100,502 images of 1,615 unique individuals, each annotated with matching IDs and 15 soft attribute labels. Data were collected from diverse perspectives using a UAV, stationary CCTV, and smart glasses-integrated camera, providing a rich variety of intra-identity variations. Additionally, we have developed an explainable attention network tailored for this dataset. This network features a three-stream architecture that efficiently processes pairwise image distances, emphasizes key top-down features, and adapts to variations in appearance due to altitude differences. Comparative evaluations demonstrate the superiority of our approach over existing baselines. We plan to release the dataset and algorithm source code publicly, aiming to advance research in this specialized field of computer vision. For access, please visit https://github.com/huynguyen792/AG-ReID.v2.}
}


@article{DBLP:journals/tifs/AbulibdehYMHSA24,
	author = {Enas E. Abulibdeh and
                  Leen Younes and
                  Baker Mohammad and
                  Khaled Humood and
                  Hani H. Saleh and
                  Mahmoud Al{-}Qutayri},
	title = {DRAM-Based {PUF} Utilizing the Variation of Adjacent Cells},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2909--2918},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3354115},
	doi = {10.1109/TIFS.2024.3354115},
	timestamp = {Sun, 19 Jan 2025 14:20:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AbulibdehYMHSA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Physical Unclonable Function (PUF) is a security mechanism that takes advantage of the physical variations in a device to create a unique response that can be used as a device signature or secure key. However, many DRAM-based PUFs violate the operating rules of commodity DRAM to exploit a source of entropy in the DRAM read path. This work proposes a fast and reliable DRAM-based PUF that evaluates the variation of adjacent cells and produces the response through the normal read operation. The proposed design is implemented using 65-nm technology, and a detailed statistical SPICE simulation verifies its validity. The statistical analysis shows that the proposed PUF achieves 54.19% uniformity and 49.43% uniqueness, with 98% of the investigated responses achieving a Shannon entropy of 0.95. Additionally, the proposed design generates the response by 45~\\mu s , which is at least 66.7 times faster than existing systems. Furthermore, the proposed design uses the relative behavior of cells, which allows for stable responses against temperature and voltage variations, eliminating the need for error correction codes. The proposed PUF also shows resiliency against machine learning-based modeling attacks, as the prediction accuracy does not exceed 55% over 5K Challenge-Response Pairs (CRPs). The area overhead is negligible as the proposed design uses standard circuits, with the addition of only one 2\\times 1 multiplexer at the inputs of the row buffer.}
}


@article{DBLP:journals/tifs/LuoWSYZ24,
	author = {Fucai Luo and
                  Haiyan Wang and
                  Willy Susilo and
                  Xingfu Yan and
                  Xiaofan Zheng},
	title = {Public Trace-and-Revoke Proxy Re-Encryption for Secure Data Sharing
                  in Clouds},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2919--2934},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3357240},
	doi = {10.1109/TIFS.2024.3357240},
	timestamp = {Sat, 16 Mar 2024 15:10:13 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LuoWSYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proxy re-encryption (PRE), as a promising cryptographic primitive for secure data sharing in clouds, has been widely studied for decades. PRE allows the proxies to use the re-encryption keys to convert ciphertexts computed under the delegator’s public key into ones that can be decrypted using the delegatees’ secret keys, without knowing anything about the underlying plaintext. This delegable property of decryption rights enables flexible cloud data sharing, but it raises an important issue: if some proxies reveal their re-encryption keys, or collude with some delegatees to create a pirate decoder, then anyone who gains access to the pirate decoder can decrypt all ciphertexts computed under the delegator’s public key without the delegator’s permission. This paper opens up a potentially new avenue of research to address the above (re-encryption) key abuse problem by proposing the first public trace-and-revoke PRE system, where the malicious delegatees and proxies involved in the generation of a pirate decoder can be identified by anyone who gains access to the pirate decoder, and their decryption capabilities can subsequently be revoked by the content distributor. Our construction is multi-hop, supports user revocation and public (black-box) traceability, and achieves significant efficiency advantages over previous constructions. Technically, our construction is a generic transformation from inner-product functional PRE (IPFPRE) that we introduce to trace-and-revoke PRE. In addition, we instantiate our generic construction of trace-and-revoke PRE from the Learning with Errors (LWE) assumption, which was widely believed to be quantum-resistant. This is achieved by proposing the first LWE-based IPFPRE scheme, which may be of independent interest. Finally, we conduct a comprehensive performance evaluation of our LWE-based trace-and-revoke PRE scheme, and the experimental results show that the proposed LWE-based trace-and-revoke PRE scheme is practical and outperforms current state-of-the-art traceable PRE schemes.}
}


@article{DBLP:journals/tifs/DuLHC24,
	author = {Runmeng Du and
                  Xuru Li and
                  Daojing He and
                  Kim{-}Kwang Raymond Choo},
	title = {Toward Secure and Verifiable Hybrid Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2935--2950},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3357288},
	doi = {10.1109/TIFS.2024.3357288},
	timestamp = {Sun, 19 Jan 2025 14:20:39 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DuLHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reducing computation cost and ensuring update integrity, are key challenges in federated learning (FL). In this paper, we present a secure and verifiable hybrid FL system for training, namely SVHFL. SVHFL enables training models on both plaintext and encrypted data simultaneously. Furthermore, we propose a mutual verification scheme for the integrity of updates in FL. It is a general and efficient scheme that can eliminate malformed updates from clients and enforce the integrity checks of the aggregation results from the server. The training and verification schemes of SVHFL have reduced the computation cost from a quadratic cost to a linear cost. The experimental results demonstrate the practicality of SVHFL.}
}


@article{DBLP:journals/tifs/YangXSWZ24,
	author = {He Yang and
                  Wei Xi and
                  Yuhao Shen and
                  Canhui Wu and
                  Jizhong Zhao},
	title = {RoseAgg: Robust Defense Against Targeted Collusion Attacks in Federated
                  Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2951--2966},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352415},
	doi = {10.1109/TIFS.2024.3352415},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangXSWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent defense approaches against targeted model poisoning attacks aim to prevent specific prediction failures in federated learning (FL). However, these defenses remain susceptible to targeted collusion attacks, particularly under conditions of high proportions of malicious clients and attack density. To address these vulnerabilities, we propose RoseAgg, which dynamically identifies a plausible clean ingredient from local updates and leverages it to constrain the influence of poisoned updates. Firstly, RoseAgg recognizes and confines common characteristics found in poisoned updates, such as scaled-up magnitudes or similar directional contributions. Furthermore, RoseAgg dynamically extracts a plausible clean ingredient using a dimension-reduction method. This clean ingredient becomes the foundation for the server to bootstrap credit scores for each local update, ensuring the dominance of benign updates over poisoned ones. Ultimately, the server computes a weighted average of local updates based on credit scores, generating a global update for refining the global model. Comprehensive evaluations on four benchmark datasets showcase RoseAgg’s effectiveness against seven advanced attacks. The code is available at https://github.com/SleepedCat/RoseAgg.}
}


@article{DBLP:journals/tifs/LiLTLLL24,
	author = {Haozhe Li and
                  Yilin Liao and
                  Zijian Tian and
                  Zhaoran Liu and
                  Jiaqi Liu and
                  Xinggao Liu},
	title = {Bidirectional Stackable Recurrent Generative Adversarial Imputation
                  Network for Specific Emitter Missing Data Imputation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2967--2980},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352393},
	doi = {10.1109/TIFS.2024.3352393},
	timestamp = {Sun, 19 Jan 2025 14:20:44 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiLTLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Specific emitter identification (SEI) uses the electromagnetic pulse signal sent by emitter to determine the emitter individual. In the actual complex electromagnetic environment, due to the interference of external signals and hardware failures, it is difficult to obtain sufficient and complete transmitter signal data. The missing data imputation methods are used to impute the emitter signal data. However, the existing imputation methods need to rely on the complete signal data to train the deep learning model, and the imputation error is large due to the long sequence characteristics of the signal. Therefore, a new specific emitter missing data imputation model is proposed, which is called bidirectional stackable recurrent generative adversarial imputation network (BiSRGAIN) including a generator and a discriminator. Specifically, the bidirectional stackable recurrent (BiSR) unit is designed to be used in generators and discriminators, which simplifies the traditional recurrent neural network (RNN) structure and improves parameter utilization and inference efficiency. The novel loss function can make the training of the model independent of the true value of the missing components, so the model can be trained in incomplete data. Extensive experiments are conducted on real-world dataset. The results show that the proposed model has lower errors under the scenario of high missing rate. In addition, the proposed model has higher parameter utilization and computational efficiency. Moreover, the completed signal data after imputation is used to identify specific emitters, and the results show that the data obtained by BiSRGAIN can achieve higher recognition accuracy.}
}


@article{DBLP:journals/tifs/TihanyiBBR24,
	author = {Norbert Tihanyi and
                  Tam{\'{a}}s Bisztray and
                  Bertalan Borsos and
                  Sebastien Raveau},
	title = {Privacy-Preserving Password Cracking: How a Third Party Can Crack
                  Our Password Hash Without Learning the Hash Value or the Cleartext},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2981--2996},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356162},
	doi = {10.1109/TIFS.2024.3356162},
	timestamp = {Sun, 19 Jan 2025 14:20:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TihanyiBBR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Using the computational resources of an untrusted third party to crack a password hash can pose a high number of privacy and security risks. The act of revealing the hash digest could in itself negatively impact both the data subject who created the password, and the data controller who stores the hash digest. This paper solves this currently open problem by presenting a Privacy-Preserving Password Cracking protocol (3PC), that prevents the third party cracking server from learning any useful information about the hash digest, or the recovered cleartext. This is achieved by a tailored anonymity set of decoy hashes, based on the concept of predicate encryption, where we extend the definition of a predicate function, to evaluate the output of a one way hash function. The probabilistic information the server obtains during the cracking process can be calculated and minimized to a desired level. While in theory, cracking more hashes would introduce additional overhead, the 3PC protocol enables constant-time lookup regardless of the list size, limited by the input/output operation per second (IOPS) capabilities of the third-party server, allowing the protocol to scale efficiently. We demonstrate these claims both theoretically and in practice, with a real-life use case implemented on an FPGA architecture.}
}


@article{DBLP:journals/tifs/LiangWLCCPX24,
	author = {Ying Liang and
                  Wenjie Wu and
                  Haobo Li and
                  Xiaojun Chang and
                  Xiaojiang Chen and
                  Jinye Peng and
                  Pengfei Xu},
	title = {DCS-Gait: {A} Class-Level Domain Adaptation Approach for Cross-Scene
                  and Cross-State Gait Recognition Using Wi-Fi {CSI}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2997--3007},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356827},
	doi = {10.1109/TIFS.2024.3356827},
	timestamp = {Sun, 19 Jan 2025 14:20:39 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiangWLCCPX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wi-Fi CSI-based gait recognition is a non-intrusive passive biometric identification technology that has garnered significant attention in the fields of security and smart furniture due to its user-friendly nature. However, in practical application scenarios, gait recognition systems face the challenge of reliably identifying subjects across different scenes or states. To overcome this challenge, this paper proposes DCS-Gait, a domain adaptation solution for cross-scene and cross-state gait recognition based on Wi-Fi CSI. DCS-Gait leverages a novel data distribution measurement called Cross-Attention Metric to align the class-level data distribution differences, enabling the model to learn invariant features across scenes and states. To address the issue of data annotation, we employ a pre-training method to obtain pseudo labels for the dataset. Additionally, a combined matching filtering technique is utilized to generate high-quality pseudo labels for unrecognized data, which can be further employed for supervised model training. We evaluated the effectiveness of DCS-Gait on a large test set consisting of 34 subjects, 2 scenes, and 3 different states, and the results demonstrate significant improvements over the state-of-the-art baselines in both cross-scene and cross-state gait recognition tasks. DCS-Gait provides a promising and reliable solution for accurate cross-scene and cross-state gait recognition in real-world settings.}
}


@article{DBLP:journals/tifs/DuanJYYXL24,
	author = {Mingxing Duan and
                  Kailun Jiao and
                  Siyang Yu and
                  Zhibang Yang and
                  Bin Xiao and
                  Kenli Li},
	title = {MC-Net: Realistic Sample Generation for Black-Box Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3008--3022},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356812},
	doi = {10.1109/TIFS.2024.3356812},
	timestamp = {Sun, 04 Aug 2024 19:49:38 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DuanJYYXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One area of current research on adversarial attacks is how to generate plausible adversarial examples when only a small number of datasets are available. Current adversarial attack algorithms used to attack these black-box systems face a number of challenges, such as difficulty in training convergence, ambiguous sample images, substitute models collapse, unsatisfactory attack success rates, high query cost, and low defense capability improvement of target models. As a result, constructing plausible adversarial situations in a few known real-world sample circumstances remains difficult. As a solution to the aforementioned issues, this study introduces MC-Net, a novel multi-stage and multi-class balanced generating method based on a limited number of samples to generate realistic adversarial examples. Firstly, a multi-task learning approach is used to train the GAN by fully utilizing the small samples, ensuring that the size of the generated dataset for each category is balanced. In addition, we design a weight-balancing strategy to ensure faster convergence of each sub-network. Then, in the second stage, the generated samples of different categories are used to train a substitute model, and the distillation method is adopted to learn the output distribution of the target model. Finally, adversarial examples are constructed on the generated samples to complete the attack on the target models. Extensive experiments have proven that MC-Net has the following advantages: 1) The substitute model converges quickly using limited samples and queries; 2) High attack success rates can be obtained with a few queries; and 3) The constructed adversarial examples significantly improve the target model’s defense. Furthermore, we only utilize a few queries for the Microsoft Azure online model to obtain a satisfactory result. Our code can be found at https://github.com/jiaokailun/A-fast.}
}


@article{DBLP:journals/tifs/LiuCWWFZ24,
	author = {Jieli Liu and
                  Jinze Chen and
                  Jiajing Wu and
                  Zhiying Wu and
                  Junyuan Fang and
                  Zibin Zheng},
	title = {Fishing for Fraudsters: Uncovering Ethereum Phishing Gangs With Blockchain
                  Data},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3038--3050},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359000},
	doi = {10.1109/TIFS.2024.3359000},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuCWWFZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As one of the most typical cybercrime types, phishing scams have extended the devil’s hand to the emerging blockchain ecosystem in recent years. Especially huge economic losses have been caused by phishing scams in Ethereum, the second-largest blockchain system. Existing approaches for Ethereum phishing detection, however, typically use machine learning or transaction graph embedding methods to identify phishers in isolation and do not effectively uncover the group of transaction accounts linked to scams (which we term a “gang”). Since accounts are pseudonymous in Ethereum, these undisclosed conspirator accounts have potential risks to the system. In this paper, we conduct the first study that characterizes and detects Ethereum phishing gangs. We first investigate the transaction behaviors in phishing gangs from the perspectives of individuals, pairs, and higher-order patterns. Our analysis reveals that although the Ethereum transaction graph is sparse with a highly skewed degree distribution, phishing accounts in the same gang have closer relationships and share specific transaction patterns. Based on our findings, we formalize the phishing gang detection problem and introduce a novel detection model named PGDetector. Given a risky phishing account as a seed, PGDetector can find out the potential risky accounts sharing close relationships within the seed’s community based on genetic algorithm optimization. Experimental results on large-scale Ethereum transaction data demonstrate the effectiveness of PGDetector.}
}


@article{DBLP:journals/tifs/LongYZP24,
	author = {Min Long and
                  Quantao Yao and
                  Le{-}Bing Zhang and
                  Fei Peng},
	title = {Face De-Morphing Based on Diffusion Autoencoders},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3051--3063},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359029},
	doi = {10.1109/TIFS.2024.3359029},
	timestamp = {Wed, 06 Nov 2024 15:38:04 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LongYZP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face morphing attacks pose a significant threat to society as they disrupt the one-to-one mapping between facial images and identity features in face recognition systems. Despite the development of several detection methods to counter such attacks, the task of restoring the facial image of the accomplice from the morphed facial image, known as face de-morphing, remains a challenging problem. In this paper, we propose a novel diffusion-based method for face de-morphing. This method employs pre-trained diffusion autoencoders to encode the image into two subspaces: a semantic latent space that captures identity features and a stochastic latent space that retains the remaining stochastic details. To ensure the effective separation of identity features, a dual-branch identity separation network is constructed in the semantic latent space. This network utilizes a cross-attention inverse linear interpolation branch to separate the accomplice’s semantic latent code and a multilayer perceptron branch to complement the separated latent code. Additionally, the morphed stochastic latent code is empirically chosen as the accomplice’s stochastic latent code. Finally, a conditional denoising diffusion implicit model is used to decode the latent code of the two subspaces, thus achieving the restoration of the accomplice’s facial image. Experimental results and analysis demonstrate that the proposed method outperforms existing face de-morphing methods in terms of restoration accuracy and image quality.}
}


@article{DBLP:journals/tifs/QingBLMW24,
	author = {Yuanyuan Qing and
                  Tao Bai and
                  Zhuotao Liu and
                  Pierre Moulin and
                  Bihan Wen},
	title = {Detection of Adversarial Attacks via Disentangling Natural Images
                  and Perturbations},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {2814--2825},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352837},
	doi = {10.1109/TIFS.2024.3352837},
	timestamp = {Sun, 19 Jan 2025 14:20:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/QingBLMW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The vulnerability of deep neural networks against adversarial attacks, i.e., imperceptible adversarial perturbations can easily give rise to wrong predictions, poses a huge threat to the security of their real-world deployments. In this paper, a novel Adversarial Detection method via Disentangling Natural images and Perturbations (ADDNP) is proposed. Compared to natural images that can typically be modeled by lower-dimensional subspaces or manifolds, the distributions of adversarial perturbations are much more complex, e.g., one normal example’s adversarial counterparts generated by different attack strategies can be significantly distinct. The proposed ADDNP exploits such distinct properties for the detection of adversarial attacks amongst normal examples. Specifically, we use a dual-branch disentangling framework to encode natural images and perturbations of inputs separately, followed by joint reconstruction. During inference, the reconstruction discrepancy (RD) measured in the learned latent feature space is used as an indicator of adversarial perturbations. The proposed ADDNP algorithm is evaluated on three popular datasets, i.e., CIFAR-10, CIFAR-100, and mini ImageNet with increasing data complexity, across multiple popular attack strategies. Compared to the existing and state-of-the-art detection methods, ADDNP has demonstrated promising performance on adversarial detection, with significant improvements on more challenging datasets.}
}


@article{DBLP:journals/tifs/LiWLCZ24,
	author = {Zhankai Li and
                  Weiping Wang and
                  Jie Li and
                  Kai Chen and
                  Shigeng Zhang},
	title = {{UCG:} {A} Universal Cross-Domain Generator for Transferable Adversarial
                  Examples},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3023--3037},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352913},
	doi = {10.1109/TIFS.2024.3352913},
	timestamp = {Sat, 16 Mar 2024 15:10:13 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiWLCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generating transferable adversarial examples is a challenging issue in adversarial attacks. Existing works on transferable adversarial examples generation mainly focus on models with similar architectures and trained on the same data domain. However, in practice, information such as the model architecture type and training data domain is unlikely to be revealed in deployed models. In this work, we introduce the Universal Cross-domain Generator (UCG), a pioneering framework for transferable adversarial examples that is the first to simultaneously address both cross-domain and cross-architecture challenges in adversarial attacks. The design of UCG is mainly inspired by two key observations. First, there exists some commonality in attention regions even when the structures of models are different. Second, there exists prevalent instability of intermediate-feature maps across cross-domain models. We accordingly design an attention transfer mechanism and a roughness abatement mechanism to enhance the cross-architecture and cross-domain transferability of the generated adversarial examples. Moreover, we propose an integrated transformation processing technique to improve the transferability of the generated adversarial examples under different transformations. Experimental results demonstrate that, compared with state-of-the-art solutions, UCG improves the average transferable attack success rate by 14.6%, 7.8%, and 7.9% in the cross-architecture task (convolutional neural networks (CNNs) to vision transformers (ViTs)), coarse-grained cross-domain tasks, and fine-grained cross-domain tasks, respectively.}
}


@article{DBLP:journals/tifs/WenCFWTR24,
	author = {Yun Wen and
                  Gaojie Chen and
                  Sisai Fang and
                  Miaowen Wen and
                  Stefano Tomasin and
                  Marco Di Renzo},
	title = {RIS-Assisted {UAV} Secure Communications With Artificial Noise-Aware
                  Trajectory Design Against Multiple Colluding Curious Users},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3064--3076},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356166},
	doi = {10.1109/TIFS.2024.3356166},
	timestamp = {Sun, 19 Jan 2025 14:20:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WenCFWTR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a secure unmanned aerial vehicle (UAV) communication system with the assistance of a reconfigurable intelligent surface (RIS), where the design of the UAV trajectory and artificial noise are incorporated to prevent eavesdropping from multiple colluding curious users. To maximize the secrecy rate of the proposed system, we undertake a joint optimization process that encompasses the trajectory of the UAV, the RIS phase shifts, and the beamforming vectors for both information and artificial noise signals, considering the constraints of the UAV transmit power, UAV flying speed and RIS phase shifts. To address the non-convex nature of the joint problem and handle the coupling effects of multiple parameters, we decompose the problem by using the block coordinate descent (BCD) method, combined with an alternating algorithm to optimize the obtained sub-problems. To further tackle the non-convexity of the sub-problems, we apply the successive convex approximation (SCA) method to tackle the optimization of the trajectory and to optimize the beamformers of information and artificial noise signals, while a majorization-minimization (MM) based scheme is adopted for optimizing the RIS phase shifts. Numerical simulation results substantiate the convergence and effectiveness of the proposed algorithm through the comparison with benchmark methods, and the proposed scheme is proven to achieve a significant improvement in terms of average secrecy rate in various operating conditions.}
}


@article{DBLP:journals/tifs/ShengYZZZ24,
	author = {Chuan Sheng and
                  Yu Yao and
                  Lianxiang Zhao and
                  Peng Zeng and
                  Jianming Zhao},
	title = {Scanner-Hunter: An Effective {ICS} Scanning Group Identification System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3077--3092},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359002},
	doi = {10.1109/TIFS.2024.3359002},
	timestamp = {Wed, 05 Feb 2025 17:14:29 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ShengYZZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the precursor of cyber-attacks, the campaigns of scanning groups are able to reflect the attack target and attack trend to a great extent, which provide highly valuable threat intelligence for cyber defenders to understand the current cyber security situation. However, how to identify scanning groups in the context of limited information, especially in the absence of relevant threat intelligence, remains a challenging problem. In this paper, we utilize the honeynet as the unique data source to propose a scanning group identification system, Scanner-Hunter, which focuses on identifying scanning groups targeting ICS devices. To better characterize scanning patterns, a novel traffic representation scheme for scanning traffic is proposed, which is composed of a set of feature vectors to describe all the ICS request packets. On this basis, we propose a novel self-expanding multi-class classification (SEMCC) model and the IP prefix judgment, which are deliberately integrated to cope with sophisticated scanning groups. Take the Modbus protocol as an example, we implement a prototype of Scanner-Hunter, and use six years of real-world honeynet datasets to evaluate its performance. The experimental results illustrate its effectiveness and superior performance compared with some popular machine learning methods and existing SOTA scanning group identification methods. In addition, Scanner-Hunter is further leveraged to investigate the group distribution and maliciousness of 506 unknown scanners, and some suspicious attack groups with APT characteristics are analyzed. Furthermore, accurate scanning group information will contribute to revealing potential attack organizations and supporting decision making to prevent or interrupt cyber-attacks in time.}
}


@article{DBLP:journals/tifs/JiangLSML24,
	author = {Fangling Jiang and
                  Yunfan Liu and
                  Haolin Si and
                  Jingjing Meng and
                  Qi Li},
	title = {Cross-Scenario Unknown-Aware Face Anti-Spoofing With Evidential Semantic
                  Consistency Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3093--3108},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356234},
	doi = {10.1109/TIFS.2024.3356234},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiangLSML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, domain adaptation techniques have been widely used to adapt face anti-spoofing models to a cross-scenario target domain. Most previous methods assume that the Presentation Attack Instruments (PAIs) in such cross-scenario target domains are the same as in the source domain. However, since malicious users are free to use any form of unknown PAIs to attack the system, this assumption does not always hold in practical applications of face anti-spoofing. Thus, unknown PAIs would inevitably lead to significant performance degradation, since samples of known and unknown PAIs usually have large differences. In this paper, we propose an Evidential Semantic Consistency Learning (ESCL) framework to address this problem. Specifically, a regularized evidential deep learning strategy with a two-way balance of class probability and uncertainty is leveraged to produce uncertainty scores for unknown PAI detection. Meanwhile, an entropy optimization-based semantic consistency learning strategy is also employed to encourage features of live and known PAIs to be gathered in the label-conditioned clusters across the source and target domains, while making the features of unknown PAIs to be self-clustered according to intrinsic semantic information. In addition, a new evaluation metric, KUHAR, is proposed to comprehensively evaluate the error rate of known classes and unknown PAIs. Extensive experimental results on six public datasets demonstrate the effectiveness of our method in generalizing face anti-spoofing models to both known classes and unknown PAIs with different types and quantities in a cross-scenario testing domain. Our method achieves state-of-the-art performance on eight different protocols.}
}


@article{DBLP:journals/tifs/HuangWYHL24,
	author = {Baojin Huang and
                  Zhongyuan Wang and
                  Jifan Yang and
                  Zhen Han and
                  Chao Liang},
	title = {Unlabeled Data Assistant: Improving Mask Robustness for Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3109--3123},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3354109},
	doi = {10.1109/TIFS.2024.3354109},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangWYHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The existing masked face recognition algorithms almost tend to adopt synthetic masked face datasets for training. However, these models are limited as they rely on existing mask augmentation methods, which contain few mask patterns and cannot simulate shadows and textures in realistic scenes. To overcome this limitation, we propose a semi-supervised face recognition framework to fully exploit unlabeled real masked face samples, improving the mask robustness of the recognition model. More specifically, unlike the original face embedding network, we design a part-aware network to explore multi-region face representation based on the face structure. In this way, we obtain multiple face sub-embeddings, which correspond to different regions of the face, including the upper half, the lower half and the whole. Crucially, we use the norm of the sub-embedding to represent the activation state of the facial region features. For the input unlabeled masked face image, we restrict the sub-embedding norm of its lower half to weaken the face feature representation of the occluded area. For normal face samples, their partial features are kept activated by maintaining the sub-embedding norm, which guides the deep network does not ignore the available information. Moreover, we employ the margin-based recognition loss for normal samples to ensure that the model is sufficiently discriminative for normal facial features. Extensive experimental results on both normal and real masked face datasets show that our approach significantly outperforms the state-of-the-arts. Code is available at https://github.com/Baojin-Huang/UFace.}
}


@article{DBLP:journals/tifs/TuttTCPBHV24,
	author = {Joakim Tutt and
                  Olga Taran and
                  Roman Chaban and
                  Brian Pulfer and
                  Yury Belousov and
                  Taras Holotyak and
                  Slava Voloshynovskiy},
	title = {Authentication of Copy Detection Patterns: {A} Pattern Reliability
                  Based Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3124--3134},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359510},
	doi = {10.1109/TIFS.2024.3359510},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TuttTCPBHV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Copy Detection Pattern (CDP) technology is a promising anti-counterfeiting solution for the protection of physical goods. In recent years, it has been shown that this technology is threatened by powerful deep learning attacks that are able to bypass original authentication schemes. In this paper, we tackle this problem by proposing a new CDP authentication scheme based on statistical knowledge discovered about the printing and imaging process. The novelty of our approach lies in providing means to measure the reliability of each local pattern appearing in the CDP. This allows to define new authentication measures to better differentiate original CDP from fakes. Our results show that this new system is capable of performing reliable CDP authentication with smartphones without the need for heavyweight machine learning tools requiring massive data entries.}
}


@article{DBLP:journals/tifs/LiYYLY24,
	author = {Shuai Li and
                  Zhemin Yang and
                  Yunteng Yang and
                  Dingyi Liu and
                  Min Yang},
	title = {Identifying Cross-User Privacy Leakage in Mobile Mini-Apps at a Large
                  Scale},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3135--3147},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356197},
	doi = {10.1109/TIFS.2024.3356197},
	timestamp = {Sun, 19 Jan 2025 14:20:44 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiYYLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the characteristics of free installation and rich functionalities, mobile mini-apps have become more and more popular in people’s daily life. A large amount of sensitive personal data is thus involved in them and shared across users for providing various services, which raises great privacy concerns. However, few researchers have paid attention to the potential privacy risks that may exist when user data is shared across users in mobile mini-apps. In this paper, we introduce a novel privacy risk that is brought forward by cross-user personal data over-delivery (denoted as XPO) in mobile mini-apps. Such a discovered privacy risk is demonstrated to be able to cause serious leakage of diverse user data. To detect XPO risk, a dynamic and lightweight mini-app analysis framework – XPOScope is proposed. XPOScope is able to automatically identify XPO risk at a large scale. By applying it to 4,273 mini-apps hosted on three popular platforms, i.e., WeChat, Baidu and Alipay, XPOScope reported 71 vulnerable ones, with a precision of 92.21% and a recall of 80.68%. In addition to the mere exposure of diverse private user data, case studies performed show that XPO in mini-apps can further lead to impersonation attacks, the infringement of employees’ privacy, economic loss and even the leakage of sensitive business secrets. The results call for the awareness and actions of mobile mini-app developers to secure cross-user personal data delivery. The code of this work is available at https://github.com/ppflower/XPOScope.}
}


@article{DBLP:journals/tifs/ZhangCDYZY24,
	author = {Xin Zhang and
                  Kejiang Chen and
                  Jinyang Ding and
                  Yuqi Yang and
                  Weiming Zhang and
                  Nenghai Yu},
	title = {Provably Secure Public-Key Steganography Based on Elliptic Curve Cryptography},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3148--3163},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361219},
	doi = {10.1109/TIFS.2024.3361219},
	timestamp = {Sun, 19 Jan 2025 14:20:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangCDYZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Steganography is the technique of hiding secret messages within seemingly harmless covers to elude examination by censors. Despite having been proposed several decades ago, provably secure steganography has not gained popularity among researchers due to its rigorous data requirements. Recent advancements in generative models have enabled these researchers to provide explicit data distributions, which has contributed to the development of provably secure steganography methods. However, these methods depend on the assumption of a preshared key. In practical settings, these methods face various challenges, including key agreement, key updating, and user expansion. Although public-key steganography provides a viable solution, existing public-key steganography approaches are burdened with inefficiency and complex implementation in practical scenarios. In this paper, we proposes a practical public-key steganography method based on elliptic curve cryptography and a generative model. This method is the first comprehensive and practical approach to public-key steganography and steganographic key exchange. Additionally, we provide a specific instance to illustrate the proposed method. The security of the proposed construction is also proven based on computational complexity theory. Further experiments have demonstrated the security and efficiency of the proposed method.}
}


@article{DBLP:journals/tifs/ZhangZJZSW24,
	author = {Shenyi Zhang and
                  Baolin Zheng and
                  Peipei Jiang and
                  Lingchen Zhao and
                  Chao Shen and
                  Qian Wang},
	title = {Perception-Driven Imperceptible Adversarial Attack Against Decision-Based
                  Black-Box Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3164--3177},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359441},
	doi = {10.1109/TIFS.2024.3359441},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZJZSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial examples (AEs) pose significant threats to deep neural networks (DNNs), as they can deceive models into making wrong predictions through craftily-designed perturbations. The emergence of decision-based attacks, which rely solely on the top-1 decision label, further increases risks for real-world black-box models. Currently, the prevailing practice for generating AEs in the decision-based setting involves penalizing adversarial perturbations with the \\ell _{p} -norm. However, this approach often overlooks the human perception of adversarial perturbations in real-world scenarios. To tackle this issue, we propose a novel and efficient Imperceptible Decision-based Black-box Attack (IDBA). Our method prioritizes optimizing the perception-related distribution of perturbations, rather than solely focusing on the \\ell _{p} -norm. Specifically, IDBA analyzes the perceptual preferences of both models and the human vision system, selectively perturbing components that influence model decisions yet remain imperceptible to human eyes. Extensive experiments demonstrate that IDBA outperforms the state-of-the-art methods in terms of invisibility and query efficiency. Notably, IDBA achieves a high Feature SIMilarity (FSIM) score of 0.92 with only 4,800 queries, while simultaneously reducing the Learned Perceptual Image Patch Similarity (LPIPS) to 0.12, showcasing its ability to remain imperceptible.}
}


@article{DBLP:journals/tifs/LiuLWZLLLS24,
	author = {Andi Liu and
                  Yizhong Liu and
                  Qianhong Wu and
                  Boyu Zhao and
                  Dongyu Li and
                  Yuan Lu and
                  Rongxing Lu and
                  Willy Susilo},
	title = {{CHERUBIM:} {A} Secure and Highly Parallel Cross-Shard Consensus Using
                  Quadruple Pipelined Two-Phase Commit for Sharding Blockchains},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3178--3193},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3358990},
	doi = {10.1109/TIFS.2024.3358990},
	timestamp = {Sun, 19 Jan 2025 14:20:39 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLWZLLLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the promising scalability property, sharding technology has gained widespread attention. It improves the transaction throughput of blockchain systems but also introduces cross-shard transactions. Current two-phase commit (2PC) protocols process different cross-shard transactions sequentially, resulting in significant system overhead and low throughput. Besides, current sharding blockchains rely on Byzantine fault tolerance (BFT) as a black box, lacking specific designs to efficiently handle cross-shard proposals. Moreover, cross-shard communication complexity is high, and transaction processing parallelism is low. In this paper, we first propose P-2PC, a general framework to process cross-shard transactions of different phases in a pipelined way, suitable for most sharding blockchains. Further, we design Cherubim with improved quadruple 2PC, 4P-2PC. By combining P-2PC with an intra-shard pipelined BFT, 4P-2PC achieves both intra-shard and cross-shard pipelined processing. Combined with a newly designed batch processing method, each shard processes 4 transaction batches simultaneously through 1 round of calculation and communication, compared to 4 rounds in previous work. In particular, Cherubim seamlessly integrates a multi-signature algorithm supporting further aggregation, reducing communication complexity. Furthermore, we evaluate our work through theoretical analysis and implementation, proving that Cherubim has a communication complexity linear to the node number. We also propose horizontal and vertical consensus parallelism degrees to evaluate the parallelism ability. Compared to the state-of-the-art solutions, the evaluation demonstrates that Cherubim achieves a transaction throughput improvement of at least 2.28 \\times\n.}
}


@article{DBLP:journals/tifs/FadulRWLST24,
	author = {Mohamed K. M. Fadul and
                  Donald R. Reising and
                  Lakmali P. Weerasena and
                  T. Daniel Loveless and
                  Mina Sartipi and
                  Joshua H. Tyler},
	title = {Improving {RF-DNA} Fingerprinting Performance in an Indoor Multipath
                  Environment Using Semi-Supervised Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3194--3209},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3360851},
	doi = {10.1109/TIFS.2024.3360851},
	timestamp = {Sun, 19 Jan 2025 14:20:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FadulRWLST24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) deployments are expected to reach 75.4 billion by 2025. Roughly 70% of all IoT devices employ weak or no encryption, thus putting them and their connected infrastructure at risk of attack by devices that are wrongly authenticated or not authenticated. A physical layer-based security approach–known as Specific Emitter Identification (SEI)–has been proposed and is being pursued as a viable IoT security mechanism. SEI is advantageous because it is a passive technique that exploits inherent and distinct features unintentionally imparted upon the signal during its formation and transmission within and by the IoT device’s Radio Frequency (RF) front end. SEI’s passive exploitation of unintentional signal features removes any need to modify the IoT device, which makes it ideal for existing and future IoT deployments. Despite the amount of SEI research conducted, challenges must be addressed to make SEI a viable IoT security approach. One of these challenges is extracting SEI features from signals collected under multipath fading conditions. Multipath corrupts the inherent SEI exploited features that discriminate one IoT device from another, thus degrading authentication performance and increasing the chance of attack. This work presents two semi-supervised Deep Learning (DL) equalization approaches and compares their performance with the current state of the art. The two approaches are the Conditional Generative Adversarial Network (CGAN) and the Joint Convolutional Auto-Encoder and Convolutional Neural Network (JCAECNN). Both approaches learn the channel distribution to enable multipath correction while preserving the SEI exploited signal features. CGAN and JCAECNN performance is assessed using a Rayleigh fading channel under degrading SNR, up to thirty-two IoT devices, and two publicly available signal sets. The JCAECNN improves SEI performance by 10% beyond the current state of the art.}
}


@article{DBLP:journals/tifs/ZhaoZWKY24,
	author = {Mengnan Zhao and
                  Lihe Zhang and
                  Wei Wang and
                  Yuqiu Kong and
                  Baocai Yin},
	title = {Adversarial Attacks on Scene Graph Generation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3210--3225},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3360880},
	doi = {10.1109/TIFS.2024.3360880},
	timestamp = {Sun, 19 Jan 2025 14:20:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoZWKY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Scene graph generation (SGG) effectively improves semantic understanding of the visual world. However, the recent interest of researchers focuses on enhancing SGG in non-adversarial settings, which raises our curiosity about the adversarial robustness of SGG models. To bridge this gap, we perform adversarial attacks on two typical SGG tasks, Scene Graph Detection (SGDet) and Scene Graph Classification (SGCls). Specifically, we initially propose a bounding box relabeling method to reconstruct reasonable attack targets for SGCls. It solves the inconsistency between the specified bounding boxes and the scene graphs selected as attack targets. Subsequently, we introduce a two-step weighted attack by removing the predicted objects and relational triples that affect attack performance, which significantly increases the success rate of adversarial attacks on two SGG tasks. Extensive experiments demonstrate the effectiveness of our methods on five popular SGG models and four adversarial attacks. The Pytorch® implementation can be downloaded from an open-source Github project https://github.com/Dlut-lab-zmn/SGG_Attack.}
}


@article{DBLP:journals/tifs/WenM24,
	author = {Daolin Wen and
                  Xiaowu Mu},
	title = {Secure Dual Asynchronous Tracking Control for Markov Jump Systems
                  Under Hybrid Cyberattacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3226--3236},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359459},
	doi = {10.1109/TIFS.2024.3359459},
	timestamp = {Sun, 19 Jan 2025 14:20:44 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WenM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, the secure dual asynchronous tracking control problem is studied for Markov jump systems (MJSs) under hybrid cyberattacks via memory-based event-triggered mechanisms (ETMs). For the first time, both the tracking system (TS) and the reference system (RS) are considered to be MJSs, and a novel dual asynchronous controller is proposed based on hidden Markov model for the case that the mode information of the TS and the RS cannot be accurately received. In order to reduce the redundant data transmission, a novel asynchronous memory-based ETM is designed by introducing two window functions. In addition, considering the openness of network, two independent random variables are introduced to characterize the cyberattacks on tracking system-controller channel and reference system-controller channel respectively. By constructing suitable Lyapunov functionals, sufficient conditions are given to guarantee the stochastic stability and H_{\\infty}\nperformance of the resulted system. Finally, simulation examples are given to verify the effectiveness of the proposed strategy.}
}


@article{DBLP:journals/tifs/ZengCZZY24,
	author = {Kai Zeng and
                  Kejiang Chen and
                  Jiansong Zhang and
                  Weiming Zhang and
                  Nenghai Yu},
	title = {Toward Secure and Robust Steganography for Black-Box Generated Images},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3237--3250},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361220},
	doi = {10.1109/TIFS.2024.3361220},
	timestamp = {Tue, 07 May 2024 20:18:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZengCZZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The progression of text-to-image generation models has incited an upsurge in disseminating generated images across social networks, providing a fertile ground for steganography. Presently, the majority of generated images are crafted utilizing black-box APIs and social networks employ lossy compression on uploaded images. However, there is a dearth of steganographic research conducted on black-box generated images, and the distinctive attributes of the generation model have not been harnessed, resulting in a performance that fails to achieve both security and robustness simultaneously. To address these challenges, we propose an innovative steganographic framework, Steganography based on Concomitantly shaRing generated Images and PrompTs (SCRIPT). This framework ensures security and robustness by precisely identifying robust coefficients within the image for message embedding and synchronizing their positions. For precise identification, we assess the ability of coefficients to withstand unknown spatial perturbations, employing this metric to quantify their robustness. For positional synchronization of robust coefficients, the relevant prompts are uploaded alongside the stego image, allowing the recipient to reconstruct the cover image using a mutually agreed random seed and the provided prompt. Subsequently, positional synchronization is achieved by consistently adopting an identical method for selecting robust coefficients between the sender and the recipient. By amalgamating these strategies, SCRIPT significantly surpasses prior algorithms. Empirical results validate our approach, with a noteworthy 98% message extraction success rate and a substantial 20%+ enhancement in security across diverse payloads.}
}


@article{DBLP:journals/tifs/NgCLT24,
	author = {Tiong{-}Sik Ng and
                  Jacky Chen Long Chai and
                  Cheng{-}Yaw Low and
                  Andrew Beng Jin Teoh},
	title = {Self-Attentive Contrastive Learning for Conditioned Periocular and
                  Face Biometrics},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3251--3264},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361216},
	doi = {10.1109/TIFS.2024.3361216},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/NgCLT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Periocular and face are two common biometric modalities for identity management. Recently, the emergence of conditional biometrics has enabled the exploitation of the correlation between face and periocular to enhance each modality’s performance, in which we coin intra-modal matching in this paper. However, limitations arise in each modality, particularly when wearing sunglasses or helmets, causing the absence of periocular or facial occlusion. A biometric system empowered with inter-modal matching capability between periocular and face is essential to mitigate these challenges. This paper presents a novel reciprocal learning model that utilizes periocular and face conditioning to facilitate flexible intra-modal and inter-modal matching. To address the intra-modal matching challenge, we devise a lightweight Gated Convolutional Channel-wise Self-Attention Network that enables selective attention to shared salient periocular and face features. On the other hand, to bridge the modality gap without sacrificing the intra-modal matching performance, we propose a modality and augmentation-aware contrastive loss that incorporates semi-supervised positive sampling and alignment-specific logit rescaling. Extensive identification and verification experiments on five face-periocular datasets under the open-set protocol attest to the efficacy of our proposed methods. Codes are publicly available at https://github.com/tiongsikng/gc2sa_net.}
}


@article{DBLP:journals/tifs/YangLLZFZWLS24,
	author = {Yulong Yang and
                  Chenhao Lin and
                  Qian Li and
                  Zhengyu Zhao and
                  Haoran Fan and
                  Dawei Zhou and
                  Nannan Wang and
                  Tongliang Liu and
                  Chao Shen},
	title = {Quantization Aware Attack: Enhancing Transferable Adversarial Attacks
                  by Model Quantization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3265--3278},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3360891},
	doi = {10.1109/TIFS.2024.3360891},
	timestamp = {Sun, 19 Jan 2025 14:20:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangLLZFZWLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantized neural networks (QNNs) have received increasing attention in resource-constrained scenarios due to their exceptional generalizability. However, their robustness against realistic black-box adversarial attacks has not been extensively studied. In this scenario, adversarial transferability is pursued across QNNs with different quantization bitwidths, which particularly involve unknown architectures and defense methods. Previous studies claim that transferability is difficult to achieve across QNNs with different bitwidths on the condition that they share the same architecture. However, we discover that under different architectures, transferability can be largely improved by using a QNN quantized with an extremely low bitwidth as the substitute model. We further improve the attack transferability by proposing quantization aware attack (QAA), which fine-tunes a QNN substitute model with a multiple-bitwidth training objective. In particular, we demonstrate that QAA addresses the two issues that are commonly known to hinder transferability: 1) quantization shifts and 2) gradient misalignments. Extensive experimental results validate the high transferability of the QAA to diverse target models. For instance, when adopting the ResNet-34 substitute model on ImageNet, QAA outperforms the current best attack in attacking standardly trained DNNs, adversarially trained DNNs, and QNNs with varied bitwidths by 4.3% ~ 20.9%, 8.7% ~ 15.5%, and 2.6% ~ 31.1% (absolute), respectively. In addition, QAA is efficient since it only takes one epoch for fine-tuning. In the end, we empirically explain the effectiveness of QAA from the view of the loss landscape. Our code is available at https://github.com/yyl-github-1896/QAA/.}
}


@article{DBLP:journals/tifs/XuCYLT24,
	author = {Peng Xu and
                  Gaojie Chen and
                  Zheng Yang and
                  Yong Li and
                  Stefano Tomasin},
	title = {Multiple Access Wiretap Channel With Partial Rate-Limited Feedback},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3279--3294},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359071},
	doi = {10.1109/TIFS.2024.3359071},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XuCYLT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the problem of secure transmission over a two-user discrete memoryless multiple-access wiretap channel with partial rate-limited feedback (MAC-WT-PLF). The receiver can causally and securely transmit feedback to one of the transmitters at a limited rate. Three achievable rate regions and one outer bound on the secrecy capacity are presented based on three proposed coding schemes and the Sato-type bounding approach. The proposed coding schemes show that the feedback can play multiple roles, i.e., encrypting part of messages, enlarging the size of the dummy message, and increasing the correlation between the channel inputs, to enhance the secrecy performance. Of particular interest is identifying the novel role of enlarging the size of the dummy message at one of the transmitters, which enables both transmitters to benefit from the feedback significantly. In addition, the proposed achievable rate regions and outer bound are computed for the Gaussian MAC-WT-PLF, and comparative numerical results are provided under different eavesdropping cases.}
}


@article{DBLP:journals/tifs/YeZGZ24,
	author = {Dayong Ye and
                  Tianqing Zhu and
                  Kun Gao and
                  Wanlei Zhou},
	title = {Defending Against Label-Only Attacks via Meta-Reinforcement Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3295--3308},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3357292},
	doi = {10.1109/TIFS.2024.3357292},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YeZGZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning models are susceptible to a range of adversarial activities. These attacks are designed to either infer private information from the target model or deceive it. For instance, an attacker may attempt to discern if a given data example is from the model’s training set (membership inference attacks) or create adversarial examples to mislead the model to make incorrect predictions (adversarial example attacks). Numerous defense methods have been proposed to counter these attacks. However, these methods typically share two common limitations. Firstly, most are not designed to address label-only attacks, which is a newly emerged kind of attacks that rely solely on the hard labels predicted by the target model. Secondly, they are often developed to mitigate specific attacks rather than universally various attacks. To address these limitations, this paper proposes a novel defense method that focuses on the most challenging attacks, i.e., label-only attacks, and can handle various types of label-only attacks. The key idea is to strategically modify the target model’s predicted labels using a meta-reinforcement learning technique. This ensures that attackers receive incorrect labels while benign users continue to receive correct labels. Notably, the defender, i.e., the owner of the target model, can make effective decisions without knowledge of the attacker’s behavior. The experimental results demonstrate that our proposed method is an effective defense against a range of attacks, including label-only model stealing, label-only membership inference, label-only model inversion, and label-only adversarial example attacks.}
}


@article{DBLP:journals/tifs/WengYDHWW24,
	author = {Jia{-}Si Weng and
                  Shenglong Yao and
                  Yuefeng Du and
                  Junjie Huang and
                  Jian Weng and
                  Cong Wang},
	title = {Proof of Unlearning: Definitions and Instantiation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3309--3323},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3358993},
	doi = {10.1109/TIFS.2024.3358993},
	timestamp = {Sun, 19 Jan 2025 14:20:39 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WengYDHWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The “Right to be Forgotten” rule in machine learning (ML) practice enables some individual data to be deleted from a trained model, as pursued by recently developed machine unlearning techniques. To truly comply with the rule, a natural and necessary step is to verify if the individual data are indeed deleted after unlearning. Yet, previous parameter-space verification metrics may be easily evaded by a distrustful model trainer. Thus, Thudi et al. recently present a call to action on algorithm-level verification in USENIX Security’22. We respond to the call, by reconsidering the unlearning problem in the scenario of machine learning as a service (MLaaS), and proposing a new definition framework for Proof of Unlearning (PoUL) on algorithm level. Specifically, our PoUL definitions (i) enforce correctness properties on both the pre and post phases of unlearning, so as to prevent the state-of-the-art forging attacks; (ii) highlight proper practicality requirements of both the prover and verifier sides with minimal invasiveness to the off-the-shelf service pipeline and computational workloads. Under the definition framework, we subsequently present a trusted hardware-empowered instantiation using SGX enclave, by logically incorporating an authentication layer for tracing the data lineage with a proving layer for supporting the audit of learning. We customize authenticated data structures to support large out-of-enclave storage with simple operation logic, and meanwhile, enable proving complex unlearning logic with affordable memory footprints in the enclave. We finally validate the feasibility of the proposed instantiation with a proof-of-concept implementation and multi-dimensional performance evaluation.}
}


@article{DBLP:journals/tifs/ChenWTW24,
	author = {Xingyu Chen and
                  Huici Wu and
                  Xiaofeng Tao and
                  Haowei Wang},
	title = {Polar Coding for Wiretap Channels With Random States Non-Causally
                  Available at the Encoder},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3324--3338},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3358992},
	doi = {10.1109/TIFS.2024.3358992},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenWTW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Channel state information (CSI) is differently available at each terminal in state-dependent wiretap channels (SD-WTCs). Considering a random channel state non-causally available only at the encoder, this paper investigates an explicit polar coding scheme for the discrete and memoryless SD-WTC, where Alice aims to transmit a secret message (SM) and a secret key (SK) to Bob while concealing them from Eve. Based on a two-layer superposition coding, which includes an inner layer and an outer layer, the proposed polar coding scheme can achieve the inner bound of the current optimal SM-SK capacity region for the discrete and memoryless SD-WTC with CSI non-causally available only at the encoder. A cross-layer construction is proposed to address the issue where the regular chaining construction used in wiretap polar codes cannot be applied in the inner layer. Results show that the decoding error probability (DEP) of the legitimate decoder vanishes to zero as the block length increases. In addition, the proposed scheme is proven to satisfy strong secrecy.}
}


@article{DBLP:journals/tifs/YangWYCTCJ24,
	author = {Qing Yang and
                  Cheng Wang and
                  Haifeng Yuan and
                  Jipeng Cui and
                  Teng Hu and
                  Xue Chen and
                  Changjun Jiang},
	title = {Approaching the Information-Theoretic Limit of Privacy Disclosure
                  With Utility Guarantees},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3339--3352},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3354412},
	doi = {10.1109/TIFS.2024.3354412},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangWYCTCJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The possibility for public attributes to disclose private information has caused widespread concern. Traditional privacy-preserving approaches have two limitations: 1) Approaches based on data anonymization or distortion often lead to poor utility-privacy trade-offs, and 2) approaches based on data encryption face heavy computational costs. These problems have prompted calls for an effective privacy-preserving framework that provides adequate privacy guarantees while maintaining good data utility. Inspired by denoising autoencoders, in this paper, we regard the information about privacy attributes contained in the public attributes as a kind of noise and design an ex ante privacy-preserving model called the Mutual Information Autoencoder (MIAE), which reconstructs the loss function of the original autoencoder by combining reconstruction errors and mutual information, and we introduce a trade-off coefficient to achieve utility-privacy trade-offs. To elucidate the superiority of the proposed model, we consider utility-privacy trade-offs with the expected distortion function as a metric of data utility and the joint mutual information as a metric of privacy disclosure, and then, we construct a convex optimization problem with multiple constraints based on rate-distortion theory. From an information theory perspective, we provide a lower bound for privacy disclosure with utility guarantees. Elaborate experiments over a real-world dataset reveal that as the level of expected distortion increases, the achievable bound obtained by MIAE exhibits a trend similar to that of the information-theoretic bound. When the expected distortion surpasses 2.2, the achievable bound obtained by MIAE also converges to 0, and the maximum gap between the achievable bound obtained by MIAE and the information-theoretic bound is no more than 1.4. Compared to existing models, MIAE can provide a tighter achievable bound and achieve good utility-privacy trade-offs.}
}


@article{DBLP:journals/tifs/TosunS24,
	author = {Tolun Tosun and
                  Erkay Savas},
	title = {Zero-Value Filtering for Accelerating Non-Profiled Side-Channel Attack
                  on Incomplete NTT-Based Implementations of Lattice-Based Cryptography},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3353--3365},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359890},
	doi = {10.1109/TIFS.2024.3359890},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TosunS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Lattice-based cryptographic schemes such as Crystals-Kyber and Dilithium are post-quantum algorithms selected to be standardized by NIST as they are considered to be secure against quantum computing attacks. The multiplication in polynomial rings is the most time-consuming operation in many lattice-based cryptographic schemes, which is also subject to side-channel attacks. While NTT-based polynomial multiplication is almost a norm in a wide range of implementations, a relatively new method, incomplete NTT is preferred to accelerate lattice-based cryptography, especially on some computing platforms that feature special instructions. In this paper, we present a novel, efficient and non-profiled power/EM side-channel attack targeting polynomial multiplication based on the incomplete NTT algorithm. We apply the attack on the Crystals-Dilithium signature algorithm and Crystals-Kyber KEM. We demonstrate that the method accelerates attack run-time when compared to the existing approaches. While a conventional non-profiled side-channel attack tests a much larger hypothesis set because it needs to predict two coefficients of secret polynomials together, we propose a much faster zero-value filtering attack (ZV-FA), which reduces the size of the hypothesis set by targeting the coefficients individually. We also propose an effective and efficient validation and correction technique employing the inverse NTT to estimate and modify the mispredicted coefficients. Our experimental results show that we can achieve a speed-up of {1915}\\times over brute-force.}
}


@article{DBLP:journals/tifs/JiJLSX24,
	author = {Xiaoyu Ji and
                  Qinhong Jiang and
                  Chaohao Li and
                  Zhuoyang Shi and
                  Wenyuan Xu},
	title = {Watch Your Speed: Injecting Malicious Voice Commands via Time-Scale
                  Modification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3366--3379},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352394},
	doi = {10.1109/TIFS.2024.3352394},
	timestamp = {Sat, 16 Mar 2024 15:10:13 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiJLSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing adversarial example (AE) attacks against automatic speech recognition (ASR) systems focus on adding deliberate noises to input audio. In this paper, we propose a new attack that purely speeds up or slows down original audio instead of adding perturbations, and we call it Time-Scale Modification Adversarial Example (TSMAE). By investigating the impact of speed variation on 100, 000 pieces of audio clips, we found that misrecognition manifests in three categories: delete, substitution, and insertion. These are the accumulated results caused by the misrecognition of both the acoustic and language models inside an ASR system. Despite the challenges, i.e., ASR systems are typically black-box and reveal no gradient information, we managed to launch one-segment untargeted and targeted TSMAE attacks based on particle swarm optimization algorithms. Our untargeted attacks only require modifying the speed of one segment (e.g., 20 ms), and our targeted attacks can generate meaningful yet benign audio to cause an ASR system to output a malicious output, e.g., “open the door”. We validate the feasibility of TSMAE on two open-source ASR models (e.g., DeepSpeech and Sphinx) and four commercial ones (e.g., IBM, Google, Baidu, and iFLYTEK). Results show that our untargeted attack can successfully attack all 6 ASR models with one segment modification, and our targeted attack is robust to various factors, such as model versions and speech sources. Finally, both attacks can bypass existing open-source defense methods, and our insights call attention to the defense’s focus from coping with perturbation to emerging adversarial example attacks.}
}


@article{DBLP:journals/tifs/ChenZJZGG24,
	author = {Zhuo Chen and
                  Liehuang Zhu and
                  Peng Jiang and
                  Can Zhang and
                  Feng Gao and
                  Fuchun Guo},
	title = {Exploring Unobservable Blockchain-Based Covert Channel for Censorship-Resistant
                  Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3380--3394},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361212},
	doi = {10.1109/TIFS.2024.3361212},
	timestamp = {Sun, 19 Jan 2025 14:20:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenZJZGG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain-based censorship-resistant systems enable the user to access the blocked content through a covert channel while avoiding a suspicious network connection between the user and the proxy. However, state-of-the-art blockchain-based censorship-resistant schemes cannot satisfy both low communication fees and unobservability, and their method of identifying transactions with covert data may inadvertently expose the covert channel. In this paper, we present Hades, a blockchain-based covert channel framework that aims to circumvent censorship. Hades allows users to encode covert data as a transaction field, and identify transactions with covert data by using another transaction field as a label. We also present the security model for Hades, which defines the unobservability of Hades as the indistinguishability of transactions with covert data from normal transactions. We further propose two cost-friendly and unobservable instantiations of Hades: the basic RDSAC and the improved DDSAC. RDSAC uses private keys to encode covert data and utilizes random factors in the signing process as labels, while incurring a communication delay. DDSAC avoids the delay by encoding covert data into random factors and sampling a transaction amount from normal transactions as the label. We implement a prototype system of Hades and evaluate its performance. Experiment results show that our Hades prototype is unobservable, robust, and efficient. RDSAC and DDSAC can identify 1,654 transactions in 6.054 seconds and 0.071 seconds, respectively. Hades supports 1KB data transfer at \\\\(0.44 on the Bitcoin mainnet and cost-free data transfer on the Bitcoin testnet.}
}


@article{DBLP:journals/tifs/BelousovQPCTTHV24,
	author = {Yury Belousov and
                  Guillaume Qu{\'{e}}tant and
                  Brian Pulfer and
                  Roman Chaban and
                  Joakim Tutt and
                  Olga Taran and
                  Taras Holotyak and
                  Slava Voloshynovskiy},
	title = {A Machine Learning-Based Digital Twin for Anti-Counterfeiting Applications
                  With Copy Detection Patterns},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3395--3408},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361798},
	doi = {10.1109/TIFS.2024.3361798},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BelousovQPCTTHV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present a new approach to model a printing-imaging channel using a machine learning-based “digital twin” for copy detection patterns (CDP). The CDP are considered as modern anti-counterfeiting features in multiple applications. Our digital twin is formulated within the information-theoretic framework of TURBO initially developed for high energy physics simulations, using variational approximations of mutual information for both encoder and decoder in the bidirectional exchange of information. This model extends various architectural designs, including paired pix2pix and unpaired CycleGAN, for image-to-image translation. Applicable to any type of printing and imaging devices, the model needs only training data comprising digital templates sent to a printing device and data acquired by an imaging device. The data can be paired, unpaired, or hybrid, ensuring architectural flexibility and scalability for multiple practical setups. We explore the influence of various architectural factors, metrics, and discriminators on the overall system’s performance in generating and predicting printed CDP from their digital versions and vice versa. We also performed a comparison with several state-of-the-art methods for image-to-image translation applications. The simulation code and extended results are publicly available at https://gitlab.unige.ch/sip-group/digital-twin.}
}


@article{DBLP:journals/tifs/XiaLLYWG24,
	author = {Ruiyang Xia and
                  Decheng Liu and
                  Jie Li and
                  Lin Yuan and
                  Nannan Wang and
                  Xinbo Gao},
	title = {MMNet: Multi-Collaboration and Multi-Supervision Network for Sequential
                  Deepfake Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3409--3422},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361151},
	doi = {10.1109/TIFS.2024.3361151},
	timestamp = {Tue, 26 Nov 2024 20:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XiaLLYWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced manipulation techniques have provided criminals with opportunities to make social panic or gain illicit profits through the generation of deceptive media, such as forgery face images. In response, various deepfake detection methods have been proposed to assess image authenticity. Sequential deepfake detection, which is an extension of deepfake detection, aims to identify forged facial regions with the correct sequence for recovery. Nonetheless, due to the different combinations of spatial and sequential manipulations, forgery face images exhibit substantial discrepancies that severely impact detection performance. Additionally, the recovery of forged images requires knowledge of the manipulation model to implement inverse transformations, which is difficult to ascertain as relevant techniques are often concealed by attackers. To address these issues, we propose Multi-Collaboration and Multi-Supervision Network (MMNet) that handles various spatial scales and sequential permutations in forgery face images and achieve recovery without requiring knowledge of the corresponding manipulation method. Furthermore, existing evaluation metrics only consider detection accuracy at a single inferring step, without accounting for the matching degree with ground-truth under continuous multiple steps. To overcome this limitation, we propose a novel evaluation metric called Complete Sequence Matching (CSM), which considers the detection accuracy at multiple inferring steps, reflecting the ability to detect integrally forged sequences. Extensive experiments on several typical datasets demonstrate that MMNet achieves state-of-the-art detection performance and independent recovery performance. Code will be available at https://github.com/xarryon/MMNet}
}


@article{DBLP:journals/tifs/HuGZY24,
	author = {Songlin Hu and
                  Xiaohua Ge and
                  Wei Zhang and
                  Dong Yue},
	title = {DoS-Resilient Load Frequency Control of Multi-Area Power Systems:
                  An Attack-Parameter-Dependent Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3423--3434},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361159},
	doi = {10.1109/TIFS.2024.3361159},
	timestamp = {Sun, 19 Jan 2025 14:20:44 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuGZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper is concerned with a resilient load frequency control (LFC) of multi-area power systems subject to unknown load disturbances and intermittent denial-of-service (DoS) attacks. The central aim is to develop a feasible and less conservative DoS-resilient LFC scheme that constrains jammer’s actions as less as possible and explores available attack information as much as possible in desired analysis and design criteria. Towards this aim, we first present a partially known DoS model that bounds merely the DoS-on durations. We then elaborate a sampled-data-based transmission paradigm which characterizes explicitly the uniform sampling instants and intermittent DoS-on and -off instants as well as the nonuniform arriving instants of the transmitted system data. Furthermore, we develop a novel attack-parameter-dependent Lyapunov functional to establish less conservative conditions for both stability analysis and controller design. It is shown that the exponential stability of the resultant closed-loop LFC system can be guaranteed, while also preserving both the desired minimum sleeping rate of DoS attacks and the prescribed H_{\\infty }\nperformance index against changing load disturbances. Finally, several case studies of a three-area power system are provided to verify the effectiveness and superiority of the derived theoretical results.}
}


@article{DBLP:journals/tifs/QiuZJFYW24,
	author = {Pengyu Qiu and
                  Xuhong Zhang and
                  Shouling Ji and
                  Chong Fu and
                  Xing Yang and
                  Ting Wang},
	title = {HashVFL: Defending Against Data Reconstruction Attacks in Vertical
                  Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3435--3450},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3356164},
	doi = {10.1109/TIFS.2024.3356164},
	timestamp = {Tue, 04 Feb 2025 20:31:50 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/QiuZJFYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vertical Federated Learning (VFL) is a trending collaborative machine learning model training solution. Existing industrial frameworks employ secure multi-party computation techniques such as homomorphic encryption to ensure data security and privacy. Despite these efforts, studies have revealed that data leakage remains a risk in VFL due to the correlations between intermediate representations and raw data. Neural networks can accurately capture these correlations, allowing an adversary to reconstruct the data. This emphasizes the need for continued research into securing VFL systems. Our work shows that hashing is a promising solution to counter data reconstruction attacks. The one-way nature of hashing makes it difficult for an adversary to recover data from hash codes. However, implementing hashing in VFL presents new challenges, including vanishing gradients and information loss. To address these issues, we propose HashVFL, which integrates hashing and simultaneously achieves learnability, bit balance, and consistency. Experimental results indicate that HashVFL effectively maintains task performance while defending against data reconstruction attacks. It also brings additional benefits in reducing the degree of label leakage, mitigating adversarial attacks, and detecting abnormal inputs. We hope our work will inspire further research into the potential applications of HashVFL.}
}


@article{DBLP:journals/tifs/XieYWBCW24,
	author = {Dong Xie and
                  Jinghua Yang and
                  Bin Wu and
                  Weixin Bian and
                  Fulong Chen and
                  Taochun Wang},
	title = {An Effectively Applicable to Resource Constrained Devices and Semi-Trusted
                  Servers Authenticated Key Agreement Scheme},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3451--3464},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3362589},
	doi = {10.1109/TIFS.2024.3362589},
	timestamp = {Thu, 29 Feb 2024 20:53:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XieYWBCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In a mobile edge computing environment, the computing tasks of resource-constrained IoT devices are often offloaded to mobile edge computing servers for processing. In order to ensure the security of the task offloading process, both parties need to perform mutual authentication and negotiate a session key first. The security defenses in the existing authentication schemes are often only aimed at external attackers, while ignoring the possible malicious behaviors of semi-trusted servers. Furthermore, they cannot effectively take into account the device-side lightweight and security, as well as the load problem of a single registry. In this paper, we propose a new anonymous authentication key agreement scheme that fully considers the resource constraints of terminal devices and the security risks of semi-trusted servers. In the scheme, we use the method of generating pairing information during registration to avoid the server-side directly contacting the user’s private information, and support trusted third parties not to participate in the authentication process. In addition, by setting up authentication servers to outsource computing tasks, the device-side can avoid blindly selecting a computing server for task offloading, achieve accurate task assignment and efficient execution of authentication. We use Real-Or-Random model and BAN logic to demonstrate the security of the proposed scheme, and use the ProVerif tool to verify its authenticated reachability and confidentiality. Compared with other schemes with the same structure, this scheme is superior to similar schemes, and has higher security on the basis of ensuring the least amount of computation on the device-side.}
}


@article{DBLP:journals/tifs/LiZYNAP24,
	author = {Kai Li and
                  Jingjing Zheng and
                  Xin Yuan and
                  Wei Ni and
                  {\"{O}}zg{\"{u}}r B. Akan and
                  H. Vincent Poor},
	title = {Data-Agnostic Model Poisoning Against Federated Learning: {A} Graph
                  Autoencoder Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3465--3480},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3362147},
	doi = {10.1109/TIFS.2024.3362147},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiZYNAP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a novel, data-agnostic, model poisoning attack on Federated Learning (FL), by designing a new adversarial graph autoencoder (GAE)-based framework. The attack requires no knowledge of FL training data and achieves both effectiveness and undetectability. By listening to the benign local models and the global model, the attacker extracts the graph structural correlations among the benign local models and the training data features substantiating the models. The attacker then adversarially regenerates the graph structural correlations while maximizing the FL training loss, and subsequently generates malicious local models using the adversarial graph structure and the training data features of the benign ones. A new algorithm is designed to iteratively train the malicious local models using GAE and sub-gradient descent. The convergence of FL under attack is rigorously proved, with a considerably large optimality gap. Experiments show that the FL accuracy drops gradually under the proposed attack and existing defense mechanisms fail to detect it. The attack can give rise to an infection across all benign devices, making it a serious threat to FL.}
}


@article{DBLP:journals/tifs/WuZL24,
	author = {Jiahui Wu and
                  Weizhe Zhang and
                  Fucai Luo},
	title = {On the Security of "LSFL: {A} Lightweight and Secure Federated
                  Learning Scheme for Edge Computing"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3481--3482},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3331274},
	doi = {10.1109/TIFS.2023.3331274},
	timestamp = {Mon, 26 Aug 2024 17:32:33 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Zhang et al. (2023) recently proposed a secure federated learning (FL) scheme named LSFL to guarantee Byzantine robustness while protecting privacy in FL. In this work, we show that LSFL breaches privacy it claimed. Specifically, we demonstrate that the secure Byzantine robustness procedure of LSFL exposes significant information of all participant models and data to a semi-honest server, thereby damaging privacy. Then, we analyze the reason for this security issue and give a suggestion to prevent privacy breaches in LSFL.}
}


@article{DBLP:journals/tifs/FuWNZ24,
	author = {Xingquan Fu and
                  Guanghui Wen and
                  Mengfei Niu and
                  Wei Xing Zheng},
	title = {Distributed Secure Filtering Against Eavesdropping Attacks in SINR-Based
                  Sensor Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3483--3494},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361177},
	doi = {10.1109/TIFS.2024.3361177},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FuWNZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper focuses on the design of a privacy-preserving distributed Kalman filtering algorithm for a class of linear time-varying systems in signal-to-interference-plus-noise ratio (SINR)-based sensor networks, where packet dropouts may occur in information transmission between neighboring sensor nodes. Considering the potential occurrence of eavesdropping attacks during information transmission, which is common due to the inherent vulnerability of SINR-based sensor networks, a new class of distributed secure Kalman filtering algorithm is developed. The presented algorithm incorporates a modified ElGamal cryptosystem and adaptive fusion weights to significantly enhance security, resist privacy leakage, and bolster robustness against packet dropping. Then, a detailed performance analysis for the presented distributed secure Kalman filtering algorithm is conducted, where the security and unbiasedness of the designed algorithm are discussed. Sufficient conditions for the stability of the estimation error are further established to ensure that the estimation error is ultimately bounded in the almost sure sense. Finally, numerical examples are given to illustrate the effectiveness of the proposed algorithm.}
}


@article{DBLP:journals/tifs/MaZY24,
	author = {Jingzhe Ma and
                  Xiaoqing Zhang and
                  Shiqi Yu},
	title = {An Identity-Preserved Framework for Human Motion Transfer},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3495--3509},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364018},
	doi = {10.1109/TIFS.2024.3364018},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MaZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human motion transfer (HMT) aims to generate a video clip for the target subject by imitating the source subject’s motion. Although previous methods have achieved good results in synthesizing good-quality videos, they lose sight of individualized motion information from the source and target motions, which is significant for the realism of the motion in the generated video. To address this problem, we propose a novel identity-preserved HMT network, termed IDPres. This network is a skeleton-based approach that uniquely incorporates the target’s individualized motion and skeleton information to augment identity representations. This integration significantly enhances the realism of movements in the generated videos. Our method focuses on the fine-grained disentanglement and synthesis of motion. To improve the representation learning capability in latent space and facilitate the training of IDPres, we introduce three training schemes. These schemes enable IDPres to concurrently disentangle different representations and accurately control them, ensuring the synthesis of ideal motions. To evaluate the proportion of individualized motion information in the generated video, we are the first to introduce a new quantitative metric called Identity Score (ID-Score), motivated by the success of gait recognition methods in capturing identity information. Moreover, we collect an identity-motion paired dataset, Dancer101\n, consisting of solo-dance videos of 101 subjects from the public domain, providing a benchmark to prompt the development of HMT methods. Extensive experiments demonstrate that the proposed IDPres method surpasses existing state-of-the-art techniques in terms of reconstruction accuracy, realistic motion, and identity preservation.}
}


@article{DBLP:journals/tifs/YangJYXWW24,
	author = {Fenghong Yang and
                  Runqing Jiang and
                  Yan Yan and
                  Jing{-}Hao Xue and
                  Biao Wang and
                  Hanzi Wang},
	title = {Dual-Mode Learning for Multi-Dataset X-Ray Security Image Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3510--3524},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364368},
	doi = {10.1109/TIFS.2024.3364368},
	timestamp = {Sun, 19 Jan 2025 14:20:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangJYXWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the recent advance of deep learning, a large number of methods have been developed for prohibited item detection in X-ray security images. Generally, these methods train models on a single X-ray image dataset that may contain only limited categories of prohibited items. To detect more prohibited items, it is desirable to train a model on the multi-dataset that is constructed by combining multiple datasets. However, directly applying existing methods to the multi-dataset cannot guarantee good performance because of the large domain discrepancy between datasets and the occlusion in images. To address the above problems, we propose a novel Dual-Mode Learning Network (DML-Net) to effectively detect all the prohibited items in the multi-dataset. In particular, we develop an enhanced RetinaNet as the architecture of DML-Net, where we introduce a lattice appearance enhanced sub-net to enhance appearance representations. Such a way benefits the detection of occluded prohibited items. Based on the enhanced RetinaNet, the learning process of DML-Net involves both common mode learning (detecting the common prohibited items across datasets) and unique mode learning (detecting the unique prohibited items in each dataset). For common mode learning, we introduce an adversarial prototype alignment module to align the feature prototypes from different datasets in the domain-invariant feature space. For unique mode learning, we take advantage of feature distillation to enforce the student model to mimic the features extracted by multiple pre-trained teacher models. By tightly combining and jointly training the dual modes, our DML-Net method successfully eliminates the domain discrepancy and exhibits superior model capacity on the multi-dataset. Extensive experimental results on several combined X-ray image datasets demonstrate the effectiveness of our method against several state-of-the-art methods. Our code is available at https://github.com/vampirename/dmlnet.}
}


@article{DBLP:journals/tifs/LiangXLLKZ24,
	author = {Wei Liang and
                  Siqi Xie and
                  Kuan{-}Ching Li and
                  Xiong Li and
                  Xiaoyan Kui and
                  Albert Y. Zomaya},
	title = {{MC-DSC:} {A} Dynamic Secure Resource Configuration Scheme Based on
                  Medical Consortium Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3525--3538},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364370},
	doi = {10.1109/TIFS.2024.3364370},
	timestamp = {Fri, 17 May 2024 21:40:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiangXLLKZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain technology, with its unique decentralized and tamper-resistant features, is being utilized to address the issue of information silos in traditional electronic healthcare. However, as healthcare data sources become increasingly complex and numerous, the limited scalability and transaction throughput of traditional blockchains result in challenges such as slow processing efficiency and vulnerability to attacks in modern healthcare blockchain systems. To address these issues, we propose a Dynamic Security Resource Configuration scheme based on Medical Consortium Blockchain (MC-DSC). This scheme allows for dynamic blockchain configuration based on the varying urgency levels of data, enhancing data processing efficiency. It ensures the security of the data processing process through identity control and data encryption methods. Experimental results demonstrate that, compared to existing blockchain configuration algorithms (SsHealth and Medge-Chain), the proposed scheme achieves approximately a 15% performance improvement by dynamically configuring the blockchain for three data types (secure, urgent, and normal). Additionally, the security module accounts for only 7% of the total time overhead, efficiently safeguarding the security of healthcare data while effectively handling data with different urgency levels.}
}


@article{DBLP:journals/tifs/WahrstatterSDBS24,
	author = {Anton Wahrst{\"{a}}tter and
                  Matthew Solomon and
                  Ben DiFrancesco and
                  Vitalik Buterin and
                  Davor Svetinovic},
	title = {BaseSAP: Modular Stealth Address Protocol for Programmable Blockchains},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3539--3553},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364081},
	doi = {10.1109/TIFS.2024.3364081},
	timestamp = {Sun, 19 Jan 2025 14:20:39 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WahrstatterSDBS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stealth addresses represent an approach to enhancing privacy within public and distributed blockchains, such as Ethereum and Bitcoin. Stealth address protocols employ a distinct, randomly generated address for the recipient, thereby concealing interactions between entities. In this study, we introduce BaseSAP, an autonomous base-layer protocol for embedding stealth addresses within the application layer of programmable blockchains. BaseSAP expands upon previous research to develop a modular protocol for executing unlinkable transactions on public blockchains. BaseSAP allows for the development of additional stealth address layers using different cryptographic algorithms on top of the primary implementation, capitalizing on its modularity. To demonstrate the effectiveness of our proposed protocol, we present simulations of an advanced Secp256k1-based dual-key stealth address protocol. This protocol is developed on top of BaseSAP and deployed on the Ethereum test network as the first prototype implementation. Furthermore, we provide cost analyses and underscore potential security ramifications and attack vectors that could affect the privacy of stealth addresses. Our study highlights the flexibility of the BaseSAP protocol and provides insights into the broader implications of stealth address technology in the realm of blockchain privacy.}
}


@article{DBLP:journals/tifs/MandlikPSB24,
	author = {Simon Mandl{\'{\i}}k and
                  Tom{\'{a}}s Pevn{\'{y}} and
                  V{\'{a}}clav Sm{\'{\i}}dl and
                  Luk{\'{a}}s Bajer},
	title = {Malicious Internet Entity Detection Using Local Graph Inference},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3554--3566},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3360867},
	doi = {10.1109/TIFS.2024.3360867},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MandlikPSB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detection of malicious behavior in a large network is a challenging problem for machine learning in computer security, since it requires a model with high expressive power and scalable inference. Existing solutions struggle to achieve this feat—current cybersec-tailored approaches are still limited in expressivity, and methods successful in other domains do not scale well for large volumes of data, rendering frequent retraining impossible. This work proposes a new perspective for learning from graph data that is modeling network entity interactions as a large heterogeneous graph. High expressivity of the method is achieved with neural network architecture HMILnet that naturally models this type of data and provides theoretical guarantees. The scalability is achieved by pursuing local graph inference, i.e., classifying individual vertices and their neighborhood as independent samples. Our experiments exhibit improvement over the state-of-the-art Probabilistic Threat Propagation (PTP) algorithm, show a further threefold accuracy improvement when additional data is used, which is not possible with the PTP algorithm, and demonstrate the generalization capabilities of the method to new, previously unseen entities.}
}


@article{DBLP:journals/tifs/ZhuMLZZ24,
	author = {Yulin Zhu and
                  Tomasz P. Michalak and
                  Xiapu Luo and
                  Xiaoge Zhang and
                  Kai Zhou},
	title = {Toward Secrecy-Aware Attacks Against Trust Prediction in Signed Social
                  Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3567--3580},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364366},
	doi = {10.1109/TIFS.2024.3364366},
	timestamp = {Fri, 17 May 2024 21:40:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuMLZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Signed social networks are widely used to model the trust relationships among online users in security-sensitive systems such as cryptocurrency trading platforms, where trust prediction plays a critical role. In this paper, we investigate how attackers could mislead trust prediction by secretly manipulating signed networks. To this end, we first design effective poisoning attacks against representative trust prediction models. The attacks are formulated as hard bi-level optimization problems, for which we propose several efficient approximation solutions. However, the resulting basic attacks would severely change the structural semantics (in particular, both local and global balance properties) of a signed network, which makes the attacks prone to be detected by the powerful attack detectors we designed. Given this, we further refine the basic attacks by integrating some conflicting metrics as penalty terms into the objective function. The refined attacks become secrecy-aware, i.e., they can successfully evade attack detectors with high probability while sacrificing little attack performance. We conduct comprehensive experiments to demonstrate that the basic attacks can severely disrupt trust prediction but could be easily detected, and the refined attacks perform almost equally well while evading detection. Overall, our results significantly advance the knowledge in designing more practical attacks, reflecting more realistic threats to current trust prediction models. Moreover, the results also provide valuable insights and guidance for building up robust trust prediction systems.}
}


@article{DBLP:journals/tifs/YangSLZ24,
	author = {Hao Yang and
                  Shiyu Shen and
                  Zhe Liu and
                  Yunlei Zhao},
	title = {cuXCMP: CUDA-Accelerated Private Comparison Based on Homomorphic Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3581--3592},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3267677},
	doi = {10.1109/TIFS.2023.3267677},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangSLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private comparison schemes constructed on homomorphic encryption offer the noninteractive and parallelizable features, and have advantages in communication bandwidth and performance. In this work, we propose cuXCMP, an extension of the privacy comparison scheme XCMP (AsiaCCS 2018). We address the relatively small input domain and the incompletely expressible output of XCMP, by modifying the encoding method and devising a constant term extraction (CTX) approach. Then, we describe a method for constructing privacy-preserving decision tree (PPDT) using this scheme. Considering the high computational overhead of CTX, we exploit the massive parallelism of the GPU to accelerate this function. Based on the results of the kernel profiling, we utilize several optimization techniques to improve the performance, including using multiple CUDA streams, reducing the grid dimension, kernel fusion, etc. By accelerating this function, we boost the execution time of the scheme and demonstrate 130\\times and 1.9\\times speedups for CTX and cuXCMP, respectively, as well as a 35% reduction in the evaluation time of PPDT.}
}


@article{DBLP:journals/tifs/JiangZMLTL24,
	author = {Qi Jiang and
                  Guichuan Zhao and
                  Xindi Ma and
                  Meng Li and
                  Youliang Tian and
                  Xinghua Li},
	title = {Cross-Modal Learning Based Flexible Bimodal Biometric Authentication
                  With Template Protection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3593--3607},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364092},
	doi = {10.1109/TIFS.2024.3364092},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiangZMLTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face and voice are two of the most popular traits used for authentication tasks in daily life, as they can be easily captured using low-cost visual and audio sensors on smartphones, laptops, tablets, etc. Many bimodal biometric authentication schemes based on these two traits have been presented to provide higher accuracy than unimodal systems. However, these schemes are inflexibility due to the requirement of submitting two traits simultaneously, and they lack template protection, which may lead to biometric data leakage. We present a cross-modal learning based bimodal biometric authentication scheme, which improves the flexibility of existing schemes while ensuring the biometric template security. We integrate cross-modal learning into the feature extraction to obtain a bimodal biometric shared representation given input face images and voice clips. In order to enhance biometric template security without sacrificing authentication accuracy, a residual network and polar codes based template protection method is proposed, which can eliminate the noise in shared representations due to intra-user variations and generate protected templates. We have evaluated the efficacy of the bimodal biometric scheme using a real video dataset containing face images and voice clips. Experimental results demonstrate that our scheme can achieve flexible authentication with high accuracy no matter the probe input is a face image, a voice clip or a combination of them. Furthermore, the security analysis demonstrates that our scheme provides irreversibility, unlinkability and revocability of protected templates.}
}


@article{DBLP:journals/tifs/FerdausTR24,
	author = {Farah Ferdaus and
                  Bashir M. Sabquat Bahar Talukder and
                  Md. Tauhidur Rahman},
	title = {Hiding Information for Secure and Covert Data Storage in Commercial
                  ReRAM Chips},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3608--3619},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364845},
	doi = {10.1109/TIFS.2024.3364845},
	timestamp = {Fri, 17 May 2024 21:40:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FerdausTR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article introduces a novel, low-cost technique for hiding data in commercially available resistive-RAM (ReRAM) chips. The data is kept hidden in ReRAM cells by manipulating its analog physical properties through switching (set/reset) operations. This hidden data, later, is retrieved by sensing the changes in cells’ physical properties (i.e., set/reset time of the memory cells). The proposed system-level hiding technique does not affect normal memory operations and does not require any hardware modifications. Furthermore, the proposed hiding approach is robust against temperature variations and the aging of the devices through normal read/write operation. The silicon results show that our proposed data hiding technique is acceptably fast with {\\sim }0.12bit/s of encoding and {\\sim }3.26Kbits/s of retrieval rates, and the hidden message is unrecoverable without the knowledge of the secret key, which is used to enhance the security of hidden information.}
}


@article{DBLP:journals/tifs/WangYMLHTL24,
	author = {Huanran Wang and
                  Wu Yang and
                  Dapeng Man and
                  Jiguang Lv and
                  Shuai Han and
                  Jingwen Tan and
                  Tao Liu},
	title = {Anchor Link Prediction for Cross-Network Digital Forensics From Local
                  and Global Perspectives},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3620--3635},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364066},
	doi = {10.1109/TIFS.2024.3364066},
	timestamp = {Tue, 06 Aug 2024 08:17:53 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangYMLHTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anchor link prediction enhances the effectiveness of digital forensics through the identification of multiple social network users. The current methods based on deep learning are characterized by both the exaggerated similarity between adjacent nodes in the same latent space and the variation in the feature spaces caused by semantics. A novel approach is developed to fuse the semantic features of different networks in this paper. The proposed method is divided into two stages. Firstly, representation learning pays more attention to the influence of uncertainty on the equivalence of node network structure, and introduces the difference between adjacent nodes from the latent space. Secondly, a joint representation learning framework trains and exchanges the parameters depending on known anchor links. The joint representation learning framework injects fused features into the representation learning processes of different networks. The combination of enhanced discrimination and cross-network feature fusion reduces the feature space differences caused by the semantics of different social networks. This paper conducts comprehensive experiments on social networks in the real world. The outcome shows that the proposed approach is more efficient and robust compared to the existing state-of-the-art methods.}
}


@article{DBLP:journals/tifs/Pelofske24,
	author = {Elijah Pelofske},
	title = {Analysis of a Programmable Quantum Annealer as a Random Number Generator},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3636--3643},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364054},
	doi = {10.1109/TIFS.2024.3364054},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Pelofske24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum devices offer a highly useful function - that is generating random numbers in a non-deterministic way since the measurement of a quantum state is not deterministic. This means that quantum devices can be constructed that generate qubits in a uniform superposition and then measure the state of those qubits. If the preparation of the qubits in a uniform superposition is unbiased, then quantum computers can be used to create high entropy, secure random numbers. Typically, preparing and measuring such quantum systems requires more time compared to classical pseudo random number generators (PRNGs) which are inherently deterministic algorithms. Therefore, the typical use of quantum random number generators (QRNGs) is to provide high entropy secure seeds for PRNGs. Quantum annealing (QA) is a type of analog quantum computation that is a relaxed form of adiabatic quantum computation and uses quantum fluctuations in order to search for ground state solutions of a programmable Ising model. Here we present extensive experimental random number results from a D-Wave 2000Q quantum annealer, totaling over 20 billion bits of QA measurements, which is significantly larger than previous D-Wave QA random number generator studies. Current quantum annealers are susceptible to noise from environmental sources and calibration errors, and are not in general unbiased samplers. Therefore, it is of interest to quantify whether noisy quantum annealers can effectively function as an unbiased QRNG. The amount of data that was collected from the quantum annealer allows a comprehensive analysis of the random bits to be performed using the NIST SP 800–22 Rev 1a testsuite, as well as min-entropy estimates from NIST SP 800-90B. The randomness tests show that the generated random bits from the D-Wave 2000Q are biased, and not unpredictable random bit sequences. With no server-side sampling post-processing, the 1 microsecond annealing time measurements had a min-entropy of 0.824.}
}


@article{DBLP:journals/tifs/HuaTZLZ24,
	author = {Zhongyun Hua and
                  Yan Tong and
                  Yifeng Zheng and
                  Yuhong Li and
                  Yushu Zhang},
	title = {PPGloVe: Privacy-Preserving GloVe for Training Word Vectors in the
                  Dark},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3644--3658},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3364080},
	doi = {10.1109/TIFS.2024.3364080},
	timestamp = {Sun, 19 Jan 2025 14:20:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuaTZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Words are treated as atomic units in natural language processing tasks and it is a fundamental step to represent them as vectors for supporting subsequent computations. GloVe is a widely used machine learning model to train word vectors. Generally, a large corpus and high computation resources are required to train high-quality word vectors using GloVe, making it difficult for users to train their own word vectors by themselves. A natural choice nowadays is to outsource the training process to the cloud. However, coming with such cloud-based training services are serious privacy concerns, which should be well addressed. In this paper, we design, implement, and evaluate PPGloVe, the first system framework that supports privacy-preserving word vectors training using GloVe over encrypted data of multiple participants. We first decompose the training task and show that previous privacy-preserving machine learning techniques are not practical for this task. We then construct a new secure training strategy to delicately bridge lightweight cryptographic techniques with GloVe in depth to support privacy-preserving GloVe training on the cloud. By design, the corpora of the participants and the trained word vectors are kept private along the whole training process. Extensive experiments over three datasets of different scales demonstrate that PPGloVe produces word vectors with promising quality comparable to plaintext training, with practically affordable overhead.}
}


@article{DBLP:journals/tifs/KuangLLJ24,
	author = {Huafeng Kuang and
                  Hong Liu and
                  Xianming Lin and
                  Rongrong Ji},
	title = {Defense Against Adversarial Attacks Using Topology Aligning Adversarial
                  Training},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3659--3673},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3359820},
	doi = {10.1109/TIFS.2024.3359820},
	timestamp = {Sun, 19 Jan 2025 14:20:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KuangLLJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent works have indicated that deep neural networks (DNNs) are vulnerable to adversarial attacks, wherein an attacker perturbs an input example with human-imperceptible noise that can easily fool the DNNs, resulting in incorrect predictions. This severely limits the application of deep learning in security-critical scenarios, such as face authentication. Adversarial training (AT) is one of the most practical approaches to strengthening the robustness of DNNs. However, existing AT-based methods treat each training sample independently, thereby ignoring the underlying topological structure in the training data. To this end, in this paper, we take full advantage of the topology information and introduce a Topology Aligning Adversarial Training (TAAT) algorithm. TAAT aims to encourage the trained model to maintain consistency in the topological structure within the feature space of both natural and adversarial examples. To ensure the stability and efficiency of topology alignment, we further introduce a novel Knowledge-Guided (KG) training scheme. This scheme explicitly aligns local logit outputs and global topological structures from the target model with a robust auxiliary model. To verify the effectiveness of the proposed method, we conduct extensive experiments on popular benchmark datasets (e.g., CIFAR and ImageNet) and evaluate the robustness against state-of-the-art adversarial attacks (e.g., PGD-attack and AutoAttack). The experimental results demonstrate that the proposed method has superior robustness over the previous state-of-the-art methods. Our code and pre-trained models are available at https://github.com/SkyKuang/TAAT.}
}


@article{DBLP:journals/tifs/ZhuCZSHG24,
	author = {Derui Zhu and
                  Jinfu Chen and
                  Xuebing Zhou and
                  Weiyi Shang and
                  Ahmed E. Hassan and
                  Jens Grossklags},
	title = {Vulnerabilities of Data Protection in Vertical Federated Learning
                  Training and Countermeasures},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3674--3689},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361813},
	doi = {10.1109/TIFS.2024.3361813},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuCZSHG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vertical federated learning (VFL) is an increasingly popular, yet understudied, collaborative learning technique. In VFL, features and labels are distributed among different participants allowing for various innovative applications in business domains, e.g., online marketing. When deploying VFL, training data (labels and features) from each participant ought to be protected; however, very few studies have investigated the vulnerability of data protection in the VFL training stage. In this paper, we propose a posterior-difference-based data attack, VFLRecon, reconstructing labels and features to examine this problem. Our experiments show that standard VFL is highly vulnerable to serious privacy threats, with reconstruction achieving up to 92% label accuracy and 0.05 feature MSE, compared to our baseline with 55% label accuracy and 0.19 feature MSE. Even worse, this privacy risk remains during standard operations (e.g., encrypted aggregation) that appear to be safe. We also systematically analyze data leakage risks in the VFL training stage across diverse data modalities (i.e., tabular data and images), different training frameworks (i.e., with or without encryption techniques), and a wide range of training hyperparameters. To mitigate this risk, we design a novel defense mechanism, VFLDefender, dedicated to obfuscating the correlation between bottom model changes and labels (features) during training. The experimental results demonstrate that VFLDefender prevents reconstruction attacks during standard encryption operations (around 17% more effective than standard encryption operations).}
}


@article{DBLP:journals/tifs/ChenWXZSZXY24,
	author = {Zhuangzhi Chen and
                  Zhangwei Wang and
                  Dongwei Xu and
                  Jiawei Zhu and
                  Weiguo Shen and
                  Shilian Zheng and
                  Qi Xuan and
                  Xiaoniu Yang},
	title = {Learn to Defend: Adversarial Multi-Distillation for Automatic Modulation
                  Recognition Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3690--3702},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3361172},
	doi = {10.1109/TIFS.2024.3361172},
	timestamp = {Sun, 19 Jan 2025 14:20:42 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenWXZSZXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automatic modulation recognition (AMR) of radio signal is an important research topic in the area of non-cooperative communication and cognitive radio. Recently deep learning (DL) techniques enable significant progress in AMR. However, the techniques of adversarial machine learning cause the threats of adversarial attacks in DL-based AMR. In this paper, we aim to make AMR model robust, accurate and lightweight, thus propose a multi-distillation mechanism for robust training of DL-based AMR models, namely Adversarial Multi-Distillation (AMD). In the framework of AMD, by knowledge distillation, two powerful teacher models transfer the learned classification knowledge and defense knowledge, respectively, to the student model to form robust training. Our experiments with public dataset RML2016.10a show that the proposed method can significantly improve the defense of AMR models to against adversarial perturbations and keep relatively high classification accuracy, which enables robust decision making with lightweight models under adversarial attacks. The code for quick use and reproduction is available at https://github.com/Wangzhangwei19/Adversarial-Multi-Distillation.}
}


@article{DBLP:journals/tifs/LiuRWQWSZLWHRB24,
	author = {Xinwei Liu and
                  Kiran B. Raja and
                  Renfang Wang and
                  Hong Qiu and
                  Hucheng Wu and
                  Dechao Sun and
                  Qiguang Zheng and
                  Nian Liu and
                  Xiaoxia Wang and
                  Gehang Huang and
                  Raghavendra Ramachandra and
                  Christoph Busch},
	title = {A Latent Fingerprint in the Wild Database},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3703--3718},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3368892},
	doi = {10.1109/TIFS.2024.3368892},
	timestamp = {Wed, 07 Aug 2024 08:00:25 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuRWQWSZLWHRB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Latent fingerprints are among the most important and widely used evidence in crime scenes, digital forensics and law enforcement worldwide. Despite the number of advancements reported in recent works, we note that significant open issues such as independent benchmarking and lack of large-scale evaluation databases for improving the algorithms are inadequately addressed. The available databases are mostly of semi-public nature, lack of acquisition in the wild environment, and post-processing pipelines. Moreover, they do not represent a realistic capture scenario similar to real crime scenes, to benchmark the robustness of the algorithms. Further, existing databases for latent fingerprint recognition do not have a large number of unique subjects/fingerprint instances or do not provide ground truth/reference fingerprint images to conduct a cross-comparison against the latent. In this paper, we introduce a new wild large-scale latent fingerprint database that includes five different acquisition scenarios: reference fingerprints from (1) optical and (2) capacitive sensors, (3) smartphone fingerprints, latent fingerprints captured from (4) wall surface, (5) Ipad surface, and (6) aluminium foil surface. The new database consists of 1,318 unique fingerprint instances captured in all above mentioned settings. A total of 2,636 reference fingerprints from optical and capacitive sensors, 1,318 fingerphotos from smartphones, and 9,224 latent fingerprints from each of the 132 subjects were provided in this work. The dataset is constructed considering various age groups, equal representations of genders and backgrounds. In addition, we provide an extensive set of analysis of various subset evaluations to highlight open challenges for future directions in latent fingerprint recognition research.}
}


@article{DBLP:journals/tifs/WuCTLLH24,
	author = {Hao{-}Tian Wu and
                  Yiu{-}Ming Cheung and
                  Zhihong Tian and
                  Dingcai Liu and
                  Xiangyang Luo and
                  Jiankun Hu},
	title = {Lossless Data Hiding in {NTRU} Cryptosystem by Polynomial Encoding
                  and Modulation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3719--3732},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3362592},
	doi = {10.1109/TIFS.2024.3362592},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WuCTLLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Lossless data hiding in ciphertexts (LDH-CT) is to perform data embedding without changing their plaintexts, which can be used to transmit extra data in the applications of homomorphic encryption at little cost. In this paper, two LDH-CT algorithms named Polynomial Encoding (PE) and Polynomial Modulation (PM) are proposed for the “N-th Degree Truncated Polynomial Ring Unit” (NTRU) scheme, respectively. In the PE algorithm, a polynomial is encoded according to a string of bit values and further used to encrypt a plain-text polynomial. After decrypting the ciphertext, the encoded polynomial can be retrieved so that dozens of bit values can be extracted from it. Moreover, the PE algorithm can be combined with a polynomial partitioning strategy to achieve data extraction before decryption as well. In applying the PM algorithm, no parameter setting of an NTRU cryptosystem is changed while a cipher-text polynomial is generated by selectively sampling a polynomial to match the to-be-hidden value. Furthermore, the data hidden with the PM algorithm can be pre-chosen to be extracted without decryption or after decryption, and in each case up to 10 bit values can be hidden into one cipher-text polynomial. The proposed algorithms and schemes are implemented and compared with several schemes developed for NTRU, BGN, LWE and Paillier encryption. Experimental results and performance evaluations demonstrate the efficacy and superiority of the proposed algorithms and schemes.}
}


@article{DBLP:journals/tifs/ZhuZLWX24,
	author = {Xiaogang Zhu and
                  Siyu Zhang and
                  Chaoran Li and
                  Sheng Wen and
                  Yang Xiang},
	title = {Fuzzing Android Native System Libraries via Dynamic Data Dependency
                  Graph},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3733--3744},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3369479},
	doi = {10.1109/TIFS.2024.3369479},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuZLWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Google suggests using only the APIs documented in Android SDK. However, many app developers still choose Java Native Interface (JNI) to access system libraries because of the flexibility and freedom that non-SDK methods provide in implementing complex functions. However, using JNI may have unexpected consequences, including low-level bug-driven crashes. The bugs in system libraries can propagate to Android apps, and further cost much time and energy for developers to debug them. We develop a fuzzing tool, called JDYNUZZ, that exposes the bugs in system JNI to mitigate the aftermath of direct invocation of JNI. To fuzz a system library, one needs to not only prepare appropriate inputs, but also deal with the challenge of maintaining a correct sequence of API calls, both syntactically and semantically. To solve the challenge, the crux of JDYNUZZ is the dynamic refinement of a data dependency graph, which gradually resolves the problem of syntactic and semantic incorrectness when constructing API sequences. JDYNUZZ achieves the dynamic refinement based on the feature of Java reflection, which enables us to dynamically modify API sequences and test different code regions. We evaluate JDYNUZZ on the most recent version of Android Open Source Project (AOSP), i.e., version android-12.0.0_r31. In our experiments, JDYNUZZ discovers 34 new bugs in system JNI libraries, all confirmed by Google.}
}


@article{DBLP:journals/tifs/WangYH24,
	author = {Min Wang and
                  Xuefei Yin and
                  Jiankun Hu},
	title = {Cancellable Deep Learning Framework for {EEG} Biometrics},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3745--3757},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3369405},
	doi = {10.1109/TIFS.2024.3369405},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangYH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {EEG-based biometric systems verify the identity of a user by comparing the probe to a reference EEG template of the claimed user enrolled in the system, or by classifying the probe against a user verification model stored in the system. These approaches are often referred to as template-based and model-based methods, respectively. Compared with template-based methods, model-based methods, especially those based on deep learning models, tend to provide enhanced performance and more flexible applications. However, there is no public research report on the security and cancellability issue for model-based approaches. This becomes a critical issue considering the growing popularity of deep learning in EEG biometric applications. In this study, we investigate the security issue of deep learning model-based EEG biometric systems, and demonstrate that model inversion attacks post a threat for such model-based systems. That is to say, an adversary can produce synthetic data based on the output and parameters of the user verification model to gain unauthorized access by the system. We propose a cancellable deep learning framework to defend against such attacks and protect system security. The framework utilizes a generative adversarial network to approximate a non-invertible transformation whose parameters can be changed to produce different data distributions. A user verification model is then trained using output generated from the generator model, while information about the transformation is discarded. The proposed framework is able to revoke compromised models to defend against hill climbing attacks and model inversion attacks. Evaluation results show that the proposed method, while being cancellable, achieves better verification performance than the template-based methods and state-of-the-art non-cancellable deep learning methods.}
}


@article{DBLP:journals/tifs/ZhangGCZ24,
	author = {Xingjian Zhang and
                  Haochen Gong and
                  Rui Chang and
                  Yajin Zhou},
	title = {{RECAST:} Mitigating Conflict-Based Cache Attacks Through Fine-Grained
                  Dynamic Mapping},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3758--3771},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3368862},
	doi = {10.1109/TIFS.2024.3368862},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangGCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conflict-based cache attacks can leak critical information from target programs. Accordingly, randomization-based cache designs have emerged as an efficient and LLC-favorable way to mitigate such attacks. However, later investigations have revealed several problems with these designs. Specifically, we identify limited randomness and coarse-grained protection as key issues of previous designs. To solve these issues, we propose Recast, a secure cache design with address-sensitive secret generation and tweakable index randomization. Our insight is that cache modules at different levels can work collaboratively to enhance their security. Address-sensitive secret generation in private caches generates a secret value for each address upon cache misses. The shared cache in Recast uses tweakable index randomization, where the cryptographic function uses the secret value from private caches as the input to calculate the cache set index. Therefore, Recast achieves fine-grained dynamic mapping. We implement Recast in the gem5 simulator. We use a micro-benchmark and a benchmark suite to showcase the security of Recast. Our performance evaluations on SPEC 2017 and PARSEC benchmarks show that Recast incurs 2.29% and 2.03% performance overhead. Moreover, Recast with the LRU replacement policy has only 0.51% and 1.04% performance overhead on the two benchmarks. Therefore, Recast provides higher security guarantees with minimal performance overhead.}
}


@article{DBLP:journals/tifs/IssaMTC24,
	author = {Wael Issa and
                  Nour Moustafa and
                  Benjamin P. Turnbull and
                  Kim{-}Kwang Raymond Choo},
	title = {{RVE-PFL:} Robust Variational Encoder-Based Personalized Federated
                  Learning Against Model Inversion Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3772--3787},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3368879},
	doi = {10.1109/TIFS.2024.3368879},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/IssaMTC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) enables distributed joint training of machine learning (ML) models without the need to share local data. FL is, however, not immune to privacy threats such as model inversion (MI) attacks. The conventional FL paradigm often uses privacy-preserving techniques, and this could lead to a considerable loss in the model’s utility and consequently compromised by MI attackers. Seeking to address this limitation, this paper proposes a robust variational encoder-based personalised FL (RVE-PFL) approach that mitigates MI attacks, preserves model utility, and ensures data privacy. RVE-PFL comprises an innovative personalised variational encoder architecture and a trustworthy threat model-integrated FL method to autonomously preserve data privacy, and mitigate MI attacks. The proposed architecture seamlessly trains heterogeneous data at every client, while the proposed approach aggregates data at the server side and effectively discriminates against adversarial settings (i.e., MI); thus, achieving robustness and trustworthiness in real-time. RVE-PFL is evaluated on three benchmark datasets, namely: MNIST, Fashion-MNIST, and Cifar-10. The experimental results revealed that RVE-PFL achieves high accuracy level while preserving data and tuning adversarial settings. It outperforms Noising before Model Aggregation FL (NbAFL) with significant accuracy improvements of 8%, 20%, and 59% on MNIST, Fashion-MNIST, and Cifar-10, respectively. These findings reinforce the effectiveness of RVE-PFL in protecting against MI attacks while maintaining the model’s utility. The source code for RVE-PFL can be found on GitHub: https://github.com/UNSW-Canberra-2023/RVE-PFL.}
}


@article{DBLP:journals/tifs/ShaoZLGZ24,
	author = {Huikai Shao and
                  Yuchen Zou and
                  Chengcheng Liu and
                  Qiang Guo and
                  Dexing Zhong},
	title = {Learning to Generalize Unseen Dataset for Cross-Dataset Palmprint
                  Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3788--3799},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3371257},
	doi = {10.1109/TIFS.2024.3371257},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShaoZLGZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-dataset palmprint recognition promotes the convenience and flexibility of palmprint recognition. However, most of the current cross-dataset palmprint recognition methods need to collect the target dataset in advance for model training. They tend to overfit this target dataset and are difficult to generalize to other unknown datasets. In this paper, we propose a novel Palmprint Data and Feature Generation (PDFG) method for a more challenging scenario, Cross-Dataset Palmprint Recognition with Unseen Target dataset (CDPR-UT). Both data-level and feature-level generalization is constructed to improve the adaptability of model to unknown target datasets. A Fourier-based data augmentation method is firstly introduced to generate more training data with new styles. Then several effective losses are constructed at feature level to reduce the shifts between source and augmented datasets and extract adaptive features. Experiments are conducted on multiple palmprint datasets. The results demonstrate that our method is more efficient and robust in dealing with CDPR-UT than other methods. Compared with the baseline, the accuracy is improved by up to 18.20% and the Equal Error Rate (EER) is reduced by up to 12.53%.}
}


@article{DBLP:journals/tifs/HuangZZDZCKC24,
	author = {Junhao Huang and
                  Haosong Zhao and
                  Jipeng Zhang and
                  Wangchen Dai and
                  Lu Zhou and
                  Ray C. C. Cheung and
                  {\c{C}}etin Kaya Ko{\c{c}} and
                  Donglong Chen},
	title = {Yet Another Improvement of Plantard Arithmetic for Faster Kyber on
                  Low-End 32-bit IoT Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3800--3813},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3371369},
	doi = {10.1109/TIFS.2024.3371369},
	timestamp = {Tue, 04 Feb 2025 20:31:50 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangZZDZCKC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In 2022, the National Institute of Standards and Technology (NIST) made an announcement regarding the standardization of Post-Quantum Cryptography (PQC) candidates. Out of all the Key Encapsulation Mechanism (KEM) schemes, the CRYSTAL-Kyber emerged as the sole winner. This paper presents another improved version of Plantard arithmetic that could speed up Kyber implementations on two low-end 32-bit IoT platforms (ARM Cortex-M3 and RISC-V) without SIMD extensions. Specifically, we further enlarge the input range of the Plantard arithmetic without modifying its computation steps. After tailoring the Plantard arithmetic for Kyber’s modulus, we show that the input range of the Plantard multiplication by a constant is at least\n2.14×\nlarger than the original design in TCHES2022. Then, two optimization techniques for efficient Plantard arithmetic on Cortex-M3 and RISC-V are presented. We show that the Plantard arithmetic supersedes both Montgomery and Barrett arithmetic on low-end 32-bit platforms. With the enlarged input range and the efficient implementation of the Plantard arithmetic on these platforms, we propose various optimization strategies for NTT/INTT. We minimize or entirely eliminate the modular reduction of coefficients in NTT/INTT by taking advantage of the larger input range of the proposed Plantard arithmetic on low-end 32-bit platforms. Furthermore, we propose two memory optimization strategies that reduce 23.50%~28.31% stack usage for the speed-version Kyber implementation when compared to its counterpart on Cortex-M4. The proposed optimizations make the speed-version implementation more feasible on low-end IoT devices. Thanks to the aforementioned optimizations, our NTT/INTT implementation shows considerable speedups compared to the state-of-the-art work. Overall, we demonstrate the applicability of the speed-version Kyber implementation on memory-constrained IoT platforms and set new speed records for Kyber on these platforms.}
}


@article{DBLP:journals/tifs/TianCYFWDH24,
	author = {Jiahe Tian and
                  Peng Chen and
                  Cai Yu and
                  Xiaomeng Fu and
                  Xi Wang and
                  Jiao Dai and
                  Jizhong Han},
	title = {Learning to Discover Forgery Cues for Face Forgery Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3814--3828},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372773},
	doi = {10.1109/TIFS.2024.3372773},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TianCYFWDH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Locating manipulation maps, i.e., pixel-level annotation of forgery cues, is crucial for providing interpretable detection results in face forgery detection. Related learning objects have also been widely adopted as auxiliary tasks to improve the classification performance of detectors whereas they require comparisons between paired real and forged faces to obtain manipulation maps as supervision. This requirement restricts their applicability to unpaired faces and contradicts real-world scenarios. Moreover, the used comparison methods annotate all changed pixels, including noise introduced by compression and upsampling. Using such maps as supervision hinders the learning of exploitable cues and makes models prone to overfitting. To address these issues, we introduce a weakly supervised model in this paper, named Forgery Cue Discovery (FoCus), to locate forgery cues in unpaired faces. Unlike some detectors that claim to locate forged regions in attention maps, FoCus is designed to sidestep their shortcomings of capturing partial and inaccurate forgery cues. Specifically, we propose a classification attentive regions proposal module to locate forgery cues during classification and a complementary learning module to facilitate the learning of richer cues. The produced manipulation maps can serve as better supervision to enhance face forgery detectors. Visualization of the manipulation maps of the proposed FoCus exhibits superior interpretability and robustness compared to existing methods. Experiments on five datasets and four multi-task models demonstrate the effectiveness of FoCus in both in-dataset and cross-dataset evaluations.}
}


@article{DBLP:journals/tifs/GeCWTL24,
	author = {Wenhan Ge and
                  Zeyuan Cui and
                  Junfeng Wang and
                  Binhui Tang and
                  Xiaohui Li},
	title = {MetaCluster: {A} Universal Interpretable Classification Framework
                  for Cybersecurity},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3829--3843},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372808},
	doi = {10.1109/TIFS.2024.3372808},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GeCWTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rising cyber threats have created an immediate demand for Deep Learning (DL) in cybersecurity. Nevertheless, the opaque nature of DL models poses challenges in deploying, collaborating, and assessing their effectiveness in less reliable cybersecurity environments. Despite eXplainable Artificial Intelligence (XAI) playing a role in enhancing cybersecurity analytics, the limited task scope, the propensity for data overfitting, and the stochastic explanations hinder its broader application. To fill the gap, this paper introduces a generic interpretable classification framework, named MetaCluster. MetaCluster generates semantic prototypes for features, patterns, and domains at varying granular levels by following three fundamental steps: embedding representations, acquiring prototypes, and aggregating semantics. These mechanisms guarantee that MetaCluster achieves critical information extraction and reliable classification at minimal cost. The experiments encompass cybersecurity classification tasks and assess the interpretability of the framework. These tasks encompass malware family classification, threat behavior analysis, and malicious traffic identification. In particular, when compared to other DL models, MetaCluster exhibits a significant reduction in parameter consumption by 79.52% to 91.78%, and boosts operational speed up to 71.37%, while its F1 scores remain stable or slightly increase. Additionally, MetaCluster possesses the ability to assess and visually represent the significance of image, text, and statistical features. This capability leads to a reduction of Mean Squared Error (MSE) between expected and actual predictions by 0.0101 to 0.1020.}
}


@article{DBLP:journals/tifs/JiangXHZC24,
	author = {Changsong Jiang and
                  Chunxiang Xu and
                  Yunxia Han and
                  Zhao Zhang and
                  Kefei Chen},
	title = {Two-Factor Authenticated Key Exchange From Biometrics With Low Entropy
                  Rates},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3844--3856},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372812},
	doi = {10.1109/TIFS.2024.3372812},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangXHZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-factor authenticated key exchange (AKE) enables a user to be authenticated by a server using multiple factors and negotiate a shared session key to protect subsequent communications. Most existing multi-factor AKE schemes utilize biometrics as one factor due to their uniqueness and invariance properties. To support matching for noisy biometrics and protect them, fuzzy extractors are employed to extract a constant random string from varying biometric measurements without disclosing biometric data. However, the fuzzy extractors used in these schemes merely work on biometrics with an entropy rate greater than the error rate. Hence these schemes are unsuitable for biometrics with low entropy rates. In this paper, we propose a secure two-factor AKE scheme dubbed AHEAD from passwords and biometrics, which eliminates the limitation of biometric entropy rates. In AHEAD, we conceive a matching mechanism to simultaneously check whether an input biometric measurement with low entropy rates is close enough to the registered one, and whether an input password exactly matches the registered password. The mechanism allows a valid user to generate a secret element shared with the server in an oblivious way. By adopting a randomization technique, the secret element can be randomized for derivation of session keys. The security and efficiency of AHEAD are demonstrated by formal security proofs and experimental evaluations.}
}


@article{DBLP:journals/tifs/CaiSSCWQT24,
	author = {Xiao Cai and
                  Kaibo Shi and
                  Yanbin Sun and
                  Jinde Cao and
                  Shiping Wen and
                  Cheng Qiao and
                  Zhihong Tian},
	title = {Stability Analysis of Networked Control Systems Under DoS Attacks
                  and Security Controller Design With Mini-Batch Machine Learning Supervision},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3857--3865},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3347889},
	doi = {10.1109/TIFS.2023.3347889},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CaiSSCWQT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study investigates the stability problem in nonlinear networked control systems (NCSs). First, innovative compression rules are introduced to mitigate network congestion and bandwidth utilization issues stemming from quality of service (QoS) queuing mechanisms and denial of service (DoS) attacks. We develop an intelligent trigger controller supervised by a mini-batch machine learning (MBML) algorithm to optimize network bandwidth utilization. Furthermore, we formulate more generalized Lyapunov-Krasovskii functions (LKFs) to simplify mathematical derivations, and we employ appropriate integral inequalities to minimize constraints. Finally, experimental evaluations are conducted on an autonomous vehicle (AV) using the joint CarSim-Simulink platform to verify the effectiveness of the proposed intelligent trigger controller.}
}


@article{DBLP:journals/tifs/MaJLWWC24,
	author = {Bowen Ma and
                  Tong Jia and
                  Mingyuan Li and
                  Songsheng Wu and
                  Hao Wang and
                  Dongyue Chen},
	title = {Toward Dual-View X-Ray Baggage Inspection: {A} Large-Scale Benchmark
                  and Adaptive Hierarchical Cross Refinement for Prohibited Item Discovery},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3866--3878},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372797},
	doi = {10.1109/TIFS.2024.3372797},
	timestamp = {Fri, 15 Nov 2024 11:23:31 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MaJLWWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dual-view baggage inspection has been widely applied in real-world scenarios, where orthogonal viewpoints are deployed to capture diverse and complementary information. Compared with single-view, it can effectively improve the identification performance when rotation and overlay hinder the viewability of the objects. However, this topic has not been rigorously explored due to the scarcity of datasets. To overcome this limitation, we contribute the first fully public large-scale Dual-view X-ray dataset. Our dataset, named DvXray, contains 16,000 pairs, 32,000 X-ray images, in which 15 common classes of 5,496 prohibited items are manually labeled. Besides, we propose an approach named Adaptive Hierarchical Cross Refinement (AHCR) to establish a strong baseline for prohibited item discovery in dual-view X-ray images. AHCR hypothesizes that each input pair is sampled from one mixture distribution, hence gathering the non-overlapping and position-aware cues along the shared axis and complementarily delivering to the other in a hierarchical structure to enrich the feature discriminability of the objects of interest from background overlaps. Upon this structure, we propose an adaptive control strategy and a confidence-weighted view fusion term to make it robust to difficult samples. Extensive experiments on DvXray show that AHCR not only brings significant classification gains over various backbones, such as recent Swin Transformer and ConvNeXt, but also exhibits an impressively better ability to localize objects. In addition, AHCR performs favorably against the counterparts and some recent multi-view learning approaches, moving a step closer towards potential application in practice. Dataset and code are available at https://github.com/Mbwslib/DvXray.}
}


@article{DBLP:journals/tifs/ZhangYZSL24,
	author = {Sicheng Zhang and
                  Yandie Yang and
                  Ziyao Zhou and
                  Zhi Sun and
                  Yun Lin},
	title = {{DIBAD:} {A} Disentangled Information Bottleneck Adversarial Defense
                  Method Using Hilbert-Schmidt Independence Criterion for Spectrum Security},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3879--3891},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372798},
	doi = {10.1109/TIFS.2024.3372798},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangYZSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automatic Modulation Classification (AMC) is crucial for monitoring the legitimacy of user frequency behavior and identifying potential sources of interference in spectrum monitoring. Deep learning-based AMC models have shown excellent performance, however, it has been proven susceptible to adversarial attacks. To address the problem, we propose a Disentangled Hilbert-Schmidt Information Bottleneck Adversarial Defense (DIBAD) method to enhance the adversarial robustness of AMC models. Specifically, we firstly analyze the task-relevant and task-irrelevant features in the intermediate representations of modulation signals from the perspective of mutual information theory. Secondly, a training framework consisting of a classification feature extractor, a supplementary feature extractor, and a classifier is designed. Under the information bottleneck constraint, the classification feature extractor and supplementary feature extractor are used to extract task-relevant and task-irrelevant features, respectively. The information bottleneck constraint is employed to reduce task-irrelevant features, thus improving the model’s adversarial robustness. Experiments on the RML2016.10a and DMRadio09.real datasets, along with comprehensive analysis, demonstrate the superiority of the DIBAD method terms of adversarial robustness.}
}


@article{DBLP:journals/tifs/WangCZHZ24,
	author = {Fengqun Wang and
                  Jie Cui and
                  Qingyang Zhang and
                  Debiao He and
                  Hong Zhong},
	title = {Blockchain-Based Secure Cross-Domain Data Sharing for Edge-Assisted
                  Industrial Internet of Things},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3892--3905},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372806},
	doi = {10.1109/TIFS.2024.3372806},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangCZHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the Industrial Internet of Things (IIoT), blockchain-based data-sharing frameworks can effectively build cross-domain trust and facilitate data sharing. However, secure data-sharing schemes are lacking for the IIoT scenario, in which smart devices cannot communicate across domains and can only access data through edge servers. In this study, we propose a lightweight and secure data-sharing scheme for the blockchain-enabled cross-domain IIoT, in which authorized smart devices can access cross-domain data anonymously. First, smart devices can dynamically generate pseudonyms by themselves and without the online participation of domain authorization centers, effectively reducing the storage overhead of smart devices and the workload of domain authorization centers. Second, the scheme combines broadcast encryption and proxy re-encryption techniques, which realize flexible data sharing across domains while protecting the privacy of smart devices. Detailed security proofs and analyses demonstrate that the proposed scheme is secure and resistant to various attacks. The performance analysis shows that our proposed scheme is efficient and performs better than related schemes.}
}


@article{DBLP:journals/tifs/QiHT24,
	author = {Mingping Qi and
                  Wei Hu and
                  Yu Tai},
	title = {{SAE+:} One-Round Provably Secure Asymmetric {SAE} Protocol for Client-Server
                  Model},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3906--3913},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372799},
	doi = {10.1109/TIFS.2024.3372799},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QiHT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SAE, short for Simultaneous Authentication of Equals, is a password-authenticated key exchange (PAKE) protocol, by which the two involved parties can achieve mutual authentication and derive high-entropy keys via a memorable password. Currently, the SAE protocol has been standardized and integrated into the latest WPA3 (Wi-Fi Protected Access 3) specifications for protecting Wi-Fi network access. Whereas, SAE is a symmetric PAKE protocol unable to resist the server compromise attacks, and it involves explicit key confirmation flows which may be redundant for usage in existing protocols such as the TLS 1.3, etc. So, we naturally wonder that if we can construct a provably secure one-round asymmetric PAKE from the distinguished SAE. This paper affirms this by presenting an efficient asymmetric variant of SAE, called SAE+, and backing it up with a formal security proof under the widely accepted BPR security model. The new SAE+ is designed to enable a single round-trip execution, with the client initiating the communication, making it an ideal fit for integration into IETF protocols such as TLS 1.3. This feature aligns with the requirements set forth in the “Usage of PAKE with TLS 1.3” document. The SAE+ is secure against the off-line dictionary and server compromise attacks, and supports the desired forward secrecy, i.e., compromising the long-term secret password does not compromise the secrecy of the previously established session keys. In addition, the performance evaluation results presented in this paper demonstrate that the new SAE+ has comparable computational efficiency with some existing outstanding PAKE protocols while outperforms many of them in terms of communication flows.}
}


@article{DBLP:journals/tifs/RajendranDTKFT24,
	author = {Sree Ranjani Rajendran and
                  Nusrat Farzana Dipu and
                  Shams Tarek and
                  Hadi Mardani Kamali and
                  Farimah Farahmandi and
                  Mark M. Tehranipoor},
	title = {Exploring the Abyss? Unveiling Systems-on-Chip Hardware Vulnerabilities
                  Beneath Software},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3914--3926},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372800},
	doi = {10.1109/TIFS.2024.3372800},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/RajendranDTKFT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the increasing size and complexity of system-on-chips (SoCs), new threats and vulnerabilities are emerging, mainly related to flaws at the system level. Due to the lack of decisive security requirements and properties from the perspective of the SoC designer, the system-level verification process, whose violation may lead to exploiting a hardware vulnerability, is not studied comprehensively. To enable more comprehensive verification of system-level properties, this paper presents a framework known as HUnTer (Hardware Underath Trigger) for identifying sets of instructions (sequences) at the processor unit (PU) that reveal the underlying hardware vulnerabilities. HUnTer automates (i) threat modeling, (ii) threat-based formal verification, (iii) generating counterexamples, and (iv) generating snippet code to exploit the vulnerability. Furthermore, the HUnTer framework defines a unique security coverage metric (HUnT_Coverage) to measure the performance and effectiveness of vulnerability exploits. To demonstrate the high effectiveness of the proposed framework, we conduct a wide variety of case studies using the HUnTer framework on RISC-V-based open-source SoC architecture and attains the security coverage of 86% as an average for 11 benchmarks of the Trust-Hub database.}
}


@article{DBLP:journals/tifs/XuZMML24,
	author = {Chongyao Xu and
                  Litao Zhang and
                  Pui{-}In Mak and
                  Rui Paulo Martins and
                  Man{-}Kay Law},
	title = {Fully Symmetrical Obfuscated Interconnection and Weak-PUF-Assisted
                  Challenge Obfuscation Strong PUFs Against Machine-Learning Modeling
                  Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3927--3942},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372801},
	doi = {10.1109/TIFS.2024.3372801},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuZMML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a fully symmetrical obfuscated-interconnection PUF (SOI PUF), which contains n delay stages with each stage having 4k obfuscated interconnections for resisting machine learning (ML)-based modeling attacks. All the delay stages contribute to k PUF primitives while achieving a 20\\times increase in the number of possible interconnections with the same hardware resources over similar prior arts. The SOI PUF mathematical model also theoretically demonstrates the large number of nonlinear matrix multiplications for resisting ML-based modeling attacks. We further exploit parallel weak PUF cells and propose the challenge-obfuscated SOI PUF (cSOI PUF), which can effectively prevent adversaries from bypassing unknown interconnections through reverse engineering (RE) attacks. The proposed SOI PUF and cSOI PUFs are evaluated by both software simulation and FPGA measurements. Without requiring a large k as in the existing PUF architectures, the simulation results demonstrate that the proposed SOI and cSOI PUFs can achieve a ~50% prediction accuracy for k\\ge 3 , even when facing ML attacks using 5-hidden-layer Artificial Neural Network (ANN) with 40M training CRPs. Furthermore, the proposed (64,2/4/6/8)-SOI PUF and (64,2/4/6/8)-cSOI PUF implemented using Xilinx Artix-7 FPGA can both achieve a measured reliability and uniformity of >94% and ~50%, respectively. Depending on the value of k , the uniqueness ranges from 29.1% to 42.7% for SOI PUFs, and further improves to ~50% for cSOI PUFs. The resilience against reliabiltiy-based modeling attacks, Probably Approximately Correct (PAC) attacks and RE-based modeling attacks will also be discussed.}
}


@article{DBLP:journals/tifs/QuXLLWL24,
	author = {Zuomin Qu and
                  Zuping Xi and
                  Wei Lu and
                  Xiangyang Luo and
                  Qian Wang and
                  Bin Li},
	title = {{DF-RAP:} {A} Robust Adversarial Perturbation for Defending Against
                  Deepfakes in Real-World Social Network Scenarios},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3943--3957},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372803},
	doi = {10.1109/TIFS.2024.3372803},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QuXLLWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The misuse of Deepfakes to create unauthorized fake facial images and videos poses a growing threat to personal privacy and social stability. Proactive defense algorithms have been proposed to prevent this fraud by injecting adversarial perturbations into facial images. However, these perturbations are sensitive to the lossy compression on online social networks (OSNs). Recent studies have attempted to produce compression resistance by modeling compression at the pixel level. However, accurate modeling is challenging due to the customization of proprietary compression mechanisms by different OSNs. In this paper, we propose a Robust Adversarial Perturbation (DF-RAP) that provides persistent protection for facial images under OSN compression. Specifically, a novel Compression Approximation GAN (ComGAN) is designed to explicitly model OSN compression. The well-trained ComGAN is then incorporated as a sub-module of the target Deepfake model to derive DF-RAP. Furthermore, we reveal a commonality among various OSNs, i.e., that the lossy compression employed tends to destroy perturbations. Based on this, a novel objective-level destruction-aware constraint (DAC) is introduced during ComGAN training. The extensive experimental results show that DF-RAP can effectively protect facial images from Deepfakes under complex OSN compression, especially for OSNs employing more stringent compression. We also investigate the lossy operation mechanisms employed by widely used OSN platforms and build an OSN-transmission dataset based on the CelebA to facilitate future research.}
}


@article{DBLP:journals/tifs/LiuWRWGQL24,
	author = {Rongke Liu and
                  Dong Wang and
                  Yizhi Ren and
                  Zhen Wang and
                  Kaitian Guo and
                  Qianqian Qin and
                  Xiaolei Liu},
	title = {Unstoppable Attack: Label-Only Model Inversion Via Conditional Diffusion
                  Model},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3958--3973},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372815},
	doi = {10.1109/TIFS.2024.3372815},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuWRWGQL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model inversion attacks (MIAs) aim to recover private data from inaccessible training sets of deep learning models, posing a privacy threat. MIAs primarily focus on the white-box scenario where attackers have full access to the model’s structure and parameters. However, practical applications are usually in black-box scenarios or label-only scenarios, i.e., the attackers can only obtain the output confidence vectors or labels by accessing the model. Therefore, the attack models in existing MIAs are difficult to effectively train with the knowledge of the target model, resulting in sub-optimal attacks. To the best of our knowledge, we pioneer the research of a powerful and practical attack model in the label-only scenario. In this paper, we develop a novel MIA method, leveraging a conditional diffusion model (CDM) to recover representative samples under the target label from the training set. Two techniques are introduced: selecting an auxiliary dataset relevant to the target model task and using predicted labels as conditions to guide training CDM; and inputting target label, pre-defined guidance strength, and random noise into the trained attack model to generate and correct multiple results for final selection. This method is evaluated using Learned Perceptual Image Patch Similarity as a new metric and as a judgment basis for deciding the values of hyper-parameters. Experimental results show that this method can generate similar and accurate samples to the target label, outperforming generators of previous approaches.}
}


@article{DBLP:journals/tifs/FeiHWWJF24,
	author = {Hongyan Fei and
                  Chuanwei Huang and
                  Song Wu and
                  Zheng Wang and
                  Zexi Jia and
                  Jufu Feng},
	title = {Fingerprint Presentation Attack Detection by Region Decomposition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3974--3985},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372813},
	doi = {10.1109/TIFS.2024.3372813},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FeiHWWJF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fingerprint Presentation Attack Detection (PAD) is a crucial step in automatic fingerprint identification systems, which safeguards users from unauthorized malicious access. However, current presentation attack (i.e. spoof) techniques can forge intricate details of fingerprints (such as sweat holes), which makes the artifact evidence harder to detect. In this paper, we propose a novel PAD method from the perspective of decomposition to highlight the artifact evidence in each constituent element. Specifically, we utilize the fingerprint enhancement to decompose the fingerprint into the ridge region and the edge region. We observe that artifact evidence mainly exists in the gradient field within the ridge region, while it primarily resides in the spatial domain within the edge region. Then we propose an Orientation-Based Central Difference Convolution (OB-CDC) layer to prioritize gradient variations along the ridge direction. To further enhance robustness, we propose a Minutia Patches Random Rotation (MPRR) operation to disrupt the identity information of the fingerprint while preserving the artifact evidence. By integrating these techniques, we propose a two-stream network called Presentation-Attack-Detection-with-Region-Decomposition-Network (PADRD-Net) which integrates the processed feature of the ridge region and the edge region through a halfway fusion ResNet-18 structure. Experimental results on the LivDet 2021 dataset show that our proposed PADRD-Net can achieve 20.39% on BPCER@APCER = 1% and 87.12% on TDR@FDR = 1%, significantly outperforms the state-of-the-art. We also achieve outstanding performance in both the cross-sensor scenario and the cross-sensor and cross-material scenario. Extensive ablation studies and analysis experiments further indicate the effectiveness and robustness of our method.}
}


@article{DBLP:journals/tifs/WuCDMS24,
	author = {Tongshuai Wu and
                  Liwei Chen and
                  Gewangzi Du and
                  Dan Meng and
                  Gang Shi},
	title = {UltraVCS: Ultra-Fine-Grained Variable-Based Code Slicing for Automated
                  Vulnerability Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {3986--4000},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3374219},
	doi = {10.1109/TIFS.2024.3374219},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuCDMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting vulnerabilities in source code using deep learning models is emerging as a valuable research area. The key issue in using deep learning to detect vulnerabilities is the accurate representation. Current approaches for detecting vulnerabilities in C/C++ programs use functions or lines of code as the unit and only consider the basic syntactic structure of vulnerabilities. Unfortunately, functions and lines of code still have vulnerability-unrelated information, which is redundant for vulnerability features and is not conducive to deep learning models to learn accurate vulnerability patterns. This paper deeply analyzes the essential features of vulnerabilities and attacks. Then, we propose a novel variable-based deep learning vulnerability detection method for C/C++ that is more granular than existing function- or line of code-based vulnerability detection methods. Based on the triggering mechanism of vulnerabilities and typical memory attacks, we propose the concepts of key variables and insecure operations; these are used to propose new rules for determining the center point of code slices with more accurate vulnerability features. We propose the first ultra-fine-grained variable-based code slicing (UltraVCS) method by the new center point, which focuses on the vulnerability-related variable. This method removes as much vulnerability-unrelated information as possible to achieve more accurate vulnerability feature extraction. Experiments show that our approach can generate more code slices, achieve more precise vulnerability representation, and perform better vulnerability detection in open-source projects compared to state-of-the-art methods. Furthermore, we have discovered four zero-day vulnerabilities in real-world application scenarios in open-source projects.}
}


@article{DBLP:journals/tifs/KeWH24,
	author = {Da Ke and
                  Xiang Wang and
                  Zhitao Huang},
	title = {Frequency-Selective Adversarial Attack Against Deep Learning-Based
                  Wireless Signal Classifiers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4001--4011},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3352423},
	doi = {10.1109/TIFS.2024.3352423},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KeWH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although Deep learning (DL) provides state-of-art results for most spectrum sensing tasks, it is vulnerable to adversarial examples. Based on this phenomenon, we consider a noncooperative communication scenario where an intruder tries to recognize the modulation type of the intercepted signal. Specifically, this paper aims to minimize the intruder’s accuracy while guaranteeing that the intended receiver can still recover the underlying message with the highest reliability. This process is implemented by adding adversarial perturbations to the channel input symbols at the encoder. In image classification, the perturbation is limited to be imperceptible to a human observer by minimizing the {\\ell _{p}}\nnorm, while in this work, we enriched the connotation of adversarial examples, and first proposed that the imperceptibility of adversarial examples in the field of wireless signals is the imperceptibility of filters. Based on this perspective, we optimized the model of adversarial examples and constrained the adversarial perturbation to a narrow frequency band so that filters cannot filter it out. We also define a new set of metrics to describe the imperceptibility of the wireless signal adversarial example. The simulation results demonstrate the viability of our approach in securing wireless communication against state-of-the-art DL-based intruders while minimizing communication performance reduction.}
}


@article{DBLP:journals/tifs/WangLJLLL24,
	author = {Xiangming Wang and
                  Yang Liu and
                  Kexin Jiao and
                  Pengfei Liu and
                  Xiapu Luo and
                  Ting Liu},
	title = {Intrusion Device Detection in Fieldbus Networks Based on Channel-State
                  Group Fingerprint},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4012--4027},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3374596},
	doi = {10.1109/TIFS.2024.3374596},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangLJLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of distributed control technologies has made Fieldbus networks widely used in industrial control systems (ICSs). Meanwhile, the weak security protection of Fieldbus networks exposes potential attack paths for attackers. Attackers can tap covert and unauthorized external devices (i.e., intrusion devices) into the network to launch attacks. As the intrusion device can remain silent when eavesdropping, there is no detectable abnormal traffic in the network to detect the intrusion device. In this paper, we analytically prove that the observed signals sent from any benign device will inevitably change when the intrusion device is tapped into the Fieldbus network. With this knowledge, we construct the channel-state group fingerprint from the communication signals of each benign device and propose a collaborative intrusion detection mechanism for physical access, PhyCID, to passively detect the covert intrusion device. Detection results on a real power distribution cabinet, an RS485 bus testbed, and a controller area network (CAN) bus testbed indicate that PhyCID is purely passive, environmentally adaptive, and protocol-independent in most Fieldbus networks, including RS485 and CAN. Furthermore, extensive experiments under different scenarios demonstrate the effectiveness and robustness of PhyCID.}
}


@article{DBLP:journals/tifs/YangWH24,
	author = {Mengxue Yang and
                  Huaqun Wang and
                  Debiao He},
	title = {Puncturable Attribute-Based Encryption From Lattices for Classified
                  Document Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4028--4042},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3374262},
	doi = {10.1109/TIFS.2024.3374262},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangWH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The country’s governmental agencies bear the responsibility for overseeing and executing a wide range of national policies and initiatives, formulating pivotal determinations aimed at safeguarding national security and fostering long-term progress. Most of the decisions are highly confidential, encrypted and transmitted to diverse administrative regions, sectors, and individuals to facilitate execution. Hence, governmental agencies must formulate fine-grained access policies that support secure one-to-many document sharing. However, if the receivers’ keys were exposed, it could result in unauthorized access to document contents, posing a significant threat to national security. When facing keys exposure scenario, addressing the challenge of preventing document content theft while maintaining document archiving for convenient accountability becomes a complex and demanding task. To tackle the above issues, we propose an innovative lattice-based puncturable ciphertext-policy attribute-based encryption scheme. This scheme supports secure one-to-many document sharing, fine-grained access control, and empowers receivers to revoke the decryption capability for specific data according to their own choice after reviewing documents, thereby achieving dual-layer protection for documents. Our scheme has exhibited resilience against quantum attacks, chosen plaintext attacks and collusion attacks.}
}


@article{DBLP:journals/tifs/AhmadTTKP24,
	author = {Baleegh Ahmad and
                  Shailja Thakur and
                  Benjamin Tan and
                  Ramesh Karri and
                  Hammond Pearce},
	title = {On Hardware Security Bug Code Fixes by Prompting Large Language Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4043--4057},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3374558},
	doi = {10.1109/TIFS.2024.3374558},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AhmadTTKP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI’s Codex have demonstrated capabilities in many coding-adjacent domains. In this work, we consider how LLMs may be leveraged to automatically repair identified security-relevant bugs present in hardware designs by generating replacement code. We focus on bug repair in code written in Verilog. For this study, we curate a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all fifteen of our benchmarks. This ensemble outperforms a state-of-the-art automated hardware bug repair tool on its own suite of bugs. These results show that LLMs have the ability to repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair tool.}
}


@article{DBLP:journals/tifs/ZhengLWWMLDW24,
	author = {Tianyi Zheng and
                  Bo Li and
                  Shuang Wu and
                  Ben Wan and
                  Guodong Mu and
                  Shice Liu and
                  Shouhong Ding and
                  Jia Wang},
	title = {{MFAE:} Masked Frequency Autoencoders for Domain Generalization Face
                  Anti-Spoofing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4058--4069},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3371266},
	doi = {10.1109/TIFS.2024.3371266},
	timestamp = {Mon, 05 Aug 2024 08:08:44 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhengLWWMLDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The generalizable face anti-spoofing (FAS) has attracted much attention recently. Even though many existing methods perform well under intra-domain settings, the model’s performance in the unseen domain is not satisfying. In this paper, we shift our attention to the frequency domain to seek a solution. Specifically, we examine the characteristics of different frequency band components of FAS images and observe that the model’s cross-domain performance is very sensitive to low-frequency features. To alleviate this sensitivity and improve the model’s performance in FAS cross-domain tasks, we propose a new approach called Masked Frequency Autoencoders (MFAE). MFAE randomly masks a portion of frequencies on the low-frequency spectrum of the image and then reconstructs the image from the resulting embedding. This innovative Masked Image Modeling (MIM) strategy can be used as a self-supervised task for pre-training vision transformers (ViTs), which can reduce the ViT encoder’s sensitivity to domain shifts. Additionally, we add an auxiliary content-regularization decoder in our MFAE to encourage the encoder to be insensitive to low-frequency features. The results show that the model insensitive to low-frequency features performs well on extensive public datasets and outperforms other state-of-the-art methods in cross-domain FAS tasks.}
}


@article{DBLP:journals/tifs/LyuHRGYCT24,
	author = {Xinchen Lyu and
                  Xinyun Hou and
                  Chenshan Ren and
                  Xin Ge and
                  Penglin Yang and
                  Qimei Cui and
                  Xiaofeng Tao},
	title = {Secure and Efficient Federated Learning With Provable Performance
                  Guarantees via Stochastic Quantization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4070--4085},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3374590},
	doi = {10.1109/TIFS.2024.3374590},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LyuHRGYCT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning is a popular distributed machine learning paradigm that enables collaborative model training at multiple entities via exchanging intermediate learning results. Security and communication efficiency are crucial for successful applications of federated learning in various privacy-sensitive services. However, existing work focused on gradient defense and communication efficiency separately, and also incurred additional computation, signaling, and accuracy overhead. A lightweight (in terms of time-complexity and signaling) technique that simultaneously achieves security and communication efficiency is critical for massive resource-constrained devices (e.g., Internet-of-Things generating the data), but has yet to be established. This paper proposes a secure and efficient federated learning framework with provable communication-accuracy-security performance guarantees. A low-complexity and signaling-free stochastic quantization module is added at the client side that quantizes the original local gradients to discrete values for communication-efficient global aggregation. The stochastic quantization module is shown to be interpreted as triangular or Gaussian-multiply-triangular noises under uniform or Gaussian distributions of local gradients, hence protecting data privacy. We prove that the proposed framework exhibits an\n{O(\nlog\n2\n1\nδ\n),O(\nδ\n2\n),O(\n1\nδ\n)}\n-tradeoff between the communication overhead, model accuracy, and data protection, where\nδ\nis an adjustable quantization interval. Experimental results validate the tradeoff and the superiority of the proposed stochastic quantization technique in terms of communication efficiency (only 14.1% of differential privacy and 0.2% of homomorphic encryption) and computation complexity (similar to differential privacy and only 0.03% of homomorphic encryption). Under the same data prote...}
}


@article{DBLP:journals/tifs/EshunP24,
	author = {Samuel N. Eshun and
                  Paolo Palmieri},
	title = {A Cryptographic Protocol for Efficient Mutual Location Privacy Through
                  Outsourcing in Indoor Wi-Fi Localization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4086--4099},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372805},
	doi = {10.1109/TIFS.2024.3372805},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/EshunP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Digital services and applications are increasingly requiring location information from users to provide personalized services. However, disclosing one’s location introduces significant privacy risks, as location traces are highly unique and can be used to infer additional sensitive data. While location-based services were once restricted to outdoor spaces, given the lack of GPS signal indoors, a growing number of applications rely on Wi-Fi to provide indoor localization. Indoor localization can impact privacy to an even greater degree, as most of our daily activities occur indoors. Therefore, several indoor privacy protocols have been proposed, focusing on protecting the user’s location. However, the problem of mutual location privacy, that is, the protection of both the user’s privacy and the service provider’s location database, has not been addressed, particularly against malicious (active) adversaries. In addressing this gap, this paper presents an efficient and privacy-preserving cryptographic protocol for indoor localization. Our protocol hides the user’s location, while also protecting the service provider’s location map and areas of interest against malicious users. Furthermore, the protocol outsources most of the user-side heavy computation to a third-party cloud server, which does not need to be trusted by the parties as it remains oblivious to both user’s location and the provider’s database throughout the computations. Compared to leading solutions in the literature, including Eshun and Palmieri (2019) and Li et al. (2014), our protocol is the first to provide security against malicious users. Additionally, it significantly reduces the user computation and communication overhead (of up to 99%), making it potentially the first practicable scheme in resource-constrained mobile and IoT environments.}
}


@article{DBLP:journals/tifs/GaoZWCPLZ24,
	author = {Ce Gao and
                  Kang Zhang and
                  Weiwei Wang and
                  Zhicheng X. Cao and
                  Liaojun Pang and
                  Eryun Liu and
                  Heng Zhao},
	title = {Protected Face Templates Generation Based on Multiple Partial Walsh
                  Transformations and Simhash},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4100--4113},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3369322},
	doi = {10.1109/TIFS.2024.3369322},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GaoZWCPLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread application of biometric, unprotected biometric data is still at risk of serious security and privacy breaches. When large amounts of unprotected biometric data leak, cancelable biometric become a powerfully remedial measure. In this paper, we propose a new method to generate stable and cancelable face templates based on multiple partial Walsh transformations (MPWT) and Simhash. Firstly, multiple partial Walsh matrices generated with random external parameters perform projection transformation on the original real-valued face features, ensuring the irreversibility and unlinkability of the system. Subsequently, the projected features are transformed into discrete binary codes (protected templates) using Simhash. And the random permutation seed ensures the revocability of generated protected template. Furtherly, the protected templates have small storage space and is more suitable for fast comparison but also yields improvements in recognition accuracy compared with several state-of-the-arts. Numerous experiments on CASIA-WebFace, LFW, FEI, and Color FERET databases show that the protected templates are nearly identical to the unprotected ones in the comparison performance. The scheme also meets the requirements of non-invertibility, revocability, unlinkability, as well as resistance for various types of attacks like attacks via record multiplicity, false accepts, brute force and pre-image. Therefore, the proposed methodology strikes a balance between recognition accuracy and security.}
}


@article{DBLP:journals/tifs/TangWXC24,
	author = {Yichao Tang and
                  Chuntao Wang and
                  Shijun Xiang and
                  Yiu{-}Ming Cheung},
	title = {A Robust Reversible Watermarking Scheme Using Attack-Simulation-Based
                  Adaptive Normalization and Embedding},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4114--4129},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372811},
	doi = {10.1109/TIFS.2024.3372811},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TangWXC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For copyright protection and perfect recovery of the original image in case of no attacks, it is necessary to develop robust reversible watermarking (RRW) methods that counteract both common signal processing (CSP) and geometric deformation (GD) attacks (RRW-CG). However, to the best of our knowledge, none of the existing RRW methods exploit target attacks as prior knowledge to improve their robustness and embedding capacity. To this end, we propose a two-stage RRW-CG scheme with attack-simulation-based adaptive normalization and embedding. Specifically, the polar harmonic transform (PHT) moments are taken as watermark carriers, and their stability with respect to target attacks is evaluated by performing attack simulation tests on large-scale images. This enables the adaptive normalization of PHT moments to improve the watermark robustness. The PHT moments with high stability are then chosen as watermark carriers, and the conventional spread transform dither modulation (STDM) with one quantization level is optimized to form the enhanced version with multiple quantization levels, in which the embedding strength is determined adaptively via attack simulation tests on the candidate watermarked image. This in turn improves the watermark robustness and increases the embedding capacity. After the robust watermark has been embedded, errors caused by robust watermarking are used as the auxiliary information and then inserted into the robustly watermarked image via the recursive code-based reversible watermarking technique, ensuring the reversibility in case of no attacks. Extensive experimental simulation results show that the proposed scheme outperforms the state-of-the-art RRW methods in terms of robustness against CSP such as AWGN, JPEG, JPEG2000, mean filtering, and median filtering as well as GD including rotation and scaling under the same invisibility, reversibility, and embedding capacity. This indicates that, by exploiting target attacks as prior knowledge and designing the attack-simulation-based adaptive normalization and embedding, the proposed novel RRW is feasible and effective.}
}


@article{DBLP:journals/tifs/ZhouZYZZ24,
	author = {Shuai Zhou and
                  Tianqing Zhu and
                  Dayong Ye and
                  Wanlei Zhou and
                  Wei Zhao},
	title = {Inversion-Guided Defense: Detecting Model Stealing Attacks by Output
                  Inverting},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4130--4145},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376190},
	doi = {10.1109/TIFS.2024.3376190},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouZYZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model stealing attacks involve creating copies of machine learning models that have similar functionalities to the original model without proper authorization. Such attacks raise significant concerns about the intellectual property of the machine learning models. Nonetheless, current defense mechanisms against such attacks tend to exhibit certain drawbacks, notably in terms of utility, and robustness. For example, watermarking-based defenses require victim models to be retrained for embedding watermarks, which can potentially impact the main task performance. Moreover, other defenses, especially fingerprinting-based methods, often rely on specific samples like adversarial examples to verify ownership of the target model. These approaches might prove less robust against adaptive attacks, such as model stealing with adversarial training. It remains unclear whether normal examples, as opposed to adversarial ones, can effectively reflect the characteristics of stolen models. To tackle these challenges, we propose a novel method that leverages a neural network as a decoder to inverse the suspicious model’s outputs. Inspired by model inversion attacks, we argue that this decoding process will unveil hidden patterns inherent in the original outputs of the suspicious model. Drawing from these decoding outcomes, we calculate specific metrics to determine the legitimacy of the suspicious models. We validate the efficacy of our defense technique against diverse model stealing attacks, specifically within the domain of classification tasks based on deep neural networks.}
}


@article{DBLP:journals/tifs/SunYH24,
	author = {Fangyuan Sun and
                  Jia Yu and
                  Jiankun Hu},
	title = {Privacy-Preserving Approximate Minimum Community Search on Large Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4146--4160},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376201},
	doi = {10.1109/TIFS.2024.3376201},
	timestamp = {Sat, 31 Aug 2024 20:43:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SunYH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The minimum community search is used to identify a minimum dense community that includes a specified vertex in a large network. It has gained significant attention because of its various applications in social-network analysis, e-commerce transactions, biological network modeling, and other areas. Nevertheless, how to realize privacy-preserving minimum community search remains unexplored up to now. In this paper, we initiate the first research on privacy-preserving approximate minimum community search. We propose an effective scheme that allows cloud servers to identify the smallest possible community while safeguarding the private information of the network. To ensure the privacy of sensitive information in the network, we employ obfuscation technology and graph encryption technology to construct two secure indexes instead of the original graph. To strike a balance between safeguarding private information and maintaining search efficiency, our scheme incorporates Bloom filters into the index and implements a two-step strategy on the secure indexes to achieve privacy-preserving approximate minimum community searches. Furthermore, to secure the privacy of the search result, we carefully design an array comparison protocol based on the BGN cryptosystem. This protocol enables cloud servers to perform privacy-preserving heuristic searches from the initial community without exposing any details about the approximate minimum community. The security analysis confirms that our scheme achieves CQA2-security for two non-colluding cloud servers. The experimental results based on real social networks show that the proposed scheme can efficiently handle approximate minimum community searches on large networks.}
}


@article{DBLP:journals/tifs/YangZXA24,
	author = {Xiao Yang and
                  Chengru Zhang and
                  Haiyang Xue and
                  Man Ho Au},
	title = {Efficient Verifiably Encrypted {ECDSA} Schemes From Castagnos-Laguillaumie
                  and Joye-Libert Encryptions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4161--4173},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3375622},
	doi = {10.1109/TIFS.2024.3375622},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangZXA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A Verifiably Encrypted Signature (VES) scheme encrypts a digital signature in a way that allows the public to verify the validity of the encrypted signature. Recently, several practical VES schemes for ECDSA have been proposed to enable escrowed transactions with cryptocurrencies. However, these schemes are inefficient in terms of both communication and computation, or require a large lookup table. In this paper, we present two efficient VES schemes for ECDSA that improve upon previous work. The first scheme is based on Castagnos-Laguillaumie (CL) encryption, while the second is based on modified Joye-Libert (JL) encryption. Our benchmark shows that our schemes outperform existing constructions by a factor of at least 2 in both computation and communication. Additionally, our solution does not rely on any lookup table. We demonstrate that these schemes can also be generalized to design VES for Schnorr signature scheme and EdDSA. The main technical contribution of this paper, which is of independent interest, is a zero-knowledge proof for the equality of the discrete log of an elliptic-curve point and that of a JL ciphertext. Importantly, the security of our proof does not rely on any non-standard assumptions.}
}


@article{DBLP:journals/tifs/TangXWTPL24,
	author = {Jinling Tang and
                  Haixia Xu and
                  Mingsheng Wang and
                  Tao Tang and
                  Chunying Peng and
                  Huimei Liao},
	title = {A Flexible and Scalable Malicious Secure Aggregation Protocol for
                  Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4174--4187},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3375527},
	doi = {10.1109/TIFS.2024.3375527},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TangXWTPL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure aggregation becomes a major solution to providing privacy for federated learning. Secure aggregation for mobile devices typically relies on Shamir secret sharing (SSS) to achieve dropout robustness, but limits the system’s corruption and dropout tolerance. Although Prio+, a state-of-the-art method utilizing two non-colluding servers, avoids such limitations, its effectiveness is only against honest-but-curious servers. Thus, this paper presents a novel secure aggregation protocol in the malicious model. The proposed protocol uses a non-colluding server and initiator to achieve almost full (up to n-2\n) corruption and dropout tolerance, and exploits our discrete-logarithm (DL) extractable and equivocable commitment scheme to achieve malicious security. The proposed protocol’s security is proven in two models: malicious users colluding with the server and malicious users colluding with the initiator. Finally, a prototype of the developed protocol is implemented, with the experimental results demonstrating that our protocol is efficient and suitable for both cross-device and cross-silo federated learning scenarios. Compared with the sum protocol of Prio+, the proposed protocol achieves malicious security with affordable additional overhead, i.e., 4.8 to 6.1 times more computation cost and 2.8 to 2.9 times more communication cost for a single user.}
}


@article{DBLP:journals/tifs/LiuDZXT24,
	author = {Jinliang Liu and
                  Yanhui Dong and
                  Lijuan Zha and
                  Xiangpeng Xie and
                  Engang Tian},
	title = {Reinforcement Learning-Based Tracking Control for Networked Control
                  Systems With DoS Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4188--4197},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376250},
	doi = {10.1109/TIFS.2024.3376250},
	timestamp = {Wed, 02 Oct 2024 16:53:16 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuDZXT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper is concerned with the reinforcement learning-based tracking control problem for a class of networked systems subject to denial-of-service (DoS) attacks. Taking the effects of DoS attacks into consideration, a novel value function is proposed, which considers the cost of the control input, external disturbance and tracking error. Then, using the structure of the value function, the tracking Bellman equation and Hamilton function are defined. By employing the Bellman optimality theory, the optimal control strategy and the game algebraic Riccati equation (GARE) are solved with the Hamilton function. Next, the desired tracking performance is guaranteed as the solution of the GARE is found. Furthermore, an attacks-based Q-learning algorithm is projected to find the solution to the optimal tracking problem without the system dynamics and the convergence of the Q-learning algorithm is given. Finally, the F-404 aircraft engine system is given to verify the effectiveness of the proposed control strategy.}
}


@article{DBLP:journals/tifs/LinYLLLBR24,
	author = {Feng Lin and
                  Hao Yan and
                  Jin Li and
                  Ziwei Liu and
                  Li Lu and
                  Zhongjie Ba and
                  Kui Ren},
	title = {PhaDe: Practical Phantom Spoofing Attack Detection for Autonomous
                  Vehicles},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4199--4214},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376192},
	doi = {10.1109/TIFS.2024.3376192},
	timestamp = {Wed, 07 Aug 2024 17:08:26 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LinYLLLBR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite their prevalence and indispensability in the perception modules of autonomous vehicles, cameras have shown susceptibility to numerous attacks. Among them, the phantom spoofing attack is of significant concern. In such attacks, malefactors employ electronic display devices like projectors and display monitors to generate deceptive objects, thereby duping the object detectors in autonomous vehicles. However, existing detection methodologies are narrowly focused on a single device category, ignoring the multitude of devices that could be leveraged for attacks. Furthermore, the artificial modality-based solution presently in use lacks efficacious fusion mechanisms. In response to these limitations, we propose PhaDe, a practical deep learning-based system adept at detecting phantom spoofing attacks from a variety of and even unfamiliar attack devices. Our approach introduces two image processing techniques to construct artificial modalities and further advances a multi-head self-attention MSA-based fusion module for more versatile integration of disparate modalities. To boost the generalization capacity of our system against novel, unseen attacks, we incorporate two representation-level losses to align feature distributions from various domains. Evaluations conducted on our own dataset, encompassing fake objects from several device types, attest to the efficacy of our system. Our results indicate an accuracy of 98.80% on familiar domains and a detection success rate of 94.03% on unfamiliar domains. Additionally, PhaDe demonstrates a swift response time, fulfilling the practicality requisites.}
}


@article{DBLP:journals/tifs/JiangW24,
	author = {Jingwei Jiang and
                  Ding Wang},
	title = {{QPASE:} Quantum-Resistant Password-Authenticated Searchable Encryption
                  for Cloud Storage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4231--4246},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372804},
	doi = {10.1109/TIFS.2024.3372804},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searchable encryption is a powerful tool that enables secure and private searches of encrypted data. It allows users to outsource their data to cloud servers while maintaining the confidentiality and privacy of their data. Password-authenticated symmetric searchable encryption (PASE) can help users avoid the complexity and security risks associated with key management while maintaining the advantages of searchable encryption. To the best of our knowledge, none of the existing PASE schemes can resist security threats in the post-quantum era, and there is an urgent need to design quantum-resistant solutions. However, post-quantum cryptography (e.g., lattice-based cryptography) varies significantly from traditional cryptography, and it is challenging to design a quantum-resistant PASE for cloud storage. In this work, we take the first step towards this challenge by proposing QPASE, a quantum-resistant password-authenticated symmetric searchable encryption for cloud storage. We employ lattice-based threshold oblivious pseudorandom function to achieve password re-randomization and formally prove that QPASE is authentication secure and indistinguishability against chosen keyword attacks secure under quantum computers. QPASE can be extended to multi-keyword search and allows servers to update keys without affecting the users. The comparison results show that QPASE outperforms its foremost counterparts in security and computation overhead.}
}


@article{DBLP:journals/tifs/YueZNWZLZ24,
	author = {Tai Yue and
                  Fengwei Zhang and
                  Zhenyu Ning and
                  Pengfei Wang and
                  Xu Zhou and
                  Kai Lu and
                  Lei Zhou},
	title = {Armor: Protecting Software Against Hardware Tracing Techniques},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4247--4262},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372816},
	doi = {10.1109/TIFS.2024.3372816},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YueZNWZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many modern processors have embedded hardware tracing techniques (e.g., Intel Processor Trace or ARM CoreSight). While these techniques are widely used due to their transparency and low overhead, they also bring serious security threats. Attackers can utilize hardware tracing to trace the trusted applications from a non-secure application. Existing protection techniques fail to effectively protect the runtime information when hardware tracing is employed. To counter these threats, in this paper, we propose a novel direction called anti-hardware tracing. Our key idea is to exploit the limitations of hardware tracing: trace buffer overflow can cause trace data loss. We build a model to analyse the overflow and outline three principles for efficient triggering overflows and achieving anti-hardware tracing: numerous branches in the program, high-speed execution of the program, and the high-water mark of the trace buffer. We develop a framework called ARMOR on ARM Juno R2 to realize our approach. ARMOR protects software against the trace unit Embedded Trace Macrocell (ETM) in CoreSight by instrumenting protection and loop functions. The protection function detects runtime environments, efficiently fills the trace buffer, and employs various protection strategies like PID (process identifier) replacement and PIE+STRIP+ASLR. Meanwhile, the loop function triggers overflows efficiently based on context-based calculations and anti-ETM loop. Our evaluation demonstrates that the overhead of ARMOR is 77.31% lower than that of OLLVM on SPEC2006. ARMOR effectively hides 54.51% of basic blocks across 16 real-world applications, triggering $113\\times $ more overflows. Moreover, we showcase two practical applications of ARMOR. Firstly, we conduct a cryptographic and cross-world attack on GnuPG 1.4.13 RSA private keys using ETM, which can steal entire keys from a program in the Secure world with a single run. ARMOR successfully reduces leaked bits by 84.5%. Secondly, ARMOR impedes hardware-assisted fuzzing by reducing throughput by 89.71% and branch coverage by 47.99%.}
}


@article{DBLP:journals/tifs/KandePTDTKR24,
	author = {Rahul Kande and
                  Hammond Pearce and
                  Benjamin Tan and
                  Brendan Dolan{-}Gavitt and
                  Shailja Thakur and
                  Ramesh Karri and
                  Jeyavijayan Rajendran},
	title = {(Security) Assertions by Large Language Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4374--4389},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372809},
	doi = {10.1109/TIFS.2024.3372809},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KandePTDTKR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The security of computer systems typically relies on a hardware root of trust. As vulnerabilities in hardware can have severe implications on a system, there is a need for techniques to support security verification activities. Assertion-based verification is a popular verification technique that involves capturing design intent in a set of assertions that can be used in formal verification or testing-based checking. However, writing security-centric assertions is a challenging task. In this work, we investigate the use of emerging large language models (LLMs) for code generation in hardware assertion generation for security, where primarily natural language prompts, such as those one would see as code comments in assertion files, are used to produce SystemVerilog assertions. We focus our attention on a popular LLM and characterize its ability to write assertions out of the box, given varying levels of detail in the prompt. We design an evaluation framework that generates a variety of prompts, and we create a benchmark suite comprising real-world hardware designs and corresponding golden reference assertions that we want to generate with the LLM.}
}


@article{DBLP:journals/tifs/OtroshiShahrezaHM24,
	author = {Hatef Otroshi{-}Shahreza and
                  Vedrana Krivokuca Hahn and
                  S{\'{e}}bastien Marcel},
	title = {Vulnerability of State-of-the-Art Face Recognition Models to Template
                  Inversion Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4585--4600},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3381820},
	doi = {10.1109/TIFS.2024.3381820},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/OtroshiShahrezaHM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face recognition systems use the templates (extracted from users’ face images) stored in the system’s database for recognition. In a template inversion attack, the adversary gains access to the stored templates and tries to enter the system using images reconstructed from those templates. In this paper, we propose a framework to evaluate the vulnerability of face recognition systems to template inversion attacks. We build our framework upon a real-world scenario and measure the vulnerability of the system in terms of the adversary’s success attack rate in entering the system using the reconstructed face images. We propose a face reconstruction network based on a new block called “enhanced deconvolution using cascaded convolution and skip connections” (shortly, DSCasConv), and train it with a multi-term loss function. We use our framework to evaluate the vulnerability of state-of-the-art face recognition models, with different network structures and loss functions (in total 31 models), on the MOBIO, LFW, and AgeDB face datasets. Our experiments show that the reconstructed face images can be used to enter the system, which threatens the system’s security. Additionally, the reconstructed face images may reveal important information about each user’s identity, such as race, gender, and age, and hence jeopardize the users’ privacy.}
}


@article{DBLP:journals/tifs/LuoQXZK24,
	author = {Dacan Luo and
                  Yitao Qiao and
                  Di Xie and
                  Shifeng Zhang and
                  Wenxiong Kang},
	title = {Palm Vein Recognition Under Unconstrained and Weak-Cooperative Conditions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4601--4614},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3378427},
	doi = {10.1109/TIFS.2024.3378427},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuoQXZK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contactless palm vein has attracted significant attention for its high security, stability, and user-friendliness. However, current contactless palm vein recognition predominantly relies on databases collected from platforms with spatial and temporal constrained design, which inadequately reflect relaxed palm vein imaging circumstances. This paper proposes a novel manner called on-the-fly palm vein that frees the user’s palm from spatial and temporal constraints, enabling palm vein recognition under unconstrained and weak-cooperative conditions. Firstly, Designing efficient and user-friendly palm vein imaging and authentication via two dynamic palm motions is proposed, resulting in an on-the-fly palm vein recognition platform. Next, a large-scale and challenging palm vein database, SCUT Palm Vein Database Version 1 (SCUT_PV_v1), is constructed. It is the first palm vein database with images collected under unconstrained and weak-cooperative conditions, encompassing a wider range of palm pose variations, grayscale variations, and lower-quality images. Finally, a lightweight and efficient Adaptive Margin Palm Vein Authentication Network (AMPVNet) is proposed as a baseline for the SCUT_PV_v1, where a vein pattern-specific convolutional neural network (CNN) is designed to extract features and a tailored online data augmentation method, combining Random Perspective Transformation (RPT) with Random Grayscale Adjustment (RGA), is proposed to enrich the diversify of out-of-plane palm pose and grayscale variations. Extensive experimental results demonstrate the effectiveness of our proposed methods. As the first work for palm vein recognition under unconstrained and weak-cooperation conditions, the AMPVNet achieves a promising accuracy and computation result while maintaining robustness to palm pose and grayscale variations. The SCUT_PV_ v1 database will be public at https://github.com/SCUT-BIP-Lab/SCUT_PV_v1.}
}


@article{DBLP:journals/tifs/GuoGXYZ24,
	author = {Yimin Guo and
                  Yajun Guo and
                  Ping Xiong and
                  Fan Yang and
                  Chengde Zhang},
	title = {Deeper Insight Into Why Authentication Schemes in IoT Environments
                  Fail to Achieve the Desired Security},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4615--4627},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3382934},
	doi = {10.1109/TIFS.2024.3382934},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GuoGXYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Designing an efficient and secure authentication scheme is a significant means to ensure the security of IoT systems. Hundreds of authentication schemes tailored for IoT environments have been proposed in recent years, and regrettably, many of them were soon found to have succumbed to security vulnerabilities. In an effort to investigate the underlying reason for this, Wang et al. (at TIFS’23) recently analyzed the vulnerability of authentication schemes from the perspective of provable security. However, we observe that some authentication schemes with sound security proofs and heuristic security analysis are also not resistant to certain attacks, and even those that have been improved several times are still not immune. To explore the deep-seated reasons for security vulnerabilities in IoT authentication schemes, we divide security attacks into explicit and implicit attacks and find that many authentication schemes exhibit security under explicit attacks but are rendered vulnerable under implicit attacks. Further, we propose the relationship between the design goals of security attributes of authentication schemes and implicit attacks, analyze the vulnerability of three typical authentication schemes under implicit attacks, and find that only the security attributes capable of resisting the strongest implicit attacks are secure. Finally, we offer some specific suggestions on how to achieve the security attribute goals.}
}


@article{DBLP:journals/tifs/ZhangYXTLLCD24,
	author = {Yunming Zhang and
                  Dengpan Ye and
                  Caiyun Xie and
                  Long Tang and
                  Xin Liao and
                  Ziyi Liu and
                  Chuanxi Chen and
                  Jiacheng Deng},
	title = {Dual Defense: Adversarial, Traceable, and Invisible Robust Watermarking
                  Against Face Swapping},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4628--4641},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3383648},
	doi = {10.1109/TIFS.2024.3383648},
	timestamp = {Mon, 03 Mar 2025 22:25:02 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangYXTLLCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malicious applications of deep face swapping technology pose security threats such as misinformation dissemination and identity fraud. Some research propose the utilization of robust watermarking methods to track the copyright of facial images, facilitating post-forgery identity attribution. However, these methods cannot fundamentally prevent or eliminate the adverse impacts of face swapping. To address this issue, we present Dual Defense, an innovative framework based on robust adversarial watermarking. It simultaneously tracks image copyrights and disrupts the face swapping model by one-time embedding the robust adversarial watermark. Specifically, we propose an Original-domain Feature Emulation Attack (OFEA) method, which makes the traceable watermark adversarial through specially designed original domain adversarial loss. Additionally, we conduct a wavelet domain image structural information compensation loss, combined with a channel attention mechanism, to jointly balance watermark invisibility, adversariality, and traceability. Furthermore, we design a more comprehensive and rational evaluation method to thoroughly assess the effectiveness of adversarial attacks against face swapping models. Extensive experiments demonstrate that Dual Defense exhibits exceptional cross-task generality and dataset generalization. It maintains impressive adversariality and traceability in both original and robust settings, surpassing current forgery defense methods that possess only one of these capabilities.}
}


@article{DBLP:journals/tifs/TengZCJX24,
	author = {Yulin Teng and
                  Pinchang Zhang and
                  Xiao Chen and
                  Xiaohong Jiang and
                  Fu Xiao},
	title = {PHY-Layer Authentication Exploiting Channel Sparsity in MmWave {MIMO}
                  UAV-Ground Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4642--4657},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3384112},
	doi = {10.1109/TIFS.2024.3384112},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TengZCJX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper exploits the efficient channel modeling and channel sparsity to propose a novel Physical (PHY)-layer authentication framework for a Millimeter Wave (mmWave) Multiple-Input Multiple-Output (MIMO) Unmanned Aerial Vehicle (UAV)-ground system. Inspired by the Image Processing theory, we first explore a new Laplace prior approach for the efficient modeling of angular-domain mmWave MIMO channels. With the help of the new channel model, we then reveal the channel sparsity in the concerned system exhibiting a nice spatial correlation property. By a joint use of channel sparsity correlation, efficient sparsity feature extraction with Expectation Maximization (EM)/Generalized Approximate Message Passing (GAMP) algorithms and hypothesis testing, we thus devise a new authentication framework for the concerned system. Theoretical performance analysis is also carried out by deriving the closed-form expressions for false alarm and detection probabilities. Finally, extensive numerical results are provided to validate the feasibility of the proposed channel model and the theoretical analysis, as well as to demonstrate the efficiency of the new authentication framework under various scenarios.}
}


@article{DBLP:journals/tifs/NiWFHS24,
	author = {Yanyan Ni and
                  Zhen Wang and
                  Yingjie Fan and
                  Xia Huang and
                  Hao Shen},
	title = {Secure Stabilization of Networked Lur'e Systems Suffering From
                  DoS Attacks: {A} Resilient Memory-Based Event-Trigger Mechanism},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4658--4669},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3384055},
	doi = {10.1109/TIFS.2024.3384055},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NiWFHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper focuses on the exponential stabilization issue of networked Lur’e systems (NLSs) suffering from DoS attacks. To conserve limited network resources and withstand aperiodic DoS attacks, a resilient memory-based event-trigger (RMET) mechanism is firstly designed. Then, based on an in-depth discussion on the relationship between the RMET scheme and DoS attacks, a comprehensive closed-loop system mathematical model is established. The model describes a clear switching characteristic of the whole control loop among waiting intervals, detection intervals, and DoS attacking intervals. On this basis, two multi-interval-dependent Lyapunov functionals (MIDLFs) are constructed. The primary advantage of the MIDLFs is that they can effectively exploit the information contained within the waiting intervals and DoS attacking intervals. Subsequently, an exponential stability criterion is derived by virtue of the continuity of the designed MIDLFs and the application of various inequality estimation techniques. Additionally, a co-design algorithm associated with the secure feedback gain and the event-trigger (ET) matrix is carried out. Finally, two numerical simulations are utilized to confirm the benefits of the RMET mechanism and MIDLFs in reducing the number of data packets as well as enhancing the tolerance ability of DoS attacks, respectively.}
}


@article{DBLP:journals/tifs/MerkleSSP24,
	author = {Florian Merkle and
                  Maximilian Samsinger and
                  Pascal Sch{\"{o}}ttle and
                  Tom{\'{a}}s Pevn{\'{y}}},
	title = {On the Economics of Adversarial Machine Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4670--4685},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3379829},
	doi = {10.1109/TIFS.2024.3379829},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MerkleSSP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the widespread deployment of machine learning algorithms, the security of these algorithms and thus, the field of adversarial machine learning gained popularity in the research community. In this article, we loosen several unrealistic restrictions found in prior art and bring economical-inspired adversarial machine learning one step closer to being applicable in the real world. First, we extend our own game-theoretical framework such that it allows any arbitrary number of actions for both actors, and analytically determine equilibrium strategies and conditions where mixed strategies are expected for the specific case in which both actors choose from any two arbitrary actions. Then, we pay special attention to an adversary’s knowledge about the attacked system by modeling them as a white-, gray-, or black-box adversary. We conduct extensive experiments for three architectures, two training procedures, and four adversarial attacks in different variations as direct and transfer attacks, resulting in 300 data points consisting of the respective accuracy and robustness values and the computational costs for both actors. We then instantiate our model with this data and explore the structure of the game for a wide range of each game parameter, overcoming the complexity by applying algorithmic game theory. We discover surprising properties in the actors’ strategies, such as the feasibility of cheap attacks that have been dismissed as practically irrelevant so far - examples include universal adversarial perturbations or (transfer) attacks utilizing only few optimization steps. For the defender, we find that given recent attacks and countermeasures, a rational defender would try to hide as much as possible from their infrastructure.}
}


@article{DBLP:journals/tifs/LiLHH24,
	author = {Xiao Li and
                  Qiongxiu Li and
                  Zhanhao Hu and
                  Xiaolin Hu},
	title = {On the Privacy Effect of Data Enhancement via the Lens of Memorization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4686--4699},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3381477},
	doi = {10.1109/TIFS.2024.3381477},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiLHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning poses severe privacy concerns as it has been shown that the learned models can reveal sensitive information about their training data. Many works have investigated the effect of widely adopted data augmentation and adversarial training techniques, termed data enhancement in the paper, on the privacy leakage of machine learning models. Such privacy effects are often measured by membership inference attacks (MIAs), which aim to identify whether a particular example belongs to the training set or not. We propose to investigate privacy from a new perspective called memorization. Through the lens of memorization, we find that previously deployed MIAs produce misleading results as they are less likely to identify samples with higher privacy risks as members compared to samples with low privacy risks. To solve this problem, we deploy a recent attack that can capture individual samples’ memorization degrees for evaluation. Through extensive experiments, we unveil several findings about the connections between three essential properties of machine learning models, including privacy, generalization gap, and adversarial robustness. We demonstrate that the generalization gap and privacy leakage are less correlated than those of the previous results. Moreover, there is not necessarily a trade-off between adversarial robustness and privacy as stronger adversarial robustness does not make the model more susceptible to privacy attacks.}
}


@article{DBLP:journals/tifs/SongHZXJ24,
	author = {Mingyang Song and
                  Zhongyun Hua and
                  Yifeng Zheng and
                  Tao Xiang and
                  Xiaohua Jia},
	title = {SimLESS: {A} Secure Deduplication System Over Similar Data in Cloud
                  Media Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4700--4715},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3382603},
	doi = {10.1109/TIFS.2024.3382603},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SongHZXJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the growing popularity of cloud computing, sharing media data through the cloud has become a common practice. Due to high information redundancy, media data take up a significant amount of storage space. Moreover, similar media data may have the same visual effect, resulting in unnecessary duplication. Thus, it can greatly improve the cloud storage efficiency by performing deduplication to the similar media data stored on the cloud. However, data privacy is a growing concern in cloud-based service. In this paper, we present SimLESS, a secure deduplication system for similar data in cloud media sharing. SimLESS allows the cloud to perform deduplication over the encrypted similar media data of different distributors while protecting the confidentiality and ownership of the data. When uploading a media file, SimLESS allows the distributor to set a distance threshold, and the cloud performs deduplication only when there is a file on the cloud whose distance from the file being uploaded is smaller than the threshold. Additionally, we provide fine-grained access control for distributors to ensure that only authorized media consumers can access the data. Furthermore, our system prevents any distributor from claiming ownership of a media file using only the tag of a similar file. We formally analyze the security of SimLESS and implement a system prototype to evaluate its performance. Our experimental results demonstrate that the computation and communication costs of SimLESS are practically affordable.}
}


@article{DBLP:journals/tifs/HuangHCLHH24,
	author = {Panjian Huang and
                  Saihui Hou and
                  Chunshui Cao and
                  Xu Liu and
                  Xuecai Hu and
                  Yongzhen Huang},
	title = {Integral Pose Learning via Appearance Transfer for Gait Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4716--4727},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3382606},
	doi = {10.1109/TIFS.2024.3382606},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangHCLHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gait recognition plays an important role in video surveillance and security by identifying humans based on their unique walking patterns. The existing gait recognition methods have achieved competitive accuracy with shape and motion patterns under limited-covariate conditions. However, when extreme appearance changes distort discriminative features, gait recognition yields unsatisfactory results under cross-covariate conditions. In this work, we first indicate that the integral pose in each silhouette maintains an appearance-unrelated discriminative identity. However, the monotonous appearance variables in a gait database cause gait models to have difficulty extracting integral poses. Therefore, we propose an Appearance-transferable Disentangling and Generative Network (GaitApp) to generate gait silhouettes with rich appearances and invariant poses. Specifically, GaitApp leverages multi-branch cooperation to disentangle pose features and appearance features, and transfers the appearance information from one subject to another. By simulating a person constantly changing appearances under limited-covariate conditions, downstream models enable to extract discriminative integral pose features. Extensive experiments demonstrate that our method allows representative gait models to stand at a new altitude, further promoting the exploration to cross-covariate gait recognition. All the code is available at https://github.com/Hpjhpjhs/GaitApp.git}
}


@article{DBLP:journals/tifs/GaoLLW24,
	author = {Lijun Gao and
                  Wenjun Liu and
                  Kai Liu and
                  Jiehong Wu},
	title = {AugSteal: Advancing Model Steal With Data Augmentation in Active Learning
                  Frameworks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4728--4740},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3384841},
	doi = {10.1109/TIFS.2024.3384841},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GaoLLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of machine learning models in diverse applications, the issue of model security has increasingly become a focal point. Model steal attacks can cause significant financial losses to model owners and potentially threaten the security of their application scenarios. Traditional model steal attacks are primarily directed at soft-label black boxes, but their effectiveness significantly diminishes or even fails in hard-label scenarios. To address this, for hard-label black boxes, this study proposes an active learning-based Fusion Augmentation Model Stealing Framework (AugSteal). This framework initially utilizes large-scale irrelevant public datasets for deep filtering and feature extraction to generate reliable, diverse, and representative high-quality data subsets as the stealing dataset. Subsequently, we developed an adaptive active learning selection strategy that selects data samples with significant information gain for different black-box models, enhancing the attack’s specificity and effectiveness. Finally, to further address the trade-off between query budget and steal precision, this paper designed a Fusion Augmentation training method constituted of two different loss functions, enabling the substitute model to closely approximate the decision distribution of the target black box.The comprehensive experimental results indicate that, compared to the current state-of-the-art attack methods, our approach achieved a maximum performance gain of 8.21% in functional similarity for the substitute models in simulated black-box scenarios CIFAR10, SVHN, CALTECH256, and the real-world application Tencent Cloud API.}
}


@article{DBLP:journals/tifs/HeLXCC24,
	author = {Daojing He and
                  Xin Lv and
                  Xueqian Xu and
                  Sammy Chan and
                  Kim{-}Kwang Raymond Choo},
	title = {Double-Layer Detection of Internal Threat in Enterprise Systems Based
                  on Deep Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4741--4751},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372771},
	doi = {10.1109/TIFS.2024.3372771},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HeLXCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, phishing email-mediated attacks are proliferating. When victims are enterprise employees, internal security of the enterprise systems will also be threatened. Currently, blockchain technology can effectively improve the security and privacy of traditional email, but attacks initiated from within are still fatal. Therefore, we propose a double-layer detection framework in this paper. Firstly, from the perspective of individual security, Long Short-Term Memory (LSTM) and extreme gradient boosting tree (XGBoost) are used to build a phishing email detection model. The model generalization ability and precision rate are improved by adding a custom loss function in the training process. Then, from the perspective of group security, Bidirectional LSTM and Attention mechanism are used to build an insider threat detection model. Our model has better results for multi-domain time series and anomaly detection in comparison to different models and existing insider threat detection models. We test the effectiveness of the proposed framework through real phishing email cases and insider threat attack events on our simulation verification platform. The experimental results demonstrate that our proposed framework can protect enterprise systems from phishing attacks and insider threats. We also point out that this framework can be applied to mitigate the increasingly serious blockchain security threats.}
}


@article{DBLP:journals/tifs/ZhangZSGCSY24,
	author = {Jiale Zhang and
                  Chengcheng Zhu and
                  Xiaobing Sun and
                  Chunpeng Ge and
                  Bing Chen and
                  Willy Susilo and
                  Shui Yu},
	title = {FLPurifier: Backdoor Defense in Federated Learning via Decoupled Contrastive
                  Training},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4752--4766},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3384846},
	doi = {10.1109/TIFS.2024.3384846},
	timestamp = {Sat, 11 Jan 2025 00:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZSGCSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have demonstrated that backdoor attacks can cause a significant security threat to federated learning. Existing defense methods mainly focus on detecting or eliminating the backdoor patterns after the model is backdoored. However, these methods either cause model performance degradation or heavily rely on impractical assumptions, such as labeled clean data, which exhibit limited effectiveness in federated learning. To this end, we propose FLPurifier, a novel backdoor defense method in federated learning that can effectively purify the possible backdoor attributes before federated aggregation. Specifically, FLPurifier splits a complete model into a feature extractor and classifier, in which the extractor is trained in a decoupled contrastive manner to break the strong correlation between trigger features and the target label. Compared with existing backdoor mitigation methods, FLPurifier doesn’t rely on impractical assumptions since it can effectively purify the backdoor effects in the training process rather than an already trained model. Moreover, to decrease the negative impact of backdoored classifiers and improve global model accuracy, we further design an adaptive classifier aggregation strategy to dynamically adjust the weight coefficients. Extensive experimental evaluations on six benchmark datasets demonstrate that FLPurifier is effective against known backdoor attacks in federated learning with negligible performance degradation and outperforms the state-of-the-art defense methods.}
}


@article{DBLP:journals/tifs/GilkarovD24,
	author = {Daniel Gilkarov and
                  Ran Dubin},
	title = {Steganalysis of {AI} Models {LSB} Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4767--4779},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3383770},
	doi = {10.1109/TIFS.2024.3383770},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GilkarovD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Artificial intelligence has made significant progress in the last decade, leading to a rise in the popularity of model sharing. The model zoo ecosystem, a repository of pre-trained AI models, has advanced the AI open-source community and opened new avenues for cyber risks. Malicious attackers can exploit shared models to launch cyber-attacks. This work focuses on the steganalysis of injected malicious Least Significant Bit (LSB) steganography into AI models, and it is the first work focusing on AI model attacks. In response to this threat, this paper presents a steganalysis method specifically tailored to detect and mitigate malicious LSB steganography attacks based on supervised and unsupervised AI detection steganalysis methods. Our proposed technique aims to preserve the integrity of shared models, protect user trust, and maintain the momentum of open collaboration within the AI community. In this work, we propose 3 steganalysis methods and open source our code. We found that the success of the steganalysis depends on the LSB attack location. If the attacker decides to exploit the least significant bits in the LSB, the ability to detect the attacks is low. However, if the attack is in the most significant LSB bits, the attack can be detected with almost perfect accuracy.}
}


@article{DBLP:journals/tifs/LiCZWC24,
	author = {Beibei Li and
                  Youtong Chen and
                  Lei Zhang and
                  Licheng Wang and
                  Yanyu Cheng},
	title = {HomeSentinel: Intelligent Anti-Fingerprinting for IoT Traffic in Smart
                  Homes},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4780--4793},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3382589},
	doi = {10.1109/TIFS.2024.3382589},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiCZWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have demonstrated that malicious adversaries are capable of fingerprinting Internet of Things (IoT) devices in a smart home and further causing privacy breaches. However, many existing anti-fingerprinting schemes, either by traffic padding or traffic mutation, are less effective in defending against state-of-the-art fingerprinting methods. To meet this gap, we in this paper propose the HomeSentinel, an intelligent anti-fingerprinting scheme to counter IoT traffic fingerprinting in smart homes. Specifically, we first design a LightGBM-based IoT traffic extraction model to accurately distinguish IoT traffic from raw network traffic in a smart home without user operations. Second, we develop a dummy IoT traffic generation model to produce dummy IoT traffic in desired spatial-temporal patterns. Third, an IoT traffic mixing strategy is crafted to heuristically merge dummy IoT traffic with real IoT traffic in desired spatial-temporal patterns. Extensive experiments on three real-world datasets (i.e., two public and one custom) demonstrate that our proposed HomeSentinel scheme can effectively defend against state-of-the-art IoT traffic fingerprinting methods, and outperforms existing IoT traffic anti-fingerprinting schemes. Further, real-world experiments are conducted on a self-built testbed show that, reasonably low communication delays can be caused when implementing the HomeSentinel in smart homes.}
}


@article{DBLP:journals/tifs/XuFZZ24,
	author = {Nanqing Xu and
                  Weiwei Feng and
                  Tianzhu Zhang and
                  Yongdong Zhang},
	title = {A Unified Optimization Framework for Feature-Based Transferable Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4794--4808},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3380248},
	doi = {10.1109/TIFS.2024.3380248},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuFZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the rapid progress and significant success of deep learning in a wide spectrum of fields, adversarial examples expose many security threats to deep learning models. Recently, an interesting property has been discovered that adversarial examples are transferable, which means adversarial examples targeting a given model can also attack another model. Therefore, many researchers are attracted by this property and work on how to improve the transferability of adversarial examples. Furthermore, compared to the traditional attack methods of disrupting output logits (dubbed logit-based attacks), recent works reveal that disrupting feature maps instead of logits can lead to more transferable adversarial examples (dubbed feature-based attacks). However, previous feature-based attacks mostly hold the intuitive designs of the optimization goals and specialization for certain scenarios with a lack of theoretical motivations and a unified framework. To overcome these limitations, we propose a Unified Feature-based Attack Framework, dubbed as UFAF, combining a dispersion loss and a distance loss, which unifies eight existing feature-based attacks. Furthermore, we also bridge the formulation gap between feature-based attacks and traditional logit-based attacks. With our UFAF, we propose an Entropy-Wasserstein (EW) attack by specifying the dispersion loss as Entropy and the distance loss as Wasserstein Distance, respectively. Besides, we provide theoretical analysis to guarantee the effectiveness of the proposed attack method. Extensive experimental results show the superior performance of our EW attack, which can outperform state-of-the-art attacks by 4.95% on attack success rates in untargeted attack settings, and by 1.95% on targeted transfer rates and 1.17% on target success rates in targeted attack settings. Moreover, our framework can help other feature-based attacks improve their performance by 7.7% in untargeted attack settings.}
}


@article{DBLP:journals/tifs/ZhuZTLZ24,
	author = {Liwang Zhu and
                  Xiaotian Zhou and
                  Jiahe Tian and
                  Wei Li and
                  Zhongzhi Zhang},
	title = {Defending Against Malicious Influence Control in Online Leader-Follower
                  Social Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4809--4819},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3383244},
	doi = {10.1109/TIFS.2024.3383244},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuZTLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The formation of opinions is fundamentally a network-based process, where the opinions of individuals in a social network exchange, evolve, and eventually converge towards a specific distribution. However, this dynamic process may be susceptible to manipulation by adversarial entities, who aim to maliciously influence the opinion formulation. The adversary may engage in extensive influence campaigns, disseminating misinformation among populations, thereby potentially destabilizing societies. It is thus of significance to develop strategies to defend against such attacks, which are essential for fostering a healthy environment for information sharing, social deliberation, and opinion formation. In this paper, we investigate a scenario wherein an external adversary aims to maliciously alter the opinions of a general social graph. This is achieved by targeting several selected nodes, referred to as followers. Concurrently, we explore a counter-strategy, aiming to negate the influence of the adversary with malicious intents. This involves identifying a subset of nodes to act as followers of a defending leader, thereby minimizing the adversary’s impact. Since this problem can be framed as a non-increasing supermodular minimization problem, we develop a\n(1−1/e)\napproximation greedy algorithm consequently. Moreover, to overcome the computation challenge for large-scale networks, we establish an efficient approximation to the key quantity of the greedy algorithm. This refinement significantly enhances computational efficiency and scalability, making the algorithm applicable to networks with millions of nodes. Extensive simulation results on various real-world networks demonstrate the superior performance of our improved algorithm over existing algorithms and other baseline schemes based on centrality measures. In particular, our improved algorithm scales to networks of considerable size, with negligible sacrifice on the quality of solutions.}
}


@article{DBLP:journals/tifs/PengTMLH24,
	author = {Rongxuan Peng and
                  Shunquan Tan and
                  Xianbo Mo and
                  Bin Li and
                  Jiwu Huang},
	title = {Employing Reinforcement Learning to Construct a Decision-Making Environment
                  for Image Forgery Localization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4820--4834},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3381470},
	doi = {10.1109/TIFS.2024.3381470},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PengTMLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread misuse of advanced image editing tools and deep generative techniques has led to a proliferation of images with altered content in real-life scenarios, often without any discernible traces of tampering. This has created a potential threat to security and credibility of images. Image forgery localization is an urgent technique. In this paper, we propose a novel reinforcement learning-based framework CoDE (Construct Decision-making Environment) that can provide reliable localization result of tampered area in forged images. We model the forgery localization task as a Markov Decision Process (MDP), where each pixel is equipped with an agent that performs Gaussian distribution-based continuous action to iteratively update the respective forgery probability, so as to achieve pixel-level image forgery localization. In order to construct the state transitions within MDP, we propose a twin-flow state encoder to handle the updated state, which consists of the forged image and its corresponding forgery probability map. What’s more, considering that the tampered area is often sparse in practical image tampering scenarios, we design a reward function specifically for these sparse tampered area. This reward function can guide the agent to more effectively learn the optimal strategy for maximizing the cumulative reward. Extensive experiments conducted on a variety of benchmark datasets demonstrate CoDE’s superior localization accuracy and robustness against image degradation caused by transmission through Online Social Networks (OSNs) and various post-processing attacks.}
}


@article{DBLP:journals/tifs/RoigGRB24,
	author = {Dail{\'{e}} Osorio Roig and
                  L{\'{a}}zaro Janier Gonz{\'{a}}lez{-}Soler and
                  Christian Rathgeb and
                  Christoph Busch},
	title = {Privacy-Preserving Multi-Biometric Indexing Based on Frequent Binary
                  Patterns},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4835--4850},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3386310},
	doi = {10.1109/TIFS.2024.3386310},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/RoigGRB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of large-scale identification systems that ensure the privacy protection of enrolled subjects represents a major challenge. Biometric deployments that provide interoperability and usability by including efficient multi-biometric solutions are a recent requirement. In the context of privacy protection, several template protection schemes have been proposed in the past. However, these schemes seem inadequate for indexing (workload reduction) in biometric identification systems. More specifically, they have been used in identification systems that perform exhaustive searches, leading to a degradation of computational efficiency. To overcome these limitations, we present an efficient privacy-preserving multi-biometric identification system that retrieves protected deep cancelable templates and is agnostic with respect to biometric characteristics and biometric template protection schemes. To this end, a multi-biometric binning scheme is designed to exploit the low intra-class variation properties contained in the frequent binary patterns extracted from different types of biometric characteristics. Experimental results reported on publicly available databases using state-of-the-art Deep Neural Network (DNN)-based embedding extractors show that the protected multi-biometric identification system can reduce the computational workload to approximately 57% (indexing up to three types of biometric characteristics) and 53% (indexing up to two types of biometric characteristics), while simultaneously improving the biometric performance of the baseline biometric system at the high-security thresholds. Code is available at https://github.com/dosorior/FBP-Multi-biometric-Indexing.}
}


@article{DBLP:journals/tifs/DuanLWFL24,
	author = {Guanghan Duan and
                  Hongwu Lv and
                  Huiqiang Wang and
                  Guangsheng Feng and
                  Xiaoli Li},
	title = {Practical Cyber Attack Detection With Continuous Temporal Graph in
                  Dynamic Network System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4851--4864},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3385321},
	doi = {10.1109/TIFS.2024.3385321},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DuanLWFL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning (DL) greatly enhances cyber anomaly detection capabilities through effective statistical network characteristic. However, previous methods have not fully addressed two real-world scenario-driven challenges. 1) Frequent node access and disconnection sourced from free-bounded 5G/B5G cyberspace introduce unfamiliar communication behavior patterns, reducing the detection ability of the pre-trained DL model. 2) Low-frequency or sporadic communication behaviors lack stable patterns, posing a challenge for existing AI-driven models, including DL-based detection methods. To address these issues, we propose a cyber anomaly detection framework based on Continuous Temporal Graph (CTG) neural network from a new interaction-centered perspective. The proposed framework refines the concrete information interaction between network entities into the CTG evolution process, thereby naturally incorporating new node access behaviors into feature extraction on CTG neural network. We furthermore present a message aggregation scheme on CTG with fusion of spatio-temporal neighborhood, the actual time distribution and the historical state, thus transforming communication into a more stable pattern for the learning of low-frequency interactions. Extensive experiments on 4 novel datasets, including ToN-IoT, UNSWNB15, CIC-Dark2020, J.P. Morgan payment, demonstrate that our approach outperforms state-of-the-art methods, particularly in detecting new access and low-frequency behaviors.}
}


@article{DBLP:journals/tifs/ViceAHM24,
	author = {Jordan Vice and
                  Naveed Akhtar and
                  Richard I. Hartley and
                  Ajmal Mian},
	title = {{BAGM:} {A} Backdoor Attack for Manipulating Text-to-Image Generative
                  Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4865--4880},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3386058},
	doi = {10.1109/TIFS.2024.3386058},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ViceAHM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise in popularity of text-to-image generative artificial intelligence (AI) has attracted widespread public interest. We demonstrate that this technology can be attacked to generate content that subtly manipulates its users. We propose a Backdoor Attack on text-to-image Generative Models (BAGM), which upon triggering, infuses the generated images with manipulative details that are naturally blended in the content. Our attack is the first to target three popular text-to-image generative models across three stages of the generative process by modifying the behaviour of the embedded tokenizer, the language model or the image generative model. Based on the penetration level, BAGM takes the form of a suite of attacks that are referred to as surface, shallow and deep attacks in this article. Given the existing gap within this domain, we also contribute a comprehensive set of quantitative metrics designed specifically for assessing the effectiveness of backdoor attacks on text-to-image models. The efficacy of BAGM is established by attacking state-of-the-art generative models, using a marketing scenario as the target domain. To that end, we contribute a dataset of branded product images. Our embedded backdoors increase the bias towards the target outputs by more than five times the usual, without compromising the model robustness or the generated content utility. By exposing generative AI’s vulnerabilities, we encourage researchers to tackle these challenges and practitioners to exercise caution when using pre-trained models. Relevant code and input prompts can be found at https://github.com/JJ-Vice/BAGM, and the dataset is available at: https://ieee-dataport.org/documents/marketable-foods-mf-dataset}
}


@article{DBLP:journals/tifs/PengYZXPHYZJ24,
	author = {Hao Peng and
                  Jieshuai Yang and
                  Dandan Zhao and
                  Xiaogang Xu and
                  Yuwen Pu and
                  Jianmin Han and
                  Xing Yang and
                  Ming Zhong and
                  Shouling Ji},
	title = {MalGNE: Enhancing the Performance and Efficiency of CFG-Based Malware
                  Detector by Graph Node Embedding in Low Dimension Space},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4881--4896},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3389614},
	doi = {10.1109/TIFS.2024.3389614},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PengYZXPHYZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rich semantic information in Control Flow Graphs (CFGs) of executable programs has made Graph Neural Networks (GNNs) a key focus for malware detection. However, existing CFG-based detection techniques face limitations in node feature extraction, such as information loss, neglect of execution sequence information, and redundancy in representation vectors. These limitations compromise the balance between high efficiency and precision when training detectors. Addressing this, we introduce an innovative Malware CFG Node Embedding (MalGNE) method. This approach utilizes a novel instruction encoding rule to address the Out-Of-Vocabulary(OOV) problem, generates high-quality initial vectors. Then, it employs aggregation layer and sequence layer to extract node aggregation feature and execution sequence feature, in conjunction with GNNs to develop a pre-trained node embedding model. The model maps the semantic information of node assembly instruction sequences into a compact, low-dimensional continuous space, ensuring high-quality feature extraction, and enhancing the performance and efficiency of the detector. We trained the MalGNE model using the BIG 2015 dataset and validated MalGNE-enhanced detector on the SOREL-20M and BODMAS datasets. MalGNE-enhanced detector demonstrates outstanding performance and efficiency in low-dimensional spaces, especially when the dimensionality of the node feature vector is reduced to 16. MalGNE-enhanced detector not only maintains a high detection accuracy of 95.49%. sacrificing only about 1.7% of accuracy to save approximately 73% of training time compared to 128 dimensions.}
}


@article{DBLP:journals/tifs/AbbadeSSRABR24,
	author = {Marcelo Lu{\'{\i}}s Francisco Abbade and
                  Welerson Santos Souza and
                  Melissa de Oliveira Santos and
                  Ivan Eduardo Lage Rodrigues and
                  Ivan Aldaya and
                  Luiz H. Bonani and
                  Murilo Ara{\'{u}}jo Romero},
	title = {Discrete Spectral Encryption of Single-Carrier Signals With Pseudo
                  Random Dynamic Keys},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4914--4929},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3390995},
	doi = {10.1109/TIFS.2024.3390995},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AbbadeSSRABR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical layer security is a crucial step towards fully secure communications systems. The flexibility and ubiquity of digital signal processors in modern wireless and optical communication systems open up a clear path for the development of discrete-signals encryption techniques, which can be implemented relatively cheap. In this paper, we show the fundamental role of amplitude and phase encoding in the security and practical implementation of linear discrete signal cryptography (DSC). We focus on the spectral implementation of these encoding schemes and consider the equivalence between spectral amplitude encoding (SAE) and spectral scrambling (SS). Numerical simulation results show that 16-quadrature amplitude modulation (16-QAM) signals encrypted by SS and spectral phase encoding (SPE) can be recovered only if eavesdroppers know the exact position of \\sim ~95 % of the scrambled samples with a maximum phase error of \\pm ~7^{\\circ } for all samples. The number of brute force attacks to break such encrypted signals far exceeds the one provided by the widely deployed data ciphering algorithm Advanced Encryption Standard (AES). Physical layer results reveal that the bit error ratio (BER) associated with the encrypted signals is 0.50 regardless of the deployed signal format and DSC scheme. The BER vs. signal-to-noise ratio performance of the encrypted/ decrypted signal is the same as that of signals not encrypted. Finally, the paper proposes the adoption of pseudo-random dynamic keys (PRDKs) to promote encryption randomness, diffusion, and confusion to the encrypted signals. A new numerical methodology shows this strategy outperforms AES diffusion and confusion properties.}
}


@article{DBLP:journals/tifs/YuanCPZLZGE24,
	author = {Lin Yuan and
                  Wu Chen and
                  Xiao Pu and
                  Yan Zhang and
                  Hongbo Li and
                  Yushu Zhang and
                  Xinbo Gao and
                  Touradj Ebrahimi},
	title = {PRO-Face {C:} Privacy-Preserving Recognition of Obfuscated Face via
                  Feature Compensation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4930--4944},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3388976},
	doi = {10.1109/TIFS.2024.3388976},
	timestamp = {Tue, 10 Dec 2024 12:34:29 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YuanCPZLZGE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advancement of face recognition technology has delivered substantial societal advantages. However, it has also raised global privacy concerns due to the ubiquitous collection and potential misuse of individuals’ facial data. This presents a notable paradox: while there is a societal demand for a robust face recognition ecosystem to ensure public security and convenience, an increasing number of individuals are hesitant to release their facial data. Numerous studies have endeavored to find such a utility-privacy trade-off, yet many struggle with the dilemma of prioritizing one at the expense of the other. In response to this challenge, this paper proposes PRO-Face C, a novel paradigm for privacy-preserving recognition of obfuscated faces via a dedicated feature compensation mechanism, aimed at optimizing the equilibrium between privacy preservation and utility maximization. The proposed approach is characterized by a specialized client-server architecture: the client transmits only obfuscated images to the server, which then performs identity recognition using a pre-trained model in conjunction with a suite of privacy-free complementary features. This framework facilitates accurate face identification while safeguarding the original facial appearance from explicit disclosure. Furthermore, the obfuscated image retains its visualization capability, crucial for image preview functionalities. To ensure the desired properties, we have developed an identity-guided feature compensation mechanism, complemented by several privacy-enhancing techniques. Extensive experiments conducted across multiple face datasets underscore the effectiveness of the proposed approach in diverse scenarios.}
}


@article{DBLP:journals/tifs/LiuJLLX24,
	author = {Beiyuan Liu and
                  Jinjing Jiang and
                  Qian Liu and
                  Jiajia Liu and
                  Sai Xu},
	title = {An Intelligent Reflecting Surface-Based Attack Scheme Against Dual-Functional
                  Radar and Communication Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4945--4956},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3390621},
	doi = {10.1109/TIFS.2024.3390621},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuJLLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dual-functional radar and communication (DFRC) system is capable of sensing potential eavesdroppers close to the DFRC base station (BS) and further ensuring secure transmission using physical layer security technologies based on the obtained location information of eavesdroppers. However, such security can be threatened by a malicious intelligent reflecting surface (IRS) that simultaneously changes both radar and communication channels. To reveal this threat, an IRS-based active attack scheme is proposed in this paper under the assumption of a prevalent DFRC framework. In this scheme, the attacker, equipped with a malicious IRS, carefully controls and optimizes the IRS phase shifts in each stage of the DFRC framework to reduce its reflected radar echo power to the BS and/or strength the wiretap link gain for pilot spoofing attack according to the statistical channel state information. Numerical results show that our proposed attack scheme can significantly reduce the secrecy rate of the legitimate user, while avoid being detected by the DFRC BS.}
}


@article{DBLP:journals/tifs/ChangSXHLS24,
	author = {Shuyu Chang and
                  Zhenqi Shi and
                  Fu Xiao and
                  Haiping Huang and
                  Xingchen Liu and
                  Chaorun Sun},
	title = {Privacy-Enhanced Frequent Sequence Mining and Retrieval for Personalized
                  Behavior Prediction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4957--4969},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3391928},
	doi = {10.1109/TIFS.2024.3391928},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChangSXHLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of smartphones has yielded a wealth of behavioral sequence data from user interactions. These interactions offer insights into user preferences and patterns for personalized behavior prediction. However, there are some challenges in current privacy-preserving works for analyzing these data. These approaches have suboptimal service quality with smaller but longer datasets and insufficient emphasis on secure pattern storage and retrieval in real-world applications. To handle these challenges on smartphones, we propose a novel Privacy-enhanced Frequent Sequence Mining and Retrieval (PrivFSMR) framework for this scenario. Specifically, we first introduce a dynamic sequence truncation to anonymize the maximum sequence length of datasets. Following this, we design a privacy-enhanced FSM algorithm to uncover patterns, effectively reducing the privacy budget by integrating differential privacy and the Markov assumption. During the secure pattern storage, PrivFSMR employs symmetric encryption for protection and constructs an encrypted index forest for retrieval. Lastly, future behavior retrieval leverages current device information and the index forest to search similar patterns, thereby predicting potential user behaviors in the future. A comprehensive security analysis proves the PrivFSMR framework guarantees differential privacy and maintains storage and retrieval confidentiality in the lifecycle. In addition to using two publicly available datasets, we also collected a real behavior dataset within 2–4 weeks from 30 users for evaluation. Experimental results on three datasets demonstrate that PrivFSMR excels in mining frequent patterns and predicting future behaviors compared to existing approaches.}
}


@article{DBLP:journals/tifs/ZhuZZC24,
	author = {Hong Zhu and
                  Yue Zhao and
                  Shengzhi Zhang and
                  Kai Chen},
	title = {NeuralSanitizer: Detecting Backdoors in Neural Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4970--4985},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3390599},
	doi = {10.1109/TIFS.2024.3390599},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuZZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) have been pervasively used in many areas, e.g., computer vision, speech recognition, natural language processing, etc. However, recent works show that they are vulnerable to backdoor/Trojan attacks, severely restricting their usage in various scenarios. In this paper, we propose NeuralSanitizer, a novel approach to detect and remove backdoors in DNNs, capable of capturing various triggers with better accuracy and higher efficiency. In particular, we identify two fundamental properties of triggers, i.e., their effectiveness in the backdoored model and ineffectiveness in other clean models, and design a novel objective function to reconstruct triggers based on them. Then we present a new approach that leverages transferability to identify adversarial patches that could be generated during trigger reconstruction, thus detecting backdoors more accurately. We evaluate NeuralSanitizer on real-world backdoored DNNs and achieve 2.1% FNR and 0.9% FPR on average, significantly outperforming the state-of-the-art works by 1~14 times. In addition, NeuralSanitizer can reconstruct triggers up to 25% of the size of the original inputs on average, compared to only 6~10% by existing works. Finally, NeuralSanitizer is also 1~25 times faster than existing works.}
}


@article{DBLP:journals/tifs/WangZYHT24,
	author = {Jiaxiang Wang and
                  Aihua Zheng and
                  Yan Yan and
                  Ran He and
                  Jin Tang},
	title = {Attribute-Guided Cross-Modal Interaction and Enhancement for Audio-Visual
                  Matching},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4986--4998},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3388949},
	doi = {10.1109/TIFS.2024.3388949},
	timestamp = {Wed, 09 Oct 2024 23:03:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangZYHT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Audio-visual matching is an essential task that measures the correlation between audio clips and visual images. However, current methods rely solely on the joint embedding of global features from audio clips and face image pairs to learn semantic correlations. This approach overlooks the importance of high-confidence correlations and discrepancies of local subtle features, which are crucial for cross-modal matching. To address this issue, we propose a novel Attribute-guided Cross-modal Interaction and Enhancement Network (ACIENet), which employs multiple attributes to explore the associations of different key local subtle features. The ACIENet contains two novel modules: the Attribute-guided Interaction (AGI) module and the Attribute-guided Enhancement (AGE) module. The AGI module employs global feature alignment similarity to guide cross-modal local feature interactions, which enhances cross-modal association features for the same identity and expands cross-modal distinctive features for different identities. Additionally, the interactive features and original features are fused to ensure intra-class discriminability and inter-class correspondence. The AGE module captures subtle attribute-related features by using an attribute-driven network, thereby enhancing discrimination at the attribute level. Specifically, it strengthens the combined attribute-related features of gender and nationality. To prevent interference between multiple attribute features, we design a multi-attribute learning network as a parallel framework. Experiments conducted on a public benchmark dataset demonstrate the efficacy of the ACIENet method in different scenarios. Code and models are available at https://github.com/w1018979952/ACIENet.}
}


@article{DBLP:journals/tifs/LiuHCLL24,
	author = {Zhihuang Liu and
                  Ling Hu and
                  Zhiping Cai and
                  Ximeng Liu and
                  Yanhua Liu},
	title = {SeCoSe: Toward Searchable and Communicable Healthcare Service Seeking
                  in Flexible and Secure {EHR} Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4999--5014},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3391914},
	doi = {10.1109/TIFS.2024.3391914},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuHCLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud-assisted electronic health record (EHR) sharing plays an important role in modern healthcare systems but faces threats of distrust and non-traceability. The advent of blockchain offers an attractive solution to overcome this issue. Many efforts are devoted to promoting secure, flexible, and multi-featured blockchain-based EHR sharing. Yet, the problem of seeking out suitable healthcare providers and communicating information beyond the EHR has unfortunately been ignored. In this paper, we propose SeCoSe, a novel EHR sharing scheme to address these concerns. SeCoSe enables patients and their general practitioners to autonomously seek out and stay in touch with their preferred healthcare professionals. Specifically, a searchable and repeatable transformation identity-based encryption (SRTIBE) is proposed to achieve dynamic and flexible authorization updates. Moreover, we design attribute-identity mapping contracts and evidence-based contracts on the blockchain to enable on-demand retrieval of anonymous identities and ensure tamper resistance and traceability of system transactions. Furthermore, we employ the advanced messages on-chain protocol (AMOP) to facilitate the online communication of off-chain messages. Detailed security analysis and extensive evaluations demonstrate that SeCoSe is privacy-secure, traceable, and attack-resistant. SeCoSe has lower overhead for repeated authorization and transformation, on-chain transactions can be responded to within seconds, and online communication can handle the transmission of 49,000 messages in about 6 seconds.}
}


@article{DBLP:journals/tifs/LiXZGDGP24,
	author = {Yuepei Li and
                  Kai Xu and
                  Junqing Zhang and
                  Chongyan Gu and
                  Yuan Ding and
                  George Goussetis and
                  Symon K. Podilchak},
	title = {PUF-Assisted Radio Frequency Fingerprinting Exploiting Power Amplifier
                  Active Load-Pulling},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5015--5029},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3389570},
	doi = {10.1109/TIFS.2024.3389570},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiXZGDGP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a novel radio frequency fingerprint (RFF) enhancement strategy by exploiting the physical unclonable function (PUF) to tune the RF hardware impairments in a unique and secure manner, which is exemplified by taking power amplifiers (PAs) in RF chains as an example. This is achieved by intentionally and slightly tuning the PA non-linearity characteristics using the active load-pulling technique. The motivation driving the proposed research is to enlarge the RFF feature differences among wireless devices of same vendor, in order to massively improve their RFF classification accuracy in low to medium signal to noise ratio (SNR) channel conditions. PUF is employed to dynamically tune the PA’s RFF feature which guarantees the security since the PUF response cannot be cloned. Specifically, a ring oscillator (RO)-based PUF is implemented to control the PA non-linearity by selecting unique but random configuration parameters. This approach is proposed to amplify the distinctions across same model PAs, thereby enhancing the RFF classification performance. In the meantime, our innovative strategy of PUF-assisted RFF does not noticeably compromise communication link performance which is experimentally tested. The resulting RFF features can be extracted from the received distorted constellation diagrams with the help of image recognition-based machine learning classification algorithms. Extensive experimental evaluations are carried out using both cable-connected and over-the-air (OTA) measurements. Our proposed approach, when classifying eight PAs from a same vendor, achieves 11% to 24% average classification accuracy improvement by enlarging the RFF feature differences arising from the PA non-linearity.}
}


@article{DBLP:journals/tifs/KangYA24,
	author = {Bichen Kang and
                  Neng Ye and
                  Jianping An},
	title = {Optimal Signaling for Covert Communications Under Peak Power Constraint},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5030--5045},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3395067},
	doi = {10.1109/TIFS.2024.3395067},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KangYA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Covert communications studied in prior works typically consider only the average power constraint on the transmit signal. In this paper, we explore the optimal signaling for covert communication under the peak power constraint, in view of the realistic limitation at the transmitter. Our main result is that the rate-optimal transmit signal distribution under the covertness constraint forms finite hyperspheres, on each of which the points distribute uniformly. To prove this, a lemma is first deduced to explore the equivalence between maximizing the achievable rate and minimizing the covertness measured by the Kullback-Leibler divergence. The equivalence property is then exploited to characterize the covert communication as a specific two-user broadcast channel, which simplifies the intractable covertness constraint. After that, by exploiting the spherical symmetry property of Gaussian noise and the identity theorem of holomorphic functions, the main result is derived. Furthermore, the analytical representation of the optimal signaling in low signal-to-noise ratio (SNR) region is studied following Shamai’s approach. For high SNR region, a nonlinear dynamic programming algorithm is developed to generate the optimal signal distribution. For ease of practical implementation, the discrete constellations are optimized based on the sequential quadratic programming algorithm. Simulation results verify the optimality of the proposed hyper-sphere signaling and demonstrate the performance gain of the optimized constellations over typical modulation constellations.}
}


@article{DBLP:journals/tifs/ZhangJWZXW24,
	author = {Yushu Zhang and
                  Junhao Ji and
                  Wenying Wen and
                  Youwen Zhu and
                  Zhihua Xia and
                  Jian Weng},
	title = {Understanding Visual Privacy Protection: {A} Generalized Framework
                  With an Instance on Facial Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5046--5059},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3389572},
	doi = {10.1109/TIFS.2024.3389572},
	timestamp = {Tue, 08 Oct 2024 15:40:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangJWZXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread application of computer vision, the scenarios in terms of visual privacy have become increasingly diverse and meanwhile numerous studies have been conducted to address privacy concerns in these scenarios. However, these studies are individually tailored for specific scenarios, making their layouts challenging to be drawn upon easily. When encountering a new scenario, it takes significant additional efforts to redesign a scheme due to the low referability of previous works. To tackle this issue, we explore commonalities among existing works and propose a generalized framework to meet the demand for visual privacy protection in various scenarios. Our framework is elaborately organized into several crucial steps, including privacy definition, scenario abstraction, algorithm design, and effect evaluation. It serves as a guide for researchers to efficiently design visual privacy protection schemes. In our framework, we establish a unified standard for quantifying privacy and introduce a novel constrained optimization theory to balance privacy and usability, which contributes to a broader understanding of visual privacy protection. Furthermore, we present an instance under the guidance of the framework that can support identity protection and attribute control scenarios through a diffusion-based model. Extensive experimental results demonstrate the effectiveness of our framework.}
}


@article{DBLP:journals/tifs/GaoZSL24,
	author = {Ge Gao and
                  Yuan Zhang and
                  Yaqing Song and
                  Shiyu Li},
	title = {PrivSSO: Practical Single-Sign-On Authentication Against Subscription/Access
                  Pattern Leakage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5075--5089},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3392533},
	doi = {10.1109/TIFS.2024.3392533},
	timestamp = {Wed, 11 Dec 2024 17:20:51 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GaoZSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Single-sign-on (SSO) authentication employs an identity provider (IdP) to provide users with an efficient way to authenticate themselves with different service providers and has been widely applied in digital systems. However, existing SSO authentication schemes suffer from critical issues in terms of security and privacy. Regarding security, most SSO authentication schemes achieve a high convenience at the expense of security and are thereby susceptible to various attacks. Regarding privacy, most existing schemes fail to protect users’ subscription pattern and access pattern against adversaries who can easily extract users’ sensitive information from their authentications and launch subsequent attacks for profits. In this paper, we develop a practical SSO authentication system, dubbed PrivSSO, with the protection of users’ subscription pattern and access pattern. To balance the trade-off between security and convenience, the key technique is a secure “hybrid” key-based authentication mechanism: a long-term key stored in a well-guarded hardware token serves as the “primary” authentication factor (AF) to guarantee strong security; an ephemeral key bound with portable device(s) serves as the “daily-used” AF to achieve high convenience. To protect the subscription pattern and access pattern from leakage, we propose a redactable token generation mechanism, where the users themselves specify what IdP and the service providers can learn from their authentications. We formally define and prove the security of PrivSSO. We also implement a PrivSSO prototype and conduct a comprehensive performance evaluation to demonstrate its practicality.}
}


@article{DBLP:journals/tifs/LiSLHZKEPH24,
	author = {Guyue Li and
                  Paul Staat and
                  Haoyu Li and
                  Markus Heinrichs and
                  Christian T. Zenger and
                  Rainer Kronberger and
                  Harald Elders{-}Boll and
                  Christof Paar and
                  Aiqun Hu},
	title = {RIS-Jamming: Breaking Key Consistency in Channel Reciprocity-Based
                  Key Generation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5090--5105},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3389569},
	doi = {10.1109/TIFS.2024.3389569},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiSLHZKEPH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Channel Reciprocity-based Key Generation (CRKG) exploits reciprocal channel randomness to establish shared secret keys between wireless terminals. This new security technique is expected to complement existing cryptographic techniques for secret key distribution of future wireless networks. In this paper, we present a new attack, reconfigurable intelligent surface (RIS) jamming, and show that an attacker can prevent legitimate users from agreeing on the same key by deploying a malicious RIS to break channel reciprocity. Specifically, we elaborate on three examples to implement the RIS-jamming attack: Using active nonreciprocal circuits, performing time-varying controls, and reducing the signal-to-noise ratio. The attack effect is then studied by formulating the secret key rate with a relationship to the deployment of RIS. To resist such RIS-jamming attacks, we propose a countermeasure that exploits wideband signals for multipath separation. The malicious RIS path is distinguished from all separated channel paths, and thus the countermeasure is referred to as contaminated path removal-based CRKG (CPR-CRKG). We present simulation results, showing that legitimate users under RIS jamming are still able to generate secret keys from the remaining paths. We also experimentally demonstrate the RIS-jamming attack by using commodity Wi-Fi devices in conjunction with a fabricated RIS prototype. In our experiments, we were able to increase the average bit disagreement ratio (BDR) of raw secret keys by 20%. Further, we successfully demonstrate the proposed CPR-CRKG countermeasure to tackle RIS jamming in wideband systems as long as the source of randomness and the RIS propagation paths are separable.}
}


@article{DBLP:journals/tifs/LuZDLLL24,
	author = {Jiucui Lu and
                  Jiaran Zhou and
                  Junyu Dong and
                  Bin Li and
                  Siwei Lyu and
                  Yuezun Li},
	title = {ForensicsForest Family: {A} Series of Multi-Scale Hierarchical Cascade
                  Forests for Detecting GAN-Generated Faces},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5106--5119},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3395013},
	doi = {10.1109/TIFS.2024.3395013},
	timestamp = {Sun, 04 Aug 2024 19:49:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuZDLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The prominent progress in generative models has significantly improved the authenticity of generated faces, raising serious concerns in society. To combat GAN-generated faces, many countermeasures based on Convolutional Neural Networks (CNNs) have been spawned due to their strong learning capabilities. In this paper, we rethink this problem and explore a new approach based on forest models instead of CNNs. Concretely, we describe a simple and effective forest-based method set, termed ForensicsForest Family, to detect GAN-generate faces. The ForensicsForest family is composed of three variants: ForensicsForest, Hybrid ForensicsForest and Divide-and-Conquer ForensicsForest. ForenscisForest is a novel Multi-scale Hierarchical Cascade Forest that takes appearance, frequency, and biological features as input, hierarchically cascades different levels of features for authenticity prediction, and employs a multi-scale ensemble scheme to consider different levels of information comprehensively for further performance improvement. Building upon ForensicsForest, we create Hybrid ForensicsForest, an extended version that integrates the CNN layers into models, to further enhance the efficacy of augmented features. Furthermore, to reduce memory usage during training, we introduce Divide-and-Conquer ForensicsForest, which can construct a forest model using only a portion of training samplings. In the training stage, we train several candidate forest models using the subsets of training samples. Then, a ForensicsForest is assembled by selecting suitable components from these candidate forest models. Our method is validated on state-of-the-art GAN-generated face datasets and compared with several CNN models, demonstrating the surprising effectiveness of our method in detecting GAN-generated faces.}
}


@article{DBLP:journals/tifs/ZhuICF24,
	author = {Yi Zhu and
                  Mohamed Imoussa{\"{\i}}ne{-}A{\"{\i}}kous and
                  Carolyn C{\^{o}}t{\'{e}}{-}Lussier and
                  Tiago H. Falk},
	title = {On the Impact of Voice Anonymization on Speech Diagnostic Applications:
                  {A} Case Study on {COVID-19} Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5151--5165},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3390990},
	doi = {10.1109/TIFS.2024.3390990},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuICF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With advances seen in deep learning, voice-based applications are burgeoning, ranging from personal assistants, affective computing, to remote disease diagnostics. As the voice contains both linguistic and para-linguistic information (e.g., vocal pitch, intonation, speech rate, loudness), there is growing interest in voice anonymization to preserve speaker privacy and identity. Voice privacy challenges have emerged over the last few years and focus has been placed on removing speaker identity while keeping linguistic content intact. For affective computing and disease monitoring applications, however, the para-linguistic content may be more critical. Unfortunately, the effects that anonymization may have on these systems are still largely unknown. In this paper, we fill this gap and focus on one particular health monitoring application: speech-based COVID-19 diagnosis. We test three anonymization methods and their impact on five different state-of-the-art COVID-19 diagnostic systems using three public datasets. We validate the effectiveness of the anonymization methods, compare their computational complexity, and quantify the impact across different testing scenarios for both within- and across-dataset conditions. Additionally, we provided a comprehensive evaluation of the importance of different speech aspects for diagnostics and showed how they are affected by different types of anonymizers. Lastly, we show the benefits of using anonymized external data as a data augmentation tool to help recover some of the COVID-19 diagnostic accuracy loss seen with anonymization.}
}


@article{DBLP:journals/tifs/ZengXGHZXZ24,
	author = {Zhirui Zeng and
                  Tao Xiang and
                  Shangwei Guo and
                  Jialing He and
                  Qiao Zhang and
                  Guowen Xu and
                  Tianwei Zhang},
	title = {Contrast-Then-Approximate: Analyzing Keyword Leakage of Generative
                  Language Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5166--5180},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3392535},
	doi = {10.1109/TIFS.2024.3392535},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZengXGHZXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There is an increasing tendency to fine-tune large-scale pre-trained language models (LMs) using small private datasets to improve their capability for downstream applications. In this paper, we systematically analyze the pre-train and then fine-tune the process of generative LMs and show that the fine-tuned LMs would leak sensitive keywords of the private datasets even without any prior knowledge of the downstream tasks. Specifically, we propose a novel and efficient keyword inference attack framework to accurately and maximally recover sensitive keywords. Owing to the fine-tuning process, pre-trained and fine-tuned models might respond differently to identical input prefixes. To identify potential sensitive sentences for training the fine-tuend LM, we introduce a contrast difference score that assesses the response variations between a pre-trained LM and its corresponding fine-tuned LM. Following this, we iteratively fine-tune the pre-trained model using these sensitive sentences to minimize the disparity between the target model and the pre-trained model, thereby maximizing the number of inferred sensitive keywords. We implement two types of keyword inference attacks (i.e., domain and private) according to our framework and conduct comprehensive experiments on three downstream applications to evaluate the performance. The experimental results demonstrate that our domain keyword inference attack achieves a precision of 85%, while our private keyword inference attack can extract highly sensitive personal information for a significant number of individuals (approximately 0.3% of all customers in the private fine-tuning dataset, which contains 40,000 pieces of personal information).}
}


@article{DBLP:journals/tifs/XingLYIM24,
	author = {Zheng Xing and
                  Chan{-}Tong Lam and
                  Xiaochen Yuan and
                  Sio Kei Im and
                  Penousal Machado},
	title = {{MMQW:} Multi-Modal Quantum Watermarking Scheme},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5181--5195},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3394768},
	doi = {10.1109/TIFS.2024.3394768},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XingLYIM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To address the problem that existing quantum image watermarking schemes have only a single watermarking mode with weak robustness, in this paper we propose a novel Multi-Modal Quantum Watermarking (MMQW) scheme using the generalized model of novel enhanced quantum representation. Our scheme provides four quantum watermarking modes (G_G, G_C, C_C, C_G), covering both types of grayscale and color images for the watermark and the carrier image. To enhance the robustness, we propose the Block Bit-plane Centrosymmetric Expansion (BBCE) method, which utilizes controlled quantum gates to extend the watermark, making our method resistant to noise and geometric attacks. Moreover, we propose a Brightness-based Watermarking Mechanism (BWM) for embedding and extraction. By uniform embedding, BWM not only minimizes the impact on the carrier image but also reduces the visual distortion of the extracted watermark. In the proposed MMQW, we implement three adaptive embedding strategies using controlled quantum gates, each of which is adaptively triggered according to the corresponding modalities. Detailed quantum circuits for quantum computing are provided. To evaluate imperceptibility and robustness of the MMQW, we conduct experiments using high-resolution images from the USC-SIPI dataset. The results show that PSNR of the watermarked image ranges from 36 dB to 56 dB, indicating the high visual quality. The PSNR of the extracted watermark is about 34 dB when the noise density is 0.05, while the PSNR is higher than 48 dB under common quantum rotation attacks, which indicate the high robustness against noise addition and geometric attacks. In addition, the proposed MMQW can resist to cropping attack with cropping percentage up to 55%. A comprehensive comparison with existing state-of-the-art works shows that our method has significant advantages.}
}


@article{DBLP:journals/tifs/JiangLZ24a,
	author = {Peng Jiang and
                  Qi Liu and
                  Liehuang Zhu},
	title = {Purified Authorization Service With Encrypted Message Moderation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5196--5206},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3393391},
	doi = {10.1109/TIFS.2024.3393391},
	timestamp = {Wed, 04 Sep 2024 21:09:35 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangLZ24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Access control encryption enables access control on both senders and receivers, and enhances message sanitization compared with traditionally cryptographic access control mechanisms. However, it is usually built on top of encrypted messages, which makes it difficult to identify malicious data and amplifies abusive message transmission. Message franking and source tracing mechanisms facilitate a report of abusive messages while support only plain-data moderation in end-to-end encryption. In this work, we present sMAC, a purified access control framework which supports both sanitization and moderation over the encrypted messages. It enables security of the data privacy, sender anonymity and backward security. We instantiate it by proposing a cryptographic primitive named amenable ACE, which expands the message accountability algorithm module in addition to access control encryption. We give formal security proof of amenable ACE in the standard model. The experimental results show that amenable ACE is efficient where computational costs of \\textsf {Decrypt} , \\textsf {Stamp} , \\textsf {Verify} and \\textsf {Inspect} are independent of the message size.}
}


@article{DBLP:journals/tifs/GulK24,
	author = {{\c{C}}agdas G{\"{u}}l and
                  Orhun Kara},
	title = {Correction to "A New Construction Method for Keystream Generators"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4198},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3372200},
	doi = {10.1109/TIFS.2024.3372200},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GulK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The authors would like to extend their apologies for the inadvertent inclusion of an erroneous index of the matrix {M} for DIZY-80 in [1]. We sincerely regret any inconvenience caused by this typographical error and appreciate the chance to rectify it.}
}


@article{DBLP:journals/tifs/XieSZMWLZ24,
	author = {Zhijie Xie and
                  Fan Shi and
                  Min Zhang and
                  Huimin Ma and
                  Huaixi Wang and
                  Zhenhan Li and
                  Yunyi Zhang},
	title = {GuessFuse: Hybrid Password Guessing With Multi-View},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4215--4230},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376246},
	doi = {10.1109/TIFS.2024.3376246},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XieSZMWLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Password guessing is a primary method for password strength evaluation. Despite various password guessing models have been proposed, there is still a significant gap between their guessing effectiveness and the actual cracking capabilities of attackers. Integrating multiple models for password guessing, also known as hybrid password guessing, could better capture the cracking capabilities of real attackers. However, the reason why hybrid password guessing can enhance cracking capabilities, and how to effectively integrate multiple heterogeneous password guessing models, are still not well understood. To address these issues, this paper draws inspiration from the concept of multi-view learning. We regard the guess lists generated by various password guessing models as multiple views of the data. Through a comprehensive analysis of these guess lists, we have identified the key reason why hybrid password guessing can enhance the cracking capabilities: integrating more diverse views allows for the coverage of a wider range of heterogeneous password characteristics, and provides more detailed information on effective password distributions. Based on the findings, we propose a new hybrid password guessing framework, named GuessFuse. GuessFuse employs the multi-view subset extraction module and the segment splitting selection module to accurately extract and reorganize the effective password from diverse guess lists. Experimental results on six large-scale datasets demonstrate the effectiveness of GuessFuse. By combining two (resp. five) guess lists, GuessFuse outperforms its foremost counterparts by an average of 11.00% ~ 59.62% (resp. 4.70% ~ 17.66%) within 107 guesses. GuessFuse can effectively improve the cracking success rate under a limited number of guesses, approaching the actual cracking capabilities of attackers.}
}


@article{DBLP:journals/tifs/ZhangJGLWWZ24,
	author = {Xinxun Zhang and
                  Pengfei Jiao and
                  Mengzhou Gao and
                  Tianpeng Li and
                  Yiming Wu and
                  Huaming Wu and
                  Zhidong Zhao},
	title = {{VGGM:} Variational Graph Gaussian Mixture Model for Unsupervised
                  Change Point Detection in Dynamic Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4272--4284},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3377548},
	doi = {10.1109/TIFS.2024.3377548},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangJGLWWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Change point detection in dynamic networks aims to detect the points of sudden change or abnormal events within the network. It has garnered substantial interest from researchers due to its potential to enhance the stability and reliability of real-world networks. Most change point detection methods are based on statistical characteristics and phased training, and some methods are required to set the percent of change points. Meanwhile, existing methods for change point detection suffer from two limitations. On one hand, they struggle to extract snapshot features that are crucial for accurate change point detection, thereby limiting their overall effectiveness. On the other hand, they are typically tailored for specific network types and lack the versatility to adapt to networks of varying scales. To solve these issues, we propose a novel unified end-to-end framework called Variational Graph Gaussian Mixture model (VGGM) for change point detection in dynamic networks. Specifically, VGGM combines Variational Graph Auto-Encoder (VGAE) and Gaussian Mixture Model (GMM) through joint training, incorporating a Mixture-of-Gaussians prior to model dynamic networks. This approach yields highly effective snapshot embeddings via VGAE and a dedicated readout function, while automating change point detection through GMM. The experimental results, conducted on both real-world and synthetic datasets, clearly demonstrate the superiority of our model in comparison to the current state-of-the-art methods for change point detection.}
}


@article{DBLP:journals/tifs/WeiFJJL24,
	author = {Jiali Wei and
                  Ming Fan and
                  Wenjing Jiao and
                  Wuxia Jin and
                  Ting Liu},
	title = {{BDMMT:} Backdoor Sample Detection for Language Models Through Model
                  Mutation Testing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4285--4300},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376968},
	doi = {10.1109/TIFS.2024.3376968},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WeiFJJL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) and natural language processing (NLP) systems have developed rapidly and have been widely used in various real-world fields. However, they have been shown to be vulnerable to backdoor attacks. Specifically, the adversary injects a backdoor into the model during the training phase, so that input samples with backdoor triggers are classified as the target class. Some attacks have achieved high attack success rates on the pre-trained language models (LMs), but there have yet to be effective defense methods. In this work, we propose a defense method based on deep model mutation testing. Our main justification is that backdoor samples are much more robust than clean samples if we impose random mutations on the LMs and that backdoors are generalizable. We first confirm the effectiveness of model mutation testing in detecting backdoor samples and select the most appropriate number of mutants and mutation operators. We then systematically defend against three extensively studied backdoor attack levels (i.e., char-level, word-level, and sentence-level) by detecting backdoor samples. We also make the first attempt to defend against the latest style-level backdoor attacks. We evaluate our approach on three benchmark datasets (i.e., IMDB, Yelp, and AG news) and three style transfer datasets (i.e., SST-2, Hate-speech, and AG news). The extensive experimental results demonstrate that our approach can detect backdoor samples more efficiently and accurately than the three state-of-the-art defense approaches.}
}


@article{DBLP:journals/tifs/LuZCM24,
	author = {Hai Lu and
                  Yan Zhu and
                  Cecilia E. Chen and
                  Di Ma},
	title = {Toward Efficient Key Extraction of {LBC} Over Ring: Fast Non-Spherical
                  G-Lattice Sampler and Optimized Perturbation Generation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4301--4315},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376206},
	doi = {10.1109/TIFS.2024.3376206},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuZCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the light of the advantages of ring, more and more Lattice-Based Cryptography (LBC) schemes are designed over it to provide small storage cost and high performance. Gaussian Sampler for Lattice Trapdoor (GSLT) plays an important role for these schemes, especially for key extraction. In this paper, we present an efficient GSLT scheme with On-line and Off-line stages. In the On-line stage, we extend the fast non-spherical Gadget-lattice sampling into the ring setting for high performance, and analyze the covariance matrix of output vectors. Subsequently, two optimized perturbation sampling constructions are designed for non-spherical Gadget-lattice sampler to avoid inefficient Cholesky decomposition during Off-line stage. The first construction aims to the spherical Gaussian distribution of preimage vectors, which is beneficial for theoretical analysis. In contrast, the second one is designed on the non-spherical distribution to improve the efficiency of perturbation sampling without leakage of trapdoor in statistic, and we further provide the method how to choose the Gaussian parameters. The complexity analysis and experimental results show that the On-line stage of our scheme has a better performance in comparison with the other works. In the Off-line stage, both of two perturbation sampling constructions can avoid low efficiency of Cholesky decomposition, and are more suitable for the non-spherical G-lattice sampling. In short, our work provides two candidates on either Gaussian parameter or sampling efficiency, thereby offering more options for key generation in LBC schemes.}
}


@article{DBLP:journals/tifs/ZhuSDXH24,
	author = {Xiaojie Zhu and
                  Peisong Shen and
                  Yueyue Dai and
                  Lei Xu and
                  Jiankun Hu},
	title = {Privacy-Preserving and Trusted Keyword Search for Multi-Tenancy Cloud},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4316--4330},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3377549},
	doi = {10.1109/TIFS.2024.3377549},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuSDXH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud service models intrinsically cater to multiple tenants. In current multi-tenancy model, cloud service providers isolate data within a single tenant boundary with no or minimum cross-tenant interaction. With the booming of cloud applications, allowing a user to search across tenants is crucial to utilize stored data more effectively. However, conducting such a search operation is inherently risky, primarily due to privacy concerns. Moreover, existing schemes typically focus on a single tenant and are not well suited to extend support to a multi-tenancy cloud, where each tenant operates independently. In this article, to address the above issue, we provide a privacy-preserving, verifiable, accountable, and parallelizable solution for “privacy-preserving keyword search problem” among multiple independent data owners. We consider a scenario in which each tenant is a data owner and a user’s goal is to efficiently search for granted documents that contain the target keyword among all the data owners. We first propose a verifiable yet accountable keyword searchable encryption (VAKSE) scheme through symmetric bilinear mapping. For verifiability, a message authentication code (MAC) is computed for each associated piece of data. To maintain a consistent size of MAC, the computed MACs undergo an exclusive OR operation. For accountability, we propose a keyword-based accountable token mechanism where the client’s identity is seamlessly embedded without compromising privacy. Furthermore, we introduce the parallel VAKSE scheme, in which the inverted index is partitioned into small segments and all of them can be processed synchronously. We also conduct formal security analysis and comprehensive experiments to demonstrate the data privacy preservation and efficiency of the proposed schemes, respectively.}
}


@article{DBLP:journals/tifs/WenCFCXT24,
	author = {Yun Wen and
                  Gaojie Chen and
                  Sisai Fang and
                  Zheng Chu and
                  Pei Xiao and
                  Rahim Tafazolli},
	title = {STAR-RIS-Assisted-Full-Duplex Jamming Design for Secure Wireless Communications
                  System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4331--4343},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376248},
	doi = {10.1109/TIFS.2024.3376248},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WenCFCXT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical layer security (PLS) technologies are expected to play an important role in the next-generation wireless networks, by providing secure communication to protect critical and sensitive information from illegitimate devices. In this paper, we propose a novel secure communication scheme where the legitimate receiver adopts full-duplex (FD) technology to transmit jamming signals with the assistance of simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) which can operate under the energy splitting (ES) model and the mode switching (MS) model, to interfere with the undesired reception by the eavesdropper. We aim to maximize the secrecy capacity by jointly optimizing the FD beamforming vectors, amplitudes and phase shift coefficients for the ES-RIS, and mode selection and phase shift coefficients for the MS-RIS. With the above optimization, the proposed scheme can concentrate the jamming signals on the eavesdropper while simultaneously eliminating the self-interference (SI) in the desired receiver. To tackle the coupling effect of multiple variables, we propose an alternating optimization algorithm to solve the problem iteratively. Furthermore, we handle the non-convexity of the problem by the the successive convex approximation (SCA) scheme for the beamforming optimizations, amplitudes and phase shifts optimizations for the ES-RIS, as well as the phase shifts optimizations for the MS-RIS. In addition, we adopt a semi-definite relaxation (SDR) and Gaussian randomization process to overcome the difficulty introduced by the binary nature of mode optimization of the MS-RIS. Simulation results validate the performance of our proposed schemes as well as the efficacy of adapting both two types of STAR-RISs in enhancing secure communications when compared to the traditional self-interference cancellation technology.}
}


@article{DBLP:journals/tifs/HongYYL24,
	author = {Sangwoo Hong and
                  Heecheol Yang and
                  Youngseok Yoon and
                  Jungwoo Lee},
	title = {Group-Wise Verifiable Coded Computing Under Byzantine Attacks and
                  Stragglers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4344--4357},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3377929},
	doi = {10.1109/TIFS.2024.3377929},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HongYYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed computing has emerged as a promising solution for accelerating machine learning training processes on large-scale datasets by leveraging the parallel processing capabilities of multiple workers. However, there remain two major issues that still need to be addressed: 1) Byzantine attacks from malicious workers; and 2) the effect of slow workers, commonly referred to as stragglers. In this paper, we address both issues concurrently by introducing Group-wise Verifiable Coded Computing (GVCC), a novel approach that combines coding techniques and group-wise verification to enhance robustness against Byzantine attacks and resilience to straggler effects in distributed computing. The key idea of GVCC is to verify a group of computation results from workers at a time, while providing resilience to stragglers through encoding tasks assigned to workers with Group-wise Verifiable Codes. We evaluate the performance of GVCC through experiments conducted on Amazon EC2 clouds and the results show that GVCC outperforms the existing methods in terms of overall processing time and verification time while maintaining the verification performance. This study highlights the potential of GVCC as an effective solution for overcoming the challenges of Byzantine attacks and stragglers in distributed computing for executing matrix multiplication.}
}


@article{DBLP:journals/tifs/LiYZL24,
	author = {Xue{-}Yang Li and
                  Xue Yang and
                  Zhengchun Zhou and
                  Rongxing Lu},
	title = {Efficiently Achieving Privacy Preservation and Poisoning Attack Resistance
                  in Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4358--4373},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3378006},
	doi = {10.1109/TIFS.2024.3378006},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiYZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning enables clients to train models locally and provide local updates to the server instead of raw dataset, thereby preserving data privacy to some extent. However, adversaries can still pry users’ privacy by inferring updates, and compromise the integrity of the global model through poisoning attack. Therefore, many related works have integrated poisoning attack detection method with secure computation to address both issues. Nevertheless, they still encounter two major challenges: 1) the efficiency is too low to be applied in practice; and 2) the privacy is still at risk of being leaked, e.g., the distance of two local updates for detecting poisoning attack could be exposed to the server. Aiming at the challenges, in this paper, we propose an Efficient Privacy-preserving and Poisoning attack Resistant scheme for Federated Learning, named EPPRFL, which preserves the privacy for local updates and some intermediate information used to detect poisoning attack. In particular, we design an efficient poisoning attack detection method based on Euclidean distance filtering & clipping technique, named F&C. Then, considering the privacy preservation of the F&C method, we efficiently customize secure comparison, secure median, secure distance computation and secure clipping protocols based on additive secret sharing. Experimental results and theoretical analysis show that compared with existing schemes, EPPRFL can better resist poisoning attack and has lower computational and communication overheads on the client side.}
}


@article{DBLP:journals/tifs/JiangLT24,
	author = {Bo Jiang and
                  Ming Li and
                  Ravi Tandon},
	title = {Online Context-Aware Streaming Data Release With Sequence Information
                  Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4390--4405},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3378008},
	doi = {10.1109/TIFS.2024.3378008},
	timestamp = {Sat, 14 Dec 2024 21:39:21 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiangLT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Publishing streaming data in a privacy-preserving manner has been a key research focus for many years. This issue presents considerable challenges, particularly due to the correlations prevalent within the data stream. Existing approaches either fall short in effectively leveraging these correlations, leading to a suboptimal utility-privacy tradeoff, or they involve complex mechanism designs that increase the computation complexity with respect to the sequence length. In this paper, we introduce Sequence Information Privacy (SIP), a new privacy notion designed to guarantee privacy for an entire data stream, taking into account the intrinsic data correlations. We show that SIP provides a similar level of privacy guarantee compared to local differential privacy (LDP), and it also enjoys a lightweight modular mechanism design. We further study two online data release models (instantaneous or batched) and propose corresponding privacy-preserving data perturbation mechanisms. We provide a numerical evaluation of how correlations influence noise addition in data streams. Lastly, we conduct experiments using real-world data to compare the utility-privacy tradeoff offered by our approaches with those from existing literature. The results reveal that our mechanisms achieve better utility-privacy tradeoff than the state-of-the-art LDP-based mechanisms. Notably, the improvements become more significant for small privacy budgets.}
}


@article{DBLP:journals/tifs/YaoWWWRM24,
	author = {Ye Yao and
                  Chen Wang and
                  Hui Wang and
                  Ke Wang and
                  Yizhi Ren and
                  Weizhi Meng},
	title = {Embedding Secret Message in Chinese Characters via Glyph Perturbation
                  and Style Transfer},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4406--4419},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3377903},
	doi = {10.1109/TIFS.2024.3377903},
	timestamp = {Sun, 19 Jan 2025 14:20:40 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YaoWWWRM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Glyph perturbation adjusts the characters’ structures and strokes to make the original characters change subtly, which cannot be detected by the naked eye. These generated variants with different glyph perturbation can represent different status of secret messages, which can be used to embed information in Chinese text documents. However, Chinese characters have characteristics in large numbers, complex structures, and diverse fonts, which limit the generation of glyph perturbation and make the design of Chinese characters time-consuming and laborious. Many font style transfer methods for Chinese characters have been proposed to improve the efficiency of Chinese character generation based on deep learning. At present, there are few studies on efficient font style transfer for glyph perturbation of Chinese characters. In this paper, a stylized glyph perturbation method based on style extractor and attention augmented convolution is proposed. It adopts a multi-head attention mechanism to enhance convolution in the font transfer, which concatenates the convolution feature maps and the self-attention activation maps to weaken the limitations of ordinary convolution in processing images. The extracted style features are sent into the decoder of the font transfer network so as to improve the stylized ability. Particularly, the impact of style extractor and attention augmented convolution on the glyph perturbation generation is addressed. The extraction accuracy and embedding capacity are tested in our experiments. The embedding capacity of secret message can achieve around 1.8 bit/character.}
}


@article{DBLP:journals/tifs/ButoraB24,
	author = {Jan Butora and
                  Patrick Bas},
	title = {Size-Independent Reliable {CNN} for {RJCA} Steganalysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4420--4431},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3379849},
	doi = {10.1109/TIFS.2024.3379849},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ButoraB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detection of image steganography is principally implemented with supervised machine learning detectors. There are two main drawbacks to this approach: the detectors are overly specific to a given image source, and the performance guarantees are only empirical. In this work, we further study a previously proposed deep learning detector that exploits natural image structure imposed by JPEG compression with high quality. We show in a controlled environment that for a fixed JPEG compressor, the soft outputs of a deep learning classifier - the logits - follow a Gaussian distribution. We prove a scaling law stating that the variance of this distribution scales linearly with the image size. By disabling padding in the convolutional neural network, we demonstrate that the mean of the logit distribution does not change, allowing us to directly analyze images of different sizes. Focusing on the logits, we show that we can prescribe a threshold with a theoretical false positive rate for a wide range of image sizes, which is then closely satisfied on real cover images, even for small probabilities such as 10−4. Moreover, the detection power on steganographic images still generalizes to non-adaptive and content-adaptive steganography.}
}


@article{DBLP:journals/tifs/HuLWHZG24,
	author = {Qingqing Hu and
                  Tianrui Lin and
                  Tianjian Wei and
                  Nuo Huang and
                  Yi{-}Jun Zhu and
                  Chen Gong},
	title = {Covert Transmission in Water-to-Air Optical Wireless Communication
                  Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4432--4447},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376965},
	doi = {10.1109/TIFS.2024.3376965},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuLWHZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Covert communications hide the information transmission from a watchful adversary (Willie) while ensuring a satisfactory decoding performance at a legitimate receiver (Bob). In this paper, we propose a covert transmission scheme based on narrow signal waveband and nonlinear suppression effect of avalanche photodiodes (APDs) for water-to-air (W2A) optical wireless communication (OWC) systems. Narrow signal waveband is selected based on a given wavelength selection pattern which is negotiated by the transmitter and receiver. Willie’s detection performance is investigated under APD characteristics and ambient radiation. Under the covertness constraints on Willie’s detection performance, the covert throughput between Alice and Bob is maximized by optimizing the power and blocklength of transmitted signals. Except for the case of Alice with knowledge of Willie’s position and optical filter passband-width, we explore a more practical scenario where the knowledge is not available to Alice. The optimal passband-width of Willie’s filter is calculated by taking into account both overlapped waveband and detection performance, and a covert region is established to limit Willie’s detection range. Numerical and experimental results indicate that strong ambient radiation and narrow signal waveband can enhance the signal covertness significantly.}
}


@article{DBLP:journals/tifs/TianMLZMX24,
	author = {Chuang Tian and
                  Jianfeng Ma and
                  Teng Li and
                  Junwei Zhang and
                  Chengyan Ma and
                  Ning Xi},
	title = {Provably and Physically Secure UAV-Assisted Authentication Protocol
                  for IoT Devices in Unattended Settings},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4448--4463},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3379861},
	doi = {10.1109/TIFS.2024.3379861},
	timestamp = {Thu, 27 Feb 2025 10:24:09 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TianMLZMX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the core subject of IoT applications, IoT devices have faced numerous security challenges. Especially for IoT devices deployed in remote or harsh environments, they are often unattended for long periods, making it difficult to share the sensing data and susceptible to potential physical attacks. While aerial assistance methods represented by unmanned aerial vehicles (UAVs) can solve the problem of data sharing at a low cost, it is necessary to establish a secure channel between ground control stations, UAVs, and IoT devices due to the sensitivity of the sensing data. Recently, Physical Unclonable Function (PUF) has been proven to provide unique identity identification for devices using its tamper-proof feature. In this paper, we propose a lightweight UAV-assisted authentication and key agreement protocol for unattended IoT devices, ensuring secure communication and physical tamper-proof requirements. However, our work does not stop there. We noticed that some existing PUF-based authentication schemes misunderstand the ability of PUF, which leads to these schemes cannot actually provide physical protection. We analyzed the security vulnerabilities of these schemes and proposed rules that should be followed when designing authentication protocols using PUF. In addition, for the first time, we put forward the formal definitions and proof methods for PUF in the formal proof of the security protocol, which avoided the unreasonable initial assumptions adopted in the proof of the existing schemes. We extended Mao-Boyd (MB) logic and comprehensively analyzed the proposed protocol. We also evaluate the performance of the proposed scheme, and the results show that the proposed scheme has certain advantages in communication and computation overhead compared with existing schemes.}
}


@article{DBLP:journals/tifs/WangDCGXZ24,
	author = {Ning Wang and
                  Jixuan Duan and
                  Biwen Chen and
                  Shangwei Guo and
                  Tao Xiang and
                  Kai Zeng},
	title = {Efficient Group Key Generation Based on Satellite Cluster State Information
                  for Drone Swarm},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4464--4479},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3381432},
	doi = {10.1109/TIFS.2024.3381432},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangDCGXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the context of drone swarms, achieving efficient group secure communication is a challenging problem, due to the inherent limitations imposed by the drones’ limited energy and constrained resources. Physical layer group key generation (PLGK) is a promising technology to enable efficient group security communication. However, most existing PLGK schemes struggle to adapt to the dynamic nature of drone swarms. To address this gap, this paper proposes a novel satellite cluster state information (SCSI)-based PLGK, which leverages signal status information from all visible navigation satellites to establish the group key. The presented method utilizes the regional similarity of SCSI as a random information source to generate group keys between different drones, and employs a novel updating framework based on a fuzzy generator and a hash chain to enhance key update and alignment robustness. The proposed scheme not only significantly reduces the overhead of group key generation also mitigates the issues of key loss and reconstruction. The security of the proposed scheme is validated through formal protocol security proof and security analysis against possible attacks. Finally, experiments with real-world drones demonstrate the efficiency and effectiveness of the SCSI-based PLGK.}
}


@article{DBLP:journals/tifs/ArdizzonCTL24,
	author = {Francesco Ardizzon and
                  Laura Crosara and
                  Stefano Tomasin and
                  Nicola Laurenti},
	title = {On Mixing Authenticated and Non-Authenticated Signals Against {GNSS}
                  Spoofing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4480--4493},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3381473},
	doi = {10.1109/TIFS.2024.3381473},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ArdizzonCTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anti-spoofing techniques for current global navigation satellite systems (GNSS) authenticate signals on a single band and from a single system. However, nowadays commercial GNSS receivers commonly calculate the position, velocity, and time (PVT) solution by simultaneously utilizing signals from multiple constellations and bands, with a substantial enhancement in both accuracy and availability. Therefore, anti-spoofing techniques have recently been proposed that mix authenticated and onauthenticated signals to increase performance without sacrificing security. In this paper, we formalize the models of such signal mixture-based authentication checks. We propose a spoofing attack generating a fake signal that leads the victim to a target PVT solution, undetected. We analytically relate the degrees of freedom of the attacker in manipulating the victim’s solution to both the employed security checks and the number of open nonauthenticated signals that can be tampered with by the attacker. The performance of the considered attack strategies are tested on an experimental dataset. Finally, we assess the limits of PVTbased GNSS authentication checks where both authenticated and non-authenticated signals are used.}
}


@article{DBLP:journals/tifs/ZhangL24,
	author = {Zehu Zhang and
                  Yanping Li},
	title = {{NSPFL:} {A} Novel Secure and Privacy-Preserving Federated Learning
                  With Data Integrity Auditing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4494--4506},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3379852},
	doi = {10.1109/TIFS.2024.3379852},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is a new distributed machine learning framework that emerged in recent years, which can protect the participants’ data privacy to a certain extent without exchanging the participants’ original data. Unfortunately, it can still be vulnerable to privacy attacks (e.g. membership inference attacks) or security attacks (e.g. model poisoning attacks), which can compromise participants’ data or corrupt the trained model. Inspired by the existing works, we propose a novel federated learning framework with data integrity auditing called NSPFL. First, NSPFL protects against privacy attacks by using a single mask to hide the participants’ original data. Second, NSPFL constructs a novel reputation evaluation method to resist security attacks by measuring the distance between the previous and current aggregated gradients. Third, NSPFL utilizes the data stored on the cloud to prevent malicious Byzantine participants from denying behaviors. Finally, sufficient theoretical analysis proves the reliability of the scheme, and a large number of experiments demonstrate the effectiveness of the NSPFL.}
}


@article{DBLP:journals/tifs/PengMLWHG24,
	author = {Chunlei Peng and
                  Zimin Miao and
                  Decheng Liu and
                  Nannan Wang and
                  Ruimin Hu and
                  Xinbo Gao},
	title = {Where Deepfakes Gaze at? Spatial-Temporal Gaze Inconsistency Analysis
                  for Video Face Forgery Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4507--4517},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3381823},
	doi = {10.1109/TIFS.2024.3381823},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PengMLWHG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the continuous development of generative models on face generation, how to distinguish the real and fake face has become an important problem for security. Because of the continuous improvement on the detection accuracy by facial physiological signals, video face forgery detection based on facial physiological signal analysis has received more and more attention, which has become an important research branch in the field of face forgery detection. Currently, most of the research on forgery detection based on physiological signal analysis use biometric features such as blinking patterns, head swings, heart rate signals, and lip movements. However, there hasn’t been much exploration on the usage of gaze features in face forgery detection. Through the analysis of gaze directions in face videos, we have observed differences in the distribution of gaze direction pattern between the real and forged videos. Specifically, real videos tend to have more concentrated gaze distribution within a short period of time, while forged videos have more dispersed gaze distributions. In this paper, we present a novel Deepfake gaze analysis method named DFGaze, to explore spatial-temporal gaze inconsistency for video face forgery detection. Our method uses the gaze analysis model (GAM) to analyze the gaze features of face video frames, and then applies a spatial-temporal feature aggregator to realize authenticity classification based on gaze features. In order to better mine the authenticity clues in the videos, we further use the texture analysis model (TAM) and attribute analysis model (AAM) to improve the representation ability of spatial-temporal feature differences between real and forged faces. Extensive experiments show that our method can achieve state-of-the-art performance with the help of gaze analysis. The source code is available at https://github.com/ziminMIAO/DFGaze.}
}


@article{DBLP:journals/tifs/LuoHZWL24,
	author = {Xuejiao Luo and
                  Xiaohui Han and
                  Wenbo Zuo and
                  Xiaoming Wu and
                  Wenyin Liu},
	title = {MLaD{\({^2}\)}: {A} Semi-Supervised Money Laundering Detection Framework
                  Based on Decoupling Training},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4518--4533},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3380262},
	doi = {10.1109/TIFS.2024.3380262},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuoHZWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Money laundering (ML) poses a severe threat to financial stability and social security. Various money laundering detection methods have emerged in the past two decades. Among these methods, some semi-supervised ones based on graph neural networks (GNNs) have achieved impressive performance. However, the homogeneity hypothesis of GNN-based methods does not fit the ML detection scenario, affecting the detection performance. This paper presents a semi-supervised money laundering detection framework based on decoupling training (MLaD2). MLaD2 constructs a transaction relationship network based on node similarity (TRNNS) to model account interactions. Performing on TRNNS, MLaD2 learns the representation of accounts using a GNN. The weighting mechanism of TRNNS can overcome the drawback of the homogeneity hypothesis. Based on the learned account representations, MLaD2 adopts a decoupling training mechanism to build an ML accounts detection model, reducing its dependence on annotated data. The pre-training phase of the decoupling training employs a contrastive self-supervised learning model to learn the intrinsic characteristics of accounts. The fine-tuning phase extracts discriminative features between ML accounts and benign accounts with labeled data. Comprehensive evaluations and comparisons on a real-world ML dataset demonstrate that MLaD2 yields results that surpass existing methods, especially when training with a small scale of labeled samples.}
}


@article{DBLP:journals/tifs/YangCCJLH24,
	author = {Guoyu Yang and
                  Chang Chen and
                  Qi Chen and
                  Jianan Jiang and
                  Jin Li and
                  Debiao He},
	title = {Sweeper: Breaking the Validity-Latency Tradeoff in Asynchronous Common
                  Subset},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4534--4546},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3382602},
	doi = {10.1109/TIFS.2024.3382602},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangCCJLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Asynchronous common subset (ACS) is an essential building block for Byzantine fault-tolerance and multi-party computation. The classic ACS framework is due to Ben-Or, Kemler, and Rabin (BKR), consisting of {n} reliable broadcast (RBC) instances and {n} asynchronous binary agreement (ABA) instances (where {n} is the total number of replicas). Despite recent progresses of practical BKR-ACS, the state-of-the-art designs are still trapped by a validity-latency tradeoff. In this paper, we propose Sweeper, a new ACS protocol that breaks the tradeoff, achieving optimal validity and latency. Moreover, Sweeper maintains other benefits including optimal resilience, signature-free, and information-theoretic settings. Sweeper is built on RBC and composable biased reproposable ABA (CBiased RABA). Different from the conventional RABA, CBiased RABA allows replicas to be more biased towards specific RABA instances. We provide generic strategies to transform existing ABA/RABA protocols and a new RABA protocol that we introduce, to CBiased RABA. Furthermore, Sweeper can achieve up to 2 \\times the throughput of PACE-ACS (CCS 2022), the state-of-the-art ACS protocol that follows the BKR-ACS framework.}
}


@article{DBLP:journals/tifs/JiaLGBC24,
	author = {Xiaojun Jia and
                  Jianshu Li and
                  Jindong Gu and
                  Yang Bai and
                  Xiaochun Cao},
	title = {Fast Propagation Is Better: Accelerating Single-Step Adversarial Training
                  via Sampling Subnetworks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4547--4559},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3377004},
	doi = {10.1109/TIFS.2024.3377004},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiaLGBC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial training has shown promise in building robust models against adversarial examples. A major drawback of adversarial training is the computational overhead introduced by the generation of adversarial examples. To overcome this limitation, adversarial training based on single-step attacks has been explored. Previous work improves the single-step adversarial training from different perspectives, e.g., sample initialization, loss regularization, and training strategy. Almost all of them treat the underlying model as a black box. In this work, we propose to exploit the interior building blocks of the model to improve efficiency. Specifically, we propose to dynamically sample lightweight subnetworks as a surrogate model during training. By doing this, both the forward and backward passes can be accelerated for efficient adversarial training. Besides, we provide theoretical analysis to show the model robustness can be improved by the single-step adversarial training with sampled subnetworks. Furthermore, we propose a novel sampling strategy where the sampling varies from layer to layer and from iteration to iteration. Compared with previous methods, our method not only reduces the training cost but also achieves better model robustness. Evaluations on a series of popular datasets demonstrate the effectiveness of the proposed FB-Better. Our code has been released at https://github.com/jiaxiaojunQAQ/ FP-Better.}
}


@article{DBLP:journals/tifs/XunJGLGC24,
	author = {Yuan Xun and
                  Xiaojun Jia and
                  Jindong Gu and
                  Xinwei Liu and
                  Qing Guo and
                  Xiaochun Cao},
	title = {Minimalism is King! High-Frequency Energy-Based Screening for Data-Efficient
                  Backdoor Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4560--4571},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3380821},
	doi = {10.1109/TIFS.2024.3380821},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XunJGLGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the effectiveness of deep neural networks in various fields, the security of neural networks has received great attention. The backdoor attack, which induces malicious behaviors of models by poisoning part of the training set, still remains a challenging problem. Many recent efforts have proposed different ways of embedding backdoors to improve the stealthiness of backdoor attacks. Yet, lowering the percentage of poisoned samples is one of the most direct ways to increase stealthiness. A recent study (Filtering-and-Updating strategy, FUS) has revealed that the sample selection for poisoning is also crucial, as different samples contribute differently to the final decision boundary of the network. Concretely, they utilize each sample’s forgetting events during the training stage to identify which samples will contribute more to the network’s prediction. The training phase of their search method, however, is computationally expensive and slow. To overcome this, in this paper, we propose an efficient sample selection strategy based on the high-frequency energy (HFE) of training samples with a global screening and updating strategy, which can not only achieve a higher backdoor-attack success rate but also reduce the searching time by a factor of 4320 compared to FUS (12 hours vs 10 seconds). The extensive experiment results on CIFAR-10, CIFAR-100, and ImageNet-10 have shown that our proposed method is much simpler, faster, and more efficient.}
}


@article{DBLP:journals/tifs/WangHJGC24,
	author = {Lipeng Wang and
                  Mingsheng Hu and
                  Zhijuan Jia and
                  Zhi Guan and
                  Zhong Chen},
	title = {SStore: An Efficient and Secure Provable Data Auditing Platform for
                  Cloud},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4572--4584},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3383772},
	doi = {10.1109/TIFS.2024.3383772},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangHJGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As more internet users opt to store their data in cloud storage, ensuring data integrity becomes a paramount concern. The emerging provable data possession (PDP) scheme enables auditors to verify data integrity with reduced bandwidth consumption compared to hash-based alternatives. Nevertheless, most existing PDP variants rely on a centralized node for generating or maintaining user keys, creating a potential single point of failure. Moreover, previous PDP schemes could only detect whether challenged data blocks were corrupted, lacking the ability to pinpoint affected blocks precisely. To tackle these challenges, we propose a novel PDP scheme that eliminates the necessity for a key management center and supports the localization of corrupted data blocks. In our scheme, users no longer need to retain private keys once they cease performing data dynamic operations, thus liberating them from reliance on external entities for key maintenance. Moreover, the new scheme utilizes existing authenticators in the cloud to identify corrupted file blocks, eliminating the necessity of storing hash values for these data blocks as seen in most of existing implementations. This effectively reduces required storage space. Furthermore, we introduce SStore, a decentralized cloud storage platform that incorporates the new PDP scheme to verify data integrity. SStore facilitates public auditing of user data, thereby enhancing transparency in the data verification procedure. Moreover, SStore leverages basic algebraic operations for data auditing, significantly increasing its efficiency. We analyze the security of the new PDP scheme, and evaluate the performance of both the PDP scheme and SStore to demonstrate their efficiency.}
}


@article{DBLP:journals/tifs/CaoYNJLLZ24,
	author = {Xuelian Cao and
                  Zheng Yang and
                  Jianting Ning and
                  Chenglu Jin and
                  Rongxing Lu and
                  Zhiming Liu and
                  Jianying Zhou},
	title = {Dynamic Group Time-Based One-Time Passwords},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4897--4913},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3386350},
	doi = {10.1109/TIFS.2024.3386350},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CaoYNJLLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Group time-based one-time passwords (GTOTP) is a novel lightweight cryptographic primitive for achieving anonymous client authentication, which enables the efficient generation of time-based one-time passwords on behalf of a group without revealing any information about the actual client’s identity beyond their group membership. The security properties of GTOTP regarding anonymity and traceability have been formulated in a static group management setting (where all group members should be determined during the group initialization phase), yet, a formal treatment for real-world dynamic groups (i.e., group members may join and leave at any time) is still an open question. It is non-trivial to construct an efficient GTOTP scheme that can provide a lightweight password generation procedure run by group members and support dynamic group management, allowing group members to join and leave without affecting other members’ states (non-disruptively). To address the above challenge, we first define the notion and the security model of dynamic group time-based one-time passwords (DGTOTP) in this work. We then present an efficient DGTOTP construction that can generically transform an asymmetric time-based one-time passwords scheme into a DGTOTP scheme utilizing a chameleon hash function family and a Merkle tree scheme. Within our construction, we particularly tailor an outsourcing solution realizing an issue-first-and-join-later (IFJL) strategy, enabling smooth joining and revocation without disrupting other group members. Moreover, our scheme minimizes symmetric cryptographic operations and maintains constant storage for group members, compared to the linear storage cost that grows rapidly with respect to the lifetime of the GTOTP instance in the previous static GTOTP scheme. Our DGTOTP scheme satisfies stronger security guarantees in a dynamic group management setting without random oracles. Our experimental results confirm the efficiency of our DGTOTP scheme.}
}


@article{DBLP:journals/tifs/ZhaiWLQDGS24,
	author = {Mingzhe Zhai and
                  Qianhong Wu and
                  Yizhong Liu and
                  Bo Qin and
                  Xiaopeng Dai and
                  Qiyuan Gao and
                  Willy Susilo},
	title = {Secret Multiple Leaders {\&} Committee Election With Application
                  to Sharding Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5060--5074},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3390584},
	doi = {10.1109/TIFS.2024.3390584},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaiWLQDGS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secret leader election in consensus could protect leaders from Denial of Service (DoS) or bribery attacks, enhancing the blockchain system security. Single Secret Leader Election (SSLE), proposed by Boneh et al., supports electing a single random leader from a group of nodes while the leader’s identity remains secret until he reveals himself. Subsequent research endeavors have introduced distinct approaches to realize SSLE, yet most of these solutions consume relatively high communication complexity. In this paper, we propose an extended SSLE scheme, Secret Multiple Leaders Election (SMLE), based on linkable membership proof. A general SMLE scheme supports the one-time election of multiple consecutive secret leaders while reducing the average communication cost of a single leader election to constant complexity. In particular, SMLE is proven to satisfy a newly proposed consistent unpredictability property for each leader. Specifically, two concrete SMLE constructions are constructed. The first construction is designed for non-interactive scenarios where pre-configured system nodes are not required. The second one is designed for interactive scenarios where nodes operate within a committee. Furthermore, we extend SMLE to Secret Committee Election (SCE) and realize the anonymous node allocation in sharding blockchains utilizing SCE, thereby significantly enhancing the security of the sharding system. Finally, the experimental results indicate that our constructions exhibit minimal communication and computational overhead. When integrated into sharding systems, our protocol could increase an adversary’s attack difficulty, with the enhancement proportion approximately equal to the shard number.}
}


@article{DBLP:journals/tifs/XiaoXZWY24,
	author = {Peng Xiao and
                  Qibin Xiao and
                  Xusheng Zhang and
                  Yumei Wu and
                  Fengyu Yang},
	title = {Vulnerability Detection Based on Enhanced Graph Representation Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5120--5135},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3392536},
	doi = {10.1109/TIFS.2024.3392536},
	timestamp = {Fri, 17 May 2024 21:40:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XiaoXZWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The detection of program vulnerabilities remains a challenging task in software security. The existing vulnerability detection methods rarely consider the multidimensional feature space complementarity of program graph structures, which easily overlooks contextual environment features and syntax structure features. This disadvantage leads to insufficient performance in capturing complex structural features, which hinders the improvement in detection accuracy. To address this issue, this paper introduces a novel vulnerability detection method, EnGS2F, which adopts the representation learning of an enhanced graph structure to improve the efficiency of capturing vulnerability information. On the dimension of the graph structure, a context relationship graph (CRG) is integrated on the basis of a program dependency graph (PDG) to enrich the global structural context representation. On the dimension of graph nodes, abstract syntax tree (AST) embedding and paragraph embedding are integrated to solve the problem of insufficient feature space complementarity. Moreover, the combination of a gated graph neural network (GGNN) with a graph attention mechanism further improves the learning performance of the enhanced graph structure. EnGS2F has been rigorously evaluated on program slices from open-source vulnerability datasets, demonstrating significant improvements over current competitive methods in detecting program vulnerabilities. Specifically, EnGS2F achieved a significant increase in the F1 score, outperforming existing technologies by 6%.}
}


@article{DBLP:journals/tifs/BitarEWX24,
	author = {Rawad Bitar and
                  Maximilian Egger and
                  Antonia Wachter{-}Zeh and
                  Marvin Xhemrishi},
	title = {Sparsity and Privacy in Secret Sharing: {A} Fundamental Trade-Off},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5136--5150},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3394256},
	doi = {10.1109/TIFS.2024.3394256},
	timestamp = {Sat, 08 Jun 2024 13:14:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BitarEWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work investigates the design of sparse secret sharing schemes that encode a sparse private matrix into sparse shares. This investigation is motivated by distributed computing, where the multiplication of sparse and private matrices is moved from a computationally weak main node to untrusted worker machines. Classical secret-sharing schemes produce dense shares. However, sparsity can help speed up the computation. We show that, for matrices with i.i.d. entries, sparsity in the shares comes at a fundamental cost of weaker privacy. We derive a fundamental tradeoff between sparsity and privacy and construct optimal sparse secret sharing schemes that produce shares that leak the minimum amount of information for a desired sparsity of the shares. We apply our schemes to distributed sparse and private matrix multiplication schemes with no colluding workers while tolerating stragglers. For the setting of two non-communicating clusters of workers, we design a sparse one-time pad so that no private information is leaked to a cluster of untrusted and colluding workers, and the shares with bounded but non-zero leakage are assigned to a cluster of partially trusted workers. We conclude by discussing the necessity of using permutations for matrices with correlated entries.}
}


@article{DBLP:journals/tifs/LiuZZCZL24,
	author = {Renyang Liu and
                  Wei Zhou and
                  Tianwei Zhang and
                  Kangjie Chen and
                  Jun Zhao and
                  Kwok{-}Yan Lam},
	title = {Boosting Black-Box Attack to Deep Neural Networks With Conditional
                  Diffusion Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5207--5219},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3390609},
	doi = {10.1109/TIFS.2024.3390609},
	timestamp = {Thu, 26 Sep 2024 15:34:35 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuZZCZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing black-box attacks have demonstrated promising potential in creating adversarial examples (AE) to deceive deep learning models. Most of these attacks need to handle a vast optimization space and require a large number of queries, hence exhibiting limited practical impacts in real-world scenarios. In this paper, we propose a novel black-box attack strategy, Conditional Diffusion Model Attack (CDMA), to improve the query efficiency of generating AEs under query-limited situations. The key insight of CDMA is to formulate the task of AE synthesis as a distribution transformation problem, i.e., benign examples and their corresponding AEs can be regarded as coming from two distinctive distributions and can transform from each other with a particular converter. Unlike the conventional query-and-optimization approach, we generate eligible AEs with direct conditional transform using the aforementioned data converter, which can significantly reduce the number of queries needed. CDMA adopts the conditional Denoising Diffusion Probabilistic Model as the converter, which can learn the transformation from clean samples to AEs, and ensure the smooth development of perturbed noise resistant to various defense strategies. We demonstrate the effectiveness and efficiency of CDMA by comparing it with nine state-of-the-art black-box attacks across three benchmark datasets. On average, CDMA can reduce the query count to a handful of times; in most cases, the query count is only ONE. We also show that CDMA can obtain >99% attack success rate for untargeted attacks over all datasets and targeted attack over CIFAR-10 with the noise budget of \\epsilon =16\n.}
}


@article{DBLP:journals/tifs/NamCLJY24,
	author = {Taesik Nam and
                  Dong{-}Hoon Choi and
                  Euibum Lee and
                  Han{-}Shin Jo and
                  Jong{-}Gwan Yook},
	title = {Data Generation and Augmentation Method for Deep Learning-Based {VDU}
                  Leakage Signal Restoration Algorithm},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5220--5234},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3393748},
	doi = {10.1109/TIFS.2024.3393748},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NamCLJY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study analyzes the phenomenon of electromagnetic (EM) leakage that occurs through cables and explores the potential for information forensics using deep learning-based image-processing algorithms. We focus on the transition-minimized differential signaling (TMDS) interface to analyze information leakage caused by the inherent differential signal synchronization errors in video graphics controllers (VGC). Our analysis includes detailed mathematical modeling of the EM leakage phenomena from the video display unit (VDU) interface that uses the TMDS protocol. Furthermore, this study presents mathematical models for distortions and alterations caused by the VDU characteristics and its associated RF front-end system. Utilizing mathematical models of EM phenomena, this paper presents a method for creating training datasets for deep learning-based signal processing algorithms by generating and augmenting pseudo leakage signals (PLS) that closely resemble actual leakage signals. This study confirms the practical utility of signal enhancement models trained with generated and augmented PLS in real-world scenarios. Validation involves applying the trained model to measured actual VDU leakage signals and evaluating the results using image quality metrics: peak signal-to-noise ratio (PSNR), signal-to-noise ratio (SNR), and the structural similarity index measure (SSIM). Ultimately, this study demonstrates the potential to develop deep learning models using theoretically generated PLS for VDU-targeted side-channel attacks, where collecting real training data poses a challenge. This suggests the potential for expanding into high-performance deep learning algorithms in future developments.}
}


@article{DBLP:journals/tifs/LiY24,
	author = {Pengyu Li and
                  Dan Ye},
	title = {Vulnerability Analysis of Distributed State Estimator Under False
                  Data Injection Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5235--5244},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3396634},
	doi = {10.1109/TIFS.2024.3396634},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper focuses on the vulnerability and strict vulnerability of distributed state estimators under false data injection (FDI) attacks, where adversaries aim to exert unbounded effects on the estimation error dynamics by injecting malicious data into sensor nodes, communication links, or both. In particular, a distributed system is characterized as vulnerable (or strictly vulnerable) if there exists an unbounded FDI attack that leads to bounded changes (or no changes) in residuals. By utilizing invertibility theory and carefully designed attack sequences, we establish the conditions for systems to be (strictly) vulnerable, based on different attack scenarios. Additionally, we provide a comparative analysis to evaluate the varying impact of different attacks on system security. Finally, a three-area grid system model is presented to illustrate the validity of the theoretical results.}
}


@article{DBLP:journals/tifs/TangDXJSW24,
	author = {Peng Tang and
                  Guoru Ding and
                  Yitao Xu and
                  Yutao Jiao and
                  Yehui Song and
                  Guofeng Wei},
	title = {Causal Learning for Robust Specific Emitter Identification Over Unknown
                  Channel Statistics},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5316--5329},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3393237},
	doi = {10.1109/TIFS.2024.3393237},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TangDXJSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Specific emitter identification (SEI) is a device identification technology that extracts radio frequency (RF) fingerprint from received signals. However, channel effects on RF fingerprint can vary between the training and testing stage, and SEI based on deep learning (DL) will be unable to withstand channel changes. To address this problem, we propose a channel-robust SEI scheme driven by causal learning. We analyze received signals from the causal perspective and construct a structural causal model (SCM) of SEI. In the SCM, received signals are considered as mixtures of the causal element and interference element, and only the former affects identification. Additionally, we design a new RF fingerprint feature representation called the centralized logarithmic power spectrum (CLPS) to reduce the impact of channel effects. Furthermore, we propose a causal purification network (CPNet) driven by causality to further alleviate channel effects. CPNet weakens the spurious associations between the channel and emitter labels through feature decorrelation and feature purification, strengthens the correlation between RF fingerprint and labels, and improves the generalization of SEI. Finally, our approach is evaluated extensively using 20 ZigBee devices under different channel environments. Experimental results demonstrate that our scheme can effectively alleviate channel effects, improve SEI performance under various channel environments, and exhibit good generalization and stability.}
}


@article{DBLP:journals/tifs/GuanWDP24,
	author = {Weinan Guan and
                  Wei Wang and
                  Jing Dong and
                  Bo Peng},
	title = {Improving Generalization of Deepfake Detectors by Imposing Gradient
                  Regularization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5345--5356},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3396064},
	doi = {10.1109/TIFS.2024.3396064},
	timestamp = {Fri, 17 May 2024 21:40:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GuanWDP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of face forgery technology has posed a significant threat to information security. While deepfake detection has proven to be an effective countermeasure, it often struggles to detect fake images generated by unknown forgery methods. Thus, the generalization ability of deepfake detectors to unseen forgery data is a critical concern. Despite many efforts aimed at discovering new forgery artifacts, they often fail to generalize to new manipulation technologies. In this paper, we tackle this challenge by focusing on the difference in texture patterns between training forgeries and unseen forgeries, which can lead to a degradation of generalization. Based on this principle, we propose a new conjecture that encourages deepfake detectors to reduce their sensitivity to forgery texture patterns, thereby improving the detection performance. To this end, we introduce an additional gradient regularization term to the original empirical loss during training. However, computing the Hessian matrix in the gradient calculation process of the regularization term poses a computational complexity. In order to overcome this issue, we optimize the formulation of the gradient regularization term using a first-order approximation method based on Taylor expansion and design a Perturbation Injection Module (PIM) to simplify the implementation process. Additionally, we provide a theoretical analysis from an optimization perspective and explore an interesting aspect of our method. Extensive experiments demonstrate the effectiveness of our approach in improving the generalization ability of deepfake detectors. Importantly, our method is orthogonal to recent advancements in powerful backbones and training data augmentation techniques. When combined with other effective techniques, our method achieves state-of-the-art experimental results.}
}


@article{DBLP:journals/tifs/MoltafetSR24,
	author = {Mohammad Moltafet and
                  Hamid R. Sadjadpour and
                  Zouheir Rezki},
	title = {On the Semantic Security in the General Bounded Storage Model: {A}
                  New Proof},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {4263--4271},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3376959},
	doi = {10.1109/TIFS.2024.3376959},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MoltafetSR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the bounded storage model introduced by Maurer, the adversary is computationally unbounded and has a bounded storage capacity. In this model, information-theoretic secrecy is guaranteed by using a publicly available random string whose length is larger than the adversary storage capacity. The protocol proposed by Maurer is simple, from the perspective of implementation, and efficient, from the perspective of the initial secret key size and random string length. However, he provided the proof of the security for the case where the adversary can access a constant fraction of the random string and store only original bits of the random string. In this paper, we provide a new proof of the security of the protocol proposed by Maurer for the general bounded storage model, i.e., the adversary can access all bits of the random string, and store the output of any Boolean function on the string. We reaffirm that the protocol is absolutely semantically secure in the general bounded storage model.}
}


@article{DBLP:journals/tifs/ZhangWQWOASG24,
	author = {Xixi Zhang and
                  Qin Wang and
                  Maoyang Qin and
                  Yu Wang and
                  Tomoaki Ohtsuki and
                  Bamidele Adebisi and
                  Hikmet Sari and
                  Guan Gui},
	title = {Enhanced Few-Shot Malware Traffic Classification via Integrating Knowledge
                  Transfer With Neural Architecture Search},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5245--5256},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3396624},
	doi = {10.1109/TIFS.2024.3396624},
	timestamp = {Sun, 19 Jan 2025 14:20:44 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangWQWOASG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware traffic classification (MTC) is one of the important research topics in the field of cyber security. Existing MTC methods based on deep learning have been developed based on the assumption of enough high-quality samples and powerful computing resources. However, both are hard to obtain in real applications especially in availability of IoT. In this paper, we propose a few-shot MTC (FS-MTC) method combining knowledge transfer and neural architecture search (i.e. NAS-based FS-MTC) with limited training samples as well as acceptable computational resources, in order to mitigate the identified challenges. Specifically, our proposed method first converts the raw network traffic into traffic images through data pre-processing to serve as input data for the neural network. Second, we use neural architecture search to adaptively search for the effective feature extraction model on the source domain (including Edge-IIoTset, Bot-IoT, and benign USTC-TFC2016). Third, the searched model is pre-trained on source task to achieve the generic feature representation of malware traffic. Finally, we only use few-shot malware traffic samples to fine-tune the pre-trained model to quickly adapt to new types of MTC tasks in realistic network environments. The experimental results show that the proposed NAS-based FS-MTC method has great scalability and classification performance in different FS-MTC tasks, including 5-way K-shot USTC-TFC2016 dataset and 10-way K-shot CIC-IoT dataset. Compared with state-of-the-art methods in the field of malware classification, the proposed NAS-based FS-MTC has higher classification accuracy. Especially in the 1-shot case of the USTC-TFC2016 dataset, its average accuracy is as high as 86.91%.}
}


@article{DBLP:journals/tifs/AlyIYM24,
	author = {Ahmed Aly and
                  Shahrear Iqbal and
                  Amr M. Youssef and
                  Essam Mansour},
	title = {{MEGR-APT:} {A} Memory-Efficient {APT} Hunting System Based on Attack
                  Representation Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5257--5271},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3396390},
	doi = {10.1109/TIFS.2024.3396390},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AlyIYM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The stealthy and persistent nature of Advanced Persistent Threats (APTs) makes them one of the most challenging cyber threats to uncover. Several systems adopted the development of provenance-graph-based security solutions to capture this persistent nature. Provenance graphs (PGs) represent system audit logs by connecting system entities using causal relations and information flows. Hunting APTs demands the processing of ever-growing large-scale PGs of audit logs for a wide range of activities over months or years, i.e., multi-terabyte graphs. Existing APT hunting systems are typically memory-based, which suffers colossal memory consumption, or disk-based, which suffers from performance hits. Therefore, these systems are hard to scale in terms of graph size or time performance. In this paper, we propose MEGR-APT, a scalable APT hunting system to discover suspicious subgraphs matching an attack scenario (query graph) published in Cyber Threat Intelligence (CTI) reports. MEGR-APT hunts APTs in a twofold process: (i) memory-efficient extraction of suspicious subgraphs as search queries over a graph database, and (ii) fast subgraph matching based on graph neural network (GNN) and our effective attack representation learning. We compared MEGR-APT with state-of-the-art (SOTA) APT systems using popular APT benchmarks, such as DARPA TC3 and OpTC. We also tested it using a real enterprise dataset. MEGR-APT achieves an order of magnitude reduction in memory consumption while achieving comparable performance to SOTA in terms of time and accuracy.}
}


@article{DBLP:journals/tifs/ZhangLZZGWSL24,
	author = {Songnian Zhang and
                  Rongxing Lu and
                  Hui Zhu and
                  Yandong Zheng and
                  Yunguo Guan and
                  Fengwei Wang and
                  Jun Shao and
                  Hui Li},
	title = {Performance Enhanced Secure Spatial Keyword Similarity Query With
                  Arbitrary Spatial Ranges},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5272--5285},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3396384},
	doi = {10.1109/TIFS.2024.3396384},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLZZGWSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing prevalence of cloud computing drives the exploration of various secure query schemes over encrypted data, among which secure spatial keyword query has drawn a great deal of attention due to its broad application in location-based services. However, most existing schemes are either limited to the boolean keyword test or incapable of protecting access pattern privacy. Although the state-of-the-art secure spatial keyword query scheme can support keyword similarity while preserving access pattern privacy, it is unable to cope with the arbitrary spatial range, which is more general, and has limitations in efficiency and security. In this paper, we propose a new secure spatial keyword similarity query scheme that can support arbitrary spatial ranges and enhance the efficiency and security of the state-of-the-art scheme at the same time. Specifically, we first present a new homomorphic encryption technique by improving the popular symmetric homomorphic encryption (SHE). After that, we propose a novel approach to make supporting arbitrary spatial ranges over encrypted data possible, in which a spatial encoding technique is designed to improve performance. Finally, by designing a pack-based solution to protect access pattern privacy, our proposed scheme can hide the number of query results while optimizing performance. We formally prove the security of our proposed scheme and conduct experiments to evaluate its performance. The results indicate that our proposed scheme outperforms the state-of-the-art scheme in both the computational costs and communication overhead.}
}


@article{DBLP:journals/tifs/LiWLCZ24a,
	author = {Zhankai Li and
                  Weiping Wang and
                  Jie Li and
                  Kai Chen and
                  Shigeng Zhang},
	title = {Foolmix: Strengthen the Transferability of Adversarial Examples by
                  Dual-Blending and Direction Update Strategy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5286--5300},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3393745},
	doi = {10.1109/TIFS.2024.3393745},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiWLCZ24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial example attacks are deemed to be a serious threat to deep neural network (DNN) models. Generating adversarial examples in white-box settings has been well-studied, however, it remains challenging to generate transferable adversarial examples that successfully attack black-box models. This work proposes Foolmix, a novel method for generating transferable adversarial examples for black-box attacks. The design of Foolmix is inspired by our observation that adversarial examples with high transferability usually carry multi-class features in the latent space of DNN models. Thus, we propose a dual-blending strategy that blends the image with a set of random pixel-blocks and blends the gradient by calculating the loss of the blended image for both the ground-truth label and a set of random labels. The dual-blending strategy pressures the example to penetrate multiple class regions and gain multi-class features in the latent space, greatly enhancing the transferability of the generated adversarial example. However, the randomness in the blending process might also pressure the example to approach the boundary of the original class region, which lowers the robustness of the example. To mitigate this problem, we further propose an update method in the starting forward direction to guide the generated adversarial example to go deep into multi-class adversarial regions while being globally far away from the original class region. Compared to state-of-the-art transformation-based attacks, Foolmix significantly enhances the transferability of generated adversarial examples, boosting the average transferable attack success rate by 13.2% and 16.9% on mainstream CNNs and ViTs respectively, while achieving better defense breakthrough ability.}
}


@article{DBLP:journals/tifs/KongC24,
	author = {Ruiqi Kong and
                  He Henry Chen},
	title = {{CSI-RFF:} Leveraging Micro-Signals on {CSI} for {RF} Fingerprinting
                  of Commodity WiFi},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5301--5315},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3396375},
	doi = {10.1109/TIFS.2024.3396375},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KongC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces CSI-RFF, a new framework that leverages micro-signals embedded within Channel State Information (CSI) curves to realize Radio-Frequency Fingerprinting of commodity off-the-shelf (COTS) WiFi devices for open-set authentication. The micro-signals that serve as RF fingerprints are termed “micro-CSI”. Through experimentation, we have found that the presence of micro-CSI can primarily be attributed to imperfections in the RF circuitry. Furthermore, this characteristic signal is detectable in WiFi 4/5/6 network interface cards (NICs). We have conducted further experiments to determine the most effective CSI collection configurations to stabilize micro-CSI. Yet, extracting micro-CSI for authentication purposes poses a significant challenge. This complexity arises from the fact that CSI measurements inherently include both micro-CSI and the distortions introduced by wireless channels. These two elements are intricately intertwined, making their separation non-trivial. To tackle this challenge, we have developed a signal space-based extraction technique for line-of-sight (LoS) scenarios, which can effectively separate the distortions caused by wireless channels and micro-CSI. Over the course of our comprehensive CSI data collection period extending beyond one year, we found that the extracted micro-CSI displays unique characteristics specific to each WiFi device and remains invariant over time. This establishes micro-CSI as a suitable candidate for device fingerprinting. Finally, we conduct a case study focusing on area access control for mobile robots. In particular, we applied our CSI-RFF framework to identify mobile robots operating in real-world indoor LoS environments based on their transmitted WiFi signals. To accomplish this, we have compared and employed anomaly detection algorithms for the authentication of 15 COTS WiFi 4/5/6 NICs that were carried by a mobile robot under both static and mobile conditions, maintaining an average signal-to-noise ratio (SNR) of 34 dB. Our experimental results demonstrate that the micro-CSI-based authentication algorithm can achieve an average attack detection rate close to 99% with a false alarm rate of 0% in both static and mobile conditions when using 20 CSI measurements to construct one fingerprint.}
}


@article{DBLP:journals/tifs/XuCCHQ24,
	author = {Gehui Xu and
                  Guanpu Chen and
                  Zhaoyang Cheng and
                  Yiguang Hong and
                  Hongsheng Qi},
	title = {Consistency of Stackelberg and Nash Equilibria in Three-Player Leader-Follower
                  Games},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5330--5344},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3397196},
	doi = {10.1109/TIFS.2024.3397196},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuCCHQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There has been significant recent interest in a class of three-player leader-follower game models in many important cybersecurity scenarios. In such a tri-level hierarchical structure, a defender usually serves as a leader, dominating the decision process by the Stackelberg equilibrium (SE) strategy. However, such a leader-follower scheme may not always work, and the Nash equilibrium (NE) strategy may provide an alternative choice. Thus, we need to reveal the consistency between SE and NE in the three-player model to help the leader evaluate its strategy impact and avoid a choice dilemma. To this end, we first provide a necessary and sufficient condition such that each SE is an NE, which not only provides access to seek a satisfactory SE but also makes a criterion for an obtained SE. Then, we apply the results for case studies with a unique SE or with at least one SE being an NE. Moreover, when the consistency condition falls short, we give an upper bound of the deviation between SE and NE to help the leader tolerably adopt an SE strategy. Finally, we apply our consistency analysis to practical scenarios, including secure wireless transmission and advanced persistent threat defense.}
}


@article{DBLP:journals/tifs/XiaoZHXW24,
	author = {Xiangli Xiao and
                  Yushu Zhang and
                  Zhongyun Hua and
                  Zhihua Xia and
                  Jian Weng},
	title = {Client-Side Embedding of Screen-Shooting Resilient Image Watermarking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5357--5372},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3397043},
	doi = {10.1109/TIFS.2024.3397043},
	timestamp = {Tue, 08 Oct 2024 15:40:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XiaoZHXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of portable camera devices, represented by smartphones, is increasing the risk of sensitive internal data being leaked by screen shooting. To trace the leak source, a lot of research has been done on screen-shooting resilient watermarking technique, which is capable of extracting the previously embedded watermark from the screen-shot image. However, all existing screen-shooting resilient watermarking schemes follow the owner-side embedding mode. In this mode, the management center will suffer heavy computational and communication burden in the case of numerous screens, which hinders the system scalability. As another embedding mode of digital watermarking, client-side embedding can solve the above scalability problem by migrating the watermark embedding operation to the same time when the screen decrypts the image. By designing a pair of image encryption and personalized decryption algorithms based on matrix operation, this paper is the first to realize the client-side embedding of screen-shooting resilient watermarking. In this implementation, challenges are overcome and the following key achievements are attained. First, our scheme embeds watermark using the algorithm of Fang et al. without modification, and thus fully inherits its robustness against screen shooting. Second, the original image is securely encrypted and the watermarked image can be directly retrieved through decryption. Third, the secrecy of the screen watermark is ensured by concealing the embedding pattern. Finally, our scheme is validated by experiments, which shows that the efficiency advantage of client-side embedding is realized while maintaining robustness.}
}


@article{DBLP:journals/tifs/LuCZCD24,
	author = {Tianyu Lu and
                  Liquan Chen and
                  Junqing Zhang and
                  Chen Chen and
                  Trung Q. Duong},
	title = {Reconfigurable Intelligent Surface-Assisted Key Generation for Millimeter-Wave
                  Multi-User Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5373--5388},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3397037},
	doi = {10.1109/TIFS.2024.3397037},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuCZCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical layer key generation (PLKG) leverages wireless channels to produce secret keys for legitimate users. However, in millimetre-wave (mmWave) frequency bands, the presence of blockage significantly reduces the key rate (KR) of a PLKG system. To address this issue, we introduce reconfigurable intelligent surfaces (RISs) as a potential solution for constructing RIS-reflected channels, thereby enhancing the KR. Our study focuses on the beam-domain channel model and exploits the sparsity of mmWave bands to enhance the randomness of secret keys. To relieve pilot overhead in multi-user systems, we employ a compressed sensing (CS) algorithm to estimate angular information and propose a channel probing protocol with the full-array configuration for acquiring the beam-domain channel. We derive the analytical expressions for the KR in the case of full-array configuration. To optimize the KR, we design the phase shift and precoding vectors based on the obtained angular information. Furthermore, we employ a water-filling algorithm that relies on the Karush-Kuhn-Tucker (KKT) conditions to optimize power allocation for estimating the beam-domain channel with the same channel variance. When channel variances of the beam-domain channel differ, we design a deep-learning-based power allocation method for a more complex problem. What is more, we design a sub-array configuration scheme that exploits the difference in spatial angles between users to reduce pilot overhead and derive the analytical expression for the KR. Through extensive simulations, we demonstrate that our proposed PLKG schemes outperform existing methods.}
}


@article{DBLP:journals/tifs/ZhaoZWNLZ24,
	author = {Mingyang Zhao and
                  Chuan Zhang and
                  Tong Wu and
                  Jianbing Ni and
                  Ximeng Liu and
                  Liehuang Zhu},
	title = {Revocable and Privacy-Preserving Bilateral Access Control for Cloud
                  Data Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5389--5404},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3394678},
	doi = {10.1109/TIFS.2024.3394678},
	timestamp = {Fri, 07 Feb 2025 10:18:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoZWNLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a revocable and privacy-preserving bilateral access control scheme (named PriBAC) for general cloud data sharing (i.e., end-cloud-based data sharing). PriBAC ensures that preference matching is successful only when both parties’ preferences are satisfied simultaneously. Otherwise, nothing is leaked beyond whether the preference matching occurs. There are three challenges in designing PriBAC. The first challenge is protecting matching information, i.e., concealing two preference matching processes, in a single cloud server. The second challenge is protecting preference content while preventing receivers from receiving much useless information. The third challenge is how to integrate efficient user revocation mechanisms into bilateral access control to handle frequent user revocation cases in practical cloud data sharing applications. To address the above challenges, the punchline in PriBAC is to leverage Newton’s interpolation formula-based secret sharing to enrich the matchmaking encryption technique for constructing a privacy-preserving preference matching mechanism. To achieve efficient user revocation, we integrate a unique symbol into each user’s keys and efficiently revoke users by invaliding the corresponding keys. Security analysis proves that PriBAC can resist the chosen-ciphertext attack and preserves preference privacy and matching privacy. Experiments show that PriBAC achieves approximately 3\\times user performance improvement compared with current state-of-the-art related schemes.}
}


@article{DBLP:journals/tifs/LuHWLZXJ24,
	author = {Jianrong Lu and
                  Shengshan Hu and
                  Wei Wan and
                  Minghui Li and
                  Leo Yu Zhang and
                  Lulu Xue and
                  Hai Jin},
	title = {Depriving the Survival Space of Adversaries Against Poisoned Gradients
                  in Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5405--5418},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3360869},
	doi = {10.1109/TIFS.2024.3360869},
	timestamp = {Sun, 19 Jan 2025 14:20:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LuHWLZXJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) allows clients at the edge to learn a shared global model without disclosing their private data. However, FL is susceptible to poisoning attacks, wherein an adversary injects tainted local models that ultimately corrupt the global model. Despite various defensive mechanisms having been developed to combat poisoning attacks, they all fall short of securing practical FL scenarios with heterogeneous and unbalanced data distribution. Moreover, the cutting-edge defenses currently at our disposal demand access to a proprietary dataset that closely mirrors the distribution of clients’ data, which runs counter to the fundamental principle of privacy protection in FL. It is still challenging to devise an effective defense approach that applies to practical FL. In this work, we strive to narrow the divide between FL defense and its practical use. We first present a general framework to comprehend the effect of poisoning attacks in FL when the training data is not independent and identically distributed (non-IID). We then present HeteroFL, a novel FL scheme that incorporates four complementary defensive strategies. These tactics are implemented in succession to refine the aggregated model toward approaching the global optimum. Ultimately, we devise an adaptive attack specifically for HeteroFL, aimed at offering a more thorough evaluation of its robustness. Our extensive experiments over heterogeneous datasets and models show that HeteroFL surpasses all state-of-the-art defenses in thwarting various poisoning attacks, i.e., HeteroFL achieves global model accuracies comparable to the baseline, whereas other defenses suffer a significant accuracy reduction ranging from 34% to 79%.}
}


@article{DBLP:journals/tifs/YangP24,
	author = {Haoxuan Yang and
                  Changgen Peng},
	title = {{CP-IPFE:} Ciphertext-Policy Based Inner Product Functional Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5419--5433},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3396395},
	doi = {10.1109/TIFS.2024.3396395},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Access control schemes in predicate encryption can effectively reduce the risk of information leakage in the inner product function encryption (IPFE). However, when we try to transition from identity-based IPFE to attribute-based IPFE, the fine-grained nature of attributes induces some unprecedented access control problems. These problems not only lead to incorrect inner product computation results from attribute-based IPFE but also inevitable passive information leakage induced by large attribute set secret key. At the same time, since the above problems are not common in identity-based IPFE and traditional ABEs, they cannot be properly addressed by existing schemes. To address the above problems, we introduce a new scheme - Ciphertext Policy Based Inner Product Functional Encryption (CP-IPFE). In this scheme, we propose to use a “label vector” to label the attributes of n-dimensional vectors and encode them onto the relevant information, so as to ensure that the attribute-based IPFE will not output incorrect inner-product computation results; establishing a leaf node set-based “reverse access control policy” to realize reverse access control on “risky ciphertext”, ensures that “risky ciphertext” will not be leaked encrypted-information by the secret key of large attribute sets. In addition, CP-IPFE also has the characteristics of traditional attribute encryption and supports more fine-grained access control. Finally, we prove the CPA security of the CP-IPFE in the GGM model and show a detailed application of the CP-IPFE on a general-purpose platform.}
}


@article{DBLP:journals/tifs/ZhangZYCXY24,
	author = {Zhibo Zhang and
                  Lei Zhang and
                  Guangliang Yang and
                  Yanjun Chen and
                  Jiahao Xu and
                  Min Yang},
	title = {The Dark Forest: Understanding Security Risks of Cross-Party Delegated
                  Resources in Mobile App-in-App Ecosystems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5434--5448},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3390553},
	doi = {10.1109/TIFS.2024.3390553},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZYCXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In app-in-app ecosystems, mobile applications (i.e., host apps) often delegate their rich resources to hosted parties (i.e., sub-apps), which can be utilized to provide millions of effective services including shopping, banking, and government. These resources vary from system abilities (e.g., web socket and GPS location) to app and user data (e.g., storage and phone number). This leads to an important research question—carefully design and enforce security regulations on these cross-party delegated resources (CPDR). Real-world host apps, according to our study, adopt 11 common security regulations in protecting the integrity, confidentiality, and availability of CPDR. However, existing practice and compliance between host apps and sub-apps are vague and inconsistent, leading to violations of these security regulations. To the best of our knowledge, no prior works have studied these security regulations. In this paper, we perform the first systematic study of the security regulations and their security weaknesses in real-world app-in-app ecosystems. We propose three novel attack vectors including masquerade attack, data-driven attack, and channel hijacking. We find that violations of the common security regulations are widespread among all 9 studied app-in-app ecosystems. More importantly, such security weakness can lead to severe consequences such as manipulating sub-apps’ back-end servers and stealing sensitive user data. We responsibly report all of our findings to host app developers of affected app-in-app ecosystems and help them fix their vulnerabilities. The code of this work is available at https://github.com/TitaniumB/MiniAppSecurity.git.}
}


@article{DBLP:journals/tifs/AliMA24,
	author = {Ziad Tariq Muhammad Ali and
                  Ameer Mohammed and
                  Imtiaz Ahmad},
	title = {Vulnerability of Deep Forest to Adversarial Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5464--5475},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402309},
	doi = {10.1109/TIFS.2024.3402309},
	timestamp = {Sun, 04 Aug 2024 19:49:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AliMA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning classifiers are vulnerable to adversarial examples, which are carefully crafted inputs designed to compromise their classification performance. Recently, a new machine learning classifier was proposed that is composed of forests of decision trees, inspired by the architecture of deep neural networks. However, deep neural networks are vulnerable to adversarial attacks. Therefore, in this work, we launch a series of adversarial attacks on deep forests, including black-box and white-box attacks, to assess its vulnerability to adversarial attacks for the first time. Prior work has shown that adversarial examples crafted on one model transfer across various models with different learning techniques. We demonstrate empirically that deep forest is vulnerable to cross-technique-based transferability attacks. On the other hand, to improve the performance of deep forest under adversarial settings, our work includes experiments that demonstrate that training non-differentiable models such as deep forests on randomly or adversarially perturbed inputs increases its adversarial robustness to such attacks. Furthermore, a heuristic white-box method to attack deep forests is proposed by implementing a faster and more efficient decision tree attack algorithm. By attacking both deep forest components, namely the cascade forest and multi-grained layer, we show that deep forests are susceptible to the proposed white-box adversarial attack.}
}


@article{DBLP:journals/tifs/WangYFW24,
	author = {Minxiao Wang and
                  Ning Yang and
                  Nicolas J. Forcade{-}Perkins and
                  Ning Weng},
	title = {ProGen: Projection-Based Adversarial Attack Generation Against Network
                  Intrusion Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5476--5491},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402155},
	doi = {10.1109/TIFS.2024.3402155},
	timestamp = {Wed, 29 May 2024 21:52:50 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangYFW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial attacks, widely recognized as significant threats to machine learning (ML) models in computer vision and natural language processing, can have more severe consequences when targeting ML-based Network Intrusion Detection Systems (NIDS). These attacks, characterized by data manipulation, necessitate a focused investigation grounded in the unique attributes of the data and practical constraints inherent to the target scenario, as opposed to indiscriminately applying methodologies borrowed from other domains. Since network traffic is complex unstructured data, ML models are commonly used in existing studies to explore how perturbations can defeat ML-based IDS. However, two challenges persist in the realm of traffic-space adversarial attack generation. First, raw traffic data cannot be directly input into ML models. Second, determining the appropriate perturbation scale and direction is challenging, particularly in the case of multi-class NIDS. In this work, we propose a projection-based adversarial attack generation framework, ProGen, to address these two challenges. ProGen is inspired by two observed characteristics of the NIDS scenario: flexible representation and clear objective. ProGen uses a basic feature sequence (BFS) space to represent network traffic in a way that aligns with realistic requirements. To achieve a clear objective, ProGen utilizes a traffic space generative adversarial network (GAN) to approximate distribution mapping between malicious traffic and benign traffic. To better apply the generative model for adversarial attacks, we further design constraints to preserve the functions of the adversarial traffic. We’ve successfully demonstrated the effectiveness of ProGen on six common ML models using the CSE-CIC-IDS2018, CIC-IDS-2017, and UNSW-NB15 datasets; however, we’re yet to validate these findings in real network environments. We visualize the generated distributions of the BFS elements to illustrate the projecting effect under the designed realistic constraints. The results of attack effectiveness tests show that attacks generated from ProGen can significantly reduce the detection performance across different ML models.}
}


@article{DBLP:journals/tifs/LiuZLS24,
	author = {Feng Liu and
                  Wenfeng Zeng and
                  Yin Li and
                  Linlin Shen},
	title = {A Lightweight and Noise-Robust Method for Internal {OCT} Fingerprint
                  Reconstruction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5492--5505},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402387},
	doi = {10.1109/TIFS.2024.3402387},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuZLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optical coherence tomography (OCT), as a non-invasive and high-resolution three-dimensional imaging technology, can capture biological tissue structure information under the skin of fingertips. This structure information facilitates stronger anti-spoofing capability of automatic fingerprint recognition systems (AFRSs), and the reconstructed internal fingerprint images based on the structural information are more robust against poor skin conditions. Various internal fingerprint reconstruction methods have been proposed, but these approaches often ignore the continuity of spatial structure information, have a large number of model parameters and are sensitive to noise. Specific to these problems, this paper proposes a lightweight and noise-robust point detection network (LNPDN) to reconstruct internal fingerprints. At first, by combining the ShuffleNet with the temporal shift module and self-attention, the continuity of spatial information is considered. Meanwhile, the previous refined tissue structural region segmentation task, which is highly affected by noise, is transformed into an easy noise-robust feature point detection mission. Then, these detected points are synthesized into a curve to represent the upper envelope of the viable epidermis by linear interpolation. Finally, internal fingerprint image is reconstructed by averaging those pixel values at a certain depth range below the envelope. The experimental results show the proposed feature point extraction model for the central vertex of ridge blocks reaches the F1-score value of 93.911%, and the average minimum point-segment distance between the proposed curve and the target curve is 1.475. It demonstrates that the proposed model can well extract the central vertex of the ridge blocks and the curve can reflect the location of the viable epidermis. We also compared the recognition capabilities of internal fingerprints extracted from 2138 OCT fingerprint volume data on the public OCT fingerprint benchmark dataset. Our method achieves the lowest equal error rate of 0.167%, with a relative reduction of 60.91% compared with state-of-the-art reconstruction methods.}
}


@article{DBLP:journals/tifs/HuLFW24,
	author = {Cong Hu and
                  Yuanbo Li and
                  Zhenhua Feng and
                  Xiaojun Wu},
	title = {Toward Transferable Attack via Adversarial Diffusion in Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5506--5519},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402167},
	doi = {10.1109/TIFS.2024.3402167},
	timestamp = {Fri, 06 Dec 2024 11:26:32 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuLFW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern face recognition systems widely use deep convolutional neural networks (DCNNs). However, DCNNs are susceptible to adversarial examples, posing security risks to these systems. Transferable adversarial examples that can be transferred from surrogate to target models greatly undermine the robustness of DCNNs. Numerous attempts have been made to generate transferable adversarial examples, but the existing methods often suffer from limited transferability or produce adversarial examples with poor image perceptual quality. Recently, diffusion models have shown remarkable success in image generation and have excelled in various downstream tasks. However, their potential in adversarial attacks remains largely unexplored. To bridge this gap, we propose a novel approach, namely Adversarial Diffusion Attack (ADA), in generation of transferable adversarial facial examples. ADA employs a dynamic game-like strategy between injection and denoising that progressively reinforces the robustness of adversarial perturbation in the reverse process of diffusion model. Additionally, both adversarial perturbation and residual image are embedded to drift benign distribution towards adversarial distribution, crafting adversarial examples with high image quality. Extensive experimental results obtained on two benchmarking datasets, LFW and CelebA-HQ, demonstrate that ADA achieves higher attack success rates and produces adversarial examples with superior image quality compared to the state-of-the-art methods.}
}


@article{DBLP:journals/tifs/CeldranSASBPS24,
	author = {Alberto Huertas Celdr{\'{a}}n and
                  Pedro Miguel S{\'{a}}nchez S{\'{a}}nchez and
                  Jan von der Assen and
                  Timo Schenk and
                  G{\'{e}}r{\^{o}}me Bovet and
                  Gregorio Mart{\'{\i}}nez P{\'{e}}rez and
                  Burkhard Stiller},
	title = {{RL} and Fingerprinting to Select Moving Target Defense Mechanisms
                  for Zero-Day Attacks in IoT},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5520--5529},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402055},
	doi = {10.1109/TIFS.2024.3402055},
	timestamp = {Fri, 31 May 2024 21:05:45 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CeldranSASBPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Moving Target Defense (MTD) is a promising approach to mitigate attacks by dynamically altering target attack surfaces. Still, selecting suitable MTD techniques for zero-day attacks is an open challenge. Reinforcement Learning (RL) could be an effective approach to optimize the MTD selection through trial and error, but the literature fails when i) evaluating the performance of RL and MTD solutions in real-world scenarios, ii) studying whether behavioral fingerprinting is suitable for RL, and iii) calculating the consumption of resources in single-board computers (SBC). Thus, the work at hand proposes an online RL-based framework that learns correct MTD mechanisms mitigating heterogeneous zero-day attacks in SBC. The framework considers behavioral fingerprinting to represent SBCs’ states and RL to learn MTD techniques that mitigate each malicious state. It has been deployed on a real IoT crowdsensing scenario with a Raspberry Pi acting as a spectrum sensor. The Raspberry Pi has been infected with different samples of command and control malware, rootkits, and ransomware to later select between four existing MTD techniques. A set of experiments demonstrated the suitability of the framework to learn proper MTD techniques mitigating all attacks (except a harmfulness rootkit) while consuming < 1 MB of storage, \\approx 10 % of RAM, and negligible CPU.}
}


@article{DBLP:journals/tifs/ZhangLMLXRD24,
	author = {Man Zhang and
                  Xinghua Li and
                  Yinbin Miao and
                  Bin Luo and
                  Wanyun Xu and
                  Yanbing Ren and
                  Robert H. Deng},
	title = {Privacy-Preserved Data Disturbance and Truthfulness Verification for
                  Data Trading},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5545--5560},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402162},
	doi = {10.1109/TIFS.2024.3402162},
	timestamp = {Fri, 14 Feb 2025 20:58:22 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLMLXRD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advanced data trading allows data generator’s (DG) disturbed data to be traded as both initial and reselling trading modes, which meets DG’s raw data privacy and data consumers’ (DCs) vast data requirement. However, the traded data truthfulness verifiability cannot be guaranteed in the privacy-preserved way. Firstly, due to DG’s independent and random disturbance, DC cannot verify whether the traded data is disturbed under his required disturbance parameter without carrying privacy leakage on DG. Secondly, because the reselling trading is allowed, DC can hardly verify the traded data’s origin truthfulness under the deceiving of data reseller (DR) while protecting his purchase privacy. Aiming at the above problems, we propose the privacy-preserved data disturbance and truthfulness verification for data trading. Specifically, an honest-but-curious trading server (TS) is introduced to assist our devised private-verifiable imprint-embedded disturbance method where imprint is blinding. Subsequently, TS implements the adaptive truthfulness verification by constructing imprint-embedded individual verification formula and requiring verified participants to decrypt the formula result. The verified participants cannot inform the blinding imprint value to forge the correct result, ensuring the accuracy of the devised verification method. Theoretical analysis proves that participants’ privacy is preserved and the traded data’s truthfulness can be guaranteed. Extensive experiments using the real-world dataset demonstrate that without any extra privacy cost, our scheme verifies 100% untruthful traded data compared with the existing solutions’ 50%.}
}


@article{DBLP:journals/tifs/PuLGHH24,
	author = {Lang Pu and
                  Chao Lin and
                  Jingjing Gu and
                  Xinyi Huang and
                  Debiao He},
	title = {Generic Construction of Conditional Privacy-Preserving Certificateless
                  Signatures With Efficient Instantiations for VANETs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5449--5463},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402992},
	doi = {10.1109/TIFS.2024.3402992},
	timestamp = {Tue, 18 Jun 2024 09:24:46 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PuLGHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular Ad-hoc Networks (VANETs) constitute crucial elements within intelligent transportation systems. However, the rapid development of VANETs has brought forth an increasing number of security concerns. Conditional Privacy-Preserving Certificateless Signature (CPP-CLS) has emerged as a promising solution to ensure data security, preserve vehicle anonymity, and establish unlinkability in VANETs. In contrast to traditional public key infrastructure systems that involve cumbersome certificate management, and identity-based frameworks fraught with key escrow issues, CPP-CLS presents a more apt approach for VANETs. Unfortunately, the researches on CPP-CLS present a strange phenomenon in that a scheme proposed is always pointed out to have various security problems, especially public key replacement attacks. Moreover, there is a scarcity of published researches on the generic construction of CPP-CLS. To tackle these challenges, this paper proposes the first generic construction for CPP-CLS based on Type-T (Three-move type) signature, in which the public key reconstruction technique enables any receiver who owns a part of the sender’s public key and the KGC’s public key to reconstruct the complete sender’s public key, which can alleviate the public key replacement attacks. A formal security analysis proves that our scheme effectively guards against existential forgery under adaptively chosen message attacks in the random oracle model, contingent upon the security of the underlying Type-T signature. Furthermore, We provide two specific instantiations of the generic construction to verify feasibility. Among them, the instantiation based on module learning with errors is effective against quantum attacks. Based on extensive experimental results and theoretical analysis, our implementations surpass the majority of existing similar schemes in either performance or security. This substantiates the feasibility of our generic scheme, making it applicable for constructing CPP-CLS schemes.}
}


@article{DBLP:journals/tifs/PohleAP24,
	author = {Erik Pohle and
                  Aysajan Abidin and
                  Bart Preneel},
	title = {Fast Evaluation of S-Boxes With Garbled Circuits},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5530--5544},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402145},
	doi = {10.1109/TIFS.2024.3402145},
	timestamp = {Tue, 18 Jun 2024 09:24:46 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PohleAP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Garbling schemes are vital primitives for privacy-preserving protocols and secure two-party computation. This paper presents a projective garbling scheme that assigns 2^{n}\nvalues to wires in a circuit comprising XOR and unary projection gates. A generalization of FreeXOR allows the XOR of wires with 2^{n}\nvalues to be very efficient. We then analyze the performance of our scheme by evaluating substitution-permutation ciphers. Using our proposal, we measure high-speed evaluation of the ciphers with a moderately increased cost in garbling and bandwidth. Theoretical analysis suggests that for evaluating the nine examined ciphers, one can expect a 4- to 70-fold improvement in evaluation performance with, at most, a 4-fold increase in garbling cost and, at most, an 8-fold increase in communication cost compared to the Half-Gates (Zahur, Rosulek and Evans; Eurocrypt’15) and ThreeHalves (Rosulek and Roy; Crypto’21) garbling schemes. In an offline/online setting, such as secure function evaluation as a service, the circuit garbling and communication to the evaluator can proceed in the offline phase. Thus, our scheme offers a fast online phase. Furthermore, we present efficient Boolean circuits for the S-boxes of TWINE and Midori64 ciphers. To our knowledge, our formulas give the smallest number of AND gates for the S-boxes of these two ciphers.}
}


@article{DBLP:journals/tifs/ChenGQZSY24,
	author = {Xun Chen and
                  Fujun Gao and
                  Min Qiu and
                  Jia Zhang and
                  Feng Shu and
                  Shihao Yan},
	title = {Achieving Covert Communication With a Probabilistic Jamming Strategy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5561--5574},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402346},
	doi = {10.1109/TIFS.2024.3402346},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenGQZSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we consider a covert communication scenario, where a transmitter Alice communicates to a receiver Bob with the aid of a probabilistic and uninformed jammer against an adversary warden’s detection. The transmission status and power of the jammer are random and follow some priori probabilities. We first analyze the warden’s detection performance as a function of the jammer’s transmission probability, transmit power distribution, and Alice’s transmit power. We then maximize the covert throughput from Alice to Bob subject to a covertness constraint, by designing the covert communication strategies from three different perspectives: Alice’s perspective, the jammer’s perspective, and the global perspective. Our analysis reveals that the minimum jamming power should not always be zero in the probabilistic jamming strategy, which is different from that in the continuous jamming strategy presented in the literature. In addition, we prove that the minimum jamming power should be the same as Alice’s covert transmit power, depending on the covertness and average jamming power constraints. Furthermore, our results show that the probabilistic jamming can outperform the continuous jamming in terms of achieving a higher covert throughput under the same covertness and average jamming power constraints.}
}


@article{DBLP:journals/tifs/LuLCTW24,
	author = {Zhi Lu and
                  Songfeng Lu and
                  Yongquan Cui and
                  Xueming Tang and
                  Junjun Wu},
	title = {Split Aggregation: Lightweight Privacy-Preserving Federated Learning
                  Resistant to Byzantine Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5575--5590},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402993},
	doi = {10.1109/TIFS.2024.3402993},
	timestamp = {Tue, 18 Jun 2024 09:24:46 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuLCTW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL), a distributed learning paradigm optimizing communication costs and enhancing privacy by uploading gradients instead of raw data, now confronts security challenges. It is particularly vulnerable to Byzantine poisoning attacks and potential privacy breaches via inference attacks. While homomorphic encryption and secure multi-party computation have been employed to design robust FL mechanisms, these predominantly rely on Euclidean distance or median-based metrics and often fall short in comprehensively defending against advanced poisoning attacks, such as adaptive attacks. Addressing this issue, our study introduces “Split-Aggregation”, a lightweight privacy-preserving FL solution capable of withstanding adaptive attacks. This method maintains a computational complexity of O(dkN+k^{3}) and a communication overhead of O(dN) , performing comparably to FedAvg when k=10 . Here, d represents the gradient dimension, N the number of users, and k the rank chosen during random singular value decomposition. Additionally, we utilize adaptive weight coefficients to mitigate gradient descent issues in honest users caused by non-independent and identically distributed (Non-IID) data. The proposed method’s security and robustness are theoretically proven, with its complexity thoroughly analyzed. Experimental results demonstrate that at k=10 , this method surpasses the top-1 accuracy of current state-of-the-art robust privacy-preserving FL approaches. Moreover, opting for a smaller k significantly boosts efficiency with only marginal compromises in accuracy.}
}


@article{DBLP:journals/tifs/MongardiniMJMM24,
	author = {Alberto Maria Mongardini and
                  Massimo La Morgia and
                  Sushil Jajodia and
                  Luigi Vincenzo Mancini and
                  Alessandro Mei},
	title = {{DARD:} Deceptive Approaches for Robust Defense Against {IP} Theft},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5591--5606},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402433},
	doi = {10.1109/TIFS.2024.3402433},
	timestamp = {Mon, 03 Mar 2025 22:25:02 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MongardiniMJMM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rise of smart working and recent global events, the risk of cyberattacks is increasing steadily. Sometimes adversaries focus on stealing valuable data, such as intellectual property (IP): they exfiltrate a large volume of IP documents from a target company. They then identify those of their interest by leveraging automated methods. This work proposes the DARD (Deceptive Approaches for Robust Defense against IP theft) system, a framework designed to deceive adversaries who rely on automatic approaches to classify exfiltrated documents. Starting from an original repository of documents, DARD automatically generates a new deceptive repository that misleads popular automatic approaches, resulting in clusters of documents that are significantly different from the actual ones. By utilizing this approach, DARD aims to hinder the accurate clustering and the identification of the topic of documents by adversaries relying on automated techniques. The paper presents four deceptive operations (Basic Shuffle, Shuffle increment, Shuffle reduction, and Change topic) that DARD leverages to create a deceptive repository. We evaluate the efficacy of our approach by considering three different types of adversaries, each possessing varying levels of knowledge and expertise. Through extensive experiments, we show that the DARD system can deceive both automatic topic modeling and document clustering techniques, including widely-used commercial tools such as Amazon Comprehend. Hence, our solution provides a robust defense mechanism against Intellectual Property (IP) theft.}
}


@article{DBLP:journals/tifs/ZhaoDLLPD24,
	author = {Bowen Zhao and
                  Weiquan Deng and
                  Xiaoguo Li and
                  Ximeng Liu and
                  Qingqi Pei and
                  Robert H. Deng},
	title = {{SOCI+:} An Enhanced Toolkit for Secure Outsourced Computation on
                  Integers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5607--5619},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402173},
	doi = {10.1109/TIFS.2024.3402173},
	timestamp = {Mon, 16 Sep 2024 10:52:02 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoDLLPD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure outsourced computation is critical for cloud computing to safeguard data confidentiality and ensure data usability. Recently, secure outsourced computation schemes following a twin-server architecture based on partially homomorphic cryptosystems have received increasing attention. The Secure Outsourced Computation on Integers (SOCI) toolkit is the state-of-the-art among these schemes which can perform secure computation on integers without requiring the costly bootstrapping operation as in fully homomorphic encryption; however, SOCI suffers from relatively large computation and communication overhead. In this paper, we propose SOCI+ which significantly improves the performance of SOCI. Specifically, SOCI+ employs a novel (2, 2)-threshold Paillier cryptosystem with fast encryption and decryption as its cryptographic primitive, and supports a suite of efficient secure arithmetic computation on integers protocols, including a secure multiplication protocol (SMUL), a secure comparison protocol (SCMP), a secure sign bit-acquisition protocol (SSBA), and a secure division protocol (SDIV), all based on the (2, 2)-threshold Paillier cryptosystem with fast encryption and decryption. In addition, SOCI+ incorporates an offline and online computation mechanism to further optimize its performance. We perform rigorous theoretical analysis to prove the correctness and security of SOCI+. Compared with SOCI, our experimental evaluation shows that SOCI+ is up to 5.3 times more efficient in online runtime and 40% less in communication overheads.}
}


@article{DBLP:journals/tifs/JiangZZ24,
	author = {Peng Jiang and
                  Jun Zhu and
                  Liehuang Zhu},
	title = {Balancing Privacy and Regulation of Cross-Chain Transaction Systems
                  via SoK-Assisted Policy Enhancement},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5620--5629},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402150},
	doi = {10.1109/TIFS.2024.3402150},
	timestamp = {Wed, 04 Sep 2024 21:09:35 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-chain systems provide a way for isolated blockchains to communicate and exchange assets and data with each other. Sidechain-based cross-chain systems support more scenarios with more complicated functionalities. However, the correlation of transactions in two underlying blockchains makes the linkability for the sidechain and exposes the identity of transaction parties and transaction amounts. This incurs the cross-chain privacy leakage. Traditional privacy-preserving mechanisms conversely compromise the regulation of transactions, which limits the identification and punishment to malicious transaction parties. To balance privacy and regulation of cross-chain systems, in this paper, we propose PCP, a privacy-preserving policy-enforcement cross-chain protocol between Monero and Bitcoin. It leverages the signature of knowledge to guarantee the correctness and privacy, while sets a trapdoor for tracing authority to revoke the anonymity when the investigation is required. We instantiate a scheme with formal security proof. We conduct a series of experiments by using Fiat-Shamir paradigm with zero-knowledge and the results show that the proposed PCP is cost-reasonable with constant 150 ms for Swap Monero phase, 40 ms for proof generation and 24 ms for proof verification.}
}


@article{DBLP:journals/tifs/Ding24,
	author = {Ni Ding},
	title = {Approximation of Pufferfish Privacy for Gaussian Priors},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5630--5640},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402104},
	doi = {10.1109/TIFS.2024.3402104},
	timestamp = {Tue, 18 Jun 2024 09:24:46 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/Ding24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies how to approximate pufferfish privacy when the adversary’s prior belief of the published data is Gaussian distributed. Using Monge’s optimal transport plan, we show that (\\epsilon , \\delta ) -pufferfish privacy is attained if the additive Laplace noise is calibrated to the differences in mean and variance of the Gaussian distributions conditioned on every discriminative secret pair. A typical application is the private release of the summation (or average) query, for which sufficient conditions are derived for approximating \\epsilon -statistical indistinguishability in individual’s sensitive data. The result is then extended to arbitrary prior beliefs trained by Gaussian mixture models (GMMs): calibrating Laplace noise to a convex combination of differences in mean and variance between Gaussian components attains (\\epsilon ,\\delta ) -pufferfish privacy.}
}


@article{DBLP:journals/tifs/XuWZNX24,
	author = {Weiyang Xu and
                  Ruiguang Wang and
                  Yuan Zhang and
                  Hien Quoc Ngo and
                  Wei Xiang},
	title = {Pilot Spoofing Attack on the Downlink of Cell-Free Massive {MIMO:}
                  From the Perspective of Adversaries},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5641--5654},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402973},
	doi = {10.1109/TIFS.2024.3402973},
	timestamp = {Tue, 18 Jun 2024 09:24:46 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuWZNX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The channel hardening effect is less pronounced in the cell-free massive multiple-input multiple-output (mMIMO) system compared to its cellular counterpart, making it necessary to estimate the downlink effective channel gains to ensure decent performance. However, the downlink training inadvertently creates an opportunity for adversarial nodes to launch pilot spoofing attacks (PSAs). First, we demonstrate that adversarial distributed access points (APs) can severely degrade the achievable downlink rate. They achieve this by estimating their channels to users in the uplink training phase and then precoding and sending the same pilot sequences as those used by legitimate APs during the downlink training phase. Then, the impact of the downlink PSA is investigated by rigorously deriving a closed-form expression of the per-user achievable downlink rate. By employing the min-max criterion to optimize the power allocation coefficients, the maximum per-user achievable rate of downlink transmission is minimized from the perspective of adversarial APs. As an alternative to the downlink PSA, adversarial APs may opt to precode random interference during the downlink data transmission phase in order to disrupt legitimate communications. In this scenario, the achievable downlink rate is derived, and then power optimization algorithms are also developed. We present numerical results to showcase the detrimental impact of the downlink PSA and compare the effects of these two types of attacks.}
}


@article{DBLP:journals/tifs/FanLJHYZ24,
	author = {Wenshu Fan and
                  Hongwei Li and
                  Wenbo Jiang and
                  Meng Hao and
                  Shui Yu and
                  Xiao Zhang},
	title = {Stealthy Targeted Backdoor Attacks Against Image Captioning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5655--5667},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402179},
	doi = {10.1109/TIFS.2024.3402179},
	timestamp = {Wed, 29 Jan 2025 14:51:06 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FanLJHYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, there is an explosive growth in multimodal learning. Image captioning, a classical multimodal task, has demonstrated promising applications and attracted extensive research attention. However, recent studies have shown that image caption models are vulnerable to some security threats such as backdoor attacks. Existing backdoor attacks against image captioning typically pair a trigger either with a predefined sentence or a single word as the targeted output, yet they are unrelated to the image content, making them easily noticeable as anomalies by humans. In this paper, we present a novel method to craft targeted backdoor attacks against image caption models, which are designed to be stealthier than prior attacks. Specifically, our method first learns a special trigger by leveraging universal perturbation techniques for object detection, then places the learned trigger in the center of some specific source object and modifies the corresponding object name in the output caption to a predefined target name. During the prediction phase, the caption produced by the backdoored model for input images with the trigger can accurately convey the semantic information of the rest of the whole image, while incorrectly recognizing the source object as the predefined target. Extensive experiments demonstrate that our approach can achieve a high attack success rate while having a negligible impact on model clean performance. In addition, we show our method is stealthy in that the produced backdoor samples are indistinguishable from clean samples in both image and text domains, which can successfully bypass existing backdoor defenses, highlighting the need for better defensive mechanisms against such stealthy backdoor attacks.}
}


@article{DBLP:journals/tifs/NakipG24,
	author = {Mert Nakip and
                  Erol Gelenbe},
	title = {Online Self-Supervised Deep Learning for Intrusion Detection Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5668--5683},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402148},
	doi = {10.1109/TIFS.2024.3402148},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NakipG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a novel Self-Supervised Intrusion Detection (SSID) framework, which enables a fully online Deep Learning (DL) based Intrusion Detection System (IDS) that requires no human intervention or prior off-line learning. The proposed framework analyzes and labels incoming traffic packets based only on the decisions of the IDS itself using an Auto-Associative Deep Random Neural Network, and on an online estimate of its statistically measured trustworthiness. The SSID framework enables IDS to adapt rapidly to time-varying characteristics of the network traffic, and eliminates the need for offline data collection. This approach avoids human errors in data labeling, and human labor and computational costs of model training and data collection. The approach is experimentally evaluated on public datasets and compared with well-known machine learning and deep learning models, showing that this SSID framework is very useful and advantageous as an accurate and online learning DL-based IDS for IoT systems.}
}


@article{DBLP:journals/tifs/YangCLWC24,
	author = {Fan Yang and
                  Hao Cheng and
                  Shanxiang Lyu and
                  Jinming Wen and
                  Hao Chen},
	title = {Lattice-Aided Extraction of Spread-Spectrum Hidden Data},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5684--5695},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402948},
	doi = {10.1109/TIFS.2024.3402948},
	timestamp = {Tue, 16 Jul 2024 20:30:55 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangCLWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper delves into the challenges of spread spectrum (SS) watermarking extraction, considering both reference-free and referential extraction scenarios, within the framework of lattice decoding. The orthogonality of carriers plays a crucial role in the accuracy of extraction, impacting the bit error rate (BER). When carriers lack sufficient orthogonality, conventional reference-free extraction methods such as multi-carrier iterative generalized least-squares (M-IGLS) and referential extraction techniques like MMSE-based schemes encounter performance degradation, posing difficulties in accurately recovering hidden data at the receiver end. To address these challenges, we propose two novel SS watermarking extraction approaches by integrating precise lattice decoding algorithms. Firstly, we introduce the highly accurate yet computationally efficient successive interference cancellation (SIC) algorithm to augment M-IGLS, resulting in a new method termed multi-carrier iterative successive interference cancellation (M-ISIC). Secondly, we adapt the near-optimal sphere decoding (SD) technique for referential extraction in SS watermarking. Theoretical analysis and experimental simulations showcase that our proposed M-ISIC and SD methods outperform M-IGLS and MMSE-based detectors, particularly in scenarios where carrier orthogonality is limited, achieving lower BER. Our code is available at https://github.com/shx-lyu/M_ISIC.}
}


@article{DBLP:journals/tifs/ZhangZSJS24,
	author = {Yu Zhang and
                  Shuangrui Zhao and
                  Yulong Shen and
                  Xiaohong Jiang and
                  Norio Shiratori},
	title = {Enhancing the Physical Layer Security of Two-Way Relay Systems With
                  {RIS} and Beamforming},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5696--5711},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402373},
	doi = {10.1109/TIFS.2024.3402373},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZSJS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies the possible physical layer security (PLS) enhancement in a wiretapped two-way relay system from utilizing the reconfigurable intelligent surface (RIS) and beamforming techniques. We first jointly apply the RIS and beamforming (RIS-B) to develop an advanced secure transmission scheme for the system, and conduct related theoretical modeling for the system secrecy sum rate (SSR) under the RIS-B scheme. We then apply the theories of alternating optimization, successive convex approximation, augmented Lagrange method and the quasi-Newton method to devise both the optimal and low-complexity sub-optimal frameworks to identify the optimal settings of RIS phase shifts and beamforming matrix of the RIS-B scheme for SSR maximization. We further investigate a special case when solely the RIS technique is applied for SSR performance enhancement. With the help of Charnes-Cooper transformation, semidefinite programming and Gaussian randomization, we devise an optimization framework to identify the optimal settings of RIS phase shifts for SSR maximization. Finally, extensive numerical results are provided to illustrate the efficiency of the RIS and RIS-B schemes in PLS enhancement in comparison with the conventional channel-capacity-based secure transmission.}
}


@article{DBLP:journals/tifs/GuanFZ24,
	author = {Xiongjun Guan and
                  Jianjiang Feng and
                  Jie Zhou},
	title = {Phase-Aggregated Dual-Branch Network for Efficient Fingerprint Dense
                  Registration},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5712--5724},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3403507},
	doi = {10.1109/TIFS.2024.3403507},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GuanFZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fingerprint dense registration aims to finely align fingerprint pairs at the pixel level, thereby reducing intra-class differences caused by distortion. Unfortunately, traditional methods exhibited subpar performance when dealing with low-quality fingerprints while suffering from slow inference speed. Although deep learning based approaches shows significant improvement in these aspects, their registration accuracy is still unsatisfactory. In this paper, we propose a Phase-aggregated Dual-branch Registration Network (PDRNet) to aggregate the advantages of both types of methods. A dual-branch structure with multi-stage interactions is introduced between correlation information at high resolution and texture feature at low resolution, to perceive local fine differences while ensuring global stability. Extensive experiments are conducted on more comprehensive databases compared to previous works. Experimental results demonstrate that our method reaches the state-of-the-art registration performance in terms of accuracy and robustness, while maintaining considerable competitiveness in efficiency.}
}


@article{DBLP:journals/tifs/HuoWZLHW24,
	author = {Lijuan Huo and
                  Libing Wu and
                  Zhuangzhuang Zhang and
                  Chunshuo Li and
                  Debiao He and
                  Jing Wang},
	title = {Libras: {A} Fair, Secure, Verifiable, and Scalable Outsourcing Computation
                  Scheme Based on Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5725--5737},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3403489},
	doi = {10.1109/TIFS.2024.3403489},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuoWZLHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing multitask outsourcing computations struggle to guarantee the fairness for participants and the correctness of the computation results. Some solutions use blockchain to address the fairness issue in outsourcing computations. However, blockchain suffers from poor data privacy due to its public and transparent nature, as well as the latency because of limited scalability. To effectively confront these problems, we propose the Libras: a fair, secure, verifiable and scalable outsourcing computation scheme based on blockchain. In Libras, tasks are divided into multiple sub-task blocks, coupled with a deposit mechanism that enforces fairness throughout the process. Libras integrates a commitment mechanism with on-chain and off-chain collaboration for security, where the computation results are securely stored off-chain while proofs of these results are immutably recorded on-chain. Moreover, it employs a Directed Acyclic Graph (DAG)-based ledger architecture to significantly expedite transaction confirmations and facilitate elastic scalability. Furthermore, we devise a batch verification algorithm to simultaneously verify the accuracy of all computation results. Theoretical analysis and experiments demonstrate that Libras is fair, secure, verifiable, and scalable. The comparison results indicate that the verification time is 1.2\\times that of FVP-EOC.}
}


@article{DBLP:journals/tifs/HuangLYCD24,
	author = {Wenke Huang and
                  Yuxia Liu and
                  Mang Ye and
                  Jun Chen and
                  Bo Du},
	title = {Federated Learning With Long-Tailed Data via Representation Unification
                  and Classifier Rectification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5738--5750},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402361},
	doi = {10.1109/TIFS.2024.3402361},
	timestamp = {Thu, 25 Jul 2024 11:07:15 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangLYCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Prevalent federated learning commonly develops under the assumption that the ideal global class distributions are balanced. In contrast, real-world data typically follows the long-tailed class distribution, where models struggle to classify samples from tail classes. In this paper, we alleviate the issue under the long-tailed data, dissecting the into two aspects: the distorted feature space and the biased classifier. Specifically, we propose the Representation Unification and Classifier Rectification (RUCR), which leverages global unified prototypes to shape the feature space and calibrate the classifier. RUCR aggregates local prototypes (class-wise mean features) extracted by the global model to obtain global unified prototypes. It calibrates the feature space by pulling features within the same class towards corresponding global unified prototypes and pushing the other classes away. Moreover, RUCR utilizes global prototypes to reduce the classifier bias via prototypical mix-up. It generates a balanced virtual feature set by arbitrarily fusing global unified prototypes and local features. The classifier re-training is then conducted on the balanced virtual feature set to rectify the decision boundary and thus alleviate the shifts. Empirical results on CIFAR-10-LT, CIFAR-100-LT, and Tiny-Imagenet-LT datasets validate the superior performance of our proposed method.}
}


@article{DBLP:journals/tifs/MiaoW24,
	author = {Guanhong Miao and
                  Samuel S. Wu},
	title = {Efficient Privacy-Preserving Logistic Model With Malicious Security},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5751--5766},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402319},
	doi = {10.1109/TIFS.2024.3402319},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MiaoW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conducting secure computations to protect against malicious adversaries is an emerging field of research. Current models designed for malicious security typically necessitate the involvement of two or more servers in an honest-majority setting. Among privacy-preserving data mining techniques, significant attention has been focused on the classification problem. Logistic regression emerges as a well-established classification model, renowned for its impressive performance. We introduce a novel matrix encryption method to build a maliciously secure logistic model. Our scheme involves only a single semi-honest server and is resilient to malicious data providers that may deviate arbitrarily from the scheme. The d-transformation ensures that our scheme achieves indistinguishability (i.e., no adversary can determine, in polynomial time, which of the plaintexts corresponds to a given ciphertext in a chosen-plaintext attack). Malicious activities of data providers can be detected in the verification stage. A lossy compression method is implemented to minimize communication costs while preserving negligible degradation in accuracy. Experiments illustrate that our scheme is highly efficient to analyze large-scale datasets and achieves accuracy similar to non-private models. The proposed scheme outperforms other maliciously secure frameworks in terms of computation and communication costs.}
}


@article{DBLP:journals/tifs/DiegoMK24,
	author = {Jorge David de Hoz Diego and
                  Taous Madi and
                  Charalambos Konstantinou},
	title = {CMXsafe: {A} Proxy Layer for Securing Internet-of-Things Communications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5767--5782},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3404258},
	doi = {10.1109/TIFS.2024.3404258},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DiegoMK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Security in Internet-of-Things (IoT) environments has become a major concern. This is partly due to a large number of remotely exploitable IoT vulnerabilities in service authentication and access control combined with the lack of timely technical support. To reduce the threat surface of remote vulnerability exploitation, we propose CMXsafe, a secure-by-design application-agnostic proxy layer that can be updated and managed independently of the IoT device application. CMXsafe places IoT devices behind gateways operating as 4th OSI transport layer relayers to offload security concerns of IoT network communications into the proxy layer. Specifically, the proxy layer produces secure communication paths between IoT applications and platforms while enforcing mutual authentication and access control to proxied services. We evaluate the performance of our architecture on the MQTT protocol used in a standard publisher-broker-subscriber configuration provided by Eclipse Mosquitto. We compare the performance penalty on the protocol when securing communications with TLS following a monolithic implementation and with CMXsafe. The experimental results suggest that CMXsafe outperforms integrated security by providing at least a 25% latency reduction and a 22% bandwidth improvement.}
}


@article{DBLP:journals/tifs/FukamiMNT24,
	author = {Takumi Fukami and
                  Tomoya Murata and
                  Kenta Niwa and
                  Iifan Tyou},
	title = {DP-Norm: Differential Privacy Primal-Dual Algorithm for Decentralized
                  Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5783--5797},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3390993},
	doi = {10.1109/TIFS.2024.3390993},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FukamiMNT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A novel algorithm is proposed for highly privacy-preserving decentralized federated learning (FL). Several studies have reported security risks in decentralized FL by reconstructing data even from model update differences. A common approach to overcome this issue is to use the diffusion process following differential privacy (DP), i.e., message passing between nodes is hidden by noise. However, this often makes the learning process unstable, leading to degraded results compared to without using DP diffusion process. In this paper, we propose a primal-dual DP algorithm with denoising normalization (DP-Norm) for less sensitivity to noise/interference, such as DP diffusion and heterogeneous data allocation. For DP-Norm, privacy analysis to determine minimal noise level and convergence analysis are conducted. Through image classification benchmark tests, we confirmed that DP-Norm performed close to the single-node reference score, even when statistically heterogeneous data was allocated on six nodes.}
}


@article{DBLP:journals/tifs/ZhouHGWJM24,
	author = {Yudi Zhou and
                  Yan Huo and
                  Qinghe Gao and
                  Yue Wu and
                  Tao Jing and
                  Jian Mao},
	title = {Securing Collaborative Authentication: {A} Weighted Voting Strategy
                  to Counter Unreliable Cooperators},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5798--5813},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402399},
	doi = {10.1109/TIFS.2024.3402399},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouHGWJM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative physical layer authentication (CPLA) is a promising alternative, addressing common single-point failure issues in centralized authentication systems through its unique architecture. However, the necessary involvement of multiple parties increases the risk to collaborative systems, particularly from hostile cooperators, significantly impacting the performance of CPLA. In existing CPLA approaches, the most common strategy to combat malicious cooperators attacks is to select the best collaborative combination. This strategy achieves the customization goal by excluding hostile-minded devices. However, processing a non-fixed search space typically demands a substantial investment of time and resources. As a remedy, we propose a decision-level-based CPLA scheme with a weighted voting mechanism. Our scheme aims to implement streamlined and effective dynamic management of cooperators to ensure that multi-directional information provides positive effects on authentication. Specifically, we conduct a two-stage performance appraisal of all cooperators. To measure the trustworthiness of cooperators, an impression-driven reliability evaluation scheme is developed. We analyze the riskiness of individual cooperators to prevent centers from falling into cognitive bias. Finally, we validate the feasibility of the scheme. The results demonstrate that, in a scenario where 50% of participants are malicious, our approach achieves an accuracy improvement of 2.96% to 3% compared to other dynamic weighted voting schemes. The robustness and stability of the proposed CPLA scheme outperform the benchmark schemes.}
}


@article{DBLP:journals/tifs/MiaoYLXLLD24,
	author = {Yinbin Miao and
                  Xinru Yan and
                  Xinghua Li and
                  Shujiang Xu and
                  Ximeng Liu and
                  Hongwei Li and
                  Robert H. Deng},
	title = {RFed: Robustness-Enhanced Privacy-Preserving Federated Learning Against
                  Poisoning Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5814--5827},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402113},
	doi = {10.1109/TIFS.2024.3402113},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MiaoYLXLLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning not only realizes collaborative training of models, but also effectively maintains user privacy. However, with the widespread application of privacy-preserving federated learning, poisoning attacks threaten the model utility. Existing defense schemes suffer from a series of problems, including low accuracy, low robustness and reliance on strong assumptions, which limit the practicability of federated learning. To solve these problems, we propose a Robustness-enhanced privacy-preserving Federated learning with scaled dot-product attention (RFed) under dual-server model. Specifically, we design a highly robust defense mechanism that uses a dual-server model instead of traditional single-server model to significantly improve model accuracy and completely eliminate the reliance on strong assumptions. Formal security analysis proves that our scheme achieves convergence and provides privacy protection, and extensive experiments demonstrate that our scheme reduces high computational overhead while guaranteeing privacy preservation and model accuracy, and ensures that the failure rate of poisoning attacks is higher than 96%.}
}


@article{DBLP:journals/tifs/MiaoKLXLCD24,
	author = {Yinbin Miao and
                  Da Kuang and
                  Xinghua Li and
                  Shujiang Xu and
                  Hongwei Li and
                  Kim{-}Kwang Raymond Choo and
                  Robert H. Deng},
	title = {Privacy-Preserving Asynchronous Federated Learning Under Non-IID Settings},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5828--5841},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402149},
	doi = {10.1109/TIFS.2024.3402149},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MiaoKLXLCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To address the challenges posed by data silos and heterogeneity in distributed machine learning, privacy-preserving asynchronous Federated Learning (FL) has been extensively explored in academic and industrial fields. However, existing privacy-preserving asynchronous FL schemes still suffer from the problem of low model accuracy caused by inconsistency between delayed model updates and current model updates, and even cannot adapt well to Non-Independent and Identically Distributed (Non-IID) settings. To address these issues, we propose a Privacy-preserving Asynchronous Federated Learning based on the alternating direction multiplier method (PAFed), which is able to achieve high-accuracy models in Non-IID settings. Specifically, we utilize vector projection techniques to correct the inconsistency between delayed model updates and current model updates, thereby reducing the impact of delayed model updates on the aggregation of current model updates. Additionally, we employ an optimization method based on alternating direction multipliers to adapt the Non-IID settings to further enhance the global model accuracy. Finally, through extensive experiments, we demonstrate that our scheme improves the model accuracy by up to 12.53% when compared with current state-of-the-art solution FedADMM.}
}


@article{DBLP:journals/tifs/ZhangZ24,
	author = {Lingjie Zhang and
                  Hai Zhang},
	title = {Shuffle Private Decentralized Convex Optimization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5842--5851},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3405183},
	doi = {10.1109/TIFS.2024.3405183},
	timestamp = {Tue, 13 Aug 2024 08:07:43 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider the distributed local stochastic gradient descent (SGD) algorithm by parallelizing multiple devices in the setting of stochastic convex optimization (SCO). The losses in the majority of the earlier literatures are required to satisfy Lipschitzness and smoothness, and the privacy leakage may exist in the calculation of gradients. Hence, by incorporating the Hölder smooth loss and the shuffle model of differential privacy (DP) to study the local SGD algorithm in parallel multiple distributed devices, we proposed a distributed learning of local SGD with sequentially interactive shuffle private algorithm (Shuffle-DSGD) under equal intercommunication interval scheme. We provide the privacy guarantees by using advanced composition and shuffle protocol for vector summation. We also analyze the convergence bound of the Shuffle-DSGD and obtain the optimal excess population risk \\mathcal {O}(1/T) up to logarithmic factors with gradient complexity \\mathcal {O}(n) . It turns out that our convergence rate is superior to the one \\mathcal {O}(1/\\sqrt {T}) in the existing work and both of the gradient complexities are consistent. The effectiveness of our algorithms is demonstrated by synthetic and real datasets.}
}


@article{DBLP:journals/tifs/CaiZDXKL24,
	author = {Hanbo Cai and
                  Pengcheng Zhang and
                  Hai Dong and
                  Yan Xiao and
                  Stefanos Koffas and
                  Yiming Li},
	title = {Toward Stealthy Backdoor Attacks Against Speech Recognition via Elements
                  of Sound},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5852--5866},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3404885},
	doi = {10.1109/TIFS.2024.3404885},
	timestamp = {Wed, 11 Dec 2024 17:20:51 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CaiZDXKL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) have been widely and successfully adopted and deployed in various applications of speech recognition. Recently, a few works revealed that these models are vulnerable to backdoor attacks, where the adversaries can implant malicious prediction behaviors into victim models by poisoning their training process. In this paper, we revisit poison-only backdoor attacks against speech recognition. We reveal that existing methods are not stealthy since their trigger patterns are perceptible to humans or machine detection. This limitation is mostly because their trigger patterns are simple noises or separable and distinctive clips. Motivated by these findings, we propose to exploit elements of sound ( e.g ., pitch and timbre) to design more stealthy yet effective poison-only backdoor attacks. Specifically, we insert a short-duration high-pitched signal as the trigger and increase the pitch of remaining audio clips to ‘mask’ it for designing stealthy pitch-based triggers. We manipulate timbre features of victim audio to design the stealthy timbre-based attack and design a voiceprint selection module to facilitate the multi-backdoor attack. Our attacks can generate more ‘natural’ poisoned samples and therefore are more stealthy. Extensive experiments are conducted on benchmark datasets, which verify the effectiveness of our attacks under different settings ( e.g ., all-to-one, all-to-all, clean-label, physical, and multi-backdoor settings) and their stealthiness. Our methods achieve attack success rates of over 95% in most cases and are nearly undetectable. The code for reproducing main experiments are available at https://github.com/HanboCai/BadSpeech_SoE.}
}


@article{DBLP:journals/tifs/ReviriegoALLL24,
	author = {Pedro Reviriego and
                  Jim Apple and
                  David Larrabeiti and
                  Shanshan Liu and
                  Fabrizio Lombardi},
	title = {On the Privacy of Adaptive Cuckoo Filters: Analysis and Protection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5867--5879},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3404868},
	doi = {10.1109/TIFS.2024.3404868},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ReviriegoALLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As probabilistic data structures are widely adopted in computing systems, their privacy is a major issue. Recent works have shown that even though the values stored in these structures look random, information can be extracted from them in some settings. In this paper, we consider the privacy of adaptive cuckoo filters, a probabilistic data structure that implements approximate membership checking. The main novelty and benefit of these filters are that they can adapt to removing false-positives. Unfortunately, our analysis shows that adaptation can dramatically reduce the privacy of the filters, allowing an attacker to extract the set of elements stored in the filter. Indeed, in some settings, the attacker can identify 100% of the elements stored in the filter. This means that the protection of the privacy of adaptive cuckoo filters should be considered. To that end, we propose preprocessing reduction (PR), a scheme that prevents an attacker from extracting the set of elements stored in the filter at the cost of increasing the false-positive probability of the filter. In many settings, the impact on false-positives will be negligible. For example, in a case study with 32-bit universes, the increase in the false-positive probability was smaller than 8% in all the configurations tested. Interestingly, PR is applicable not only to adaptive filters but also to approximate membership check filters in general and thus can be used to protect, for example, Bloom filters.}
}


@article{DBLP:journals/tifs/YangFLLZS24,
	author = {Yulong Yang and
                  Haoran Fan and
                  Chenhao Lin and
                  Qian Li and
                  Zhengyu Zhao and
                  Chao Shen},
	title = {Exploiting the Adversarial Example Vulnerability of Transfer Learning
                  of Source Code},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5880--5894},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402153},
	doi = {10.1109/TIFS.2024.3402153},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangFLLZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {State-of-the-art source code classification models exhibit excellent task transferability, in which the source code encoders are first pre-trained on a source domain dataset in a self-supervised manner and then fine-tuned on a supervised downstream dataset. Recent studies reveal that source code models are vulnerable to adversarial examples, which are crafted by applying semantic-preserving transformations that can mislead the prediction of the victim model. While existing research has introduced practical black-box adversarial attacks, these are often designed for transfer-based or query-based scenarios, necessitating access to the victim domain dataset or the query feedback of the victim system. These attack resources are very challenging or expensive to obtain in real-world situations. This paper proposes the cross-domain attack threat model against the transfer learning of source code where the adversary has only access to an open-sourced pre-trained code encoder. To achieve such realistic attacks, this paper designs the Code Transfer learning Adversarial Example (CodeTAE) method. CodeTAE applies various semantic-preserving transformations and utilizes a genetic algorithm to generate powerful identifiers, thereby enhancing the transferability of the generated adversarial examples. Experimental results on three code classification tasks show that the CodeTAE attack can achieve 30% \\sim ~80\n% attack success rates under the cross-domain cross-architecture setting. Besides, the generated CodeTAE adversarial examples can be used in adversarial fine-tuning to enhance both the clean accuracy and the robustness of the code model. Our code is available at https://github.com/yyl-github-1896/CodeTAE/.}
}


@article{DBLP:journals/tifs/ZhongWSYL24,
	author = {Ying Zhong and
                  Zhiliang Wang and
                  Xingang Shi and
                  Jiahai Yang and
                  Keqin Li},
	title = {{RFG-HELAD:} {A} Robust Fine-Grained Network Traffic Anomaly Detection
                  Model Based on Heterogeneous Ensemble Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5895--5910},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402439},
	doi = {10.1109/TIFS.2024.3402439},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhongWSYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fine-grained attack detection is an important network security task. A large number of machine learning/deep learning(ML/DL) based algorithms have been proposed. However, attacks not present in the training set pose a challenge to the model (open-set problem). Further, ML/DL based models face the problem of adversarial attacks. Despite the large amount of work attempting to address these problems, there are still some challenges as follows. First, the open-set problem in fine-grained attack detection is difficult to solve because there is no effective representation of the distribution of unknown attacks. Second, in the open set environment, how the fine-grained attack detection model resists the adversarial attack is a more difficult problem. For example, the presence of unknown attacks poses a challenge for adversarial defense. For these reasons, we propose the RFG-HELAD model, which consists of a K classification model based on deep neural network (DNN) with contrastive learning (CL), and a $K+1$ classification model combining a generative adversarial networks (GAN) with two discriminators and deep k-nearest neighbors (Deep kNN). Among them, Deep kNN uses latent features from GAN and contrastive learning as input, which is essentially a distance-based out-of-distribution detection algorithm used to determine unknown attacks. The large category of unknown attacks has been added to the K classification, so it is a $K + 1$ classification. To further improve the robustness of the RFG-HELAD model, we perform Fourier transform as well as feature fusion on the features, and also conduct adversarial training on the K classification model. Generative adversarial training of our GAN model can implicitly defend against adversarial attack. Experiments show that our model is superior to other state-of-the-art (SOTA) models in the presence of unknown attacks as well as under adversarial attacks. Especially, our model improves the accuracy by at least 18.7% over the corresponding SOTA model with adversarial defense. Further, we discuss the grounded deployment of the model and demonstrate its feasibility.}
}


@article{DBLP:journals/tifs/LiLXXSL24,
	author = {Meiqi Li and
                  Xinyi Luo and
                  Kaiping Xue and
                  Yingjie Xue and
                  Wentuo Sun and
                  Jian Li},
	title = {A Secure and Efficient Blockchain Sharding Scheme via Hybrid Consensus
                  and Dynamic Management},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5911--5924},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3406145},
	doi = {10.1109/TIFS.2024.3406145},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiLXXSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sharding significantly enhances blockchain scalability by dividing the entire network into smaller shards that reach consensus and process transactions in parallel. Nevertheless, two new issues emerge with the adoption of sharding. One issue involves the shrinking size of consensus groups, which leads to vulnerability in consensus. Most existing works introduce periodic shuffle mechanisms to mitigate this problem. Nevertheless, these measures necessitate stronger security assumptions and can only offer a probabilistic assurance of consensus security. Another issue is the challenge in processing cross-shard transactions posed by the isolation of shards. Existing approaches utilize two-phase commit (2PC) or relay transaction mechanisms to handle cross-shard transactions. However, these approaches are vulnerable to double cross-shard attacks from malicious shards and are unable to achieve immediate atomicity. In this paper, to address the vulnerable consensus issue and achieve instant atomicity in cross-shard transactions, we design a hybrid consensus mechanism that embeds a lightweight global consensus into parallel intra-shard consensus processes. The global consensus allows all consensus nodes to jointly process cross-shard transactions, achieving cross-shard transaction instant atomicity. It also records shard snapshots to facilitate shard auditing to defend against malicious shards. Furthermore, we consider the performance of the proposed mechanism, and design a dynamic shard management mechanism. The dynamic shard management mechanism reduces transaction congestion and maintains an appropriate number of shards based on the system’s state. We conduct analyses of potential attacks and prove that our approach ensures safety and liveness even in the presence of malicious shards. We also evaluate the performance of our system and compare it with both non-sharded and classic blockchain-sharding systems. The evaluation results demonstrate the efficacy of our approach in dealing with transaction congestion while astutely controlling the number of shards.}
}


@article{DBLP:journals/tifs/LiHY24,
	author = {Ronghua Li and
                  Haibo Hu and
                  Qingqing Ye},
	title = {RFTrack: Stealthy Location Inference and Tracking Attack on Wi-Fi
                  Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5925--5939},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3404810},
	doi = {10.1109/TIFS.2024.3404810},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiHY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present RFTrack, a new indoor location inference attack on Wi-Fi devices. This attack differs from existing Wi-Fi localization methods as it does not need bulky appliance deployment or inner physical access to the place of interest. RFTrack distinguishes itself by leveraging the temporal sequence of unlabeled Received Signal Strength Indicator (RSSI) values to deduce location labels. To achieve this, we deploy a Reinforcement Learning (RL) agent to model the most likely path of device movement and utilize these modeled trajectories to construct an RSSI fingerprint map. To enhance the accuracy of trajectory reconstruction, our technique exploits certain stationary Wi-Fi devices within the target area as reference points, facilitating the assessment of whether the mobile devices have traversed near specific zones with a newly proposed metric, the RSSI difference. The experimental results demonstrate that our system can accurately recover the trends of moving trajectories and successfully associate the unlabeled RSSI values with positions inside the place of interest to build a fingerprint map for real-time device tracking.}
}


@article{DBLP:journals/tifs/PengDZYW24,
	author = {Datian Peng and
                  Jianmin Dong and
                  Mingjiang Zhang and
                  Jungang Yang and
                  Zhen Wang},
	title = {CSFAdv: Critical Semantic Fusion Guided Least-Effort Adversarial Example
                  Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5940--5955},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402385},
	doi = {10.1109/TIFS.2024.3402385},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PengDZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extensive studies have revealed that the prevalent deep neural networks (DNNs) are vulnerable to adversarial examples in image recognition tasks. However, previous adversarial example attacks always work in either the global semantic space or local semantic attributes, resulting that these attacks may violate the sophisticated attackers’ least-effort intentions, whereas adversarial perturbations due to the explicit semantic variations are probably perceived by human vision. In this paper, we propose a two-phase optimization modeling framework to devise a novel Critical Semantic Fusion guided least-effort Adversarial example attack (CSFAdv). Specifically, the first phase fuses the coarse-&fine-grained semantic maps to localize the latent critical semantic attention region (CSAR) from genuine image. Under the friendly guidance of CSAR-feasibility, the second phase absorbs the ReLU-penalization,\nL\n0\n-regularization and\nL\n∞\n-limitation to formulate a Top-1&Top-2 misclassification optimization problem, which can characterize the holistic least-effort tampering behaviors embodied in localizing the most critical semantic space, doctoring the least amounts of pixels, injecting the limited amplitudes of perturbations and launching the most readily adversarial attacks. Further, to solve this NP-hard problem mildly, we adapt the gradient renewal by means of merging the momentum (past gradient), present gradient and Hessian (future gradient) to formalize a generalized gradient descent algorithm for generating an optimal adversarial image. Finally, we perform numerical experiments to verify the validity of our CSFAdv against seven types of DNN-based image classifiers on three public ImageNet, MNIST and CIFAR10. Empirical illustrations from ten evaluations indices shed light on the superiority of CSFAdv over eight kinds of state-of-the-art attacks and also offer key clues in reinforcing the DNNs’ robustness.}
}


@article{DBLP:journals/tifs/ChewLSCWL24,
	author = {Chit{-}Jie Chew and
                  Wei{-}Bin Lee and
                  Tzu{-}Li Sung and
                  Ying{-}Chin Chen and
                  Shiuh{-}Jeng Wang and
                  Jung{-}San Lee},
	title = {Lawful Remote Forensics Mechanism With Admissibility of Evidence in
                  Stochastic and Unpredictable Transnational Crime},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5956--5970},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3368888},
	doi = {10.1109/TIFS.2024.3368888},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChewLSCWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional industries rapidly transcend the time and place restrictions of the country according to the technology growth by leaps and bounds over the year. Regrettably, international cybercrime incidents simultaneously explode by 2,400 million from 2020 to 2021. Undoubtedly, the real-time incident response has become the primary subject of incident handling. In this article, we aim to propose lawful remote forensics mechanism for ensuring the optimal protection of potential evidence in stochastic and unpredictable transnational crime. Meanwhile, the entire process can be performed remotely and compliant with legal requirements, such as ISO/IEC and NIST regulations. Specifically, all the procedures can be retroactive based on the design of the chain of custody, which leads to the proof of evidence admissibility. Aside from the security essential confirmation by the formal tools Proverif, AVISPA, and Scyther, simulation results have demonstrated that remote forensics can fulfill the legal requirements and perform excellently in various incident scales.}
}


@article{DBLP:journals/tifs/ShiWHGSWZ24,
	author = {Tairong Shi and
                  Wenling Wu and
                  Bin Hu and
                  Jie Guan and
                  Han Sui and
                  Senpeng Wang and
                  Mengyuan Zhang},
	title = {Dedicated Quantum Attacks on XOR-Type Function With Applications to
                  Beyond-Birthday- Bound MACs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5971--5984},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402970},
	doi = {10.1109/TIFS.2024.3402970},
	timestamp = {Tue, 18 Jun 2024 09:24:47 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShiWHGSWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A lot of work in the field of quantum cryptanalysis is currently devoted to finding applications of Grover-meets-Simon algorithm and its complexity is given in the form of \\mathcal {O} , but research on how to implement the attack efficiently is still insufficient. After all, it is crucial to study quantum attacks in resource-limited situations, according to NIST’s guidance on circuit depth. This work first evaluates the parallelization of Grover-meets-Simon by drawing on the Grover’s parallel approach and shows that as the width increases by 2^{t}(t\\gt 0) , the depth decreases by a factor of \\sqrt {2^{t}} . Further, the first dedicated quantum attack on a class of functions that appear in cryptographic scheme applications (so-called XOR-type function) is proposed. The depth, width, and the number of gates required for the attack are greatly reduced compared to the general parallelization. Then we apply the attack to various Beyond-Birthday-Bound (BBB) MACs, where the XOR function can be constructed, including SUM-ECBC and its variants (2K-SUM-ECBC, 2K-ECBC_Plus), and GCM-SIV2. In the typical case where SUM-ECBC is based on AES-128, our attack saves at least 62.3% in depth, 19.5% in width and 22.2% in gate count simultaneously. The impact on some lightweight ciphers is further explored, and it is interesting to note that the lighter the quantum circuit implementation of the cipher is, the greater the possible impact of an attack will be. This observation may provide new insights into quantum cryptanalysis.}
}


@article{DBLP:journals/tifs/AbdukhamidovATKA24,
	author = {Eldor Abdukhamidov and
                  Mohammed Abuhamad and
                  George K. Thiruvathukal and
                  Hyoungshick Kim and
                  Tamer Abuhmed},
	title = {SingleADV: Single-Class Target-Specific Attack Against Interpretable
                  Deep Learning Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5985--5998},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3407652},
	doi = {10.1109/TIFS.2024.3407652},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AbdukhamidovATKA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Establishing trust and helping experts debug and understand the inner workings of deep learning models, interpretation methods are increasingly coupled with these models, building interpretable deep learning systems. However, adversarial attacks pose a significant threat to public trust by making interpretations of deep learning models confusing and difficult to understand. In this paper, we present a novel Single-class target-specific ADVersarial attack called SingleADV. The goal of SingleADV is to generate a universal perturbation that deceives the target model into confusing a specific category of objects with a target category while ensuring highly relevant and accurate interpretations. The universal perturbation is stochastically and iteratively optimized by minimizing the adversarial loss that is designed to consider both the classifier and interpreter costs in targeted and non-targeted categories. In this optimization framework, ruled by the first- and second-moment estimations, the desired loss surface promotes high confidence and interpretation scores of adversarial samples. By avoiding unintended misclassification of samples from other categories, SingleADV enables more effective targeted attacks on interpretable deep learning systems in both white-box and black-box scenarios. To evaluate the effectiveness of SingleADV, we conduct experiments using four different model architectures (ResNet-50, VGG-16, DenseNet-169, and Inception-V3) coupled with three interpretation models (CAM, Grad, and MASK). Through extensive empirical evaluation, we demonstrate that SingleADV effectively deceives target deep learning models and their associated interpreters under various conditions and settings. Our results show that the performance of SingleADV is effective, with an average attack success rate of 74% and prediction confidence exceeding 77% on successful adversarial samples. Furthermore, we discuss several countermeasures against SingleADV, including a transfer-based learning approach and existing preprocessing defenses.}
}


@article{DBLP:journals/tifs/WangZJW24,
	author = {Songlei Wang and
                  Yifeng Zheng and
                  Xiaohua Jia and
                  Cong Wang},
	title = {eGrass: An Encrypted Attributed Subgraph Matching System With Malicious
                  Security},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {5999--6014},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409089},
	doi = {10.1109/TIFS.2024.3409089},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangZJW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is increasingly common for enterprises/ organizations to outsource graph analytics services to the cloud. For example, enterprises may leverage the cloud to store and query large attributed graphs. Among others, subgraph matching over a large attributed graph is a common and fundamental query functionality for graph analytics. It aims to retrieve all isomorphic subgraphs for a small query graph and greatly benefits various application domains like cheminformatics, social network analysis, and anti-money laundering. Deploying subgraph matching service in the cloud, however, poses a threat to the privacy of the information-rich graph data as the cloud gains access to the attributed graph, query graph, and query result. Given this, several works have been proposed for supporting privacy-aware subgraph matching. However, prior works only consider a weak semi-honest threat model and cannot provide integrity guarantees for the subgraph matching results in case of malicious adversary. In light of this, we design, implement, and evaluate eGrass, a new system enabling maliciously secure attributed subgraph matching service outsourced to the cloud. In addition to offer protection for graph data confidentiality, eGrass is also designed to hide search access patterns as well as defend against malicious cloud server attempting to compromise the result integrity. We conduct extensive experiments on a real-world dataset. The results demonstrate that compared to the state-of-the-art previous protocol with semi-honest security, eGrass is only 3\\times -4.7\\times slower in query latency, uses 3\\times -3.5\\times more communication, and does not require extra cloud-side storage.}
}


@article{DBLP:journals/tifs/WeiWGHS24,
	author = {Jianze Wei and
                  Yunlong Wang and
                  Xingyu Gao and
                  Ran He and
                  Zhenan Sun},
	title = {Multi-Faceted Knowledge-Driven Graph Neural Network for Iris Segmentation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6015--6027},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3407508},
	doi = {10.1109/TIFS.2024.3407508},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WeiWGHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate iris segmentation, especially around the iris inner and outer boundaries, is still a formidable challenge. Pixels within these areas are difficult to semantically distinguish since they have similar visual characteristics and close spatial positions. To tackle this problem, the paper proposes an iris segmentation graph neural network (ISeGraph) for accurate segmentation. ISeGraph regards individual pixels as nodes within the graph and constructs self-adaptive edges according to multi-faceted knowledge, including visual similarity, positional correlation, and semantic consistency for feature aggregation. Specifically, visual similarity strengthens the connections between nodes sharing similar visual characteristics, while positional correlation assigns weights according to the spatial distance between nodes. In contrast to the above knowledge, semantic consistency maps nodes into a semantic space and learns pseudo-labels to define relationships based on label consistency. ISeGraph leverages multi-faceted knowledge to generate self-adaptive relationships for accurate iris segmentation. Furthermore, a pixel-wise adaptive normalization module is developed to increase the feature discriminability. It takes informative features in the shallow layer as a reference to improve the segmentation features from a statistical perspective. Experimental results on three iris datasets illustrate that the proposed method achieves superior performance in iris segmentation, increasing the segmentation accuracy in areas near the iris boundaries.}
}


@article{DBLP:journals/tifs/ZhuLCCCD24,
	author = {Hengye Zhu and
                  Mengxiang Liu and
                  Binbin Chen and
                  Xin Che and
                  Peng Cheng and
                  Ruilong Deng},
	title = {HoneyJudge: {A} {PLC} Honeypot Identification Framework Based on Device
                  Memory Testing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6028--6043},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3407520},
	doi = {10.1109/TIFS.2024.3407520},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuLCCCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of programmable logic controllers (PLCs) in critical infrastructures has given rise to escalating cybersecurity concerns regarding PLC attacks. As a proactive defense mechanism, PLC honeypots emulate genuine controllers to engage adversaries so as to observe their attack tactics and techniques. As part of the arms race between the offense and defense, multiple PLC honeypot identification tools have been developed. However, many existing tools cannot recognize high-fidelity honeypots, since they rely on identifying common network services and fingerprints. In this paper, we propose an innovative and practical honeypot identification framework called HoneyJudge, which goes beyond state-of-the-art (SOTA) network fingerprint-based identification tools like Nmap and the PLCScan tool. HoneyJudge tests the suspected target’s special memory content and features. Specifically, HoneyJudge models the internal memory of a PLC in three categories, from system-level, user-level, to process-level categories, based on which it extracts six representative memory features. All characteristics are acquired through automated network request messages. Then, we design a weighted voting algorithm to combine the test results over different memory features to reach the final conclusion. We validate the effectiveness of HoneyJudge in comparison with several SOTA honeypot identification tools, and the results indicate that the memory-related issues have not been well addressed in existing PLC honeypots and still need substantial research efforts.}
}


@article{DBLP:journals/tifs/GuoMXLW24,
	author = {Dengke Guo and
                  Dongtang Ma and
                  Jun Xiong and
                  Xiaoran Liu and
                  Jibo Wei},
	title = {On the Secret-Key Capacity Over Multipath Fading Channel},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6044--6054},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402392},
	doi = {10.1109/TIFS.2024.3402392},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GuoMXLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secret-key generation (SKG) at physical layer is considered as a promising solution for lightweight key distribution. On the analysis of the secret-key capacity over multipath fading channels, existing studies generally neglect the channel observation method, which has a direct impact on the secret-key capacity. Moreover, there is a lack of concise and interpretable expressions for the secret-key capacity based on the channel state information. Motivated by the above, we analyze the performance of SKG based on MMSE estimation of channel impulse response over multipath fading channels. The general expression of secret-key capacity is derived. We find that the secret-key capacity depends on the estimation signal-to-noise ratios (SNRs) of channel-tap gains. Then, the condensed-parameter expressions of exact secret-key capacity and the expressions of asymptotic secret-key capacity at high SNR are derived in two specific PDP cases. We show that the bandwidth and the transmission SNR determine the upper bound of secret-key capacity over channels with different degrees of freedom for the flat PDP case. In addition, we find that the asymptotic secret-key capacities under these two PDPs follow a uniform form, which is a linear function of the channel estimation SNR (in dB). Finally, we simulate the channel probing process under different transmission and channel parameters and exploit the simulated channel estimates to estimate the secret-key capacity through numerical methods. The simulation results demonstrate the theoretical analysis and conclusions.}
}


@article{DBLP:journals/tifs/ChenWLL24,
	author = {Yijing Chen and
                  Hongxia Wang and
                  Wanjie Li and
                  Wenshan Li},
	title = {A Steganography Immunoprocessing Framework Against CNN-Based and Handcrafted
                  Steganalysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6055--6069},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409075},
	doi = {10.1109/TIFS.2024.3409075},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenWLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Performing post-processing on the stego image has promise for improving the steganography security. Nevertheless, the existing post-processing schemes neglect the characteristics of the stego image, which lack strong theoretical interpretability. Moreover, existing schemes do not fully consider the holistic steganography security against both CNN-based and handcrafted steganalyzers. In this paper, we propose a steganography immunoprocessing (IP) framework based on Artificial Immune System (AIS) that is universal for the stego images from the same steganographic process to further enhance the security. Based on the natural relationship between immune theory and steganography, we regard the immunoprocessing policy as the antibody, and the performance of the anti-steganalysis for stego images protected by antibody as the antibody affinity. By the immune dynamic optimization process, the optimal immunoprocessing policy is dynamically searched and performed on the stego image to achieve further optimization. In addition, we enhance the resistance of the stego against the target CNN-based steganalyzer by limiting the immunoprocessing direction. Performing the optimal immunoprocessing on stego images will enhance the holistic security of steganography. Experimental results demonstrate that the proposed immunoprocessing can significantly improve the holistic security of adaptive steganography against both CNN-based and handcrafted steganalyzers, and achieve better performance than related schemes.}
}


@article{DBLP:journals/tifs/LiLLCSL24,
	author = {Chengxin Li and
                  Saiqin Long and
                  Haolin Liu and
                  Youngjune Choi and
                  Hiroo Sekiya and
                  Zhetao Li},
	title = {Enhancing Sparse Mobile CrowdSensing With Manifold Optimization and
                  Differential Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6070--6083},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3407668},
	doi = {10.1109/TIFS.2024.3407668},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiLLCSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sparse Mobile CrowdSensing (SMCS) effectively lowers sensing costs while maintaining data quality, offering an alternative approach to data collection. Unfortunately, the fact that data contain sensitive information raises serious privacy concerns. Local Differential Privacy (LDP) has emerged as the de facto standard for ensuring data privacy. However, the LDP based on the perturbation concept causes a substantial reduction in the data utility of the SMCS system. To address this problem, we propose a novel scheme named enhancing Sparse mobile crowdsensing With manifold Optimization and differential Privacy (SWOP). Specifically, we first revisit the Gaussian mechanism based on the fact that data utility intervals are ubiquitous in sensing tasks, and introduce a novel perturbation mechanism, namely Truncated Gaussian Mechanism (TGM). Subsequently, we perturb user-collected data by locally injecting noise sampled from TGM and deduce a sufficient condition for the scale parameter to ensure \\epsilon\n-LDP. Furthermore, we model the data inference with privacy-preserving properties as an unconstrained optimization problem on a Riemannian manifold and solve it using the nonlinear conjugate gradient method. Extensive experiments on large-scale real-world and synthetic datasets are conducted to evaluate the proposed scheme. The results demonstrate that SWOP can greatly enhance the utility of data inference while ensuring workers’ data privacy compared to baseline models.}
}


@article{DBLP:journals/tifs/YangXSYLPD24,
	author = {Yang Yang and
                  Wenyi Xue and
                  Jianfei Sun and
                  Guomin Yang and
                  Yingjiu Li and
                  HweeHwa Pang and
                  Robert H. Deng},
	title = {PkT-SIN: {A} Secure Communication Protocol for Space Information Networks
                  With Periodic k-Time Anonymous Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6097--6112},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409070},
	doi = {10.1109/TIFS.2024.3409070},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangXSYLPD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Space Information Network (SIN) enables universal Internet connectivity for any object, even in remote and extreme environments where deploying a cellular network is difficult. Access authentication is crucial for ensuring user access control in SIN and preventing unauthorized entities from gaining access to network services. However, due to the complex communication environment in SIN, including exposed links and higher signal delay, designing a secure and efficient authentication scheme presents a significant challenge. In this paper, we propose a secure communication protocol for SIN with periodic k-time anonymous authentication (named PkT-SIN) that allows satellite users to anonymously authenticate to ground stations at most k times in each single time period. An efficient handover mechanism is designed to ensure seamless communication for satellite users to communicate with different satellites and ground stations, taking into account the dynamic topology of SIN. As a core component of PkT-SIN, we propose a novel primitive, periodic k-time keyed-verification anonymous credential (PkT-KVAC), that enables users to derive k tokens from a credential for anonymous and unlinkable authentication. On the other hand, a verifier can always recognize a reused token from a dishonest user. PkT-KVAC is of independent contribution to anonymous authentication in pay-per-use business scenarios. Formal security proofs confirm that PkT-SIN and PkT-KVAC have desired security features. The supremacy of their computing features is demonstrated through comprehensive comparison and rigorous performance analysis.}
}


@article{DBLP:journals/tifs/ZhangZYCM24,
	author = {Huan Zhang and
                  Lixin Zhao and
                  Aimin Yu and
                  Lijun Cai and
                  Dan Meng},
	title = {Ranker: Early Ransomware Detection Through Kernel-Level Behavioral
                  Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6113--6127},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3410511},
	doi = {10.1109/TIFS.2024.3410511},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZYCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ransomware is a rapidly evolving type of malware crafted to encrypt user files, rendering them inaccessible and demanding a ransom. The impact of ransomware attacks on both enterprises and individuals is significant. However, early detection of such malware remains a formidable challenge with current detection methods. In this paper, we propose Ranker, a real-time approach designed for early ransomware detection through kernel-level behavioral analysis. Analyzing various ransomware families, we discovered that half of these attacks exhibit stealthy behaviors preceding the actual attack. Extracting insights from the pre-attack malicious behavior proves effective for early detection of ransomware. For ransomware families that encrypt files directly, considering that interacting with user files is their goal, our focus is on monitoring file changes during the attack, hoping to detect ransomware when fewer files are lost. Therefore, Ranker systematically characterizes the kernel-level behavior of ransomware during the pre-attack and attack stages, identifying general and essential characteristics. Ranker also introduces a lightweight detector for real-time ransomware detection. Extensive experiments demonstrate that Ranker achieves an average F1 score of 99.43% in ransomware detection, with a mere 0.11% false positives across 68 distinct ransomware families. Notably, Ranker detects 95% of ransomware attacks with no more than one file encrypted and attains a 97.16% accuracy in identifying 22 previously unseen ransomware families.}
}


@article{DBLP:journals/tifs/JingCW24,
	author = {Chao Jing and
                  Chaoyuan Cui and
                  Yun Wu},
	title = {SIa-CBc: Sensitive Intent-Assisted and Crucial Behavior-Cognized Malware
                  Detection Based on Human Brain Cognitive Theory},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6128--6143},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3407655},
	doi = {10.1109/TIFS.2024.3407655},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JingCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {API call sequence-based approaches are proven to have significant superiority in malware detection but generally overlook or evade two core issues: ( i ) ignoring parameters and return values that contain more fine-grained security semantic sensitive information (SSSI) and ( ii ) handling lengthy API call sequences roughly, causing the poor interpretability and incompleteness of program behavior semantics. To effectively overcome these issues, we propose SIa-CBc, a sensitive intent-assisted and crucial behavior-cognized malware detection method leveraging human brain cognitive theory, which consists of two key modules. ( i ) SIa divides the vast and heterogeneous SSSI space into a few categories, meanwhile representing the sensitive intents to assist API calls. ( ii ) CBc extracts crucial snippets from lengthy API call sequences via judgment and multi-step reasoning and further obtains their representations. The embedding representations from the previous two modules are concatenated as the input of ten representative baseline networks. Our experimental results indicate that SIa-CBc achieves an enhancement in malware detection accuracy ranging from 14.08% to 28.01%, reduces the average detection time per sample by 0.28 to 16.29 ms, and improves the defense against adversarial sample attacks by 4.86% to 55.04%. Moreover, SIa-CBc demonstrates outstanding performance compared to recent methods, not only limited to detection but also encompassing enhanced resilience to intricate adversarial tactics, thereby ensuring reliable protection without the need for frequent re-training. This underscores the model’s innovative approach in leveraging human brain cognitive theory-based techniques for heightened security efficacy.}
}


@article{DBLP:journals/tifs/ChenZXW24,
	author = {Liaogehao Chen and
                  Zhenjun Zhang and
                  Yang Xiao and
                  Yaonan Wang},
	title = {{EGST:} An Efficient Solution for Human Gaits Recognition Using Neuromorphic
                  Vision Sensor},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6144--6154},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409167},
	doi = {10.1109/TIFS.2024.3409167},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenZXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional cameras struggle to perform in challenging scenarios such as low latency, high speed and high dynamic range. In contrast, neuromorphic vision sensors (event cameras) have great potential for robotics and computer vision due to the advantages of high temporal resolution, high dynamic range, and ultra-low resource consumption. Event cameras are novel bio-inspired sensors that monitor the brightness change of each pixel asynchronously and provide a stream of events encoding the time, position and sign of the brightness changes. Hence, traditional computer vision methods cannot be directly applied to the event-stream. Finding event representations that completely maintain event attributes, as well as efficient and accurate learning approaches, is the key to unlocking the potential of event cameras. In this study, we reveal the rigid transfer from event-stream to graph that has been overlooked in previous work and introduce a novel event representation, namely event graph sequence (EGS) considering the local and global temporal clues. Coupled with EGS, we propose a spatio-temporal pattern extracting (STPE) module to capture the spatio-temporal correlation and evolution of EGS. Our novel framework, Event Graph Sequence Transformer (EGST), exploits event properties to provide efficient and accurate recognition. This study focuses on the event-based human gaits recognition task, and EGST is evaluated on three different event-based gait datasets. The evaluation results show better or comparable accuracy than the state-of-the-art, while requiring extremely low computation resources. The code will be available at https://github.com/C19h/EGST.}
}


@article{DBLP:journals/tifs/TriznaDBR24,
	author = {Dmitrijs Trizna and
                  Luca Demetrio and
                  Battista Biggio and
                  Fabio Roli},
	title = {Nebula: Self-Attention for Dynamic Malware Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6155--6167},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409083},
	doi = {10.1109/TIFS.2024.3409083},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TriznaDBR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic analysis enables detecting Windows malware by executing programs in a controlled environment and logging their actions. Previous work has proposed training machine learning models, i.e., convolutional and long short-term memory networks, on homogeneous input features like runtime APIs to either detect or classify malware, neglecting other relevant information coming from heterogeneous data like network and file operations. To overcome these issues, we introduce Nebula, a versatile, self-attention Transformer-based neural architecture that generalizes across different behavioral representations and formats, combining diverse information from dynamic log reports. Nebula is composed by several components needed to tokenize, filter, normalize and encode data to feed the transformer architecture. We firstly perform a comprehensive ablation study to evaluate their impact on the performance of the whole system, highlighting which components can be used as-is, and which must be enriched with specific domain knowledge. We perform extensive experiments on both malware detection and classification tasks, using three datasets acquired from different dynamic analyses platforms, show that, on average, Nebula outperforms state-of-the-art models at low false positive rates, with a peak of 12% improvement. Moreover, we showcase how self-supervised learning pre-training matches the performance of fully-supervised models with only 20% of training data, and we inspect the output of Nebula through explainable AI techniques, pinpointing how attention is focusing on specific tokens correlated to malicious activities of malware families. To foster reproducibility, we open-source our findings and models at https://github.com/dtrizna/nebula.}
}


@article{DBLP:journals/tifs/XuWLSJMWH24,
	author = {Shouyin Xu and
                  Yuewu Wang and
                  Lingguang Lei and
                  Kun Sun and
                  Jiwu Jing and
                  Siyuan Ma and
                  Jie Wang and
                  Heqing Huang},
	title = {Condo: Enhancing Container Isolation Through Kernel Permission Data
                  Protection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6168--6183},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3411915},
	doi = {10.1109/TIFS.2024.3411915},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuWLSJMWH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Container technology is widely adopted due to its features such as light weight and ease of rapid deployment. However, as an OS-level virtualization mechanism, container isolation relies on the kernel’s security mechanisms and the kernel permission data (usually non-control flow data) used by these mechanisms. None of the existing mitigation schemes for non-control flow data attacks provide an effective and practical solution to container security since they either trigger too much overhead, have limited effectiveness over attacks launched in specific ways, or can only be used to protect some specific kernel data. In addition, none of them accurately identify the kernel data associated with container isolation. In this paper, we provide a solution called Condo that enhances container isolation by protecting the associated kernel permission data. We first present a generic non-control flow kernel data protection mechanism that protects different types of kernel data uniformly with low overhead and is not limited by attack methods or data types. We then demystify the models of various kernel access control mechanisms in the container environment, and identify the subject and object permission data that are critical to container isolation. Finally, we provide a solution named Condo to enhance container isolation, which is completely transparent to the existing container ecosystem, including containerized applications and container management/orchestration tools such as Docker. Experimental results show that Condo can effectively reduce the compromises of container isolation due to memory corruption attacks with an acceptable overhead.}
}


@article{DBLP:journals/tifs/HuZTAW24,
	author = {Jingwei Hu and
                  Yongjun Zhao and
                  Benjamin Hong Meng Tan and
                  Khin Mi Mi Aung and
                  Huaxiong Wang},
	title = {Enabling Threshold Functionality for Private Set Intersection Protocols
                  in Cloud Computing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6184--6196},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402355},
	doi = {10.1109/TIFS.2024.3402355},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuZTAW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-party computation (MPC) allows parties to interact with cloud-based data and services while maintaining privacy and confidentiality of their private data. As a special case of MPC, private set intersection (PSI) protocols focus on securely computing the intersection between a server and a client of their private set. Our research extends the threshold functionality for PSI within the realm of cloud computing, where the server possesses a larger set than the client. This paper fills this gap by proposing new private intersection cardinality (PSI-CA) protocol, and more broadly, threshold private set intersection (tPSI) protocol using fully homomorphic encryption (FHE). In tPSI protocol, two parties holding two private sets collaboratively compute the intersection and reveal the result if and only if the size of the intersection exceeds some predefined threshold. In this process, no other information, in particular, elements not in the intersection remain hidden. The problem of PSI-CA and tPSI has many applications in online collaboration, e.g., fingerprint matching, online dating, and ride sharing. At a high level, we use FHE to encrypt a Bloom filter (BF) that encodes the small set and homomorphically check whether the elements in the larger set belongs to the small set, e.g., homomorphic membership test. Counting the number of positive membership directly already yields a PSI-CA protocol with optimal asymptotic communication complexity $\\Omega (n) = \\Omega (\\min (N,n))$ , where N (resp. n) is the size of the large (resp. small) set. To construct a tPSI protocol, we develop a novel secret token generation protocol: a shared secret token is generated if and only if the intersection size satisfies the threshold condition, by exploiting the programmable bootstrapping technique in FHE. This new secret token generation protocol, when composed with any standard PSI protocol, yields a tPSI with the same asymptotic communication complexity as the chosen plain PSI. Along the way, we develop specific FHE optimizations that might be of independent interest. These optimizations overcome the weakness of low precision in programmable bootstrapping. As a result, tPSI over relatively large sets can be supported.}
}


@article{DBLP:journals/tifs/SongW24,
	author = {Mi Song and
                  Ding Wang},
	title = {{AB-PAKE:} Achieving Fine-Grained Access Control and Flexible Authentication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6197--6212},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402073},
	doi = {10.1109/TIFS.2024.3402073},
	timestamp = {Thu, 04 Jul 2024 22:02:59 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SongW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Two-factor authentication provides a strong defense against account compromise. However, traditional two-factor authentication schemes cannot provide users with much flexibility and fine-grained authorization. In this work, we present an efficient design of Attribute-Based Password Authenticated Key Exchange (AB-PAKE) protocol, ensuring that only two legitimate users with desired attributes and correct passwords can establish a shared session key. We, for the first time, tackle the problem of “how to enhance a peer-to-peer PAKE scheme by using a storage device (e.g., a smart-phone, a USB token, or a personal computer that the user logs in), such that even if ephemeral secret keys of two participants have been leaked, it still provides user privacy protection and truly two-factor security”. AB-PAKE works well in peer-to-peer (i.e., end-to-end) scenarios where the participants expect to hide their real identity information and the peer is enforced to satisfy the defined conditions (aka authentication policy). It achieves flexibility, privacy preservation, and dynamic access control lacking in prior authentication proposals. In addition, our work mitigates a practical threat in authenticated key exchange schemes, namely, the ephemeral secret leakage attack. We aim to increase the attack difficulty and limit password leakage even if the user’s long-term key or ephemeral key is leaked. The proposed protocol is also round-optimal, i.e., it is a single-round protocol consisting of only two message flows among the parties. Our new construction of AB-PAKE protocol reduces the number of pairing operations to be constant and supports richer policies. Provable security and practicality are demonstrated by comprehensive analysis.}
}


@article{DBLP:journals/tifs/CoccominiKACFPG24,
	author = {Davide Alessandro Coccomini and
                  Giorgos Kordopatis{-}Zilos and
                  Giuseppe Amato and
                  Roberto Caldelli and
                  Fabrizio Falchi and
                  Symeon Papadopoulos and
                  Claudio Gennaro},
	title = {{MINTIME:} Multi-Identity Size-Invariant Video Deepfake Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6084--6096},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409054},
	doi = {10.1109/TIFS.2024.3409054},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CoccominiKACFPG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present MINTIME, a video deepfake detection method that effectively captures spatial and temporal inconsistencies in videos that depict multiple individuals and varying face sizes. Unlike previous approaches that either employ simplistic a-posteriori aggregation schemes, i.e., averaging or max operations, or only focus on the largest face in the video, our proposed method learns to accurately detect spatio-temporal inconsistencies across multiple identities in a video through a Spatio-Temporal Transformer combined with a Convolutional Neural Network backbone. This is achieved through an Identity-aware Attention mechanism that applies a masking operation on the face sequence to process each identity independently, which enables effective video-level aggregation. Furthermore, our system incorporates two novel embedding schemes: (i) the Temporal Coherent Positional Embedding, which encodes the temporal information of the face sequences of each identity, and (ii) the Size Embedding, which captures the relative sizes of the faces to the video frames. MINTIME achieves state-of-the-art performance on the ForgeryNet dataset, with a remarkable improvement of up to 14% AUC in videos containing multiple people. Moreover, it demonstrates very robust generalization capabilities in cross-forgery and cross-dataset settings. The code is publicly available at: https://github.com/davide-coccomini/MINTIME-Multi-Identity-size-iNvariant-TIMEsformer-for-Video-Deepfake-Detection.}
}


@article{DBLP:journals/tifs/VazquezCastroWZ24,
	author = {{\'{A}}ngeles V{\'{a}}zquez{-}Castro and
                  Andreas J. Winter and
                  Hugo Zbinden},
	title = {Quantum Keyless Private Communication With Decoy States for Space
                  Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6213--6224},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3410132},
	doi = {10.1109/TIFS.2024.3410132},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/VazquezCastroWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing demand for secure communication in optical space networks, it is essential to develop physical-layer scalable security solutions. In this context, we present the asymptotic security analysis of a keyless quantum private communication protocol that transmits classical information over quantum states. Different from the previous literature, our protocol sends dummy (decoy) states optimally obtained from the true information to deceive the eavesdropper. We analyze optical on-off keying (OOK) and binary phase shift keying (BPSK) for several detection scenarios. Our protocol significantly improves the protocol without decoy states whenever Bob is at a technological disadvantage with respect to Eve. Our protocol guarantees positive secrecy capacity when the eavesdropper gathers up to 90-99.9% (depending on the detection scenario) of the photon energy that Bob detects, even when Eve is only limited by the laws of quantum mechanics. We apply our results to the design of an optical inter-satellite link (ISL) study case with pointing losses, and introduce a new design methodology whereby the link margin is guaranteed to be secure by our protocol. Hence, our design does not require knowing the eavesdropper’s location and/or channel state: the protocol aborts whenever the channel drops below the secured margin. Our protocol can be implemented with state-of-the-art space-proof technology. Finally, we also show the potential secrecy advantage when using (not yet available) squeezed quantum states technology.}
}


@article{DBLP:journals/tifs/WangBXCXJJ24,
	author = {Yiran Wang and
                  Jing Bai and
                  Zhu Xiao and
                  Zheng Chen and
                  Yong Xiong and
                  Hongbo Jiang and
                  Licheng Jiao},
	title = {AutoSMC: An Automated Machine Learning Framework for Signal Modulation
                  Classification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6225--6236},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3414249},
	doi = {10.1109/TIFS.2024.3414249},
	timestamp = {Wed, 26 Feb 2025 21:07:18 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangBXCXJJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The electromagnetic environments have become more complex with the development of wireless communication technology. Signal modulation classification has attracted extensive attention due to its application in electronic countermeasures and physical layer security threat prevention under complex electromagnetic environments. Excellent classification performance requirements challenge the adaptability of the method and the ability to extract modulation characteristics. This paper proposes an automated machine learning framework, AutoSMC, for signal modulation classification. An adaptive signal augmentation method is proposed to adapt to the network changes during the search process. In order to extract the modulation features effectively, an scalable convolutional random fourier feature block is proposed. Moreover, the initial search space of the framework is given. The Bayesian Optimization is used to drive hyperparameter optimization to achieve AutoSMC and obtain the optimal method state. Great experiments were carried out on RADIOML 2016.10A and RADIOML 2016.10B. Experimental evaluations on these datasets show that our approach AutoSMC achieves state-of-the-art results compared to the most relevant signal modulation classification methods.}
}


@article{DBLP:journals/tifs/ZhengZLZGWSL24,
	author = {Yandong Zheng and
                  Hui Zhu and
                  Rongxing Lu and
                  Songnian Zhang and
                  Yunguo Guan and
                  Fengwei Wang and
                  Jun Shao and
                  Hui Li},
	title = {Secure Similarity Queries Over Vertically Distributed Data via TEE-Enhanced
                  Cloud Computing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6237--6251},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3413630},
	doi = {10.1109/TIFS.2024.3413630},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhengZLZGWSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outsourcing big data to cloud servers has gained prominence, and growing concerns about privacy, alongside privacy-related regulations, underscore the need to encrypt data before sending them to the cloud. Nevertheless, encryption significantly hampers the query capabilities of data, particularly in the case of vertically distributed data. This paper focuses on developing secure and efficient similarity query schemes for vertically distributed data in cloud environments. As is known, current solutions are constrained by limitations in query efficiency, approximate query results, and their ability to support vertical data. To address these issues, we introduce two novel schemes: a Fast Similarity Query Scheme (FSQ) and a Non-interactive Similarity Query Scheme (NoSQ) for outsourced distributed data. In the FSQ scheme, we enhance query efficiency by designing a trusted execution environment (TEE) assisted fast secret sharing (FSS) scheme and a series of FSS-based private algorithms, enabling secure data index construction and fast similarity query processing. For the NoSQ scheme, we eliminate communication overheads by designing a TEE assisted non-interactive secret sharing (NoSS) scheme and a series of NoSS-based private algorithms. Both schemes have undergone rigorous security validation using a simulation-based real/ideal worlds model, and their efficiency has been confirmed through comprehensive experiments.}
}


@article{DBLP:journals/tifs/HanHWL24,
	author = {Ke Han and
                  Yan Huang and
                  Liang Wang and
                  Zikun Liu},
	title = {Self-Supervised Recovery and Guide for Low-Resolution Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6252--6263},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409066},
	doi = {10.1109/TIFS.2024.3409066},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HanHWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Low-resolution person re-identification is a challenging task to match low-resolution (LR) probes with high-resolution (HR) gallery images. To address the resolution gap, existing methods typically recover missing details for LR probes by super-resolution, and then match the recovered HR images (instead of the original LR probes) with gallery images. However, they usually pre-specify fixed scale factors for all LR images, and ignore that choosing a preferable scale factor for each image can recover more discriminative content and accordingly benefit the re-id performance. Moreover, these methods do not focus on learning LR representations themselves and always resort to extra recovery to handle LR probes, which is quite time-consuming during inference. To tackle these problems, we propose a Self-supervised Recovery and Guide (SRG) re-id model in this paper. Given LR images during training, our model first recovers more discriminative HR images by finding out preferable scale factors, and further leverages them as guide to improve original LR representations. By enforcing LR representations to approach the self-recovered HR guide in a self-supervised manner, our model can learn more discriminative representations for LR images. As a result, our model is able to directly handle LR probes without requiring recovery during inference, thereby reducing inference time significantly. Extensive experiments demonstrate the effectiveness of our method on four datasets.}
}


@article{DBLP:journals/tifs/KimSMLNS24,
	author = {Jinwoo Kim and
                  Minjae Seo and
                  Eduard Marin and
                  Seungsoo Lee and
                  Jaehyun Nam and
                  Seungwon Shin},
	title = {Ambusher: Exploring the Security of Distributed {SDN} Controllers
                  Through Protocol State Fuzzing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6264--6279},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402967},
	doi = {10.1109/TIFS.2024.3402967},
	timestamp = {Fri, 06 Dec 2024 11:52:26 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KimSMLNS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed SDN (Software-Defined Networking) controllers have rapidly become an integral element of Wide Area Networks (WAN), particularly within SD-WAN, providing scalability and fault-tolerance for expansive network infrastructures. However, the architecture of these controllers introduces new potential attack surfaces that have thus far received inadequate attention. In response to these concerns, we introduce Ambusher, a testing tool designed to discover vulnerabilities within protocols used in distributed SDN controllers. Ambusher achieves this by leveraging protocol state fuzzing, which systematically finds attack scenarios based on an inferred state machine. Since learning states from a cluster is complicated, Ambusher proposes a novel methodology that extracts a single and relatively simple state machine, achieving efficient state-based fuzzing. Our evaluation of Ambusher, conducted on a real SD-WAN deployment spanning two campus networks and one enterprise network, illustrates its ability to uncover 6 potential vulnerabilities in the widely used distributed controller platform.}
}


@article{DBLP:journals/tifs/WangQLXF24,
	author = {Qizao Wang and
                  Xuelin Qian and
                  Bin Li and
                  Xiangyang Xue and
                  Yanwei Fu},
	title = {Exploring Fine-Grained Representation and Recomposition for Cloth-Changing
                  Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6280--6292},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3414667},
	doi = {10.1109/TIFS.2024.3414667},
	timestamp = {Tue, 01 Oct 2024 17:31:10 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangQLXF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloth-changing person Re-IDentification (Re-ID) is a particularly challenging task, suffering from two limitations of inferior discriminative features and limited training samples. Existing methods mainly leverage auxiliary information to facilitate identity-relevant feature learning, including soft-biometrics features of shapes or gaits, and additional labels of clothing. However, this information may be unavailable in real-world applications. In this paper, we propose a novel FIne-grained Representation and Recomposition (FIRe2) framework to tackle both limitations without any auxiliary annotation or data. Specifically, we first design a Fine-grained Feature Mining (FFM) module to separately cluster images of each person. Images with similar so-called fine-grained attributes (e.g., clothes and viewpoints) are encouraged to cluster together. An attribute-aware classification loss is introduced to perform fine-grained learning based on cluster labels, which are not shared among different people, promoting the model to learn identity-relevant features. Furthermore, to take full advantage of fine-grained attributes, we present a Fine-grained Attribute Recomposition (FAR) module by recomposing image features with different attributes in the latent space. It significantly enhances robust feature learning. Extensive experiments demonstrate that FIRe2 can achieve state-of-the-art performance on five widely-used cloth-changing person Re-ID benchmarks. The code is available at https://github.com/QizaoWang/FIRe-CCReID.}
}


@article{DBLP:journals/tifs/WangWWLZZZ24,
	author = {Yajie Wang and
                  Yi Wu and
                  Shangbo Wu and
                  Ximeng Liu and
                  Wanlei Zhou and
                  Liehuang Zhu and
                  Chuan Zhang},
	title = {Boosting the Transferability of Adversarial Attacks With Frequency-Aware
                  Perturbation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6293--6304},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3411921},
	doi = {10.1109/TIFS.2024.3411921},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangWWLZZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) are vulnerable to adversarial examples, with transfer attacks in black-box scenarios posing a severe real-world threat. Adversarial perturbation is often globally manipulated image disturbances crafted in the spatial domain, leading to perceptible noise due to overfitting to the source model. Both the human visual system (HVS) and DNNs (endeavoring to mimic HVS behavior) exhibit unequal sensitivity to different frequency components of an image. In this paper, we intend to exploit this characteristic to create frequency-aware perturbation. Concentrating adversarial perturbations on components within images that contribute more significantly to model inference to enhance the performance of transfer attacks. We devise a systematic approach to select and constrain adversarial optimization in a subset of frequency components that are more critical to model prediction. Specifically, we measure the contributions of each individual frequency component and devise a scheme to concentrate adversarial optimization on these important frequency components, thereby creating frequency-aware perturbations. Our approach confines perturbations within model-agnostic critical frequency components, significantly reducing overfitting to the source model. Our approach can be seamlessly integrated with existing state-of-the-art attacks. Experiments demonstrate that while concentrating perturbation within selected frequency components yields a smaller perturbation magnitude overall, our approach does not sacrifice adversarial effectiveness. Conversely, our frequency-aware perturbation manifests superior performance, boosting imperceptibility, transferability, and evasion against various defenses.}
}


@article{DBLP:journals/tifs/WangSD24,
	author = {Yuwei Wang and
                  Li Sun and
                  Qinghe Du},
	title = {Multi-Antenna Signal Masking and Round-Trip Transmission for Privacy-Preserving
                  Wireless Sensing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6305--6320},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3414185},
	doi = {10.1109/TIFS.2024.3414185},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangSD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the openness of wireless medium and the public structure of pilot signals, wireless sensing procedure is vulnerable to eavesdropping, which causes privacy concerns. In this paper, a novel physical layer obfuscation solution termed as multi-antenna signal masking is proposed to realize privacy-preserving sensing. The privacy protection is realized via controlling the phase difference between the sensing signals of different antennas. Considering the fact that the channel state information (CSI) variation caused by changes of the physical environment typically slowly varies with time, the phase difference is designed as a slowly-varying function with temporal-correlation such that the real variation pattern in CSI is masked and the eavesdropper is thus unable to perform sensing based on the measured CSI. Furthermore, we also devise a round-trip transmission method to avoid secret information exchange between legitimate users, hence realizing privacy-protection without additional overhead. Simulation results demonstrate the superiority of the proposed method in terms of sensing accuracy and privacy-protection capability compared with existing works.}
}


@article{DBLP:journals/tifs/MaoYYZ24,
	author = {Yunlong Mao and
                  Zhujing Ye and
                  Xinyu Yuan and
                  Sheng Zhong},
	title = {Secure Model Aggregation Against Poisoning Attacks for Cross-Silo
                  Federated Learning With Robustness and Fairness},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6321--6336},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3416042},
	doi = {10.1109/TIFS.2024.3416042},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MaoYYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is a promising approach for participants’ collaborative learning tasks with cross-silo data. Participants benefit from FL since heterogeneous data can contribute to the generalization of the global model while keeping private data locally. However, practical issues of FL, such as security and fairness, keep emerging, impeding its further development. One of the most threatening security issues is the poisoning attack, corrupting the global model by an adversary’s will. Recent studies have demonstrated that elaborate model poisoning attacks can breach the existing Byzantine-robust FL solutions. Although various defenses have been proposed to mitigate poisoning attacks, participants will sacrifice learning performance and fairness due to strict regulations. Considering that the importance of fairness is no less than security, it is crucial to explore alternative solutions that can secure FL while ensuring both robustness and fairness. This paper introduces a robust and fair model aggregation solution, Romoa-AFL, for cross-silo FL in an agnostic data setting. Unlike a previous study named Romoa and other similarity-based solutions, Romoa-AFL ensures robustness against poisoning attacks and learning fairness in agnostic FL, which has no assumptions of participants’ data distributions and the server’s auxiliary dataset.}
}


@article{DBLP:journals/tifs/ZhangLLCC24,
	author = {Zihou Zhang and
                  Jiangtao Li and
                  Yufeng Li and
                  Chenhong Cao and
                  Zhenfu Cao},
	title = {Hardware Secure Module Based Lightweight Conditional Privacy-Preserving
                  Authentication for VANETs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6337--6350},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3412418},
	doi = {10.1109/TIFS.2024.3412418},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLLCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The security and privacy challenges faced by Vehicular Ad hoc Networks (VANETs) have led to the development of conditional privacy-preserving authentication (CPPA) schemes. Hardware security modules (HSMs) are seen as a promising solution for implementing these schemes while minimizing the burden on certificate storage. However, existing HSM-based CPPA schemes still have high computation overhead and do not meet the forward security requirements for system secret key (SSK) updates. To address these challenges, we propose an HSM-based lightweight CPPA scheme for VANETs that enjoy low computation costs. Most operations could be performed within the HSM before the message is ready to be signed, reducing real-time computation delay. The scheme also supports SSK updating using an identity-based batch multi-signature algorithm, which helps to provide forward security and vehicle revocation. Especially, the proposed SSK update scheme does not rely on any single trusted authority. Formal proof demonstrates that the proposed scheme satisfies the desired security notions. Our analysis shows that this scheme surpasses other similar ones in terms of efficiency when it comes to generating signatures.}
}


@article{DBLP:journals/tifs/HuCCMD24,
	author = {Mengdi Hu and
                  Lanxiang Chen and
                  Gaolin Chen and
                  Yi Mu and
                  Robert H. Deng},
	title = {A Pruned Pendant Vertex Based Index for Shortest Distance Query Under
                  Structured Encrypted Graph},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6351--6363},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3414156},
	doi = {10.1109/TIFS.2024.3414156},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuCCMD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The shortest distance query is used to determine the shortest distance between two vertices. Various graph encryption schemes have been proposed to achieve accurate, efficient and secure shortest distance queries for encrypted graphs. However, the majority of these schemes are inefficient or lack scalability due to the time-consuming index construction and large index storage. Moreover, none of them consider the trade-off between query efficiency and accuracy. To better trade off the query efficiency and accuracy, we propose a Pruned Pendant Vertex based Index for Shortest Distance Query ( \\mathsf { PPVI} - \\mathsf { SDQ} ) under structured encryption. The proposed scheme utilizes the structured encryption technique to encrypt a graph and build indexes. The main idea is to use the recursive method to repeatedly prune the pendant vertex, and thereby reducing the index size and construction time by minimizing the redundant data storage and graph traversal. The proposed scheme achieves accurate, efficient and secure shortest distance query with privacy-preserving for encrypted graph. The security analysis demonstrates that the proposed scheme satisfies CQA2-security. Experimental results with real datasets show that the scheme achieves the optimal accuracy and efficiency.}
}


@article{DBLP:journals/tifs/GaoLGLXW24,
	author = {Yinghua Gao and
                  Yiming Li and
                  Xueluan Gong and
                  Zhifeng Li and
                  Shu{-}Tao Xia and
                  Qian Wang},
	title = {Backdoor Attack With Sparse and Invisible Trigger},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6364--6376},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3411936},
	doi = {10.1109/TIFS.2024.3411936},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GaoLGLXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) are vulnerable to backdoor attacks, where the adversary manipulates a small portion of training data such that the victim model predicts normally on the benign samples but classifies the triggered samples as the target class. The backdoor attack is an emerging yet threatening training-phase threat, leading to serious risks in DNN-based applications. In this paper, we revisit the trigger patterns of existing backdoor attacks. We reveal that they are either visible or not sparse and therefore are not stealthy enough. More importantly, it is not feasible to simply combine existing methods to design an effective sparse and invisible backdoor attack. To address this problem, we formulate the trigger generation as a bi-level optimization problem with sparsity and invisibility constraints and propose an effective method to solve it. The proposed method is dubbed sparse and invisible backdoor attack (SIBA). We conduct extensive experiments on benchmark datasets under different settings, which verify the effectiveness of our attack and its resistance to existing backdoor defenses. The codes for reproducing main experiments are available at https://github.com/YinghuaGao/SIBA.}
}


@article{DBLP:journals/tifs/ZhouCYCH24,
	author = {Yuyang Zhou and
                  Guang Cheng and
                  Shui Yu and
                  Zongyao Chen and
                  Yujia Hu},
	title = {MTDroid: {A} Moving Target Defense-Based Android Malware Detector
                  Against Evasion Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6377--6392},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3414339},
	doi = {10.1109/TIFS.2024.3414339},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouCYCH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) has been widely adopted for Android malware detection to deal with serious threats brought by explosive malware attacks. However, it has been recently proven that ML-based detection systems exhibit inherent vulnerabilities to evasion attacks, which inject adversarial perturbations into a malicious app to hide its malicious behaviors and evade detection. To date, researchers have not found effective solutions for this critical problem. Although there are some similar works in the image classification field, most of those ideas cannot be borrowed due to the significant differences between images and Android apps. In this paper, we exploit Moving Target Defense (MTD) to continually change the attack surface of the protected detector and create uncertainty on the attacker side. We thus propose a novel Android malware detection framework named MTDroid, which fully leverages a seamless blend of dynamicity, diversity, and heterogeneity to mitigate the impact of evasion attacks. To this end, we develop a dynamic model pool to decrease the exposure time of a single classifier, by building and rebuilding multiple heterogeneous models with distinct data. We then generate diversified variant models to provide defensive measures against various attacks, and further improve robustness through ensemble learning. Specifically, we propose a two-stage selection algorithm to optimize the ensemble learning process, and design a hybrid update strategy to refresh the framework dynamically. The experimental results show that MTDroid significantly enhances the robustness against a wide range of attacks and outperforms the state-of-the-art methods upon three popular practical datasets.}
}


@article{DBLP:journals/tifs/ZhangYTM24,
	author = {Zhenyong Zhang and
                  Kedi Yang and
                  Youliang Tian and
                  Jianfeng Ma},
	title = {An Anti-Disguise Authentication System Using the First Impression
                  of Avatar in Metaverse},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6393--6408},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3410527},
	doi = {10.1109/TIFS.2024.3410527},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangYTM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metaverse is a vast virtual world parallel to the physical world, where the user acts as an avatar to enjoy various services that break through the temporal and spatial limitations of the physical world. Metaverse allows users to create arbitrary digital appearances as their own avatars by which an adversary may disguise his/her avatar to fraud others. In this paper, we propose an anti-disguise authentication method that draws on the idea of the first impression from the physical world to recognize an old friend. Specifically, the first meeting scenario in the metaverse is stored and recalled to help the authentication between avatars. To prevent the adversary from replacing and forging the first impression, we construct a chameleon-based signcryption mechanism and design a ciphertext authentication protocol to ensure the public verifiability of encrypted identities. The security analysis shows that the proposed signcryption mechanism meets not only the security requirement but also the public verifiability. Besides, the ciphertext authentication protocol has the capability of defending against the replacing and forging attacks on the first impression. Extensive experiments show that the proposed avatar authentication system is able to achieve anti-disguise authentication at a low storage consumption on the blockchain.}
}


@article{DBLP:journals/tifs/LuLH24,
	author = {Zefeng Lu and
                  Ronghao Lin and
                  Haifeng Hu},
	title = {Mind the Inconsistent Semantics in Positive Pairs: Semantic Aligning
                  and Multimodal Contrastive Learning for Text-Based Pedestrian Search},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6409--6424},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3417251},
	doi = {10.1109/TIFS.2024.3417251},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Aiming at retrieving pedestrian images based on a provided textual description query, Text-Based Pedestrian Search (TBPS) has gained attention due to its implications in public security tasks such as suspect tracking. Nevertheless, the modality discrepancies between textual descriptions and visual images pose a challenge in aligning semantic information between these two modalities. Moreover, the text description annotated on a particular pedestrian image may not align with the content of other images sharing the same identity, due to variations in viewpoint. These text-image pairs exhibiting inconsistent semantics, termed weak positive pairs, have a discernible impact on the model’s performance. To address these challenges, we propose a Semantic Aligning and Multimodal Contrastive learning (SAMC) model to capture cross-modality identity-invariant features, including three modules: Multi-modality Features Fusion (MFF), Semantic-aligning Optimal Transport (SOT), and Multi-modality Contrastive Learning (MCL). Firstly, the MFF is designed to fuse textual and visual information and extract identity-discriminative multimodal features using self- and cross-attention mechanisms. The multimodal features act as anchors, bridging the gap between the two modalities and enhancing the identity-invariance of unimodal features. Secondly, the SOT is designed to address the semantic misalignment issue between textual descriptions and visual images. Utilizing the Optimal Transport (OT) theory, SOT encourages high features similarity between positive samples from different modalities, thereby exploring semantic relationships between image and text data without requiring extra supervised labels. Lastly, the MCL is introduced to narrow the modality gap, compelling two unimodal features towards the identity-discriminative multimodal features through contrastive learning. Different temperature coefficients are employed for strong and weak positive pairs to mitigate the inconsistency in text-image pair correlation. The effectiveness of SAMC is validated by extensive comprehensive experiments on three TBPS datasets.}
}


@article{DBLP:journals/tifs/LiZSLCTLY24,
	author = {Shiyu Li and
                  Yuan Zhang and
                  Yaqing Song and
                  Hongbo Liu and
                  Nan Cheng and
                  Dahai Tao and
                  Hongwei Li and
                  Kan Yang},
	title = {Beyond Security: Achieving Fairness in Mailmen-Assisted Timed Data
                  Delivery},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6425--6440},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3416049},
	doi = {10.1109/TIFS.2024.3416049},
	timestamp = {Wed, 11 Dec 2024 17:20:51 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiZSLCTLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Timed data delivery is a critical service for time-sensitive applications that allows a sender to deliver data to a recipient, but only be accessible at a specific future time. This service is typically accomplished by employing a set of mailmen to complete the delivery mission. While this approach is commonly used, it is vulnerable to attacks from realistic adversaries, such as a greedy sender (who accesses the delivery service without paying the service charge) and malicious mailmen (who release the data prematurely without being detected). Although some research works have been done to address these adversaries, most of them fail to achieve fairness. In this paper, we formally define the fairness requirement for mailmen-assisted timed data delivery and propose a practical scheme, dubbed DataUber, to achieve fairness. DataUber ensures that honest mailmen receive the service charge, lazy mailmen do not receive the service charge, and malicious mailmen are punished. Specifically, DataUber consists of two key techniques: 1) a new cryptographic primitive, i.e., Oblivious and Verifiable Threshold Secret Sharing (OVTSS), enabling a dealer to distribute a secret among multiple participants in a threshold and verifiable way without knowing any one of the shares; and 2) a smart-contract-based complaint mechanism, allowing anyone to become a reporter to complain about a mailman’s misbehavior to a smart contract and receive a reward. Furthermore, we formally prove the security of DataUber and demonstrate its practicality through a prototype implementation.}
}


@article{DBLP:journals/tifs/WuCFHZRXLX24,
	author = {Cong Wu and
                  Jing Chen and
                  Qianru Fang and
                  Kun He and
                  Ziming Zhao and
                  Hao Ren and
                  Guowen Xu and
                  Yang Liu and
                  Yang Xiang},
	title = {Rethinking Membership Inference Attacks Against Transfer Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6441--6454},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3413592},
	doi = {10.1109/TIFS.2024.3413592},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuCFHZRXLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transfer learning, successful in knowledge translation across related tasks, faces a substantial privacy threat from membership inference attacks (MIAs). These attacks, despite posing significant risk to ML model’s training data, remain limited-explored in transfer learning. The interaction between teacher and student models in transfer learning has not been thoroughly explored in MIAs, potentially resulting in an under-examined aspect of privacy vulnerabilities within transfer learning. In this paper, we propose a new MIA vector against transfer learning, to determine whether a specific data point was used to train the teacher model while only accessing the student model in a white-box setting. Our method delves into the intricate relationship between teacher and student models, analyzing the discrepancies in hidden layer representations between the student model and its shadow counterpart. These identified differences are then adeptly utilized to refine the shadow model’s training process and to inform membership inference decisions effectively. Our method, evaluated across four datasets in diverse transfer learning tasks, reveals that even when an attacker only has access to the student model, the teacher model’s training data remains susceptible to MIAs. We believe our work unveils the unexplored risk of membership inference in transfer learning.}
}


@article{DBLP:journals/tifs/ElsayedKF24,
	author = {Ahmed Abd Elaziz Elsayed and
                  Hadi Khani and
                  Hany Essa Zidan Farag},
	title = {A Feasibility Area Approach for Early Stage Detection of Stealthy
                  Infiltrated Cyberattacks in Power Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6455--6470},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420075},
	doi = {10.1109/TIFS.2024.3420075},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ElsayedKF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced stealthy cyberattacks are capable of infiltrating the cybersecurity layers of power grids and alter their operating conditions, resulting in adverse effects on the system performance. Detecting such Stealthy Infiltrated Cyberattacks (SICA) at the earliest opportunity becomes crucial in order to enable power system operators to implement appropriate corrective measures. To that end, this paper proposes the addition of a new cybersecurity layer for SICA after they have broken through existing cyberattack prevention layers. The paper develops the Feasibility Area (FA) as a classifier mechanism to detect SICA in the collected data of Power System State Variables (PSSV). The proposed detection layer consists of two computational stages. The first stage involves estimating the FA parameters through a historical window of data over a specified period of time, which is then inputted to the second stage. In the second stage, the position of each PSSV with respect to the estimated FA is assessed and utilized by the SICA detection mechanism to identify broken through attacks. A flag vector is created indicating the location of each PSSV with respect to the defined FA. The location of each PSSV and its pattern represented in the flag vector are utilized to identify the existence of SICA. Various SICA detection mechanisms using mathematical techniques and the Pattern Recognition Neural Network (PRNN) have been applied. The numerical results from the evaluation of the proposed FA approach demonstrate a promising performance in detecting the SICA using the proposed method.}
}


@article{DBLP:journals/tifs/MiaoDDH24,
	author = {Yunqi Miao and
                  Jiankang Deng and
                  Guiguang Ding and
                  Jungong Han},
	title = {Confidence-Guided Centroids for Unsupervised Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6471--6483},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3414310},
	doi = {10.1109/TIFS.2024.3414310},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MiaoDDH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised person re-identification (ReID) aims to train a feature extractor for identity retrieval without exploiting identity labels. Due to the no-reference trust in imperfect clustering results, the learning is inevitably misled by unreliable pseudo labels. Albeit the pseudo label refinement has been investigated by previous works, they generally leverage auxiliary information such as camera IDs and body part predictions. This work explores the internal characteristics of clusters to refine pseudo labels. To this end, Confidence-Guided Centroids (CGC) are proposed to provide reliable cluster-wise prototypes for feature learning. Since samples with high confidence are exclusively involved in the formation of centroids, the identity information of low-confidence samples, i.e., boundary samples, are NOT likely to contribute to the corresponding centroid. Given the new centroids, the current learning scheme, where samples are forced to learn from their assigned centroids solely, is unwise. To remedy the situation, we propose to use Confidence-Guided pseudo Label (CGL), which enables samples to approach not only the originally assigned centroid but also other centroids that are potentially embedded with their identity information. Empowered by confidence-guided centroids and labels, our method yields comparable performance with, or even outperforms, state-of-the-art pseudo label refinement works that largely leverage auxiliary information.}
}


@article{DBLP:journals/tifs/GaoZWZWLT24,
	author = {Haoran Gao and
                  Hua Zhang and
                  Jiahui Wang and
                  Xin Zhang and
                  Huawei Wang and
                  Wenmin Li and
                  Tengfei Tu},
	title = {{NUAT-GAN:} Generating Black-Box Natural Universal Adversarial Triggers
                  for Text Classifiers Using Generative Adversarial Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6484--6498},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3416849},
	doi = {10.1109/TIFS.2024.3416849},
	timestamp = {Sat, 27 Jul 2024 13:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GaoZWZWLT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent works have demonstrated that text classifiers are vulnerable to universal adversarial triggers (UATs), which are concatenated to any original text from the dataset to mislead text classifiers. Existing methods for generating UATs are limited to a white-box setting, where the adversary needs access to the gradient information about the target model. In the more practical black-box setting, the adversary can only access the logit output of the target model, which increases the difficulty of crafting UATs. In this paper, we propose a framework for generating natural UATs using generative adversarial networks (NUAT-GAN) in the black-box setting. To update parameters of the generator in the black-box setting, we design a training generator algorithm with policy gradient (TGPG), in which the gradient of the target model is replaced with the policy gradient of reinforcement learning. On three text classification datasets, we evaluate the attack and the natural performance of UATs generated on LSTM, CNN and BERT models. Results show that UATs generated by NUAT-GAN can mislead the above models. The average values of the Attack Success Rate (ASR) and GPT-2 Loss of UATs are 0.81 and 9.10, respectively. The UATs can effectively attack online models, such as AllenNLP and ChatGPT. Moreover, we replace the reward given by the discriminator with GPT-2 Loss, the attack and the natural performance of UATs are close to those of NUAT-GAN. This shows that NUAT-GAN is extensible and can combined with the language model.}
}


@article{DBLP:journals/tifs/XiaoHCLS24,
	author = {Meiyan Xiao and
                  Qiong Huang and
                  Wenya Chen and
                  Chuan Lyu and
                  Willy Susilo},
	title = {Domain-Specific Fine-Grained Access Control for Cloud-Edge Collaborative
                  IoT},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6499--6513},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3419716},
	doi = {10.1109/TIFS.2024.3419716},
	timestamp = {Fri, 19 Jul 2024 23:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XiaoHCLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cloud-edge collaborative data sharing supporting data confidentiality can be realized by adopting outsourced Attribute-Based Encryption (ABE) schemes. Yet, most existing schemes in such kind of scenarios are facing challenges such as vulnerable terminal devices that are easy to be attacked, lack of flexible authorization management methods for a large number of devices, and lack methods to securely specify on-demand data sharing domains. In this paper, we propose a Domain-specific On-demand Access Control scheme with fully Independent Revocation (DOACIR), which not only realizes a three-layer on-demand data sharing framework for cloud-edge collaborative IoT environments but also allows data uploader to restrict the data sharing domain through a succinct way. The attribute authority and multiple edge servers perform data access authorization collaboratively to improve the data sharing efficiency as well as avoid the key-abuse problem and key-leakage problem. Fully independent user revocation is also realized in DOACIR to flexibly manage terminal devices in IoT. Further, we improve the scheme to support cross-domain data sharing, namely Cross-Domain DOACIR (CD-DOACIR), by improving the encryption phase allowing data uploader to specify any number of sharing domains while the size of ciphertext remains constant. We provide the security proofs of DOACIR and CD-DOACIR, and the experiment results demonstrate the effectiveness and efficiency of our solutions in cloud-edge collaborative on-demand data sharing.}
}


@article{DBLP:journals/tifs/NamTL24,
	author = {Seung{-}Hyun Nam and
                  Vincent Y. F. Tan and
                  Si{-}Hyeon Lee},
	title = {Optimal Private Discrete Distribution Estimation With 1-bit Communication},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6514--6528},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3419721},
	doi = {10.1109/TIFS.2024.3419721},
	timestamp = {Fri, 19 Jul 2024 23:16:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NamTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a private discrete distribution estimation problem with one-bit communication constraint. The privacy constraints are imposed with respect to the local differential privacy and the maximal leakage. The estimation error is quantified by the worst-case mean squared error. We completely characterize the first-order asymptotics of this privacy-utility trade-off under the one-bit communication constraint for both types of privacy constraints by using ideas from local asymptotic normality and the resolution of a block design mechanism. These results demonstrate the optimal dependence of the privacy-utility trade-off under the one-bit communication constraint in terms of the parameters of the privacy constraint and the size of the alphabet of the discrete distribution.}
}


@article{DBLP:journals/tifs/LiCXLL24,
	author = {Bin Li and
                  Jincheng Chen and
                  Yuxiong Xu and
                  Weixiang Li and
                  Zhenghui Liu},
	title = {{DRAW:} Dual-Decoder-Based Robust Audio Watermarking Against Desynchronization
                  and Replay Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6529--6544},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3416047},
	doi = {10.1109/TIFS.2024.3416047},
	timestamp = {Sun, 06 Oct 2024 21:41:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiCXLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Digital watermarking is a widely adopted authentication technique and one of its primary concerns in practical usage is robustness. However, existing audio watermarking methods face challenges in countering desynchronization attacks and replay attacks, which can easily lead to watermark extraction failure. In this paper, we introduce a learning-based scheme, named DRAW (Dual-decoder-based Robust Audio Watermarking), to overcome the robustness issue. Specifically, a watermark encoder embeds payloads together with synch codes into audio frames with high imperceptibility. For reliable watermark extraction, two separate decoders are designed, one for Fixed Length Synchronization Decoding (FLSD) and the other for Variable Length Payload Decoding (VLPD). The dual decoders are trained with the encoder with different weights in the loss function by considering their different roles for watermark extraction. To better resist attacks, a distortion layer is incorporated in-between the encoder and the decoders to simulate distortion and facilitate end-to-end learning. For the more challenging replay attacks, a pre-trained Replay Attack Simulation Network (RASN) is applied to simplify the simulation of re-recording with background noise and reverberation. Extensive experimental results show that the proposed method can be applied to variable-length audio clips with better auditory quality, and it outperforms state-of-the-art methods in robustness against various kinds of attacks.}
}


@article{DBLP:journals/tifs/MengYYYSK24,
	author = {Ruohan Meng and
                  Chenyu Yi and
                  Yi Yu and
                  Siyuan Yang and
                  Bingquan Shen and
                  Alex C. Kot},
	title = {Semantic Deep Hiding for Robust Unlearnable Examples},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6545--6558},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3421273},
	doi = {10.1109/TIFS.2024.3421273},
	timestamp = {Tue, 12 Nov 2024 13:34:49 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MengYYYSK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ensuring data privacy and protection has become paramount in the era of deep learning. Unlearnable examples are proposed to mislead the deep learning models and prevent data from unauthorized exploration by adding small perturbations to data. However, such perturbations (e.g., noise, texture, color change) predominantly impact low-level features, making them vulnerable to common countermeasures. In contrast, semantic images with intricate shapes have a wealth of high-level features, making them more resilient to countermeasures and potential for producing robust unlearnable examples. In this paper, we propose a Deep Hiding (DH) scheme that adaptively hides semantic images enriched with high-level features. We employ an Invertible Neural Network (INN) to invisibly integrate predefined images, inherently hiding them with deceptive perturbations. To enhance data unlearnability, we introduce a Latent Feature Concentration module, designed to work with the INN, regularizing the intra-class variance of these perturbations. To further boost the robustness of unlearnable examples, we design a Semantic Images Generation module that produces hidden semantic images. By utilizing similar semantic information, this module generates similar semantic images for samples within the same classes, thereby enlarging the inter-class distance and narrowing the intra-class distance. Extensive experiments on CIFAR-10, CIFAR-100, and an ImageNet subset, against 18 countermeasures, reveal that our proposed method exhibits outstanding robustness for unlearnable examples, demonstrating its efficacy in preventing unauthorized data exploitation.}
}


@article{DBLP:journals/tifs/SuNHL24,
	author = {Wenkang Su and
                  Jiangqun Ni and
                  Xianglei Hu and
                  Bin Li},
	title = {Efficient Audio Steganography Using Generalized Audio Intrinsic Energy
                  With Micro-Amplitude Modification Suppression},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6559--6572},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3417268},
	doi = {10.1109/TIFS.2024.3417268},
	timestamp = {Fri, 19 Jul 2024 23:16:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SuNHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in content-adaptive Audio Steganography in Temporal Domain (ASTD) suggest that modification of micro-amplitude samples may compromise its security. To prevent the micro-amplitude samples from being modified, a targeted Large Amplitude First (LAF) rule was adopted in some audio steganographic schemes, e.g., DFR. However, it is observed that the results with LAF rule are often unstable across different datasets, we thus propose a new Micro-Amplitude Suppression (MAS) rule in this paper following the design philosophy of wet paper coding. Unlike DFR where the audio steganographic performance heavily depends on the adopted heuristic filters, we propose to evaluate the embedding cost of cover audio with the Generalized Audio Intrinsic Energy (GAIE), which is obtained by calculating the weighted sum of squared DCT coefficients for each segmented audio clip with carefully designed weights. Extensive experimental results demonstrate that the proposed MAS rule tends to be more general and consistent than the LAF rule, and the proposed GAIE also shows better empirical security performance and audio quality compared to the advanced AAC and DFR_res (a variant of DFR). In addition, by preventing the micro-amplitude samples from being modified, the proposed GAIE_MAS can not only outperform other hand-crafted audio steganographic schemes but also the recently emerged deep learning-based schemes, e.g., IAA.}
}


@article{DBLP:journals/tifs/JiangXYJZ24,
	author = {Peiqi Jiang and
                  Hongtao Xie and
                  Lingyun Yu and
                  Guoqing Jin and
                  Yongdong Zhang},
	title = {Exploring Bi-Level Inconsistency via Blended Images for Generalizable
                  Face Forgery Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6573--6588},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3417266},
	doi = {10.1109/TIFS.2024.3417266},
	timestamp = {Fri, 19 Jul 2024 23:16:24 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangXYJZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The challenge of generalization in face forgery detection has become increasingly prominent as manipulation techniques continue to evolve. Although recent image blending-based methods have demonstrated remarkable potential, they often encounter a significant performance drop when applied to datasets exhibiting significant domain gaps. This limitation stems from the exclusive reliance of prior methods on blending unaltered faces with various augmentations to produce common artifacts, which ignores the inherent characteristics of the forged regions. To fully exploit the potential of image blending-based methods for generalizable Deepfake detection, we propose a novel image synthesis framework called Bi-Level Inconsistency Generator (Bi-LIG) to introduce bi-level inconsistency in the synthesized images. Specifically, Bi-LIG generates synthetic images by blending source and target images from both pristine and forged image sets, introducing a) Extrinsic-Inconsistency between real and pseudo-forged regions, and b) Inherent-Inconsistency between real and manipulated areas. In this way, Bi-LIG creates a diverse synthesized image set and establishes a generalizable training domain. Furthermore, we propose a novel face forgery detection network named Token Consistency Constrained Vision Transformer, in which two modules are developed based on patch consistency learning. Firstly, a Patch Token Contrast module is employed to learn the bi-level patch inconsistencies. Secondly, a Progressive Patch Token Assemble module is adopted to aggregate local patch relations and enhance the inconsistency representations. Experimental results demonstrate the effectiveness and superiority of our method on both in-dataset and cross-dataset evaluations. Notably, our approach outperforms state-of-the-art methods by 5.09% and 10.15% on cross-dataset evaluations in DFDCp and DFDC, respectively.}
}


@article{DBLP:journals/tifs/LeeK24,
	author = {Seungkwang Lee and
                  Jeong{-}Nyeo Kim},
	title = {Balanced Encoding of Near-Zero Correlation for an {AES} Implementation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6589--6603},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420101},
	doi = {10.1109/TIFS.2024.3420101},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LeeK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Power analysis poses a significant threat to the security of cryptographic algorithms, as it can be leveraged to recover secret keys. While various software-based countermeasures exist to mitigate this non-invasive attack, they often involve a trade-off between time and space constraints. Techniques such as masking and shuffling, while effective, can noticeably impact execution speed and rely heavily on run-time random number generators. On the contrary, internally encoded implementations of block ciphers offer an alternative approach that does not rely on run-time random sources, but it comes with the drawback of requiring substantial memory space to accommodate lookup tables. Internal encoding, commonly employed in white-box cryptography, suffers from a significant security limitation as it does not effectively protect the secret key against statistical analysis. To overcome this weakness, this paper introduces a secure internal encoding method for an AES implementation. By addressing the root cause of vulnerabilities found in previous encoding methods, we propose a balanced encoding technique that aims to minimize the problematic correlation with key-dependent intermediate values. We analyze the potential weaknesses associated with the balanced encoding and present a method that utilizes complementary sets of lookup tables. In this approach, the size of the lookup tables is approximately 512KB, and the number of table lookups is 1,024. This is comparable to the table size of non-protected white-box AES-128 implementations, while requiring only half the number of lookups. By adopting this method, our aim is to introduce a non-masking technique that mitigates the vulnerability to statistical analysis present in existing internally-encoded AES implementations.}
}


@article{DBLP:journals/tifs/LiuHCYLL24,
	author = {Zizhen Liu and
                  Weiyang He and
                  Chip{-}Hong Chang and
                  Jing Ye and
                  Huawei Li and
                  Xiaowei Li},
	title = {{SPFL:} {A} Self-Purified Federated Learning Method Against Poisoning
                  Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6604--6619},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420135},
	doi = {10.1109/TIFS.2024.3420135},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuHCYLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While Federated learning (FL) is attractive for pulling privacy-preserving distributed training data, the credibility of participating clients and non-inspectable data pose new security threats, of which poisoning attacks are particularly rampant and hard to defend without compromising privacy, performance or other desirable properties. In this paper, we propose a self-purified FL (SPFL) method that enables benign clients to exploit trusted historical features of locally purified model to supervise the training of aggregated model in each iteration. The purification is performed by an attention-guided self-knowledge distillation where the teacher and student models are optimized locally for task loss, distillation loss and attention loss simultaneously. SPFL imposes no restriction on the communication protocol and aggregator at the server. It can work in tandem with any existing secure aggregation algorithms and protocols for augmented security and privacy guarantee. We experimentally demonstrate that SPFL outperforms state-of-the-art FL defenses against poisoning attacks. The attack success rate of SPFL trained model remains the lowest among all defense methods in comparison, even if the poisoning attack is launched in every iteration with all but one malicious clients in the system. Meantime, it improves the model quality on normal inputs compared to FedAvg, either under attack or in the absence of an attack.}
}


@article{DBLP:journals/tifs/ZhangXH24,
	author = {Zhao Zhang and
                  Chunxiang Xu and
                  Yunxia Han},
	title = {Privacy-Preserving Cryptocurrency With Threshold Authentication and
                  Regulation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6620--6635},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3419694},
	doi = {10.1109/TIFS.2024.3419694},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangXH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptocurrency allows for immutable and transparent payments in the decentralized manner. The transparency nature inevitably leads to leakage of users’ private information. Although existing schemes provided privacy preservation in cryptocurrencies, they fail to consider regulation and facilitates conducting illegal activities. To solve this problem, several works aimed at striking a balance between preservation of users’ privacy and identification of malicious users. However, they introduced a central authority (which runs counter to the decentralization design of cryptocurrencies), and reveals only the pseudonym of a malicious user other than her/his real identity due to lack of authentication. In this work, we propose PICTURE, a privacy-preserving cryptocurrency with threshold authentication and regulation. In PICTURE, a user registers to a group of authorities (instead of a centralized one) who cooperatively issue the user with a master account which is actually a randomizable signature. The user randomizes the master account to be authenticated and transact anonymously. Besides, the transaction contains a record, with which the authorities can reveal the user’s identity (that is used in registration) in the threshold way. Our construction enables the user to prove that the record is well-formed with only a standard Schnorr’s protocol, leading to lower overheads compared with existing works. We provide a formal security proof to demonstrate that PICTURE is secure, and conduct a comprehensive performance evaluation to show that PICTURE is ready to be deployed in real world.}
}


@article{DBLP:journals/tifs/FanCZZZY24,
	author = {Zexin Fan and
                  Kejiang Chen and
                  Kai Zeng and
                  Jiansong Zhang and
                  Weiming Zhang and
                  Nenghai Yu},
	title = {Natias: Neuron Attribution-Based Transferable Image Adversarial Steganography},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6636--6649},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3421893},
	doi = {10.1109/TIFS.2024.3421893},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FanCZZZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image steganography is a technique to conceal secret messages within digital images. Steganalysis, on the contrary, aims to detect the presence of secret messages within images. Recently, deep-learning-based steganalysis methods have achieved excellent detection performance. As a countermeasure, adversarial steganography has garnered considerable attention due to its ability to effectively deceive deep-learning-based steganalysis. However, steganalysts often employ unknown steganalytic models for detection. Therefore, the ability of adversarial steganography to deceive non-target steganalytic models, known as transferability, becomes especially important. Nevertheless, existing adversarial steganographic methods do not consider how to enhance transferability. To address this issue, we propose a novel adversarial steganographic scheme named Natias. Specifically, we first attribute the output of a steganalytic model to each neuron in the target middle layer to identify critical features. Next, we corrupt these critical features that may be adopted by diverse steganalytic models. Consequently, it can promote the transferability of adversarial steganography. Our proposed method can be seamlessly integrated with existing adversarial steganography frameworks. Thorough experimental analyses affirm that our proposed technique possesses improved transferability when contrasted with former approaches, and it attains heightened security in retraining scenarios.}
}


@article{DBLP:journals/tifs/LiRLJS24,
	author = {Zhiwei Li and
                  Min Ren and
                  Qi Li and
                  Fangling Jiang and
                  Zhenan Sun},
	title = {Improving Transferability of Adversarial Samples via Critical Region-Oriented
                  Feature-Level Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6650--6664},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3404857},
	doi = {10.1109/TIFS.2024.3404857},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiRLJS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) have received a lot of attention because of their impressive progress in computer vision. However, it has been recently shown that DNNs are vulnerable to being spoofed by carefully crafted adversarial samples. These samples are generated by specific attack algorithms that can obfuscate the target model without being detected by humans. Recently, feature-level attacks have been the focus of research due to their high transferability. Existing state-of-the-art feature-level attacks all improve the transferability by greedily changing the attention of the model. However, for images that contain multiple target class objects, the attention of different models may differ significantly. Thus greedily changing attention may cause the adversarial samples corresponding to these images to fall into the local optimum of the surrogate model. Furthermore, due to the great structural differences between vision transformers (ViTs) and convolutional neural networks (CNNs), adversarial samples generated on CNNs with feature-level attacks are more difficult to successfully attack ViTs. To overcome these drawbacks, we perform the Critical Region-oriented Feature-level Attack (CRFA) in this paper. Specifically, we first propose the Perturbation Attention-aware Weighting (PAW), which destroys critical regions of the image by performing feature-level attention weighting on the adversarial perturbations without changing the model attention as much as possible. Then we propose the Region ViT-critical Retrieval (RVR), which enables the generator to accommodate the transferability of adversarial samples on ViTs by adding extra prior knowledge of ViTs to the decoder. Extensive experiments demonstrate significant performance improvements achieved by our approach, i.e., improving the fooling rate by 19.9% against CNNs and 25.0% against ViTs as compared to state-of-the-art feature-level attack method.}
}


@article{DBLP:journals/tifs/YinYRMWW24,
	author = {Weifeng Yin and
                  Lifeng Yuan and
                  Yizhi Ren and
                  Weizhi Meng and
                  Dong Wang and
                  Qiuhua Wang},
	title = {Differential Cryptanalysis of Bloom Filters for Privacy-Preserving
                  Record Linkage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6665--6678},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3421292},
	doi = {10.1109/TIFS.2024.3421292},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YinYRMWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving record linkage (PPRL) aims to link records of the same real-world entity from different databases without exposing any private information about the entity. Bloom filters are widely used in PPRL due to their effectiveness in encoding records while enabling fast approximate linkage in the case of attribute value errors and changes. However, the basic Bloom filters used for PPRL can be subject to cryptanalysis attacks that expose the plain-text values encoded in them. Recent studies have successfully attacked some improved Bloom filter encodings in PPRL but require specific conditions or knowledge of various encoding parameters to obtain high accuracy. This paper presents a novel attack based on differential analysis against Bloom filters used for PPRL. The attack exploits graphs to model the relationship between attribute value variation and the difference between Bloom filters. Then, features are generated for the node in graphs according to a clustering algorithm that we propose. Thus, we can match nodes with similar features to re-identify encoded records. Experiments on two real-world databases show that even with improved Bloom filter encoding and some hardening techniques, our attack can re-identify private information from encoded records with high accuracy and require less priori knowledge.}
}


@article{DBLP:journals/tifs/DongreR24,
	author = {Siddharth Dongre and
                  Hanif Rahbari},
	title = {Fair and Secure 5G and Wi-Fi Coexistence Using Robust Implicit Channel
                  Coordination},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6679--6692},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3421235},
	doi = {10.1109/TIFS.2024.3421235},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DongreR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5G and Wi-Fi systems are embracing coexistence in the unlicensed portions of the 5–7 GHz bands recently allocated by FCC to support the increasing data rate demands for the growing number of wireless users. To achieve fair and effective spectrum sharing, both 5G and Wi-Fi rely on carrier sensing for medium access. However, differences in sensing thresholds create an unfair advantage for 5G nodes, as they access the medium more aggressively and degrade the data rate and latency of Wi-Fi users. We first demonstrate how an adversary can stealthily exploit this unfairness to further reduce the spectrum occupancy of Wi-Fi nodes, effectively denying Wi-Fi services. Accordingly, in this paper, we propose a novel implicit channel coordination (ICC) approach to both mitigate starvation attacks and improve spectrum access fairness under practical considerations like noise and strong adversaries who try to circumvent our technique. In ICC, Wi-Fi access points (APs) influence 5G gNBs into choosing a precoding matrix that nearly nullifies 5G downlink signals at the APs, enabling concurrent gNB and AP transmissions while accounting for a hidden terminal problem this creates. We theoretically analyze and show that our ICC mitigates novel attacks we have identified, and experimentally demonstrate on a USRP testbed its resilience against starvation attacks. Our design outperforms prior work by achieving an overall 30% higher data rate of the 5G and Wi-Fi coexistence system, 3x improvement in spectrum access fairness, and 1.5x in system capacity, all while conforming with the latency requirements of 5G.}
}


@article{DBLP:journals/tifs/YazdinejadDKSP24,
	author = {Abbas Yazdinejad and
                  Ali Dehghantanha and
                  Hadis Karimipour and
                  Gautam Srivastava and
                  Reza M. Parizi},
	title = {A Robust Privacy-Preserving Federated Learning Model Against Model
                  Poisoning Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6693--6708},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420126},
	doi = {10.1109/TIFS.2024.3420126},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YazdinejadDKSP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although federated learning offers a level of privacy by aggregating user data without direct access, it remains inherently vulnerable to various attacks, including poisoning attacks where malicious actors submit gradients that reduce model accuracy. In addressing model poisoning attacks, existing defense strategies primarily concentrate on detecting suspicious local gradients over plaintext. However, detecting non-independent and identically distributed encrypted gradients poses significant challenges for existing methods. Moreover, tackling computational complexity and communication overhead becomes crucial in privacy-preserving federated learning, particularly in the context of encrypted gradients. To address these concerns, we propose a robust privacy-preserving federated learning model resilient against model poisoning attacks without sacrificing accuracy. Our approach introduces an internal auditor that evaluates encrypted gradient similarity and distribution to differentiate between benign and malicious gradients, employing a Gaussian Mixture Model and Mahalanobis Distance for byzantine-tolerant aggregation. The proposed model utilizes Additive Homomorphic Encryption to ensure confidentiality while minimizing computational and communication overhead. Our model demonstrates superior performance in accuracy and privacy compared to existing strategies and encryption techniques, such as Fully Homomorphic Encryption and Two-Trapdoor Homomorphic Encryption. The proposed model effectively addresses the challenge of detecting maliciously encrypted non-independent and identically distributed gradients with low computational and communication overhead.}
}


@article{DBLP:journals/tifs/GarciaBB24,
	author = {Julio C{\'{e}}sar P{\'{e}}rez Garc{\'{\i}}a and
                  An Braeken and
                  Abderrahim Benslimane},
	title = {Blockchain-Based Group Key Management Scheme for IoT With Anonymity
                  of Group Members},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6709--6721},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3414663},
	doi = {10.1109/TIFS.2024.3414663},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GarciaBB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Group communications play a crucial role in enhancing the quality of service (QoS) of Internet of Things (IoT) networks, enabling efficient information dissemination while minimizing resource utilization. However, ensuring information security and privacy in IoT group communications necessitates the implementation of an efficient and lightweight key management scheme due to the limited capabilities of most IoT devices. This paper presents a novel key management protocol for group communications that employs distributed Blockchain technology in IoT networks. The proposed scheme considers nodes belonging to multiple groups. By utilizing an asymmetric key shared among group members, secure communication is established between outsiders and group members while preserving anonymity inside the group. A distinguishing feature of the protocol is its combination of group member anonymity and automatic key revocation facilitated by a Smart Contract. Furthermore, simulation results demonstrate the efficiency of the proposed scheme, consuming less than 300 mJ of energy and taking less than 7 seconds to establish a group key among 1000 nodes, outperforming several existing approaches in the literature in terms of computation and communication costs.}
}


@article{DBLP:journals/tifs/BiXLNLTZ24,
	author = {Renwan Bi and
                  Jinbo Xiong and
                  Changqing Luo and
                  Jianting Ning and
                  Ximeng Liu and
                  Youliang Tian and
                  Yan Zhang},
	title = {Communication-Efficient Privacy-Preserving Neural Network Inference
                  via Arithmetic Secret Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6722--6737},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420216},
	doi = {10.1109/TIFS.2024.3420216},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BiXLNLTZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Well-trained neural network models are deployed on edge servers to provide valuable inference services for clients. To protect data privacy, a promising way is to exploit various types of secret sharing to implement privacy-preserving neural network inference. However, existing schemes suffer high communication rounds and overhead, making them hardly practical. In this paper, we propose Cenia, a new communication-efficient privacy-preserving neural network inference model. Specifically, we exploit arithmetic secret sharing to develop low-interaction secure comparison protocols, that can be used to realize secure activation layers (e.g., ReLU) and secure pooling layers (e.g., max pooling) without expensive garbled circuit and oblivious transfer primitives. Besides, we also design secure exponent and division protocols to realize secure normalization layers (e.g., Sigmoid). Theoretical analysis demonstrates the security and low complexity of Cenia. Extensive experiments have also been conducted on benchmark datasets and classical models, and experimental results show that Cenia achieves privacy-preserving, accurate, and efficient neural network inference. Particularly, Cenia can achieve 37.5% and 60.76% of Sonic’s communication rounds and overhead, respectively, compared to Sonic (i.e., the state-of-the-art scheme).}
}


@article{DBLP:journals/tifs/ShahidinejadAH24,
	author = {Ali Shahidinejad and
                  Jemal H. Abawajy and
                  Shamsul Huda},
	title = {Highly-Secure Yet Efficient Blockchain-Based CRL-Free Key Management
                  Protocol for IoT-Enabled Smart Grid Environments},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6738--6750},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3423724},
	doi = {10.1109/TIFS.2024.3423724},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShahidinejadAH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) has advanced smart grid (SG) infrastructure by providing smart meters (SMs) with enhanced capabilities such as the ability to leverage the Internet platform for bidirectional information exchange. Cryptographic keys are necessary for securely exchanging sensitive information between SMs and energy providers. To manage these keys, a secure key management protocol (KMP) with little overhead and influence on the SG’s overall performance is necessary. Although various KMPs are available for IoT-enabled SG environments, exiting solutions have several flaws in terms of certificate revocation, security requirements, and overall SG performance. To address these challenges, this paper proposes a blockchain-based computationally-efficient and highly-secure KMP for IoT-enabled SG environments. We show that, compared to existing solutions, the proposed KMP has better SM side efficiency with improved security and more properties such as perfect forward secrecy, conditional anonymity, and simple SM revocation.}
}


@article{DBLP:journals/tifs/ZhangWTY24,
	author = {Chenhan Zhang and
                  Weiqi Wang and
                  Zhiyi Tian and
                  Shui Yu},
	title = {Forgetting and Remembering Are Both You Need: Balanced Graph Structure
                  Unlearning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6751--6763},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3422799},
	doi = {10.1109/TIFS.2024.3422799},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangWTY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In light of the growing emphasis on the right to be forgotten of graph data, machine unlearning has been extended to unlearn the graph structures’ knowledge from graph neural networks (GNNs), namely, structure unlearning. Whereas the complex dependencies in graph data, structure unlearning is intrinsically prone to imbalanced performance between the objectives of knowledge forgetting and model utility maintenance. Nevertheless, most existing methods fall short in addressing the two objectives in tandem and developing balanced solutions. In this paper, we propose imbalanced Structure Unlearning Mitigation using MultI-objective OpTimization (SUMMIT), which aims to develop balanced solutions regarding both knowledge forgetting and model utility maintenance effects. Corresponding to the two aspects, we first construct two tailored objectives that specifically address the challenges inherent in structure unlearning. Specifically, for the forgetting objective, we introduce a higher-order forgetting enhancement strategy aimed at mitigating the adverse effects of GNN oversmoothing on node decoupling. For the remembering objective, we adhere to the principle of ideal unlearning and propose to minimize the distributional distance between the node embeddings developed by unlearned and well-trained GNNs. Considering the potential competitive relationship between the two objectives during the optimization process, we present an adaptive two-objective balancer based on multi-objective optimization to reconcile the two objectives and strike a balance between them. We conduct comprehensive experiments to evaluate the efficacy of SUMMIT on three representative GNNs and four datasets, and compare the performance of SUMMIT with its ablation variants and a cadre of baselines. We demonstrate the superiority of SUMMIT in its ability to yield optimal and balanced solutions, addressing both the facets of knowledge forgetting and model utility maintenance.}
}


@article{DBLP:journals/tifs/LiuZLZLLC24,
	author = {Wenxi Liu and
                  Hao Zhang and
                  Xinyang Lin and
                  Qing Zhang and
                  Qi Li and
                  Xiaoxiang Liu and
                  Ying Cao},
	title = {Attentive and Contrastive Image Manipulation Localization With Boundary
                  Guidance},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6764--6778},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3424987},
	doi = {10.1109/TIFS.2024.3424987},
	timestamp = {Thu, 08 Aug 2024 22:03:57 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuZLZLLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the rapid advancement of image generation techniques has resulted in the widespread abuse of manipulated images, leading to a crisis of trust and affecting social equity. Thus, the goal of our work is to detect and localize tampered regions in images. Many deep learning based approaches have been proposed to address this problem, but they can hardly handle the tampered regions that are manually fine-tuned to blend into image background. By observing that the boundaries of tempered regions are critical to separating tampered and non-tampered parts, we present a novel boundary-guided approach to image manipulation detection, which introduces an inherent bias towards exploiting the boundary information of tampered regions. Our model follows an encoder-decoder architecture, with multi-scale localization mask prediction, and is guided to utilize the prior boundary knowledge through an attention mechanism and contrastive learning. In particular, our model is unique in that 1) we propose a boundary-aware attention module in the network decoder, which predicts the boundary of tampered regions and thus uses it as crucial contextual cues to facilitate the localization; and 2) we propose a multi-scale contrastive learning scheme with a novel boundary-guided sampling strategy, leading to more discriminative localization features. Our state-of-art performance on several public benchmarks demonstrates the superiority of our model over prior works.}
}


@article{DBLP:journals/tifs/ChenLHPW24,
	author = {Yong Chen and
                  Xuedong Li and
                  Peng Hu and
                  Dezhong Peng and
                  Xu Wang},
	title = {DifFilter: Defending Against Adversarial Perturbations With Diffusion
                  Filter},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6779--6794},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3422923},
	doi = {10.1109/TIFS.2024.3422923},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenLHPW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The inherent vulnerability of deep learning to adversarial examples poses a significant security challenge. Although existing defense methods have partially mitigated the harm caused by adversarial attacks, they are still unable to meet practical needs due to their high cost, high latency, and poor defense performance. In this paper, we propose an advanced plug-and-play adversarial purification model called DifFilter. Specifically, we use the superior generative properties of diffusion models to denoise adversarial perturbations and recover clean images. To make Gaussian noise disrupt adversarial perturbations while preserving the real semantic information in the input image, we extend forward diffusion to an infinite number of noise scales so that the distribution of perturbation data evolves with increasing noise according to stochastic differential equations. In the inverse denoising process, we develop a score-based model learning method to restore the input prior distribution to the data distribution of the original clean sample, resulting in stronger purification effects. Additionally, we propose an efficient sampling method to accelerate the computation speed of inverse process, greatly reducing the time cost of purification. We conduct extensive experiments to evaluate the defense generalization performance of DifFilter. The results demonstrate that our method not only surpasses existing defense methods in defense robustness under strong adaptive and black-box attacks but also achieves higher certificate accuracy than the baseline. Furthermore, DifFilter can be combined with adversarial training to further improve defense robustness.}
}


@article{DBLP:journals/tifs/ZhouZHYDL24,
	author = {Man Zhou and
                  Wenyu Zhou and
                  Jie Huang and
                  Junhui Yang and
                  Minxin Du and
                  Qi Li},
	title = {Stealthy and Effective Physical Adversarial Attacks in Autonomous
                  Driving},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6795--6809},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3422920},
	doi = {10.1109/TIFS.2024.3422920},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouZHYDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In autonomous assistance systems, accurate camera vision is indispensable for driving safety. Featuring this safety-critical scenario, physical adversarial examples are arguably the most threatening. However, existing physical adversarial attacks are either conspicuous or ineffective, leaving a dilemma for balancing between attack effectiveness and stealthiness. In this paper, we put forth a new type of adversarial patch attack, leveraging the behavior characteristic of high-speed shutters in autonomous driving cameras. Instead of deploying static images onto real-world objects, we embed adversarial examples into videos and cast them with projectors. By delicately deciding the frame contents and display frequencies, the adversarial frame contents are almost invisible to humans, but high-speed shutters can capture them (see our demos (https://anonymous.4open.science/r/7003)). We demonstrate the attack feasibility by fooling traffic sign detectors, altering speed limit signs to be mis-detected or undetected, and hence manipulating the driving speed of victims. We conduct extensive experiments under various conditions, confirming that our new attack is effective and robust: It can deceive state-of-the-art detector models with success rates of 99% and over 90% in untargeted and targeted manners, respectively. Our further investigations unravel the transferability of our attack to other detectors in a black-box setting.}
}


@article{DBLP:journals/tifs/LvXCCJ24,
	author = {Zefang Lv and
                  Liang Xiao and
                  Yifan Chen and
                  Haoyu Chen and
                  Xiangyang Ji},
	title = {Safe Multi-Agent Reinforcement Learning for Wireless Applications
                  Against Adversarial Communications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6824--6839},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3423428},
	doi = {10.1109/TIFS.2024.3423428},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LvXCCJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Based on the network observations and learning parameters shared by the neighboring learning agents, multi-agent reinforcement learning (RL) has to enhance the performance over adversarial communications, in which spoofing attackers send fake learning messages to fool the learning agent and thus degrade the performance of wireless applications. In this paper, we propose a safe multi-agent RL algorithm for wireless applications against adversarial communications, in which each learning agent chooses the cooperative agents to share the learning information and authenticates the received learning messages before integrating them into the RL state formulation and the learning parameter update. The communication policy distribution for the cooperative agent selection is formulated based on the long-term discounted reward and the sharing reputation for each neighboring agent, which is updated based on the authentication results to indicate the probability as a spoofing attacker. Neural networks are designed to estimate the long-term discounted reward and the sharing reputation for the learning agent with sufficient computational resources in large-scale wireless networks to enhance the agent selection security. As a case study, our proposed algorithm is implemented in the unmanned aerial vehicle swarm anti-jamming video transmission against spoofing attackers that send fake received jamming power as well as Q-values and neural network weights in the anti-jamming transmission policy learning. Both simulation and experimental results are provided to verify the performance gain over the benchmark.}
}


@article{DBLP:journals/tifs/HuangBZLFLSDL24,
	author = {Jinyang Huang and
                  Jia{-}Xuan Bai and
                  Xiang Zhang and
                  Zhi Liu and
                  Yuanhao Feng and
                  Jianchun Liu and
                  Xiao Sun and
                  Mianxiong Dong and
                  Meng Li},
	title = {KeystrokeSniffer: An Off-the-Shelf Smartphone Can Eavesdrop on Your
                  Privacy From Anywhere},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6840--6855},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3424301},
	doi = {10.1109/TIFS.2024.3424301},
	timestamp = {Mon, 30 Sep 2024 08:10:05 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangBZLFLSDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With mobile phones becoming increasingly prevalent and embedding high-quality microphones, attackers have the ability to employ these microphones to eavesdrop user’s keyboard input. However, existing work usually assumes that keystroke eavesdropping is performed against known environments and victims, which inevitably makes attack systems lack generalization. To reveal the real threat of the acoustic signal-based attack strategy, this paper proposes a keystroke eavesdropping algorithm called KeystrokeSniffer, which is robust to unknown input environments and unknown victims. In particular, to mimic the real input environment of victims, an environment estimation algorithm is first designed by extracting the timbre-related characteristics to predict the keyboard type and identifying large-size key data from collected unlabeled samples to estimate the 3D microphone coordinates. Then, by imitating unknown environments and victim data, this algorithm achieves effective keystroke eavesdropping with a small training set. By further considering the commonalities of different keystroke habits, a robust feature extraction method that reflects the keystroke location is adopted to reduce the impact of individual input habits. Extensive experimental results using various commodity smartphones indicate that the scheme is capable of predicting keyboard input accurately under different unknown scenarios. Specifically, even when both the victims and keyboards are unknown, KeystrokeSniffer can still achieve high Top-5 accuracy, reaching 79.5% in predicting keystrokes and 96.7% in predicting meaningful words, which demonstrates KeystrokeSniffer has excellent generalization capabilities. By setting different parameter values of various impact factors, e.g., noise and hand length factors, the strong robustness of the system is demonstrated, which proves that KeystrokeSniffer can violate privacy in real situations.}
}


@article{DBLP:journals/tifs/LeiWPSLL24,
	author = {Jing Lei and
                  Le Wang and
                  Qingqi Pei and
                  Wenhai Sun and
                  Xiaodong Lin and
                  Xuefeng Liu},
	title = {PrivGrid: Privacy-Preserving Individual Load Forecasting Service for
                  Smart Grid},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6856--6870},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3422876},
	doi = {10.1109/TIFS.2024.3422876},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LeiWPSLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart meter-based individual load forecasts are more and more widely deployed to serve smart grid and home energy management. Customary load forecasting systems collect a massive amount of fine-grained electrical data from people’s smart meters in plaintext, inevitably raising privacy concerns and even anti-smart-meter initiatives. Current privacy solutions either compromise accuracy and efficacy or require the redeployment of trusted infrastructure. In this paper, we present PrivGrid, the first systematic solution for smart grids that collects, clusters, trains, and forecasts customers’ load data in a privacy-preserving way. Moreover, we highlight the technical contribution of our building block: a novel and fast arithmetic multiplication triple via secure inner product protocol outperforms the existing methods and may be included in other privacy computing modules. Then, we develop efficient secure protocols to enable the arithmetic operations of individual load forecasting in a server-aided model and utilize the best alternatives to nonlinear functions. Besides, aggregating all of our individual forecasts can produce a more accurate estimate of the system-level load than the typical aggregate technique. We rigorously prove that the servers cannot obtain the user’s historical load data and short-term load forecast values while providing services. PrivGrid is also tested on real residential smart meter data to show its efficiency, and the relevant code has been made available to the community for further research.}
}


@article{DBLP:journals/tifs/LuoXYPO24,
	author = {Linbo Luo and
                  Shangwei Xie and
                  Haiyan Yin and
                  Chunlei Peng and
                  Yew{-}Soon Ong},
	title = {Detecting and Quantifying Crowd-Level Abnormal Behaviors in Crowd
                  Events},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6810--6823},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3423388},
	doi = {10.1109/TIFS.2024.3423388},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuoXYPO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting and quantifying abnormal crowd motion emerging from complex interactions of individuals is paramount to ensure the safety of crowds. Crowd-level abnormal behaviors (CABs), e.g., counter flow and crowd turbulence, are proven to be the crucial causes of many crowd disasters. Unlike individual-level anomaly, CABs usually do not exhibit salient difference from the normal behaviors when observed locally and the scale of CABs could vary from one scenario to another. It is also challenging to quantify the risk level of these CABs from video surveillance. In this paper, we present an improved version of our crowd motion learning framework for CABs detection, multi-scale motion consistency network (MSMC-Net) with a dual-attention fusion process to accommodate both the spatio-temporal and scale variations of different CABs. In addition, we propose an assessment method to quantify the risk level of detected CABs based on the anomaly score generated from our MSMC-Net. The risk quantification is performed in an online and accumulated manner and it can reflect the risk level of CABs consistent with other offline assessment metrics (e.g., crowd pressure), but without the extraction of detailed crowd data (e.g., pedestrian trajectories). For empirical study, we evaluate our method on large-scale crowd event datasets, including UMN, Hajj and Love Parade. Experimental results show that MSMC-Net could improve the AUC performance by 7.9%, 12.2% and 29.5% on three datasets respectively, compared to the best results of the state-of-the-art methods.}
}


@article{DBLP:journals/tifs/HanLLJLL24,
	author = {Xueying Han and
                  Song Liu and
                  Junrong Liu and
                  Bo Jiang and
                  Zhigang Lu and
                  Baoxu Liu},
	title = {ECNet: Robust Malicious Network Traffic Detection With Multi-View
                  Feature and Confidence Mechanism},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6871--6885},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3426304},
	doi = {10.1109/TIFS.2024.3426304},
	timestamp = {Sat, 14 Dec 2024 21:39:21 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HanLLJLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malicious traffic detection in the real world faces the challenge of dealing with a diverse mix of known, unknown, and variant malicious traffic, requiring methods that are accurate, generalizable, and reliable for identifying both known and emerging threats. However, existing methods are unable to fully meet these requirements. Supervised methods can accurately detect known malicious traffic, but their performance declines significantly when encountering unknown attacks. Additionally, the misclassification is usually silent, leading to doubts about the reliability and practicality. Unsupervised methods can deal with unknown attacks, but their high false positive rate and inability to utilize the knowledge of existing attack data constitute obvious shortcomings. To overcome these limitations, we propose ECNet, an end-to-end robust malicious network traffic detection method. Particularly, ECNet incorporates multi-view features, including content and pattern features, and employs a gated-based feature fusion approach, providing an efficient and robust representation. Moreover, ECNet introduces a confidence mechanism and combines category probability and confidence values during training and detection; therefore, it can accurately detect both known and unknown malicious traffic while ensuring the credibility of results. To validate the performance of ECNet, we conduct comprehensive experiments on six reorganized datasets and compare ECNet with seven state-of-the-art methods. The results demonstrate that ECNet outperforms others, particularly showing significant improvements in detecting unknown attacks, with up to a 14.15% increase in F1 compared to the best-performing method.}
}


@article{DBLP:journals/tifs/DengYL24,
	author = {Yahan Deng and
                  Hao Yu and
                  Yuzhe Li},
	title = {Stealthy Insider Attack on Stochastic Event-Triggered Scheduler: Dealing
                  With Non-Gaussian Components},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6886--6895},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3427005},
	doi = {10.1109/TIFS.2024.3427005},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DengYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article considers malicious attacks on a stochastic event-based state estimation where a smart sensor equipped with the standard Kalman filter is utilized to transmit the local estimate. A novel attack strategy called stealthy insider attack is proposed, which can compromise remote state estimation by hacking the scheduler, reversing the triggering condition, and tampering with the schedule parameter. The discovery of the complete Gaussian crater (CGC) distribution is significant for analyzing various properties of the innovation under the stochastic event-triggered scheme (ETS). An extended CGC distribution is developed to explore the probability distribution of innovation sequences with successive packet losses, and a closed-form expression is derived for the estimation error covariance under attack. Furthermore, to bypass the communication rate detector, a method is presented for tampering with the schedule parameter based on the ergodicity of the underlying Markov chain. Finally, two numerical simulations demonstrate the efficacy of the proposed attack strategy in diminishing the estimation performance of the remote estimator.}
}


@article{DBLP:journals/tifs/YuZYY24,
	author = {Haiyang Yu and
                  Hui Zhang and
                  Zhen Yang and
                  Shui Yu},
	title = {Edasvic: Enabling Efficient and Dynamic Storage Verification for Clouds
                  of Industrial Internet Platforms},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6896--6909},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3422790},
	doi = {10.1109/TIFS.2024.3422790},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YuZYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial Internet platforms (IIP) can provide many intelligent services based on the industrial big data stored in clouds. However, the vulnerability of cloud storage can cause data corruption, demanding verifying its integrity. Unfortunately, existing cloud storage verification approaches cannot be directly applied to IIP, since they pose heavy computational burdens on the edge side. In this work, we propose an efficient and dynamic storage verification scheme Edasvic for cloud storage in the IIP. We adopt the polynomial commitment to build an efficient homomorphic authenticator, and further design an authenticator accumulator, which can be efficiently generated with limited computational overheads. In addition, we integrate the dynamic information into the authenticator accumulator to support data dynamics. The security of Edasvic is analyzed under the random oracle model. We conduct extensive experiments to evaluate the performance of Edasvic and compare it with the state-of-the-art approaches. Experimental results affirm that Edasvic is superior to existing solutions in terms of computational efficiency.}
}


@article{DBLP:journals/tifs/LiuQZWWZ24,
	author = {Yimin Liu and
                  Meibin Qi and
                  Yongle Zhang and
                  Qiang Wu and
                  Jingjing Wu and
                  Shuo Zhuang},
	title = {Improving Consistency of Proxy-Level Contrastive Learning for Unsupervised
                  Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6910--6922},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3426351},
	doi = {10.1109/TIFS.2024.3426351},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuQZWWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, contrastive learning-based unsupervised person re-identification (Re-ID) methods have garnered significant attention due to their effectiveness. These methods rely on predicted pseudo-labels to construct contrastive pairs, optimizing the network gradually. Some methods also utilize camera labels to explore intra-camera and inter-camera contrastive relations, achieving state-of-the-art results. However, these methods fail to address the issue of inconsistency in proxy-level contrastive learning, which arises from variations in the distribution of instances belonging to the same proxy. Specifically, they are sensitive to the distribution of instances in a mini-batch used for contrastive pair construction, and uncertainty or noise in the data distribution can lead to turbulence in the contrastive loss, degrading the effectiveness of contrastive learning. In this work, we first propose a dual-branch contrastive learning (DBCL) framework. The framework comprises a dual-branch structure with an identity discrimination branch and a camera view awareness branch. These branches are mutually trained to produce a jointly optimized model with both high person identification accuracy and cross-camera robustness. Moreover, to mitigate the proxy-level contrastive inconsistency issue in the camera view awareness branch, we design intra-camera and inter-camera consistent contrastive losses. Our DBCL has been extensively evaluated on several person Re-ID datasets and has demonstrated superior performance compared to state-of-the-art methods. Notably, on the challenging MSMT17 dataset with complex scenes, our method achieved an mAP of 45.3% and Rank-1 accuracy of 75.3%.}
}


@article{DBLP:journals/tifs/ChenGZSJLW24,
	author = {Honglong Chen and
                  Yudong Gao and
                  Anqing Zhang and
                  Peng Sun and
                  Nan Jiang and
                  Weifeng Liu and
                  Xingang Wang},
	title = {Investigating the Backdoor on DNNs Based on Recolorization and Reconstruction:
                  From a Multi-Channel Perspective},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6923--6934},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3427432},
	doi = {10.1109/TIFS.2024.3427432},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenGZSJLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, backdoor attacks have become a serious security threat to Deep Neural Networks (DNNs). Backdoor attacks involve embedding a hidden backdoor into a DNN model, compelling it to correctly classify benign images while erroneously classifying images with backdoor triggers as the target label. However, both current backdoor attacks and defenses have their limitations. In backdoor attacks, they are either non-stealthy or vulnerable to well-designed backdoor defense strategies. As for backdoor defenses, they often rely heavily on additional assumptions (such as determined extra clean images) and are not universally applicable, which may become impractical in the face of the latest backdoor attacks. To address the above problems, in this paper, we investigate the backdoor attack and defense strategies from a multi-channel perspective. Specifically, in terms of attacks, we propose a recolorization based attack method (RC-Attack) to generate triggers in color ab channels, which is more stealthy and effective. In terms of defenses, we propose a reconstruction-based defense method (RC-Defense) to reconstruct the color AB channels and lightness channel respectively, thus making the triggers in the reconstructed images ineffective, which is a more practical solution. Extensive experiments are conducted to demonstrate the superior performance of the proposed RC-Attack in terms of effectiveness, stealthiness and defense-resistance, and also to validate the effectiveness of the proposed RC-Defense.}
}


@article{DBLP:journals/tifs/DengW24,
	author = {Jie Deng and
                  Bin Wu},
	title = {A Practical Data Trading Protocol for Sudoku Solutions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6935--6948},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3419702},
	doi = {10.1109/TIFS.2024.3419702},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DengW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Developing a fair, efficient, and scalable data trading protocol in decentralized networks has attracted much research effort recently. Zero-knowledge contingent payments (ZKCP) allows sellers and buyers to complete their trade fairly over the blockchain using zero-knowledge proofs. However, it suffers from memory-intensive requirements and scalability limitations. In this paper, we propose a practical data trading protocol tailored for Sudoku solutions, which is fair, efficient, and scalable. The core component of our protocol is a zero-knowledge argument for the correctness of a Sudoku solution of homomorphic encryption. This argument achieves sublinear communication complexity and the number of group exponentiations for both proving and verification is linear in the size of Sudoku solutions. The security of our protocol can be proven in the random oracle model under the Decision Diffie-Hellman assumption. In addition, we devise a mechanism that allows buyers to recover the private key through two zero-knowledge proofs and prevents the direct exposure of the decryption key. Furthermore, we implement the proposed protocol on the Ethereum testnet, and the experimental results show a significant improvement in overall efficiency.}
}


@article{DBLP:journals/tifs/RenZWHS24,
	author = {Min Ren and
                  Yuhao Zhu and
                  Yunlong Wang and
                  Yongzhen Huang and
                  Zhenan Sun},
	title = {Understanding Deep Face Representation via Attribute Recovery},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6949--6961},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3424291},
	doi = {10.1109/TIFS.2024.3424291},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/RenZWHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks have proven to be highly effective in the face recognition task, as they can map raw samples into a discriminative high-dimensional representation space. However, understanding this complex space proves to be challenging for human observers. In this paper, we propose a novel approach that interprets deep face recognition models via facial attributes. To achieve this, we introduce a two-stage framework that recovers attributes from the deep face representations. This framework allows us to quantitatively measure the significance of facial attributes in relation to the recognition model. Moreover, this framework enables us to generate sample-specific explanations through counterfactual methodology. These explanations are not only understandable but also quantitative. Through the proposed approach, we are able to acquire a deeper understanding of how the recognition model conceptualizes the notion of “identity” and understand the reasons behind the error decisions made by the deep models. By utilizing attributes as an interpretable interface, the proposed method marks a paradigm shift in our comprehension of deep face recognition models. It allows a complex model, obtained through gradient backpropagation, to effectively “communicate” with humans. The source code is available here, or you can visit this website: https://github.com/RenMin1991/Facial-Attribute-Recovery.}
}


@article{DBLP:journals/tifs/YuLHL24,
	author = {Donghyun Yu and
                  Sungho Lee and
                  Ruei{-}Hau Hsu and
                  Jemin Lee},
	title = {Ensuring End-to-End Security With Fine-Grained Access Control for
                  Connected and Autonomous Vehicles},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6962--6977},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3417292},
	doi = {10.1109/TIFS.2024.3417292},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YuLHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As advanced V2X applications emerge in the connected and autonomous vehicle (CAV), the data communications between in-vehicle end-devices and outside nodes increase, which make the end-to-end (E2E) security to in-vehicle end-devices as the urgent issue to be handled. However, the E2E security with fine-grained access control still remains as a challenging issue for resource-constrained end-devices since the existing security solutions require complicated key management and high resource consumption. Therefore, this paper proposes a practical and secure vehicular communication protocol for the E2E security based on a new attribute-based encryption (ABE) scheme. In the ABE scheme, the outsourced computation is provided for encryption, and the computation cost for decryption constantly remains small, regardless of the number of attributes. The policy privacy can be ensured by the proposed ABE to support privacy-sensitive V2X applications, and the existing identity-based signature for outsourced signing is newly reconstructed. The protocol achieves the confidentiality, message authentication, identity anonymity, unlinkability, traceability, and reconfigurable outsourced computation, and this paper also shows the practical feasibility of the protocol via the performance evaluation.}
}


@article{DBLP:journals/tifs/ShenSASY24,
	author = {Yizhou Shen and
                  Carlton Shepherd and
                  Chuadhry Mujeeb Ahmed and
                  Shigen Shen and
                  Shui Yu},
	title = {{SGD3QN:} Joint Stochastic Games and Dueling Double Deep Q-Networks
                  for Defending Malware Propagation in Edge Intelligence-Enabled Internet
                  of Things},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6978--6990},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420233},
	doi = {10.1109/TIFS.2024.3420233},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShenSASY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware propagation in IoT (Internet of Things) systems can lead to data leakages, financial losses, and other serious consequences. To solve this issue, we propose a new active IoT malware propagation defence work. Specifically, aided by stochastic games, we express the process of cyber conflicts between IoT system nodes and edge devices considering malware propagation in edge intelligence-enabled IoT. Here, IoT system nodes and edge devices choose their own strategies and receive the corresponding rewards determined by the current state and strategy. After that, the game randomly moves to the next stage according to the distribution of probabilities and the participants’ strategies until reaching the fixed Nash equilibrium point. Following a theoretical analysis, we design and implement SGD3QN (Stochastic Games and Dueling Double Deep Q-networks)—a novel algorithm to receive the optimal strategy for mitigating IoT malware propagataion in practice. Here, the Dueling Double Deep Q-networks are acted as an end-to-end decision control system, in which IoT malware propagataion environment is used as the input to obtain the failure or success experience to update the network parameters, followed by making the optimal decision output. Afterwards, we perform experimental simulations that probe the influence of batch size and replay memory size on the optimal IoT malware propagation defense strategy selection and prove the ascendancy of the proposed SGD3QN-aided decision-making algorithm.}
}


@article{DBLP:journals/tifs/KongLJ24,
	author = {Yubo Kong and
                  Zhong Li and
                  Changjun Jiang},
	title = {{ASIA:} {A} Federated Boosting Tree Model Against Sequence Inference
                  Attacks in Financial Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {6991--7004},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3428412},
	doi = {10.1109/TIFS.2024.3428412},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KongLJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, a lot of studies unite multiple organizations to form an anti-fraud alliance to detect fraudulent transactions better using federated boosting tree algorithms. However, there are two challenges when building the federated boosting tree-based fraud detection model. First, the vertical federated learning (VFL) framework is not enough for the transaction fraud detection task because there are various participants in the same field (e.g., different banks) who cannot share data with others freely. And a lot of local data would be discarded due to the private set intersection process under the VFL framework. Second, there are still many privacy threats that can infer the data sequence information of the participants. Once the attackers illegally obtain the data sequence information, they can infer the raw data of the victims based on the data distribution. Specially, the instance spaces and score lists would also be maliciously exploited to launch a new data sequence inference attack that is currently indefensible. In response to the above challenges, we first propose a sequence inference attack that is the first work showing the vulnerabilities regarding the instance spaces and score lists. Then, we propose a federated boosting tree-based fraud detection method against (A) sequence (S) inference (I) attacks (A), named ASIA. ASIA method can combine the horizontal federated learning (HFL) framework with the VFL framework to better detect fraudulent transactions while defending against sequence inference attacks. Finally, we evaluate SIS attack and ASIA method in experiments based on two public fraud detection datasets: European Credit Card (ECC) and IEEE-CIS Fraud Detection (Vesta). The experimental results show that the sequences of the participants are at a high risk of being leaked when suffering SIS attack. Moreover, compared with several widely used federated boosting tree methods, ASIA method can significantly improve privacy-preserving performance without sacrificing fraud detection accuracy.}
}


@article{DBLP:journals/tifs/LiLHZZZJZV24,
	author = {Ruoyu Li and
                  Qing Li and
                  Yucheng Huang and
                  Qingsong Zou and
                  Dan Zhao and
                  Zhengxin Zhang and
                  Yong Jiang and
                  Fa Zhu and
                  Athanasios V. Vasilakos},
	title = {SeIoT: Detecting Anomalous Semantics in Smart Homes via Knowledge
                  Graph},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7005--7018},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3428856},
	doi = {10.1109/TIFS.2024.3428856},
	timestamp = {Tue, 14 Jan 2025 14:24:31 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiLHZZZJZV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing IoT Network Anomaly Detection Systems (NADSes) typically treat IoT devices as independent entities and model them by Euclidean space features. These approaches suffer from low accuracies on new attacks (e.g., platform-based attacks and evasion attacks), since they do not fully consider the semantic information including traffic periodicity and device/environment interactions. In this paper, we propose SeIoT, a knowledge graph-based bimodal anomaly detection framework for smart homes. We propose a knowledge graph structure to represent the semantic information of a smart home. First, we propose the Action Fingerprint module, an efficient and effective traffic classification approach to extract the device actions and features required by the knowledge graph. Then, we propose a bimodal anomaly detection framework including interaction-related and time-related detectors to detect the knowledge graph. We propose a feature separation-based heterogeneous graph attention network that can accurately model the interactions among devices and environments, and a method to represent traffic periodicity for the time-related detector. For evaluation, we set up a real-world testbed and evaluate the detection performance of both device-targeted attacks and platform-based attacks. Experiment results show that SeIoT can achieve better detection capability than prior work on both of the attacks.}
}


@article{DBLP:journals/tifs/LiuWYMCZL24,
	author = {Zhusen Liu and
                  Weizheng Wang and
                  Yutong Ye and
                  Nan Min and
                  Zhenfu Cao and
                  Lu Zhou and
                  Zhe Liu},
	title = {Collusion-Resilient and Maliciously Secure Cloud- Assisted Two-Party
                  Computation Scheme in Mobile Cloud Computing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7019--7032},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3428410},
	doi = {10.1109/TIFS.2024.3428410},
	timestamp = {Thu, 27 Feb 2025 22:37:47 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuWYMCZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile smart devices provide convenience for people’s daily life with the users’ data, but also put consumers’ privacy and security at risk. Privacy-enhancing technologies (PETs), including secure two/multi-party computation, have emerged as solutions to alleviate privacy concerns in mobile cloud computing (MCC). However, cloud servers, although capable of easing the burden of PETs, introduce potential risks by being malicious and colluding with computation parties to access additional private data. In this article, we propose a privacy-preserving cloud-assisted two-party computation scheme and the optimized variant with the half-gate method in MCC with a higher security level. To the best of our knowledge, the work is the first cloud-assisted two-party computation, designed to resist all collusion attacks in the malicious model. This is achieved by distributing circuit generation tasks among the parties and separately processing private inputs based on authenticated garbled circuits. Security analysis demonstrates that our scheme ensures correctness and fairness. Performance comparison results indicate the efficiency of our work, even with stronger security against malicious servers and any collusion attack. It outperforms the state-of-the-art scheme, particularly in terms of the server’s communication cost in the online phase, achieving a remarkable reduction of approximately 96.8%.}
}


@article{DBLP:journals/tifs/KongDM24,
	author = {Justin Kong and
                  Fikadu T. Dagefu and
                  Terrence J. Moore},
	title = {Covert Routing in Heterogeneous Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7047--7059},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3419703},
	doi = {10.1109/TIFS.2024.3419703},
	timestamp = {Fri, 02 Aug 2024 21:40:09 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KongDM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we explore covert routing communication in a heterogeneous network where a source sends a confidential message to a destination node with the help of relaying nodes where each node adaptively selects one modality among multiple communication modalities based on the wireless environment. We study three optimization problems: 1) the maximization of the end-to-end detection error probability at an adversary with a requirement on the throughput; 2) the end-to-end throughput maximization under a covertness constraint; and 3) the end-to-end latency minimization with a covertness condition. For the three optimization problems, we develop novel algorithms that identify the routes from a source to a destination and allocate resources, which are communication modality, transmit power, and bandwidth, at all nodes along the route. First, for single-hop communications, we derive a closed-form joint optimal power and bandwidth solution for a given modality, and then provide a modality selection method. For multi-hop communications, we propose the optimal routing strategies for the three problems by modeling the network as graphs and defining edge weights based on the objectives of the problems. From numerical simulations, it is validated that the performance of the network can be enhanced with the proposed optimal joint route and resource allocation techniques by judiciously selecting one of the multiple modalities for each hop in the route based on the wireless environment.}
}


@article{DBLP:journals/tifs/LiuHJNQW24,
	author = {Chao Liu and
                  Cankun Hou and
                  Tianyu Jiang and
                  Jianting Ning and
                  Hui Qiao and
                  Yusen Wu},
	title = {{FACOS:} Enabling Privacy Protection Through Fine-Grained Access Control
                  With On-Chain and Off-Chain System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7060--7074},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3427311},
	doi = {10.1109/TIFS.2024.3427311},
	timestamp = {Sun, 06 Oct 2024 21:41:08 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuHJNQW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data-driven landscape across finance, government, and healthcare, the continuous generation of information demands robust solutions for secure storage, efficient dissemination, and fine-grained access control. Blockchain technology emerges as a significant tool, offering decentralized storage while upholding the tenets of data security and accessibility. However, on-chain and off-chain strategies are still confronted with issues such as untrusted off-chain data storage, absence of data ownership, limited access control policy for clients, and a deficiency in data privacy and auditability. To solve these challenges, we propose a permissioned blockchain-based privacy-preserving fine-grained access control on-chain and off-chain system, namely FACOS. We applied three fine-grained access control solutions and comprehensively analyzed them in different aspects, which provides an intuitive perspective for system designers and clients to choose the appropriate access control method for their systems. Compared to similar work that only stores encrypted data in centralized or non-fault-tolerant IPFS systems, we enhanced off-chain data storage security and robustness by utilizing a highly efficient and secure asynchronous Byzantine fault tolerance (BFT) protocol in the off-chain environment. As each of the clients needs to be verified and authorized before accessing the data, we involved the Trusted Execution Environment (TEE)-based solution to verify the credentials of clients. Additionally, our evaluation results demonstrated that our system (https://github.com/cliu717/AsynchronousStorage) offers better scalability and practicality than other state-of-the-art designs. We deployed our system on Alibaba Cloud and Tencent Cloud and conducted multiple evaluations. The results indicate that it takes about 2.79 seconds for a client to execute the protocol for uploading and about 0.96 seconds for downloading. Compared to other decentralized systems, our system exhibits efficient latency for both download and upload operations.}
}


@article{DBLP:journals/tifs/XieFZWZHZ24,
	author = {Yumeng Xie and
                  Qing Fan and
                  Chuan Zhang and
                  Tong Wu and
                  Yuao Zhou and
                  Debiao He and
                  Liehuang Zhu},
	title = {Accountable and Secure Threshold EdDSA Signature and Its Applications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7033--7046},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3428848},
	doi = {10.1109/TIFS.2024.3428848},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XieFZWZHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Threshold signatures as a method to realize multi-party cooperation and trust distribution in blockchain have been widely studied in recent years. However, among these researches, few threshold signature schemes achieve all the properties of accountability, privacy, and key protection for the EdDSA-based blockchain systems. To fill this gap, we propose an EdDSA-based accountable threshold signature protocol with privacy and proactive refresh, named TAPS-PR. Meanwhile, we define new security models and give a detailed analysis to prove protocol security. In TAPS-PR, the threshold is variable and hidden with the signing quorum from the public view. However, the signing quorum can be traced when threshold signatures related to fraudulent events are generated. We also enhance the key security of each signer by proactive refresh, which realizes updating the private key while the public key remains unchanged. Apart from that, we present ATS-PR with increased efficiency and reduced communication cost at the cost of weaker security. The theoretical analysis and experimental results indicate that our protocols perform efficiently in terms of communication and computation overhead. Furthermore, we use Tezos, a blockchain project employing EdDSA, as a case study to demonstrate the compatibility of our protocol with real-world blockchain applications.}
}


@article{DBLP:journals/tifs/LuoLZ24,
	author = {Hualiang Luo and
                  Quanzhong Li and
                  Qi Zhang},
	title = {Joint Secure Beamforming and Power Splitting Design for {MIMO} Relay
                  Assisted Over-the-Air Computation Networks With Imperfect {CSI}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7075--7090},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3430549},
	doi = {10.1109/TIFS.2024.3430549},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuoLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider a physical layer security issue in a multiple-input multiple-output (MIMO) relay assisted over-the-air computation (AirComp) network, where sensors send their sensing data to the access point (AP) via a harvest and forward relay, and an eavesdropper (Eve) attempts to wiretap the aggregation result of sensors’ sensing signals. In the first time slot, the AP applies artificial noise (AN) to protect the aggregation result from being wiretapped by the Eve, and the relay harvests energy from the received signal according to the power splitting protocol. In the second time slot, the relay forwards the received signal, containing AN and sensors’ sensing signals, to the AP. The channel state information (CSI) between each node is assumed to be imperfect, and the channel uncertainties are molded as bounded errors. Specifically, we investigate a joint secure beamforming and power splitting design to minimize the worst-case mean-square error (MSE) at the AP, subject to the worst-case MSE constraint of the Eve and the worst-case transmit power constraints at each node. Different from the common approach that ignores the higher-order terms of channel uncertainties caused by cascade channels, by exploiting the block coordinate descent (BCD) algorithm, cutting set (CS) method and constrained concave-convex procedure (CCCP), we propose a BCD-CS-CCCP algorithm attempting to solve the robust optimization problem while retaining the higher-order terms of channel uncertainties. Numerical results indicate the effectiveness of our proposed schemes.}
}


@article{DBLP:journals/tifs/ChenW24,
	author = {Yige Chen and
                  Yipeng Wang},
	title = {{MPAF:} Encrypted Traffic Classification With Multi-Phase Attribute
                  Fingerprint},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7091--7105},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3428839},
	doi = {10.1109/TIFS.2024.3428839},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of cryptographic protocols such as Transport Layer Security (TLS) has necessitated the development of effective methods for encrypted traffic classification. The existing methods relying on a single feature source face challenges in achieving high accuracy and efficiency simultaneously. Additionally, there is a decrease in accuracy in complex scenarios, posing significant challenges for networks and security services based on application-level traffic classification. In this paper, we propose Multi-Phase Attribute Fingerprint (MPAF), an encrypted traffic classification system that overcomes these limitations. MPAF leverages three phases to separately leverage attributes that emerge at different time periods of encrypted traffic communication. Additionally, we transform discrete attributes into computable vectors through embedding and design a classifier for the multi-phase mechanism based on a leaf node masking tree. The experimental results show that MPAF achieves a classification accuracy ranging from 96.33% to 99.42% and an average waiting time (AWT) ranging from 0.18s to 0.45s. MPAF outperforms other approaches in scenarios with high robustness requirements, including small-scale training datasets, cross-dataset classification, and unknown application recognition.}
}


@article{DBLP:journals/tifs/HuangXZWSL24,
	author = {Yaxuan Huang and
                  Kaiping Xue and
                  Bin Zhu and
                  David S. L. Wei and
                  Qibin Sun and
                  Jun Lu},
	title = {Joint Distribution Analysis for Set-Valued Data With Local Differential
                  Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7106--7117},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3423657},
	doi = {10.1109/TIFS.2024.3423657},
	timestamp = {Tue, 17 Dec 2024 16:57:28 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuangXZWSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Set-valued data are commonly used to represent subsets of a universal set and are frequently utilized in online services, such as online shopping preferences, website browsing records, and recently visited places. By collecting set-valued data from users, service providers can perform statistical analysis to obtain a joint distribution of service usage data and subsequently learn the association between different kinds of set-valued data to improve the quality of service. However, collecting set-valued data raises privacy concerns about the potential misuse of records to infer individuals’ identities and preferences. Although some privacy-preserving aggregation mechanisms for set-valued data have been proposed, they have not yet achieved joint distribution analysis with high accuracy. In this paper, we propose a joint distribution analysis method for set-valued data with local differential privacy (LDP). We design a scalable perturbation mechanism under \\epsilon -LDP by limiting the range of users’ responses in the collection process and cyclically shifting the set-valued data in an encoded uniform format, ensuring that the size of the universal set does not influence the accuracy of the results. Based on the perturbation method, we develop an analysis method to efficiently obtain association information between two sets. By performing specific bitwise operations on the perturbed data matrices, the computational overhead is linear with respect to the cardinality of the item set. In addition to theoretically analyzing the error bound and proving the security of our work, extensive experimental results on synthetic and real-world datasets demonstrate that our scheme achieves better utility than existing state-of-the-art approaches.}
}


@article{DBLP:journals/tifs/FanZWWZZY24,
	author = {Haopeng Fan and
                  Hailong Zhang and
                  Yongjuan Wang and
                  Wenhao Wang and
                  Yanbei Zhu and
                  Haojin Zhang and
                  Qingjun Yuan},
	title = {Screening Least Square Technique Assisted Multivariate Template Attack
                  Against the Random Polynomial Generation of Dilithium},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7118--7132},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3430854},
	doi = {10.1109/TIFS.2024.3430854},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FanZWWZZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the security of Dilithium against side-channel attacks (SCA) has attracted great attentions from the cryptographic engineering community. However, existing power analysis attacks cannot fully utilize the side-channel leakages of the Dilithium reference implementation to efficiently recover the private key. In light of this, a screening least square technique assisted multivariate template attack (SLST assisted MTA) is proposed in this paper. In SLST assisted MTA, side-channel leakages of coefficient y_{i} of random polynomial y, unsigned number x_{i} and random byte string a_{i^{\\prime }} can be utilized simultaneously to recover coefficient y_{i} of random polynomial y with MTA. Then, one can build error-tolerant equations, and the private key \\mathbf {s_{1}} can be solved with SLST efficiently. We evaluate the private key recovery efficiency of SLST assisted MTA with real traces measured from the Cortex-M4 processor based Dilithium reference implementation, and the evaluation results show that with MTA, 19.41%, 15.70% and 16.88% of the coefficients of y can be accurately recovered in cases of Dilithium 2, 3 and 5. Besides, using SLST, after five times screening, only 38, 40 and 39 power traces are enough to recover private key \\mathbf {s_{1}} of Dilithium 2, 3 and 5 with 100% of success rate.}
}


@article{DBLP:journals/tifs/WuYSLHL24,
	author = {Junyan Wu and
                  Qilin Yin and
                  Ziqi Sheng and
                  Wei Lu and
                  Jiwu Huang and
                  Bin Li},
	title = {Audio Multi-View Spoofing Detection Framework Based on Audio-Text-Emotion
                  Correlations},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7133--7146},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3431888},
	doi = {10.1109/TIFS.2024.3431888},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuYSLHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, audio spoofing detection has received widespread attention for protecting personal privacy and social security. Despite the significant progress achieved in audio single-view spoofing detection, challenges remain with regard to addressing unknown spoofing attacks in realistic scenarios. To solve these challenging problems, in this paper, we introduce a novel audio multi-view spoofing detection framework (AMSDF), whose goal is to capture both intra-view and inter-view cues by measuring correlations within audio multi-view features (i.e., audio-emotion-text) for audio spoofing detection. In general, different view features are inherently interconnected in the real patterns, while they may present unnatural correlations in the spoofing patterns. Therefore, more discriminative cues can be mined by utilizing their complex interactions, which is beneficial to the audio spoofing detection task. To this end, an intra-view graph attention mechanism (IGAM) is first utilized to aggregate each intra-view node within the same view. Subsequently, a heterogeneous graph fusion module (HGFM) is applied to measure correlations within inter-view nodes, which are enhanced with a master node for comprehensive analysis purposes. Finally, a group-based readout scheme (GRS) is designed to capture and preserve the most distinctive cues by leveraging the strengths of different feature sets, thereby effectively distinguishing subtle differences between real and spoofing audio. The experimental results show that our proposed framework can achieve better performance than that of the state-of-the-art methods, especially in realistic scenarios. The code and pre-trained models are available at https://github.com/ItzJuny/AMSDF.}
}


@article{DBLP:journals/tifs/WangYW24,
	author = {Minxiao Wang and
                  Ning Yang and
                  Ning Weng},
	title = {K-GetNID: Knowledge-Guided Graphs for Early and Transferable Network
                  Intrusion Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7147--7160},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3431932},
	doi = {10.1109/TIFS.2024.3431932},
	timestamp = {Mon, 05 Aug 2024 21:42:57 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Developing early and transferable Network Intrusion Detection Systems (NIDSs) is essential for robust network security. Early detection prevents further damage, while transferable NIDSs enables reuse across diverse networks. For Machine Learning (ML) and Deep Learning (DL)-based NIDSs, transferability significantly reduces data collection and annotation costs for timely attack mitigation. Current DL-based early intrusion detection studies often focus on identifying attacks from the first few packets, neglecting the crucial aspect of adjustable early detection. Additionally, most DL-based NIDS methods overlook transferability during both design and evaluation phases. To address these limitations, we propose K-GetNID, a knowledge-guided graph learning-based NIDS that excels in both early and transferability. We introduce a Heterogeneous Temporal Graph (HTGraph) to represent the dynamic feature series of network flows, providing enough information for early detection. Additionally, we construct this HTGraph format based on prior knowledge about feature types and correlations to assist the neural network in learning general and transferable knowledge for intrusion detection. We develop a corresponding Heterogeneous Temporal Graph Neural Network (HTGNN) model to learn from the HTGraph format. Furthermore, an Adjustable Early Detection Decoder is designed to enhance the generalization of the proposed model to the input distribution shifts caused by early detection. Experiments on CIC-IDS-2017 and UNSW-NB15 datasets show that K-GetNID matches the performance of deep learning methods, excelling in adjustable early intrusion detection and transferability.}
}


@article{DBLP:journals/tifs/LiLLCJGY24,
	author = {Ximing Li and
                  Linghui Li and
                  Xiaoyong Li and
                  Binsi Cai and
                  Jia Jia and
                  Yali Gao and
                  Shui Yu},
	title = {{GMFITD:} Graph Meta-Learning for Effective Few-Shot Insider Threat
                  Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7161--7175},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3430106},
	doi = {10.1109/TIFS.2024.3430106},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiLLCJGY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Insider threats represent a significant challenge in both corporate and governmental sectors. Most existing supervised learning based detection methods that rely on transforming user behavior into sequential data do not fully utilize structural information and require extensive labeled data. This reliance poses a challenge due to the scarcity of labeled data in real-world scenarios, leading to a few-shot learning situation. To address these limitations, we propose a novel Graph modularized-based Meta-learning Framework for Insider Threat Detection, named GMFITD. Specifically, GMFITD utilizes a structural reconstruction mechanism that combines a graph-based autoencoder with an attention mechanism to explore structural information and infer potential relationships between users. Additionally, we employ a graph prototype construction method coupling episodic meta-learning principle (MAML) to compute representative embeddings for few-shot learning scenarios. By leveraging MAML, the proposed method can capture prior knowledge of insider threat classification by training on similar few-shot learning tasks with few labeled samples. We further enhance the resilience of GMFITD to adversarial attacks through an edge importance estimation mechanism, which assigns higher weights to relevant edges. Extensive experiments demonstrate that our proposed GMFITD outperforms state-of-the-art methods in insider threat detection, achieving higher accuracy with fewer labeled samples and resisting adversarial attacks.}
}


@article{DBLP:journals/tifs/AhnLHLC24,
	author = {Kyeongjin Ahn and
                  SeungEon Lee and
                  Sungwon Han and
                  Cheng{-}Yaw Low and
                  Meeyoung Cha},
	title = {Uncertainty-Aware Face Embedding With Contrastive Learning for Open-Set
                  Evaluation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7176--7186},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3426973},
	doi = {10.1109/TIFS.2024.3426973},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AhnLHLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While advances in deep learning have enabled novel applications in various fields, face recognition in open-set scenarios remains a complex task, owing to the challenges posed by the extensive volume of low-quality face images. We introduce a new approach for recognizing faces in unconstrained open-set settings by leveraging uncertainty-aware embeddings through contrastive learning. Our model, called UCFace, effectively regulates the contribution of each face image based on the face uncertainty derived from image quality as an inverse proxy. Face embeddings are reinterpreted as a probabilistic distribution within the embedding space, where the degree of sharpness (i.e., distribution concentration) reflects the underlying uncertainty and probability density is used as a similarity metric to facilitate contrastive learning. Experiments on a wide range of face datasets, including those with high, mixed, and real-world low-resolution face images, demonstrate that UCFace enhances open-set face recognition performance by integrating the aspect of uncertainty.}
}


@article{DBLP:journals/tifs/LiXWZ24,
	author = {Chengchao Li and
                  Fengde Xu and
                  Yuhan Wang and
                  Xudong Zhao},
	title = {Data-Driven Dynamic Periodic Event-Triggered Control of Cyber-Physical
                  Systems Under Packet Dropouts and DoS Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7187--7199},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3431280},
	doi = {10.1109/TIFS.2024.3431280},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiXWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the problem of data-driven and dynamic periodic event-triggered control (DPETC) for unknown cyber-physical systems (CPSs) against Denial-of-Service (DoS) attacks and successive packet losses. An unified hybrid system framework is proposed to describe the whole CPS, in which DoS attacks are characterized in terms of duration and frequency. Building on the hybrid system framework, we present model-based co-design conditions for a dynamic periodic event-triggering mechanism (DPETM) and controller to ensure\nL\n2\n-stability of the CPSs while tolerating both DoS attacks and a maximal allowable number of successive packet dropouts (MANSDs). By integrating the model-based conditions with the data-based parametric representation and employing a linear fractional transformation (LFT) approach, corresponding data-based sufficient conditions are derived. Finally, numerical simulations of a batch reactor system demonstrate the effectiveness of the proposed co-design approach.}
}


@article{DBLP:journals/tifs/DarjaniKRK24,
	author = {Armin Darjani and
                  Nima Kavand and
                  Shubham Rai and
                  Akash Kumar},
	title = {Thwarting GNN-Based Attacks Against Logic Locking},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7200--7215},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3431991},
	doi = {10.1109/TIFS.2024.3431991},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DarjaniKRK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The globalization of the IC manufacturing flow has exposed intellectual property (IP) to many untrustworthy entities. As a result, security should be considered a new paradigm in designing circuits to protect the integrity and confidentiality of the IP. Logic locking is a holistic design-for-trust (DFT) technique that can protect circuits against IP piracy and reverse engineering. However, a large body of recent research has demonstrated successful methods of recovering the secret key and restoring the original functionality of existing locking systems. Although SAT attack has been a de facto technique to break the logic locking, the threat model and efficiency of this attack have been questioned recently. To overcome these shortcomings, researchers have proposed powerful structural attacks that break the locked circuits without the need for functionally unlocked circuits (Oracle). Among structural attacks, machine learning (ML)-based attacks are the most potent attacks as they harness the power of neural networks to learn traces of the locking structures and use this knowledge to reverse back and neutralize the locking scheme. Among ML approaches, GNN (graph neural networks)-based attacks are shown to be the most capable tools that attackers can employ as they exploit graph structures inherent to a circuit’s netlist. In this paper, (1) We discuss the inherent structural weaknesses of the logic locking techniques. (2) Knowing these weaknesses, we investigate the challenges of protecting circuits against GNN-based attacks. (3) We propose GNN-resilient Interconnect-based obfuscation (GRIN) and GNN-resilient Gate-based Obfuscation (GREGO) logic locking schemes with learning resilient structures. We evaluate our secure schemes using ISCAS-85 and ITC-99 benchmarks and provide comprehensive security and overhead analysis of our proposed schemes.}
}


@article{DBLP:journals/tifs/QianHMDYCW24,
	author = {Yuwen Qian and
                  Guodong Huang and
                  Chuan Ma and
                  Ming Ding and
                  Long Yuan and
                  Zi Chen and
                  Kai Wang},
	title = {Enhancing Resilience in Website Fingerprinting: Novel Adversary Strategies
                  for Noisy Traffic Environments},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7216--7231},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3432404},
	doi = {10.1109/TIFS.2024.3432404},
	timestamp = {Mon, 03 Feb 2025 07:44:38 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/QianHMDYCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The act of website fingerprinting, which involves monitoring traffic features to infer private user information, has attracted much attention in the research community recently. While previous studies primarily focused on classifying fingerprint information using clean traffic data, it remains a challenging task to apply fingerprinting to noisy traffic data or evade defensive measures. This work aims to address the challenges associated with website fingerprinting attacks and defense strategies in the presence of noise. Specifically, we introduce two novel attack methods: filter-assisted attack and augmentation-assisted attack. The first attack method leverages packet size distribution to effectively filter out noise, while the second one trains a classification model by incorporating artificial noise. Compared with the traditional website fingerprinting attacks, these proposed attack methods demonstrate superior resilience to noise and exceptional evasion capabilities against defensive measures (e.g., random packet defense, Walkie-Talkie, WTF-PAD, etc.). In parallel, we propose a list-assisted defense strategy that strikes a balance between defense performance and network overhead. This defense mechanism offers effective protection against website fingerprinting attacks while minimizing the impact on network performance. In our experiments, we employ a comprehensive dataset encompassing TCP/IP traffic with packet size information collected from three prominent web browsers, as well as Tor cell traffic without packet size information obtained from a Tor browser. We thoroughly evaluate our proposed methods in both closed-world and open-world scenarios. Our experimental results shed valuable insights into the influence of noise and the efficacy of different attack and defense approaches on website fingerprinting.}
}


@article{DBLP:journals/tifs/LuoWYW24,
	author = {Fucai Luo and
                  Haiyan Wang and
                  Xingfu Yan and
                  Jiahui Wu},
	title = {Key-Policy Attribute-Based Encryption With Switchable Attributes for
                  Fine-Grained Access Control of Encrypted Data},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7245--7258},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3432279},
	doi = {10.1109/TIFS.2024.3432279},
	timestamp = {Mon, 26 Aug 2024 17:32:33 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuoWYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fine-grained access control systems facilitate granting differential access rights to a set of users and allow flexibility in specifying the access rights of individual users. As an important fine-grained access control technique, key-policy attribute-based encryption (KP-ABE) has been introduced to achieve fine-grained access control over encrypted data, where each ciphertext is associated with an attribute set such that users satisfying the attribute set can decrypt the ciphertext. In the real-world application scenarios of KP-ABE, various situations such as users leaving the system, compromise of users’ private keys, and business requirements frequently occur, necessitating the revocation of decryption rights for large-scale users. To address the user revocation, numerous revocable KP-ABE schemes have been proposed. However, existing revocable KP-ABE schemes are vulnerable to quantum computer attacks. More importantly, existing solutions fail to address the user addition, where users capable of decrypting certain ciphertexts would like to grant decryption rights to others; this is a highly common requirement, such as changes in user decryption permissions and business needs. This paper explores a potentially new avenue of research to address the above issues by introducing a novel cryptographic primitive called key-policy ABE with switchable attributes (KP-ABE-SA). In the KP-ABE-SA system, each ciphertext linked to an attribute set can be transformed into one associated with another (distinct) attribute set, enabling both user revocation and addition. Furthermore, to withstand quantum computer attacks, we construct a KP-ABE-SA scheme based on the Learning with Errors (LWE) assumption, which is widely believed to be quantum-resistant. Finally, we conduct a comprehensive performance evaluation of our LWE-based KP-ABE-SA scheme, and the experimental results show that the proposed LWE-based KP-ABE-SA scheme is efficient and practical.}
}


@article{DBLP:journals/tifs/ZhongHJHZW24,
	author = {Fangtian Zhong and
                  Qin Hu and
                  Yili Jiang and
                  Jiaqi Huang and
                  Cheng Zhang and
                  Dinghao Wu},
	title = {Enhancing Malware Classification via Self-Similarity Techniques},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7232--7244},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3433372},
	doi = {10.1109/TIFS.2024.3433372},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhongHJHZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite continuous advancements in defense mechanisms, attackers often find ways to circumvent security measures. Windows operating systems, in particular, are vulnerable due to fewer restrictions on downloading software from unknown sources, facilitating the spread of malware. To address this challenge, researchers have focused on developing techniques to identify Windows malware, crucial for mitigating potential damage. Traditional approaches typically categorize threats into broad classes such as trojans or adware, often failing to capture the full spectrum of malicious behaviors exhibited by diverse malware variants. In response, we propose a novel approach to malware categorization that incorporates both the general malware family and subfamily for each sample. Our method leverages self-similarity techniques to extract local semantics and similarities within the blocks of malware binaries while preserving correlations between these blocks. We utilize a VGG11 model to capture these features, enabling accurate classification. Central to our approach is the conversion of malware binaries into self-similarity descriptors, facilitating space savings while capturing essential semantics within blocks. By focusing on local self-similarities and their geometric layouts across malware, our method effectively identifies repetitive patterns indicative of malware behavior. Our proof-of-concept implementation demonstrates the effectiveness of our framework, achieving an impressive average precision of 98.2% on a newly gathered dataset with over 25,000 samples. Moreover, our method offers significant space savings, outperforming recent research efforts by a factor of over 96. These results underscore the efficacy of incorporating self-similarities and correlations within blocks for robust malware classification, making our approach a promising solution for real-world malware detection and prevention.}
}


@article{DBLP:journals/tifs/FeiMGMS24,
	author = {Hongming Fei and
                  Owen Millwood and
                  Prosanta Gope and
                  Jack Miskelly and
                  Biplab Sikdar},
	title = {Attacking Delay-Based PUFs With Minimal Adversarial Knowledge},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7259--7274},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3433548},
	doi = {10.1109/TIFS.2024.3433548},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FeiMGMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physically Unclonable Functions (PUFs) provide a streamlined solution for lightweight device authentication. Delay-based Arbiter PUFs, with their ease of implementation and vast challenge space, have received significant attention; however, they are not immune to modelling attacks that exploit correlations between their inputs and outputs. Research is therefore polarized between developing modelling-resistant PUFs and devising machine learning attacks against them. This dichotomy often results in exaggerated concerns and overconfidence in PUF security, primarily because there lacks a universal tool to gauge a PUF’s security. In many scenarios, attacks require additional information, such as PUF type or configuration parameters. Alarmingly, new PUFs are often branded ‘secure’ if they lack a specific attack model upon introduction. To impartially assess the security of delay-based PUFs, we present a generic framework featuring a Mixture-of-PUF-Experts (MoPE) structure for mounting attacks on various PUFs with minimal adversarial knowledge, which provides a way to compare their performance fairly and impartially. We demonstrate the capability of our model to attack different PUF types, including the first successful attack on Heterogeneous Feed-Forward PUFs using only a reasonable amount of challenges and responses. We propose an extension version of our model, a Multi-gate Mixture-of-PUF-Experts (MMoPE) structure, facilitating multi-task learning across diverse PUFs to recognise commonalities across PUF designs. This allows a streamlining of training periods for attacking multiple PUFs simultaneously. We conclude by showcasing the potent performance of MoPE and MMoPE across a spectrum of PUF types, employing simulated, real-world unbiased, and biased data sets for analysis.}
}


@article{DBLP:journals/tifs/LvLDCYZZ24,
	author = {Qingxuan Lv and
                  Yuezun Li and
                  Junyu Dong and
                  Sheng Chen and
                  Hui Yu and
                  Huiyu Zhou and
                  Shu Zhang},
	title = {DomainForensics: Exposing Face Forgery Across Domains via Bi-Directional
                  Adaptation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7275--7289},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3426317},
	doi = {10.1109/TIFS.2024.3426317},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LvLDCYZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent DeepFake detection methods have shown excellent performance on public datasets but are significantly degraded on new forgeries. Solving this problem is important, as new forgeries emerge daily with the continuously evolving generative techniques. Many efforts have been made for this issue by seeking the commonly existing traces empirically on data level. In this paper, we rethink this problem and propose a new solution from the unsupervised domain adaptation perspective. Our solution, called DomainForensics, aims to transfer the forgery knowledge from known forgeries (fully labeled source domain) to new forgeries (label-free target domain). Unlike recent efforts, our solution does not focus on data view but on learning strategies of DeepFake detectors to capture the knowledge of new forgeries through the alignment of domain discrepancies. In particular, unlike the general domain adaptation methods which consider the knowledge transfer in the semantic class category, thus having limited application, our approach captures the subtle forgery traces. We describe a new bi-directional adaptation strategy dedicated to capturing the forgery knowledge across domains. Specifically, our strategy considers both forward and backward adaptation, to transfer the forgery knowledge from the source domain to the target domain in forward adaptation and then reverse the adaptation from the target domain to the source domain in backward adaptation. In forward adaptation, we perform supervised training for the DeepFake detector in the source domain and jointly employ adversarial feature adaptation to transfer the ability to detect manipulated faces from known forgeries to new forgeries. In backward adaptation, we further improve the knowledge transfer by coupling adversarial adaptation with self-distillation on new forgeries. This enables the detector to expose new forgery features from unlabeled data and avoid forgetting the known knowledge of known forgery. Extensive experiments demonstrate that our method is surprisingly effective in exposing new forgeries, and can be plug-and-play on other DeepFake detection architectures.}
}


@article{DBLP:journals/tifs/HouHCLH24,
	author = {Saihui Hou and
                  Xuecai Hu and
                  Chunshui Cao and
                  Xu Liu and
                  Yongzhen Huang},
	title = {Adaptive Knowledge Transfer for Weak-Shot Gait Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7290--7303},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3428371},
	doi = {10.1109/TIFS.2024.3428371},
	timestamp = {Sun, 19 Jan 2025 14:20:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HouHCLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most works for cloth-changing gait recognition assume that the sequences of different clothes are accessible for each subject in the training set, which, however, is almost impossible for real applications. In practice, the collection of gait sequences is usually aided by person re-identification which is more likely to cluster the cloth-consistent sequences for a subject, and it is laborious to merge the cloth-changing clusters with the same identity. As a result, the training set is usually comprised of two subsets, i.e., a fully-annotated base set where the cloth-changing sequences are available for each subject, and a weakly-annotated wild set where the sequences of different clothes for a subject are assigned diverse labels. In this work, we formulate a problem named Weak-Shot Gait Recognition which seeks to learn discriminative features from the mixture of base set and wild set. Furthermore, we propose an effective method called Adaptive Knowledge Transfer to deal with the weak-shot issue. In particular, we define the knowledge as the ability to judge whether two sequences come from the same subject or not, and we take an adaptive way to mine the useful information from wild set. For the experimental study, we build three weak-shot benchmarks based on CASIA-B, Outdoor-Gait, and CASIA-E respectively. Extensive experiments show that our method can bring consistent improvement. For example, under the cloth-changing condition of on the weak-shot CASIA-B, our method exceeds a naïve baseline by 7.10%.}
}


@article{DBLP:journals/tifs/RassKAG24,
	author = {Stefan Rass and
                  Sandra K{\"{o}}nig and
                  Shahzad Ahmad and
                  Maksim Goman},
	title = {Metricizing the Euclidean Space Toward Desired Distance Relations
                  in Point Clouds},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7304--7319},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420246},
	doi = {10.1109/TIFS.2024.3420246},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/RassKAG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce the concept of an \\varepsilon\n-semimetric that satisfies the same axioms as a topological metric, except for an arbitrarily small allowance to violate the triangle inequality. Under this modification, we demonstrate the possibility of taking arbitrary points in space, assigning arbitrary desired distances between them (independent of their geometric location relative to each other, that is, independent of their “features”), and constructing an \\varepsilon\n-semimetric that measures exactly the desired distances in the point cloud. This results in a threat to fairness and objectiveness in applications of clustering algorithms: suppose that an adversary subjectively classifies people according to its whim or discriminatory preferences. Upon accusations of unethical behavior, the malicious data processor can plausibly deny these as follows: it designs a distance function (an \\varepsilon\n-semimetric) that is (up to a fully controllable numeric “round-off-error” \\varepsilon\n) equivalent to a standard distance like the Euclidean. However, this crafted distance will exactly reproduce the (malicious) results and thus confirm them while pretending objectivity and transparency, since only standard and explainable artificial intelligence was used. This demonstration works without any data poisoning. We illustrate the method on randomly chosen points with stochastically independent random classifications assigned to them. Then, we apply standard implementations of k-Means and DBSCAN on the data points, which both exactly reproduce the desired (randomly chosen) classes. We also discuss non-adversarial applications of \\varepsilon\n-semimetrics, and corroborate the construction with examples and implementation in Octave.}
}


@article{DBLP:journals/tifs/IliasKA24,
	author = {Loukas Ilias and
                  Ioannis Michail Kazelidis and
                  Dimitris Askounis},
	title = {Multimodal Detection of Bots on {X} (Twitter) Using Transformers},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7320--7334},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3435138},
	doi = {10.1109/TIFS.2024.3435138},
	timestamp = {Mon, 03 Mar 2025 22:25:01 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/IliasKA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although not all bots are malicious, the vast majority of them are responsible for spreading misinformation and manipulating the public opinion about several issues, i.e., elections and many more. Therefore, the early detection of bots is crucial. Although there have been proposed methods for detecting bots in social media, there are still substantial limitations. For instance, existing research initiatives still extract a large number of features and train traditional machine learning algorithms or use GloVe embeddings and train LSTMs. However, feature extraction is a tedious procedure demanding domain expertise. Also, language models based on transformers have been proved to be better than LSTMs. Other approaches create large graphs and train graph neural networks requiring in this way many hours for training and access to computational resources. To tackle these limitations, this is the first study employing only the user description field and images of three channels denoting the type and content of tweets posted by the users. Firstly, we create digital DNA sequences, transform them to 3d images, and apply pretrained models of the vision domain, including EfficientNet, AlexNet, VGG16, etc. Next, we propose a multimodal approach, where we use TwHIN-BERT for getting the textual representation of the user description field and employ VGG16 for acquiring the visual representation for the image modality. We propose three different fusion methods, namely concatenation, gated multimodal unit, and crossmodal attention, for fusing the different modalities and compare their performances. Finally, we present a qualitative analysis of the behavior of our best performing model. Extensive experiments conducted on the Cresci’17 and TwiBot-20 datasets demonstrate valuable advantages of our introduced approaches over state-of-the-art ones.}
}


@article{DBLP:journals/tifs/XuZZWHFL24,
	author = {Wei Xu and
                  Hui Zhu and
                  Yandong Zheng and
                  Fengwei Wang and
                  Jiafeng Hua and
                  Dengguo Feng and
                  Hui Li},
	title = {ToNN: An Oblivious Neural Network Prediction Scheme With Semi-Honest
                  {TEE}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7335--7348},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3435493},
	doi = {10.1109/TIFS.2024.3435493},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XuZZWHFL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid advancements in machine learning and the widespread adoption of Model-as-a-Service (MaaS) platforms, there has been significant attention on convolutional neural network (CNN) inference services. However, traditional inference services over plaintext data and models are susceptible to the risks of data and model leakage. Although several privacy-preserving CNN inference schemes utilizing trusted execution environment (TEE) and cryptography have been proposed, their security models and performance still have limitations in some scenarios. Aiming at the above challenges, we present an oblivious neural network prediction scheme with semi-honest TEE, namely ToNN, which ensures the security of users’ inputs, outputs, and the model itself. Specifically, based on the limited memory of the TEE, we design secure protocols to perform CNN calculations securely and efficiently, which are friendly to support the single instruction multiple data technique. Additionally, we propose a look-up-table method to optimize the convolution and pooling layers calculations. A detailed security analysis under the simulation-based real/ideal worlds model shows that ToNN can achieve the desired security. Extensive simulation results further demonstrate that ToNN can improve the performance of linear calculations by \\textbf {4.86}\\times and non-linear calculation by \\textbf {37.68}\\times , and can be implemented effectively with low computation and communication costs.}
}


@article{DBLP:journals/tifs/YaoPWXWLG24,
	author = {Zhisheng Yao and
                  Yang Peng and
                  Yu Wang and
                  Congan Xu and
                  Juzhen Wang and
                  Yun Lin and
                  Guan Gui},
	title = {A Novel Radio Frequency Fingerprint Concealment Method Based on {IQ}
                  Imbalance Compensation and Digital Pre-Distortion},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7349--7361},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3434605},
	doi = {10.1109/TIFS.2024.3434605},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YaoPWXWLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio frequency fingerprinting (RFF) serves as a distinctive hardware trait in transmitters, forming the cornerstone of transmitter identification. While recent advancements led to significant improvements in identification accuracy, these developments also inadvertently simplify the process for adversaries to detect our transmitters. This vulnerability is particularly concerning in secure communications, as the exposure of device information could potentially result in the compromise of communication content, posing significant security threats. To counteract such risks and safeguard transmitters against unauthorized identification, this paper proposes a novel RFF concealment (RFFC) method based on IQ imbalance compensation and digital pre-distortion (DPD) techniques. This method not only effectively conceals the RFF, preventing malicious detection of the transmitter, but also enhances the system’s linearization performance. The effectiveness of the proposed RFFC framework is validated through MATLAB Simulink and a software and hardware test platform. Experimental results show that using the blind generalized linear structure-based IQ imbalance and deep neural network (DNN)-based PA nonlinearity joint concealment method performs best, reducing transmitter identification accuracy to only 17% under various signal-to-noise ratio conditions. Additionally, this method performs the best in system linearization performance.}
}


@article{DBLP:journals/tifs/PangZXX24,
	author = {Yujing Pang and
                  Guangming Zhuang and
                  Jianwei Xia and
                  Xiangpeng Xie},
	title = {Fault Detection and Robust Security Control for Implicit Jump Systems
                  Against Random {FDI} Attacks and Packet Loss Under Memorized Output-Perceptive
                  Event-Triggered Protocol},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7362--7373},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3434739},
	doi = {10.1109/TIFS.2024.3434739},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PangZXX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates fault detection and robust security control of implicit Markovian jump (IMJ) systems affected by random false data injection (FDI) attacks and packet loss under memorized output-perceptive event-triggered protocol (MOETP). In order to harmonize control performance and communication efficiency, a mode-dependent MOETP is proposed by designing an output-dependent threshold function and introducing weight parameters. Fault detector and feedback controller incorporating random FDI attacks and packet loss information are cooperatively designed to detect the occurrence of system faults and achieve robust security control for IMJ systems. Considering the property that the derivative of “time-varying delay” function is 1 and the definition of error in MOETP, a novel mode-delay-related Lyapunov-Krasovskii functional is constructed so as to derive the strict linear matrix inequality criteria of H_{\\infty }\nstochastic admissibility as well as the expected gains of fault detector and security controller based on free-weight matrix method and matrix transformation technique. The validity of the presented co-design methodology is confirmed by a tunnel diode circuit system.}
}


@article{DBLP:journals/tifs/WangHLY24,
	author = {Qing Wang and
                  Donghui Hu and
                  Meng Li and
                  Guomin Yang},
	title = {Secure and Flexible Wildcard Queries},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7374--7388},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3430056},
	doi = {10.1109/TIFS.2024.3430056},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangHLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wildcard Keyword Searchable Encryption (WKSE) enables users to search desired encrypted files with wildcard queries. Previous schemes only enabled single-character wildcard queries or restricted multi-character wildcard queries. Even if the two types of queries are supported by several schemes, they are vulnerable to correlation attacks and composition attacks. In this paper, we propose a WKSE scheme Secure Flexible Wildcard Queries (SFWQ) that supports highly flexible wildcard queries and resists correlation and composition attacks. Specifically, we adopt the interval matching method instead of traditional position matching, so that SFWQ supports a variety of queries, including single-character wildcard queries, multi-character wildcard queries, and mixed wildcard queries that the combination of both single-character and multi-character wildcards within the same query. Moreover, the number and position of wildcards within wildcard keywords are adjustable according to user preference. To resist the correlation attack and composition attack, we leverage key aggregate searchable encryption (KASE) and key exchange protocol to process characters so that even the same characters of the same keyword behave as different ciphertexts. We define a security model for WKSE which catches the correlation attack and composition attack. Our proof validates SFWQ is secure under the security model. Finally, we implement SFWQ and compare it with state-of-the-art schemes. The experimental results demonstrate that our scheme is feasible and efficient.}
}


@article{DBLP:journals/tifs/WangZLJM24,
	author = {Mingyu Wang and
                  Fangyu Zheng and
                  Jingqiang Lin and
                  Fangjie Jiang and
                  Yuan Ma},
	title = {ZeroShield: Transparently Mitigating Code Page Sharing Attacks With
                  Zero-Cost Stand-By},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7389--7403},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3435062},
	doi = {10.1109/TIFS.2024.3435062},
	timestamp = {Tue, 04 Feb 2025 20:31:50 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangZLJM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Numerous cache side-channel attack techniques enable attackers to execute a cross-VM cache side-channel attack through the sharing of code pages with the targeted victim. Nonetheless, most prior defense solutions fall short of efficiency and ease of deployment, thus restricting their practicality for real-world implementation. This paper introduces ZeroShield, an adaptive and transparent approach implemented at the hypervisor layer, designed to counteract the code page sharing attack, a subset of cache side-channel attacks, occurring within a single virtual machine (VM) or spanning across multiple VMs. By thoroughly scrutinizing the “by-products” resulting from a code page sharing attack, we meticulously track the attacker’s access to security-sensitive code pages. This is achieved through harnessing hardware virtualization features, such as the Intel extended page table, in conjunction with the CR3 register. Utilizing this information, ZeroShield continuously monitors security-sensitive code pages, adeptly navigating complex OS and hypervisor behaviors. The architecture of ZeroShield exhibits an attack-aware design, enabling it to deploy protection measures on demand. Consequently, the system theoretically experiences negligible overhead in the absence of attackers. Empirical evidence confirms the effectiveness of ZeroShield in thwarting code page sharing attacks. It achieves this without imposing any performance penalties in the absence of attackers, and with a minimal overhead of less than 3.8% when attackers are active. Significantly, ZeroShield boasts a cost-free standby state and necessitates no adjustments to upper applications, guest OS, or hardware configurations. This attribute positions ZeroShield as an optimal default solution in real-world cloud environments to effectively counter code page sharing attacks.}
}


@article{DBLP:journals/tifs/ChenYCWLD24,
	author = {Zekai Chen and
                  Shengxing Yu and
                  Farong Chen and
                  Fuyi Wang and
                  Ximeng Liu and
                  Robert H. Deng},
	title = {Lightweight Privacy-Preserving Cross-Cluster Federated Learning With
                  Heterogeneous Data},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7404--7419},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3435476},
	doi = {10.1109/TIFS.2024.3435476},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenYCWLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) eliminates data silos that hinder digital transformation while training a shared global model collaboratively. However, training a global model in the context of FL has been highly susceptible to heterogeneity and privacy concerns due to discrepancies in data distribution, which may lead to potential data leakage from uploading model updates. Despite intensive research on above-identical issues, existing approaches fail to balance robustness and privacy in FL. Furthermore, limiting model updates or iterative clustering tends to fall into local optimum problems in heterogeneous (Non-IID) scenarios. In this work, to address these deficiencies, we provide lightweight privacy-preserving cross-cluster federated learning (PrivCrFL) on Non-IID data, to trade off robustness and privacy in Non-IID settings. Our PrivCrFL exploits secure one-shot hierarchical clustering with cross-cluster shifting for optimizing sub-group convergences. Furthermore, we introduce intra-cluster learning and inter-cluster learning with separate aggregation for mutual learning between each group. We perform extensive experimental evaluations on three benchmark datasets and compare our results with state-of-the-art studies. The findings indicate that PrivCrFL offers a notable performance enhancement, with improvements ranging from 0.26\\%~\\uparrow to 1.35\\%~\\uparrow across different Non-IID settings. PrivCrFL also demonstrates a superior communication compression ratio in secure aggregation, outperforming current state-of-the-art works by 10.59%.}
}


@article{DBLP:journals/tifs/SunYLJ24,
	author = {Xiao Sun and
                  Haining Yu and
                  Zhichao Liu and
                  Xiaohua Jia},
	title = {{MI-VFDNN:} An Efficient Vertical Federated Deep Neural Network With
                  Multi-Layer Interaction},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7435--7448},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3435557},
	doi = {10.1109/TIFS.2024.3435557},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SunYLJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is proposed to address the challenge of data isolation, with federated machine learning algorithms continuously evolving. Vertical Federated Learning (VFL) is a specific FL setting where parties possessing different features but the same entities collaboratively train models. However, existing VFL neural network schemes lack sufficient interactivity between involved parties, which results in diminished data value as model complexity increases. This limitation can lead to reduced accuracy with more intricate model structures. In our proposed scheme, we introduce additional interactions to enhance the effective utilization of data owned by the parties during the training period. To maintain security, we design a novel protocol that utilizes dimensionality reduction methods, ensuring interactions occur without information leakage and excessive communication costs. Experimental comparisons among various schemes validate the algorithm’s efficiency considerably. Additionally, we assess the model’s robustness against data poisoning attacks.}
}


@article{DBLP:journals/tifs/LazriBTDPDW24,
	author = {Zachary McBride Lazri and
                  Ivan Brugere and
                  Xin Tian and
                  Dana Dachman{-}Soled and
                  Antigoni Polychroniadou and
                  Danial Dervovic and
                  Min Wu},
	title = {A Canonical Data Transformation for Achieving Inter- and Within-Group
                  Fairness},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7449--7464},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3416040},
	doi = {10.1109/TIFS.2024.3416040},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LazriBTDPDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increases in the deployment of machine learning algorithms for applications that deal with sensitive data have brought attention to the issue of fairness in machine learning. Many works have been devoted to applications that require different demographic groups to be treated fairly. However, algorithms that aim to satisfy inter-group fairness (also called group fairness) may inadvertently treat individuals within the same demographic group unfairly. To address this issue, this article introduces a formal definition of within-group fairness that maintains fairness among individuals from within the same group. A pre-processing framework is proposed to meet both inter- and within-group fairness criteria with little compromise in performance. The framework maps the feature vectors of members from different groups to an inter-group fair canonical domain before feeding them into a scoring function. The mapping is constructed to preserve the relative relationship between the scores obtained from the unprocessed feature vectors of individuals from the same demographic group, guaranteeing within-group fairness. This framework has been applied to the Adult, COMPAS risk assessment, and Law School datasets, and its performance is demonstrated and compared with two regularization-based methods in achieving inter-group and within-group fairness.}
}


@article{DBLP:journals/tifs/ChenHXX24,
	author = {Chen Chen and
                  Haibo Hong and
                  Tao Xiang and
                  Mande Xie},
	title = {Anti-Backdoor Model: {A} Novel Algorithm to Remove Backdoors in a
                  Non-Invasive Way},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7420--7434},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3436508},
	doi = {10.1109/TIFS.2024.3436508},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenHXX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research findings suggest that machine learning models are highly susceptible to backdoor poisoning attacks. Backdoor poisoning attacks can be easily executed and achieve high success rates, as the model exhibits anomalous behavior even if a small quantity of malicious data is incorporated into the training dataset. In conventional backdoor defense technologies, fine-tuning is employed as an invasive method that involves adjusting the parameters of model neurons to eliminate backdoors in the attacked model. Nevertheless, this method poses a challenge as the same neurons are responsible for both the original and backdoor tasks, resulting in a decline in the accuracy of the original task during the fine-tuning process. In order to address this issue, we propose a non-invasive approach known as Anti-Backdoor Model (ABM), which does not involve modifying the parameters of the attacked model. ABM employs an external model to counteract the influence of the backdoor task on the attacked model, thereby achieving a balance between eliminating backdoors and preserving the accuracy of the original task. Specifically, our approach involves initially embedding a controllable backdoor in the dataset and leveraging the strong and weak relationships between backdoors to identify a highly concentrated poisoned dataset. Subsequently, we employ the standard training method to train the attacked model (the teacher model). Finally, we utilize this dataset with low volume to train an external model (the student model) that exclusively focuses on backdoors by means of knowledge distillation to counteract the backdoor task in the attacked model (the teacher model). In the experimental part, we assess the effectiveness of ABM by testing eight mainstream attacks on three standard public datasets. Experimental results reveal that ABM exhibits promising efficacy in eliminating the backdoor task while preserving the accuracy of the original task. Our source codes are open at https://gitee.com/dugu1076/ABM.git.}
}


@article{DBLP:journals/tifs/ChahokiSR24,
	author = {Atefeh Zareh Chahoki and
                  Hamid Reza Shahriari and
                  Marco Roveri},
	title = {CryptojackingTrap: An Evasion Resilient Nature-Inspired Algorithm
                  to Detect Cryptojacking Malware},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7465--7477},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3353072},
	doi = {10.1109/TIFS.2024.3353072},
	timestamp = {Sun, 19 Jan 2025 14:20:41 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChahokiSR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The high profitability of mining cryptocurrencies mining, a computationally intensive activity, forms a fertile ecosystem that is enticing not only legitimate investors but also cyber attackers who invest their illicit computational resources in this area. Cryptojacking refers to the surreptitious exploitation of a victim’s computing resources to mine cryptocurrencies on behalf of the cyber-criminal. This malicious behavior is observed in executable files and browser executable codes, including JavaScript and Assembly modules, downloaded from websites to victims’ machines and executed. Although there are numerous botnet detection techniques to stop this malicious activity, attackers can circumvent these protections using a variety of techniques. In this paper, CryptojackingTrap is presented as a novel cryptojacking detection solution designed to resist most malware defense methods. The CryptojackingTrap is armed with a debugger and extensible cryptocurrency listeners and its algorithm is based on the execution of cryptocurrency hash functions: an indispensable behavior of all cryptojacking executors. This algorithm becomes aware of this specific hash execution by correlating the memory access traces of suspicious executables with publicly available cryptocurrency P2P network data. With the advantage of this assembly-level investigation and a nature-inspired approach to triggering the detection alarm, CryptojackingTrap provides an accurate, evasion-proof technique for detecting cryptojacking. After experimental evaluation, the false negative and false positive rates are zero, and in addition, the false positive rate is mathematically calculated as 10−20. CryptojackingTrap has an open, extensible architecture and is available to the open-source community.}
}


@article{DBLP:journals/tifs/AlperG24,
	author = {Raphael Alper and
                  Mordechai Guri},
	title = {TrueWatch: Polygraph Examination With Smartwatches},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7478--7491},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3435409},
	doi = {10.1109/TIFS.2024.3435409},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AlperG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The traditional polygraph instrument is used worldwide for lie detection tests. It is currently used broadly in the civil sector, terrorism investigations, and criminal cases. In this paper, we introduce a novel concept of conducting lie detection tests with modern wearable devices. Unlike traditional polygraph instruments, wearable devices are easier and more accessible to use. This allows the test to be conducted in various environments, under flexible conditions, and is much cheaper. Our study consists of a comprehensive assessment of modern wearable devices for lie detection, employing the Guilty Knowledge Test (GKT) protocol. We also compared its effectiveness to that of a traditional polygraph instrument. In order to achieve our goal, we administered laboratory polygraph tests on 30 individuals, where we staged a ‘mock crime’ as a preliminary step. We built a data acquisition system along with a sequence of signal-processing steps for the examined devices. We have also developed an algorithm (AUTOMATED-KEY-FINDER) that simulates the human decision-making process for determining the final decision in polygraph tests. Our research results demonstrate that modern wearable devices can be used to detect lies in the GKT protocol. We show that this ability is comparatively weaker than that of a conventional polygraph instrument.}
}


@article{DBLP:journals/tifs/WangWDTP24,
	author = {Wei Wang and
                  Licheng Wang and
                  Junke Duan and
                  Xiaofei Tong and
                  Haipeng Peng},
	title = {Redactable Blockchain Based on Decentralized Trapdoor Verifiable Delay
                  Functions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7492--7507},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3431917},
	doi = {10.1109/TIFS.2024.3431917},
	timestamp = {Thu, 22 Aug 2024 20:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangWDTP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain technology was originally designed to ensure data security and trustworthiness through decentralization and immutability. However, in recent years, the misuse of immutability limits the development of blockchain. To address this challenge, several redactable blockchain solutions have been proposed. However, existing solutions either struggle to maintain block consistency or compromise the decentralization principles of blockchain. In this paper, we present a novel redactable blockchain to address these issues. Firstly, we propose a decentralized trapdoor verifiable delay function (DTVDF) based on Wesolowski’s verifiable delay function (VDF) scheme (EUROCRYPT’2019), which distributes trapdoor shares among a group of participants. Then, we leverage the proposed DTVDF to construct our redactable blockchain solution (DTRB), where redacting blocks requires consensus from threshold nodes. Moreover, DTRB provides accountability for malicious modifications and supports aggregate verification of redacted blocks, significantly improving the efficiency of our scheme. Through experimental analysis and comparison with existing solutions, our approach demonstrates superior performance.}
}


@article{DBLP:journals/tifs/DaiZGDXXHJ24,
	author = {Xiaohai Dai and
                  Zhaonan Zhang and
                  Zhengxuan Guo and
                  Chaozheng Ding and
                  Jiang Xiao and
                  Xia Xie and
                  Rui Hao and
                  Hai Jin},
	title = {Wahoo: {A} DAG-Based {BFT} Consensus With Low Latency and Low Communication
                  Overhead},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7508--7522},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409082},
	doi = {10.1109/TIFS.2024.3409082},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DaiZGDXXHJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To parallelize data processing within BFT consensus protocols, Directed Acyclic Graph (DAG) structures have been integrated into consensus design, shaping the realm of DAG-based BFT protocols. Existing DAG-based protocols rely on the Reliable Broadcast (RBC) protocol or its variants for block dissemination, which ensures consistency and totality properties of the data delivery. However, the inherent communication overhead of O(n^{2}) in RBC (where n is the total replica count) results in an unwieldy O(n^{3}) overhead in current DAG-based solutions, as each replica disseminates blocks through RBC in parallel. In response to this issue, we propose two new broadcast protocols: Provable Broadcast (PBC) and Enhanced Provable Broadcast (EPBC). Both PBC and EPBC maintain the consistency property of data delivery, similar to RBC, while offering linear communication overhead without totality. Leveraging these broadcast protocols, we devise Wahoo, a novel DAG-based BFT protocol that significantly reduces communication overhead to O(n^{2}) . To address the absence of the totality property, we introduce a block retrieval mechanism to assist replicas in acquiring missing blocks. Additionally, under favorable conditions, Wahoo achieves a low latency of 4\\delta (where \\delta symbolizes the actual network delay), rivaling the best performance of existing DAG-based protocols. Various experiments showcase Wahoo’s high performance, owing to its substantially reduced communication overhead.}
}


@article{DBLP:journals/tifs/ChenYYL24,
	author = {Yu{-}Chi Chen and
                  Jhe{-}Kai Yang and
                  Hsin{-}Chan Yen and
                  Pei{-}Wen Lin},
	title = {Dual-Cloud Multi-Secret Sharing Architecture for Privacy Preserving
                  Persistent Computation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7523--7535},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3436662},
	doi = {10.1109/TIFS.2024.3436662},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenYYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the prevalence of artificial intelligence, people collect data through numerous sensors and use machine learning to create models for intelligent services. However, data privacy and massive data issues are raised with the proliferation of devices. Although secret sharing can be the solution to providing privacy and performing efficient computations (than homomorphic encryption-based) in the privacy domain, sharing large amounts of data may impose a considerable storage burden on resource-restricted devices. Therefore, we aim to reduce the shares that participants need to hold and construct secure computation protocols that form privacy-preserving data utilization with multi-secret sharing. In this paper, we study the mechanism of persistent computation with multi-secret sharing for privacy protection, which avoids the requirements for participants to store extra information during secure computation. We present the mask techniques to convert secrets into protected data and upload them separately to non-colluding dual-cloud servers through multi-secret sharing. Then, we can locally evaluate the operation result shares by revealing a part of the protected data, where the true secret consistently remains secure as the other part stays in a shared state. Eventually, we outsource a dataset to the cloud, build a privacy-preserving multi-party kNN classification based on our scheme, and provide some experiments to demonstrate the feasibility and usability of storage size.}
}


@article{DBLP:journals/tifs/ZhouHSC24,
	author = {Xinye Zhou and
                  Hu Han and
                  Shiguang Shan and
                  Xilin Chen},
	title = {Fine-Grained Open-Set Deepfake Detection via Unsupervised Domain Adaptation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7536--7547},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3435440},
	doi = {10.1109/TIFS.2024.3435440},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhouHSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deepfake represented by face swapping and face reenactment can transfer the appearance and behavioral expressions of a face in one video image to another face in a different video. In recent years, with the advancement of deep learning techniques, deepfake technology has developed rapidly, achieving increasingly realistic effects. Therefore, many researchers have begun to study deepfake detection research. However, most existing studies on deepfake detection are mainly limited to binary classification of real and fake images, rather than identifying different methods in an open-world scenario, leading to failures in dealing with unknown deepfake categories in practice. In this paper, we propose an unsupervised domain adaptation method for fine-grained open-set deepfake detection. Our method first uses labeled data from the source domain for model pre-training to establish the ability of recognizing different deepfake methods in the source domain. Then, the method uses a Network Memorization based Adaptive Clustering (NMAC) approach to cluster unlabeled images in the target domain and designs a Pseudo-Label Generation (PLG) to generate virtual class labels for unknown deepfake categories by matching the adaptive clustering results with the known deepfake categories in the source domain. Finally, we retrain the initial multi-class deepfake detection model using labeled data of the source domain and pseudo-labeled data of the target domain to improve its generalization ability to unknown deepfake classes presented in the target domain. We validate the effectiveness of the proposed method under multiple open-set fine-grained deepfake detection tasks based on three deepfake datasets (ForgerNet, FaceForensics++, and FakeAVCeleb). Experimental results show that our method has better domain generalization ability than the state-of-the-art methods, and achieves promising performance in fine-grained open-set deepfake detection.}
}


@article{DBLP:journals/tifs/YaoHWS24,
	author = {Lan Yao and
                  Xia Huang and
                  Zhen Wang and
                  Hao Shen},
	title = {A Multi-Sensor-Based Switching Event-Triggered Mechanism for Synchronization
                  Control of Markovian Jump Neural Networks Under DoS Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7548--7559},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3441812},
	doi = {10.1109/TIFS.2024.3441812},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YaoHWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the secure synchronization control of Markovian jump neural networks (MJNNs) suffering from denial of service attacks (DoS attacks). The issue is presented for two reasons: 1) multiple sensors are generally used to measure the information of different state variables in practical networked control systems; 2) DoS attacks will disrupt the transmission of data packets in communication channels, thereby causing the system performance degradation. To deal with these problems, a multi-sensor-based switching event-triggered mechanism (SETM) is designed. More specifically, when the data packets are transmitted normally, the SETM will switch to an adaptive memory-based event-triggered mechanism, thereby saving the network resources. When the DoS attack occurs, the SETM will trigger immediately at the end of the DoS attack to improve the system performance. To facilitate the stability analysis, a merging time series is constructed by integrating the triggering instants of successful transmission and the ending instants of DoS attacks together. In light of the merging time series, a switched closed-loop system is established. Then, by utilizing the stability analysis idea of switched systems, a multiple Lyapunov functional is constructed, enabling the exploitation of multi-sampling. On this basis, a synchronization criterion is derived, accompanied by a co-design method for controller and the trigger matrices. Finally, the outcomes of the simulation confirm both the efficacy and the advantage of the suggested approach, especially when dealing with DoS attacks.}
}


@article{DBLP:journals/tifs/DuanWWG24,
	author = {Junke Duan and
                  Wei Wang and
                  Licheng Wang and
                  Lize Gu},
	title = {Controlled Redactable Blockchain Based on T-Times Chameleon Hash and
                  Signature},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7560--7572},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3436925},
	doi = {10.1109/TIFS.2024.3436925},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DuanWWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Immutability is widely recognized as one of the blockchain’s key security attributes. However, in recent years, incidents involving the use of blockchain for disseminating illegal or malicious information have raised concerns over its strict immutability. To address these issues, redactable blockchains are proposed as a novel solution, permitting authorized content redactions without compromising the structural integrity of the blockchain. Unfortunately, current solutions are unable to restrict the abuse of redaction privilege, except for relying on a trusted authority or committee, which contradicts the trustlessness principle of blockchain. In this paper, we propose a controlled redactable blockchain protocol that allows for a limited number of redactions and supports a transparent setup. The cryptographic tools enabling this functionality are our proposed t-times chameleon hash (t-CH) and signature (t-CS) schemes, where generating more than t collisions will expose the trapdoor. We present security models, discrete logarithm-based instantiations, and formal security proofs for both t-CH and t-CS. Subsequently, we present the construction of our redaction protocol in both permissioned and permissionless settings. Finally, we experimentally demonstrate the effectiveness of the proposed protocol in practice.}
}


@article{DBLP:journals/tifs/GaoYJLM24,
	author = {Ning Gao and
                  Yuze Yao and
                  Shi Jin and
                  Cen Li and
                  Michail Matthaiou},
	title = {Integrated Communications and Security: RIS-Assisted Simultaneous
                  Transmission and Generation of Secret Keys},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7573--7587},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3436885},
	doi = {10.1109/TIFS.2024.3436885},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GaoYJLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We develop a new integrated communications and security (ICAS) design paradigm by leveraging the concept of reconfigurable intelligent surfaces (RISs). In particular, we propose RIS-assisted simultaneous transmission and secret key generation by sharing the RIS for these two tasks. Specifically, the legitimate transceivers intend to jointly optimize the data transmission rate and the key generation rate by configuring the phase-shift of the RIS in the presence of a smart attacker. We first derive the key generation rate of the RIS-assisted physical layer key generation (PLKG). Then, to obtain the optimal RIS configuration, we formulate the problem as a secure transmission (ST) game and prove the existence of the Nash equilibrium (NE), and then derive the NE point of the static game. For the dynamic ST game, we model the problem as a finite Markov decision process and propose a model-free reinforcement learning approach to obtain the NE point. Particularly, considering that the legitimate transceivers cannot obtain the channel state information (CSI) of the attacker in real-world conditions, we develop a deep recurrent Q-network (DRQN) based dynamic ST strategy to learn the optimal RIS configuration. The details of the algorithm are provided, and then, the system complexity is analyzed. Our simulation results show that the proposed DRQN based dynamic ST strategy has a better performance than the benchmarks even with a partial observation information, and achieves “one time pad” communication by allocating a suitable weight factor for data transmission and PLKG.}
}


@article{DBLP:journals/tifs/CaiWCWZC24,
	author = {Yicheng Cai and
                  Haizhou Wang and
                  Hao Cao and
                  Wenxian Wang and
                  Lei Zhang and
                  Xingshu Chen},
	title = {Detecting Spam Movie Review Under Coordinated Attack With Multi-View
                  Explicit and Implicit Relations Semantics Fusion},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7588--7603},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3441947},
	doi = {10.1109/TIFS.2024.3441947},
	timestamp = {Thu, 31 Oct 2024 16:54:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CaiWCWZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spam reviews have long polluted review systems, undermining their industries. Detecting spam movie reviews faces some brand-new challenges compared to traditional spam detection. These include coordinated spamming attacks during premieres or at advance screenings. However, most of existing studies only use inherent relations among reviews, movies, and users, they do not fully exploit explicit and implicit relations between reviews in coordinated spamming attacks. To address these novel challenges, we propose a spam movie review detection method based on mining explicit and implicit relation semantics and fusing multi-view semantics. To the best of our knowledge, we are the first to enhance spam movie review detection by exploiting both explicit and implicit relations between reviews in coordinated spamming attacks. First, we build an explicit relation movie-review graph with movie synopses and high-quality external reviews. We extract movie factual knowledge embeddings using a Heterogeneous Graph Transformer (HGT) network. Next, we input the factual knowledge embeddings with corresponding review embeddings into a contrastive network to get review credibility features. Additionally, we build an implicit relation graph between reviews using metadata and semantic similarities. We extract relation-enhanced review semantics via another HGT network. Finally, we fuse the three review semantic features through an attention layer before making classification. Experiments show our method achieves higher performance and robustness over state-of-the-art methods.}
}


@article{DBLP:journals/tifs/FeiSZZWL24,
	author = {Lunke Fei and
                  Le Su and
                  Bob Zhang and
                  Shuping Zhao and
                  Jie Wen and
                  Xiaoping Li},
	title = {Learning Frequency-Aware Common Feature for {VIS-NIR} Heterogeneous
                  Palmprint Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7604--7618},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3441945},
	doi = {10.1109/TIFS.2024.3441945},
	timestamp = {Mon, 03 Mar 2025 22:25:01 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/FeiSZZWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Palmprint recognition has shown great value for biometric recognition due to its advantages of good hygiene, semi-privacy and low invasiveness. However, most existing palmprint recognition studies focus only on homogeneous palmprint recognition, where comparing palmprint images are collected under similar conditions with small domain gaps. To address the problem of matching heterogeneous palmprint images captured under the visible light (VIS) and the near-infrared (NIR) spectrum with large domain gaps, in this paper, we propose a Fourier-based feature learning network (FFLNet) for VIS-NIR heterogeneous palmprint recognition. First, we extract the multi-scale shallow representations of heterogeneous palmprint images via three vanilla convolution layers. Then, we convert the shallow palmprint feature maps into frequency-specific representations via Fourier transform to separate different layers of palmprint features, and exploit the underlying common and palmprint-specific frequency information of heterogeneous palmprint images. This effectively reduces the modality gap of heterogeneous palmprint images at the feature level. After that, we convert the common frequency-specific feature maps back to the spatial domain to learn the identity-invariant discriminative features via residual convolution for heterogeneous palmprint recognition. Extensive experimental results on three challenging heterogeneous palmprint databases clearly demonstrate the effectiveness of the proposed FFLNet for VIS-NIR heterogeneous palmprint recognition.}
}


@article{DBLP:journals/tifs/TanPXWLCZ24,
	author = {Xiaobin Tan and
                  Chuang Peng and
                  Peng Xie and
                  Hao Wang and
                  Mengxiang Li and
                  Shuangwu Chen and
                  Cliff C. Zou},
	title = {Inter-Flow Spatio-Temporal Correlation Analysis Based Website Fingerprinting
                  Using Graph Neural Network},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7619--7632},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3441935},
	doi = {10.1109/TIFS.2024.3441935},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TanPXWLCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Website fingerprinting has emerged as a prominent topic in the area of network management. However, the proliferation of encrypted network traffic poses new challenges for website fingerprinting. In this paper, we analyze the behavior and correlations among the network flows generated by browsing a webpage and conclude that there exist specific spatio-temporal correlations among these network flows. Based on this finding, we propose the construction of an inter-flow spatio-temporal correlation graph (STCG) to model these correlations. In the STCG, each node represents a flow, with its features capturing the properties of the flow itself, and each edge with a weight vector represents the spatio-temporal correlation between two flows. Subsequently, we propose a graph neural network-based website fingerprinting method (STC-WF) by considering the inter-flow spatio-temporal correlations, in which the Graph Attention Network (GAT) and Self-Attention Graph Pooling (SAGPool) mechanisms are employed to acquire a comprehensive representation of the STCG. To evaluate the performance of STC-WF, we construct a real-world traffic dataset and conduct comprehensive evaluations. The experimental results demonstrate that STC-WF outperforms state-of-the-art methods in terms of accuracy and time consumption.}
}


@article{DBLP:journals/tifs/QianCWGJWZ24,
	author = {Yaguan Qian and
                  Kecheng Chen and
                  Bin Wang and
                  Zhaoquan Gu and
                  Shouling Ji and
                  Wei Wang and
                  Yanchun Zhang},
	title = {Enhancing Transferability of Adversarial Examples Through Mixed-Frequency
                  Inputs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7633--7645},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3430508},
	doi = {10.1109/TIFS.2024.3430508},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QianCWGJWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have shown that Deep Neural Networks (DNNs) are easily deceived by adversarial examples, revealing their serious vulnerability. Due to the transferability, adversarial examples can attack across multiple models with different architectures, called transfer-based black-box attacks. Input transformation is one of the most effective methods to improve adversarial transferability. In particular, the attacks fusing other categories of image information reveal the potential direction of adversarial attacks. However, the current techniques rely on input transformations in the spatial domain, which ignore the frequency information of the image and limit its transferability. To tackle this issue, we propose Mixed-Frequency Inputs (MFI) based on a frequency domain perspective. MFI alleviates the overfitting of adversarial examples to the source model by considering high-frequency components from various kinds of images in the process of calculating the gradient. By accumulating these high-frequency components, MFI acquires a more steady gradient direction in each iteration, leading to the discovery of better local maxima and enhancing transferability. Extensive experimental results on the ImageNet-compatible datasets demonstrate that MFI outperforms existing transform-based attacks with a clear margin on both Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), which proves MFI is more suitable for realistic black-box scenarios.}
}


@article{DBLP:journals/tifs/HuangXZZL24,
	author = {Yaxuan Huang and
                  Kaiping Xue and
                  Bin Zhu and
                  Jingcheng Zhao and
                  Ruidong Li},
	title = {Collecting Partial Ordered Data With Local Differential Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7646--7658},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3442554},
	doi = {10.1109/TIFS.2024.3442554},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangXZZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The partial ordered data is typically used to describe the order of some elements within a set, and it widely exists in various fields, such as clinical investigations, preference ranking and voting. However, the collection of partial ordered data poses critical privacy concerns about abusing records to infer individuals’ identities and preferences. To solve this problem, this paper proposes a distribution analysis method for partial ordered data with local differential privacy (LDP). The private information of partial ordered data includes whether an element is associated with a partial order relation and either a relation is preceding or succeeding. To preserve privacy, we perturb partial ordered data by randomly responding raw data or the data with mapped elements. This makes it impossible to distinguish whether any element has a partial order relationship with other elements and what kind of partial order relationship exists. To maintain the logicality of partial ordered data, we utilize the transitivity of partial orders to distinguish between direct and indirect orders in the perturbation. The inherent properties of partial orders are still satisfied after perturbation, which reduces the possibility of servers inferring the raw data through logical errors. Moreover, we theoretically analyze the error bound and prove the security of our work. Extensive experimental results on synthetic and real-world datasets demonstrate that our scheme achieves better utility than existing state-of-the-art approaches.}
}


@article{DBLP:journals/tifs/XieCZZHPWXSDLZL24,
	author = {Renjie Xie and
                  Jiahao Cao and
                  Yuxi Zhu and
                  Yixiang Zhang and
                  Yi He and
                  Hanyi Peng and
                  Yixiao Wang and
                  Mingwei Xu and
                  Kun Sun and
                  Enhuan Dong and
                  Qi Li and
                  Menghao Zhang and
                  Jiang Li},
	title = {Cactus: Obfuscating Bidirectional Encrypted {TCP} Traffic at Client
                  Side},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7659--7673},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3442530},
	doi = {10.1109/TIFS.2024.3442530},
	timestamp = {Mon, 11 Nov 2024 16:51:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XieCZZHPWXSDLZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the mainstream encrypted protocols adopt TCP protocol to ensure lossless data transmissions, the privacy of encrypted TCP traffic becomes a significant focus for adversaries. They can leverage Deep Learning (DL) models to infer the sensitive information from encrypted TCP traffic by analyzing its packet size, direction, and timing information. To defend against such DL-based traffic analysis attacks, recent advances reshape the encrypted traffic and achieve desired results. However, they typically require deploying cooperative modules on both communication endpoints and only support specific applications, such as browsers. In this paper, we propose Cactus, a client-side plug-in to obfuscate bidirectional encrypted TCP traffic for a wide range of applications transparently using the inherent TCP semantics and the emerging eBPF technique. In particular, Cactus provides four effective operations to enable bidirectional traffic obfuscation while preserving communication semantics of applications. Besides, Cactus empowers users to specify which applications to conduct traffic obfuscation and what obfuscation level for each application. We conduct comprehensive experiments to demonstrate that Cactus can effectively obfuscate encrypted TCP traffic with low overhead to hinder the traffic analysis efforts in website fingerprinting and application identification.}
}


@article{DBLP:journals/tifs/ZhangYCZBH24,
	author = {Jing Zhang and
                  Ruonan Ying and
                  Jie Cui and
                  Hong Zhong and
                  Irina Bolodurina and
                  Debiao He},
	title = {Secure and Efficient User-Centric {V2C} Communication for Intelligent
                  Cyber-Physical Transportation System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7674--7689},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3442609},
	doi = {10.1109/TIFS.2024.3442609},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangYCZBH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the concept of intelligent cyber-physical transportation systems (ICTS) has entered the vehicle network, providing more efficient, safe, and sustainable services by applying intelligent technology to the transportation system. Because the communication channel between the vehicle and the cloud service provider (CSP) is open and insecure. Therefore, we must construct a secure Vehicle-to-CSP (V2C) communication scheme to ensure the security of vehicle privacy data. Current communication schemes mainly have two limitations. One is that the user’s role in communication is not considered, and the other is that the computational and communication overhead are not sufficiently low to satisfy the low latency requirements. To address the deficiencies, we propose a user-centric V2C communication scheme. The primary key in the signature is concealed, which ensures the confidentiality of the user’s legal real identity. Its main steps, based on the extended Chebyshev chaotic map and hash function, reduce the computational and communication overhead in the process. The security proof and analysis show that our proposed scheme satisfies the security and privacy requirements. The performance analysis shows that our proposed scheme outperforms other related schemes.}
}


@article{DBLP:journals/tifs/YangWSXXCHL24,
	author = {Xinlong Yang and
                  Haixin Wang and
                  Jinan Sun and
                  Yijia Xiao and
                  Wei Xiang and
                  Chong Chen and
                  Xian{-}Sheng Hua and
                  Xiao Luo},
	title = {{ROSE:} Relational and Prototypical Structure Learning for Universal
                  Domain Adaptive Hashing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7690--7704},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3444319},
	doi = {10.1109/TIFS.2024.3444319},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangWSXXCHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an important problem in searching system development, domain adaptive retrieval seeks to train a retrieval model with both labeled source samples and unlabeled target samples. Although several domain adaptive hashing algorithms have been proposed to handle the problem with high efficiency, they often presume that source and target domains share all classes. However, prior knowledge about the label space on the target domain is hard to obtain in reality. To tackle this, we study a novel and challenging problem of universal domain adaptive retrieval, which evidently increases the difficulty of effective domain alignment. In this paper, we propose a hashing method named Relational and prOtotypical Structure lEarning (ROSE) to solve the problem. In particular, to overcome domain shift, we construct a relational structure depicting cross-domain similar pairs based on ranking statistics, then learn from the structure by maximizing the similarity between similar pairs compared with challenging negatives. Moreover, target private samples are detected using the min-max criterion, which helps to construct hashing prototypes in the Hamming space. On this basis, we combine prototypical structure learning with online clustering in the Hamming space, which improves target semantic learning under label deficiency. Extensive experiments on several benchmarks demonstrate that our proposed ROSE significantly outperforms a wide range of state-of-the-art methods. Our source code is available at https://github.com/WillDreamer/Rose.git.}
}


@article{DBLP:journals/tifs/GaoNGGLZZ24,
	author = {Guangyuan Gao and
                  Weina Niu and
                  Jiacheng Gong and
                  Dujuan Gu and
                  Song Li and
                  Mingxue Zhang and
                  Xiaosong Zhang},
	title = {GraphTunnel: Robust {DNS} Tunnel Detection Based on {DNS} Recursive
                  Resolution Graph},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7705--7719},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3443596},
	doi = {10.1109/TIFS.2024.3443596},
	timestamp = {Tue, 15 Oct 2024 08:12:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GaoNGGLZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DNS tunnels, due to their versatility and concealment, have become a preferred method for attackers to execute Command and Control (C&C) attacks, posing a significant security threat to terminal devices. Therefore, the efficient and accurate detection of DNS tunnels is important in reducing the economic losses and privacy risks faced by both enterprises and individuals. Despite notable advancements in the research of intelligent detection of DNS tunnels, existing model-based approaches predominantly concentrate on the surface-level features of domain names or packet payloads. This narrow focus leads to low detection accuracy when dealing with unknown DNS tunnel attacks and traffic from wildcard DNS. Furthermore, these methods struggle with accurately identifying DNS tunneling tools, complicating the task of swiftly locating and mitigating malware for analysts. This paper proposes GraphTunnel, a framework based on graph neural networks for detecting DNS tunnels and identifying tunneling tools. It delves into the correlations among DNS resolutions to construct paths that represent the recursive resolution process of DNS. By using central nodes that denote the gateways, these paths are connected and transformed into graph structures. Concurrently, it employs GraphSage to aggregate the features of nodes and their edges in the graph, enabling effective detection of DNS tunnels. Additionally, GraphTunnel utilizes the G2M algorithm to capture the statistical features of nodes in the graph and maps them into grayscale images, which are then processed by a CNN for multi-class identification of DNS tunneling tools. Experimental results demonstrate that in non-wildcard DNS scenarios, GraphTunnel achieves a 100% accuracy in DNS tunnel detection, encompassing unknown DNS tunnels. Even in high false-positive environments caused by wildcard DNS, GraphTunnel maintains an F1-Score of 99.78%. Moreover, GraphTunnel can identify DNS tunneling tools with an accuracy rate exceeding 98.57%, enhancing the rapid mitigation capabilities of emergency responders in dealing with malicious DNS tunnels.}
}


@article{DBLP:journals/tifs/JoungY24,
	author = {Jingon Joung and
                  Chau Yuen},
	title = {Space-Time Line Code Hopping for Physical-Layer Secure Communications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7720--7729},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3442543},
	doi = {10.1109/TIFS.2024.3442543},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JoungY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study explores the security of the existing space-time line code (STLC) scheme. A novel STLC-hopping scheme is proposed to ensure physical-layer secure communication of the STLC transceiver, overcoming the limitations of the conventional STLC systems posed by correlated legitimate and eavesdropping channels. The transmitter randomly selects an STLC encoding matrix for every two symbols, and the legitimate receiver decodes them based on the transmitter’s chosen matrix under the assumption that the transceiver shares a pseudorandom sequence generator for the STLC-hopping pattern. The proposed STLC-hopping system is scalable for the number of transmit antennas and compatible with a conventional STLC scheme. Even with highly correlated eavesdropping channels, the proposed STLC-hopping method prevents an eavesdropper from decoding STLC signals. Numerical results confirm the effectiveness of the proposed STLC-hopping method by showing it can almost sustain the secrecy rate lower bound, regardless of the eavesdropping channel correlations, and offer enhanced physical-layer security for STLC systems. Further, bit-error-rate performance results verify that hopping between merely two STLCs can provide sufficient secure communications.}
}


@article{DBLP:journals/tifs/SongCCHCW24,
	author = {Yujie Song and
                  Yue Cao and
                  Chaklam Cheong and
                  Debiao He and
                  Kim{-}Kwang Raymond Choo and
                  Juan Wang},
	title = {{CAT:} {A} Consensus-Adaptive Trust Management Based on the Group
                  Decision Making in IoVs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7730--7743},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3442611},
	doi = {10.1109/TIFS.2024.3442611},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SongCCHCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Securing Internet of Vehicles (IoVs) systems against common threats such as false message injection remains challenging, and one typical approach is to deploy trust management solutions. In this work, we propose a Consensus-Adaptive Trust management (CAT) based on the Group Decision Making (GDM) in IoVs. Specifically, in our approach the consensus levels are calculated to measure the difference of opinions (trust values) among vehicles. To estimate the reliability of consensus levels, the divergence between consensus levels is calculated, namely: consensus level similarity. GDM allows us to dynamically adjust the opinion of vehicles (namely: Consensus Reaching Process, CRP). Then, a credit guarantee mechanism is designed to improve the efficiency of CRP and seek out malicious vehicles quickly. To empower the adaptability of trust management for changing environments in IoVs, CAT dynamically manages opinions of vehicles, self-confidence, and their consensus thresholds according to the feedback of delivered messages. Extensive simulation results show the potential of CAT operating in high-risk scenarios, and outperforming other competing baseline methods in terms of accuracy, precision, recall, and F-score.}
}


@article{DBLP:journals/tifs/LiNXLLS24,
	author = {Chen Li and
                  Jianting Ning and
                  Shengmin Xu and
                  Chao Lin and
                  Jiguo Li and
                  Jian Shen},
	title = {{DTACB:} Dynamic Threshold Anonymous Credentials With Batch-Showing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7744--7758},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3443622},
	doi = {10.1109/TIFS.2024.3443622},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiNXLLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Threshold anonymous credentials enable users to acquire credentials in a decentralized manner while upholding their privacy. However, distributed network environments, such as electronic voting systems and federated identity management systems, have pressing needs for enhancing security, reducing reliance on fixed-group issuers, and achieving scalability. These requirements expose the significant constraints of existing threshold anonymous credential systems, which struggle to support dynamic threshold settings. This struggle leads to the necessity of system rewinding whenever an issuer is included or excluded. Moreover, the communication and computation complexities involved in showing credentials exhibit a linear relationship with the number of credentials possessed by each user. In this paper, we present a novel dynamic threshold anonymous credential system, named DTACB, to tackle the aforementioned challenges. DTACB enables the dynamic adjustment of thresholds, allowing issuer adjustments without rewinding the system. DTACB additionally supports batch-showing of credentials and proof of credential quantity values while preserving the user’s credentials collection remains undisclosed. We conduct rigorous security analysis and validate our efficiency claims via implementing and benchmarking. In particular, DTACB effectively reduces the cost of batch-proof verification to 3.78 ms, independent of the user’s proof size.}
}


@article{DBLP:journals/tifs/FuCSXCS24,
	author = {Jiaxuan Fu and
                  Ke Cheng and
                  Anxiao Song and
                  Yuheng Xia and
                  Zhao Chang and
                  Yulong Shen},
	title = {{FSS-DBSCAN:} Outsourced Private Density-Based Clustering via Function
                  Secret Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7759--7773},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3446233},
	doi = {10.1109/TIFS.2024.3446233},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FuCSXCS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Density-based clustering algorithms such as DBSCAN, are highly effective in handling large datasets and identifying clusters of arbitrary shapes, playing a crucial role in data analysis fields like outlier detection and social networks. Outsourcing DBSCAN to the cloud brings substantial benefits but also raises major privacy concerns regarding the private input data of data owners. Existing private DBSCAN methods often face challenges of inefficiency or potential privacy leakage, hindering their practical deployment. To address these challenges, we introduce FSS-DBSCAN, a three-server MPC platform designed for outsourced private density-based clustering using function secret sharing (FSS). This solution guarantees clustering quality equivalent to plaintext algorithms, ensures comprehensive privacy protection, and achieves top-tier efficiency. The high performance of FSS-DBSCAN is driven by two pivotal strategies. First, we devise an MPC-friendly DBSCAN algorithm that is highly compatible with efficient secret-sharing-based cryptographic protocols and benefits from GPU acceleration. Second, we construct novel FSS-based protocols tailored for complex operations integral to our DBSCAN variant, such as Euclidean distance comparison and point assignment, and further optimize their computation through tensorization techniques. We implement our platform as an extensible system on top of PyTorch that leverages GPU hardware acceleration for cryptographic and tensorized operations. These innovations enable FSS-DBSCAN to significantly outperform ppDBSCAN (AsiaCCS 2021), reducing the clustering time for 5000 samples to approximately 2 hours, achieving an 83.4\\times speed improvement.}
}


@article{DBLP:journals/tifs/LamLA24,
	author = {Denley Lam and
                  Letitia W. Li and
                  Cory Anderson},
	title = {{PDF} Investigation With Parser Differentials and Ontology},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7774--7782},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3445733},
	doi = {10.1109/TIFS.2024.3445733},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LamLA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper describes the Verifiable Automatic Language Analysis and Recognition for Inputs (VALARIN) system to process, evaluate, and flag unsafe PDFs. The system extracts error features from a collection of PDF parsers, and organizes the different types of error messages by how they impact file safety. An ontology was designed to describe the relationships between parsers, error messages, safety, and PDF properties to support PDF-based malware classification efforts. Our domain-specific PDF ontology shows that PDF parsers exhibit mutual biases when recovering from specification ambiguities. Consensus on extracted error features among parsers had a direct relationship to the safety of the PDF. The PDF OWL ontology serves as a shareable method for information security and forensics efforts to highlight discrepancies and aid understanding by standardizing and describing the hierarchical relationship of diverse parsers, PDF structure, and validity.}
}


@article{DBLP:journals/tifs/DjaidjaBSBG24,
	author = {Taki Eddine Toufik Djaidja and
                  Bouziane Brik and
                  Sidi Mohammed Senouci and
                  Abdelwahab Boualouache and
                  Yacine Ghamri{-}Doudane},
	title = {Early Network Intrusion Detection Enabled by Attention Mechanisms
                  and RNNs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7783--7793},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3441862},
	doi = {10.1109/TIFS.2024.3441862},
	timestamp = {Sun, 08 Sep 2024 16:06:27 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DjaidjaBSBG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current flow-based Network Intrusion Detection Systems (NIDSs) have the drawback of detecting attacks only once the flow has ended, resulting in potential delays in attack detection and increasing the risk of damage due to the infiltration of a greater number of malicious packets. Moreover, the delay provides attackers with an extended period of presence within the network, enabling them to execute subsequent attacks. To overcome this drawback, this work addresses the issue of early flow classification in NIDSs that incorporates a Deep Learning (DL) model. This model leverages Recurrent Neural Networks (RNNs), including Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), coupled with attention mechanisms. This strategic combination allows the system to harness the inherent sequential nature of packets within network flows, enhancing the efficiency of early flow classification. We conducted experiments on two up-to-date network intrusion datasets, namely CIC-IDS2017 and 5G-NIDD. Our findings demonstrate the effectiveness and accuracy of the proposed NIDS in classifying network flows. Additionally, our approach showcases its efficacy by promptly identifying and detecting attacks in their early stages without the need for flow termination. This results in a reduction in both the number of initial packets required for classification and the time needed for detection.}
}


@article{DBLP:journals/tifs/JiangCFWYB24,
	author = {Meiyi Jiang and
                  Baojiang Cui and
                  Junsong Fu and
                  Tao Wang and
                  Lu Yao and
                  Bharat K. Bhargava},
	title = {{RUDOLF:} An Efficient and Adaptive Defense Approach Against Website
                  Fingerprinting Attacks Based on Soft Actor-Critic Algorithm},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7794--7809},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3436818},
	doi = {10.1109/TIFS.2024.3436818},
	timestamp = {Fri, 20 Sep 2024 14:01:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangCFWYB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although Tor is designed to provide anonymity, website fingerprinting (WF) attacks have posed significant threats to user privacy. In response, various defense approaches have been developed. Randomization and regularization-based defenses are criticized to be inefficient due to their bandwidth-consuming nature. Some adversarial learning-based defenses are impractical because the generation of perturbation depends on the complete traffic traces. Other adversarial learning-based defenses have weaknesses of lacking adaptability because their perturbations are input-agnostic. To overcome these shortcomings, we propose RUDOLF, an efficient and adaptive WF defense based on the soft actor-critic (SAC) algorithm of reinforcement learning (RL). We train the agent that can incrementally output perturbations synchronously following each burst of real-time traffic. Different from previous defenses, RUDOLF’s perturbation does not depend on the integrity of the traffic and concerns the actual real-time traffic, which ensures the practicality of implementation and adaptability. Besides, we take advantage of the exploratory characteristics of the SAC algorithm to obtain the optimal policy of adding perturbations that can efficiently balance defense effects and bandwidth consumption. Experiments on synthetic datasets show that with less than 30% bandwidth overhead (BWO), RUDOLF can reduce the average attack accuracy to around 15%–20%, which is superior to previous works. We also have implemented RUDOLF as a Tor pluggable transport. The performance in the real Tor network shows that RUDOLF can reduce the average accuracy of WF classifier to around 24% with about 25% BWO and almost no time delay.}
}


@article{DBLP:journals/tifs/WangGTK24,
	author = {Yifan Wang and
                  Jie Gui and
                  Yuan Yan Tang and
                  James Tin{-}Yau Kwok},
	title = {CFVNet: An End-to-End Cancelable Finger Vein Network for Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7810--7823},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3436528},
	doi = {10.1109/TIFS.2024.3436528},
	timestamp = {Fri, 20 Sep 2024 14:01:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangGTK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finger vein recognition technology has become one of the primary solutions for high-security identification systems. However, it still has information leakage problems, which seriously jeopardizes user’s privacy and anonymity and cause great security risks. In addition, there is no work to consider a fully integrated secure finger vein recognition system. So, different from the previous systems, we integrate preprocessing and template protection into an integrated deep learning model. We propose an end-to-end cancelable finger vein network (CFVNet), which can be used to design an secure finger vein recognition system. It includes a plug-and-play BWR-ROIAlign unit, which consists of three sub-modules: Localization, Compression and Transformation. The localization module achieves automated localization of stable and unique finger vein ROI. The compression module losslessly removes spatial and channel redundancies. The transformation module uses the proposed BWR method to introduce unlinkability, irreversibility and revocability to the system. BWR-ROIAlign can directly plug into the model to introduce the above features for DCNN-based finger vein recognition systems. We perform extensive experiments on four public datasets to study the performance and cancelable biometric attributes of the CFVNet-based recognition system. The average accuracy, EERs and D_{\\leftrightarrow } ^{sys}\non the four datasets are 99.82%, 0.01% and 0.025, respectively, and achieves competitive performance compared with the state-of-the-arts.}
}


@article{DBLP:journals/tifs/LiuZZZD24,
	author = {Mengxiang Liu and
                  Xin Zhang and
                  Hengye Zhu and
                  Zhenyong Zhang and
                  Ruilong Deng},
	title = {Physics-Aware Watermarking Embedded in Unknown Input Observers for
                  False Data Injection Attack Detection in Cyber-Physical Microgrids},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7824--7840},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3447235},
	doi = {10.1109/TIFS.2024.3447235},
	timestamp = {Fri, 20 Sep 2024 14:01:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuZZZD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The physics-aware watermarking-based detection method has shown great potential in detecting stealthy False Data Injection Attacks (FDIAs) by adding appropriate watermarks to control commands or sensor measurements, especially in industrial control systems and grid-tied Distributed Energy Resources (DERs). However, existing watermarking-based detection methods have limitations in either handling the intricate physical couplings among DERs or characterising the fast changing power electronics dynamics, and thus cannot be directly applied to microgrids. Inspired by the methodology of Unknown Input Observer (UIO), which can be employed for the distributed anomaly monitoring in cyber-physical microgrids but would be easily bypassed once the adversary has the knowledge of certain electrical parameters, this paper makes the first attempt to investigate the physics-aware watermarking embedded in UIOs such that the stealthy FDIAs would be intentionally disrupted by the watermarking scheme. Based on the theoretical analysis of the detection enhancement and performance degradation under watermarking-enhanced UIOs, the watermark strengths, UIO parameters, and control gains are optimally co-designed to significantly enhance the detection effectiveness while not degrading the control performance. The robustness of the watermarking-enhanced UIO to Time Synchronisation Errors (TSEs) is improved by employing a sliding time window with appropriate length. The performance of the proposed method is validated through Matlab/Simulink studies and cyber-physical co-simulation experiments, and the sensitivities of the detection latency and TSE robustness to watermark strength and detection window’s length are comprehensively studied.}
}


@article{DBLP:journals/tifs/CaoZLWP24,
	author = {Jian Cao and
                  Minghui Zhang and
                  Weiqi Liu and
                  Lin Wang and
                  Jinye Peng},
	title = {Deep Learning-Based Security Analysis of Quantum Random Numbers Generated
                  by Imperfect Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7841--7852},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3445169},
	doi = {10.1109/TIFS.2024.3445169},
	timestamp = {Fri, 27 Sep 2024 16:24:56 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CaoZLWP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The quantum random number generator (QRNG) is theoretically capable of generating unpredictable random numbers based on the inherent uncertainty of quantum mechanics, which is of paramount importance for information security. However, the security of practical QRNG is susceptible to the influence of unknown classical noise introduced by imperfect measurement devices, leading to potential security threats. In this paper, we propose a deep learning-based prediction model for analyzing the bidirectional security of QRNG where the quantum source is contaminated by classical noise. Firstly, we train a deep learning model capable of evaluating the randomness of mixed entropy source composed of quantum source and classical source, which exhibits excellent performance and effectively avoids the limitations of Statistical tests in evaluating the randomness of the mixture of quantum and classical source results. Secondly, systematically analyzes the impact of non-ideal measurement devices on the practical security of the continuous variable QRNG, which provides an explicit basis for compensating the discrepancy between theory and experiment. Finally, we perform correlation detection on QRNG output sequences with a deep learning model and focus on both the forward and backward security of random numbers. Through bidirectional security detection, random number sequences that may be biased or manipulated can be more accurately and comprehensively evaluated, further preventing potential correlations from opening security holes for eavesdroppers.}
}


@article{DBLP:journals/tifs/LiHCSJDH24,
	author = {Siqin Li and
                  Kun He and
                  Jing Chen and
                  Min Shi and
                  Meng Jia and
                  Ruiying Du and
                  Ling Han},
	title = {MaskAuct: Seller-Autonomous Auction With Bidder Anonymity and Bidding
                  Confidentiality},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7853--7865},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3449116},
	doi = {10.1109/TIFS.2024.3449116},
	timestamp = {Fri, 20 Sep 2024 14:01:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiHCSJDH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Electronic auctions, popular in the digital era, raise great privacy concerns that may impact participant interests. However, traditional privacy-preserving auction systems fall short in facilitating seller autonomy, particularly in identifying and excluding previously mischievous anonymous bidders. In this paper, we propose MaskAuct, a seller-autonomous auction system with the privacy of bidder identity and bidding price. To enable seller autonomy without compromising bidder privacy, we present a new cryptographic primitive, called Zero-Knowledge Blacklistable Group Signature (ZKBGS), which can invalidate signatures from users in the blacklist without opening user identity. We construct MaskAuct from fully homomorphic encryption and ZKBGS, and introduce the distributed privacy server provider to address the collusion problem. The experimental results show ZKBGS has a smaller signature size (8320 bytes) and running time (635 ms for signing and 24 ms for verification) than the linkable ring signature, even when the length of the blacklist is 2^{9}\n. In contrast to the sealed-bid auction scheme SEAL, MaskAuct provides better communication complexity, and is 27\\times\nfaster on bidder computation.}
}


@article{DBLP:journals/tifs/WangYSH24,
	author = {Min Wang and
                  Jia Yu and
                  Wenting Shen and
                  Rong Hao},
	title = {Privacy-Preserving Time-Based Auditing for Secure Cloud Storage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7866--7878},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3449095},
	doi = {10.1109/TIFS.2024.3449095},
	timestamp = {Fri, 27 Sep 2024 16:24:56 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangYSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud storage auditing mechanism is used to check whether the data of users stored in the cloud is intact. Most existing auditing schemes for secure cloud storage are designed to check the integrity for specified files based on file identities. In some scenarios, the user would like to check the integrity of the files generated and uploaded to the cloud in a certain time period. Existing cloud storage auditing schemes cannot work well for supporting this practical requirement because the private information will be exposed. To satisfy this requirement, we propose a brand-new paradigm termed as privacy-preserving time-based auditing for secure cloud storage. The proposed paradigm allows the user to check whether the files generated and uploaded in a certain time period are intactly stored in the cloud. When intending to check the integrity of the files uploaded in this time period, the user only provides the challenged time period t to the Third Party Auditor (TPA). The TPA can verify the integrity of all the files based on this time period, but cannot know how many files and which files the user has generated and uploaded to the cloud in this time period. To decrease the complex overhead associated with certificate management, we introduce an identity-based auditing mechanism. We provide a specific security analysis to show the correctness, auditing soundness and privacy preserving of this scheme. The experiments demonstrate the efficiency of the proposed scheme.}
}


@article{DBLP:journals/tifs/HuangFHYG24,
	author = {Yilong Huang and
                  Fan Fan and
                  Chaofeng Huang and
                  Haomiao Yang and
                  Min Gu},
	title = {{MA-DG:} Learning Features of Sequences in Different Dimensions for
                  Min-Entropy Evaluation via 2D-CNN and Multi-Head Self-Attention},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7879--7894},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3447242},
	doi = {10.1109/TIFS.2024.3447242},
	timestamp = {Fri, 20 Sep 2024 14:01:30 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangFHYG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In information security, random number quality is closely related to cryptographic system security; moreover, random number quality depends on the corresponding entropy source quality. Therefore, evaluating the entropy source quality is extremely important. For existing evaluation methods, the ability of statistical-based entropy estimators to extract and learn data information is weak, resulting in lower entropy evaluation accuracies for some complex entropy sources. The prediction-based (especially neural network-based) entropy estimators with machine learning techniques have strong data-fitting and feature-extracting capabilities and can more accurately estimate the entropy values of complex entropy sources. However, owing to the relatively simple architecture of 1D neural networks, the 1D neural networks used by these estimators frequently reach bottlenecks, seriously limiting the further improvement in entropy estimation accuracy. Considering the above issues, this paper innovatively proposes an entropy estimation method based on a 2D-CNN and a multi-head self-attention mechanism. First, we built the MA-DG Net model. This model converts 1D random number sequences into 2D images via the GAF and DFT methods and then uses a 2D-CNN to extract and learn feature information from 2D images while retaining the original 1D sequential feature information via a multi-head self-attention mechanism. Next, we train the model to find its optimal parameters. Finally, we test the evaluation effect of the model using simulated datasets with known min-entropy and a real-world dataset with unknown min-entropy. The results show that compared with the entropy estimators in the experiment, our model achieves the lowest average relative error in entropy estimation on the simulated dataset of only 1.03%. In the real-world dataset, our model achieves the lowest entropy estimation value, which is an average of 0.88 lower than that of the other entropy estimators in the experiment.}
}


@article{DBLP:journals/tifs/ZhangZZCLH24,
	author = {Qingyang Zhang and
                  Xiaolong Zhou and
                  Hong Zhong and
                  Jie Cui and
                  Jiaxin Li and
                  Debiao He},
	title = {Device-Side Lightweight Mutual Authentication and Key Agreement Scheme
                  Based on Chameleon Hashing for Industrial Internet of Things},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7895--7907},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451357},
	doi = {10.1109/TIFS.2024.3451357},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZZCLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Several authentication and key agreement (AKA) schemes have been proposed to ensure secure communication in the Industrial Internet of Things (IIoT). However, most of these schemes face two primary problems. First, they cannot resist various attacks, such as impersonation and device capture attacks. Second, these schemes overlook the resource-constrained IIoT devices, failing to guarantee lightweight overhead for device operations. Therefore, we propose a novel and efficient AKA scheme. Utilizing the chameleon hash function and physical unclonable function, the proposed scheme implements a lightweight overhead for both authentication parties while maintaining the overhead of the gateway within a reasonable range. Furthermore, we implement device anonymity based on lightweight operations such as hash and XOR. In addition, we perform a rigorous security analysis using the widely accepted Real-Or-Random model, BAN logic, and Proverif tool. Finally, through heuristic analysis and experiments, we substantiate that our scheme surpasses the compared schemes in terms of both security attributes and system overhead.}
}


@article{DBLP:journals/tifs/YanLMX24,
	author = {Yuhao Yan and
                  Bo Lang and
                  Xiaoyuan Meng and
                  Nan Xiao},
	title = {Toward Generating Communication Graph Datasets for Botnet Detection
                  in Autonomous Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7908--7923},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3453172},
	doi = {10.1109/TIFS.2024.3453172},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YanLMX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Botnet is one of the main threats to cybersecurity because of its concealment and hazardous nature, especially in autonomous systems (ASs), such as campus networks. Graph-based detection methods are attracting increasing attention due to their ability to find and use the topological features of botnets. However, constructing or obtaining a botnet dataset is always difficult, and almost all existing public datasets suffer from extreme imbalances and poor authenticity, which makes training graph-based detection models challenging. To address these problems, we propose a role-based multistage growth method for generating AS botnet datasets, which is scalable and efficient. Our method generates a background communication graph based on complex network theory, models botnet behaviors by building a state machine, and generates the traffic of botnets. The experimental results show that our method can effectively restore the AS communication graph, and the generated datasets can significantly improve the performance of various graph-based detection models. Our generated dataset is available at https://github.com/Yebmoon/Botnet-graph-dataset.}
}


@article{DBLP:journals/tifs/XieNLSS24,
	author = {Weicheng Xie and
                  Zenghao Niu and
                  Qinliang Lin and
                  Siyang Song and
                  Linlin Shen},
	title = {Generative Imperceptible Attack With Feature Learning Bias Reduction
                  and Multi-Scale Variance Regularization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7924--7938},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451689},
	doi = {10.1109/TIFS.2024.3451689},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XieNLSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing studies have shown that malicious and imperceptible adversarial samples may significantly weaken the reliability and validity of deep learning systems. Since gradient-based attack algorithms may result in higher generation latency or demand large computation overhead, generative attack methods are frequently considered. However, the effectiveness and imperceptibility are still the main concerns for these generative attacks, 1) biased feature learning may occur, i.e., these algorithms may generate undesirable feature perturbations for samples that are less likely to be successfully attacked; 2) the produced perturbation noises may be easily perceived by human eyes. To this end, we propose a novel generative attack by manipulating the feature update. The proposed algorithm has two main merits, 1) our Bias-reduced Feature Manipulation (BrFM) that differentiates the hard-to-attack (Hard2Attack) and easy-to-attack (Easy2Attack) features, can avoid the possible learning shortcut for different difficulties of features in attack process, by customizing perturbations for Hard2Attack features to make them behave oppositely to those of benign features; 2) our Multi-scale Variance Regularization (MsVR) can reduce the unnatural transitions of perturbations in mask edges and flat areas with low contrast, while simultaneously trading off a reasonable attack capacity. Extensive experiments on the datasets of Caltech-101 and Imagenette in terms of the attack success rate and four imperceptibility metrics, show the effectiveness of our attack paradigm over the related state-of-the-art generative attack methods. Our codes will be made publicly available.}
}


@article{DBLP:journals/tifs/PengLZGLWLG24,
	author = {Yang Peng and
                  Pengfei Liu and
                  Qianyun Zhang and
                  Lantu Guo and
                  Yuchao Liu and
                  Yu Wang and
                  Yun Lin and
                  Guan Gui},
	title = {Dynamic Adaptation {RFF} Identification Method Leveraging Cognitive
                  Representation Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7939--7951},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451710},
	doi = {10.1109/TIFS.2024.3451710},
	timestamp = {Mon, 03 Mar 2025 22:25:02 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/PengLZGLWLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The evolution of wireless communication technologies has brought significant conveniences but also raised security concerns. Radio frequency fingerprint (RFF) is a potential feature, which can uniquely identify a specific emitter. The integration of Deep Learning (DL) has further enhanced the reliability of RFF identification. However, DL methods often struggle in dynamic communication environments. In this paper, we propose a dynamic adaptive RFF identification method leveraging Cognitive Representation Learning (CRL). Our proposed method is capable of recognizing and storing cognitive knowledge from historical environments. Furthermore, it dynamically adapts to current situations through its cognitive module, offering enhanced adaptability in dynamic environments. Specifically, we analyze the causes of RFF and define the RFF identification problems at first. Secondly, our cognitive module evaluates current data by examining both data distribution and feature distribution distances. Concurrently, our representation learning strategy enhances feature reuse and focuses on feature space. Finally, we implement an unsupervised ensemble module, combining unsupervised clustering with model ensemble techniques to boost performance. Simulation results validate our method’s robust generalization in dynamic settings, with an improvement of 7.66% in controlled environments and 5.98% in more challenging scenarios on PA dataset. Furthermore, the high identification ratio and ablation study results underscore the efficacy and necessity of each module in our approach.}
}


@article{DBLP:journals/tifs/PandaSVJB24,
	author = {Manoj Kumar Panda and
                  Badri Narayan Subudhi and
                  Thangaraj Veerakumar and
                  Vinit Jakhetiya and
                  Thierry Bouwmans},
	title = {A Multi-Scale Contrast Preserving Encoder-Decoder Architecture for
                  Local Change Detection From Thermal Video Scenes},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7968--7981},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3447237},
	doi = {10.1109/TIFS.2024.3447237},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PandaSVJB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article presents a new deep-learning architecture based on an encoder-decoder framework that retains contrast while performing background subtraction (BS) on thermal videos. The proposed scheme consists of three consecutive blocks: the encoder, the Multi-Scale Contrast Preservation (MSCP) block, and the decoder. The encoder network employs a hybrid of convolution and atrous convolution blocks to preserve both sparse and dense features, with a skip connection. The encoder, combined with the MSCP block, maintains multi-scale contrast features with reduced training loss. Furthermore, the decoder network accurately projects the extracted features at different layers into pixel-level detail. The proposed end-to-end model efficiently provides a binary map for the corresponding thermal video scene. The efficiency of the proposed algorithm is validated on two large-scale datasets, namely CDnet 2014 and the Tripura University Video Dataset at Night Time (TU-VDN). Both qualitative and quantitative results demonstrate that MSCP outperforms thirty-eight existing BS schemes.}
}


@article{DBLP:journals/tifs/GrosseSO24,
	author = {Leonhard Grosse and
                  Sara Saeidian and
                  Tobias J. Oechtering},
	title = {Extremal Mechanisms for Pointwise Maximal Leakage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7952--7967},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3449556},
	doi = {10.1109/TIFS.2024.3449556},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GrosseSO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data publishing under privacy constraints can be achieved with mechanisms that add randomness to data points when released to an untrusted party, thereby decreasing the data’s utility. In this paper, we analyze this privacy-utility tradeoff for the pointwise maximal leakage (PML) privacy measure and provide optimal privacy mechanisms for a general class of convex utility functions. PML was recently proposed as an operationally meaningful privacy measure based on two equivalent threat models: An adversary guessing a randomized function and an adversary aiming to maximize a general gain function. We prove a cardinality bound, showing that output alphabets of optimal mechanisms in this context need not to be larger than the size of their inputs. Then, we characterize the optimization region as a (convex) polytope. We derive closed-form optimal privacy mechanisms for arbitrary priors in the high privacy regime (when the privacy parameter is sufficiently small) and uniform priors for all ranges of the privacy parameter using tools from convex analysis. Furthermore, we present a linear program that can compute optimal mechanisms for PML in a general setting. We conclude by demonstrating the performance of the closed-form mechanisms through numerical simulations.}
}


@article{DBLP:journals/tifs/QuZWPGW24,
	author = {Haomin Qu and
                  Hongze Zhao and
                  Qingguo Wei and
                  Weihua Pei and
                  Xiaorong Gao and
                  Yijun Wang},
	title = {Combing Multiple Visual Stimuli to Enhance the Performance of VEP-Based
                  Biometrics},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7982--7993},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3452628},
	doi = {10.1109/TIFS.2024.3452628},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QuZWPGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, electroencephalography (EEG) has received increasing attention in the field of biometrics because of its unique advantages such as covertness, resistance to spoofing, sensitivity to emotional and mental states, and continuous nature. Visual evoked potentials (VEPs) have been widely used in EEG-based biometrics owing to fast recognition speed and high accuracy. This study proposes a new method to combine multiple visual stimuli for VEP-based individual identification. Correct recognition rate (CRR) was estimated using steady-state VEPs (ss-VEPs), and code modulated VEPs (c-VEPs) recorded from a group of 35 subjects. c-VEPs achieved a 100% CRR using 3.1-s of VEP data (a 10.8-s duration, including 7.7-s intervals) in the cross-session condition. An online system based on the combination of stimuli optimized from the data of 35 subjects was further developed and validated with an additional group of 22 subjects. A cross-session CRR of 99.55% was achieved using the same parameters. These results indicate that the proposed VEP-based individual identification method using multiple visual stimuli shows great potential for practical applications.}
}


@article{DBLP:journals/tifs/BianTL24,
	author = {Yuhao Bian and
                  Shengjing Tian and
                  Xiuping Liu},
	title = {iBA: Backdoor Attack on 3D Point Cloud via Reconstructing Itself},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {7994--8008},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3452630},
	doi = {10.1109/TIFS.2024.3452630},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BianTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread deployment of deep neural networks (DNNs) for 3D point cloud processing contrasts sharply with their vulnerability to security breaches, particularly backdoor attacks. Studying these attacks is crucial for raising security awareness and mitigating potential risks. However, the irregularity of 3D data and the heterogeneity of 3D DNNs pose unique challenges. Existing methods frequently fail against basic point cloud preprocessing or require intricate manual design. Exploring simple, imperceptible, effective, and difficult-to-defend triggers in 3D point clouds remains challenging. To address this issue, we propose iBA, a novel solution utilizing a folding-based auto-encoder (AE). By leveraging united reconstruction losses, iBA enhances both effectiveness and imperceptibility. Its data-driven nature eliminates the need for complex manual design, while the AE core imparts significant nonlinearity and sample specificity to the trigger, rendering traditional preprocessing techniques ineffective. Additionally, a trigger smoothing module based on spherical harmonic transformation (SHT) allows for controllable intensity. We also discuss potential countermeasures and the possibility of physical deployment for iBA as an extensive reference. Both quantitative and qualitative results demonstrate the effectiveness of our method, achieving state-of-the-art attack success rates (ASR) across a variety of victim models, even with defensive measures in place. iBA’s imperceptibility is validated with multiple metrics as well.}
}


@article{DBLP:journals/tifs/KimKK24,
	author = {Wilton Kim and
                  Stanislav Kruglik and
                  Han Mao Kiah},
	title = {Verifiable Coded Computation of Multiple Functions},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8009--8022},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3450288},
	doi = {10.1109/TIFS.2024.3450288},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KimKK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the problem of evaluating distinct multivariate polynomials over several massive datasets in a distributed computing system with a single master node and multiple worker nodes. We focus on the general case when each multivariate polynomial is evaluated over its corresponding dataset and propose a generalization of the Lagrange Coded Computing framework (Yu et al., 2019) to perform all computations simultaneously while providing robustness against stragglers who do not respond in time, adversarial workers who respond with wrong computation and information-theoretic security of dataset against colluding workers. Our scheme introduces a small computation overhead which results in a reduction in download cost and also offers comparable resistance to stragglers over existing solutions. On top of it, we also propose two verification schemes to detect the presence of adversaries, which leads to incorrect results, without involving additional nodes.}
}


@article{DBLP:journals/tifs/WangLZXY24,
	author = {Wei Wang and
                  Dongli Liu and
                  Zilin Zheng and
                  Peng Xu and
                  Laurence Tianruo Yang},
	title = {Identity-Based Group Encryption With Keyword Search Against Keyword
                  Guessing Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8023--8036},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3452548},
	doi = {10.1109/TIFS.2024.3452548},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangLZXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Public key Encryption with Keyword Search (PEKS) has emerged as a solution for the receiver to securely search the sender’s encrypted data on the cloud. However, the PEKS scheme is threatened by the Keyword Guessing Attack (KGA), which leaks the receiver’s keyword privacy. To resist KGA, researchers have inherited the authentication mechanism into the PEKS system (PAEKS) but also forbid using one trapdoor to search all sender’s encrypted data. In this paper, we explore the KGA problem from grouping senders and propose the notion of Identity-based Group Encryption with Keyword Search (IBGEKS), which leverages Identity-based cryptography to securely search encrypted data. Compared with the PAEKS scheme, the IBGEKS scheme can search the sender’s ciphertexts within the same group established by the receiver via one receiver’s trapdoor. For security, we analyze the KGA problem and propose ciphertexts, identities, and trapdoors indistinguishability for IBGEKS. The evaluation depicts that the IBGEKS has competitive algorithm performance with other SA-PEKS and PAEKS schemes and has superior search performance on the Enron email dataset.}
}


@article{DBLP:journals/tifs/LiuCP24,
	author = {Xiuwen Liu and
                  Yanjiao Chen and
                  Shanchen Pang},
	title = {Defending Against Membership Inference Attack for Counterfactual Federated
                  Recommendation With Differentially Private Representation Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8037--8051},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3453031},
	doi = {10.1109/TIFS.2024.3453031},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuCP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When it comes to the marriage of federated learning and personalized recommendation services (FedRec), characterizing user-item interaction behaviors is a long-standing and unresolved issue, highlighting the growing data privacy concerns due to the inherent openness of recommender systems. As the new interaction-level membership inference attacks on FedRecs have recently surfaced, quite possibly such adversarial attacks act as the hidden confounders lying behind the interactive recommendation, resulting in the obstruction of the causal effect disentanglement on long-term user satisfaction. As such, tailored to the specifics of private learning, we propose a counterfactual interactive recommendation system that builds a differentially private representation learning based defender (CIRDP) to capture and mitigate the adversarial threats, augmenting causal inference-based interactive recommendation of FedRecs. When characterizing interaction-level membership inference attacks of the hidden eavesdropping adversary as the primary cause of adversarial effect on user satisfaction, CIRDP incorporates causal inference-augmented offline reinforcement learning (offline RL) into FedRecs. CIRDP innovatively provides counterfactual satisfaction by optimizing a sensitivity-guided disentangled representation module with an innovative two-fold mutual information objective. As such, CIRDP introduces a differentially private representation learning based defender, guaranteeing interaction behavior-level differential privacy (DP) with a significant reduction in privacy costs. Extensive comparisons demonstrate CIRDP’s superiority over the state-of-the-art baselines in reducing inference attack threats and improving long-term success in the interactive recommendation.}
}


@article{DBLP:journals/tifs/DengRWLC24,
	author = {Aixian Deng and
                  Qian Ren and
                  Yingjun Wu and
                  Hong Lei and
                  Bangdao Chen},
	title = {Proof of Finalization: {A} Self-Fulfilling Function of Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8052--8065},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451355},
	doi = {10.1109/TIFS.2024.3451355},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DengRWLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain has been widely used in various industries for providing trustworthy data. On-chain data can be regarded as trusted after it is finalized by blockchain consensus, namely after the data is believed to be immutable. Unfortunately, nodes with poor/isolated network conditions are still susceptible to data spoofing attacks of blockchain view, spawning kinds of severe attacks. For example, a light node newly joining a blockchain network may request the blockchain view from a malicious full node and accept a spoof view, leading to a double spending attack. Besides, a Trusted Execution Environment (TEE), the network stack of which is fully controlled by its host, may be fed spoofed blockchain data as input, undermining the trustworthiness of TEE-based computation by cheating inputs. To resist data spoofing, existing methods rely on a trusted authority to identify trusted data, or timely provide sufficient confirmation blocks for a block b to prove the finalization of b (since the adversary holding less hash power than the honest blockchain node cannot generate the confirmation blocks timely). These methods either suffer the risks caused by centralized trust base or are only PoW-oriented and high-latency. As promising blockchains including Ethereum migrate to energy-saving consensus, e.g., PoS, designing consensus-agnostic approaches against data spoofing becomes an urgent need of the industries. In this paper, we introduce a Proof of Finalization (PoF) problem for proving the finalization of blockchain to prevent data spoofing attacks of blockchain. We also contrive a novel PoF scheme, which leverages the chain quality property of blockchain to establish a trustworthy committee for proof generation. The scheme is chain-agnostic, non-interactive, non-authority-involved, and with negligible latency. Once blockchain data is finalized, the latency of proof generation in our scheme is only 106 milliseconds. Therefore, our scheme paves the way for any system, e.g., light nodes, cross-chain bridges, and layer-2 systems, to read blockchains with various consensus securely.}
}


@article{DBLP:journals/tifs/ChenCQZ24,
	author = {Congcong Chen and
                  Jinhua Cui and
                  Gang Qu and
                  Jiliang Zhang},
	title = {Write+Sync: Software Cache Write Covert Channels Exploiting Memory-Disk
                  Synchronization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8066--8078},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3414255},
	doi = {10.1109/TIFS.2024.3414255},
	timestamp = {Mon, 03 Mar 2025 22:25:01 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenCQZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Memory-disk synchronization is a critical technology for ensuring data correctness, integrity, and security, especially in systems that handle sensitive information like financial transactions and medical records. We propose Write+Sync, a group of attacks that exploit the memory-disk synchronization primitives. Write+Sync works by subtly varying the timing of synchronization on a software cache (i.e., the write buffer), offering two advantages: 1) implemented purely in software, enabling deployment on any hardware devices; 2) resilient against existing countermeasures. We present the principles of Write+Sync through the implementation of two write covert channel protocols, using either a single file or page, and introduce three enhanced strategies that utilize multiple files and pages. The feasibility of these channels is demonstrated in both cross-process and cross-sandbox scenarios across diverse operating systems (OSes). Experimental results show that, the average rate can reach 2.036 Kb/s (with a peak rate of 14.762 Kb/s) and the error rate is 0% on Linux; when running on macOS, the average rate achieves 10.211 Kb/s (with a peak rate of 253.022 Kb/s) and the error rate is 0.004%. To show its security implications, we evaluate it using two case studies-website fingerprinting and performance degradation attacks. To the best of our knowledge, Write+Sync is the first high-speed write covert channel for software cache.}
}


@article{DBLP:journals/tifs/ZhangWQLWW24,
	author = {Shixuan Zhang and
                  Haixia Wang and
                  Pengfei Qiu and
                  Yongqiang Lyu and
                  Hongpeng Wang and
                  Dongsheng Wang},
	title = {SCAFinder: Formal Verification of Cache Fine-Grained Features for
                  Side Channel Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8079--8093},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3452002},
	doi = {10.1109/TIFS.2024.3452002},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangWQLWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research has unveiled numerous cache-timing side-channel attacks exploiting the side effects of fine-grained cache features, such as coherence protocol and prefetch, among others. Traditional modeling methods and verification techniques are insufficient for verifying caches with fine-grained features and detecting cache timing vulnerabilities. There is a necessity for comprehensive verification of such complex cache designs. This paper presents SCAFinder, a verification framework targeting the cache designs with fine-grained features; it identifies cache side-channel attacks through model checking techniques. Specifically, it proposes a modeling methodology for cache designs that enables us to abstract the cache’s behavior and latency characteristics. We implement a search algorithm for finding all counterexamples based on open-source model checking software. Subsequently, we add an attack scenario analysis module to discover attacks applicable to specific scenarios. We evaluate SCAFinder on Intel Skylake-X microarchitecture, demonstrating its capability to generate 7 new attack sequences exploiting coherence protocol and prefetch, and 12 new replacement policy-based side channels. As a case study, we successfully built a covert channel for one of the sequences on the real-world processor. To the best of our knowledge, we are the first to implement cross-core replacement policy-based attacks on non-inclusive caches.}
}


@article{DBLP:journals/tifs/HuLYPZQ24,
	author = {Xiaoxiao Hu and
                  Sheng Li and
                  Qichao Ying and
                  Wanli Peng and
                  Xinpeng Zhang and
                  Zhenxing Qian},
	title = {Establishing Robust Generative Image Steganography via Popular Stable
                  Diffusion},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8094--8108},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3444311},
	doi = {10.1109/TIFS.2024.3444311},
	timestamp = {Thu, 03 Oct 2024 00:45:28 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuLYPZQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generative steganography, a novel paradigm in information hiding, has garnered considerable attention for its potential to withstand steganalysis. However, existing generative steganography approaches suffer from the limited visual quality of generated images and are challenging to apply to lossy transmissions in real-world scenarios with unknown channel attacks. To address these issues, this paper proposes a novel robust generative image steganography scheme, facilitating zero-shot text-driven stego image generation without the need for additional training or fine-tuning. Specifically, we employ the popular Stable Diffusion model as the backbone generative network to establish a covert transmission channel. Our proposed framework overcomes the challenges of numerical instability and perturbation sensitivity inherent in diffusion models. Adhering to Kerckhoff’s principle, we propose a novel mapping module based on dual keys to enhance robustness and security under lossy transmission conditions. Experimental results showcase the superior performance of our method in terms of extraction accuracy, robustness, security, and image quality.}
}


@article{DBLP:journals/tifs/LuoJWWXO24,
	author = {Xinjian Luo and
                  Yangfan Jiang and
                  Fei Wei and
                  Yuncheng Wu and
                  Xiaokui Xiao and
                  Beng Chin Ooi},
	title = {Exploring Privacy and Fairness Risks in Sharing Diffusion Models:
                  An Adversarial Perspective},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8109--8124},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3453555},
	doi = {10.1109/TIFS.2024.3453555},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LuoJWWXO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined. In this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execute fairness poisoning attacks to undermine the receiver’s downstream models by manipulating the training data distribution of the diffusion model. Meanwhile, the receiver can perform property inference attacks to reveal the distribution of sensitive features in the sharer’s dataset. Our experiments conducted on real-world datasets demonstrate remarkable attack performance on different types of diffusion models, which highlights the critical importance of robust data auditing and privacy protection protocols in pertinent applications.}
}


@article{DBLP:journals/tifs/JiaCMDGZXLC24,
	author = {Xiaojun Jia and
                  Yuefeng Chen and
                  Xiaofeng Mao and
                  Ranjie Duan and
                  Jindong Gu and
                  Rong Zhang and
                  Hui Xue and
                  Yang Liu and
                  Xiaochun Cao},
	title = {Revisiting and Exploring Efficient Fast Adversarial Training via {LAW:}
                  Lipschitz Regularization and Auto Weight Averaging},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8125--8139},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420128},
	doi = {10.1109/TIFS.2024.3420128},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiaCMDGZXLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fast Adversarial Training (FAT) not only improves the model robustness but also reduces the training cost of standard adversarial training. However, fast adversarial training often suffers from Catastrophic Overfitting (CO), which results in poor robustness performance. Catastrophic Overfitting describes the phenomenon of a sudden and significant decrease in robust accuracy during the training of fast adversarial training. Many effective techniques have been developed to prevent Catastrophic Overfitting and improve the model robustness from different perspectives. However, these techniques adopt inconsistent training settings and require different training costs, i.e., training time and memory costs, leading to unfair comparisons. In this paper, we conduct a comprehensive study of over 10 fast adversarial training methods in terms of adversarial robustness and training costs. We revisit the effectiveness and efficiency of fast adversarial training techniques in preventing Catastrophic Overfitting from the perspective of model local nonlinearity and propose an effective Lipschitz regularization method for fast adversarial training. Furthermore, we explore the effect of data augmentation and weight averaging in fast adversarial training and propose a simple yet effective auto weight averaging method to improve robustness further. By assembling these techniques, we propose an effective FGSM-based fast adversarial training method equipped with Lipschitz regularization and Auto Weight averaging, abbreviated as FGSM-LAW. Experimental evaluations on four benchmark databases demonstrate the superiority of our method over state-of-the-art fast adversarial training methods and the advanced standard adversarial training methods.}
}


@article{DBLP:journals/tifs/ChenZLMZZMD24,
	author = {Zhe Chen and
                  Haiyan Zhang and
                  Xinghua Li and
                  Yinbin Miao and
                  Xiaohan Zhang and
                  Man Zhang and
                  Siqi Ma and
                  Robert H. Deng},
	title = {{FDFL:} Fair and Discrepancy-Aware Incentive Mechanism for Federated
                  Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8140--8154},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3433537},
	doi = {10.1109/TIFS.2024.3433537},
	timestamp = {Fri, 14 Feb 2025 20:58:22 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenZLMZZMD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is an emerging distributed machine learning paradigm crucial for ensuring privacy-preserving learning. In FL, a fair incentive mechanism is indispensable for inspiring more clients to participate in FL training. Nevertheless, achieving a fair incentive mechanism in FL is an arduous endeavor, underscored by two significant challenges that persistently elude resolution within existing methodologies. Firstly, existing works overlook the issue of category distribution heterogeneity in contribution evaluation, leading to incomplete contribution evaluations. Secondly, the fact that malicious servers will dishonestly allocate rewards to save costs is not considered in existing work, which can be a barrier to client participation in FL. This paper introduces FDFL (Fair and Discrepancy-aware incentive mechanism for Federated Learning), a novel system addressing these concerns. FDFL encompasses two key elements: 1) Discrepancy-aware contribution evaluation approach; 2) Provable reward allocation approach. Extensive experiments on four model-dataset combinations demonstrate that, under the heterogeneous setting, our scheme improves accuracy by an average of 9.85% and 11.97% compared to FedAvg and FAIR, respectively.}
}


@article{DBLP:journals/tifs/JiangZ24,
	author = {Yiming Jiang and
                  Jiangfan Zhang},
	title = {Profitability Analysis of Time-Restricted Double-Spending Attack on
                  PoW-Based Large Scale Blockchain With the Aid of Multiple Types of
                  Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8155--8171},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3449224},
	doi = {10.1109/TIFS.2024.3449224},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiangZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the time-restricted double-spending attack (TR-DSA) on the Proof-of-Work-based blockchain, where an adversary conducts a DSA within a finite timeframe and simultaneously launches multiple types of attacks on the blockchain. To be specific, the adversary can conduct attacks to isolate some honest miners and cause block propagation delays among miners to enhance the success probability of the TR-DSA. We first develop the closed-form expression for the success probability of a TR-DSA with the aid of multiple types of attacks, which is leveraged to develop the closed-form expression for the expected profit of a TR-DSA. The numerical analysis reveals that in scenarios where an adversary lacks the majority of computational power in the blockchain network, it is advisable for the adversary to refrain from indefinitely conducting a DSA, and moreover, the adversary can repeatedly launch “short-time” TR-DSAs to obtain their maximum expected profit. Notably, by leveraging the closed-form expression for the expected profit of a TR-DSA, the blockchain network designer can reduce the expected profit of a TR-DSA and therefore significantly mitigate the risk of TR-DSAs by adjusting system parameters, such as the number of blocks required for transaction confirmation, mining reward, and mining cost.}
}


@article{DBLP:journals/tifs/KruglikDKWZ24,
	author = {Stanislav Kruglik and
                  Son Hoang Dau and
                  Han Mao Kiah and
                  Huaxiong Wang and
                  Liang Feng Zhang},
	title = {Querying Twice to Achieve Information-Theoretic Verifiability in Private
                  Information Retrieval},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8172--8187},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3453550},
	doi = {10.1109/TIFS.2024.3453550},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/KruglikDKWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private Information Retrieval (PIR) protocols allow a client to retrieve any file of interest while keeping the files identity hidden from the database servers. While many existing PIR protocols assume servers to be honest but curious, we investigate the scenario of dishonest servers that provide incorrect answers to mislead clients into obtaining wrong results. We propose a unified framework for polynomial PIR protocols encompassing various existing protocols that optimize the download rate or total communication cost. We introduce a way to transform a polynomial PIR to a verifiable one without increasing the number of involved servers by doubling the queries. The security guarantees can be information-theoretic or computational, and the verification keys can be public or private. Moreover, in one of our protocols, the ratio between the additional download overhead associated with verification and the normal download cost approaches zero as the file size goes to infinity.}
}


@article{DBLP:journals/tifs/WuGKLXLZ24,
	author = {Hao Wu and
                  Yuhang Gong and
                  Xiaopeng Ke and
                  Hanzhong Liang and
                  Fengyuan Xu and
                  Yunxin Liu and
                  Sheng Zhong},
	title = {{TIM:} Enabling Large-Scale White-Box Testing on In-App Deep Learning
                  Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8188--8203},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3455761},
	doi = {10.1109/TIFS.2024.3455761},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuGKLXLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intelligent Applications (iApps), equipped with in-App deep learning (DL) models, are emerging to provide reliable DL inference services. However, in-App DL models are typically compiled into inference-only versions to enhance system performance, thereby impeding the evaluation of DL models. Specifically, the assessment of in-App models currently relies on black-box testing methods rather than direct white-box testing approaches. In this work, we propose TIM, an automated tool designed for conducting large-scale white-box testing of in-App models. Taking an iApp as input, TIM can lift the black-box (i.e., inference-only) in-App DL model into a backpropagation-enabled one and package it together, allowing comprehensive DL model testing or security issues detection. TIM proposes two reconstruction techniques to convert the inference-only model to a backpropagation-enabled version and reconstruct the DL-related IO processing code. In our experiments, we utilize TIM to extract 100 unique commercial in-App models and convert the models to white-box models, enabling backpropagation functionality. Experimental results show that TIM’s reconstruction techniques exhibit high accuracy. We open-source our prototype and part of the experimental data on the website https://zenodo.org/record/7548141.}
}


@article{DBLP:journals/tifs/BagheriKKMWJNP24,
	author = {Sima Bagheri and
                  Hugo Kermabon{-}Bobinnec and
                  Mohammad Ekramul Kabir and
                  Suryadipta Majumdar and
                  Lingyu Wang and
                  Yosr Jarraya and
                  Boubakr Nour and
                  Makan Pourzandi},
	title = {{ACE-WARP:} {A} Cost-Effective Approach to Proactive and Non-Disruptive
                  Incident Response in Kubernetes Clusters},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8204--8219},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3449038},
	doi = {10.1109/TIFS.2024.3449038},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BagheriKKMWJNP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A large-scale cluster of containers managed with an orchestrator like Kubernetes are behind many cloud-native applications today. However, the weaker isolation provided by containers means attackers can potentially exploit a vulnerable container and then escape its isolation to cause more severe damages to the underlying infrastructure and its hosted applications. Defending against such an attack using existing attack detection solutions can be challenging. Due to the well known high false positive rate of such solutions, taking aggressive actions upon every alert can lead to unacceptable service disruption. On the other hand, waiting for security administrators to perform in-depth analysis and validation could render the mitigation too late to prevent irreversible damages. In this paper, we propose ACE-WARP, a cost-effective proactive and non-disruptive incident response to address such security challenges for Kubernetes clusters. First, our approach is proactive in the sense that it performs mitigation based on predicted (instead of real) attacks, which prevents irreversible damages. Second, our approach is also non-disruptive since the mitigation is achieved through live migration of containers, which causes no service disruption even in the case of false positives. Finally, to realize the full potential of this approach in containers migration, we formulate the inherent trade-off between security and cost (delay) as a multi-objective optimization problem. Our evaluation results show that ACE-WARP can successfully mitigate up to 81% of the attacks, and our optimization algorithm achieves up to 30% more threat reduction and 7% less delay while being 37 times faster compared to a standard optimization solution.}
}


@article{DBLP:journals/tifs/TanWHMY24,
	author = {Jingwen Tan and
                  Huanran Wang and
                  Shuai Han and
                  Dapeng Man and
                  Wu Yang},
	title = {An Adaptability-Enhanced Few-Shot Website Fingerprinting Attack Based
                  on Collusion},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8220--8235},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3433586},
	doi = {10.1109/TIFS.2024.3433586},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TanWHMY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Few-shot website fingerprinting (FSWF) attacks attempt to identify whether the users have access to specific websites based on a few training data. Existing FSWF attack methods focus on adapting to variable network conditions in real scenarios. They use various techniques to transfer the model to adapt to test data which has a different distribution from training data. However, recent methods ignore the impact of pre-training data diversity on adaptability. The poor data diversity caused by the user-specific data crawl limits representation ability, and further hinders rapid adaptation to new network conditions. Due to the extreme Non-IId between multiple attackers’ datasets, it is not feasible to mix multiple datasets or perform traditional federated learning methods to improve representation ability. To address the issue, we propose a novel method based on a joint learning framework to achieve the collusion FSWF attacks. The proposed method fuses the feature spaces of multiple user-side attackers to enhance the representation ability of the local model, and constructs a virtual fusion center to mitigate the impact of Non-IID. It improves the adaptability under variable network conditions for the local attacker. This paper conducts comprehensive experiments to evaluate the performance of the proposed method in both closed-world and open-world settings. Compared with the state-of-the-art method, the proposed method improves the accuracy by up to 13.02% in the closed-world setting and the AUC by up to 0.085 in the open-world setting, respectively.}
}


@article{DBLP:journals/tifs/NiuXLDXY24,
	author = {Hong Niu and
                  Yue Xiao and
                  Xia Lei and
                  Lilin Dan and
                  Wei Xiang and
                  Chau Yuen},
	title = {Reconfigurable Intelligent Surface-Assisted Passive Beamforming Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8236--8247},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3444193},
	doi = {10.1109/TIFS.2024.3444193},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NiuXLDXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the reconfigurable intelligent surface (RIS), capable of adjusting the phase shifts (PSs) of the reflecting signals through its low-cost elements, has emerged as a promising technology for next-generation wireless communications. However, the RIS may be manipulated by an illegal passive attacker (Wyn) due to the shared nature of wireless channels. In this paper, a Wyn-controlled RIS is considered to attack multiple-input single-output (MISO) communications via passive beamforming based on existing localization and Rician factor estimation techniques. Specifically, we propose an alignment cancellation (AC) scheme to minimize the achievable rate (AR), where the closed-form expressions for location, reflecting element number, and PSs are derived. Furthermore, the computational complexity is quantified to evaluate the low-cost characteristics of this algorithm. Simulation results demonstrate that the proposed AC scheme outperforms other benchmark schemes in degrading the AR with efficient and low-complexity designs.}
}


@article{DBLP:journals/tifs/HuangWL24,
	author = {Qinlong Huang and
                  Chao Wang and
                  Boyu Lu},
	title = {An Efficient and Verifiable Encrypted Data Filtering Framework Over
                  Large-Scale Storage in Cloud Edge},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8248--8262},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3456600},
	doi = {10.1109/TIFS.2024.3456600},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid growth of edge computing is accelerating data subscriptions between cloud platforms and mobile subscribers, but sensitive information in these data faces security and privacy concerns. Fortunately, matchmaking attribute-based encryption (MABE) as a new type of encrypted data filtering mechanism has been introduced in cloud edge, which not only enforces fine-grained access control over the encrypted data, but also allows subscribers to dynamically filter data of interest from authentic publishers through edge nodes. However, filtering entire ciphertext collection in linear time is not feasible for large-scale data storage, and edge nodes may return mismatched or incomplete results due to corruption or compromise. To this end, we propose VDFilter, an efficient and verifiable encrypted data filtering framework over large-scale storage in cloud edge. VDFilter first introduces a verifiable MABE as the underlying primitive, which achieves efficient data filtering in edge nodes with an inverted collection from the ciphertext collection, and verifies the soundness and completeness of filtered results with an accumulation tree. To accommodate the ciphertext collection from multiple publishers, VDFilter deploys the construction of the accumulation tree on the Intel SGX enclave within the cloud server, and utilizes authenticated data structures to guarantee secure and efficient filtered result verification. Finally, we provide formal security proofs for VDFilter and demonstrate its efficiency with extensive experiments. Compared with existing schemes, VDFilter is much more efficient in data storing and filtering even with verification operations, and its computational and communication overhead on the subscriber is also low.}
}


@article{DBLP:journals/tifs/ChenYGPC24,
	author = {Yanru Chen and
                  Fengming Yin and
                  Bing Guo and
                  Zhiwen Pan and
                  Liangyin Chen},
	title = {Cross-Layer {AKA} Protocol for Industrial Control Based on Channel
                  State Information},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8263--8274},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3443647},
	doi = {10.1109/TIFS.2024.3443647},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenYGPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial control technology faces serious communication security threats. Authenticated key agreement(AKA) protocols are essential to secure communication between industrial control nodes, but they must be efficient and robust due to resource constraints. Existing AKA protocols based on encryption algorithms have limitations such as vulnerability to clone attacks. Also, there is a lack of protocol’s research that fully integrate advantages of physical and upper layer. We propose a novel cross-layer AKA protocol that leverages channel state information(CSI), which has uniqueness and real randomness, and is unforgeable, to enhance security and reduce computational overhead. Our protocol only requires simple operations such as algebraic, Hash and XOR. We introduce a new security verification model, superCK, which extends the well-known eCK and relaxes assumptions on attackers. Our protocol achieves 12 fully provable key security capabilities, and has 75.91% less computational overhead and 6.99% less communication overhead than the best ones, achieving an optimal trade-off between security and efficiency.}
}


@article{DBLP:journals/tifs/LiCCLFLLS24,
	author = {Shijie Li and
                  Yuqi Chen and
                  Xin Chen and
                  Zedong Li and
                  Dongliang Fang and
                  Kaixiang Liu and
                  Shichao Lv and
                  Limin Sun},
	title = {PowerGuard: Using Power Side-Channel Signals to Secure Motion Controllers
                  in {ICS}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8275--8290},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451362},
	doi = {10.1109/TIFS.2024.3451362},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiCCLFLLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Motion control systems, extensively utilized in domains like 3D printing, CNC machining, and robotic arm operations, are pivotal in modern manufacturing and automation processes. Consequently, a specific category of attacks, designed to target these systems, can manipulate the movements of controlled objects while replaying false sensor readings to evade existing tools, thereby severely disrupting these essential operations without being detected. To make things worse, the limited computing resources of embedded devices in these systems constrain the implementation of robust security protections and monitoring mechanisms locally. To solve this, we propose a novel side-channel method that leverages current signals emitted by motors to reconstruct trajectories for attack detection. In this paper, we design and implement a two-stage detection framework, dubbed PowerGuard. In the offline learning stage, PowerGuard first captures the current signals emitted by the servo motors and models the correlation between these signals and corresponding movement trajectories. In the real-time monitoring stage, PowerGuard finds outliers that deviate from the desired trajectory described in the benign G-code file. We have evaluated PowerGuard using a typical motion control system that contains CNC machine tools from different vendors (e.g., Siemens 828D, 840D-sl, Fanuc 0i-md, 0i-tf). We conducted extensive experiments to evaluate the reconstruction accuracy and attack detection performance. Experimental results show that PowerGuard can reconstruct movement trajectories with an error of 0.047mm, and detect 93.35% of various trajectory anomalies.}
}


@article{DBLP:journals/tifs/HuangGJHJCPL24,
	author = {Yihao Huang and
                  Qing Guo and
                  Felix Juefei{-}Xu and
                  Ming Hu and
                  Xiaojun Jia and
                  Xiaochun Cao and
                  Geguang Pu and
                  Yang Liu},
	title = {Texture Re-Scalable Universal Adversarial Perturbation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8291--8305},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3416030},
	doi = {10.1109/TIFS.2024.3416030},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangGJHJCPL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Universal adversarial perturbation (UAP), also known as image-agnostic perturbation, is a fixed perturbation map that can fool the classifier with high probabilities on arbitrary images, making it more practical for attacking deep models in the real world. Previous UAP methods generate a scale-fixed and texture-fixed perturbation map for all images, which ignores the multi-scale objects in images and usually results in a low fooling ratio. Since the widely used convolution neural networks tend to classify objects according to semantic information stored in local textures, it seems a reasonable and intuitive way to improve the UAP from the perspective of utilizing local contents effectively. In this work, we find that the fooling ratios significantly increase when we add a constraint to encourage a small-scale UAP map and repeat it vertically and horizontally to fill the whole image domain. To this end, we propose texture scale-constrained UAP (TSC-UAP), a simple yet effective UAP enhancement method that automatically generates UAPs with category-specific local textures that can fool deep models more easily. Through a low-cost operation that restricts the texture scale, TSC-UAP achieves a considerable improvement in the fooling ratio and attack transferability for both data-dependent and data-free UAP methods. Experiments conducted on two state-of-the-art UAP methods, eight popular CNN models and four classical datasets show the remarkable performance of TSC-UAP.}
}


@article{DBLP:journals/tifs/ZhangZZ24,
	author = {Shunsheng Zhang and
                  Youwen Zhu and
                  Ao Zeng},
	title = {Collusion-Resilient Privacy-Preserving Database Fingerprinting},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8306--8321},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3455748},
	doi = {10.1109/TIFS.2024.3455748},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Database sharing may bring about privacy disclosure and illegal redistribution. A previously proposed entry-level Differential Privacy FingerPrinting mechanism (DPFP) for relational database achieves privacy and liability guarantees simultaneously. However, it is only robust against common attacks from a vicious Data Analyzer (DA) and lacks robustness against logical AND or OR collusion attack even if Anti-Collusion Code (ACC) is used to trace who the colluders are. In this work, we propose a Collusion-Resilient entry-level DP FingerPrinting mechanism (CRDPFP) for uniquely identifying colluders by directly using ACCs. Specifically, we firstly theoretically and experimentally demonstrate the vulnerabilities of existing fingerprinting schemes by identification of logical AND/OR collusion attack. To survive 5 types of collusion attacks and identify colluders, a Group-oriented Concatenated (GC) ACC based on I-code and Cover Free Family code is constructed and a catch-all detector is designed. By leveraging the randomization nature of fingerprint, we transform GC code into provable entry-level DP guarantees on the entire database. We also show that CRDPFP inherits the same connection properties between privacy, fingerprint robustness, and database utility from DPFP. Via experiments on two real-world relational databases, we exhibit that our mechanism supplies stronger robustness against 50% random flipping attack from a vicious DA, achieves higher and lower detecting rates of at least one colluder and innocent, uniquely traces all colluders for logical AND or OR collusion attack and obtains near-optimal utility with fingerprint parameter being close to 2 compared to existing schemes.}
}


@article{DBLP:journals/tifs/FeiXTB24,
	author = {Jianwei Fei and
                  Zhihua Xia and
                  Benedetta Tondi and
                  Mauro Barni},
	title = {Wide Flat Minimum Watermarking for Robust Ownership Verification of
                  GANs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8322--8337},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3443650},
	doi = {10.1109/TIFS.2024.3443650},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/FeiXTB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a novel multi-bit box-free watermarking method for the protection of Intellectual Property Rights (IPR) of GANs with improved robustness against white-box model-level attacks like fine-tuning, pruning, quantization, and surrogate model attacks. The watermark is embedded by adding an extra watermarking loss term during GAN training, ensuring that the images generated by the GAN contain an invisible watermark that can be retrieved by a pre-trained watermark decoder. In order to improve the robustness against white-box model-level attacks, we make sure that the model converges to a wide flat minimum of the watermarking loss term, in such a way that any modification of the model parameters does not erase the watermark. To do so, we add random noise vectors to the parameters of the generator and require that the watermarking loss term is as invariant as possible with respect to the presence of noise. This procedure forces the generator to converge to a wide flat minimum of the watermarking loss. The proposed method is architecture- and dataset-agnostic, thus being applicable to many different generation tasks and models, as well as to CNN-based image processing architectures. We present the results of extensive experiments showing that the presence of the watermark has a negligible impact on the quality of the generated images, and proving the superior robustness of the watermark against model modification and surrogate model attacks.}
}


@article{DBLP:journals/tifs/JiaLLLTLGDL24,
	author = {Jingyu Jia and
                  Xinhao Li and
                  Tong Li and
                  Zhewei Liu and
                  Chang Tan and
                  Siyi Lv and
                  Liang Guo and
                  Changyu Dong and
                  Zheli Liu},
	title = {ABSyn: An Accurate Differentially Private Data Synthesis Scheme With
                  Adaptive Selection and Batch Processes},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8338--8352},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3453175},
	doi = {10.1109/TIFS.2024.3453175},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/JiaLLLTLGDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In private data publishing, a promising solution is generating synthetic data that enables any query on the private dataset while satisfying differential privacy. Over the past decade, researchers mainly focused on improving the query accuracy of synthetic data. However, the limitations of existing works restrict them from achieving a better trade-off between accuracy and privacy. In this paper, we propose ABSyn, a novel scheme for differentially private data synthesis. Under the Select-Measure-Generate paradigm, ABSyn has an adaptive mechanism for precisely selecting marginals and follows the batch processes. Our adaptive-batch scheme can provide a well-selected marginal set and the optimal allocation of privacy budget, which makes its synthetic data achieve high accuracy without compromising privacy. We implement an efficient prototype of ABSyn and compare it with existing works by analyzing public datasets. Experimental results show that ABSyn achieves query accuracy on synthetic datasets by a factor of 1.26\\times and efficiency by a factor of 18.60\\times over the state-of-the-art scheme on average.}
}


@article{DBLP:journals/tifs/HeTGSZ24,
	author = {Weizhen He and
                  Jinglei Tan and
                  Yunfei Guo and
                  Ke Shang and
                  Hengwei Zhang},
	title = {A Deep Reinforcement Learning-Based Deception Asset Selection Algorithm
                  in Differential Games},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8353--8368},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451189},
	doi = {10.1109/TIFS.2024.3451189},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HeTGSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Currently, there are various problems in the field of network attack-defense analysis and deception asset deployment of game theory-based, such as difficulties in constructing attack and defense models and determining real-time attack and defense strategies. To address these problems, this study proposes a differential game deception asset selection algorithm based on multi-agent deep reinforcement learning. Specifically, by analyzing the attack and defense strategies, the infectious disease model is developed to conduct the evolution analysis of the network security state, and the differential equation of the node state in the deception defense system is derived. In addition, a differential game model for the cyber deception attack-defense process is constructed, and the reward functions of the attacker and defender are designed. A deception asset selection algorithm is established based on the deep Q network method to solve optimal deception assets. The effectiveness of the proposed model is validated through a microservices attack-defense example in a cloud-native environment. The results show that compared to the deception asset selection algorithms based on the Fictitious Self Play and Policy Space Response Oracles, the convergence speed of the proposed algorithm is improved by 77.8% and 95.6%, respectively.}
}


@article{DBLP:journals/tifs/hammeGAPJ24,
	author = {Tim Van hamme and
                  Giuseppe Garofalo and
                  Enrique Argones{-}R{\'{u}}a and
                  Davy Preuveneers and
                  Wouter Joosen},
	title = {A Novel Evaluation Framework for Biometric Security: Assessing Guessing
                  Difficulty as a Metric},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8369--8384},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3455930},
	doi = {10.1109/TIFS.2024.3455930},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/hammeGAPJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biometric authentication systems have traditionally relied on the False Match Rate (FMR) to evaluate security against impersonation threats. However, this metric alone is insufficient for assessing vulnerabilities to statistical attacks because it cannot account for the non-uniformity of mismatches and atypical inputs that adversaries may manipulate. To address this issue, we propose a new evaluation framework that overcomes these limitations. The framework includes an estimate of the effective key space of biometrics and metrics that consider non-uniformity in the biometric embedding space. Our findings demonstrate that our framework provides a nuanced understanding of biometric security. Moreover, optimizing for the proposed metric leads to better security against statistical attacks than optimizing the FMR. Furthermore, the framework provides a comparative security analysis with traditional methods like passwords and PIN codes. It also quantifies the impact on security when adversaries partially know their victims, e.g., demographics.}
}


@article{DBLP:journals/tifs/CaiYKLCHK24,
	author = {Rizhao Cai and
                  Zitong Yu and
                  Chenqi Kong and
                  Haoliang Li and
                  Changsheng Chen and
                  Yongjian Hu and
                  Alex C. Kot},
	title = {S-Adapter: Generalizing Vision Transformer for Face Anti-Spoofing
                  With Statistical Tokens},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8385--8397},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3420699},
	doi = {10.1109/TIFS.2024.3420699},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CaiYKLCHK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face Anti-Spoofing (FAS) aims to detect malicious attempts to invade a face recognition system by presenting spoofed faces. State-of-the-art FAS techniques predominantly rely on deep learning models but their cross-domain generalization capabilities are often hindered by the domain shift problem, which arises due to different distributions between training and testing data. In this study, we develop a generalized FAS method under the Efficient Parameter Transfer Learning (EPTL) paradigm, where we adapt the pre-trained Vision Transformer models for the FAS task. During training, the adapter modules are inserted into the pre-trained ViT model, and the adapters are updated while other pre-trained parameters remain fixed. We find the limitations of previous vanilla adapters in that they are based on linear layers, which lack a spoofing-aware inductive bias and thus restrict the cross-domain generalization. To address this limitation and achieve cross-domain generalized FAS, we propose a novel Statistical Adapter (S-Adapter) that gathers local discriminative and statistical information from localized token histograms. To further improve the generalization of the statistical tokens, we propose a novel Token Style Regularization (TSR), which aims to reduce domain style variance by regularizing Gram matrices extracted from tokens across different domains. Our experimental results demonstrate that our proposed S-Adapter and TSR provide significant benefits in both zero-shot and few-shot cross-domain testing, outperforming state-of-the-art methods on several benchmark tests. We will release the source code upon acceptance.}
}


@article{DBLP:journals/tifs/ZhuW24,
	author = {Liufu Zhu and
                  Ding Wang},
	title = {Robust Multi-Factor Authentication for WSNs With Dynamic Password
                  Recovery},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8398--8413},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451364},
	doi = {10.1109/TIFS.2024.3451364},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhuW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-factor authentication (MFA) is crucial for Wireless Sensor Networks (WSNs) to ensure secure communication in security-critical applications such as smart homes, industrial control, and military defense due to the open nature of WSNs. Considerable efforts have been made to propose various MFA schemes with varied security goals and desirable properties. However, little attention has been given to the property of dynamic password recovery, and it still remains a question of how to construct a robust MFA scheme with the desirable property of dynamic password recovery for WSNs. In this paper, we first review two representative multi-factor authentication schemes proposed by Li-Tian (at IEEE Syst J’22) and Fatima et al. (at ACM TOSN’23) as case studies, and reveal that these two schemes fail to resist some known attacks and pay little attention to password forgetting and leakage issues. Accordingly, we employ the techniques of the honeywords method, fuzzy-verifier technique, and public key cryptosystem to construct a novel MFA scheme. Particularly, we propose the first dynamic password recovery method for MFA to address password forgetting and leakage issues. Key rotation is implemented to ensure the security of the long-term secret key. Our scheme is provably secure under the Random Oracle Model. Comparison results show the superiority of our new scheme.}
}


@article{DBLP:journals/tifs/SheHLLL24,
	author = {Huimin She and
                  Yongjian Hu and
                  Beibei Liu and
                  Jicheng Li and
                  Chang{-}Tsun Li},
	title = {Using Graph Neural Networks to Improve Generalization Capability of
                  the Models for Deepfake Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8414--8427},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451356},
	doi = {10.1109/TIFS.2024.3451356},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SheHLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deepfake detection plays a key role in preventing the misuses of artificial intelligence in video editing. Current deep learning-based deepfake detection methods often perform quite well in intra-dataset testing, but they may lose good performance in cross-dataset testing. In other words, generalization capability is still a crucial problem to be resolved. In this paper, we address deepfake detection by treating an image as non-Euclidean data and representing it as a graph so as to infer the informative connections between image patches/nodes to improve the detector’s generalization capability. Specifically, we propose a graph neural network-based paradigm that casts deepfake detection as a graph binary classification problem. First, we propose a dual-branch network to extract node features from both RGB images and their color difference images (CDIs) via the Transformer-based trainable node encoder module (TNEM). Second, we adopt the adjacency matrix to establish the connections of the nodes and further optimize the graph representation by applying the adaptive threshold to the adjacency matrix. Third, multi-head graph convolutional neural networks are carried out for node feature extraction. RGB node features and CDI node features are concatenated and separately fed into the graph classifier and node classifier for forgery detection and forgery localization. Experimental results demonstrate that our method can overall outperform other state-of-the-art methods on 7 popular benchmark datasets. Notably, our model achieves the highest AUC values of 96.19%, 80.99% and 87.68% on Celeb-DF-V2, DFDC and DFDCP in turn when trained on FF++ (C23). The visualization of node classification results also provides good interpretability of our proposed approach.}
}


@article{DBLP:journals/tifs/GroszGJ24,
	author = {Steven A. Grosz and
                  Akash Godbole and
                  Anil K. Jain},
	title = {Mobile Contactless Palmprint Recognition: Use of Multiscale, Multimodel
                  Embeddings},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8428--8440},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3413631},
	doi = {10.1109/TIFS.2024.3413631},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GroszGJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contactless palmprints are comprised of both global and local discriminative features. Most prior work focuses on extracting global features or local features alone for palmprint matching, whereas this research introduces a novel framework that combines global and local features for enhanced palmprint matching accuracy. Leveraging recent advancements in deep learning, this study integrates a vision transformer (ViT) and a convolutional neural network (CNN) to extract complementary local and global features. Next, a mobile-based, end-to-end palmprint recognition system is developed, referred to as Palm-ID. On top of the ViT and CNN features, Palm-ID incorporates a palmprint enhancement module and efficient dimensionality reduction (for faster matching). Palm-ID balances the trade-off between accuracy and latency, requiring just 18ms to extract a template of size 516 bytes, which can be efficiently searched against a 10,000 palmprint gallery in 0.33ms on an AMD EPYC 7543 32-Core CPU utilizing 128-threads. Cross-database matching protocols and evaluations on large-scale operational datasets demonstrate the robustness of the proposed method, achieving a TAR of 98.06% at FAR=0.01% on a newly collected, time-separated dataset. To show a practical deployment of the end-to-end system, the entire recognition pipeline is embedded within a mobile device for enhanced user privacy and security.}
}


@article{DBLP:journals/tifs/LongOWWZ24,
	author = {Jiangshan Long and
                  Changhai Ou and
                  Chenxu Wang and
                  Zhu Wang and
                  Yongbin Zhou},
	title = {What Is Now Possible? Security Evaluation on Univariate {DPA} Attacks
                  With Inaccurate Leakage Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8441--8456},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3459636},
	doi = {10.1109/TIFS.2024.3459636},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LongOWWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Success Rate (SR) is one of the most popular side-channel security metrics measuring the efficiency of key recovery. Theoretical expression of success rate reveals the functional dependency between relevant parameters such as number of measurements and Signal-to-Noise Ratio (SNR), helping researchers understand the resistance of a given implementation rapidly. However so far, existing works have exposed fundamental problems: (1) Evaluation is confined to a very limited range of distinguishers and specialized methods; (2) Evaluation assumes a perfect leakage model that is detached from reality. It is widely observed that an inaccurate leakage model will lead to a degraded or even distorted success rate. In this paper, we tackle above problems by introducing a novel framework which is able to evaluate seven side-channel distinguishers with a unified expression. Among them, we explore four new distinguishers that have not been investigated in the existing literature. Within the framework, DPA distinguishers are intuitively understood as linear maximum likelihood attack testing closeness between vectors with some easy-to-comprehend geometric metrics. Our evaluation is able to deal with profiled models of any quality and is agnostic to model profiling techniques. It uniquely enables the evaluation of success rates under inaccurate leakage models, whilst providing an (indirect) answer to the open question “how much information is lost due to the model biases” through quantifying the degradation of success rates. Finally, we formulate a set of criterion values for quantitative analyses of the model biases. It provides theoretical evidences for a more thorough explanation for the various behaviors of DPA attacks. Experimental results are inline with the theory, confirming its practical applicability.}
}


@article{DBLP:journals/tifs/WangTZLKTYL24,
	author = {Jiakai Wang and
                  Ye Tao and
                  Yichi Zhang and
                  Wanting Liu and
                  Yusheng Kong and
                  Shaolin Tan and
                  Rongen Yan and
                  Xianglong Liu},
	title = {Adversarial Examples Against WiFi Fingerprint-Based Localization in
                  the Physical World},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8457--8471},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3453041},
	doi = {10.1109/TIFS.2024.3453041},
	timestamp = {Mon, 03 Mar 2025 22:25:02 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangTZLKTYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WiFi Fingerprint-based Localization (WFL) has recently achieved promising results in the bloom of deep learning techniques. Unfortunately, current studies reveal the great risks of deep-learning models when facing adversarial attacks, raising broader concerns about Deep-learning-based WiFi Fingerprint Localization Models (DFLMs). However, real-world adversarial attacks targeting DFLMs are not fully investigated, making it unclear how to counter this potential threat. In this paper, we take the first step to introduce adversarial examples into the physical world against DFLMs. Specifically, we propose a general attack method named Phy-Adv, consisting of a physical attenuation loss and a differentiable simulation module, the generated adversarial noise could be feasibly produced in the real world and make effects on DFLMs, i.e., misleading the DFLMs from the signal source end. Furthermore, aiming at countering this typical adversarial threat, we propose a Relaxant Multiple Batch Normalization (RMBN) approach, which alleviates the weak robustness of DFLMs by the data-end adaptive training-set segmenting and model-end multiple batch normalization designing. To demonstrate the de facto effectiveness of the proposed physical adversarial examples and the adversarial defense strategy, we conducted extensive experiments on 2 datasets, i.e., BHD and TUT, and multiple deep models, e.g., AlexNet, VGG, and ResNet. The experimental results strongly support that our Phy-Adv shows satisfactory adversarial attacking ability in the physical world, meanwhile, the RMBN enjoys considerable defense ability against the adversarial attacks.}
}


@article{DBLP:journals/tifs/YangCLHHJBD24,
	author = {Xuanang Yang and
                  Jing Chen and
                  Yuqing Li and
                  Kun He and
                  Xiaojie Huang and
                  Zikuan Jiang and
                  Hao Bai and
                  Ruiying Du},
	title = {Fregata: Fast Private Inference With Unified Secure Two-Party Protocols},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8472--8484},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3444327},
	doi = {10.1109/TIFS.2024.3444327},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangCLHHJBD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private Inference (PI) safeguards client and server privacy when the client utilizes the server’s model to make predictions. Existing PI solutions for Convolutional Neural Networks (CNNs) employ distinct cryptographic primitives to customize secure two-party protocols for linear and non-linear layers. This requires data to be converted into a specific form to switch between protocols, thus leading to a significant increase in inference latency. In this paper, we present Fregata, a fast PI scheme for CNNs by leveraging identical cryptographic primitives to calculate both linear and nonlinear layers. Specifically, our protocols utilize homomorphic encryption to obtain additive secret shares of matrix products during the offline phase, followed by lightweight multiplication and addition operations on these shares in the latency-sensitive online phase. Benefiting from uniformity, we accelerate inference from a holistic perspective by decoupling certain procedures of our protocols and executing them asynchronously. Moreover, to improve the efficiency of the offline phase, we elaborate a homomorphic matrix multiplication calculation method with reduced computation and communication complexity compared to existing approaches. Furthermore, we minimize inference latency by employing graphics processing units to parallelize the operations on the shares during the online phase. Experimental evaluations on popular CNN models such as SqueezeNet, ResNet, and DenseNet demonstrate that Fregata reduces 35-45 times inference latency over the state-of-the-art counterparts, accompanied by a 1.6-2.8 times decrease in communication overhead. In terms of total runtime, Fregata maintains a reduction of approximately 3 times.}
}


@article{DBLP:journals/tifs/BaGWLCLLR24,
	author = {Zhongjie Ba and
                  Bin Gong and
                  Yuwei Wang and
                  Yuxuan Liu and
                  Peng Cheng and
                  Feng Lin and
                  Li Lu and
                  Kui Ren},
	title = {Indelible "Footprints" of Inaudible Command Injection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8485--8499},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3459728},
	doi = {10.1109/TIFS.2024.3459728},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/BaGWLCLLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inaudible command injection transmits inaudible ultrasounds to inject adversarial speech commands into a voice assistant, therefore manipulating voice control systems (e.g., a garage door or a security camera) for illegitimate purposes. Although the attack is inaudible, we find it does leave visible “footprints”. Such attack “footprints” are the side product due to the interaction between the attack signal (i.e., input) and the acoustic components (i.e., transfer function), so they reflect the hardware characteristics of the sound capture system, including the microphone diaphragm, the low-pass filter, and the analog-to-digital converter. Moreover, unlike the non-linearity distortion that is erasable with signal-shaping techniques, the “footprints” are indelible because they are unrelated to the content of injected commands. We discover two types of indelible “footprints” embedded in the recording spectrogram, namely abnormal interfering noise and abnormal demodulation. A software-based detection method and a portable detector, DolphinTag, are further designed to identify these “footprints”. The software-based method achieves a detection accuracy of 99.8% on the phone models exhibiting abnormal interfering noise, and our DolphinTag achieves 100% detection accuracy which detects the ultrasound attack by actively facilitating the abnormal demodulation.}
}


@article{DBLP:journals/tifs/TianJHYDS24,
	author = {Buwei Tian and
                  Junyong Jiang and
                  Zichen He and
                  Xin Yuan and
                  Lu Dong and
                  Changyin Sun},
	title = {Functionality-Verification Attack Framework Based on Reinforcement
                  Learning Against Static Malware Detectors},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8500--8514},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3453047},
	doi = {10.1109/TIFS.2024.3453047},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TianJHYDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current adversarial attacks are capable of achieving effective evasion against machine learning-based static malware detectors. However, these methods have problems such as long example generation times and lack of functionality validation. To address these issues, we propose an enhanced adversarial example generation framework based on reinforcement learning. This framework improves the example generation efficiency by redesigning the state space and action space employed by the agents. Furthermore, we incorporate the functionality of adversarial example validation for the first time as a component of the example generation process within the framework, significantly enhancing the efficiency of verification. Multiple popular detectors are chosen as victim models to assess the effectiveness of the attack framework. The vulnerabilities of these detectors are elucidated through explanations of the detectors and the analysis of attack results. Finally, a policy distillation approach based on transfer learning is employed to enhance the generalizability of the framework. By learning expert knowledge from agents trained against different detectors, the framework could launch effective attacks against various detectors. The effectiveness of the proposed framework is verified through experiment results.}
}


@article{DBLP:journals/tifs/ZhangLDTC24,
	author = {Junning Zhang and
                  Yicen Liu and
                  Guoru Ding and
                  Bo Tang and
                  Yanlong Chen},
	title = {Adaptive Decomposition and Extraction Network of Individual Fingerprint
                  Features for Specific Emitter Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8515--8528},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3427361},
	doi = {10.1109/TIFS.2024.3427361},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLDTC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of emitter individual identification technology in cognitive radio networks, electromagnetic emitter individual target identification based on deep learning has received much attention. However, the confusion of unintentional features (i.e., individual fingerprint features) and modulation features resulting from the received signal might lead to low identification accuracy. In order to address this narrow, we propose an emitter individual identification network based on the competitive collaboration framework, called Specific Emitter Identification with Adaptive Decomposition and Extraction of individual fingerprint features (SEI-ADE), which can adaptively decompose and extract individual fingerprint features. Firstly, a signal adaptive decomposition network is proposed to distinguish the emitter signal and the interference signal by adopting the gradient inversion layer and the non-sequential characteristics of the signal. Then, in order to distinguish and extract corresponding features, the feature extractor and the training loss constraints are constructed for individual fingerprint feature signals, modulation signals, and external emitter interference signals, respectively. The proposed framework can continuously adjust the gradient loss, classification loss, and timing coding contrast loss, thus minimizing the entire training loss. For the separation of the modulation signal and individual fingerprint feature signal, the signal is transformed into the feature domain, and a mask prediction network is proposed to locate the domain of the individual fingerprint feature. The obtained experimental results show the outstanding performance of our proposal, compared with the current benchmarks. All our models and code are available at https://github.com/jn-z/SEI-ADE.}
}


@article{DBLP:journals/tifs/DuZW24,
	author = {Yuefeng Du and
                  Anxin Zhou and
                  Cong Wang},
	title = {DWare: Cost-Efficient Decentralized Storage With Adaptive Middleware},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8529--8543},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3459650},
	doi = {10.1109/TIFS.2024.3459650},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DuZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed Outsourced Storage systems, exemplified by the InterPlanetary File System (IPFS), offer compelling alternatives to traditional centralized cloud storage by emphasizing resilience and openness. Advancing this paradigm, Decentralized Storage (DS) markets leverage distributed ledgers to facilitate the monetization of outsourced storage. However, these markets often prioritize security over cost-efficiency, leading to high costs in existing DS markets. In our work, we introduce a middleware service, DWare, utilizing trusted hardware to balance security and cost efficiency. DWare offers two key advantages: 1) It enhances storage auditing efficiency by delegating computational tasks and standardizing the batched audit process. This approach offers a more feasible solution for validating outsourced storage with recurring pay-offs. 2) It implements secure and verifiable data deduplication, thereby increasing storage efficiency and reducing operational costs. This step, commonplace in cloud storage services, remains largely unexplored in current DS designs. While DWare could empirically reduce costs to levels near raw storage fees, it entails certain security concessions due to middleware involvement. To address this, we propose a hybrid trust security model, granting data owners the flexibility to adjust the security-cost balance as needed.}
}


@article{DBLP:journals/tifs/WeiHWWSDZM24,
	author = {Congming Wei and
                  Guangze Hong and
                  An Wang and
                  Jing Wang and
                  Shaofei Sun and
                  Yaoling Ding and
                  Liehuang Zhu and
                  Wenrui Ma},
	title = {Time Is Not Enough: Timing Leakage Analysis on Cryptographic Chips
                  via Plaintext-Ciphertext Correlation in Non-Timing Channel},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8544--8558},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3449119},
	doi = {10.1109/TIFS.2024.3449119},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WeiHWWSDZM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In side-channel testing, the standard timing analysis works when the vendor can provide a measurement to indicate the execution time of cryptographic algorithms. In this paper, we find that there exists timing leakage in power/electromagnetic channels, which is often ignored in traditional timing analysis. Hence a new method of timing analysis is proposed to deal with the case where execution time is not available. Different execution time leads to different execution intervals, affecting the locations of plaintext and ciphertext transmission. Our method detects timing leakage by studying changes in plaintext-ciphertext correlation when traces are aligned forward and backward. Experiments are then carried out on different cryptographic devices. Furthermore, we propose an improved timing analysis framework which gives appropriate methods for different scenarios.}
}


@article{DBLP:journals/tifs/ZhangYWHSGR24,
	author = {Yaning Zhang and
                  Zitong Yu and
                  Tianyi Wang and
                  Xiaobin Huang and
                  Linlin Shen and
                  Zan Gao and
                  Jianfeng Ren},
	title = {GenFace: {A} Large-Scale Fine-Grained Face Forgery Benchmark and Cross
                  Appearance-Edge Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8559--8572},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3461958},
	doi = {10.1109/TIFS.2024.3461958},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangYWHSGR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid advancement of photorealistic generators has reached a critical juncture where the discrepancy between authentic and manipulated images is increasingly indistinguishable. Thus, benchmarking and advancing techniques detecting digital manipulation become an urgent issue. Although there have been a number of publicly available face forgery datasets, the forgery faces are mostly generated using GAN-based synthesis technology, which does not involve the most recent technologies like diffusion. The diversity and quality of images generated by diffusion models have been significantly improved and thus a much more challenging face forgery dataset shall be used to evaluate SOTA forgery detection literature. In this paper, we propose a large-scale, diverse, and fine-grained high-fidelity dataset, namely GenFace, to facilitate the advancement of deepfake detection, which contains a large number of forgery faces generated by advanced generators such as the diffusion-based model and more detailed labels about the manipulation approaches and adopted generators. In addition to evaluating SOTA approaches on our benchmark, we design an innovative Cross Appearance-Edge Learning (CAEL) detector to capture multi-grained appearance and edge global representations, and detect discriminative and general forgery traces. Moreover, we devise an Appearance-Edge Cross-Attention (AECA) module to explore the various integrations across two domains. Extensive experiment results and visualizations show that our detection model outperforms the state of the arts on different settings like cross-generator, cross-forgery, and cross-dataset evaluations. Code and datasets will be available at https://github.com/Jenine-321/GenFace.}
}


@article{DBLP:journals/tifs/WangZCDC24,
	author = {Ruochen Wang and
                  Jun Zhou and
                  Zhenfu Cao and
                  Xiaolei Dong and
                  Kim{-}Kwang Raymond Choo},
	title = {Updatable Private Set Intersection With Forward Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8573--8586},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3461475},
	doi = {10.1109/TIFS.2024.3461475},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangZCDC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private set intersection (PSI) facilitates the computation of intersection between the private sets of two parties, ensuring that no additional information beyond the intersection itself is revealed. However, most state-of-the-art are limited to static PSI, leaving updatable PSI untouched. Existing PSI protocols will cost huge computational resources to compute intersection on updated sets. More seriously, none of the existing updatable PSI approaches can achieve both secure addition and deletion operations in once update. To address these challenges, we propose Forward Private Updatable PSI (FUPSI) for two-party setting. FUPSI is designed to support addition and deletion simultaneously, while ensuring forward privacy against semi-honest adversaries. In this work, we analyze the infeasibility of secure synchronous addition and deletion in the existing updatable PSI approaches, by presenting a practical attack which would lead to privacy leakages while deletion function is performed. Then, to resist this attack against semi-honest adversaries, we demonstrate how FUPSI can protect the forward privacy of user sets, by utilizing a variant of keyword Private Information Retrieval (PIR) to hide sensitive intermediate parameters. Specifically in FUPSI, two parties execute keyword PIR to retrieve a flag indicating that the current element is added or deleted so as to determine whether it is in the participants’ datasets. Finally, we provide the formal security proof for our proposed FUPSI, and extensive experimental results demonstrate efficiency and the practicality of our proposal. For instance, the communication complexity of our proposal is only logarithmically related to the size of update sets and the computational overhead is mainly composed of logarithmical times PIR calculations. Owing to the variant of keyword PIR, our work also incurs minimal communication overhead even for enormous datasets, which performs well in updatable settings and slow networks.}
}


@article{DBLP:journals/tifs/YangKTGCZZ24,
	author = {Ziyuan Yang and
                  Ming Kang and
                  Andrew Beng Jin Teoh and
                  Chengrui Gao and
                  Wen Chen and
                  Bob Zhang and
                  Yi Zhang},
	title = {A Dual-Level Cancelable Framework for Palmprint Verification and Hack-Proof
                  Data Storage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8587--8599},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3461869},
	doi = {10.1109/TIFS.2024.3461869},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangKTGCZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, palmprints have been extensively utilized for individual verification. The abundance of sensitive information in palmprint data necessitates robust protection to ensure security and privacy without compromising system performance. Existing systems frequently use cancelable transformations to protect palmprint templates. However, if an adversary gains access to the stored database, they could initiate a replay attack before the system detects the breach and can revoke and replace the reference template. To address replay attacks while meeting template protection criteria, we propose a dual-level cancelable palmprint verification framework. In this framework, the reference template is initially transformed using a cancelable competition hashing network with a first-level token, enabling the end-to-end generation of cancelable templates. During enrollment, the system creates a negative database (NDB) using a second-level token for further protection. Due to the unique NDB-to-vector matching characteristic, a replay attack involving the matching between the reference template and a compromised instance in NDB form is infeasible. This approach effectively addresses the replay attack problem at its root. Furthermore, the dual-level protected reference template enjoys heightened security, as reversing the NDB is NP-hard. We also propose a novel NDB-to-vector matching algorithm based on matrix operations to expedite the matching process, addressing the inefficiencies of previous NDB methods reliant on dictionary-based matching rules. Extensive experiments conducted on public palmprint datasets confirm the effectiveness and generality of the proposed framework. Upon acceptance of the paper, the code will be accessible at https://github.com/Zi-YuanYang/DCPV.}
}


@article{DBLP:journals/tifs/ZhaoCYQZY24,
	author = {Jiawei Zhao and
                  Kejiang Chen and
                  Xiaojian Yuan and
                  Yuang Qi and
                  Weiming Zhang and
                  Nenghai Yu},
	title = {Silent Guardian: Protecting Text From Malicious Exploitation by Large
                  Language Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8600--8615},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3455775},
	doi = {10.1109/TIFS.2024.3455775},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaoCYQZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of large language models (LLMs) has yielded impressive success in various downstream tasks. However, the vast potential and remarkable capabilities of LLMs also raise new security and privacy concerns if they are exploited for nefarious purposes due to their open-endedness. For example, LLMs may be used to plagiarize or imitate writing, thereby infringing the copyright of the original content or to create indiscriminate fake information based on a certain source text. In some cases, LLMs can even analyze text from the Internet to infer personal privacy. Unfortunately, previous text protection research could not foresee the emergence of powerful LLMs, rendering it no longer effective in this new context. To bridge this gap, we introduce Silent Guardian (SG), a text protection mechanism against LLMs, which allows LLMs to refuse to generate responses when receiving protected text, preventing the malicious use of text from the source. Specifically, we first propose the concept of Truncation Protection Examples (TPE). By carefully modifying the text to be protected, TPE can induce LLMs to first sample the end token, thus directly terminating the interaction. In addition, to efficiently construct TPE in the discrete space of text data, we propose a novel optimization algorithm called Super Tailored Protection (STP), which is not only highly efficient but also maintains the semantic consistency of the text during the optimization process. The comprehensive experimental evaluation demonstrates that SG can effectively protect the target text under various configurations and achieve almost 100% protection success rate in some cases. Notably, SG also exhibits relatively good transferability and robustness, making its application in practical scenarios possible. Our code is available at https://github.com/weiyezhimeng/Silent-Guardian.}
}


@article{DBLP:journals/tifs/XieWFM24,
	author = {Wei Xie and
                  Hongjun Wang and
                  Zimo Feng and
                  Chunlai Ma},
	title = {A Novel PHY-Layer Spoofing Attack Detection Scheme Based on WGAN-Encoder
                  Model},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8616--8629},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3460373},
	doi = {10.1109/TIFS.2024.3460373},
	timestamp = {Mon, 11 Nov 2024 20:54:53 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XieWFM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {PHY-layer spoofing attack is a potential critical issue in wireless network communication security, which could lead to catastrophic consequences for critical mission and applications, especially in Industrial Internet of Things scenarios with enormous number of devices. In this paper, we propose a novel spoofing attack detection scheme exploiting Channel State Information (CSI) phase difference. Firstly, we establish a mapping between CSI phase difference and the location of wireless communication devices to achieve the goal of spoofing attack detection. Due to the stable property of CSI phase difference, we convert CSI phase difference into heatmaps for subsequent training of the neural network model. Then we propose Wasserstein generative adversarial network and Encoder (WGAN-Encoder) deep-learning-based model in the scheme. This model utilizes discriminator feature residual error and image reconstruction error to get anomaly score for spoofing attack detection. This model overcomes the limitations of traditional detection methods on prior knowledge the attacker’s real CSI under real communication scenarios. Finally, we carry out extensive experimental evaluations about the detection performance and robustness of the proposed scheme based on data collected in time-varying scenarios. The results have successfully demonstrated that the proposed scheme exhibits outstanding performance.}
}


@article{DBLP:journals/tifs/ZhangKS24,
	author = {Yufeng Zhang and
                  Wenxiong Kang and
                  Wenwei Song},
	title = {Robust and Accurate Hand Gesture Authentication With Cross-Modality
                  Local-Global Behavior Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8630--8643},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451367},
	doi = {10.1109/TIFS.2024.3451367},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangKS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Obtaining robust fine-grained behavioral features is critical for dynamic hand gesture authentication. However, behavioral characteristics are abstract and complex, making them more difficult to capture than physiological characteristics. Moreover, various illumination and backgrounds in practical applications pose additional challenges to existing methods because commonly used RGB videos are sensitive to them. To overcome this robustness limitation, we propose a two-stream CNN-based cross-modality local-global network (CMLG-Net) with two complementary modules to enhance the discriminability and robustness of behavioral features. First, we introduce a temporal scale pyramid (TSP) module consisting of multiple parallel convolution subbranches with different temporal kernel sizes to capture the fine-grained local motion cues at various temporal scales. Second, a cross-modality temporal non-local (CMTNL) module is devised to simultaneously aggregate the global temporal features and cross-modality features with an attention mechanism. Through the complementary combination of the TSP and CMTNL modules, our CMLG-Net obtains a comprehensive and robust behavioral representation that contains both multi-scale (short- and long-term) and multimodal (RGB-D) behavioral information. Extensive experiments are conducted on the largest dataset, SCUT-DHGA, and a simulated practical dataset, SCUT-DHGA-br, to demonstrate the effectiveness of CMLG-Net in exploiting fine-grained behavioral features and complementary multimodal information. Finally, it achieves stat-of-the-art performance with the lowest ERR of 0.497% and 4.848% in two challenging evaluation protocols and shows significant superiority in robustness under practical scenes with unsatisfactory illumination and backgrounds. The code is available at https://github.com/SCUT-BIP-Lab/CMLG-Net.}
}


@article{DBLP:journals/tifs/LinLCXH24,
	author = {Zesheng Lin and
                  Hongbo Li and
                  Xinjian Chen and
                  Meiyan Xiao and
                  Qiong Huang},
	title = {Identity-Based Encryption With Disjunctive, Conjunctive and Range
                  Keyword Search From Lattices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8644--8657},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3459646},
	doi = {10.1109/TIFS.2024.3459646},
	timestamp = {Thu, 03 Oct 2024 00:45:29 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LinLCXH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To reduce data storage costs, more individuals are using cloud servers for reliable, scalable, cost-effective, and globally accessible solutions. However, storing data in plaintext on cloud servers can lead to data leakage risks. Moreover, the advancement of quantum computing poses a threat to traditional encryption algorithms. To counter quantum computing attacks and enable searches over encrypted keywords, lattice-based searchable encryption with conjunctive keyword search has been implemented. Nonetheless, existing schemes expose keyword fields and leaks additional information. To mitigate this, we propose a privacy-preserving method based on lattice hardness assumptions. It enables testing the existence of an encrypted keyword in a set of encrypted keywords without requiring the keyword fields. Additionally, we propose two improved methods: one for inclusion-based searches between two keyword sets, and another for range-based keyword searches. These form the basis for three lattice-based identity-based searchable encryption schemes that support disjunctive, conjunctive, and range keyword searches, respectively. The storage overhead of ciphertexts and trapdoors is unaffected by the number of keywords, making our scheme suitable for multi-keyword search scenarios. Our formal security analysis uses the learning with errors (LWE) assumption and our theoretical analysis and experimental simulations show comparable efficiency and low storage overhead.}
}


@article{DBLP:journals/tifs/KimDZ24,
	author = {Yeongwoo Kim and
                  Gy{\"{o}}rgy D{\'{a}}n and
                  Quanyan Zhu},
	title = {Human-in-the-Loop Cyber Intrusion Detection Using Active Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8658--8672},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3434647},
	doi = {10.1109/TIFS.2024.3434647},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KimDZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Timely detection of cyber attacks is essential for minimizing attack impact, but it requires accurate real-time situational awareness (SA). In practice, SA is hampered by frequent false alerts from anomaly-based intrusion detection systems (IDS), causing alarm fatigue. Investigating alerts by humans can enhance SA, but it is resource-intensive and it is often unclear which alerts to prioritize. In this paper, we propose a framework for optimizing human-in-the-loop attack detection, consisting of three key components: 1) dynamic alert prioritization, which ranks alerts based on previous alerts and investigations, 2) human alert investigation, referring to the manual analysis of alerts, and 3) sequential hypothesis testing, a method that confirms a hypothesis based on incoming alerts, with pruned hidden Markov models (HMMs). We formulate the problem as that of active learning in an HMM, and we propose two alert prioritization policies, namely Max Ratio and Max KL. The proposed policies aim to select the most informative alerts based on historical data and prior investigations, thereby minimizing the detection time. Simulation results show that our proposed policies reduce the time to detection by up to 79% compared to a static baseline policy, while maintaining a target mean time between false detections (MTBFD).}
}


@article{DBLP:journals/tifs/LiHFLSW24,
	author = {Qian Li and
                  Qingyuan Hu and
                  Haoran Fan and
                  Chenhao Lin and
                  Chao Shen and
                  Libing Wu},
	title = {Attention-SA: Exploiting Model-Approximated Data Semantics for Adversarial
                  Attack},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8673--8684},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409945},
	doi = {10.1109/TIFS.2024.3409945},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiHFLSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial Defense of deep neural networks have gained significant attention and there have been active research efforts on model vulnerabilities for attacking such as gradient-based attack and pre-defined semantic manipulation. However, they often lack clear adversarial pattern connecting model extracted notion and are restricted to fixed constraint, making the gradual inability to proposed robust defense. In this paper, we propose to utilize the learned semantics of model, possibly not be the true one for the correct prediction, as inspiring clue in adversarial example construction. And we propose a new attention-based semantic oriented adversarial attack without any prior constraint about semantic preservation, dubbed Attention-SA from the learned task-related decision factors perspective. Specifically, to capture the learned factor, we introduce a post-hoc soft attention with a gradient-sensitivity activation consistency to probe the information of latent representation that bridge the input and prediction. With the attention guidance, we perturb the separated and semantic units, then back-propagate the variation onto input to discover expanded adversarial examples. Finally, extensive performance evaluations on CIFAR-10 and ImageNet datasets demonstrate the superiority of our proposed method. And we verify the effectiveness of our method on various robust defenses.}
}


@article{DBLP:journals/tifs/SangWLG24,
	author = {Chao Sang and
                  Jun Wu and
                  Jianhua Li and
                  Mohsen Guizani},
	title = {From Control Application to Control Logic: {PLC} Decompile Framework
                  for Industrial Control System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8685--8700},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3402117},
	doi = {10.1109/TIFS.2024.3402117},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/SangWLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial Control System (ICS) depends on the underlying Programmable Logical Controllers (PLCs) to run. As such, the security of the internal control logic of the PLCs is the top concern of ICS. Reversing analysis and forensic work against PLC require extracting control logic from the control application running inside PLC, which is still an unresolved problem. To address the challenge, we propose a PLC decompile framework named CLEVER, which can analyze the control application and extract the control logic. First, we propose a simulation execution based code extraction method, which is utilized to filter the control logic related data. Then, to normalize the control application decompile process, an intermediate representation (IR) is designed, which can simplify the analysis process and enhance the extensibility of CLEVER. Finally, a heuristic data flow analysis algorithm is proposed to find variable dependency, and a sequential parsing method is utilized to reconstruct the source code from the control application. To evaluate our work, real world PLC hardware and programming software are used for the experiment. We use 22 real-world, 58 hand-written, and 150 auto-generated control applications to demonstrate the usability, correctness, and operational efficiency of CLEVER.}
}


@article{DBLP:journals/tifs/ZhangWZZH24,
	author = {Zhaoyang Zhang and
                  Shen Wang and
                  Guopu Zhu and
                  Dechen Zhan and
                  Jiwu Huang},
	title = {Adversarial Perturbation Prediction for Real-Time Protection of Speech
                  Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8701--8716},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463538},
	doi = {10.1109/TIFS.2024.3463538},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangWZZH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread collection and analysis of private speech signals have become increasingly prevalent, raising significant privacy concerns. To protect speech signals from unauthorized analysis, adversarial attack methods for deceiving speaker recognition models have been proposed. While a few of these methods are specifically designed for real-time protection of speech signals, they introduce significant delays that can severely impact speech communication when applied to streaming speech data. In this paper, we present a novel approach that aims to offer real-time protection for speech signals without delays. By utilizing observed data only, we generate initial adversarial seed perturbations and refine them to obtain the necessary adversarial perturbations predicted for adjacent unobserved signals. This refinement process is conducted via a proposed model called PAPG. On the basis of perturbation prediction, we develop a streaming audio processing framework that generates perturbations in synchronization with the playback of the original signal, effectively eliminating delays. The experimental results demonstrate that under the proposed attack, the average Top-1 accuracy of various advanced speaker recognition methods is reduced by 89%, and the average equal error rate (EER) increases to 36%. Remarkably, these results are achieved without delays while maintaining superior perceptual quality.}
}


@article{DBLP:journals/tifs/LiuYFLCL24,
	author = {Yipeng Liu and
                  Hangtao Yu and
                  Haonan Fang and
                  Zhanqing Li and
                  Peng Chen and
                  Ronghua Liang},
	title = {A Wavelet-Based Memory Autoencoder for Noncontact Fingerprint Presentation
                  Attack Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8717--8730},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463957},
	doi = {10.1109/TIFS.2024.3463957},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuYFLCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fingerprint presentation attack detection (FPAD) is essential in fingerprint identification systems. Noncontact methods such as fingerprint biometrics are becoming popular because they are not affected by skin conditions and there are no hygiene issues. However, most of the existing noncontact FPAD methods are supervised methods with poor generalizability and poor performance during events such as unseen presentation attacks (PAs). Moreover, easily overlooked frequency domain information contributes to the fingerprint antispoofing task. Therefore, we propose a wavelet-based memory-augmented autoencoder that fully utilizes the frequency domain information. Specifically, the model first decomposes the input image into high- and low-frequency information and extracts features separately. Subsequently, we propose a frequency complementary connection (FCC) module to realize the fusion and complementation of frequency domain information at the feature level. Moreover, a memory distance expansion loss is proposed to keep the memory module diverse. Experiments are conducted to verify the effectiveness of the method. The code of our model is available on https://github.com/SuperIOyht/WaveMemAE.}
}


@article{DBLP:journals/tifs/ZhangJMMHYZSFXD24,
	author = {Lei Zhang and
                  Yunzhe Jiang and
                  Yazhou Ma and
                  Shiwen Mao and
                  Wenyuan Huang and
                  Zhiyong Yu and
                  Xiao Zheng and
                  Lin Shu and
                  Xiaochen Fan and
                  Guangquan Xu and
                  Changyu Dong},
	title = {Toward Robust and Effective Behavior Based User Authentication With
                  Off-the-Shelf Wi-Fi},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8731--8746},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3428367},
	doi = {10.1109/TIFS.2024.3428367},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangJMMHYZSFXD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Behavior-based Wi-Fi user authentication has gained popularity in user-centered smart systems. However, its wide adoption has been hindered by certain critical issues, including significant performance degradation when the environment changes, the inability to handle unknown activities, and weak security due to basing authentication on the recognition of a single, one-off activity. In this paper, we propose Wi-Dist, which authenticates a user using a behavior password, i.e. a pre-chosen sequence of activities. Wi-Dist addressed the previously mentioned technical challenges through a cross-layer joint optimization framework. In particular, we address environment dependency by incorporating adversarial learning and optimizing both the signal layer and the domain adaptation layer. This enhances the performance of the learned model across various environments. To effectively handle unknown behaviors, we utilize an adversarial learning-based network. This network establishes a pseudo-decision boundary between samples from known and unknown sources, ensuring robust authentication. Additionally, for authentication using continuous activities, we employ double-sliding windows activity monitoring. This approach, coupled with activity state correction, partitions activities for accurate recognition. We also conducted extensive experiments in indoor environments to demonstrate that Wi-Dist is effective and robust.}
}


@article{DBLP:journals/tifs/WuZXDLL24,
	author = {Minzhe Wu and
                  Bowen Zhao and
                  Yang Xiao and
                  Congjian Deng and
                  Yuan Liu and
                  Ximeng Liu},
	title = {{MODEL:} {A} Model Poisoning Defense Framework for Federated Learning
                  via Truth Discovery},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8747--8759},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3461449},
	doi = {10.1109/TIFS.2024.3461449},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WuZXDLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is an emerging paradigm for privacy-preserving machine learning, in which multiple clients collaborate to generate a global model through training individual models with local data. However, FL is vulnerable to model poisoning attacks (MPAs) as malicious clients are able to destroy the global model by modifying local models. Although numerous model poisoning defense methods are extensively studied, they remain vulnerable to newly proposed optimized MPAs and are constrained by the necessity to presume a certain proportion of malicious clients. To this end, in this paper, we propose MODEL, a model poisoning defense framework for FL through truth discovery (TD). A distinctive aspect of MODEL is its ability to effectively prevent both optimized and byzantine MPAs. Furthermore, it requires no presupposed threshold for different settings of malicious clients (e.g., less than 33% or no more than 50%). Specifically, a TD-based metric and a clustering-based filtering mechanism are proposed to evaluate local models and avoid presupposing a threshold. Furthermore, MODEL is effective for non-independent and identically distributed (non-IID) training data. In addition, inspired by game theory, we incorporate a truthful and fair incentive mechanism in MODEL to encourage active client participation while mitigating the potential desire for attacks from malicious clients. Extensively comparative experiments demonstrate that MODEL effectively safeguards against optimized MPAs and outperforms the state-of-the-art.}
}


@article{DBLP:journals/tifs/HeLXS24,
	author = {Shiming He and
                  GenXin Li and
                  Kun Xie and
                  Pradip Kumar Sharma},
	title = {Fusion Graph Structure Learning-Based Multivariate Time Series Anomaly
                  Detection With Structured Prior Knowledge},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8760--8772},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3459631},
	doi = {10.1109/TIFS.2024.3459631},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HeLXS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time series anomaly detection (MTSAD) plays a crucial role in the Internet of Things (IoT) to identify device malfunction or system attacks. Graph neural networks (GNN) are widely applied in MTSAD to capture the spatial features among sensors. However, GNNs depend on a graph structure and explicit graph structures are not always available. To solve the problem of missing explicit graph structure, graph structure learning is introduced to learn an accurate graph structure joint with a GNNs-based anomaly detection task. However, the existing GSL-based methods provide only a partial view of the graph structure and cannot represent multiple and complex relationships. The noise of data also brings noisy edges. Therefore, we propose a fusion graph structure learning-based multivariate time-series anomaly detection with structured prior knowledge (FuGLAD). To the best of our knowledge, it appears to be the first application of fusion graphs in time series anomaly detection. FuGLAD selects three kinds of typical graph structure learners to learn as many relationship types among sensors as possible and exploits the prior similarity to evaluate the importance of all learned graphs and adaptively learn the fusion weight instead of the direct average weight. To handle noise in raw data, FuGLAD compares the neighbors of nodes by Jaccard similarity to identify and remove the noisy edges in the prior graph. Extensive experiments demonstrate that our approach outperforms state-of-the-art single-graph structure learning techniques in detection performance across four public and real-world datasets.}
}


@article{DBLP:journals/tifs/YangXXZQWHH24,
	author = {Haoxin Yang and
                  Xuemiao Xu and
                  Cheng Xu and
                  Huaidong Zhang and
                  Jing Qin and
                  Yi Wang and
                  Pheng{-}Ann Heng and
                  Shengfeng He},
	title = {G{\({^2}\)}Face: High-Fidelity Reversible Face Anonymization via Generative
                  and Geometric Priors},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8773--8785},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3449104},
	doi = {10.1109/TIFS.2024.3449104},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangXXZQWHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reversible face anonymization, unlike traditional face pixelization, seeks to replace sensitive identity information in facial images with synthesized alternatives, preserving privacy without sacrificing image clarity. Traditional methods, such as encoder-decoder networks, often result in significant loss of facial details due to their limited learning capacity. Additionally, relying on latent manipulation in pre-trained GANs can lead to changes in ID-irrelevant attributes, adversely affecting data utility due to GAN inversion inaccuracies. This paper introduces G2Face, which leverages both generative and geometric priors to enhance identity manipulation, achieving high-quality reversible face anonymization without compromising data utility. We utilize a 3D face model to extract geometric information from the input face, integrating it with a pre-trained GAN-based decoder. This synergy of generative and geometric priors allows the decoder to produce realistic anonymized faces with consistent geometry. Moreover, multi-scale facial features are extracted from the original face and combined with the decoder using our novel identity-aware feature fusion blocks (IFF). This integration enables precise blending of the generated facial patterns with the original ID-irrelevant features, resulting in accurate identity manipulation. Extensive experiments demonstrate that our method outperforms existing state-of-the-art techniques in face anonymization and recovery, while preserving high data utility. Code is available at https://github.com/Harxis/G2Face.}
}


@article{DBLP:journals/tifs/ChenYJLN24,
	author = {Zheyu Chen and
                  Zhiqiang Yao and
                  Biao Jin and
                  Mingwei Lin and
                  Jianting Ning},
	title = {FIBNet: Privacy-Enhancing Approach for Face Biometrics Based on the
                  Information Bottleneck Principle},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8786--8801},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3424303},
	doi = {10.1109/TIFS.2024.3424303},
	timestamp = {Wed, 12 Feb 2025 16:03:51 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenYJLN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Neural Networks (DNNs) have been extensively employed for automatic face recognition, enabling the extraction of compact and discriminative representations from facial images. However, these representations typically encode a multitude of information ranging from individual identities to sensitive soft-biometric attributes such as gender, race, or age. This raises concerns regarding the privacy disclosure of soft-biometric as these attributes should be protected. To address this issue, we propose a novel Face Information Bottleneck Network (FIBNet), which is a representation-level privacy-enhancing framework based on the Information Bottleneck (IB) principle. The proposed FIBNet differs significantly from previous representation-level privacy-enhancing techniques in three key aspects. First, it generates a privacy-enhanced face representation, providing novel insights through an information-theoretic privacy framework. Second, we formulate the privacy protection of soft-biometric attributes as an IB optimization problem by striking a tradeoff between preserving a controlled amount of identity information within face representations and suppressing soft-biometric attribute information. Last, the proposed approach protects soft-biometric privacy from adversaries interested in specific sensitive attributes that are unknown to the biometric system designers or users. Detailed experimental results obtained on widely recognized facial recognition datasets demonstrate that the proposed FIBNet significantly outperforms the state-of-the-art methods in terms of both biometric performance for face verification and its soft-biometric attribute suppression efficiency. These notable results verify FIBNet as a novel and effective approach for ensuring representation-level soft-biometric privacy.}
}


@article{DBLP:journals/tifs/ZhengXWXWCJ24,
	author = {Yubo Zheng and
                  Peng Xu and
                  Miao Wang and
                  Wanying Xu and
                  Wei Wang and
                  Tianyang Chen and
                  Hai Jin},
	title = {Themis: Robust and Light-Client Dynamic Searchable Symmetric Encryption},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8802--8816},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463971},
	doi = {10.1109/TIFS.2024.3463971},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhengXWXWCJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic searchable symmetric encryption (DSSE), as one of the promising cryptographic tools in cloud-based services, faces two crying needs at the age of multi-device. One is a lightweight client, and the other is robustness. A lightweight client facilitates seamless synchronization among multiple devices allowing users to feel as if they are operating on a single device, even on resource-constrained devices. Robustness ensures a reliable system that can tolerate misoperations. DSSE requires both of them to achieve a leap in practicability. However, to our best knowledge, lightweight client and robustness have not been effectively combined thus far. Most existing DSSE schemes maintain a substantial amount of state information on the client for sub-linear search efficiency, but they fail to guarantee security even correctness, after executing the client’s misoperations (e.g., duplicate addition or deletion operation and deleting non-existent targets). The seminal work on robustness, ROSE (TIFS’22), leverages a heavy primitive to preserve security and correctness during post-processing and requires a heavy client storage burden. To guarantee robustness and constant client storage simultaneously, we devise a novel method to preserve robustness timely in the process of misoperations. Specifically, we introduce an alarm mechanism to promptly eliminate the effects of misoperations. Based on the misoperation alarm mechanism and the vORAM+HIRB oblivious map (S&P’16), we propose a new DSSE scheme Themis. In addition to satisfying robustness and constant client storage, it has competitive search and update performance compared to prior representative DSSE schemes. Moreover, it is superior to existing robust schemes in search.}
}


@article{DBLP:journals/tifs/LiSWQZ24,
	author = {Fengyong Li and
                  Yang Sheng and
                  Kui Wu and
                  Chuan Qin and
                  Xinpeng Zhang},
	title = {LiDiNet: {A} Lightweight Deep Invertible Network for Image-in-Image
                  Steganography},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8817--8831},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463547},
	doi = {10.1109/TIFS.2024.3463547},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiSWQZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces a novel, lightweight deep invertible steganography network (LiDiNet) for image-in-image steganography. Traditional methods, while hiding a secret image within a cover image, often suffer from contour shadows or color distortion, making the secret image easily detectable. Additionally, the superposition of multiple invertible networks may complicate network structures and introduce excessive parameters, making the network training and learning processes difficult. LiDiNet addresses these issues by employing multiple invertible neural networks (INNs) to create a pair of coupled invertible processes for image hiding and recovery. A key innovation is the invertible convolutional layer, which streamlines the affine coupling structure in each INN for improved information fusion. In addition, a series of adaptive coordination spatial-wise attention modules are integrated to enhance the network’s effectiveness in image hiding and recovery, thereby elevating the security of the steganography. LiDiNet’s lightweight structure ensures both high-capacity steganography and robustness against steganalysis. Extensive experiments across various image datasets demonstrate LiDiNet’s superior performance, particularly in visual quality and anti-steganalysis capability, compared to existing methods.}
}


@article{DBLP:journals/tifs/LinYWDZLS24,
	author = {Chenhao Lin and
                  Fangbin Yi and
                  Hang Wang and
                  Jingyi Deng and
                  Zhengyu Zhao and
                  Qian Li and
                  Chao Shen},
	title = {Exploiting Facial Relationships and Feature Aggregation for Multi-Face
                  Forgery Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8832--8844},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3461469},
	doi = {10.1109/TIFS.2024.3461469},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LinYWDZLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of advanced Deepfake technologies has gradually raised concerns in society, prompting significant attention to Deepfake detection. However, in real-world scenarios, Deepfakes often involve multiple faces. Despite this, most existing detection methods still detect these faces individually, overlooking the informative correlation between them and the relationship between the global information of the image and the local information of the faces. In this paper, we address this limitation by proposing FILTER, a novel framework for multi-face forgery detection that explicitly captures underlying correlations. FILTER consists of two main modules: Multi-face Relationship Learning (MRL) and Global Feature Aggregation (GFA). Specifically, MRL learns the correlation of local facial features in multi-face images, and GFA constructs the relationship between image-level labels and individual facial features to enhance performance from a global perspective. In particular, a contrastive learning loss function is used to better discriminate between real and fake faces. Extensive experiments on two publicly available multi-face forgery datasets demonstrate the state-of-the-art performance of FILTER in multi-face forgery detection. For example, on Openforensics Test-Challenge dataset, FILTER outperforms the previous state-of-the-art methods with a higher AUC score (0.980) and higher detection accuracy (92.04%).}
}


@article{DBLP:journals/tifs/CaoZZSH24,
	author = {Yihao Cao and
                  Jianbiao Zhang and
                  Yaru Zhao and
                  Hong Shen and
                  Haoxiang Huang},
	title = {Privacy-Preserving Federated Learning With Improved Personalization
                  and Poison Rectification of Client Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8845--8859},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463532},
	doi = {10.1109/TIFS.2024.3463532},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/CaoZZSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL), a secure and emerging distributed learning paradigm, has garnered significant interest in the Internet of Things (IoT) domain. However, it remains vulnerable to adversaries who may compromise privacy and integrity. Previous studies on privacy-preserving FL (PPFL) have demonstrated limitations in client model personalization and resistance to poisoning attacks, including Byzantine and backdoor attacks. In response, we propose a novel PPFL framework, FedRectify, that employs a personalized dual-layer approach through the deployment of Trusted Execution Environments and an interactive training strategy. This strategy facilitates the learning of personalized client features via private and shared layers. Furthermore, to improve model’s robustness to poisoning attacks, we introduce a novel aggregation method that employs clustering to filter out outlier model parameters and robust regression to assess the confidence of cluster members, thereby rectifying poisoned parameters. We theoretically prove the convergence of FedRectify and empirically validate its performance through extensive experiments. The results demonstrate that FedRectify converges 1.47-2.63 times faster than state-of-the-art methods when countering Byzantine attacks. Moreover, it can rapidly reduce the attack success rate to a low level between 10% and 40% in subsequent rounds when confronting bursty backdoor attacks.}
}


@article{DBLP:journals/tifs/JiaHWFWF24,
	author = {Zexi Jia and
                  Chuanwei Huang and
                  Zheng Wang and
                  Hongyan Fei and
                  Song Wu and
                  Jufu Feng},
	title = {Finger Recovery Transformer: Toward Better Incomplete Fingerprint
                  Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8860--8874},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3419690},
	doi = {10.1109/TIFS.2024.3419690},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiaHWFWF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fingerprint recognition is a crucial biometric technology extensively used in identity verification, including areas like criminal investigations, security systems, and biometric authentication. This technology encounters greater challenges when dealing with incomplete fingerprint images, especially those with significant background noise or substantial portions of the fingerprint missing. Existing incomplete fingerprint recognition technologies struggle with extensive data loss, primarily due to the significant reduction and difficulty in extracting usable features from incomplete fingerprint images. Current image processing methods or deep learning models are unable to comprehensively reconstruct fingerprint features with limited information. To address these challenges, we introduce the Finger Recovery Transformer (FingerRT), an innovative network specifically designed for recovering incomplete fingerprint information. FingerRT can simultaneously complete ambient noise cancellation and fingerprint feature information recovery, resulting in a complete and clean fingerprint image. FingerRT combines the most critical feature information in fingerprints, directional field, and minutiae, as supervision information. FingerRT inherits the denoising ability of the fingerprint enhancement networks and the powerful generative ability of the Vision Transformer architecture, enabling high-quality and robust fingerprint information recovery. By imposing constraints at multiple levels, including fingerprint features, fingerprint images, and multi-stage generation, FingerRT can complete fingerprint information accurately and effectively. Experiments demonstrate that FingerRT significantly enhances fingerprint recognition accuracy after recovery across various fingerprint datasets, including rolled, snapped, and latent fingerprints.}
}


@article{DBLP:journals/tifs/ChenXGGYX24,
	author = {Xue Chen and
                  Shiyuan Xu and
                  Shang Gao and
                  Yu Guo and
                  Siu{-}Ming Yiu and
                  Bin Xiao},
	title = {{FS-LLRS:} Lattice-Based Linkable Ring Signature With Forward Security
                  for Cloud-Assisted Electronic Medical Records},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8875--8891},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3455772},
	doi = {10.1109/TIFS.2024.3455772},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChenXGGYX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ring signatures have been extensively researched for Cloud-assisted Electronic Medical Records (EMRs) sharing, aiming to address the challenge of “medical information silos” while safeguarding the privacy of patients’ personal information and the security of EMRs. However, most existing EMRs sharing systems that utilize ring signatures are vulnerable to quantum attacks, posing a severe challenge for the e-health scenario. To alleviate this issue, some studies have been conducted on lattice-based ring signatures. Nevertheless, there still exist two challenges. Firstly, current schemes fail to verify if multiple EMRs come from the same signer, undermining e-health reliability. Additionally, adversaries can exploit weaknesses in the network security of signers’ secret keys to forge signatures. In this paper, we propose an efficient lattice-based linkable ring signature (LLRS) for EMRs sharing to ensure patient privacy through anonymity, EMRs security through unforgeability, and checking the linkability for multiple signatures. We then present an enhancement scheme, called FS-LLRS, to additionally offer forward security, ensuring the security of previous ring signatures even if the current key has been compromised. To achieve this, we introduce a binary tree structure to divide time periods and leverage lattice basis algorithms for one-way secret key evolution, allowing users to update the secret keys periodically. Ultimately, we conduct a rigorous security analysis and compare our primitives with prior arts. In computational cost, the best performance of our LLRS and FS-LLRS schemes are just 0.17 and 0.34 times compared to others, respectively. Our LLRS scheme only incurs 0.08 times the communication overhead of others.}
}


@article{DBLP:journals/tifs/LiMZZZ24,
	author = {Jiachun Li and
                  Yan Meng and
                  Yuxia Zhan and
                  Le Zhang and
                  Haojin Zhu},
	title = {Dangers Behind Charging {VR} Devices: Hidden Side Channel Attacks
                  via Charging Cables},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8892--8907},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3465026},
	doi = {10.1109/TIFS.2024.3465026},
	timestamp = {Tue, 08 Oct 2024 15:19:33 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiMZZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual reality (VR), offering 3D visuals and stereophonic sounds, significantly enhances users’ immersive experiences and has become a milestone in the era of the metaverse. However, due to the limited battery capacity of VR devices, it is common for users to rely on charging cables, which serve the dual purpose of power supply and audio output, to recharge their VR devices while in use. In this study, we propose an inconspicuous and stealthy side channel attack, coined as LineTalker, which can unveil visual-related and audio-related activities from VR devices during the charging process. The insight behind LineTalker is rooted in the observation that visual-related activities (e.g., 3D image rendering) are power-intensive and result in fluctuations in the current strength of the cable’s power supply line, which can be leveraged as side channel information. Similarly, audio-related activities (e.g., playing music) leave traces on the cable’s audio output line. Rather than providing a user with a compromised charging cable (i.e., embedding a current sensor) to measure the current strength, to make the attack less conspicuous, LineTalker employs the Hall effect to indirectly access side channel information. This is achieved by capturing magnetic signals using a Hall sensor placed near the target cable in a contactless manner. Experimental results demonstrate that LineTalker achieves an overall accuracy of 94.60% and 64.38% in inferring user activities in VR devices with intrusive and non-intrusive attack manners, respectively.}
}


@article{DBLP:journals/tifs/TharaniHCRPM24,
	author = {Jeyakumar Samantha Tharani and
                  Zh{\'{e}} H{\'{o}}u and
                  Eugene Yugarajah Andrew Charles and
                  Punit Rathore and
                  Marimuthu Palaniswami and
                  Vallipuram Muthukkumarasamy},
	title = {Unified Feature Engineering for Detection of Malicious Entities in
                  Blockchain Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8924--8938},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3412421},
	doi = {10.1109/TIFS.2024.3412421},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TharaniHCRPM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain technology has been integrated into a wide range of applications in various sectors, such as finance, supply chain, health, and governance. However, the participation of a few actors with malicious intentions challenges law enforcement authorities, regulators and other users. These challenges revolve around dealing with an array of illegal activities such as asset trades in dark markets, receiving payments for cyber-attacks, and facilitating money laundering. Developing an efficient mechanism to identify malicious actors in blockchain networks is a pressing need to build confidence among the stakeholders and ensure regulatory adherence. The raw data of blockchain transactions do not readily reveal the dynamic behavioural changes and their interconnection between transactions and accounts. These behavioural patterns can be useful for identifying malicious actors. Machine Learning (ML)-based models for early warning and/or detection are considered one of the potential approaches. In ML, feature engineering plays a crucial role in enhancing the predictive performance of a model. This study proposes different categories of features and unified feature extraction approaches for raw Bitcoin and Ethereum transaction data and their interconnection information. As far as we are aware, there has been no study that considered a feature engineering approach for identifying malicious activities. The significance of the engineered features was validated against eight classifiers, including Random Forest (RF), XG-boost (XG), Silas, and neural network-based classifiers. The results showed that these features contribute to higher classification accuracy and higher Area Under the Receiver Operating Characteristic Curve (AUC) value for both Bitcoin and Ethereum transactions. This work also analysed the influence of engineered features in classification using the eXplainable Artificial Intelligence (XAI) technique SHapley Additive exPlanations (SHAP) values. The feature importance scores confirmed the significance of the proposed engineered features towards implementing classification models to identify, target and disrupt malicious activities in blockchain networks.}
}


@article{DBLP:journals/tifs/WengLLLZ24,
	author = {Juanjuan Weng and
                  Zhiming Luo and
                  Shaozi Li and
                  Dazhen Lin and
                  Zhun Zhong},
	title = {Boosting Adversarial Transferability via Logits Mixup With Dominant
                  Decomposed Feature},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8939--8951},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3465212},
	doi = {10.1109/TIFS.2024.3465212},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WengLLLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research has shown that adversarial samples are highly transferable and can be used to attack other unknown black-box Deep Neural Networks (DNNs). To improve the transferability of adversarial samples, several feature-based adversarial attack methods have been proposed to disrupt neuron activation in the middle layers. However, current state-of-the-art feature-based attack methods typically require additional computation costs for estimating the importance of neurons. To address this challenge, we propose a Singular Value Decomposition (SVD)-based feature-level attack method. Our approach is inspired by the discovery that eigenvectors associated with the larger singular values decomposed from the middle layer features exhibit superior generalization and attention properties. Specifically, we conduct the attack by retaining the dominant decomposed feature that corresponds to the largest singular value (i.e., Rank-1 decomposed feature) for computing the output logits before the final softmax. These logits are later integrated with the original logits to optimize adversarial examples. Our extensive experimental results verify the effectiveness of our proposed method, which can be easily integrated into various baselines to significantly enhance the transferability of adversarial samples for disturbing normally trained CNNs and advanced defense strategies. The source code is available at Link.}
}


@article{DBLP:journals/tifs/DongFQDXL24,
	author = {Jiankuo Dong and
                  Yusheng Fu and
                  Xusheng Qin and
                  Zhenjiang Dong and
                  Fu Xiao and
                  Jingqiang Lin},
	title = {{ECO-BIKE:} Bridging the Gap Between {PQC} {BIKE} and {GPU} Acceleration},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8952--8965},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3443617},
	doi = {10.1109/TIFS.2024.3443617},
	timestamp = {Tue, 04 Feb 2025 20:31:50 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DongFQDXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advancements in quantum computing pose a threat to public-key cryptosystems, leading to the development of post-quantum cryptography. NIST is standardizing candidate algorithms, with BIKE, a code-based key encapsulation mechanism, among those under consideration. Performance is crucial in NIST PQC standardization process, and researchers have introduced a range of optimization techniques for BIKE across various platforms. To the best of our knowledge, our Efficient CryptOgraphy BIKE (ECO-BIKE) represents the first attempt at optimizing the implementation of BIKE on GPU architecture. In this paper, we introduce a comprehensive construction of a 3-threading parallel architecture tailored for the BIKE cryptosystem. This architecture covers a range of computational tasks, addressing operations from low-level to high-level computations. These include a parallel dense polynomial multiplication scheme with a better memory access pattern and a better XOR calculation, which forms the basis for a comprehensive parallel execution framework for the entire BIKE algorithm. Targeted optimizations are implemented for specific modules (KEYGEN, ENCAPS, DECAPS), which collectively enhance the overall efficiency of the algorithm. Our ECO-BIKE exhibits exceptional throughput performance on the NVIDIA GeForce RTX 4090. In the 3-thread mode, the throughput of the KEYGEN, ENCAPS, and DECAPS modules reaches 24.033 kops/s, 277.789 kops/s, and 5.817 kops/s, respectively. Our proposed optimal parallel multiplication scheme achieves a significantly higher overall throughput of 481.302 kops/s. These results highlight the substantial computational advantages our approach provides for cryptographic workloads.}
}


@article{DBLP:journals/tifs/LiWLSZCSL24,
	author = {Qianyu Li and
                  Ruipeng Wang and
                  Dong Li and
                  Fan Shi and
                  Min Zhang and
                  Anupam Chattopadhyay and
                  Yi Shen and
                  Yang Li},
	title = {DynPen: Automated Penetration Testing in Dynamic Network Scenarios
                  Using Deep Reinforcement Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8966--8981},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3461950},
	doi = {10.1109/TIFS.2024.3461950},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiWLSZCSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Penetration testing, a crucial industrial practice for securing networked systems and infrastructures, has traditionally depended on the extensive expertise of human professionals. Addressing the scarcity of human experts, the development of automated penetration testing tools emerges as a promising avenue. Against the backdrop of rapid advancements in artificial intelligence technologies, reinforcement learning has demonstrated considerable potential for realizing automated penetration testing. However, existing research predominantly concentrates on reinforcement learning-based automated penetration testing tools within static scenarios, with limited exploration in dynamic network environments. This paper addresses a noteworthy challenge in developing autonomous agents for real-world applications, particularly focusing on scenarios marked by environmental changes. Such alterations necessitate autonomous agents to continuously monitor environmental characteristics, and adapt, and adjust learned actions to ensure the system’s effective operation. Consequently, the paper proposes an automated reinforcement learning-based penetration testing scheme tailored for dynamic network scenarios, named DynPen. DynPen captures observed changes in the scenario, aiding the penetration testing agent in decision-making based on historical experiences. Simulation results demonstrate the proposed scheme’s efficacy in significantly expediting the convergence speed of the penetration testing agent using reinforcement learning algorithms. Furthermore, the scheme successfully maintains the learning agility and adaptability of the agent in dynamic network scenarios.}
}


@article{DBLP:journals/tifs/DaiLDZL24,
	author = {Wanying Dai and
                  Beibei Li and
                  Qingyun Du and
                  Ziqing Zhu and
                  Ao Liu},
	title = {Chaos-Based Index-of-Min Hashing Scheme for Cancellable Biometrics
                  Security},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8982--8997},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3455109},
	doi = {10.1109/TIFS.2024.3455109},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/DaiLDZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cancellable biometrics is essential for preserving sensitive biometric information from potential exposure. Existing studies usually convert real-valued biometric vectors into protected templates by randomly generated transformation keys. However, this way is realized by the built-in functions of the cancellable biometric system, which creates vulnerabilities for cancellable biometric schemes. In this paper, we propose a novel chaos-based Index-of-Min cancellable biometric scheme, named C-IoM, for privacy-preserving template updates in biometric technique. Specifically, we first design a chaos-based cancellable biometric framework to ensure the security and privacy of the biometric template. Second, we develop a secure random chaos seed generation algorithm, which non-linearly converts the biometric vectors into protected templates and conceals biometric dimensional information. Further, we craft a sliding window selection mechanism to choose the input biometric features, allowing each feature data to fully participate in the generation of protected templates through sliding intervals. Theoretical analysis confirms that the C-IoM satisfies the criteria of irreversibility, revocability, unlinkability, and performance preservation in cancellable biometrics. Extensive experiments on LFW, CFPW, and CASIA-V5 datasets demonstrate the security of the proposed framework in protecting biometric data as well as the superiorities over state-of-the-art schemes.}
}


@article{DBLP:journals/tifs/QiaoZSHHRL24,
	author = {Tong Qiao and
                  Bin Zhao and
                  Ran Shi and
                  Meng Han and
                  Mahmoud Hassaballah and
                  Florent Retraint and
                  Xiangyang Luo},
	title = {Scalable Universal Adversarial Watermark Defending Against Facial
                  Forgery},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8998--9011},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3460387},
	doi = {10.1109/TIFS.2024.3460387},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/QiaoZSHHRL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The illegal use of facial forgery models, such as Generative Adversarial Networks (GAN) synthesized contents, has been on the rise, thereby posing great threats to personal reputation and national security. To mitigate these threats, recent studies have proposed the use of adversarial watermarks as countermeasures against GAN, effectively disrupting their outputs. However, the majority of these adversarial watermarks exhibit very limited defense ranges, providing defense against only a single GAN forgery model. Although some universal adversarial watermarks have demonstrated impressive results, they lack the defense scalability as a new-emerging forgery model appears. To address the tough issue, we propose a scalable approach even when the original forgery models are unknown. Specifically, a watermark expansion scheme, which mainly involves inheriting, defense and constraint steps, is introduced. On the one hand, the proposed method can effectively inherit the defense range of the prior well-trained adversarial watermark; on the other hand, it can defend against a new forgery model. Extensive experimental results validate the efficacy of the proposed method, exhibiting superior performance and reduced computational time compared to the state-of-the-arts.}
}


@article{DBLP:journals/tifs/LvFMZWL24,
	author = {Yongyang Lv and
                  Ruitao Feng and
                  Maode Ma and
                  Manqing Zhu and
                  Hanwei Wu and
                  Xiaohong Li},
	title = {Reinventing Multi-User Authentication Security From Cross-Chain Perspective},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {8908--8923},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463533},
	doi = {10.1109/TIFS.2024.3463533},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LvFMZWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain systems encompass many distinct and autonomous entities, each utilizing its own self-contained identity authentication algorithm. Unlike identity authentication within a singular blockchain, cross-chain scenarios demand special attention due to their pivotal role in enabling the acknowledgment of users’ identities across diverse domains. This capability is the foundational prerequisite for the circulation of resources across different chains. Consequently, the central challenge for cross-chain systems lies in establishing mutual recognition and trust in users’ digital identities. This paper proposes a Multi-User Proxy Re-Signature (MU-PRS) algorithm, facilitating the cross-chain conversion of signatures from multiple users. Concurrently, This paper propose the Multi-Notary Signature Conversion (MN-SC) mechanism, designed to address the challenge posed by disparate system mechanisms across blockchains during cross-chain authentication. Leveraging the MU-PRS algorithm and MN-SC mechanism, we present a Multi-User Cross-Chain Authentication Scheme (MU-CCAS) within a heterogeneous blockchain environment. This scheme enables the verification of identities of multiple cross-chain users through a single signature verification. This innovative approach not only addresses the centralization issues inherent in third-party cross-chain authentication but also significantly enhances the efficiency of identity authentication. The evaluation results demonstrate MU-CCAS’s superior security over existing solutions in three dimensions: BAN logic, Scyther verification, and security attribute analysis. Additionally, it establishes that MU-PRS and MU-CCAS have low computational overhead, easy implementation, and excel in algorithm, scheme, and cross-chain performance. Overall, our work provides a robust and efficient framework for cross-chain authentication, addressing centralization challenges and enhancing digital security.}
}


@article{DBLP:journals/tifs/AblaLHHYZ24,
	author = {Parhat Abla and
                  Taotao Li and
                  Debiao He and
                  Huawei Huang and
                  Songsen Yu and
                  Yan Zhang},
	title = {Fair and Privacy-Preserved Data Trading Protocol by Exploiting Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9012--9025},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3398535},
	doi = {10.1109/TIFS.2024.3398535},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/AblaLHHYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularity of the mobile Internet, data is increasingly becoming a new resource. Therefore, the trading of such data resources has become an increasing demand. In this paper, we propose a fair privacy-preserving data trading protocol based on blockchain. Firstly, our data trading protocol achieves fairness by carefully combining the probabilistic approaches and the fully homomorphic encryption techniques. Moreover, our protocol allows online arbitration when misbehavior occurs in the trading process is detected. Note that previous data trading protocols need a Trusted Third Party (TTP) or an offline arbitrator to solve disputes, weakening the trust of those protocols. Secondly, the data validity verification process of our protocol is more flexible. Most Importantly, different from all previous designs which only achieve privacy against communication channel eavesdroppers, our protocol achieves privacy against any eavesdropper and the passive arbitrator. The above-distinguishing properties of our protocol are mainly benefited from the homomorphic encryption and double encryption techniques. In addition, our data trading protocol can be instantiated with post-quantum primitives and thus achieves post-quantum security. To demonstrate the feasibility of the proposed protocol, we conduct a comprehensive evaluation with the instantiated cryptographic primitives based on the Ethereum test network.}
}


@article{DBLP:journals/tifs/PanPLH24,
	author = {Honghu Pan and
                  Wenjie Pei and
                  Xin Li and
                  Zhenyu He},
	title = {Unified Conditional Image Generation for Visible-Infrared Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9026--9038},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3426335},
	doi = {10.1109/TIFS.2024.3426335},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/PanPLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a unified multi-modal image generation method to address two critical challenges in visible-infrared (VI) person re-identification (ReID): the insufficiency of training samples and the large cross-modality discrepancy. To be specific, we propose to generate cross-modal and middle-modal images to explicitly reduce the modality discrepancy, and generate intra-modal images to serve as training samples for datasets augmentation. To this end, we adapt the conditional diffusion model for multi-modal image generation. The condition includes a binary modality indicator and modal-irrelative pedestrian contour to control the target modality and pedestrian identity, respectively. For the intra-modality and cross-modality image generation, we modify the structure of UNet to take as input the conditions, and estimate the conditional probability density by optimizing its variational lower bound. Furthermore, we devise modal discriminators and adversarial training strategies to achieve modality alignment. The middle-modality image generation method shares the same network architecture with intra- and cross-modality generation, but has specific training objectives. We define the middle modality as the distribution equidistant from the visible modality and infrared modality. We employ the adversarial training to measure the distance from the visible or infrared modality to the middle modality, and thus minimize the difference between these two adversarial losses, serving as an equidistant constraint. Experimental results on SYSU-MM01 and RegDB demonstrate the effectiveness and generalization of the intra-modality, cross-modality, and middle-modality image generation.}
}


@article{DBLP:journals/tifs/TanLZLP24,
	author = {Wenyi Tan and
                  Yang Li and
                  Chenxing Zhao and
                  Zhunga Liu and
                  Quan Pan},
	title = {DOEPatch: Dynamically Optimized Ensemble Model for Adversarial Patches
                  Generation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9039--9054},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468908},
	doi = {10.1109/TIFS.2024.3468908},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TanLZLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Object detection is a fundamental task in various applications ranging from autonomous driving to intelligent security systems. However, recognition of a person can be hindered when their clothing is decorated with carefully designed graffiti patterns, leading to the failure of object detection. To achieve greater attack potential against unknown black-box models, adversarial patches capable of affecting the outputs of multiple-object detection models are required. While ensemble models have proven effective, current research in the field of object detection typically focuses on the simple fusion of the outputs of all models, with limited attention being given to developing general adversarial patches that can function effectively in the physical world. In this paper, we introduce the concept of energy and treat the adversarial patches generation process as an optimization of the adversarial patches to minimize the total energy of the “person” category. Additionally, by adopting adversarial training, we construct a dynamically optimized ensemble model. During training, the weight parameters of the attacked target models are adjusted to find the balance point at which the generated adversarial patches can effectively attack all target models. We carried out six sets of comparative experiments and tested our algorithm on five mainstream object detection models. The adversarial patches generated by our algorithm can reduce the recognition accuracy of YOLOv2 and YOLOv3 to 13.19% and 29.20%, respectively. In addition, we conducted experiments to test the effectiveness of T-shirts covered with our adversarial patches in the physical world and could achieve that people are not recognized by the object detection model. Finally, leveraging the Grad-CAM tool, we explored the attack mechanism of adversarial patches from an energetic perspective.}
}


@article{DBLP:journals/tifs/XieCLM24,
	author = {Mingyue Xie and
                  Zheng Chang and
                  Hongwei Li and
                  Geyong Min},
	title = {{BASUV:} {A} Blockchain-Enabled {UAV} Authentication Scheme for Internet
                  of Vehicles},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9055--9069},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3465847},
	doi = {10.1109/TIFS.2024.3465847},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/XieCLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned aerial vehicles (UAVs) have emerged as pivotal roles within internet of vehicles (IoV), serving as mobile base stations. However, while expanding coverage and improving mobility, the deployment of UAVs also poses a threat to the integrity and privacy of sensitive data due to open wireless communication channels in IoV. Therefore, preventing unauthorized access and data tampering is critically important between UAVs and vehicles. For the authenticity and legitimacy of the UAV certificate, existing authentication approaches may lead to significant challenges in key management overhead or dependence on a trusted third party. In this paper, a blockchain-based authentication scheme for UAV-assisted IoV system (BASUV) is proposed. This solution enables dependable UAV registration and authentication services, and permits the dynamic addition and removal. Specifically, blockchain is introduced to achieve the decentralized management and distributed trust of the UAV certificate ledger. Furthermore, to prevent information tampering and identity deception, we design CMPES, a novel combined scheme based on multiple public key generators (PKGs) for encryption and signature. Identical key pair in encryption and signature can reduce key generation and management overhead. The security and experimental analysis demonstrates the effectiveness and efficiency of the proposed scheme.}
}


@article{DBLP:journals/tifs/ChengTWFG24,
	author = {De Cheng and
                  Haichun Tai and
                  Nannan Wang and
                  Chaowei Fang and
                  Xinbo Gao},
	title = {Neighbor Consistency and Global-Local Interaction: {A} Novel Pseudo-Label
                  Refinement Approach for Unsupervised Person Re-Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9070--9084},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3465037},
	doi = {10.1109/TIFS.2024.3465037},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ChengTWFG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised person re-identification (ReID) aims at learning discriminative identity features for person retrieval without any annotations. Recent advances accomplish this task by leveraging clustering-based pseudo labels, but these pseudo labels are inevitably noisy, which deteriorates model performance. In this paper, we propose a Neighbour Consistency guided Pseudo Label Refinement (NCPLR) framework, which can be regarded as a transductive form of label propagation under the assumption that the prediction of each example should be similar to its nearest neighbours’. Specifically, the refined label for each training instance can be obtained from the original clustering result and a weighted ensemble of its neighbours’ predictions, with weights determined according to their similarities in the feature space. Furthermore, we also explore building a unified global-local NCPLR mechanism through a global-local label interaction module to achieve mutual label refinement. Such a strategy promotes efficient complementary learning while mitigating some unreliable information, finally improving the quality of the refined pseudo labels for each global-local region. Extensive experimental results demonstrate the effectiveness of the proposed method, showing superior performance to state-of-the-art methods by a large margin. Our source code is released in https://github.com/haichuntai/NCPLR-ReID.}
}


@article{DBLP:journals/tifs/LiangMMSD24,
	author = {Yanrong Liang and
                  Jianfeng Ma and
                  Yinbin Miao and
                  Yuan Su and
                  Robert H. Deng},
	title = {Efficient and Privacy-Preserving Encode-Based Range Query Over Encrypted
                  Cloud Data},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9085--9099},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3465928},
	doi = {10.1109/TIFS.2024.3465928},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiangMMSD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving range query, which allows the server to implement secure and efficient range query on encrypted data, has been widely studied in recent years. Existing privacy-preserving range query schemes can realize effective range query, but usually suffer from the low efficiency and security. In order to solve the above issues, we propose an Efficient and Privacy-preserving encode-based Range Query over encrypted cloud data (namely basic EPRQ), which encodes the data and range by using Range Encode (REncoder), and then encrypts the codes via Additional Symmetric-Key Hidden Vector Encryption (ASHVE) technology. The basic EPRQ can achieve effective range query while ensuring privacy protection. Then, we split the codes to reduce the storage cost. We further propose an improved scheme, EPRQ+, which constructs a binary tree-based index to achieve faster-than-linear retrieval. Finally, our formal security analysis proves that our schemes are secure against Indistinguishability under Chosen-Plaintext Attack (IND-CPA), and extensive experiments demonstrate that our schemes are feasible in practice, where EPRQ+ scheme improves the storage efficiency by about 4 times and the query efficiency by about 8 times compared to the basic EPRQ.}
}


@article{DBLP:journals/tifs/MuCLZGS24,
	author = {Xutong Mu and
                  Ke Cheng and
                  Teng Liu and
                  Tao Zhang and
                  Xueli Geng and
                  Yulong Shen},
	title = {FedPTA: Prior-Based Tensor Approximation for Detecting Malicious Clients
                  in Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9100--9114},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451359},
	doi = {10.1109/TIFS.2024.3451359},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MuCLZGS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is vulnerable to poisoning attacks, where malicious clients tamper their model parameters to deteriorate the global model. Existing methods for defending against poisoning attacks primarily rely on identifying malicious clients, but struggle to balance robustness and efficiency. To address these issues, we propose FedPTA, a Prior-based Tensor Approximation (PTA) method. The core idea of FedPTA is to detect malicious clients in federated learning by leveraging inherent priors. This method initially innovatively defines multi-round model parameters as a three-dimensional tensor and unfolds it along different dimensions. Subsequently, three inherent priors - the similarity among benign clients, the continuity of multi-round client model parameters and the sparsity of malicious parameters, are integrated into a convex optimization framework. Through the optimization process, the optimal solutions for the background tensor and anomaly tensor are solved. Ultimately, the anomaly tensor is used to highlight the element-level features of malicious parameters, effectively distinguishing malicious clients. Evaluative studies supported by theoretical significance demonstrate the effectiveness of FedPTA, outperforming current state-of-the-art methods in terms of detection accuracy and computational efficiency.}
}


@article{DBLP:journals/tifs/WangGLGX24,
	author = {Jianhuan Wang and
                  Shang Gao and
                  Guyue Li and
                  Keke Gai and
                  Bin Xiao},
	title = {{SAMCU:} Secure and Anonymous Multi-Channel Updates in Payment Channel
                  Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9115--9128},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3451366},
	doi = {10.1109/TIFS.2024.3451366},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/WangGLGX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Payment Channel Network (PCN) has emerged as an extensively adopted solution to address the scalability issues of Bitcoin by efficient off-chain updates. However, conflicts arise while existing update protocols are pursuing multiple goals of security, privacy, and expressiveness. In this work, we propose a new off-chain update protocol, Secure and Anonymous Multi-Channel Updates (SAMCU), which is developed on the basis of Unspent Transaction Output (UTXO). SAMCU aims at achieving goals of internal anonymity, balance security, and multi-channel updates simultaneously, which has not been done before. To achieve these goals, we exploit the technique of updating graph splitting (UGS) to make participants aware of only the identities of their neighboring sub-graphs, thereby ensuring internal anonymity in multi-channel updates. Then, to avoid security issues arising from equal sub-graphs, we further propose an Enable Payment Transaction Tree (EPTT) to guarantee balance security for each honest protocol participant. Moreover, we optimize the performance of our solution, reducing transaction fees by splitting transactions and the number of communication connections by hierarchical communication. To evaluate the performance of the SAMCU, we implement a prototype involving up to 100 updating payment channels. Experimental results demonstrate that SAMCU outperforms the state-of-the-art, resulting in approximately 70% savings in communication connections and a 66% reduction in on-chain transaction fees when the number of updating payment channels is 100.}
}


@article{DBLP:journals/tifs/HuangHWZ24,
	author = {Yuanming Huang and
                  Mingshu He and
                  Xiaojuan Wang and
                  Jie Zhang},
	title = {HeVulD: {A} Static Vulnerability Detection Method Using Heterogeneous
                  Graph Code Representation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9129--9144},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3457162},
	doi = {10.1109/TIFS.2024.3457162},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangHWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vulnerability detection in source code has been a focal point of research in recent years. Traditional rule-based methods fail to identify complex and unknown vulnerabilities, leading to poor performance. While deep learning (DL)-based methods have improved these shortcomings, there is still room for enhancement. For C/C++ source code, effective vulnerability detection requires considering both the information in code statements and the structural information of the code. Graph-based code representation methods can address this need, but existing approaches often use homogeneous graphs that do not differentiate between various types of code statements or dependencies. Few methods use heterogeneous graphs for C/C++ code representation. This study explores this potential and proposes a new C/C++ vulnerability detection method named HeVulD. HeVulD introduces two node definition approaches and a key-node-based program slicing method, generating heterogeneous graph representations for source code. These representations consist of both heterogeneous nodes and edges, providing a more precise representation of source code. HeVulD achieves an F1-score of 96.4% on the SARD dataset, outperforming nine baseline C/C++ vulnerability detection methods. HeVulD has been tested under adversarial attack scenarios to assess its robustness. Additionally, HeVulD has been tested on ten open-source software projects and the latest CVEs, demonstrating its detection and generalization capabilities in real-world scenarios and its ability to identify unknown vulnerabilities.}
}


@article{DBLP:journals/tifs/ZhangGGJYF24,
	author = {Qian Zhang and
                  Qing Guo and
                  Ruijun Gao and
                  Felix Juefei{-}Xu and
                  Hongkai Yu and
                  Wei Feng},
	title = {Adversarial Relighting Against Face Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9145--9157},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3380848},
	doi = {10.1109/TIFS.2024.3380848},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangGGJYF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep face recognition (FR) has achieved significantly high accuracy on several challenging datasets and fosters successful real-world applications, even showing high robustness to the illumination variation that is usually regarded as a main threat to the FR system. However, in the real world, illumination variation caused by diverse lighting conditions cannot be fully covered by the limited face dataset. In this paper, we study the threat of lighting against FR from a new angle, i.e., adversarial attack, and identify a new task, i.e., adversarial relighting. Given a face image, adversarial relighting aims to produce a naturally relighted counterpart while fooling the state-of-the-art deep FR methods. To this end, we first propose the physical model-based adversarial relighting attack (ARA) denoted as albedo-quotient-based adversarial relighting attack (AQ-ARA). It generates natural adversarial lighting under the guidance of FR systems and synthesizes adversarially relighted face images. Moreover, we propose the auto-predictive adversarial relighting attack (AP-ARA) by training an adversarial relighting network (ARNet) to automatically predict the adversarial lighting in a one-step manner according to different input faces, allowing efficiency-sensitive applications. More importantly, we propose to transfer the above digital attacks to physical ARA (Phy-ARA) through a precise relighting device, making the estimated adversarial lighting condition reproducible in the real world. We validate our methods on several state-of-the-art deep FR methods on two public datasets. The extensive and insightful results demonstrate our work can generate realistic adversarial relighted face images fooling face recognition tasks easily, revealing the threat of specific light directions and strengths.}
}


@article{DBLP:journals/tifs/ZhaiLWQZDDS24,
	author = {Mingzhe Zhai and
                  Yizhong Liu and
                  Qianhong Wu and
                  Bo Qin and
                  Haibin Zheng and
                  Xiaopeng Dai and
                  Zhenyang Ding and
                  Willy Susilo},
	title = {Accountable Secret Committee Election and Anonymous Sharding Blockchain
                  Consensus},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9158--9172},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3459608},
	doi = {10.1109/TIFS.2024.3459608},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ZhaiLWQZDDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Consensus protocols play a crucial role in determining the security and performance of blockchain systems, with committee-based consensus protocols being particularly important, especially in sharding consensus protocols. Anonymous election of committee nodes can mitigate DDoS attacks and bribery attempts. This approach can also be applied to sharding systems to mitigate the risk associated with a single vulnerable shard. However, current node secret selection schemes still present remaining issues. Single secret leader election schemes struggle to elect multiple leaders with equal anonymity, and existing secret committee election schemes lack adequate measures for tracking malicious nodes. To address these issues, we propose accountable secret committee election schemes that not only regulate the number of nodes but also maintain anonymity during the phases of leader proposal and verifier voting. Furthermore, our schemes enable the tracing of malicious nodes in a threshold way. In addition, we introduce two efficient threshold traceable membership proof schemes for both ad hoc and interactive scenarios. Unlike traceable ring signatures, our scheme can trace malicious nodes even after a single malicious behavior. Subsequently, we apply the accountable secret committee election scheme to sharding blockchains and devise a fully accountable anonymous consensus protocol. The experiment demonstrates that this protocol can elevate the difficulty of corrupting a single shard to the level of compromising the entire system, thereby significantly enhancing the security of the sharding system.}
}


@article{DBLP:journals/tifs/ZamanXGHJJ24,
	author = {Zakia Zaman and
                  Wanli Xue and
                  Praveen Gauravaram and
                  Wen Hu and
                  Jiaojiao Jiang and
                  Sanjay K. Jha},
	title = {Privacy-Preserving Probabilistic Data Encoding for IoT Data Analysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9173--9187},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468150},
	doi = {10.1109/TIFS.2024.3468150},
	timestamp = {Fri, 17 Jan 2025 20:52:50 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZamanXGHJJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread integration of the Internet of Things (IoT) is crucial in advancing sustainable development. IoT service providers actively collect user data for analysis using sophisticated Deep Learning (DL) algorithms. This enables the extraction of valuable insights for business intelligence and improving service quality. However, as these datasets contain sensitive personal information, there is a risk of privacy breaches when DL models are employed. This vulnerability may result in Membership Inference Attacks (MIA), potentially leading to the unauthorized disclosure of highly sensitive data. Therefore, developing an efficient and privacy-preserving data analysis system for IoT is imperative. Recent research has highlighted the effectiveness of utilizing Bloom Filter (BF)-encoding in conjunction with Differential Privacy (DP) for safeguarding privacy during data analysis. Given its attributes of low complexity and high utility, this approach proves effective, particularly in resource-constrained IoT domains. With this in mind, we propose a novel framework for privacy-preserving IoT data analysis based on BF-encoded data. Our research introduces an innovative BF-encoding technique combined with Local Differential Privacy (LDP), capable of efficiently encoding various types of IoT data (such as facial images and smart-meter data) while maintaining privacy when integrated into DL algorithms for downstream analysis. Experimental results demonstrate that our BF-encoded data surpasses the utility of standard BF-encoded data when utilized in DL algorithms for downstream tasks, showcasing an approximate 30% improvement in classification accuracy. Furthermore, we assess the privacy of these DL models against MIA, revealing that attackers can only make random guesses with an accuracy of approximately 50%.}
}


@article{DBLP:journals/tifs/LiuLSYL24,
	author = {Yicheng Liu and
                  Zhao Li and
                  Kang G. Shin and
                  Zheng Yan and
                  Jia Liu},
	title = {iCoding: Countermeasure Against Interference and Eavesdropping in
                  Wireless Communications},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9188--9203},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468902},
	doi = {10.1109/TIFS.2024.3468902},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LiuLSYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of wireless communication technologies, interference management (IM) and security/privacy in data transmission have become critically important. On one hand, due to the broadcast nature of wireless medium, the interference superimposed on the desired signal can destroy the integrity of data transmission. On the other hand, malicious receivers (Rxs) may eavesdrop a legitimate user’s transmission and thus breach the confidentiality of communication. To counter these threats, we propose a novel encoding method, called immunizing coding (iCoding), which handles both IM and physical-layer security simultaneously. By exploiting both channel state information (CSI) and data carried in the interference, an iCoded signal is generated and sent by the legitimate transmitter (Tx). The iCoded signal interacts with the interference at the desired/legitimate Rx, so that the intended data can be recovered without the influence of disturbance, i.e., immunity to interference. In addition, since the data carried in the iCoded signal which is obtained via encoding the desired data and interference cooperatively, is different from the original desired data, the eavesdropper cannot access unauthorized information by wiretapping the desired signal, thus achieving immunity to eavesdropping. Our theoretical analysis, experimental and numerical evaluation have shown iCoding to effectively manage interference while preventing potential eavesdropping, hence enhancing the legitimate user’s transmission and secrecy thereof.}
}


@article{DBLP:journals/tifs/ShenZWM24,
	author = {Guanxiong Shen and
                  Junqing Zhang and
                  Xuyu Wang and
                  Shiwen Mao},
	title = {Federated Radio Frequency Fingerprint Identification Powered by Unsupervised
                  Contrastive Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9204--9215},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3469820},
	doi = {10.1109/TIFS.2024.3469820},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ShenZWM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio frequency fingerprint identification (RFFI) is a promising physical layer authentication technique that utilizes the unique impairments within the analog front-end of transmitters as distinct identifiers. State-of-the-art RFFI systems are frequently powered by deep learning, which requires extensive training data to ensure satisfactory performance. However, current RFFI studies suffer from a severe lack of training data, which poses challenges in achieving high identification accuracy. In this paper, we propose a federated RFFI system that is particularly suitable for Internet of Things (IoT) networks, which holds a high potential to address the data scarcity challenge in RFFI development. Specifically, all the receivers in an IoT network can pre-train a deep learning-driven feature extractor in a federated and unsupervised manner. Subsequently, a new client can perform fine-tuning on the basis of the pre-trained feature extractor to activate its RFFI functionality. Extensive experimental evaluation was carried out, involving 60 commercial off-the-shelf (COTS) LoRa transmitters and six software-defined radio (SDR) receivers. The experimental results demonstrate that the federated RFFI protocol can effectively improve the identification accuracy from 63% to 95%, and is robust to receiver hardware and location variations.}
}


@article{DBLP:journals/tifs/GongNLZZ24,
	author = {Jiacheng Gong and
                  Weina Niu and
                  Song Li and
                  Mingxue Zhang and
                  Xiaosong Zhang},
	title = {Sensitive Behavioral Chain-Focused Android Malware Detection Fused
                  With {AST} Semantics},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9216--9229},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468891},
	doi = {10.1109/TIFS.2024.3468891},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/GongNLZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of Android malware poses a substantial security threat to mobile devices. Thus, achieving efficient and accurate malware detection and malware family identification is crucial for safeguarding users’ individual property and privacy. Graph-based approaches have demonstrated remarkable detection performance in the realm of intelligent Android malware detection methods. This is attributed to the robust representation capabilities of graphs and the rich semantic information. The function call graph (FCG) is the most widely used graph in intelligent Android malware detection. However, existing FCG-based malware detection methods face challenges, such as the enormous computational and storage costs of modeling large graphs. Additionally, the ignorance of code semantics also makes them susceptible to structured attacks. In this paper, we proposed AndroAnalyzer, which embeds abstract syntax tree (AST) code semantics while focusing on sensitive behavior chains. It leverages FCGs to represent the macroscopic behavior of the application, and employs structured code semantics to represent the microscopic behavior of functions. Furthermore, we proposed the sensitive function call graph (SFCG) generation algorithm to narrow down the analysis scope to sensitive function calls, and the AST vectorization algorithm (AST2Vec) to capture structured code semantics. Experimental results demonstrate that the proposed SFCG generation algorithm noticeably reduces graph size while ensuring robust detection performance. AndroAnalyzer outperforms the baseline methods in binary and multiclass classification tasks, achieving F1-scores of 99.21% and 98.45% respectively. Moreover, AndroAnalyzer (trained with samples of 2010-2018) exhibits good generalization capabilities in detecting samples of 2019-2022.}
}


@article{DBLP:journals/tifs/TangLLY24,
	author = {Bo Tang and
                  Fengdong Li and
                  Jianbo Liu and
                  Cheng Yang},
	title = {A Video Visual Security Metric Based on Spatiotemporal Self-Attention},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9230--9244},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3459731},
	doi = {10.1109/TIFS.2024.3459731},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/TangLLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Visual Security Index (VSI) of encrypted videos measure the security of encryption algorithms by evaluating the visual information content, which provides a critical evaluation criterion for selective encryption. The VSI for encrypted videos needs to assess security in both spatial and temporal domains. Existing visual security metrics, which rely on averaging, optical flow, and convolutions, fail to capture information leakage in the temporal domain effectively. This paper proposes a spatiotemporal self-attention-based video security assessment model called Spatiotemporal Self Attention (StSA). In the spatial domain, windowed self-attention is used to calculate regional correlations within video frames. By introducing multi-layer outputs, a multi-depth self-attention network named Multi-Depth Swin-Transformer (MDST) is constructed to compute the regional correlation within video frames. A weak label calculation method based on edge similarity is proposed to calculate the scores for frames and blocks based on the video Mean Opinion Score (MOS), thereby supporting the pre-training of spatial models. In the temporal domain, considering human visual persistence characteristics and the one-way relationship between video frames, temporal unidirectional window self-attention is proposed to calculate frame correlations in the temporal sequence. Finally, the visual security index score for encrypted videos is obtained by combining the spatiotemporal correlation changes of encrypted and plaintext videos. Experimental results show that StSA achieves a Pearson Linear Correlation Coefficient (PLCC) of 0.955 and a Root Mean Squared Error (RMSE) of 0.458 on the encryption datasets. Compared to other visual security metrics, StSA demonstrates higher accuracy and correlation, effectively capturing spatiotemporal information leakage in encrypted videos and reflecting the human perception of the security.}
}


@article{DBLP:journals/tifs/NiknamiSW24,
	author = {Nadia Niknami and
                  Avinash Srinivasan and
                  Jie Wu},
	title = {Cyber-AnDe: Cybersecurity Framework With Adaptive Distributed Sampling
                  for Anomaly Detection on SDNs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9245--9257},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468632},
	doi = {10.1109/TIFS.2024.3468632},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/NiknamiSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By decoupling the control plane and data plane in the software-defined network (SDN), the controller gains a comprehensive global view of the network. The SDN controller samples traffic from all switches to effectively manage data plane traffic. The sampling rate of flow traffic significantly impacts the accuracy of the controller’s decisions. While increasing the sampling rate is desirable for improved detection accuracy, it also escalates resource consumption on both switches and the controller. Hence, it is crucial to carefully manage sampling on switches to fine-tune anomaly detection accuracy. Existing flow sampling solutions often struggle to strike a balance between detection accuracy, sampling rate, and overhead. To address this challenge, we propose a robust cybersecurity framework for anomaly detection on SDNs through traffic flow inspection. Our proposed framework, Cyber-AnDe, integrates adaptive distributed sampling (ADS) with a Reinforcement Learning (RL) agent to enhance anomaly detection accuracy while minimizing the increase in controller overhead. In our framework, the controller leverages information gathered from each sampled traffic flow to determine whether the flow’s state is malicious, suspicious, or benign based on underlying anomaly detection algorithms. Once the flow state is determined, the controller takes the appropriate action with the help of the RL agent. Through extensive simulations and SDN test-bed experiments, we confirm a significant improvement of up to 93% in network traffic-based anomaly detection compared to existing solutions.}
}


@article{DBLP:journals/tifs/ArroyoBT24,
	author = {Jose A. Gutierrez del Arroyo and
                  Brett J. Borghetti and
                  Michael A. Temple},
	title = {Fingerprint Extraction Through Distortion Reconstruction {(FEDR):}
                  {A} CNN-Based Approach to {RF} Fingerprinting},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9258--9269},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463528},
	doi = {10.1109/TIFS.2024.3463528},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/ArroyoBT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio Frequency Fingerprinting (RFF) is the attribution of uniquely identifiable signal distortions to emitters via Machine Learning (ML) classifiers. RFF approaches relying on pre-determined expert features lack generalizability, and state-of-the-art approaches based on Convolutional Neural Networks (CNNs) can be too demanding for endpoint devices to train. This work presents Fingerprint Extraction through Distortion Reconstruction (FEDR), a best-of-both-worlds technique which employs a pre-trained CNN to identify and extract a small, salient set of unique features, amenable for use in lightweight machine learning models. Given a received distorted signal, the FEDR network encodes signal distortions into “fingerprints,” which can be used by lightweight ML classifiers to perform RFF with minimal resource consumption at the endpoint. FEDR learns by transforming generated signals into reconstructions of received signals, relying solely on the fingerprints as representations of the distortions – as the reconstructions improve, the fingerprints better encode the distortions. The FEDR technique was evaluated on synthetic IQ-imbalanced IEEE 802.11a/g data, where FEDR fingerprints were shown to encode actual IQ imbalance parameters, signifying successful isolation of distortion information and validating the FEDR technique. FEDR was further evaluated on a representative real-world WiFi dataset, where extracted fingerprints were coupled with a lightweight two-layer dense network. When compared against two common RFF techniques, the FEDR-based approach achieved state-of-the-art performance with Matthews Correlation Coefficient ranging from 0.984 (5 classes) to 0.851 (100 classes), using nearly 73% fewer training parameters than the next-best technique.}
}


@article{DBLP:journals/tifs/HuangZLSC24,
	author = {Jiancheng Huang and
                  Donghao Zhou and
                  Jianzhuang Liu and
                  Linxiao Shi and
                  Shifeng Chen},
	title = {{IFAST:} Weakly Supervised Interpretable Face Anti-Spoofing From Single-Shot
                  Binocular {NIR} Images},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9270--9284},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3465930},
	doi = {10.1109/TIFS.2024.3465930},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/HuangZLSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Single-shot face anti-spoofing (FAS) is a key technique for securing face recognition systems, relying solely on static images as input. However, single-shot FAS remains a challenging and under-explored problem due to two reasons: 1) On the data side, learning FAS from RGB images is largely context-dependent, and single-shot images without additional annotations contain limited semantic information. 2) On the model side, existing single-shot FAS models struggle to provide proper evidence for their decisions, and FAS methods based on depth estimation require expensive per-pixel annotations. To address these issues, we construct and release a large binocular NIR image dataset named BNI-FAS, which contains more than 300,000 real face and plane attack images, and propose an Interpretable FAS Transformer (IFAST) that requires only weak supervision to produce interpretable predictions. Our IFAST generates pixel-wise disparity maps using the proposed disparity estimation Transformer with Dynamic Matching Attention (DMA) blocks. Besides, we design a confidence map generator to work in tandem with a dual-teacher distillation module to obtain the final discriminant results. Comprehensive experiments show that our IFAST achieves state-of-the-art performance on BNI-FAS, verifying its effectiveness of single-shot FAS on binocular NIR images. The project page is available at https://ifast-bni.github.io/.}
}


@article{DBLP:journals/tifs/MathewsHHW24,
	author = {Nate Mathews and
                  James K. Holland and
                  Nicholas Hopper and
                  Matthew Wright},
	title = {Laserbeak: Evolving Website Fingerprinting Attacks With Attention
                  and Multi-Channel Feature Representation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9285--9300},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468171},
	doi = {10.1109/TIFS.2024.3468171},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/MathewsHHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present Laserbeak, a new state-of-the-art website fingerprinting attack for Tor that achieves nearly 96% accuracy against FRONT-defended traffic by combining two innovations: 1) multi-channel traffic representations and 2) advanced techniques adapted from state-of-the-art computer vision models. Our work is the first to explore a range of different ways to represent traffic data for a classifier. We find a multi-channel input format that provides richer contextual information, enabling the model to learn robust representations even in the presence of heavy traffic obfuscation. We are also the first to examine how recent advances in transformer models can take advantage of these representations. Our novel model architecture utilizing multi-headed attention layers enhances the capture of both local and global patterns. By combining these innovations, Laserbeak demonstrates absolute performance improvements of up to 36.2% (e.g., from 27.6% to 63.8%) compared with prior attacks against defended traffic. Experiments highlight Laserbeak’s capabilities in multiple scenarios, including a large open-world dataset where it achieves over 80% recall at 99% precision on traffic obfuscated with padding defenses. These advances reduce the remaining anonymity in Tor against fingerprinting threats, underscoring the need for stronger defenses.}
}


@article{DBLP:journals/tifs/YangLLWHLZ24,
	author = {Jingjing Yang and
                  Jieli Liu and
                  Dan Lin and
                  Jiajing Wu and
                  Baoying Huang and
                  Quanzhong Li and
                  Zibin Zheng},
	title = {Who Stole My NFT? Investigating Web3 {NFT} Phishing Scams on Ethereum},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9301--9314},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463541},
	doi = {10.1109/TIFS.2024.3463541},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/YangLLWHLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularity of Non-Fungible Tokens (NFTs), the high value of NFTs makes them a target for phishing scammers, which harms the security and reliability of the Web3 NFT ecosystem. Despite the significance of this issue, there is a lack of systematic research in the area of emerging NFT phishing scams. To address this gap, we are the first to conduct a case retrospective analysis and empirical measurement study of real-world historical NFT phishing scams on Ethereum. We collect and publicly release the first NFT phishing dataset which includes 1,625 NFT phishing accounts and transaction records as of August 2023. We further categorize the existing scams into four phishing patterns and investigate their distinguishable behaviors. Then, we reveal the modus operandi preferences and economic impacts to characterize NFT phishing scams. We find that NFT phishers stole 67,188 NFTs, with a total direct selling profit of {\\$}\n20.92 million. We also observe that scammers favor certain categories and collections of NFTs, coupled with signs of gang theft. Furthermore, we design a variety of account features for the classification task of NFT phishers based on empirical conclusions. Experimental results on real-world NFT transaction data demonstrate the effectiveness of these features in detecting NFT phishing accounts, and outperform traditional phishing detection methods with 41% average Precision and 44% average Recall.}
}


@article{DBLP:journals/tifs/LaiWLWZMRZ24,
	author = {Yuni Lai and
                  Marcin Waniek and
                  Liying Li and
                  Jingwen Wu and
                  Yulin Zhu and
                  Tomasz P. Michalak and
                  Talal Rahwan and
                  Kai Zhou},
	title = {Coupled-Space Attacks Against Random-Walk-Based Anomaly Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9315--9329},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468156},
	doi = {10.1109/TIFS.2024.3468156},
	timestamp = {Tue, 22 Oct 2024 21:08:37 +0200},
	biburl = {https://dblp.org/rec/journals/tifs/LaiWLWZMRZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Random Walks-based Anomaly Detection (RWAD) is commonly used to identify anomalous patterns in various applications. An intriguing characteristic of RWAD is that the input graph can either be pre-existing graphs or feature-derived graphs constructed from raw features. Consequently, there are two potential attack surfaces against RWAD: graph-space attacks and feature-space attacks. In this paper, we explore this vulnerability by designing practical coupled-space (interdependent feature-space and graph-space) attacks, investigating the interplay between graph-space and feature-space attacks. To this end, we conduct a thorough complexity analysis, proving that attacking RWAD is NP-hard. Then, we proceed to formulate the graph-space attack as a bi-level optimization problem and propose two strategies to solve it: alternative iteration (alterI-attack) or utilizing the closed-form solution of the random walk model (cf-attack). Finally, we utilize the results from the graph-space attacks as guidance to design more powerful feature-space attacks (i.e., graph-guided attacks). Comprehensive experiments demonstrate that our proposed attacks are effective in enabling the target nodes to evade the detection from RWAD with a limited attack budget. In addition, we conduct transfer attack experiments in a black-box setting, which show that our feature attack significantly decreases the anomaly scores of target nodes. Our study opens the door to studying the coupled-space attack against graph anomaly detection in which the graph space relies on the feature space.}
}


@article{DBLP:journals/tifs/QinXLEW24,
	author = {Huafeng Qin and
                  Zhipeng Xiong and
                  Yantao Li and
                  Mounim A. El{-}Yacoubi and
                  Jun Wang},
	title = {Attention BLSTM-Based Temporal-Spatial Vein Transformer for Multi-View
                  Finger-Vein Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9330--9343},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468898},
	doi = {10.1109/TIFS.2024.3468898},
	timestamp = {Thu, 14 Nov 2024 07:27:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/QinXLEW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finger-vein biometrics has recently gained significant attention due to its robust privacy and high security features. Despite notable advancements, most existing methods focus on extracting features from a 2-dimensional (2D) image projected from 3D vein vessels with a single view. However, recognition based on a single view is prone to errors due to variations in finger positioning, especially those caused by finger roll movements, which can degrade recognition performance. To address this challenge, we propose ABLSTM-TSVT, an Attention Bidirectional LSTM-based Temporal-Spatial Vein Transformer for multi-view finger-vein recognition. First, we enhance LSTM with an attention mechanism to create an attention LSTM for extracting temporal features. We further improve this by introducing a local attention module, which learns temporal dependencies between a patch (token) and its adjacent patches across multiple views, integrating it with the attention LSTM to form a temporal attention module. Second, we develop a spatial attention module that captures the spatial dependencies of patches within an image. Finally, merging the temporal and the spatial attention modules, we create our temporal-spatial transformer model, which effectively represents features from multi-view images. Experimental results on two multi-view datasets demonstrate that our approach outperforms state-of-the-art approaches in enhancing identification accuracy and reducing verification errors in vein classifiers.}
}


@article{DBLP:journals/tifs/TranHH24,
	author = {Hong{-}Yen Tran and
                  Jiankun Hu and
                  Wen Hu},
	title = {Biometrics-Based Authenticated Key Exchange With Multi-Factor Fuzzy
                  Extractor},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9344--9358},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468624},
	doi = {10.1109/TIFS.2024.3468624},
	timestamp = {Fri, 17 Jan 2025 20:52:50 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TranHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing fuzzy extractor and similar methods provide an effective way for extracting a secret key from a user’s biometric data, but are susceptible to impersonation attack: once a valid biometric sample is captured, the scheme is no longer secure. We propose a novel multi-factor fuzzy extractor that integrates both a user’s secret (e.g., a password) and a user’s biometrics in the generation and reconstruction process of a cryptographic key. We then employ this multi-factor fuzzy extractor to construct personal identity credentials, which can be used in a new multi-factor authenticated key exchange protocol that possesses multiple important features. First, the protocol provides mutual authentication. Second, the user and service provider can authenticate each other without the involvement of the identity authority. Third, the protocol can prevent user impersonation from a compromised identity authority. Finally, even when both a biometric sample and the secret are captured, the user can re-register to create a new credential using a new secret (renewable biometrics-based identity credentials). Most existing works on multi-factor authenticated key exchange only have a subset of these features. We formally prove that the proposed protocol is semantically secure. Our experiments carried out on the finger vein dataset SDUMLA achieved a low equal error rate (EER) of 0.04%, a reasonable computation time of 0.93 seconds for the user and service provider to authenticate and establish a shared session key, and a small communication overhead of 448 bytes.}
}


@article{DBLP:journals/tifs/GaoZCHXL24,
	author = {Shiqi Gao and
                  Haoyi Zhou and
                  Tianyu Chen and
                  Mingrui He and
                  Runhua Xu and
                  Jianxin Li},
	title = {PE-Attack: On the Universal Positional Embedding Vulnerability in
                  Transformer-Based Models},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9359--9373},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3442617},
	doi = {10.1109/TIFS.2024.3442617},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GaoZCHXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Transformer model has gained significant recognition for its remarkable computational capabilities and versatility, positioning itself as a fundamental component in numerous practical applications. However, the robustness of the Transformer model, specifically its stability and reliability under various types of adversarial attacks, is of utmost importance for its practical applicability. Furthermore, it offers valuable insights for the design of more efficient and secure models. In contrast with conventional investigations into adversarial robustness, our study focuses on the analysis of Positional Embeddings (PEs), a crucial component that sets the Transformer model apart from previous model architectures. Theoretical analysis of PEs has been limited due to previous predominantly empirical design, which includes features such as sinusoidal or linear patterns, learned or fixed characteristics, and absolute or relative measurements. Our investigation delves deep into potential vulnerabilities within PEs. Initially, we develop a set of input infection techniques that can be universally applied to exploit vulnerabilities present in the Transformer architecture and its variants. In addition, we propose a novel adversarial attack that manipulates the model by providing it with incorrect positional information, enabling an evasion attack. Significantly, in contrast to previous attacks that were limited to a single task, our conducted experiments involving time-series analysis, natural language processing, and computer vision indicate that the susceptibility of PEs could be universal and transferable. This finding serves as a significant warning for future Transformer-based model design, urging researchers to consider potential security risks inherent in the model’s structure.}
}


@article{DBLP:journals/tifs/LiuWQZ24,
	author = {Ya Liu and
                  Xiao Wang and
                  Bo Qu and
                  Fengyu Zhao},
	title = {{ATVITSC:} {A} Novel Encrypted Traffic Classification Method Based
                  on Deep Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9374--9389},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3433446},
	doi = {10.1109/TIFS.2024.3433446},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuWQZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing prevalence of encrypted communication on the modern internet has presented new challenges for traffic classification and network management. Traditional traffic classification methods cannot handle encrypted traffic effectively. Meanwhile, many existing methods either rely on hand-crafted features or fail to extract the underlying interaction patterns between data packets adequately. In this paper, we propose a novel encrypted traffic classification method called the Attention-based Vision Transformer and Spatiotemporal for Traffic Classification (ATVITSC). In the preprocessing stage, packet-level images within a session, generated from the payload of data packets, are combined into a session image to mitigate information confusion. In the classification stage, session images are first processed by the packet vision transformer (PVT) module, which employs the transformer encoder and multi-head self-attention mechanism, to capture the global features. In parallel, session images are also processed by the spatiotemporal feature extraction (STFE) module, where spatial features of packets are extracted by the convolution operation with the attention mechanism and temporal features between packets are then combined by the bidirectional Long Short-Term Memory (LSTM). The global and spatiotemporal features are fused in the feature fusion classification (FFC) module by a dynamic weighting mechanism and encrypted traffic is finally classified based on the fused features. Comprehensive experiments on various types of encrypted traffic, including virtual private network (VPN), onion router (Tor), malicious traffic, and mobile traffic, show that the ATVITSC successfully improves the macro-f1 scores to 97.88%, 98.79%, 99.67%, 94.90%, respectively. The results also reveal that the ATVITSC exhibits better classification performance and generalization ability than the state-of-the-art methods.}
}


@article{DBLP:journals/tifs/LinLLBTL24,
	author = {Kaiqing Lin and
                  Bin Li and
                  Weixiang Li and
                  Mauro Barni and
                  Benedetta Tondi and
                  Xulong Liu},
	title = {Constructing an Intrinsically Robust Steganalyzer via Learning Neighboring
                  Feature Relationships and Self-Adversarial Adjustment},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9390--9405},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3470651},
	doi = {10.1109/TIFS.2024.3470651},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LinLLBTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The effectiveness of deep learning-based steganalyzers is significantly compromised by adversarial steganography. In response to this challenge, recent efforts have been devoted to identifying distinct traces of adversarial perturbations, yet they have overlooked the inherently adversarial robustness required in steganalyzers. This paper aims to develop a steganalytic model that defends against adversarial steganography by increasing the difficulty of generating adversarial stego images. To achieve this objective, the techniques of learning neighboring feature relationships and self-adversarial adjustment are proposed with three essential modules. The first one, named K-times Dropout Neighboring Feature Transformer (KDNFT), is designed to accept a set of neighboring features obtained by dropout as input. Based on the finding that K-times dropout neighboring features have different distributions for covers and adversarial stegos, KDNFT effectively learns to exploit the relationships among these features for adversarial steganalysis. To facilitate adversarial training, which is an effective way to improve intrinsic robustness, the second module called Pseudo Adversarial Stego Generator (PASG) is proposed to synthesize samples for training. The third module is a Test-time Active Perturbation (TAP) module that adjusts the results of adversarial stego samples close to the decision boundary in a self-adversarial way. Extensive experiments demonstrate that our method achieves improvements in steganalyzing various kinds of adversarial steganographic methods.}
}


@article{DBLP:journals/tifs/AminMSA24,
	author = {Insha Amin and
                  Deepak Mishra and
                  Ravikant Saini and
                  Sonia A{\"{\i}}ssa},
	title = {Power Allocation and Decoding Order Selection for Secrecy Fairness
                  in Downlink Cooperative {NOMA} With Untrusted Receivers Under Imperfect
                  {SIC}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9406--9418},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3471429},
	doi = {10.1109/TIFS.2024.3471429},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AminMSA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non-orthogonal multiple access (NOMA) has been recognized as a promising multiple access technique for enhanced spectral efficiency in the current and next-generation wireless networks. In this paper, we examine a realistic NOMA model where users, assisted by a regenerative relay, cannot be fully trusted. We address the challenge of ensuring secure access for these users while accounting for the error propagation in successive interference cancellation (SIC) during the decoding process. For such, we formulate and solve two optimization problems, viz. maximizing the minimum secrecy rate of the users and maximizing the sum secrecy rate of the users, while accounting for SIC errors and the constraint on the power budget. For each case, we derive the optimal power allocation solution to achieve positive secrecy rates despite imperfect SIC. Simulation results provide key insights on the obtained secrecy rates and power allocations, factoring in residual interference. The joint optimal solution for the decoding order and power allocation is compared with different benchmark schemes: optimal decoding order and equal power allocation, fixed decoding order and equal power allocation, fixed decoding order and optimal power allocation, and optimal decoding order and channel-based power allocation. Our proposed framework demonstrates average performance gains of about 47.62 dB, 50.79 dB, 54.02 dB and 39.83 dB over these schemes and, hence, the fact that the proposed framework can substantially improve the secrecy performance.}
}


@article{DBLP:journals/tifs/MeschiniTBM24,
	author = {Marcello Meschini and
                  Giorgio Di Tizio and
                  Marco Balduzzi and
                  Fabio Massacci},
	title = {A Case-Control Study to Measure Behavioral Risks of Malware Encounters
                  in Organizations},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9419--9432},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3456960},
	doi = {10.1109/TIFS.2024.3456960},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MeschiniTBM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The behavior of enterprise users (e.g. browsing at night or visiting gambling sites) is a potential factor that might increase the chances of malware encounters (e.g. coinminers vs ransomware) on the field. We report a case-control study on telemetry data collected by Trend Micro, a global cybersecurity vendor, to identify users’ behavioral characteristics that can be used to differentiate cybersecurity risks profiles. Our results show that different types of ‘patients zero’ are vulnerable to different types of epidemics. The odds ratio of encountering malware such as PUAs, trojans, and hacktools is higher for a variety of network and system behavior (e.g. number, types, and diversity of visited web sites, visit of gambling sites, etc.) but it is not significant for other factors such as browsing at night. Other type of malware such as coinminers have an increase in the odds ratio only for few type of factors (e.g. gambling web sites). We also present a specific methodology tailored for investigating self-propagating malware such as ransomware in which one is infected by one’s neighbor. With this approach, we observed a more accurate characterization of the odds of encountering ransomware based on system-based behaviors than with a standard case-control study setup. Experiments with different vendors may be needed to generalize the results and offset potential bias due to differences in market share.}
}


@article{DBLP:journals/tifs/KongCWSZCLYQZK24,
	author = {Dezhang Kong and
                  Xiang Chen and
                  Chunming Wu and
                  Yi Shen and
                  Zhengyan Zhou and
                  Qiumei Cheng and
                  Xuan Liu and
                  Mingliang Yang and
                  Yubing Qiu and
                  Dong Zhang and
                  Muhammad Khurram Khan},
	title = {rDefender: {A} Lightweight and Robust Defense Against Flow Table Overflow
                  Attacks in {SDN}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9436--9451},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3472477},
	doi = {10.1109/TIFS.2024.3472477},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KongCWSZCLYQZK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The flow table is a critical component of Software-Defined Networking (SDN). However, flow tables’ limited capacity makes them highly vulnerable to flow table overflow attacks (FTOAs). Due to the low attack cost and highly flexible attack forms, it is hard to eradicate FTOAs. This paper addresses three unsolved problems for table security and proposes a robust defense accordingly. First, we reveal that the existing defenses with fixed defense speeds will cause severe packet loss when handling diverse traffic. We prove that deleting multiple rules can efficiently solve this problem and give a rigorous derivation to calculate the suitable deletion number according to the environment. Second, we illustrate that abnormal table occupancy squeezing is a constant characteristic of FTOAs regardless of attack forms. It can be used to identify attacked ports accurately in different scenarios. Third, we mathematically prove that random deletion can guarantee the continuous decrease of malicious flow rules after confirming attacked ports. It achieves fast speed and robust effectiveness in different environments. Based on these findings, we design rDefender, a robust and lightweight defense prototype. We evaluate its effect by designing diverse, powerful attacks and using real-world datasets and topology. The results demonstrate that it achieves the best overall performance compared to six existing mainstream defenses, providing stable security for switch flow tables.}
}


@article{DBLP:journals/tifs/ZhangW24,
	author = {Jianhong Zhang and
                  Jie Wei},
	title = {On the Security of Privacy-Enhanced Authentication Protocol for Federated
                  Learning in VANETs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9433--9435},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3445730},
	doi = {10.1109/TIFS.2024.3445730},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In federated learning for VANET, Yuan et al. proposed a privacy-enhanced authentication protocol to balance training efficiency and vehicle privacy. They claimed that their protocol provides both unforgeability and traceability, asserting that it is secure against unforgeable attacks from Type I adversaries and allows Trust Authorities (TAs) to trace the real identities of malicious vehicles. Unfortunately, our analysis reveals that Yuan et al.’s protocol is insecure in the presence of malicious vehicles. Specifically, malicious vehicles can forge the signatures of arbitrary messages through public key replacement attacks by Type I adversaries. Furthermore, the real identities of malicious vehicles cannot be effectively traced. Consequently, the authenticity and integrity of the collected model parameters cannot be guaranteed. After analyzing the reasons for these vulnerabilities, we offer corresponding suggestions to overcome them.}
}


@article{DBLP:journals/tifs/YangLLYZZ24,
	author = {Yishan Yang and
                  Jiajun Li and
                  Niya Luo and
                  Zheng Yan and
                  Yifan Zhang and
                  Kai Zeng},
	title = {BatchAuth: {A} Physical Layer Batch Authentication Scheme for Multiple
                  Backscatter Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9452--9466},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3473322},
	doi = {10.1109/TIFS.2024.3473322},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangLLYZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Backscatter communication (BC) offers a promising power-efficient communication paradigm for wireless devices with constrained energy resources. However, the innate openness and broadcast characteristics of BC raise considerable security concerns. To address this, physical layer authentication has emerged as a primary solution to enable secure BC. To facilitate efficient authentication on multiple backscatter devices (BDs), batch authentication becomes essential. Nevertheless, existing schemes have not yet bridged the research gap regarding effective batch authentication on mobile BDs with high scalability support. This paper proposes BatchAuth, a physical layer batch authentication scheme designed to authenticate multiple BDs simultaneously by leveraging orthogonal frequency-division multiple access (OFDMA) technology. BatchAuth utilizes two factors, received signal strength (RSS) and multiple channel impulse responses (CIRs), to authenticate a group of BDs and leverages a channel correlation coefficient to offset performance loss and support BD dynamicity. What’s more, a backscatter waveform design facilitates an access point (AP) in estimating the CIRs from backscattered signals. Additionally, BatchAuth possesses the capability to detect and trace potential attackers by analyzing the specific characteristics of orthogonal subcarriers to facilitate countermeasure. In particular, BatchAuth demonstrates significant potential on scalability in large-scale BC systems and multiple-input multiple-output (MIMO) systems. Theoretical analysis on BatchAuth security and extensive simulations under various settings by comparing with cutting-edge schemes further validate its commendable performance with regard to accuracy, robustness, efficiency, and scalability.}
}


@article{DBLP:journals/tifs/LevecqueBB24,
	author = {Etienne Levecque and
                  Jan Butora and
                  Patrick Bas},
	title = {Finding Incompatible Blocks for Reliable {JPEG} Steganalysis},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9467--9479},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3470650},
	doi = {10.1109/TIFS.2024.3470650},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LevecqueBB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article presents a refined notion of incompatible JPEG images for a quality factor of 100. It can detect the presence of steganographic schemes embedding in DCT coefficients. We show that, within the JPEG pipeline, the combination of the DCT transform with the quantization function can map several blocks in the pixel domain to the same block in the DCT domain. However, not every DCT block can be obtained: we call those blocks incompatible. In particular, incompatibility can happen when DCT coefficients are manually modified to embed a message. We show that the problem of distinguishing compatible blocks from incompatible ones is an inverse problem with or without solution and we propose two different methods to solve it. The first one is heuristic-based, fast to find a solution if it exists. The second is formulated as an Integer Linear Programming problem and can detect incompatible blocks only for a specific DCT transform in a reasonable amount of time. We show that the probability for a block to become incompatible only relies on the number of modifications. Finally, using the heuristic algorithm we can derive a Likelihood Ratio Test depending on the number of compatible blocks per image to perform steganalysis. We simulate the result of this test and show that it outperforms a deep learning detector e-SRNet for every payload between 0.001 and 0.01 bpp by using only 10% of the blocks from \\bf 256\\times 256\nimages. A Selection-Channel-Aware version of the test is even more powerful and outperforms e-SRNet while using only 1% of the blocks.}
}


@article{DBLP:journals/tifs/ZengHFYL24,
	author = {Chenkai Zeng and
                  Debiao He and
                  Qi Feng and
                  Xiaolin Yang and
                  Qingcai Luo},
	title = {SecureGPT: {A} Framework for Multi-Party Privacy-Preserving Transformer
                  Inference in {GPT}},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9480--9493},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3461408},
	doi = {10.1109/TIFS.2024.3461408},
	timestamp = {Tue, 24 Dec 2024 22:38:16 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZengHFYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generative Pretrained Transformer (GPT) is an advanced natural language processing (NLP) model and is excellent at understanding and generating human language. As GPT is increasingly utilized, more and more cloud inference services for pre-trained generative models are being offered. However, when users upload their data to cloud servers to experience cloud inference services, ensuring the privacy and security of their data becomes a challenge. Thus, in this work, we present SecureGPT, a framework for multi-party privacy-preserving transformer inference in GPT and design a series of building blocks which include M2A (conversion of multiplicative share to additive share), truncation, division, softmax and GELU protocols for our framework. Specifically, we follow the work of SecureNLP and further explore the M2A protocol for non-linear functions such as GELU and softmax. We also design multi-party private protocols for GPT’s transformer sub-layers. Finally we prove the security of our framework in the semi-honest adversary model with all-but-one corruptions. we evaluate the runtime of our framework under different parties settings and our implementation leads to up to 100\\times improvement compared to state-of-the-art works.}
}


@article{DBLP:journals/tifs/TomasinEGMNM24,
	author = {Stefano Tomasin and
                  Tarek N. M. M. Elwakeel and
                  Anna V. Guglielmi and
                  Robin Maes and
                  Nele Noels and
                  Marc Moeneclaey},
	title = {Analysis of Challenge-Response Authentication With Reconfigurable
                  Intelligent Surfaces},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9494--9507},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3471185},
	doi = {10.1109/TIFS.2024.3471185},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TomasinEGMNM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical-layer authentication (PLA) mechanisms exploit signals exchanged at the physical layer of communication systems to confirm the sender of a received message. In this paper, we propose a novel challenge-response PLA (CR-PLA) mechanism for a cellular system that leverages the reconfigurability property of a reconfigurable intelligent surface (RIS) (under the control of the verifier) in an authentication mechanism. In CR-PLA, the verifier base station (BS) sets a random RIS configuration, which remains secret to the intruder, and then checks that the resulting estimated channel is modified correspondingly. In fact, for a message sent by an attacker in a different location than the legitimate user equipment (UE), the BS will estimate a different channel and the message will be rejected as fake. Such a solution reduces the communication and computational overhead with respect to higher-layer cryptographic authentication. We derive the maximum a-posteriori attack when the attacker observes a correlated channel and the reconfigurable intelligent surface (RIS) has many elements, and the attacker transmits to Bob either directly or through the RIS. Using a generalized likelihood ratio test to test the authenticity at the base station (BS), we derive approximate expressions of the false alarm and misdetection probabilities when both the BS and the UE have a single antenna each, while the RIS has a large number of elements. We also evaluate the trade-off between security and communication performance, since choosing a random RIS configuration reduces the data rate. Moreover, we investigate the impact of various parameters (e.g., the RIS randomness, the number of RIS elements, and the operating signal-to-noise ratio) on security and communication performance.}
}


@article{DBLP:journals/tifs/LeeRLP24,
	author = {Joohee Lee and
                  Hansol Ryu and
                  Minju Lee and
                  Jaehui Park},
	title = {Cryptanalysis on "NTRU+: Compact Construction of {NTRU} Using
                  Simple Encoding Method"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9508--9517},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3471074},
	doi = {10.1109/TIFS.2024.3471074},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LeeRLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In IEEE TIFS 2023, NTRU+ has been proposed, an efficient lattice-based post-quantum Key Encapsulation Mechanism (KEM), which has also been submitted to the KpqC competition. In this paper, we propose an effective classical chosen ciphertext attack to recover the transmitted session key for NTRU+ with all but negligible probability for the first time. With the proposed attacks, we show that all the suggested parameters of NTRU+ do not satisfy the claimed IND-CCA security. Moreover, we elaborate on some flaws in the security proof, a part of which introduces our attack. We also suggest a way to modify the NTRU+ scheme to defend our attack while maintaining its practical performance.}
}


@article{DBLP:journals/tifs/TorshiziH24,
	author = {Ehsan Olyaei Torshizi and
                  Werner Henkel},
	title = {Pairwise Physical Layer Secret Key Generation for {FDD} Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9518--9533},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468170},
	doi = {10.1109/TIFS.2024.3468170},
	timestamp = {Mon, 09 Dec 2024 22:46:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/TorshiziH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical-layer secret key generation (PSKG) stands as a promising privacy protection technique, establishing shared encryption keys through the analysis of highly correlated wireless channel measurements. This approach relies on exploiting reciprocal channel characteristics between uplink and downlink transmissions. Nonetheless, the distinct carrier frequencies employed for uplink and downlink in frequency-division duplexing (FDD) systems pose a challenge in identifying common features. This paper presents a novel approach that exploits the inherent reciprocity between scattering parameters of passive two-port networks within same frequency ranges to overcome this obstacle. By capitalizing this reciprocity and considering closely situated FDD bands, a seamless continuity is anticipated in phase differences extracted form the corresponding S-parameters, between neighboring antennas of an antenna array from both uplink and downlink directions. This continuity, thereby ensures consistency in the generated keys from both transmission ends. Furthermore, a two-stage pre-processing method is proposed to enhance performance effectively. Additionally, the paper suggests the utilization of polynomial curve-fitting through measurement data to improve reciprocity and proposes a non-linear framework for quantizing the merging points of the two FDD bands. A statistical analysis employing multiple linear regression is provided to determine the error probability associated with the generated keys. Empirical results validate the feasibility and effectiveness of the proposed key generation scheme, affirming its attributes in terms of randomness, efficiency, key distribution uniformity, and key disagreement ratio (KDR).}
}


@article{DBLP:journals/tifs/ZhangLBHZLLR24,
	author = {Xinyu Zhang and
                  Qingyu Liu and
                  Zhongjie Ba and
                  Yuan Hong and
                  Tianhang Zheng and
                  Feng Lin and
                  Li Lu and
                  Kui Ren},
	title = {FLTracer: Accurate Poisoning Attack Provenance in Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9534--9549},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3410014},
	doi = {10.1109/TIFS.2024.3410014},
	timestamp = {Fri, 21 Feb 2025 08:48:13 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangLBHZLLR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is a promising distributed learning approach that enables multiple clients to collaboratively train a shared global model. However, recent studies show that FL is vulnerable to various poisoning attacks, which can degrade the performance of global models or introduce backdoors into them. In this paper, we first conduct a comprehensive study on prior FL attacks and detection methods. The results show that all existing detection methods are only effective against limited and specific attacks. Most detection methods suffer from high false positives, which lead to significant performance degradation, especially in not independent and identically distributed (non-IID) settings. To address these issues, we propose FLTracer, the first FL attack provenance framework to accurately detect various attacks and trace the attack time, objective, type, and poisoned location of updates. Different from existing methodologies that rely solely on cross-client anomaly detection, we propose a Kalman filter-based cross-round detection to identify adversaries by seeking the behavior changes before and after the attack. Thus, this makes it resilient to data heterogeneity and is effective even in non-IID settings. To further improve the accuracy of our detection method, we employ four novel features and capture their anomalies with the joint decisions. Extensive evaluations show that FLTracer achieves an average true positive rate of over 96.88% at an average false positive rate of less than 2.67%, significantly outperforming SOTA detection methods (https://github.com/Eyr3/FLTracer).}
}


@article{DBLP:journals/tifs/XuCWXL24,
	author = {Keyizhi Xu and
                  Zhan Chen and
                  Zhongyuan Wang and
                  Chunxia Xiao and
                  Chao Liang},
	title = {Toward Robust Adversarial Purification for Face Recognition Under
                  Intensity-Unknown Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9550--9565},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3473293},
	doi = {10.1109/TIFS.2024.3473293},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XuCWXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed dramatic progress in adversarial attacks, which can easily mislead face recognition systems via the injection of imperceptible perturbations on the input image. Many defense methods have been proposed to mitigate the detrimental impact of adversarial attacks, including adversarial purification which intends to reconstruct clean images through a generative model. This paper studies a more practical and challenging problem: how to defend face recognition systems against intensity-unknown or even intensity-varying adversarial attacks? We attempt to crack this tough nut from the dimensionality of input resolutions. Looking into the performance of purification methods with various input resolutions, we reveal a phenomenon that, higher-resolution input images help better defend against weaker attacks, while lower-resolution ones are naturally defensive against stronger attacks. It inspires us to design an adaptive purification framework under intensity-unknown attacks, dubbed adversarial Intensity-guided Multi-scale Attention (IMA). Via the aggregation of information from different resolution scales and flexible adjustment according to an estimation of adversarial intensity, it leverages the respective advantages of different scales and constructs a robust ensemble against intensity-unknown attacks. We validate the superiority of IMA by defending against both face obfuscation and impersonation of 9 typical attack algorithms under gray-box, white-box and black-box evaluation, outperforming state-of-the-art defense methods on LFW and YTF datasets.}
}


@article{DBLP:journals/tifs/ChenYSXFWZ24,
	author = {Changhua Chen and
                  Tingzhen Yan and
                  Chenxuan Shi and
                  Hao Xi and
                  Zhirui Fan and
                  Hai Wan and
                  Xibin Zhao},
	title = {The Last Mile of Attack Investigation: Audit Log Analysis Toward Software
                  Vulnerability Location},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9566--9581},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3459616},
	doi = {10.1109/TIFS.2024.3459616},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenYSXFWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyberattacks have caused significant damage and losses in various domains. While existing attack investigations against cyberattacks focus on identifying compromised system entities and reconstructing attack stories, there is a lack of information that security analysts can use to locate software vulnerabilities and thus fix them. In this paper, we present AiVl, a novel software vulnerability location method to push the attack investigation further. AiVl relies on logs collected by the default built-in system auditing tool and program binaries within the system. Given a sequence of malicious log entries obtained through traditional attack investigations, AiVl can identify the functions responsible for generating these logs and trace the corresponding function call paths, namely the location of vulnerabilities in the source code. To achieve this, AiVl proposes an accurate, concise, and complete specific-domain program modeling that constructs all system call flows by static-dynamic techniques from the binary, and develops effective matching-based algorithms between the log sequences and program models. To evaluate the effectiveness of AiVl, we conduct experiments on 18 real-world attack scenarios and an APT, covering comprehensive categories of vulnerabilities and program execution classes. The results show that compared to actual vulnerability remediation reports, AiVl achieves a 100% precision and an average recall of 90%. Besides, the runtime overhead is reasonable, averaging at 7%.}
}


@article{DBLP:journals/tifs/LiuMWZ24,
	author = {Hang Liu and
                  Yang Ming and
                  Chenhao Wang and
                  Yi Zhao},
	title = {Flexible Selective Data Sharing With Fine-Grained Erasure in VANETs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9582--9597},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3474969},
	doi = {10.1109/TIFS.2024.3474969},
	timestamp = {Mon, 10 Feb 2025 08:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuMWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular ad hoc networks (VANETs), an increasingly significant technology in intelligent transportation systems, achieve information sharing, intelligent traffic flow control, and road condition prediction through data sharing between vehicles and other devices, enhancing traffic efficiency and driving safety. Nevertheless, there are still challenges to data sharing with respect to efficiency, flexibility, and security. In this paper, we build a flexible selective data sharing with fine-grained erasure (FSDS-FE) scheme in VANETs by introducing the novel cryptographic primitive called puncturable identity-based fine-grained proxy re-encryption and employing identity-based signature. In FSDS-FE, with the support for ciphertext transformation, the vehicles are able to flexibly share the outsourced traffic data with others. Different sharing content can be customized for various entities through fine-grained re-encryption to protect sensitive information. Furthermore, the outsourced traffic data could be erased in a fine-grained way by the vehicles. In order to optimize the efficiency and practicality of FSDS-FE, we construct an improved FSDS-FE scheme by designing a novel puncturable identity-based fine-grained broadcast proxy re-encryption with verifiable outsourced decryption scheme. Rigorous security analysis demonstrates that FSDS-FE can achieve the desired security requirements. The comprehensive performance evaluation shows that our schemes are efficient and practical enough in VANETs.}
}


@article{DBLP:journals/tifs/RuanLQ24,
	author = {Song Ruan and
                  Yantao Li and
                  Huafeng Qin},
	title = {{LSFM:} Light Style and Feature Matching for Efficient Cross-Domain
                  Palmprint Recognition},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9598--9612},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3476978},
	doi = {10.1109/TIFS.2024.3476978},
	timestamp = {Wed, 06 Nov 2024 22:17:59 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/RuanLQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The exceptional feature extraction capabilities of deep neural networks (DNNs) have significantly advanced palmprint recognition. However, DNNs typically require training and testing data originate from the same distribution, which limits their practical applications. Moreover, existing unsupervised domain adaptation methods struggle to achieve high accuracy with efficiency. To address these challenges, we propose LSFM, an efficient Light Style and Feature Matching method that enhances palmprint recognition performance in cross-domain scenarios with fewer resources. Specifically, we develop an efficient style transfer model to mitigate domain shifts at the pixel level. We then align features across multiple task-specific layers in high dimensional space to reduce domain discrepancies, further improving cross-domain performance. Finally, we evaluate the effectiveness of the proposed LSFM through extensive experiments on two public multi-domain palmprint databases. The experimental results demonstrate that LSFM achieves superior performance with significantly reduced resource consumption, improving average accuracy to 94.87% and lowering the average equal error rate to 1.46%, while saving over 80% of resources.}
}


@article{DBLP:journals/tifs/YangCPSCDLSYD24,
	author = {Yunbo Yang and
                  Xiang Chen and
                  Yuhao Pan and
                  Jiachen Shen and
                  Zhenfu Cao and
                  Xiaolei Dong and
                  Xiaoguo Li and
                  Jianfei Sun and
                  Guomin Yang and
                  Robert H. Deng},
	title = {OpenVFL: {A} Vertical Federated Learning Framework With Stronger Privacy-Preserving},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9670--9681},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3477924},
	doi = {10.1109/TIFS.2024.3477924},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangCPSCDLSYD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) allows multiple parties, each holding a dataset, to jointly train a model without leaking any information about their own datasets. In this paper, we focus on vertical FL (VFL). In VFL, each party holds a dataset with the same sample space and different feature spaces. All parties should first agree on the training dataset in the ID alignment phase. However, existing works may leak some information about the training dataset and cause privacy leakage. To address this issue, this paper proposes OpenVFL, a vertical federated learning framework with stronger privacy-preserving. We first propose NCLPSI, a new variant of labeled PSI, in which both parties can invoke this protocol to get the encrypted training dataset without leaking any additional information. After that, both parties train the model over the encrypted training dataset. We also formally analyze the security of OpenVFL. In addition, the experimental results show that OpenVFL achieves the best trade-offs between accuracy, performance, and privacy among the most state-of-the-art works.}
}


@article{DBLP:journals/tifs/JafarYLZG24,
	author = {Mousa Tayseer Jafar and
                  Lu{-}Xing Yang and
                  Gang Li and
                  Qingyi Zhu and
                  Chenquan Gan},
	title = {Minimizing Malware Propagation in Internet of Things Networks: An
                  Optimal Control Using Feedback Loop Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9682--9697},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463965},
	doi = {10.1109/TIFS.2024.3463965},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JafarYLZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite extensive research on optimal control formulations for cyber threat mitigation, a significant gap persists between theoretical and practical implementation in real-time scenarios. The open-loop structure of the optimal control framework is insufficiently robust for effectively addressing cyber threats. To overcome this, adopting a model learning process that iteratively updates the optimal control strategy is proposed. This paper proposes an innovative approach to addressing cybersecurity attacks in the Internet of Things (IoT) networks by integrating reinforcement learning (RL) and model predictive control (MPC) in a hybrid framework to optimize control parameters and enhance system effectiveness in combating malware. This novel approach aims to overcome the limitations of the previous approaches and establish superior control strategies for IoT network security. This approach enhances the adaptability and responsiveness of the mitigation process, improving the handling of evolving cyber threats in real-world applications. This framework enhances the security and resilience of IoT networks against malicious activities, offering a robust solution for mitigating cyber threats by leveraging RL algorithms and the proactive capabilities of MPC. A comprehensive evaluation demonstrates the effectiveness and efficiency of the hybrid framework, highlighting its potential to protect IoT networks from evolving cybersecurity risks. The primary aim extends beyond using an RL agent solely for computing control actions to optimize closed-loop performance and stability. It also leverages RL to estimate model parameters that are currently unknown but within known bounds. Our main objective in using the RL agent is to accurately estimate unidentified model parameters within specified limits. The simulation results provide compelling evidence supporting the effectiveness of this methodology in mitigating malware propagation, highlighting its superior performance compared to state-of-the-art methods. RLMPC rapidly initiated recovery, achieving full network restoration in 8 seconds and recovering 60 IoT devices. Also, the evaluation focused on average speed, scalability, and performance under various cyber-attack scenarios.}
}


@article{DBLP:journals/tifs/ChenZJZS24,
	author = {Zhuo Chen and
                  Liehuang Zhu and
                  Peng Jiang and
                  Zijian Zhang and
                  Chengxiang Si},
	title = {Blockchain-Based Covert Communication: {A} Detection Attack and Efficient
                  Improvement},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9698--9713},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3478834},
	doi = {10.1109/TIFS.2024.3478834},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenZJZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Covert channels in blockchain networks achieve undetectable and reliable communication, while transactions incorporating secret data are perpetually stored on the chain, thereby leaving the secret data continuously susceptible to extraction. MTMM (IEEE Transactions on Computers 2023) is a state-of-the-art blockchain-based covert channel. It utilizes Bitcoin network traffic that will not be recorded on the chain to embed data, thus mitigating the above issues. However, we identify a distinctive pattern in MTMM, based on which we propose a comparison attack to accurately detect MTMM traffic. To defend against the attack, we present an improvement named ORIM, which exploits the permutation of transaction hashes within inventory messages to transmit secret data. ORIM leverages a pseudo-random function to obscure the transaction hashes involved in the permutation to ensure unobservability. The obfuscated values, rather than the original transaction hashes, are utilized to encode the confidential data. Furthermore, we introduce a variable-length encoding scheme predicated on complete binary trees. This scheme considerably amplifies the bandwidth and facilitates efficient encoding and decoding of secret data. Experimental results indicate that ORIM maintains unobservability and that ORIM’s bandwidth is approximately 3.7\\times of MTMM.}
}


@article{DBLP:journals/tifs/DongYDGWCFS24,
	author = {Qihao Dong and
                  Shengyuan Yang and
                  Zhiyang Dai and
                  Yansong Gao and
                  Shang Wang and
                  Yuan Cao and
                  Anmin Fu and
                  Willy Susilo},
	title = {CareFL: Contribution Guided Byzantine-Robust Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9714--9729},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3477912},
	doi = {10.1109/TIFS.2024.3477912},
	timestamp = {Mon, 02 Dec 2024 08:13:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/DongYDGWCFS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Byzantine-robust federated learning (FL) endeavors to empower service providers in acquiring a precise global model, even in the presence of potentially malicious FL clients. While considerable strides have been taken in the development of robust aggregation algorithms for FL in recent years, their efficacy is confined to addressing particular forms of Byzantine attacks, and they exhibit vulnerabilities when confronted with a spectrum of attack vectors. Notably, a prevailing issue lies in the heavy reliance of these algorithms on the examination of local model gradients. It is worth noting that an attacker possesses the ability to manipulate a carefully chosen small gradient of a model within a context where there could be millions of gradients available, thereby facilitating adaptive attacks. Drawing inspiration from the foundational Shapley value methodology in game theory, we introduce an effective FL scheme named CareFL. This scheme is designed to provide robustness against a spectrum of state-of-the-art Byzantine attacks. Unlike approaches that rely on the examination of gradients, CareFL employs a universal metric, the loss of the local model—independent of specific gradients, to identify potentially malicious clients. Specifically, in each aggregation round, the FL server trains a reference model using a small auxiliary dataset— the auxiliary dataset can be removed with a slight defense degradation trade-off. It employs the Shapley value to assess the contribution of each client-submitted model in minimizing the global model loss. Subsequently, the server selects client models closer to the reference model in terms of Shapley values for the global model update. To reduce the computational overhead of CareFL when the number of clients is relatively scaled-up, we construct its variant, namely CareFL+ generally by grouping clients. Extensive experimentation conducted on well-established MNIST and CIFAR-10 datasets, encompassing diverse model architectures, including AlexNet, demonstrates that CareFL consistently achieves accuracy levels comparable to those attained under attack-free conditions when faced with five formidable attacks. CareFL and CareFL+ outperform six existing state-of-the-art Byzantine-robust FL aggregation methods, including FLTrust, across both IID and non-IID data distribution settings.}
}


@article{DBLP:journals/tifs/LiSXXRZGFL24,
	author = {Ziqiang Li and
                  Hong Sun and
                  Pengfei Xia and
                  Beihao Xia and
                  Xue Rui and
                  Wei Zhang and
                  Qinglang Guo and
                  Zhangjie Fu and
                  Bin Li},
	title = {A Proxy Attack-Free Strategy for Practically Improving the Poisoning
                  Efficiency in Backdoor Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9730--9743},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3472510},
	doi = {10.1109/TIFS.2024.3472510},
	timestamp = {Wed, 26 Feb 2025 08:16:45 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiSXXRZGFL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Poisoning efficiency is crucial in poisoning-based backdoor attacks, as attackers aim to minimize the number of poisoning samples while maximizing attack efficacy. Recent studies have sought to enhance poisoning efficiency by selecting effective samples. However, these studies typically rely on a proxy backdoor injection task to identify an efficient set of poisoning samples. This proxy attack-based approach can lead to performance degradation if the proxy attack settings differ from those of the actual victims, due to the shortcut nature of backdoor learning. Furthermore, proxy attack-based methods are extremely time-consuming, as they require numerous complete backdoor injection processes for sample selection. To address these concerns, we present a Proxy attack-Free Strategy (PFS) designed to identify efficient poisoning samples based on the similarity between clean samples and their corresponding poisoning samples, as well as the diversity of the poisoning set. The proposed PFS is motivated by the observation that selecting samples with high similarity between clean and corresponding poisoning samples results in significantly higher attack success rates compared to using samples with low similarity. Additionally, we provide theoretical foundations to explain the proposed PFS. We comprehensively evaluate the proposed strategy across various datasets, triggers, poisoning rates, architectures, and training hyperparameters. Our experimental results demonstrate that PFS enhances backdoor attack efficiency while also offering a remarkable speed advantage over previous proxy attack-based selection methodologies.}
}


@article{DBLP:journals/tifs/WangCWMGQZ24,
	author = {Hao Wang and
                  Yichen Cai and
                  Jun Wang and
                  Chuan Ma and
                  Chunpeng Ge and
                  Xiangmou Qu and
                  Lu Zhou},
	title = {Voltran: Unlocking Trust and Confidentiality in Decentralized Federated
                  Learning Aggregation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9744--9759},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3472531},
	doi = {10.1109/TIFS.2024.3472531},
	timestamp = {Sat, 11 Jan 2025 00:33:54 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangCWMGQZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The decentralized Federated Learning (FL) paradigm built upon blockchain architectures leverages distributed node clusters to replace the single server for executing FL model aggregation. This paradigm tackles the vulnerability of the centralized malicious server in vanilla FL and inherits the trustfulness and robustness offered by blockchain. However, existing blockchain-enabled schemes face challenges related to inadequate confidentiality on models and limited computational resources of blockchains. In this paper, we present Voltran, an innovative hybrid platform designed to achieve trust, confidentiality, and robustness for FL based on the combination of the Trusted Execution Environment (TEE) and blockchain technology. We offload the FL aggregation computation into TEE to provide an isolated, trusted and customizable off-chain execution and then guarantee the authenticity and verifiability of aggregation results on the blockchain. Moreover, we provide strong scalability on multiple FL scenarios by introducing a multi-SGX parallel execution strategy to amortize the large-scale FL workload. We implement a prototype of Voltran and conduct a comprehensive performance evaluation. Extensive experimental results demonstrate that Voltran incurs minimal additional overhead while guaranteeing trust, confidentiality, and authenticity, and it significantly brings a significant speed-up compared to state-of-the-art ciphertext aggregation schemes.}
}


@article{DBLP:journals/tifs/LyuZRWG24,
	author = {Qiuyun Lyu and
                  Yilong Zhou and
                  Yizhi Ren and
                  Zhen Wang and
                  Yunchuan Guo},
	title = {Toward Personal Data Sharing Autonomy: {A} Task-Driven Data Capsule
                  Sharing System},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9760--9774},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3472529},
	doi = {10.1109/TIFS.2024.3472529},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LyuZRWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personal data custodian services enable data owners to share their data with data consumers in a convenient manner, anytime and anywhere. However, with data hosted in these services being beyond the control of the data owners, it raises significant concerns about privacy in personal data sharing. Many schemes have been proposed to realize fine-grained access control and privacy protection in data sharing. However, they fail to protect the rights of data owners to their data under the law, since their designs focus on the management of system administrators rather than enhancing the data owners’ privacy. In this paper, we introduce a novel task-driven personal data sharing system based on the data capsule paradigm realizing personal data sharing autonomy. It enables data owners in our system to fully control their data, and share it autonomously. Specifically, we present a tamper-resistant data capsule encapsulation method, where the data capsule is the minimal unit for independent and secure personal data storage and sharing. Additionally, to realize selective sharing and informed-consent based authorization, we propose a task-driven data sharing mechanism that is resistant to collusion and EDoS attacks. Furthermore, by updating parts of the data capsules, the permissions granted to data consumers can be immediately revoked. Finally, we conduct a security and performance analysis, proving that our scheme is correct, sound, and secure, as well as revealing more advantageous features in practicality, compared with the state-of-the-art schemes.}
}


@article{DBLP:journals/tifs/JiZZLC24,
	author = {Xiaopeng Ji and
                  Ruizhi Zhu and
                  Qiaosheng Eric Zhang and
                  Chunguo Li and
                  Daming Cao},
	title = {Enhancing Covert Communication in {OOK} Schemes by Phase Deflection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9775--9788},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3480365},
	doi = {10.1109/TIFS.2024.3480365},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiZZLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work proposes an On-Off Keying (OOK) coding scheme for covert communication over complex Gaussian channels. In particular, a transmitter Alice employs phase deflection to covertly transmit information to a receiver Bob, simultaneously ensuring that the communication intent is concealed from a warden Willie. The utilization of phase deflection allows Alice to improve the transmission rate by leveraging Willie’s uncertainty about the received phase, without changing the codebook construction. Considering the asymmetry of the OOK codebook’s input distribution and shape constellation, we first analyze the relationship between the input distribution and the signal amplitude, and then propose a scheme that can achieve covert transmission with the input distribution of the “on” symbol a_{n}=\\mathcal {O}\\left ({{\\frac {1}{\\sqrt {n}}}}\\right)\nand an average transmission power \\beta ^{2}=\\mathcal {O}({1})\n. We quantify the improvement brought from the phase resource as phase deflection gain and derive its closed-form expression by approximating the Kullback-Leibler (KL) divergence and mutual information through Taylor expansion. Numerical results show that our scheme achieves significant phase deflection gain, and the maximum gain can be achieved by fully utilizing the phase resources through three stages.}
}


@article{DBLP:journals/tifs/ChengYZGYL24,
	author = {Xiaojuan Cheng and
                  Lu{-}Xing Yang and
                  Qingyi Zhu and
                  Chenquan Gan and
                  Xiaofan Yang and
                  Gang Li},
	title = {Cost-Effective Hybrid Control Strategies for Dynamical Propaganda
                  War Game},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9789--9802},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3468903},
	doi = {10.1109/TIFS.2024.3468903},
	timestamp = {Mon, 03 Mar 2025 22:25:01 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChengYZGYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber propaganda wars significantly impact users on Online Social Networks (OSNs), potentially altering their psychological/ideological attitudes and behaviors. Understanding these behavioral dynamics necessitates models that can effectively capture the propagation of dual competitive information, encompassing both propaganda and counter-propaganda campaigns by both conflicting parties. However, current models do not adequately account for competitive information spreading in dual setting and it lacks efficient strategies for managing both propaganda and counter-propaganda investments. To bridge these gaps, our study presents an innovative netwORked dIfferENTial gAme wiTh hybrId cONtrol (ORIENTATION) framework that integrates differential game with 1) a degree-based network model characterizing the spreading dynamics of dual competitive information for both parties; and 2) a dual hybrid control mechanism consisting of investment rates by continuous-time propaganda and discrete-time counter-propaganda. Using this framework, we formulate the Hybrid-contrOlled Differential GamE (HODGE) problem. We theoretically derive the necessary conditions for Nash equilibrium, and develop an iterative algorithm, termed the HODGE algorithm, to numerically approximate the Nash equilibrium. Our experiments, performed on different groups of OSNs, reveal that the resulting strategy profiles consistently outperform several alternative profiles in terms of cost-effectiveness. Scalability assessment for the HODGE algorithm is then carried out on OSNs with different scales, demonstrating its strong performance in terms of computational efficiency, scalability and practicability. Additional experimental results suggest that a decrease in the lower bounds of the investment rates in both propaganda and counter-propaganda campaigns and an early implementation of counter-propaganda strategies can significantly enhance cost-effectiveness, offering strategic insights for those engaged in cyber propaganda war.}
}


@article{DBLP:journals/tifs/MouGZWZW24,
	author = {Ningping Mou and
                  Binqing Guo and
                  Lingchen Zhao and
                  Cong Wang and
                  Yue Zhao and
                  Qian Wang},
	title = {No-Box Universal Adversarial Perturbations Against Image Classifiers
                  via Artificial Textures},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9803--9818},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3478828},
	doi = {10.1109/TIFS.2024.3478828},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/MouGZWZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advancements in adversarial attack research have seen a transition from white-box to black-box and even no-box threat models, greatly enhancing the practicality of these attacks. However, existing no-box attacks focus on instance-specific perturbations, leaving more powerful universal adversarial perturbations (UAPs) unexplored. This study addresses a crucial question: can UAPs be generated under a no-box threat model? Our findings provide an affirmative answer with a texture-based method. Artificially crafted textures can act as UAPs, termed Texture-Adv. With a modest density and a fixed budget for perturbations, it can achieve an attack success rate of 80% under the constraint of l_{\\infty }\n= 10/255. In addition, Texture-Adv can also take effect under traditional black-box threat models. Building upon a phenomenon associated with dominant labels, we utilize Texture-Adv to develop a highly efficient decision-based attack strategy, named Adv-Pool. This approach creates and traverses a set of Texture-Adv instances with diverse classification distributions, significantly reducing the average query budget to less than 1.3, which is near the 1-query lower bound for decision-based attacks. Moreover, we empirically demonstrate that Texture-Adv, when used as a starting point, can enhance the success rates of existing transfer attacks and the efficiency of decision-based attacks. The discovery suggests its potential as an effective starting point for various adversarial attacks while preserving the original constraints of their threat models.}
}


@article{DBLP:journals/tifs/WangLYYY24,
	author = {Rui Wang and
                  Longlong Li and
                  Guozheng Yang and
                  Xuehu Yan and
                  Wei Yan},
	title = {Secret Cracking and Security Enhancement for the Image Application
                  of CRT-Based Secret Sharing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9819--9834},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3477265},
	doi = {10.1109/TIFS.2024.3477265},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WangLYYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Asmuth and Bloom threshold secret sharing (AB-SS) is a classical introduction of the Chinese remainder theorem (CRT) to secret sharing, offering low computational complexity compared to other branches of secret sharing. For decades, numerous schemes have been proposed for practical applications of AB-SS, such as secret image sharing (SIS). However, in terms of security, AB-SS has proved to be neither ideal nor perfect, and its derivatives in image sharing exhibit vulnerabilities associated with secret leakage. This paper studies the security issues in the SIS schemes derived from AB-SS and improves the core sharing principle of AB-SS to enhance security in image protection. First, for (2,n) -CRTSIS schemes, we exploit the vulnerability in a single share image to crack the confidential information of the original image, including secret pixel values and the ratio of different pixels. Then, by employing the XOR operation, we introduce a chain obfuscation technology and propose a secure image sharing scheme based on the Chinese remainder theorem (COxor-CRTSIS). The COxor-CRTSIS scheme utilizes integer linear programming for achieving lossless recovery without segmentation and eliminates potential secret disclosure risks without additional encryption. Furthermore, to comprehensively evaluate the security of existing schemes, this paper presents three metrics, information loss rate, fluctuation degree, and coverage rate, enabling a quantitative comparison of security for the first time. Theoretical analyses and experiments are conducted to validate the effectiveness of our scheme.}
}


@article{DBLP:journals/tifs/ChenZXL24,
	author = {Fei Chen and
                  Haohui Zhang and
                  Tao Xiang and
                  Joseph K. Liu},
	title = {A Two-Stage Approach for Fair Data Trading Based on Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9835--9849},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3482716},
	doi = {10.1109/TIFS.2024.3482716},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenZXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How to enable fairness for e-commerce applications has attracted years of research. Recent research has proposed employing blockchain smart contract as an efficient trusted third party (TTP) to enable fair data trading. However, the state-of-the-art schemes suffer from two issues, i.e., they either fail to work for situations where data validity cannot be encoded as an oracle function in the smart contract, or leak data to attackers for free. To resolve these issues, this paper proposes a two-stage approach for blockchain-based fair data trading. The main idea is to employ a lightweight off-chain TTP and an on-chain smart contract to handle dispute issues. Both the TTP and smart contract only require a logarithmic complexity for making arbitration in case of disputes; moreover, they are not invoked when there is no dispute. The rationale is that although the off-chain TTP cannot be eliminated, it is only needed in a minimal sense to judge the validity of the traded data. The proposed approach designs a new cryptographic protocol that combines sampling, commitment schemes, and encryption schemes to achieve this logarithmic efficiency. The proposed approach also features privacy protection. Experimental evaluation of the public Ethereum blockchain confirms that the proposed approach is practically usable. Specifically, for a dataset of 15GB, the off-chain computation for each trading party costs approximately 80 seconds while on-chain computation costs around 30 seconds; the additional storage cost is around 9MB; the gas cost is approximately 2.23 million GWei.}
}


@article{DBLP:journals/tifs/SunYHDXWZX24,
	author = {Xinyue Sun and
                  Qingqing Ye and
                  Haibo Hu and
                  Jiawei Duan and
                  Qiao Xue and
                  Tianyu Wo and
                  Weizhe Zhang and
                  Jie Xu},
	title = {Generating Location Traces With Semantic- Constrained Local Differential
                  Privacy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9850--9865},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3480712},
	doi = {10.1109/TIFS.2024.3480712},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SunYHDXWZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Valuable information and knowledge can be learned from users’ location traces and support various location-based applications such as intelligent traffic control, incident response, and COVID-19 contact tracing. However, due to privacy concerns, no authority could simply collect users’ private location traces for mining or even publishing. To echo such concerns, local differential privacy (LDP) enables individual privacy by allowing each user to report a perturbed version of their data. Unfortunately, when applied to location traces, LDP cannot preserve the semantics in the context of location traces because it treats all locations (i.e., various points of interest) as equally sensitive. This results in a low utility of LDP mechanisms for collecting location traces. In this paper, we address the challenge of collecting and sharing location traces with valuable semantics while providing sufficient privacy protection for participating users. We first propose semantic-constrained local differential privacy (SLDP), a new privacy model to provide a provable mathematical privacy guarantee while preserving desirable semantics. Then, we design a location trace perturbation mechanism (LTPM) that users can use to perturb their traces in a way that satisfies SLDP. Finally, we propose a private location trace synthesis (PLTS) framework in which users use LTPM to perturb their traces before sending them to the collector, who aggregates the users’ perturbed data to generate location traces with valuable semantics. Extensive experiments on three real-world datasets demonstrate that our PLTS outperforms existing state-of-the-art methods by at least 21% in a range of real-world applications, such as spatial visiting queries and frequent pattern mining, under the same privacy leakage.}
}


@article{DBLP:journals/tifs/ShiHJC24,
	author = {Caiqun Shi and
                  Qinlong Huang and
                  Rui Jian and
                  Genghui Chi},
	title = {Cross-Domain Inner-Product Access Control Encryption for Secure {EMR}
                  Flow in Cloud Edge},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9866--9880},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3482724},
	doi = {10.1109/TIFS.2024.3482724},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ShiHJC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The quality of medical services is improved by sharing electronic medical records (EMRs) across multiple medical institutions via cloud edge. However, EMRs contain private information about patients, and cloud servers are untrustworthy, thus they cannot be shared arbitrarily among senders and receivers. Access control encryption (ACE) is a preferred technique that produces encrypted EMRs and then restricts the capabilities of both senders and receivers to enforce the EMR flow via sanitizers. However, existing cross-domain ACE schemes employ a single sender authority to issue encryption keys for senders, which suffers from single point of failure and encryption key escrow that the sender authority can public EMRs arbitrarily. Moreover, they only support coarse-grained access structures such as AND gates, which is not suitable for flexible EMR sharing among medical institutions. To this end, we propose a cross-domain inner-product ACE (CD-IPACE) scheme that features decentralized encryption key generation and fine-grained access structures. Specifically, we construct CD-IPACE from inner-product encryption, threshold structure-preserving signature instantiated with a distributed key generation protocol, and non-interactive zero-knowledge proof, which prevents individual sender authorities from sending ciphertexts, and also protects both data and receiver privacy. Then, we design a secure EMR flow system in cloud edge named ESFlow based on CD-IPACE, which employs edge nodes as sanitizers to check encrypted EMRs and discard illegal ones. Finally, we demonstrate the security and practicality of ESFlow via formal security analysis and extensive experiments.}
}


@article{DBLP:journals/tifs/GaoMZSJHZ24,
	author = {Ya Gao and
                  Haocheng Ma and
                  Qizhi Zhang and
                  Xintong Song and
                  Yier Jin and
                  Jiaji He and
                  Yiqiang Zhao},
	title = {EMSim+: Accelerating Electromagnetic Security Evaluation With Generative
                  Adversarial Network and Transfer Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9881--9893},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3483551},
	doi = {10.1109/TIFS.2024.3483551},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GaoMZSJHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Electromagnetic side-channel analysis (EM SCA) attack poses a serious threat to integrated circuits (ICs), necessitating timely vulnerability detection before deployment to enhance EM side-channel security. Various EM simulation methods have emerged for analyzing EM side-channel leakage, providing sufficiently accurate results. However, these simulator-based methods still face two principal challenges in the design process of high security chips. Firstly, the large volume of measurement data required for a single security evaluation results in substantial time overhead. Secondly, design iterations lead to repetitive security evaluations, thus increasing the evaluation cost. In this paper, we propose EMSim+ which includes two efficient and accurate layout-level EM side-channel leakage evaluation frameworks named EMSim+GAN and EMSim+GAN+TL to mitigate the above challenges, respectively. EMSim+GAN integrates a Generative Adversarial Network (GAN) model that utilizes the chip’s cell current and power grid information to predict EM emanations quickly. EMSim+GAN+TL further incorporates transfer learning (TL) within the framework, leveraging the experience of existing designs to reduce the training datasets for new designs and achieve the target accuracy. We compare the simulation results of EMSim+ with the state-of-the-art EM simulation tool, EMSim as well as silicon measurements. Experimental results not only prove the high efficiency and high simulation accuracy of EMSim+, but also verify its generalization ability across different designs and technology nodes.}
}


@article{DBLP:journals/tifs/YuWZSC24,
	author = {Ningning Yu and
                  Jiajun Wu and
                  Chengwei Zhou and
                  Zhiguo Shi and
                  Jiming Chen},
	title = {Open Set Learning for RF-Based Drone Recognition via Signal Semantics},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9894--9909},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3463535},
	doi = {10.1109/TIFS.2024.3463535},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YuWZSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The abuse of drones has raised critical concerns about public security and personal privacy, bringing an urgent requirement for drone recognition. Existing radio frequency (RF)-based recognition methods follow the assumption of the closed set, resulting in the unknown signals being misclassified as known classes. To address this problem, we propose a Signal Semantic-based open Set Recognition (S3R) method in this paper. First, the short-time Fourier transform is introduced to construct the signal spectra, decoupling the drone signals with other interference signals. Then, we design a texture extractor and a position extractor to extract the texture features and position features from the spectra, respectively. The extracted features are further fused and structurally optimized to construct distinguishable signal semantics. Based on the structural characteristics of signal semantics, an outlier analysis-based semantic classifier is proposed, which searches the outliers of each known class in the closed set as the bounding thresholds to detect unknown instances. Finally, the detected unknown instances are further classified into their exact classes by implementing clustering in a new semantic space, where semantics are augmented by introducing basic features from the intermediate layers of the texture extractor. Besides, a real-world spectrogram dataset of commonly-used drones is released, which includes 24 classes and covers 7 brands. Extensive experiments demonstrate that the proposed S3R method outperforms the state-of-the-art methods in terms of accuracy and generalizability for both the closed set and the open set.}
}


@article{DBLP:journals/tifs/ChenLLW24,
	author = {Liqing Chen and
                  Jiayi Li and
                  Jiguo Li and
                  Jian Weng},
	title = {{PAESS:} Public-Key Authentication Encryption With Similar Data Search
                  for Pay-Per-Query},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9910--9923},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3484155},
	doi = {10.1109/TIFS.2024.3484155},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenLLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, many cloud service providers adopt the pay-per-query model to offer paid search services to the public. The data owner rents the resources of cloud service providers and charges the data user a fee based on the data volume to be queried. While this commercial model offers flexibility, convenience, and cost-effectiveness, it comes with a significant vulnerability to data breaches. Public-key authentication encryption with keyword search (PAEKS) is a technology which is well applied in the pay-per-query model. But there is no PAEKS scheme applicable to this scenario. For this purpose, we present public-key authentication encryption with similar data search for pay-per-query (PAESS) and construct the first idiographic scheme PAESS-I. PAESS-I utilizes Shamir secret sharing and locality sensitive hashing to implement similar data search, has the verifiability of results, adds the charge function to prevent cloud servers and data users from colluding to deny deductions. We propose the second scheme PAESS-II based on PAESS-I, which is a mobile-friendly lightweight PAESS. Our second scheme operates in the pay-per-query model without pairing and exponential operations. PAESS-I satisfies ciphertext indistinguishability and trapdoor indistinguishability, and sacrifices the computational performance in favor of the pay-per-query model. The optimized PAESS-II is resistant to adaptively-chosen-targets attack, and satisfies ciphertext indistinguishability and trapdoor indistinguishability. PAESS-II distinguishes itself from other existing similar schemes by having the same characteristics as PAESS-I, along with the benefits when it comes to the calculation cost.}
}


@article{DBLP:journals/tifs/YangYWLWZ24,
	author = {Jingjing Yang and
                  Wenjia Yu and
                  Jiajing Wu and
                  Dan Lin and
                  Zhiying Wu and
                  Zibin Zheng},
	title = {2DynEthNet: {A} Two-Dimensional Streaming Framework for Ethereum Phishing
                  Scam Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9924--9937},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3484296},
	doi = {10.1109/TIFS.2024.3484296},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangYWLWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, phishing scams have emerged as one of the most serious crimes on Ethereum. Existing phishing scam detection methods typically model public transaction records on the blockchain as a graph, and then identify phishing addresses through manual feature extraction or graph learning frameworks. Meanwhile, these methods model transactions within a period as a static network for analysis. Therefore, these methods lack the ability to capture fine-grained time dynamics, and on the other hand, they cannot handle the large-scale and continuously growing transaction data on the Ethereum blockchain, resulting in lower scalability and efficiency. In this paper, we propose a two-dimensional streaming framework 2DynEthNet for Ethereum phishing scam detection. First, we cast the transaction series into 6 slices according to block numbers, treating each as a separate task. In the first dimension, we treat transaction features as edge features instead of node features within one task, allowing each transaction to be streamed in 2DynEthNet, aiming to capture the evolutionary features of the Ethereum transaction network at a fine-grained level in continuous time. In the second dimension, we adopt the strategy of incremental information training between tasks, which utilizes meta-learning to quickly update the model parameters under new slices, thus effectively improving the scalability of the model. Finally, experimental results on large-scale real Ethereum phishing scam datasets show that our 2DynEthNet outperforms the state-of-the-art methods with 28.44% average Recall and achieves the most efficient training speed, proving the effectiveness of both temporal edge representation and meta-learning. In addition, we provide an Ethereum large-scale dynamic graph transaction dataset, ETGraph, which aligns with the data distribution in real transaction scenarios without sampling and filtering unlabeled accounts.}
}


@article{DBLP:journals/tifs/ChenFXWG24,
	author = {Xiaofang Chen and
                  Xue Fu and
                  Wenbo Xu and
                  Yue Wang and
                  Guan Gui},
	title = {Joint Variational Modal Decomposition for Specific Emitter Identification
                  With Multiple Sensors},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9938--9953},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3482861},
	doi = {10.1109/TIFS.2024.3482861},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenFXWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Specific emitter identification (SEI) is important to guarantee the security of device administration. Recently, to increase the effectiveness of the recognition, traditional SEI employing only one sensor has been extended to the scenario with multiple sensors. However, the inherent distortion at different sensors impacts the radio frequency fingerprints (RFFs) of the emitter independently, which inevitably leads to the non-universalization of the features extracted at different sensors. Besides, variational modal decomposition (VMD), which is an effective preprocessing in SEI, has not been well investigated in noisy scenarios. To combat the environment noise, this paper proposes two joint VMD (JVMD) algorithms, i.e., JVMD for ignoring the distortions at sensors (I-JVMD) and JVMD for considering the distortions at sensors (C-JVMD). Specifically, I-JVMD exploits the consistency of the central frequencies and intrinsic modal functions (IMFs) of multiple sensors, and C-JVMD further estimates and filters out the phase noise at each sensor that may distort the RFFs of the emitter. Simulations of the proposed JVMD algorithms and their corresponding applications in SEI are provided on two real-world datasets. When compared with the traditional VMD, the proposed ones improve the accuracy of device classification and the robustness towards noise.}
}


@article{DBLP:journals/tifs/WuLK24,
	author = {Jiahong Wu and
                  Nan Liu and
                  Wei Kang},
	title = {The Capacity Region of Distributed Multi-User Secret Sharing Under
                  Perfect Secrecy},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9954--9969},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3484666},
	doi = {10.1109/TIFS.2024.3484666},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WuLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of distributed multi-user secret sharing (DMUSS), involving a main node, N storage nodes, and K users. Every user has access to the contents of a certain subset of storage nodes and wants to decode an independent secret message. With knowledge of K secret messages, the main node strategically places encoded shares in the storage nodes, ensuring two crucial conditions: (i) each user can recover its own secret message from the storage nodes that it has access to; (ii) each user is unable to acquire any information regarding the collection of K-1\nsecret messages for all the other users. The rate of each user is defined as the size of its secret message normalized by the size of a storage node. We characterize the capacity region of the DMUSS problem, which is the closure of the set of all achievable rate tuples that satisfy the correctness and perfect secrecy conditions. The converse proof relies on a bound from the traditional single-secret sharing regime. In the achievability proof, we firstly design the linear decoding functions, based on the fact that each secret message needs to be recovered from a single set of storage nodes. It turns out that the perfect secrecy condition holds if K matrices, whose entries are extracted from the decoding functions, are full rank. We prove that the decoding functions can be constructed explicitly if the rate tuple satisfies the converse and the field size is not less than K. At last, the encoding functions are obtained by solving the system of linear decoding functions, where some shares are equal to the randomness and the other shares are linear combinations of the secret messages and the randomness.}
}


@article{DBLP:journals/tifs/WeiLH24,
	author = {Kangkang Wei and
                  Weiqi Luo and
                  Jiwu Huang},
	title = {Color Image Steganalysis Based on Pixel Difference Convolution and
                  Enhanced Transformer With Selective Pooling},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9970--9983},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3486027},
	doi = {10.1109/TIFS.2024.3486027},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WeiLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current deep learning-based steganalyzers often depend on specific image dimensions, leading to inevitable adjustments in network structure when dealing with varied image sizes. This impedes their effectiveness in managing the wide range of image sizes commonly found on social media. To address this issue, our paper presents a novel steganalytic network that is optimized for fixed-size (notably, 256\\times 256 ) color images, but is capable of efficiently detecting stego images of arbitrary size without needing retraining or modifications to the network. Our proposed network is comprised of four modules. In the initial stem module, we calculate truncated residuals for each color channel of the input image. Diverging from existing steganalytic networks that rely on vanilla convolution, we have developed a pixel difference convolution module designed to better capture the artifacts introduced by steganography. Following this, we introduce an enhanced Transformer module with selective pooling, aimed at more effectively extracting global steganalytic features. To guarantee our network’s adaptability to different image sizes, we have developed a selective pooling strategy. This involves using global covariance pooling for fixed-size color images and spatial pyramid pooling for color images of various other sizes. This approach effectively standardizes the feature maps into uniform feature vectors. The final module is focused on classification. Extensive testing results on the ALASKA II color image dataset have demonstrated that our approach significantly improves detection performance for both fixed-size and arbitrary-size images, achieving state-of-the-art results. Additionally, we provide numerous ablation studies to confirm the effectiveness and soundness of our proposed network architecture.}
}


@article{DBLP:journals/tifs/SarjanAAG24,
	author = {Hamed Sarjan and
                  Mohammadmahdi Asghari and
                  Amir Ameli and
                  Mohsen Ghafouri},
	title = {Mitigating Propagation of Cyber-Attacks in Wide-Area Measurement Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {9984--9999},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3477269},
	doi = {10.1109/TIFS.2024.3477269},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SarjanAAG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wide Area Measurement Systems (WAMSs) are used in power networks to improve the situational awareness of the operator, as well as to facilitate real-time control and protection decisions. In WAMSs, Phasor Data Concentrators (PDCs) collect time-synchronized data of Phasor Measurement Units (PMUs) through the communication system, and direct it to the control center to be used in wide-area control and protection applications. Due to the dependence of WAMSs on information and communication technologies, cyber-attacks can target these systems and propagate through them, i.e., infect a greater number of components by accessing and controlling a few of them. On this basis, this paper initially develops a Learning-Based Framework (LBF) to estimate the required defense strategy to counter the propagation of cyber-attacks in WAMSs. Afterwards, through solving a linear Binary Integer Programming (BIP) problem, this paper develops a mitigation strategy to optimally reconfigure the communication network and reduce the contamination probability for critical PMUs and PDCs while maintaining the observability of the grid. The simulation results obtained from IEEE 14- and 30-bus test systems corroborate the effectiveness of the proposed LBF and communication network reconfiguration strategy in mitigating the propagation of cyber-attacks in WAMSs.}
}


@article{DBLP:journals/tifs/LiYLYZH24,
	author = {Jiajia Li and
                  Qian Yi and
                  Ming Kim Lim and
                  Shuping Yi and
                  Pengxing Zhu and
                  Xingjun Huang},
	title = {MBBFAuth: Multimodal Behavioral Biometrics Fusion for Continuous Authentication
                  on Non-Portable Devices},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10000--10015},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3480363},
	doi = {10.1109/TIFS.2024.3480363},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiYLYZH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous authentication based on behavioral biometrics is effective and crucial as user behaviors are not easily copied. However, relying solely on one behavioral biometric limits the accuracy of continuous authentication. Therefore, a continuous authentication system based on multimodal behavioral biometrics fusion is proposed in this study, which fuses three modalities: contextual behavior, mouse behavior, and information interaction behavior. The multimodal dataset of user behavior is collected through a self-built website, and the behavioral feature sets for each modality are then created. An improved generative adversarial network method is used to align the datasets of the three modalities. The autoencoder with long short-term memory is employed for unsupervised anomaly detection of time-series behaviors and enables continuous authentication for each modality. The multimodal fusion is achieved using the meta-model of the stacked generalization method, and the final decision for continuous authentication is then determined. The experimental results demonstrate that the proposed multimodal fusion method significantly outperforms the unimodal and provides an effective way to improve the accuracy and user-friendliness of continuous authentication. This study offers insights into user behavior analysis, behavioral anomaly detection, and multimodal behavior fusion.}
}


@article{DBLP:journals/tifs/HuaZZTGLSG24,
	author = {Minyu Hua and
                  Yibin Zhang and
                  Qianyun Zhang and
                  Huaiyu Tang and
                  Lantu Guo and
                  Yun Lin and
                  Hikmet Sari and
                  Guan Gui},
	title = {{KG-IBL:} Knowledge Graph Driven Incremental Broad Learning for Few-Shot
                  Specific Emitter Identification},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10016--10028},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3481902},
	doi = {10.1109/TIFS.2024.3481902},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HuaZZTGLSG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Specific emitter identification (SEI) plays a crucial role in the security of the Industrial Internet of Things (IIoT). In recent years, research on applying deep learning (DL) methods for signal identification has mushroomed. However, DL-based SEI methods rely on a huge amount of training data and powerful computing devices, limiting their application scenarios. In addition, DL models are considered black box models with poor interpretability. To solve the above problems, this paper proposes a novel few-shot SEI solution using knowledge graph-driven incremental broad learning (KG-IBL). Specifically, this paper uses a deep belief network (DBN) to dig deep into features and expand the broad structure with additional enhancement nodes. Furthermore, the proposed KG-IBL does not need to retrain all data to achieve dynamic incremental update learning. To our knowledge, this is the first endeavor to integrate KG with broad learning for addressing the few-shot SEI problem. The experimental results demonstrate that the proposed KG-IBL surpasses existing incremental methods in both identification performance and computational overhead. Last but not least, the accuracy of the proposed KG-IBL is 97.5%, which is only 1.67% lower than the theoretical upper limit, and the training time is nearly 267 times lower than that of deep learning models. The code and dataset are available for download at https://github.com/Lollipophua/KG-IBL.}
}


@article{DBLP:journals/tifs/XiongCGN24,
	author = {Shuming Xiong and
                  Pengchao Chen and
                  Shusheng Ge and
                  Qiang Ni},
	title = {{SFOM-DT:} {A} Secure and Fair One-to-Many Data Trading Scheme Based
                  on Blockchain},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10029--10042},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3475816},
	doi = {10.1109/TIFS.2024.3475816},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/XiongCGN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The requirements for large amounts of data have promoted the rapid emergence of an industry for trading data. However, the current one-to-one trading constraints in the existing data trading schemes lead to low security and low efficiency. To tackle the challenges, a novel one-to-many distributed data trading scheme is proposed based on blockchain, which enables a data seller to sell one piece of data to multiple data buyers simultaneously, saving storage resources and computing resources significantly. Firstly, some new smart contracts are devised for two decentralized applications. Then, attribute-based searchable encryption technology is proposed to establish a data circulation scheme that realizes end-to-end encryption of data and ensures data security and highly efficient access. Finally, an inspection mechanism based on zero-knowledge proof and a pricing strategy based on the Stackelberg game are designed to guarantee fairness in trading and maximize revenue. The experiment results show that, in comparison to one-to-one trading, the high efficiency of this data trading scheme gradually emerges as the number of buyers (n) is greater than 2, and the run time is less than 1/10 of the former when n =35. Furthermore, the pricing strategy can enable buyers and sellers to obtain more revenue when \\text {n} \\gt 4\n.}
}


@article{DBLP:journals/tifs/LiuSP24,
	author = {Hang Liu and
                  Anna Scaglione and
                  Sean Peisert},
	title = {Graph-Signal-to-Graph Matching for Network De-Anonymization Attacks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10043--10057},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3483669},
	doi = {10.1109/TIFS.2024.3483669},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiuSP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph matching over two given graphs is a well-established method for re-identifying obscured node labels within an anonymous graph by matching the corresponding nodes in a reference graph. This paper studies a new application, termed the graph-signal-to-graph matching (GS2GM) problem, where the attacker observes a set of filtered graph signals originating from a hidden graph. These signals are generated through an unknown graph filter activated by certain input excitation signals. Our goal is to match their components to a labeled reference graph to reveal the labels of asymmetric nodes in this unknown graph, where the excitations can be either known or unknown to the attacker. To this end, we integrate the existing blind graph matching algorithm with techniques of graph filter inference and covariance-based eigenvector estimation. Furthermore, we establish sufficient conditions for perfect node de-anonymization through graph signals, showing that graph signals can leak substantial private information on the concealed labels of the underlying graph. Experimental results validate our theoretical insights and demonstrate that the proposed attack effectively reveals many of the hidden labels, particularly when the graph signals are adequately uncorrelated and sampled.}
}


@article{DBLP:journals/tifs/AgrawalM24,
	author = {Anand Agrawal and
                  Rajib Ranjan Maiti},
	title = {iTieProbe: How Vulnerable Your IoT Provisioning via Wi-Fi {AP} Mode
                  or {EZ} Mode?},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10058--10070},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3471080},
	doi = {10.1109/TIFS.2024.3471080},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AgrawalM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT provisioning is a critical phase in IoT communication, where a number of security parameters are exchanged that are used both in this phase and later. Due to the headless nature of IoT devices, the exchange of these parameters faces challenges of balancing security and convenience. Some proprietary (e.g., “SmartConfig” by Texas Instruments) and open de-facto standards (e.g., AP mode and EZ mode by Tuya Inc.) are proposed to address these challenges, leaving scopes for certain vendor-specific settings. The analysis of vulnerability and threats thereby is a challenging task due to the lack of a common model of IoT provisioning in commercial IoT devices over Wi-Fi AP mode and EZ mode. In this paper, we propose a model using a sequence diagram for such provisioning and fuse seven research questions (RQs) to discover vendor-agnostic vulnerabilities. We develop a system, called iTieProbe to resolve the RQs. We discover six non-trivial potential vulnerabilities, identified as $\\mathcal {V}1$ to $\\mathcal {V}6$ . We evaluate the efficacy of testing these six vulnerabilities using iTieProbe by applying it to nine commercial IoT devices that include seven types, like a smart plug, IoT doorbell, spy bulb, smart speaker, spy clock, smart camera, and air quality monitor. We show that using iTieProbe, among others, an attacker can find $\\mathcal {V}1$ - leads to access neighbor’s Wi-Fi AP - in five devices, $\\mathcal {V}3$ and $\\mathcal {V}4$ in three devices, and $\\mathcal {V}5$ and $\\mathcal {V}6$ - both lead to successful provisioning using either an expired authentication token or a valid token belonging to an attacker - in three devices. We have reported all these vulnerabilities to respective vendors via email and received acknowledgment from some of them with three registered vulnerability (CVE-2024-7408, CVE-2024-46040, CVE-2024-46041). The average runtime of iTieProbe to test a vulnerability of any individual IoT provisioning is about 48.95 seconds, which is much less than the provisioning itself (typically in the range of a few minutes). We believe that our revelation can help the vendors or the developers of these IoT devices to fix the security vulnerabilities in their implementations of the provisioning.}
}


@article{DBLP:journals/tifs/HePCYLL24,
	author = {Yan He and
                  Fei Peng and
                  Rizhao Cai and
                  Zitong Yu and
                  Min Long and
                  Kwok{-}Yan Lam},
	title = {Category-Conditional Gradient Alignment for Domain Adaptive Face Anti-Spoofing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10071--10085},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3486098},
	doi = {10.1109/TIFS.2024.3486098},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HePCYLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In view of inconsistent face acquisition procedure in face anti-spoofing, the detection performance on the target domain generally suffers severe degradation under source-specific gradient optimization. Existing domain adaptation face anti-spoofing methods focus on improving model generalization capability through feature matching, which do not consider the gradient discrepancy between the source and target domains. To this end, this work develops a category-conditional gradient alignment guided face anti-spoofing algorithm (CCGA-FAS) from a novel perspective of gradient discrepancy elimination. Technically, the category-conditional gradient alignment mechanism maximizes the cosine similarity of the gradient vectors generated by source and target samples within the live and spoof categories separately, which promotes the source and target domains to follow similar gradient descent directions during optimization. Considering that the gradient vector generation and alignment is computationally dependent on reliable category information, a temporal knowledge and flexible threshold based dynamic category measurer is devised to provide pseudo category information for unlabelled target samples in an easy-to-hard manner. The optimization for CCGA-FAS is implemented under the teacher-student structure, where the student model serves as the gradient optimization backbone, and the category prediction simultaneously benefits from the teacher and student models to consolidate the alignment stability. Experimental results and analysis demonstrate that the proposed method outperforms the state-of-the-art methods in both unsupervised and K-shot semi-supervised domain adaptive face anti-spoofing scenarios.}
}


@article{DBLP:journals/tifs/WuZWGN24,
	author = {Jiawen Wu and
                  Kai Zhang and
                  Lifei Wei and
                  Junqing Gong and
                  Jianting Ning},
	title = {Practical Searchable Symmetric Encryption for Arbitrary Boolean Query-Join
                  in Cloud Storage},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10086--10098},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3486002},
	doi = {10.1109/TIFS.2024.3486002},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WuZWGN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure cloud storage offers encrypted databases outsourcing service for resource-constrained clients, containing numerous tables with certain relations. Searchable symmetric encryption enables a client to search over its encrypted database on the cloud, while rarely considering queries over joins of tables. Join Cross-Tags (JXT) protocol (ASIACRYPT 2022) is thence presented that enables conjunctive queries over joins of tables, while neglecting arbitrary Boolean queries with disjunctive and conjunctive normal forms (DNF/CNF) in TWINSSE (PETS 2023). However, trivially combining JXT and TWINSSE for arbitrary DNF/CNF boolean queries over joins of tables seems infeasible due to: (i) no support for dis/conjunctive query with the same meta-keyword; (ii) returning inaccurate search results; (iii) incurring costly storage overhead. Therefore, we introduce TNT-QJ, a practical TwiN cross-Tag protocol for arbitrary boolean Query-Join over multi-tables. The result is technically obtained from revisiting TWINSSE’s framework via using s-term (the least frequent keyword) for the relation between a keyword and its meta-keyword, and non-trivially combined with JXT’s query-join approach for introducing a connective attributed in encryption tuples. In addition, we present a semi-full multi-fork searchable tree to store keyword information and reveal keyword containment relations, where the storage consumption is reduced from \\mathcal {O}(n^{3}) to \\mathcal {O}(n^{2}) . Finally, to clarify practical performance, we conduct extensive experiments on JXT and TNT-QJ using an open database in the HUAWEI cloud. Besides enabling disjunctive queries over joins of tables, TNT-QJ also runs 1.2\\times faster for conjunctive queries than JXT (with #keywords=2), which confirms rich features and practical efficiency.}
}


@article{DBLP:journals/tifs/SalimA24,
	author = {Shinimol Salim and
                  Waquar Ahmad},
	title = {Advancing Voice Biometrics for Dysarthria Speakers Using Multitaper
                  {LFCC} and Voice Conversion Data Augmentation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10114--10129},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3484661},
	doi = {10.1109/TIFS.2024.3484661},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SalimA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Patients with dysarthria and physical impairments face challenges with traditional user interfaces. An Automatic Speaker Verification (ASV) system can enhance accessibility by replacing complex authentication methods and enabling voice biometrics in various applications for patients with dysarthria. This study focuses on enhancing accessibility of patients with dysarthria through an ASV system. In this study, a noval low variance Multitaper Linear Frequency Cepstral Coefficients (MTLFCC) feature is proposed. An ASV system for patients with dysarthria is implemented using the voice conversion data augmentation within a DNN framework. An extensive analysis is conducted to compare various multitaper techniques and taper weight choices using the Thomson multitaper method, specifically verifying patients with dysarthria as speakers. The impact of voice conversion through a cycle-consistent generative adversarial network (Cycle GAN) is also examined by modifying the acoustic attributes of control speech to make it perceptually similar to dysarthria speech and its implications for dysarthria ASV. Furthermore, the system performance is analyzed for different severity level of dysarthria to gain insight into how the selected multitaper parameters influence the outcomes. This study pioneers the use of MTLFCC features for ASV in the context of dysarthria, offering a novel approach to improve accessibility for this group.}
}


@article{DBLP:journals/tifs/KongSYGMHC24,
	author = {Zhengmin Kong and
                  Jing Song and
                  Shaoshi Yang and
                  Li Gan and
                  Weizhi Meng and
                  Tao Huang and
                  Sheng Chen},
	title = {Distributed Robust Artificial-Noise-Aided Secure Precoding for Wiretap
                  {MIMO} Interference Channels},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10130--10140},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3486548},
	doi = {10.1109/TIFS.2024.3486548},
	timestamp = {Sat, 30 Nov 2024 21:07:30 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/KongSYGMHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a distributed artificial noise-assisted precoding scheme for secure communications over wiretap multi-input multi-output (MIMO) interference channels, where K legitimate transmitter-receiver pairs communicate in the presence of a sophisticated eavesdropper having more receive-antennas than the legitimate user. Realistic constraints are considered by imposing statistical error bounds for the channel state information of both the eavesdropping and interference channels. Based on the asynchronous distributed pricing model, the proposed scheme maximizes the total utility of all the users, where each user’s utility function is defined as the secrecy rate minus the interference cost imposed on other users. Using the weighted minimum mean square error, Schur complement and sign-definiteness techniques, the original non-concave optimization problem is approximated with high accuracy as a quasi-concave problem, which can be solved by the alternating convex search method. Simulation results consolidate our theoretical analysis and show that the proposed scheme outperforms the artificial noise-assisted interference alignment and minimum total mean-square error-based schemes.}
}


@article{DBLP:journals/tifs/LiZWSYWHMW24,
	author = {Yahui Li and
                  Han Zhang and
                  Jilong Wang and
                  Xingang Shi and
                  Xia Yin and
                  Zhiliang Wang and
                  Jiankun Hu and
                  Congcong Miao and
                  Jianping Wu},
	title = {Proactively Verifying Quantitative Network Policy Across Unsafe and
                  Unreliable Environments},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10099--10113},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3409935},
	doi = {10.1109/TIFS.2024.3409935},
	timestamp = {Sun, 22 Dec 2024 15:48:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/LiZWSYWHMW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network managers configure networks to enforce various high-level policies, and to respond to the wide range of network events (e.g., attacks, intrusions, malicious route announcements from neighbors) that may occur. It is incredibly difficult to specify these high-level policies in terms of distributed low-level configuration. These high-level policies hold only if the distributed configurations are well equipped to react to unsafe and unreliable environments (e.g., malicious route announcements, unsafe components and devices). Therefore, it is important to proactively verify whether network policies hold across continually changing environments in terms of current network configurations. State-of-the-art policy verification techniques are limited because they can check only the Boolean policies (e.g., forwarding reachability, waypoint or blackhole-freeness). However, many policy violations express themselves in quantitative ways (e.g., a link becomes overloaded). In this paper, we propose quantitative network verification (QNV) analyzing the quantitative policies of networks across unsafe and unreliable environments. QNV translates network configurations into a symbolic simulation model that captures the stable states to which the network forwarding will converge as a result of interactions between routing protocols. It then generates a logical formula matrix that describes network forwarding in the event of failures and verifies quantitative policies based on the formula matrix. We implement QNV and evaluate it on realistic and synthetic configurations. Our evaluation shows that QNV can precisely verify quantitative policies in only a few minutes, even in large networks.}
}


@article{DBLP:journals/tifs/ChenXXZ24,
	author = {Lvjun Chen and
                  Di Xiao and
                  Xiangli Xiao and
                  Yushu Zhang},
	title = {Secure and Efficient Federated Learning via Novel Authenticable Multi-Party
                  Computation and Compressed Sensing},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10141--10156},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3486611},
	doi = {10.1109/TIFS.2024.3486611},
	timestamp = {Sun, 22 Dec 2024 15:48:56 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenXXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) facilitates collaborative training of a global model without sharing the participants’ raw data. Nevertheless, existing FL approaches still face three major issues: 1) How to propose a more efficient and secure privacy-preserving method; 2) How to verify the identity of participants to ensure they are not impersonators; 3) How to reduce the significant communication cost. To address the aforementioned concerns, several schemes have been proposed. However, these schemes suffer from flaws in security, efficiency, and functionality. Furthermore, few researches have considered the possibility of adversaries impersonating legitimate participants to undermine the integrity and availability of the model or launch a free-riding attack. In this paper, we first combine the advantages of secret sharing, Diffie-Hellman key agreement, and functional encryption to develop an authenticable secure multi-party computing algorithm (SDF-ASMC). This algorithm can guarantee the security of transmitted data and provide authentication functionality in the absence of a trusted third party. Moreover, an efficient, secure, and authenticable FL algorithm (ESAFL), which leverages compressed sensing and all-or-nothing transform, is introduced to reduce the transmission and encryption of local gradients. Then, only the final element of the transformed measurements is encrypted by our proposed SDF-ASMC to protect all the measurements. This method effectively improves the efficiency of our algorithm. In addition, ESAFL also tolerates participants’ dropout. Security analysis demonstrates that our proposed algorithms can securely aggregate local gradients. Finally, the extensive experiments demonstrate the practical performance of our proposed algorithms.}
}


@article{DBLP:journals/tifs/CaiWXLZLY24,
	author = {Xiangrui Cai and
                  Yang Wang and
                  Sihan Xu and
                  Hao Li and
                  Ying Zhang and
                  Zheli Liu and
                  Xiaojie Yuan},
	title = {{LAN:} Learning Adaptive Neighbors for Real-Time Insider Threat Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10157--10172},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488527},
	doi = {10.1109/TIFS.2024.3488527},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CaiWXLZLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Enterprises and organizations are faced with potential threats from insider employees that may lead to serious consequences. Previous studies on insider threat detection (ITD) mainly focus on detecting abnormal users or abnormal time periods (e.g., a week or a day). However, a user may have hundreds of thousands of activities in the log, and even within a day there may exist thousands of activities for a user, requiring a high investigation budget to verify abnormal users or activities given the detection results. On the other hand, existing works are mainly post-hoc methods rather than real-time detection, which can not report insider threats in time before they cause loss. In this paper, we conduct the first study towards real-time ITD at activity level, and present a fine-grained and efficient framework LAN. Specifically, LAN simultaneously learns the temporal dependencies within an activity sequence and the relationships between activities across sequences with graph structure learning. Moreover, to mitigate the data imbalance problem in ITD, we propose a novel hybrid prediction loss, which integrates self-supervision signals from normal activities and supervision signals from abnormal activities into a unified loss for anomaly detection. We evaluate the performance of LAN on two widely used datasets, i.e., CERT r4.2 and CERT r5.2. Extensive and comparative experiments demonstrate the superiority of LAN, outperforming 9 state-of-the-art baselines by at least 8.43% and 6.35% in AUC for real-time ITD on CERT r4.2 and r5.2, respectively. Moreover, LAN can be also applied to post-hoc ITD, surpassing 8 competitive baselines by at least 7.70% and 4.03% in AUC on two datasets. Finally, the ablation study, parameter analysis, and compatibility analysis evaluate the impact of each module and hyper-parameter in LAN. The source code can be obtained from https://github.com/Li1Neo/LAN.}
}


@article{DBLP:journals/tifs/HaoCWLLWP24,
	author = {Yurong Hao and
                  Xihui Chen and
                  Wei Wang and
                  Jiqiang Liu and
                  Tao Li and
                  Junyong Wang and
                  Witold Pedrycz},
	title = {Eyes on Federated Recommendation: Targeted Poisoning With Competition
                  and Its Mitigation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10173--10188},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488500},
	doi = {10.1109/TIFS.2024.3488500},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HaoCWLLWP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated recommendation (FR) addresses privacy concerns in recommender systems by training a global model without requiring raw user data to leave individual devices. A server, known as the aggregator, integrates users’ local gradients and updates the global model parameters. However, FR is vulnerable to attacks where malicious users manipulate these updates, known as model poisoning attacks. In this work, we propose a new targeted attack called StairClimbing to promote specific items through model poisoning, and a new defence mechanism CrossEU. StairClimbing adopts a new strategy resembling stair climbing to enable target items to beat competitive items and increase their popularity level by level. Compared to prior attacks, StairClimbing guarantees balanced effectiveness, efficiency and stealthiness simultaneously. Our defence mechanism CrossEU leverages two patterns regarding the lists of items updated by benign users between iterative epochs. Extensive experiments on six real-world datasets demonstrate StairClimbing’s superiority across all three desirable attack properties, even with a small proportion of malicious users (1%). In addition, CrossEU effectively delays the impact of all tested attacks and even eliminates their damage entirely.}
}


@article{DBLP:journals/tifs/BouomLGFSK24,
	author = {Aymar Le P{\`{e}}re Tchimwa Bouom and
                  Jean{-}Pierre Lienou and
                  Wilson Ejuh Geh and
                  Frederica Free{-}Nelson and
                  Sachin Shetty and
                  Charles A. Kamhoua},
	title = {TriAssetRank: Ranking Vulnerabilities, Exploits, and Privileges for
                  Countermeasures Prioritization},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10189--10205},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488533},
	doi = {10.1109/TIFS.2024.3488533},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BouomLGFSK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network defence practices have no standardized mechanism for determining the priority of threat events. Prioritization of cyber vulnerabilities intends to make network administrators focus on the most critical points within the system to mitigate potential damages produced by attackers. More likely, in managing vulnerabilities, current approaches always focus on the common vulnerability exposures (CVE), which are not the only existing vulnerabilities in a network. Also, while the Common Vulnerability Scoring System (CVSS) effectively scores individual vulnerabilities, it fails to consider the relationships between them but considers each vulnerability in isolation. Existing research, such as the ‘AssetRank’ algorithm, has made progress in exploring these relationships. Building on this foundation, in this paper we propose TriAssetRank, a tripartite ranking algorithm that evaluates three key elements within a logical attack graph: vulnerabilities, privileges, and potential attack exploits. Since each node type has its unique characteristics and potential impact on the system’s security, we rank them in concert, taking into account the dependencies between nodes in the attack graph. The proposed ranking scheme computes a numerical value for each node based on its type, which is a clear indication of how valuable it is to a potential attacker. Several tests on various model networks have empirically validated the effectiveness of the algorithm, which enables organizations to prioritize countermeasures by identifying the most critical vulnerabilities, exploits, and privilege escalation risks, allowing efficient allocation of resources to mitigate high-impact threats and reduce overall risk exposure effectively.}
}


@article{DBLP:journals/tifs/ChengHWZKDY24,
	author = {Guanjie Cheng and
                  Junqin Huang and
                  Yewei Wang and
                  Jun Zhao and
                  Linghe Kong and
                  Shuiguang Deng and
                  Xueqiang Yan},
	title = {Conditional Privacy-Preserving Multi-Domain Authentication and Pseudonym
                  Management for 6G-Enabled IoV},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10206--10220},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2023.3314211},
	doi = {10.1109/TIFS.2023.3314211},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChengHWZKDY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the emergence of the sixth-generation (6G) communication technologies, the Internet of Vehicles (IoV) is rapidly developing with the coordination between intelligent networked vehicles, road infrastructures, and the cloud. However, the openness and dynamic nature of the IoV raise significant security and privacy concerns, highlighting the need for efficient authentication schemes. Conventional authentication schemes are no longer suitable for 6G-enabled IoV due to high latency, single point of failure, and heavy management costs. Additionally, existing literature on multi-domain authentication mainly investigates vehicle mobility, ignoring the challenges posed by vehicle heterogeneity. To fill this gap, we propose a multi-domain authentication scheme with conditional privacy preservation (MACPP) that considers administrative domains (AD) and geographic domains (GD) in the IoV. In MACPP, we design a novel identity-based signature scheme without requiring bilinear pairing for efficient authentication. Additionally, we propose a blockchain-assisted pseudonym management scheme (BAPM) to further improve system security by designing a dynamical sparse Merkle tree structure (DSMT). We demonstrate that the proposed MACPP satisfies the security requirements through an in-depth security analysis. Moreover, the experimental results demonstrate the effectiveness and efficiency of both MACPP and BAPM.}
}


@article{DBLP:journals/tifs/ChenSS24,
	author = {Jiajun Chen and
                  Yichen Shen and
                  Chi Wan Sung},
	title = {A New Shift-Add Secret Sharing Scheme for Partial Data Protection
                  With Parallel Zigzag Decoding},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10221--10232},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488498},
	doi = {10.1109/TIFS.2024.3488498},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies distributed storage for protecting the confidentiality of partial data in the presence of storage node failures. It is required that not only the original data can be reconstructed from the remaining surviving nodes, but also the data lost by a failed node can be repaired from as few nodes as possible. The minimum number of surviving nodes required to repair a failed node is called the repair degree. Inspired by the zigzag-decodable secret sharing scheme, we propose a new shift-add secret sharing scheme based on the XOR and bitwise-shift operations, in which confidential data is protected by using random keys generated from non-confidential data. The reliability and repairability of the proposed scheme are measured by the message loss probability and the maximum repair degree among all nodes, respectively, and then compared with three benchmark schemes. In contrast to conventional zigzag-decodable codes, the special structure of our proposed scheme allows the design of fast parallel algorithms for modern devices with multi-core processors, which have a linear speedup in decoding time compared with various versions of serial zigzag decoding. Experiments are implemented on a multi-core computer, and the empirical results on decoding time are consistent with our theoretical observations.}
}


@article{DBLP:journals/tifs/HeHLSZG24,
	author = {Kaiyan He and
                  Yikun Hu and
                  Xuehui Li and
                  Yunhao Song and
                  Yubo Zhao and
                  Dawu Gu},
	title = {Strtune: Data Dependence-Based Code Slicing for Binary Similarity
                  Detection With Fine-Tuned Representation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10233--10245},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3484944},
	doi = {10.1109/TIFS.2024.3484944},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/HeHLSZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Binary Code Similarity Detection (BCSD) is significant for software security as it can address binary tasks such as malicious code snippets identification and binary patch analysis by comparing code patterns. Recently, there has been a growing focus on artificial intelligence-based approaches in BCSD due to their scalability and generalization. Because binaries are compiled with different compilation configurations, existing approaches still face notable limitations when comparing binary similarity. First, BCSD requires analysis on code behavior, and existing work claims to extract semantic, but actually still makes analysis in terms of syntax. Second, directly extracting features from assembly sequences, existing work cannot address the issues of instruction reordering and different syntax expressions caused by various compilation configurations. In this paper, we propose STRTUNE, which slices binary code based on data dependence and perform slice-level fine-tuning. To address the first limitation, STRTUNE performs backward slicing based on data dependence to capture how a value is computed along the execution. Each slice reflects the collecting semantics of the code, which is stable across different compilation configurations. STRTUNE introduces flow types to emphasize the independence of computations between slices, forming a graph representation. To overcome the second limitation, based on slices corresponding to the same value computation but having different syntax representation, STRTUNE utilizes a Siamese Network to fine-tune such pairs, making their representations closer in the feature space. This allows the cross-graph attention to focus more on the matching of similar slices based on slice contents and flow types involved. Our evaluation results demonstrate the effectiveness and practicality of STRTUNE. We show that STRTUNE outperforms the state-of-the-art methods for BCSD, achieving a Recall@1 that is 25.3% and 22.2% higher than jTrans and GMN in the task of function retrieval cross optimization in x64.}
}


@article{DBLP:journals/tifs/GuoJCYW24,
	author = {Liang Guo and
                  Jie Jia and
                  Jian Chen and
                  Shuhui Yang and
                  Xingwei Wang},
	title = {Secure Beamforming and Radar Association in CoMP-NOMA Empowered Integrated
                  Sensing and Communication Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10246--10257},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3484950},
	doi = {10.1109/TIFS.2024.3484950},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/GuoJCYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrated sensing and communication (ISAC) has been regarded as an emerging technique to satisfy the sensing requirements for future 6G networks. However, the confidential communication information embedded in the probing waveform could be eavesdropped by the radar targets, which leads to insecurity issues for ISAC systems. To this end, we propose a coordinated multi-point transmission (CoMP) empowered secure ISAC system. Unlike existing work focusing on a single base station (BS), multiple BSs are coordinated to improve sensing performance and communication security. Specifically, non-orthogonal multiple access (NOMA) is employed to improve spectrum efficiency and facilitate spectrum sharing between sensing and communication functions. By importing the artificial noise (AN) to disrupt eavesdropper reception, a joint radar association and beamforming design optimization problem is formulated to maximize the minimum beampattern gain, subject to the maximum power constraint and secure communication requirements. The mixed-integer non-convex optimization problem is first transformed into more tractable forms. Then, a near-optimal solution is obtained by applying an accelerated stochastic coordinate descent algorithm for radar association and the penalty-based iterative algorithm for beamforming design. Moreover, the optimization problem is further extended to more practical cases with uncertain target directions. Our numerical results show: i) the proposed AN-aided COMP-NOMA empowered ISAC system can support much higher high-quality radar sensing, while simultaneously guaranteeing secure communication; ii) the proposed scheme significantly outperforms the relevant benchmark schemes in terms of the beampattern gain; iii) the proposed joint optimization algorithm can achieve high beampattern gain, even with uncertain target directions.}
}


@article{DBLP:journals/tifs/BoahenSOXW24,
	author = {Edward Kwadwo Boahen and
                  Rexford Nii Ayitey Sosu and
                  Selasi Kwame Ocansey and
                  Qinbao Xu and
                  Changda Wang},
	title = {{ASRL:} Adaptive Swarm Reinforcement Learning for Enhanced {OSN} Intrusion
                  Detection},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10258--10272},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488506},
	doi = {10.1109/TIFS.2024.3488506},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/BoahenSOXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online Social Networks (OSNs) face escalating security threats that imperil user privacy. Conventional Deep Learning methods, relying predominantly on fixed learning rates, encounter limitations when capturing the nuanced intricacies of OSN traffic that arise from shifting user behaviors, diverse content types, and evolving interaction patterns because of social trending topics changes. To tackle these challenges, our paper delves into the diverse variations and transitions from a uniform approach, where a single method is employed for various types of data, to a multi-variation methodology. This methodology dynamically adapts to the special characteristics of each data type, resulting in more effective data representation while alleviating the limitations associated with fixed-rate calibration. Therefore, we devise the Adaptive Swarm Reinforcement Learning (ASRL) method that leverages adaptive learning to intricately analyze a wide range of user interactions, endowing our proposed method with the capacity to flexibly adjust to the constantly shifting OSN patterns. The experiments show that the proposed ASRL method achieves an accuracy of 98.59% in detecting a range of threat patterns, surpassing other prevalent methods by an average of 5% across the datasets from Facebook, Google+, and Twitter. Meanwhile, ASRL logs suspicious activities to identify the intruder for forensic analysis. The implementation of our proposed method is now publicly accessible at https://github.com/don2c/asrl_Project.}
}


@article{DBLP:journals/tifs/ChenLHHXZZ24,
	author = {Hanxiao Chen and
                  Hongwei Li and
                  Meng Hao and
                  Jia Hu and
                  Guowen Xu and
                  Xilin Zhang and
                  Tianwei Zhang},
	title = {SecBNN: Efficient Secure Inference on Binary Neural Networks},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10273--10286},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3484936},
	doi = {10.1109/TIFS.2024.3484936},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ChenLHHXZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work studies secure inference on Binary Neural Networks (BNNs), which have binary weights and activations as a desirable feature. Although previous works have developed secure methodologies for BNNs, they still have performance limitations and significant gaps in efficiency when applied in practice. We present SecBNN, an efficient secure two-party inference framework on BNNs. SecBNN exploits appropriate underlying primitives and contributes efficient protocols for the non-linear and linear layers of BNNs. Specifically, for non-linear layers, we introduce a secure sign protocol with an innovative adder logic and customized evaluation algorithms. For linear layers, we propose a new binary matrix multiplication protocol, where a divide-and-conquer strategy is provided to recursively break down the matrix multiplication problem into multiple sub-problems. Building on top of these efficient ingredients, we implement and evaluate SecBNN over two real-world datasets and various model architectures under LAN and WAN. Experimental results show that SecBNN substantially improves the communication and computation performance of existing secure BNN inference works by up to 29 \\times and 14 \\times , respectively.}
}


@article{DBLP:journals/tifs/CaiYHLF24,
	author = {Jianping Cai and
                  Qingqing Ye and
                  Haibo Hu and
                  Ximeng Liu and
                  Yanggeng Fu},
	title = {Boosting Accuracy of Differentially Private Continuous Data Release
                  for Federated Learning},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10287--10301},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3477325},
	doi = {10.1109/TIFS.2024.3477325},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/CaiYHLF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incorporating differentially private continuous data release (DPCR) into private federated learning (FL) has recently emerged as a powerful technique for enhancing accuracy. Designing an effective DPCR model is the key to improving accuracy. Still, the state-of-the-art DPCR models hinder the potential for accuracy improvement due to insufficient privacy budget allocation and the design only for specific iteration numbers. To boost accuracy further, we develop an augmented BIT-based continuous data release (AuBCR) model, leading to demonstrable accuracy enhancements. By employing a dual-release strategy, AuBCR gains the potential to further improve accuracy, while confronting the challenge of consistent release and doubly-nested complex privacy budget allocation problem. Against this, we design an efficient optimal consistent estimation algorithm with only O(1) complexity per release. Subsequently, we introduce the (k, N) -AuBCR Model concept and design a meta-factor method. This innovation significantly reduces the optimization variables from O(T) to O\\left ({{lg^{2} T}}\\right) , thereby greatly enhancing the solvability of optimal privacy budget allocation and simultaneously supporting arbitrary iteration number T. Our experiments on classical datasets show that AuBCR boosts accuracy by 4.9% ~ 18.1% compared to traditional private FL and 0.4% ~ 1.2% compared to the state-of-the-art ABCRG model.}
}


@article{DBLP:journals/tifs/PaiKC24,
	author = {Hao{-}Ting Pai and
                  Yu{-}Hsuan Kang and
                  Wen{-}Cheng Chung},
	title = {An Interpretable Generalization Mechanism for Accurately Detecting
                  Anomaly and Identifying Networking Intrusion Techniques},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10302--10313},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488967},
	doi = {10.1109/TIFS.2024.3488967},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/PaiKC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing complexity of modern network environments presents formidable challenges to Intrusion Detection Systems (IDS) in effectively mitigating cyber-attacks. Recent advancements in IDS research, integrating Explainable AI (XAI) methodologies, have led to notable improvements in system performance via precise feature selection. However, a thorough understanding of cyber-attacks requires inherently explainable decision-making processes within IDS. In this paper, we present the Interpretable Generalization Mechanism (IG), poised to revolutionize IDS capabilities. IG discerns coherent patterns, making it interpretable in distinguishing between normal and anomalous network traffic. Further, the synthesis of coherent patterns sheds light on intricate intrusion pathways, providing essential insights for cybersecurity forensics. By experiments with real-world datasets NSL-KDD, UNSW-NB15, and UKM-IDS20, IG is accurate even at a low ratio of training-to-test. With 10%-to-90%, IG achieves Precision (PRE) =0.93, Recall (REC) =0.94, and Area Under Curve (AUC) =0.94 in NSL-KDD; PRE =0.98, REC =0.99, and AUC =0.99 in UNSW-NB15; and PRE =0.98, REC =0.98, and AUC =0.99 in UKM-IDS20. Notably, in UNSW-NB15, IG achieves REC =1.0 and at least PRE =0.98 since 40%-to-60%; in UKM-IDS20, IG achieves REC =1.0 and at least PRE =0.88 since 20%-to-80%. Importantly, in UKM-IDS20, IG successfully identifies all three anomalous instances without prior exposure, demonstrating its generalization capabilities. These results and inferences are reproducible. In sum, IG showcases superior generalization by consistently performing well across diverse datasets and training-to-test ratios (from 10%-to-90% to 90%-to-10%), and excels in identifying novel anomalies without prior exposure. Its interpretability is enhanced by coherent evidence that accurately distinguishes both normal and anomalous activities, significantly improving detection accuracy and reducing false alarms, thereby strengthening IDS reliability and trustworthiness.}
}


@article{DBLP:journals/tifs/JiaCJCZX24,
	author = {Chengyu Jia and
                  Jinyin Chen and
                  Shouling Ji and
                  Yao Cheng and
                  Haibin Zheng and
                  Qi Xuan},
	title = {Backdoor Online Tracing With Evolving Graphs},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10314--10327},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488517},
	doi = {10.1109/TIFS.2024.3488517},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/JiaCJCZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The backdoor attacks have posed a severe threat to deep neural networks (DNNs). Online training platforms and third-party model training providers are more vulnerable to backdoor attacks due to uncontrollable data sources, untrusted developers or unmonitorable training processes. Researchers have proposed to detect the backdoor in the well-trained models, and then remove them by some mitigation techniques, e.g., retraining and pruning. However, they are still limited from two aspects: (i) real-time - they cannot detect in time at the beginning of training due to their reliance on well-trained models; (ii) mitigation effect - the later discovery of backdoors usually leads to 1) deeper backdoors, 2) less effective mitigation, and 3) greater costs. To address these challenges, we rethink the evolution of the backdoor, and intend to cope with backdoors along with the online training process, that is to detect the backdoors sooner rather than later. We propose BackdoorTracer, a novel framework that detects the backdoor in the training phase. BackdoorTracer constructs the model into an equivalent graph based on the activated neural path during training, thereby detecting the backdoor through multiple graph metrics. BackdoorTracer can incorporate any existing backdoor mitigation approaches that require accessing training to stop the impact of backdoors as soon as possible. It differs from previous works in several key aspects: (i) lightweight - BackdoorTracer is independent of the training process, and thus it has little negative impact on the training efficiency and testing accuracy; (ii) generalizable - it works different modalities of data, models and different backdoor attacks. BackdoorTracer outperforms the state-of-the-art (SOTA) detection approaches in experiments on 5 modes, 10 models and 9 backdoor attack scenarios. Compared with the existing 5 backdoor detection methods, our method can detect backdoors earlier ( $\\sim ~1.5$ epochs) and higher detection rate (~ +10%), effectively improving the effectiveness of backdoor defense (ASR. ~ -78%, ACC. +47%). Finally, we make BackdoorTracer a plug-and-play backdoor detector, which enables real-time backdoor tracing in the training phase.}
}


@article{DBLP:journals/tifs/WanLCHWCYJ24,
	author = {Zheng Wan and
                  Kexin Liu and
                  Yajun Chen and
                  Kaizhi Huang and
                  Hui{-}Ming Wang and
                  Zheng Chu and
                  Ming Yi and
                  Liang Jin},
	title = {Resource Allocation for STAR-RIS-Assisted {MIMO} Physical-Layer Key
                  Generation},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10328--10338},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488509},
	doi = {10.1109/TIFS.2024.3488509},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/WanLCHWCYJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the limited coverage of reflecting-only reconfigurable intelligent surfaces (RIS), the existing RIS-assisted physical-layer key generation (PKG) scheme limits its overall performance in the full space. This paper proposes a novel simultaneously transmitting and reflecting (STAR)-RIS-assisted PKG protocol for multiple-input multiple-output (MIMO) systems, where the closed-form sum secret key rate is derived in the presence of full-space eavesdroppers. Two optimization problems are formulated to maximize the sum secret key rate by designing the transmit beamforming (TBF) and transmitting and reflecting coefficients (TRCs) for energy splitting (ES) with coupled phase-shift and mode switching (MS) mode. For ES mode with coupled phase-shift, a penalty-based alternating optimization (AO) algorithm is proposed to address its non-convexity. For MS mode, the semidefinite relaxation-successive convex approximation-based AO algorithm is utilized to achieve continuous solutions and then quantize to binary value for the MS mode. Simulation results demonstrate that the coupled phase-shift STAR-RIS incurs a slight KGR loss in comparison to the independent phase-shift STAR-RIS. Additionally, the ES mode outperforms the MS mode in terms of KGR performance. Finally, STAR-RIS can achieve a higher sum secret key rate than traditional reflecting-only RIS.}
}


@article{DBLP:journals/tifs/ZhenWYSHLY24,
	author = {Zihang Zhen and
                  Xiaoding Wang and
                  Xu Yang and
                  Jiwu Shu and
                  Jia Hu and
                  Hui Lin and
                  Xun Yi},
	title = {SemantiChain: {A} Trust Retrieval Blockchain Based on Semantic Sharding},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10339--10354},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488501},
	doi = {10.1109/TIFS.2024.3488501},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhenWYSHLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since its inception, blockchain technology has found wide-ranging applications in various fields including agriculture, energy, and so on, owing to its immutable and decentralized nature. However, existing blockchains encounter significant challenges in scenarios that demand efficient retrieval of big data. This is primarily because current blockchains cannot directly store and process diverse types of rich media information. Additionally, the semantic relationships between data within the blockchains are weak, complicating the categorization and retrieval of data and transactions. Moreover, the scalability of current blockchains is limited, with the capacity of full nodes continually increasing. Although some semantic-based blockchain solutions that combine off-chain scalability have been proposed, they are limited in effectiveness and applications. To address these issues, this paper introduces a brand-new blockchain sharding technique called Semantic Sharding, which enhances blockchain scalability through a hybrid on/off-chain approach. Building on this, we propose a semantic sharding blockchain architecture, SemantiChain, which enables the on-chain storage and retrieval of transaction semantic features. Furthermore, through the Po2RW consensus protocol, we balance the scalability and security of SemantiChain. Security analysis proves that SemantiChain can resist security risks such as man-in-the-middle attacks, malicious node attacks and on/off-chain data inconsistency. Experimental results demonstrate that SemantiChain can reduce search time and memory usage by at least 32.29% and 77.97% respectively under the same retrieval performance, compared to mainstream approximate nearest neighbour retrieval algorithms. Furthermore, compared to the SOTA semantic blockchain, SemantiChain achieves a retrieval performance improvement of at least 45.88% and reduces retrieval memory usage by 95.76%.}
}


@article{DBLP:journals/tifs/SongWLH24,
	author = {Lushan Song and
                  Zhexuan Wang and
                  Guopeng Lin and
                  Weili Han},
	title = {Ruyi: {A} Configurable and Efficient Secure Multi-Party Learning Framework
                  With Privileged Parties},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10355--10370},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488507},
	doi = {10.1109/TIFS.2024.3488507},
	timestamp = {Sun, 22 Dec 2024 15:48:57 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/SongWLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure multi-party learning (MPL) enables multiple parties to train machine learning models with privacy preservation. MPL frameworks typically follow the peer-to-peer architecture, where each party has the same chance to handle the results. However, the cooperative parties in business scenarios usually have unequal statuses. Thus, Song et al. (CCS’22) presented pMPL, a hierarchical MPL framework with a privileged party. Nonetheless, pMPL has two limitations: (i) it has limited configurability requiring manually finding a public matrix that satisfies four constraints, which is difficult when the number of parties increases, and (ii) it is inefficient due to the huge online communication overhead. In this paper, we are motivated to propose Ruyi, a configurable and efficient MPL framework with privileged parties. Firstly, we reduce the public matrix constraints from four to two while ensuring the same privileged guarantees by extending the standard resharing paradigm to vector space secret sharing in order to implement the share conversion protocol and performing all the computations over a prime field rather than a ring. This enhances the configurability so that the Vandermonde matrix can always satisfy the public matrix constraints when given the number of parties, including privileged parties, assistant parties, and assistant parties allowed to drop out. Secondly, we reduce the online communication overhead by adapting the masked evaluation paradigm to vector space secret sharing. Experimental results demonstrate that Ruyi is configurable with multiple parties and outperforms pMPL by up to 53.87 \\times , 13.91 \\times , and 2.76 \\times for linear regression, logistic regression, and neural networks, respectively.}
}


@article{DBLP:journals/tifs/Lin24,
	author = {Xi Jun Lin},
	title = {On the Unforgeability of "Privacy-Preserving Aggregation-Authentication
                  Scheme for Safety Warning System in Fog-Cloud Based VANET"},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10371--10372},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3408055},
	doi = {10.1109/TIFS.2024.3408055},
	timestamp = {Sat, 28 Dec 2024 22:12:19 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/Lin24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Yang et al. proposed a privacy-preserving aggregation authentication scheme (PPAAS) for fog-cloud-based vehicular ad hoc network based on an anonymous certificateless aggregation signcryption. In their scheme, the vehicles’ public keys and pseudonyms are contained in the ciphertexts to provide sender anonymity. The receiver uses them after they are retrieved from the ciphertexts. However, this method contradicts the authentication. A pseudonym is essentially an encryption of the real identity. The receiver who does not know the encryption key cannot check the validity of the public keys with the pseudonyms. Thus, the attacker can contain public keys and pseudonyms selected by himself in the forged aggregated ciphertext. The receiver has to use them directly. Hence, the PPAAS can be broken in real life.}
}


@article{DBLP:journals/tifs/YangZZCZ24,
	author = {Yafang Yang and
                  Lei Zhang and
                  Yunlei Zhao and
                  Kim{-}Kwang Raymond Choo and
                  Yan Zhang},
	title = {Rebuttal to "On the Unforgeability of 'Privacy-Preserving
                  Aggregation-Authentication Scheme for Safety Warning System in Fog-Cloud
                  Based VANET"'},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10373--10374},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488520},
	doi = {10.1109/TIFS.2024.3488520},
	timestamp = {Wed, 08 Jan 2025 21:11:21 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/YangZZCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Lin recently claimed that the privacy-preserving aggregation authentication scheme (PPAAS) based on a certificateless aggregation signcryption scheme (CASS) proposed in our paper (IEEE Transactions on Information Forensics and Security, vol.17, pp.317-331, Jan.2022) suffers from a forgery attack from type II adversary. In this paper, we show that this attack is not valid since the adversary outputs a trivial forged ciphertext. Specifically, the adversary has the master secret key and randomly selects the secret values of all users.}
}


@article{DBLP:journals/tifs/AfeefFA24,
	author = {Liza Afeef and
                  Haji M. Furqan and
                  H{\"{u}}seyin Arslan},
	title = {Robust Tracking-Based PHY-Authentication in mmWave {MIMO} Systems},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10375--10386},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3488362},
	doi = {10.1109/TIFS.2024.3488362},
	timestamp = {Fri, 14 Feb 2025 20:49:49 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/AfeefFA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical Layer Authentication (PLA) is a topic of considerable interest in ensuring strong security for upcoming wireless networks. However, existing PLA methods face challenges in maintaining performance in dynamic environments. To overcome this, we propose a novel tracking-based PLA approach, utilizing properties of the beamspace multiple-input multiple-output (MIMO) channel in narrowband millimeter-wave (mmWave) networks. Specifically, In particular, the proposed technique involves extracting a distance signature vector from the positions of the principal components within the beamspace MIMO channel representation. These components are then sorted in descending order based on their indices. To address mobility concerns in dynamic settings, a tracking filter is introduced. This filter allows the authentication system to continuously track and update the stored signature, enhancing overall authentication performance. Additionally, the proposed technique is extended to ultra-wideband signaling. In this extension, the richness of the derived signature is further improved by exploiting the beam squint effect, contributing to a more robust authentication process. Simulation results demonstrate that our approach overcomes the limitations of previous methods, resulting in improved authentication performance measured by detection and false alarm rates.}
}


@article{DBLP:journals/tifs/ZhangJ24,
	author = {Peirong Zhang and
                  Lianwen Jin},
	title = {Online Writer Retrieval With Chinese Handwritten Phrases: {A} Synergistic
                  Temporal-Frequency Representation Learning Approach},
	journal = {{IEEE} Trans. Inf. Forensics Secur.},
	volume = {19},
	pages = {10387--10399},
	year = {2024},
	url = {https://doi.org/10.1109/TIFS.2024.3493594},
	doi = {10.1109/TIFS.2024.3493594},
	timestamp = {Wed, 08 Jan 2025 21:11:21 +0100},
	biburl = {https://dblp.org/rec/journals/tifs/ZhangJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Currently, the prevalence of online handwriting has spurred a critical need for effective retrieval systems to accurately search relevant handwriting instances from specific writers, known as online writer retrieval. Despite the growing demand, this field suffers from a scarcity of well-established methodologies and public large-scale datasets. This paper tackles these challenges with a focus on Chinese handwritten phrases. First, we propose DOLPHIN, a novel retrieval model designed to enhance handwriting representations through synergistic temporal-frequency analysis. For frequency feature learning, we propose the HFGA block, which performs gated cross-attention between the vanilla temporal handwriting sequence and its high-frequency sub-bands to amplify salient writing details. For temporal feature learning, we propose the CAIR block, tailored to promote channel interaction and reduce channel redundancy. Second, to address data deficit, we introduce OLIWER, a large-scale online writer retrieval dataset encompassing over 670,000 Chinese handwritten phrases from 1,731 individuals. Through extensive evaluations, we demonstrate the superior performance of DOLPHIN over existing methods. In addition, we explore cross-domain writer retrieval and reveal the pivotal role of increasing feature alignment in bridging the distributional gap between different handwriting data. Our findings emphasize the significance of point sampling frequency and pressure features in improving handwriting representation quality and retrieval performance. Code and dataset are available at https:// github.com/SCUT-DLVCLab/DOLPHIN.}
}
