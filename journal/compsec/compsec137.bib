@article{DBLP:journals/compsec/XuT24,
	author = {Jiacheng Xu and
                  Chengxiang Tan},
	title = {Unawareness detection: Discovering black-box malicious models and
                  quantifying privacy leakage risks},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103565},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103565},
	doi = {10.1016/J.COSE.2023.103565},
	timestamp = {Fri, 09 Feb 2024 16:22:19 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/XuT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Because machine learning models, especially black-box malicious models vulnerable to attribute inference attacks, are capable of generating a great deal of privacy leakage, recent work has focused on assessing these models in an attempt to prevent unexpected attribute privacy leakage. While there has been some success at model privacy risk evaluations, these traditional solutions are almost brittle in practice because they not only require white-box access to obtain model feature layer outputs but also their evaluation results are heavily influenced by the training dataset and the model structure, leading to difficulty in generalization. In this paper, we propose a novel unawareness detection mechanism for discovering black-box malicious models and quantifying potential unawareness privacy leakage risk along with machine learning models to overcome the two limitations. A new method for quantifying the privacy risk caused by a specific loss function has been proposed to mitigate the impact of the training dataset and the model structure. A new evaluation model has also been proposed that uses Matthew's correlation coefficient score as a new metric and the final output of the target model as a new input. In addition, the theoretical upper bound of the model privacy risk has also been given a mathematical formula that is positively correlated to the mutual information between the sensitive attributes and the target model outputs. Compared with traditional detection methods, our evaluation model reduces the requirement for model access and minimizes evaluation errors caused by data imbalance, and our privacy risk assessment method and theoretical upper bounds on privacy risk can be applied to a broader range of datasets and target model structures. The experimental results show that the adversary's prediction capability is affected by the distribution of datasets and the level of malicious intent of the model, which is consistent with the theoretical prediction, and the detecting method can find potential model privacy leaks in public datasets UTKFace and FairFace.}
}


@article{DBLP:journals/compsec/ChenLL24,
	author = {Hongsong Chen and
                  Xingyu Li and
                  Wenmao Liu},
	title = {Multivariate time series anomaly detection by fusion of deep convolution
                  residual autoencoding reconstruction model and ConvLstm forecasting
                  model},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103581},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103581},
	doi = {10.1016/J.COSE.2023.103581},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ChenLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time-series anomaly detection is very essential to ensure the normal operation of physical equipment. Great achievements have been made in this field in recent years. However, two critical challenges limit the generalization ability of the model. Graph attention networks without prior knowledge are unable to extract the distribution features of dependencies among variables in a fine granularity. This reduces the accuracy of the dependence matrix to represent the correlations between variables. Beyond this challenge, the reconstruction model loses the fine-grained seasonal feature information in the spatial dimension during the reconstruction analysis process of the sample. In order to solve the above challenges, we propose a multivariate time-series anomaly detection model consisting of characterization network and forecasting network. In the characterization network, we first remove non-existent dependencies between variables by using prior knowledge. This approach can accurately capture the fine-grained dependency distribution features between variables and improve the accuracy of the dependence matrix representation of the correlations between variables. We then construct a deep convolutional residual autoencoder to reduce the loss of seasonal feature information in the spatial dimension. In forecasting network, we construct a temporal attention-based ConvLstm forecasting network to make fine-grained anomaly decisions on the output of the characterization network in the time dimension. We perform systematic experiments on six open-source datasets, in social network security scenario,the malicous acount behavior can be detected. Experimental results show that the proposed method outperforms the baseline anomaly detection methods with excellent detection performance and robustness. Specifically, our method achieves an average F1 score improvement of 0.23 over the baseline method at its highest level.}
}


@article{DBLP:journals/compsec/BrownGA24,
	author = {Austin Brown and
                  Maanak Gupta and
                  Mahmoud Abdelsalam},
	title = {Automated machine learning for deep learning based malware detection},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103582},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103582},
	doi = {10.1016/J.COSE.2023.103582},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/BrownGA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning (DL) has proven to be effective in detecting sophisticated malware that is constantly evolving. Even though deep learning has alleviated the feature engineering problem, finding the most optimal DL model's architecture and set of hyper-parameters, remains a challenge that requires domain expertise. In addition, many of the proposed state-of-the-art models are very complex and may not be the best fit for different datasets. A promising approach, known as Automated Machine Learning (AutoML), can reduce the domain expertise required to develop custom DL models by automating the ML pipeline key components, namely hyperparameter optimization and neural architecture search (NAS). AutoML reduces the amount of human trial-and-error involved in designing DL models, and in more recent implementations can find new model architectures with relatively low computational overhead.}
}


@article{DBLP:journals/compsec/WangYLZZG24,
	author = {Xiaoyu Wang and
                  Xiaobo Yang and
                  Xueping Liang and
                  Xiu Zhang and
                  Wei Zhang and
                  Xiaorui Gong},
	title = {Combating alert fatigue with AlertPro: Context-aware alert prioritization
                  using reinforcement learning for multi-step attack detection},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103583},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103583},
	doi = {10.1016/J.COSE.2023.103583},
	timestamp = {Fri, 22 Mar 2024 09:01:46 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WangYLZZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Alert fatigue problems can have serious consequences for the enterprise security. When analysts become overwhelmed by the sheer number of alerts, high-risk alerts may go unnoticed or receive delayed responses, exposing the organization to potential cyber threats or data breaches. While current research on alert triage primarily concentrates on reducing false positives, analysts still face a shortage of resources to investigate all true alerts. The key to resolving this issue lies in the prioritization of alerts based on their potential severity, allowing analysts to allocate their efforts effectively.}
}


@article{DBLP:journals/compsec/WengLLL24a,
	author = {Juanjuan Weng and
                  Zhiming Luo and
                  Dazhen Lin and
                  Shaozi Li},
	title = {Learning transferable targeted universal adversarial perturbations
                  by sequential meta-learning},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103584},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103584},
	doi = {10.1016/J.COSE.2023.103584},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WengLLL24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the transferability of adversarial perturbations in non-targeted scenarios has been extensively studied. However, changing the predictions of an unknown model to a pre-defined ‘targeted’ class still remains challenging. In this study, we aim to learn the targeted universal adversarial perturbations (UAPs) with higher transferability by the ensemble of multiple models. First, we observe the phenomenon that the logit of the target class will bias to a specific white-box model in existing ensemble-based attacks. To deal with the issue, we propose a normalized logit loss to narrow the margin of the targeted class's logits among different models. Besides, we introduce a novel sequential meta-learning optimization strategy to further increase transferability, consisting of the inner loop and the outer loop. In the inner loop, we sequentially learn task-specific targeted UAPs for each source model by jointly considering the perturbation from the previous model. In the outer loop, we optimize the task-agnostic targeted UAP by combining the targeted UAPs from the inner loop. Experimental results demonstrate the mutual benefits of the normalized logit loss and the sequential meta-learning optimization strategy for learning targeted adversarial perturbations, outperforming existing ensemble attacks in both white-box and black-box settings. The source code of this study is available at: Link.}
}


@article{DBLP:journals/compsec/GernotR24,
	author = {Tanguy Gernot and
                  Christophe Rosenberger},
	title = {Robust biometric scheme against replay attacks using one-time biometric
                  templates},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103586},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103586},
	doi = {10.1016/J.COSE.2023.103586},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/GernotR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User authentication is an important issue on the Internet and usually solved through static and often unique passwords. Another method is to use biometrics, but biometric data are sensitive and need to be protected. Protection schemes such as cancelable biometric template generation have appeared, but they are sensitive to replay attacks. In this paper, we propose an original method to generate one-time biometric templates for user authentication applications. This proposed scheme limits replay attacks, consisting of an attacker maliciously retransmitting an intercepted user's identity proof. Our method is generic: any biometric modality could be used, the identity verification is realized by the service/identity provider to be realistic. Biometric features are extracted from captures using deep learning and then protected with biohashing, a cancelable biometric scheme. Finally, a step consisting of cryptographic hashing and symmetric encryption guarantees the generation of a one-time, non-replayable template. We have tested our scheme on two common biometric databases, from faces and fingerprints, and the results confirm its efficiency and robustness to attacks given a rigorous threat model.}
}


@article{DBLP:journals/compsec/TurukmaneD24,
	author = {Anil V. Turukmane and
                  Ramkumar Devendiran},
	title = {M-MultiSVM: An efficient feature selection assisted network intrusion
                  detection system using machine learning},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103587},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103587},
	doi = {10.1016/J.COSE.2023.103587},
	timestamp = {Fri, 09 Feb 2024 16:22:19 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/TurukmaneD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The intrusions are increasing daily, so there is a huge amount of privacy violations, financial loss, illegal transferring of information, etc. Various forms of intrusion occur in networks, such as menacing networks, computer resources and network information. Each type of intrusion focuses on specified tasks, whereas the hackers may focus on stealing confidential data, industrial secrets and personal information, which is then leaked to others for illegal gains. Due to the false detection of attacks in the security and changing environmental fields, limitations like data lagging on actual attacks and sustaining financial harms occur. To resolve this, automatic abnormality detection systems are required to secure the required computing ability and to analyze the attacks. Hence, an efficient automated intrusion detection system using machine learning methodology is proposed in this research paper. Initially, the data are gathered from CSE-CIC-IDS 2018 and UNSW-NB15 datasets. The acquired data are pre-processed using Null value handling and Min-Max normalization. Null value handling is used to remove missing values and irrelevant parameters. Min-Max normalization adjusted the unnormalized data in the pre-processing stage. After pre-processing, the class imbalance problem is reduced by using the Advanced Synthetic Minority Oversampling Technique (ASmoT). ASmoT aims to balance the class and reduce imbalance class problems and overfitting issues. The next phase is feature extraction, which is performed by Modified Singular Value Decomposition (M-SvD). M-SvD extracts essential features such as basic features, content features and traffic features from the input. The extracted features are optimized by the Opposition-based Northern Goshawk Optimization algorithm (ONgO). These optimal features are able to produce optimal output. After feature selection, the different types of attacks are classified by a hybrid machine learning model called Mud Ring assisted multilayer support vector machine (M-MultiSVM) and finally, the hyperparameters are tuned by the Mud Ring optimization algorithm. Thus, the proposed M-MultiSVM model can efficiently detect intrusion in the network. The performance metrics show that the proposed system achieved 99.89 % accuracy by using the CSE-CIC-IDS 2018 dataset; also, the proposed system achieved 97.535 % accuracy by using the UNSW-NB15 dataset.}
}


@article{DBLP:journals/compsec/GadallahIO24,
	author = {Waheed G. Gadallah and
                  Hosny M. Ibrahim and
                  Nagwa M. Omar},
	title = {A deep learning technique to detect distributed denial of service
                  attacks in software-defined networks},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103588},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103588},
	doi = {10.1016/J.COSE.2023.103588},
	timestamp = {Fri, 09 Feb 2024 16:22:19 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/GadallahIO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software-Defined Network (SDN) is an established networking paradigm that separates the control plane from the data plane. It has central network control, and programmability facilities, therefore SDN can improve network flexibility, management, performance, and scalability. The programmability and control centralization of SDN have improved network functions but also exposed it to security challenges such as Distributed Denial of Service (DDoS) attacks that target both control and data planes. This paper proposes an effective detection technique against DDoS attack in SDN control plane and data plane. For the control plane, the technique detects DDoS attacks through a Deep Learning (DL) model using new features extracted from traffic statistics. A DL method (AE-BGRU) for DDoS detection uses Autoencoder (AE) with Bidirectional Gated Recurrent Unit (BGRU). The proposed features for the control plane include unknown IP destination address, packets inter-arrival time, Transport layer protocol (TLP) header, and Type of service (ToS) header. For the data plane, the technique tracks the switch's average arrival bit rate with an unknown destination address in the data plane. Then, the technique detects DDoS attacks through a DL-based model which also uses AE with BGRU. The proposed features in the data plane include the switch's stored capacity, the average rate of packets with unknown destination addresses, the IP Options header, and the average number of flows. The dataset is generated from feature extraction and computations from normal and attack packets and used with the classifier. Also, additional Machine Learning (ML) methods are used to enhance the detection process. If the model detects an attack, the technique mitigates DDoS effects by updating the user's trust value and blocking suspicious senders based on the trust value. The experimental results proved that compared to related techniques, the suggested method had a higher accuracy and lower false alarm rate.}
}


@article{DBLP:journals/compsec/WoodsS24,
	author = {Naomi Woods and
                  Mikko T. Siponen},
	title = {How memory anxiety can influence password security behavior},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103589},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103589},
	doi = {10.1016/J.COSE.2023.103589},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WoodsS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Password reuse and modification are insecure password behaviors that are becoming increasingly prevalent as users are obliged to remember more passwords to access various digital services. Many users adopt these risky behaviors as a memory strategy in the belief that they have too many passwords for their memories to cope with. One important avenue in password research is metamemory, which encompasses the knowledge and understanding of memory capabilities and strategies. Previous research on password metamemory has examined the role that metamemory plays in memory performance (i.e., how well memory performs) and password recall. However, no previous research to date has investigated whether password reuse and modification are adopted as memory strategies due to an increase in knowledge and understanding of metamemory. To address this gap, two survey studies (Study1: N = 50, Study 2: N = 303) were implemented to examine the role that password metamemory plays in reusing and modifying passwords. Our findings suggest that of all metamemory constructs, users’ anxiety regarding their perceived ability to remember passwords can influence them to reuse and modify their passwords. These findings have potentially important implications because with an enhanced understanding of how users’ anxiety towards remembering passwords influences their security behavior, this could identify means of reducing password reuse and modification, thereby increasing password security and ultimately reduce some of the consequences of insecure password behaviors.}
}


@article{DBLP:journals/compsec/LanduytWJ24,
	author = {Dimitri Van Landuyt and
                  Vincent Wijshoff and
                  Wouter Joosen},
	title = {A study of NoSQL query injection in Neo4j},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103590},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103590},
	doi = {10.1016/J.COSE.2023.103590},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LanduytWJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Query injection refers to a class of attack types that involve the insertion of maliciously crafted query parameters in database query operations, and/or API calls. Although these security issues have been studied extensively in relational databases, the possibility and incidence of injection in NoSQL data stores –which are built around fundamentally different data models– has received less attention.}
}


@article{DBLP:journals/compsec/DurstHZ24,
	author = {Susanne Durst and
                  Christoph Hinteregger and
                  Malgorzata Zieba},
	title = {The effect of environmental turbulence on cyber security risk management
                  and organizational resilience},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103591},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103591},
	doi = {10.1016/J.COSE.2023.103591},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/DurstHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Even though there is a plethora of research on the role of environmental turbulence in organizational performance in general, little attention has been paid to the effect of environmental turbulence on cyber security risk management and further - organizational resilience. Drawing on the resource-based view and contingency theory, this study investigates how technological and market turbulence influence organizational cyber security risk management (CSRM) and then organizational resilience. Using a data set from 150 European companies, the study findings show how the two types of turbulence have different effects on CSRM in the companies studied. Technological turbulence directly impacts the firms’ cyber security risk maturity while market turbulence has a direct positive affect on firms’ cyber security risk perception. The study also determines the interplay between risk perception and risk maturity and subsequent resilience.}
}


@article{DBLP:journals/compsec/Schiavone24,
	author = {Antonio Giovanni Schiavone},
	title = {Municipality2HTTPS: {A} study on {HTTPS} protocol's usage in
                  Italian municipalities' websites},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103592},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103592},
	doi = {10.1016/J.COSE.2023.103592},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/Schiavone24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The usage of HTTPS protocol is essential for secure communication with websites, especially when it comes to the websites of local municipalities. This protocol ensures the confidentiality, integrity, and authenticity of online data transmissions, protecting users from unauthorised access and data breaches. By implementing HTTPS, municipalities can provide a secure and reliable online experience for their citizens and build trust in their digital services. This paper presents the Municipality2HTTPS research project, which aim is to provide a comprehensive analysis of the current state of HTTPS implementation in approximately 8,000 Italian municipalities’ websites. The study was conducted using the purpose-built software platform, named MunicipalityEvaluator, and the results were aggregated both geographically and demographically based on a numerical score derived from a specific scoring system: this system was obtained by expanding the requirements set forth by Italian regulations on the topic. The obtained results identified several areas for improvement in HTTPS implementation and regulatory compliance, including the need for more awareness-raising activities and support for municipalities with limited technical expertise. The results also revealed discrepancies between regions and demographic groups in terms of HTTPS implementation and regulatory compliance.}
}


@article{DBLP:journals/compsec/TuptukH24,
	author = {Nilufer Tuptuk and
                  Stephen Hailes},
	title = {Identifying vulnerabilities of industrial control systems using evolutionary
                  multiobjective optimisation},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103593},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103593},
	doi = {10.1016/J.COSE.2023.103593},
	timestamp = {Sun, 06 Oct 2024 21:22:23 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/TuptukH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a novel methodology to assist in identifying vulnerabilities in real-world complex heterogeneous industrial control systems (ICS) using two Evolutionary Multiobjective Optimisation (EMO) algorithms, NSGA-II and SPEA2. Our approach is evaluated on a well-known benchmark chemical plant simulator, the Tennessee Eastman (TE) process model. We identified vulnerabilities in individual components of the TE model and then made use of these vulnerabilities to generate combinatorial attacks. The generated attacks were aimed at compromising the safety of the system and inflicting economic loss. Results were compared against random attacks, and the performance of the EMO algorithms was evaluated using hypervolume, spread, and inverted generational distance (IGD) metrics. A defence against these attacks in the form of a novel intrusion detection system was developed, using machine learning algorithms. The designed approach was further tested against the developed detection methods. The obtained results demonstrate that the developed EMO approach is a promising tool in the identification of the vulnerable components of ICS, and weaknesses of any existing detection systems in place to protect the system. The proposed approach can serve as a proactive defense tool for control and security engineers to identify and prioritise vulnerabilities in the system. The approach can be employed to design resilient control strategies and test the effectiveness of security mechanisms, both in the design stage and during the operational phase of the system.}
}


@article{DBLP:journals/compsec/ChenHK24,
	author = {Jiayi Chen and
                  Urs Hengartner and
                  Hassan Khan},
	title = {{SHRIMPS:} {A} framework for evaluating multi-user, multi-modal implicit
                  authentication systems},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103594},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103594},
	doi = {10.1016/J.COSE.2023.103594},
	timestamp = {Fri, 09 Feb 2024 16:22:19 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ChenHK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart devices are commonly used in multi-user scenarios, such as shared household devices and shared corporate devices for front-line workers. A multi-user device requires both identification and authentication to defend against unauthorized access and distinguish between legitimate users in real-time, especially when multiple users participate in the same session. Although implicit authentication (IA) has been proposed to provide continuous and transparent authentication throughout a session, most existing IA solutions are optimized for single-user scenarios. The challenges of designing multi-user IA systems include fusing multiple modalities for good accuracy, segmenting and labeling behavioral data while authenticating, and adapting IA models to new users and new incoming data. We propose SHRIMPS, an evaluation framework to support IA researchers in the design of multi-user, multi-modal IA systems. SHRIMPS allows the evaluation of multi-user IA solutions that incorporate multiple modalities and supports adding new users and automatically labeling new incoming data for model updating. SHRIMPS supports different score fusion strategies, including a novel score fusion strategy based on Dempster-Shafer (D-S) theory to improve accuracy with considering uncertainties among different IA mechanisms. SHRIMPS enables composing tasks with public datasets to evaluate and compare different IA schemes. We present and evaluate two sample use cases to showcase how SHRIMPS helps address practical design questions of multi-user, multi-modal IA systems. The evaluation results show that D-S theory based score fusion methods can effectively reject attackers and detect user switches for the multi-user scenario in real-time.}
}


@article{DBLP:journals/compsec/GengWFZWG24,
	author = {Jiaxuan Geng and
                  Junfeng Wang and
                  Zhiyang Fang and
                  Yingjie Zhou and
                  Di Wu and
                  Wenhan Ge},
	title = {A survey of strategy-driven evasion methods for {PE} malware: Transformation,
                  concealment, and attack},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103595},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103595},
	doi = {10.1016/J.COSE.2023.103595},
	timestamp = {Fri, 22 Mar 2024 09:01:46 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/GengWFZWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The continuous proliferation of malware poses a formidable threat to the cyberspace landscape. Researchers have proffered a multitude of sophisticated defense mechanisms aimed at its detection and mitigation. Nevertheless, malware writers persistently pursue pioneering and innovative methods to evade detection by security software, thereby presenting an ever-evolving and dynamic threat to computer systems. Malware evasion refers to the use of certain strategies by malware to evade the detection of security software. Despite numerous surveys on malware evasion techniques, the existing surveys were fragmented and focused on specific types of evasion methods, leading to a lack of systematic and comprehensive research on malware evasion approaches. To fill this gap, this paper proposed a strategy-driven framework from the perspective of malware writers. Based on this framework, we categorize existing evasion detection techniques into transformation (alter the structural and behavioral pattern of the malware), concealment (conceal the behavior of the malware), and attack-based (engage in an attack on the detector to render it inoperable) methods and conduct a comprehensive survey of the relevant research works. In addition, we demonstrate how to integrate existing evasion strategies in the process of generating malware from the perspective of malware writers to subvert the multiple defenses of defenders. Our investigation indicates that: 1) evasion techniques such as packer and code obfuscation remain the foremost selection for attackers, no fewer than 10 off-the-shelf tools provide great assistance to them, 2) environment analysis is the primary concealment-based strategy used by the attacker (48% of the reviewed concealment-based strategy), defenders need greater efforts to counter them, 3) only 3 works discussed techniques for evasion attacks by leveraging fragilities in antivirus engines, meaning that direct attack on the detector is no longer as effective, 4) reinforcement learning algorithm serves as the most popular adversarial attack-based methods and 50% of works based on reinforcement learning are effective against real-world antivirus engines. Furthermore, this paper delves into the development trends in evasive malware and open issues for defenders. The primary objective of this survey is to furnish researchers and practitioners with a thorough comprehension of malware evasion strategies and techniques, thereby fostering the advancement of more potent and efficient approaches to detect and thwart malware.}
}


@article{DBLP:journals/compsec/SanchezCBP24,
	author = {Pedro Miguel S{\'{a}}nchez S{\'{a}}nchez and
                  Alberto Huertas Celdr{\'{a}}n and
                  G{\'{e}}r{\^{o}}me Bovet and
                  Gregorio Mart{\'{\i}}nez P{\'{e}}rez},
	title = {Single-board device individual authentication based on hardware performance
                  and autoencoder transformer models},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103596},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103596},
	doi = {10.1016/J.COSE.2023.103596},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SanchezCBP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of the Internet of Things (IoT) has led to the emergence of crowdsensing applications, where a multitude of interconnected devices collaboratively collect and analyze data. Ensuring the authenticity and integrity of the data collected by these devices is crucial for reliable decision-making and maintaining trust in the system. Traditional authentication methods are often vulnerable to attacks or can be easily duplicated, posing challenges to securing crowdsensing applications. Besides, current solutions leveraging device behavior are mostly focused on device identification, which is a simpler task than authentication. To address these issues, an individual IoT device authentication framework based on hardware behavior fingerprinting and Transformer autoencoders is proposed in this work. To support the design, a threat model details the security problems faced when performing hardware-based authentication in IoT. This solution leverages the inherent imperfections and variations in IoT device hardware to differentiate between devices with identical specifications. By monitoring and analyzing the behavior of key hardware components, such as the CPU, GPU, RAM, and Storage on devices, unique fingerprints for each device are created. The performance samples are considered as time series data and used to train outlier detection transformer models, one per device and aiming to model its normal data distribution. Then, the framework is validated within a spectrum crowdsensing system leveraging Raspberry Pi devices. After a pool of experiments, the model from each device is able to individually authenticate it between the 45 devices employed for validation. An average True Positive Rate (TPR) of 0.74±0.13 and an average maximum False Positive Rate (FPR) of 0.06±0.09 demonstrate the effectiveness of this approach in enhancing authentication, security, and trust in crowdsensing applications.}
}


@article{DBLP:journals/compsec/CorinS24,
	author = {Roberto Doriguzzi Corin and
                  Domenico Siracusa},
	title = {{FLAD:} Adaptive Federated Learning for DDoS attack detection},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103597},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103597},
	doi = {10.1016/J.COSE.2023.103597},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/CorinS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has been recently receiving increasing consideration from the cybersecurity community as a way to collaboratively train deep learning models with distributed profiles of cyber threats, with no disclosure of training data. Nevertheless, the adoption of FL in cybersecurity is still in its infancy, and a range of practical aspects have not been properly addressed yet. Indeed, the Federated Averaging algorithm at the core of the FL concept requires the availability of test data to control the FL process. Although this might be feasible in some domains, test network traffic of newly discovered attacks cannot be always shared without disclosing sensitive information. In this paper, we address the convergence of the FL process in dynamic cybersecurity scenarios, where the trained model must be frequently updated with new recent attack profiles to empower all members of the federation with the latest detection features. To this aim, we propose FLAD (adaptive Federated Learning Approach to DDoS attack detection), an FL solution for cybersecurity applications based on an adaptive mechanism that orchestrates the FL process by dynamically assigning more computation to those members whose attacks profiles are harder to learn, without the need of sharing any test data to monitor the performance of the trained model. Using a recent dataset of DDoS attacks, we demonstrate that FLAD outperforms state-of-the-art FL algorithms in terms of convergence time and accuracy across a range of unbalanced datasets of heterogeneous DDoS attacks. We also show the robustness of our approach in a realistic scenario, where we retrain the deep learning model multiple times to introduce the profiles of new attacks on a pre-trained model.}
}


@article{DBLP:journals/compsec/AzimjonovK24,
	author = {Jahongir Azimjonov and
                  Taehong Kim},
	title = {Designing accurate lightweight intrusion detection systems for IoT
                  networks using fine-tuned linear {SVM} and feature selectors},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103598},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103598},
	doi = {10.1016/J.COSE.2023.103598},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/AzimjonovK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intrusion detection systems (IDSs) play a crucial role in ensuring the security and integrity of Internet of Things (IoT) networks by blocking unwanted packets and facilitating secure traffic flow. However, traditional IDSs based on data mining, fuzzy logic, heuristics, rough sets, or conventional machine learning (ML) techniques often lack accuracy and are not energy efficient, primarily due to inappropriate feature selection or the use of all features in datasets. To address these challenges, this study proposes a lightweight, accurate, and high-performance IDSs for IoT networks using fine-tuned Linear Support Vector Machines (LSVMs) and feature selection methods. Four feature selectors, including Importance Coefficient-, Forward- and Backward-Sequential-, and Correlation Coefficient-based approaches, were applied to identify the most important and efficient features from three datasets: KDD Cup-1999, BotIoT-2018, and N-BaIoT-2021. The fine-tuned LSVMs algorithm was then trained on subsets of the selected and full features of the datasets to detect various IoT botnet attacks. Evaluation results show that the IDS models trained with subsets of relevant features outperform those trained with the full feature sets of the datasets in terms of training and test performance and accuracy. The study concludes that it is possible to develop lightweight IDSs by training them with a reduced number of features (6) instead of using the full features (40, 15, 115) in KDD Cup-1999, BotIoT-2018, and N-BaIoT-2021, respectively. The findings highlight a potential for significantly improving the efficiency and accuracy of IDSs on IoT networks using the fine-tuned feature selectors and LSVMs.}
}


@article{DBLP:journals/compsec/KozikFPPPC24,
	author = {Rafal Kozik and
                  Massimo Ficco and
                  Aleksandra Pawlicka and
                  Marek Pawlicki and
                  Francesco Palmieri and
                  Michal Choras},
	title = {When explainability turns into a threat - using xAI to fool a fake
                  news detection method},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103599},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103599},
	doi = {10.1016/J.COSE.2023.103599},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KozikFPPPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The inclusion of Explainability of Artificial Intelligence (xAI) has become a mandatory requirement for designing and implementing reliable, interpretable and ethical AI solutions in numerous domains. xAI is now the subject of extensive research, from both the technical and social science perspectives. It is being received enthusiastically by legislative bodies and regular users of machine-learning-boosted applications alike. However, opening the black box of AI comes at a cost. This paper presents the results of the first study proving that xAI can enable successful adversarial attacks in the domain of fake news detection and lead to a decrease in AI security. We postulate the novel concept that xAI and security should strike a balance, especially in critical applications, such as fake news detection. An attack scheme against fake news detection methods is presented that employs an explainable solution. The described experiment demonstrates that the well-established SHAP explainer can be used to reshape the structure of the original message in such a way that the value of the model's prediction could be arbitrarily forced, whilst the meaning of the message stays the same. The paper presents various examples for which the SHAP values are used to point the adversary to the words and phrases that have to be changed to flip the label on the model prediction. To the best of the authors' knowledge, it has been the first research work to experimentally demonstrate the sinister side of xAI. As the generation and spreading of fake news has become a tool of modern warfare and a grave threat to democracy, the potential impact of explainable AI should be addressed as soon as possible.}
}


@article{DBLP:journals/compsec/SethuramanSRRK24,
	author = {Sibi Chakkaravarthy Sethuraman and
                  Devi Priya V. S and
                  Tarun Reddi and
                  Mulka Sai Tharun Reddy and
                  Muhammad Khurram Khan},
	title = {A comprehensive examination of email spoofing: Issues and prospects
                  for email security},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103600},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103600},
	doi = {10.1016/J.COSE.2023.103600},
	timestamp = {Sun, 06 Oct 2024 21:22:23 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SethuramanSRRK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attackers are becoming more skilled in recent years, using sophisticated technology to produce look-alike emails that make it difficult to distinguish between real and fake ones. Most false emails can be detected, but certain undiscovered ones can be dangerous and compromise security. The attacker compromises SMTP to launch an email spoofing attack. This is not difficult given that it was designed without any security safeguards. Spoofers typically exploit the various fields in email headers. By taking advantage of loopholes in email security systems, attackers can create an ideal spoofing mail. As a result, it appears as a reliable source and succeeds in phishing attempts. An in-depth analysis of the email process, its protocols, and authentication mechanisms along with the security measures and adoption rates that led to a variety of spoofing attacks has been examined in our work. Our experiments on renowned mail service suppliers observed that some of them are still vulnerable to associated flaws. Further, we analyzed how different aspects such as age and education, determine whether or not a message is spoofed, and how malware uses email as a command and control to compromise the victim's device and seize control of it. Further, it offers a multitude of mitigation strategies against spoofing attempts that aid aspirants in future research.}
}


@article{DBLP:journals/compsec/ChenDLC24,
	author = {Peng Chen and
                  Xin Du and
                  Zhihui Lu and
                  Hongfeng Chai},
	title = {Universal adversarial backdoor attacks to fool vertical federated
                  learning},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103601},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103601},
	doi = {10.1016/J.COSE.2023.103601},
	timestamp = {Wed, 14 Aug 2024 11:18:55 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenDLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vertical federated learning (VFL) is a privacy-preserving distribution learning paradigm that enables participants, owning different features of the same sample space to train a machine learning model collaboratively while retaining their data locally. This paradigm facilitates improved efficiency and security for participants such as financial or medical fields, making VFL an essential component of data-driven Artificial Intelligence systems. Nevertheless, the partitioned structure of VFL can be exploited by adversaries to inject a backdoor, enabling them to manipulate the VFL predictions. In this paper, we aim to investigate the vulnerability of VFL in the context of binary classification tasks. To this end, we define a threat model for backdoor attacks in VFL and introduce a universal adversarial backdoor (UAB) attack to poison the predictions of VFL. The UAB attack, consisting of universal trigger generation and clean-label backdoor injection, is incorporated during the VFL training at specific iterations. This is achieved by alternately optimizing VFL sub-problems' universal trigger and model parameters. Our work distinguishes itself from existing studies on designing backdoor attacks for VFL, as those require the knowledge of auxiliary information that is not accessible within the split VFL architecture. In contrast, our approach does not require additional data to execute the attack. On the real-world datasets, our approach surpasses existing state-of-the-art methods, achieving up to 100% backdoor task performance while maintaining the main task performance. Our results in this paper make a major advance in revealing the hidden backdoor risks of VFL, hence paving the way for the future development of secure VFL. Our results in this paper make a major advance in revealing the hidden backdoor risks of VFL, hence paving the way for the future development of secure VFL applications such as finance.}
}


@article{DBLP:journals/compsec/KonstaLSD24a,
	author = {Alyzia Maria Konsta and
                  Alberto Lluch{-}Lafuente and
                  Beatrice Spiga and
                  Nicola Dragoni},
	title = {Survey: Automatic generation of attack trees and attack graphs},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103602},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103602},
	doi = {10.1016/J.COSE.2023.103602},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KonstaLSD24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphical security models constitute a well-known, user-friendly way to represent the security of a system. These classes of models are used by security experts to identify vulnerabilities and assess the security of a system. The manual construction of these models can be tedious, especially for large enterprises. Consequently, the research community is trying to address this issue by proposing methods for the automatic generation of such models. In this work, we present a survey illustrating the current status of the automatic generation of two popular kinds of graphical security models: Attack Trees and Attack Graphs. The goal of this survey is to present the current methodologies used in the field, compare them, and present the challenges and future directions to the research community.}
}


@article{DBLP:journals/compsec/YuWW24,
	author = {Rongwei Yu and
                  Yong Wang and
                  Wang Wang},
	title = {{AMAD:} Active learning-based multivariate time series anomaly detection
                  for large-scale {IT} systems},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103603},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103603},
	doi = {10.1016/J.COSE.2023.103603},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YuWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time series anomaly detection on key performance indicators helps mitigate the impact of large-scale IT system anomalies. Due to the large volume and the abstract nature of multivariate time series, previous works have tended to make overly strict or optimistic hypotheses on labeling costs and resulted in unsatisfactory results. Thus, it remains a challenge to make an appropriate trade-off between labeling costs and model performance. This research proposes AMAD, an active learning-based approach that works to address this problem. Its core idea is to provide the learner model high-value label queries via an ensemble query strategy, which dynamically adapts to the estimated anomaly ratio and the ever-changing model performance. Moreover, it is the first to discuss in detail the margin effect of query strategies on model performance, to our knowledge, this has not been investigated in previous works on time series anomaly detection. Extensive experiments on five public datasets demonstrate that AMAD works well and robustly on various real-world scenarios, which outperforms state-of-the-art baseline methods by 16% and 11% in terms of recall and F1, with only 3% of data being labeled.}
}


@article{DBLP:journals/compsec/LiHLFYL24,
	author = {Junhao Li and
                  Junjiang He and
                  Wenshan Li and
                  Wenbo Fang and
                  Geying Yang and
                  Tao Li},
	title = {SynDroid: An adaptive enhanced Android malware classification method
                  based on {CTGAN-SVM}},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103604},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103604},
	doi = {10.1016/J.COSE.2023.103604},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiHLFYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Android mobile phones have the highest market share nowadays, bringing a boom of Android application programming as well as malicious software (malware) issues. Traditional machine learning and deep learning methods are widely used in Android malware detection and classification, both require plenty of application samples to train classifiers. However, the collected samples are always imbalanced, because the distribution of malware categories differs hugely in the real environment. For Android malware samples with high dimension features, and Class Imbalance Ratio coming to more than 100:1, traditional methods become weak. To fill the gap, we propose an Android malware classification model named SynDroid. The core step of SynDroid uses CTGAN-SVM to generate qualified high-dimension samples, and adaptively discards bad results. Besides, we propose KS-CIR test to help the model to determine which classes of data needed to be enhanced most. This new proposed test can measure the data in respect of both samples' quality and quantity. Lastly, Random Forest is taken as a classifier to finish the classification task. The performance of SynDroid is evaluated on CCCS-CIC-AndMal2020 on the accuracy, precision, recall and F1-score. Both longitudinal and horizontal comparison experiments have been done with traditional oversampling methods, cost-sensitive learning, and other complicated methods. The result shows that the proposed method gets 12% more accuracy than the method on the same dataset and alleviates imbalanced data problems.}
}


@article{DBLP:journals/compsec/MestariLD24,
	author = {Soumia Zohra El Mestari and
                  Gabriele Lenzini and
                  H{\"{u}}seyin Demirci},
	title = {Preserving data privacy in machine learning systems},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103605},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103605},
	doi = {10.1016/J.COSE.2023.103605},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MestariLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The wide adoption of Machine Learning to solve a large set of real-life problems came with the need to collect and process large volumes of data, some of which are considered personal and sensitive, raising serious concerns about data protection. Privacy-enhancing technologies (PETs) are often indicated as a solution to protect personal data and to achieve a general trustworthiness as required by current EU regulations on data protection and AI. However, an off-the-shelf application of PETs is insufficient to ensure a high-quality of data protection, which one needs to understand. This work systematically discusses the risks against data protection in modern Machine Learning systems taking the original perspective of the data owners, who are those who hold the various data sets, data models, or both, throughout the machine learning life cycle and considering the different Machine Learning architectures. It argues that the origin of the threats, the risks against the data, and the level of protection offered by PETs depend on the data processing phase, the role of the parties involved, and the architecture where the machine learning systems are deployed. By offering a framework in which to discuss privacy and confidentiality risks for data owners and by identifying and assessing privacy-preserving countermeasures for machine learning, this work could facilitate the discussion about compliance with EU regulations and directives.}
}


@article{DBLP:journals/compsec/ZouCWFQS24,
	author = {Binghui Zou and
                  Chunjie Cao and
                  Longjuan Wang and
                  Sizheng Fu and
                  Tonghua Qiao and
                  Jingzhang Sun},
	title = {{FACILE:} {A} capsule network with fewer capsules and richer hierarchical
                  information for malware image classification},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103606},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103606},
	doi = {10.1016/J.COSE.2023.103606},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZouCWFQS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The struggle between security researchers and malware perpetuates an endless arms race. Recent studies indicate that converting malware into grayscale images and using convolutional neural network or capsule network to classify and identify them is a promising approach. Nonetheless, training convolutional neural networks demands a significant amount of data and parameters, posing a challenge to obtaining enough training samples for malware detection tasks, particularly for new malware families. Additionally, a high number of parameters translates to low classification efficiency. Capsule networks offer a promising approach to achieve higher-level feature representations through dynamic routing between capsules, but research on capsule networks is still nascent, and there are two major challenges for malware classification tasks: the huge number of parameters, which makes model training difficult, and capsules shedding, which results in information loss during routing. To address these issues, we propose a capsule network called FACILE that uses fewer capsules and richer hierarchical information. In the initial feature extraction stage, we perform multi-level feature extraction and fusion using dynamic convolution. In the routing phase, we introduce balance coefficients to enhance the model's representational power and stabilize the training process. We conducted experiments on the VIRUS-MNIST, MalImg, and BIG2015 datasets and found that FACILE requires only 8.1% of the capsules and 1.8%-3.3% of the parameters compared to the original CapsNet, while reducing the error rate to 8.087%, 1.149%, and 2.797%, respectively. Furthermore, FACILE demonstrates competitive performance with a small number of parameters as the training samples decrease compared to convolutional neural network-based models such as ResNet, EfficientNet, and VGG.}
}


@article{DBLP:journals/compsec/KrzyworzekaOO24,
	author = {Natalia Krzyworzeka and
                  Lidia Ogiela and
                  Marek R. Ogiela},
	title = {Personal CAPTCHA-based authentication protocol},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103613},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103613},
	doi = {10.1016/J.COSE.2023.103613},
	timestamp = {Fri, 09 Feb 2024 16:22:19 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KrzyworzekaOO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the number of personal accounts assigned to a single user has considerably increased. According recent study, the average employee had above 190 individual login credentials. The most important problems users face with such a large number of passwords are the strength of passwords and the user's ability to remember them. Researchers have shown that, in general, users are aware of what a secure password should look like, but may forgot these security measures in favour of more convenient passwords, depending largely on the type of account (le Bras, 2015). Repeating the same password across multiple platforms or creating it using dictionary words has also proven to be a common practice among many people. In this article, a new password reminder scheme will be presented. The goal was for the user to create a CAPTCHA-like image with a hidden meaning that only the user would be able to reveal. The image must have some connection to the person's experience and memory or unique knowledge. With such an image, presented each time the user logs in, he is asked to associate a password consisting of two or more words and a number. If the image is appropriately selected and associated with a strong association with the person's visual memory, the chances of recalling the long password he created in this way should not be a problem.}
}


@article{DBLP:journals/compsec/BilikaMAP24,
	author = {Domna Bilika and
                  Nikoletta Michopoulou and
                  Efthimios Alepis and
                  Constantinos Patsakis},
	title = {Hello me, meet the real me: Voice synthesis attacks on voice assistants},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103617},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103617},
	doi = {10.1016/J.COSE.2023.103617},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BilikaMAP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The radical advances in telecommunications and computer science have enabled a myriad of applications and novel seamless interactions with computing interfaces. Voice Assistants (VAs) have become the norm for smartphones, and millions of VAs incorporated in smart devices are used to control these devices in the smart home context. Previous research has shown that they are prone to attacks, leading vendors to implement countermeasures. One of these measures is to allow only a specific individual, the device's owner, to perform potentially dangerous tasks that may disclose personal information, involve monetary transactions, etc. To understand the extent to which VAs provide the necessary protection to their users, we experimented with two of the most widely used VAs, which the participants trained. We then utilised voice synthesis, using samples provided by participants, to synthesise commands that were used to trigger the corresponding VA and perform a dangerous task. Our extensive results showed that more than 30% of our audio synthesis attacks were successful and at least one successful attack for more than half of the participants. Moreover, they illustrate statistically significant variation among vendors and, in one case, even gender bias. The outcomes are rather alarming and require the deployment of further countermeasures to prevent exploitation, as the number of VAs in use is currently comparable to the world population.}
}


@article{DBLP:journals/compsec/LiSGYL24,
	author = {Huang Li and
                  Yiqin Sang and
                  Hongjuan Ge and
                  Jie Yan and
                  Shijia Li},
	title = {Anomaly detection of aviation data bus based on {SAE} and {IMD}},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103619},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103619},
	doi = {10.1016/J.COSE.2023.103619},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiSGYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To detect remote terminal (RT) spoofing attacks on MIL-STD-1553B data bus and prevent the network paralysis of integrated avionics system (IAS) caused by misjudgment, an anomaly detection method of aviation data bus based on the combination of sparse autoencoder (SAE) and integrated mahalanobis distance (IMD) is proposed. Aiming at the communication traffic training set with only normal data, an unsupervised learning algorithm SAE is used to train a model that only represents normal behavior. To combine the feature information of each layer within SAE, the IMD, which can measure the similarity between data characteristics, is used to obtain the anomaly score of test data, and the comprehensive anomaly score (CAS) is obtained by considering the reconstruction error between SAE input and output. To solve the problem that data distribution and detection requirements were not considered in a single threshold, a heuristic multi-threshold selection method is proposed, which maximizes the performance of the classifier by considering the accuracy, youden index (YI), and F1. The experimental results demonstrate the effectiveness and feasibility of the method.}
}


@article{DBLP:journals/compsec/BerensMV24,
	author = {Benjamin Maximilian Berens and
                  Mattia Mossano and
                  Melanie Volkamer},
	title = {Taking 5 minutes protects you for 5 months: Evaluating an anti-phishing
                  awareness video},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103620},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103620},
	doi = {10.1016/J.COSE.2023.103620},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BerensMV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing is one of the biggest security threats to organizations. Anti-phishing awareness measures can improve phishing email detection rates. These measures need to be efficient, effective, and have an enduring impact over months, rather than days. Related research provides evidence of their effectiveness in the short term. However, questions remain as to how long this impact endures. We conducted a retention user study in two phases, with almost 200 participants in the first phase and almost 80 in the second phase, to determine whether a five-minute video retains its effectiveness five months after the intervention (similar to related work on more time-intensive measures). Our results suggest that short videos can indeed still exert a positive influence five months later. We also report on the video's influence on phishing detection strategies, as well as on viewers' confidence in this respect. Based on our results, we propose recommendations to inform the content of future awareness refreshment measures.}
}


@article{DBLP:journals/compsec/YangLW24,
	author = {Benyuan Yang and
                  Lili Luo and
                  Zhimeng Wang},
	title = {Ensuring secure interoperation of access control in a multidomain
                  environment},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103621},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103621},
	doi = {10.1016/J.COSE.2023.103621},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/YangLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interoperation can combine multiple resources and domains, thus it has been widely used in many practical industrial applications, such as distributed database systems. However, the merger of local access control policies in such systems may lead to security violations with regard to access control. For instance, a person can potentially have access (indirectly) to another one's file or data in the interoperation to which s/he should be denied access in the individual system. Therefore, it is critical to deal with such issues in a multidomain environment. Nevertheless, a real-world interoperation contains a large number of entities and access. This imposes a challenge to find the maximum secure interoperation in terms of direct data sharing among individual systems. To overcome this difficulty, we propose an integer linear programming-based approach which can find the maximum secure interoperation in a computationally efficient way. Experimental results are given to demonstrate the efficacy of our approach.}
}


@article{DBLP:journals/compsec/RizviW24,
	author = {Syed Rizvi and
                  Iyonna Williams},
	title = {Analyzing transparency and malicious insiders prevention for cloud
                  computing environment},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103622},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103622},
	doi = {10.1016/J.COSE.2023.103622},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/RizviW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emerging cloud technology and its integration with cloud services from an enterprise standpoint have provided a gateway for Cloud Service Providers (CSPs) to garner consumers and their data. Due to the growing increase of Cloud Service Users (CSUs), it is pertinent to provide an adequate amount of cloud security to prevent detrimental impacts to businesses. Two large challenges CSPs face for cloud security include transparency and malicious insiders. The primary objective of this work is to provide a framework that analyzes CSPs based on evaluation metrics such as data breaches, data loss, account hijacking, insecure APIs, DoS, malicious insiders, abuse of cloud services, insufficient due diligence, and shared technology concerns. The security index of a CSP is then computed based on the listed evaluation metrics and given a score that translates to a linguistic rating of the CSP. Factors within transparency and malicious insiders are further broken down within the framework to emphasize various components. Transparency factors include published audit certifications, consumer base, membership of cloud organizations, and published incidents. Malicious insiders are sub-sectioned into personnel-related prevention, policy-related prevention, third-party CSP prevention, technical-related prevention, and hypervisor-related prevention. With this scoring contribution, analysis is able to be done on a CSP's potential threats within the network, which can then be visualized into recommended security controls or preventative measures. Finally, we conducted case studies to demonstrate the application of the scoring analysis using our proposed framework and to evaluate the security levels of two extensively employed CSPs.}
}


@article{DBLP:journals/compsec/ZhangXLYLGF24,
	author = {Xiyuan Zhang and
                  Gang Xiong and
                  Zhen Li and
                  Chen Yang and
                  Xinjie Lin and
                  Gaopeng Gou and
                  Binxing Fang},
	title = {Traffic spills the beans: {A} robust video identification attack against
                  YouTube},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103623},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103623},
	doi = {10.1016/J.COSE.2023.103623},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangXLYLGF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic-based video identification attack is a side-channel attack that allows an attacker to identify transmitted online videos from encrypted network traffic. Existing attacks face two types of challenges: 1) YouTube's improved streaming technology renders them invalid or impacted; 2) real-world diverse traffic makes them underperform. In this paper, we provide the first study of YouTube's technical improvements and reveal its three key features: i) the mechanism that replaces the MPD file, ii) variable combined segments, and iii) various buffering processes. Based on the above analysis, we propose a Robust and easily scalable Video Identification Attack against YouTube called RoVIA. RoVIA extracts video fingerprints from video file headers and reference sequences from video traffic. RoVIA uses the reference sequence to generate candidate sequences in the pre-built video fingerprint library and achieves video identification by measuring sequence similarity. Experimental results show that RoVIA achieves open-world accuracy of 0.967, 0.924, and 0.863 in open-world, fixed-quality, and poor network experiments. Furthermore, RoVIA's scalability allows the target classes to be adjusted by updating the fingerprint library without collecting new samples and retraining parameters. This study aims to demonstrate the vulnerabilities of YouTube streaming technology and the potential consequences of its malicious use. We also propose two YouTube-friendly countermeasures to help developers build effective defenses.}
}


@article{DBLP:journals/compsec/LiXSSZLZ24,
	author = {Xiang Li and
                  Jiang Xie and
                  Qige Song and
                  Yafei Sang and
                  Yongzheng Zhang and
                  Shuhao Li and
                  Tianning Zang},
	title = {Let model keep evolving: Incremental learning for encrypted traffic
                  classification},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103624},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103624},
	doi = {10.1016/J.COSE.2023.103624},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiXSSZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encrypted Traffic Classification (ETC) is valuable for many network management and security solutions as it provides insights into applications active on the network. However, the network environment constantly evolves, and new applications emerge in an endless stream daily, which gradually makes well-trained ETC models ineffective. The conventional approach to adapting new applications is to re-train the models on a re-formed dataset with both pre-existing and new application samples. The major limitation is that requiring redundant computing resources and sufficient storage spaces. In this work, we propose an Incremental Learning (IL) framework based on multi-view sequences fusion, MISS, to keep ETC models evolving with new applications. The key novelty of MISS is three-fold: extract cross-view information from multi-view sequences to capture sufficient knowledge; propose an exemplar selection algorithm from communication patterns to reduce redundant consumption; design a pair of branches from the learnability of parameters to mitigate accuracy loss during evolution. MISS outperforms the existing IL methods of ETC, and the state-of-the-art ETC models using the classic IL framework, on the real-world network traffic datasets, which achieves satisfactory improvements of 11.37%↑ and 1.58%↑. Furthermore, we comprehensively perform incremental experiments to evaluate the evolution ability of MISS, which is able to select representative exemplars of old applications, counteract the adverse effects of homogeneous applications, and keep evolving with unknown applications.}
}


@article{DBLP:journals/compsec/ZhouG24,
	author = {Peng Zhou and
                  Yuhan Gao},
	title = {Detecting prototype pollution for node.js: Vulnerability review and
                  new fuzzing inputs},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103625},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103625},
	doi = {10.1016/J.COSE.2023.103625},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhouG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Prototype pollution is a unique vulnerability originating from the JavaScript languages and has been found widely prevalent across the modern Node.js ecosystem. To detect this kind of vulnerability, state-of-the-art research either runs dynamic fuzzing on the function level to trigger the pollution in the run time or performs static analysis to look up the polluted objects in symbolic conditions. Despite succeeding to some extent, we find the current dynamic fuzzing highly relies on a very limited set of pre-defined function inputs for detection, and the static analysis cannot adapt well to large and complex Node.js modules, hence likely missing lots of potential detection possibilities. In this paper, to the best of our knowledge, we take the first review by re-detecting historical vulnerabilities of prototype pollution that have been disclosed and recorded in public databases. Surprisingly, we find out the current research can only cover some of these records. Our further analysis reveals that many cases cannot be detected because of the very limited code coverage of dynamic fuzzing and their incapability to parse large-scale code bases by static analysis. We thus can confirm the current research still has much room to improve and accordingly, we take dynamic fuzzing as a case study to show this possibility. Specifically, we have extended dynamic fuzzing by reusing new function inputs summarized from historical vulnerabilities and evaluated it over\n60\n,\n000\nNode.js packages. With this extension, we have discovered 65 new prototype pollution vulnerabilities in zero days, which cannot be covered by original dynamic fuzzing. Compared with static analysis, we also find 28 of the 65 new vulnerabilities that cannot be detected. Furthermore, for the vulnerabilities covered by both the approaches, our extended fuzzing runs more reliably and faster (with more than tens of times of speed) than its static counterpart. To the date we write this paper, we have received 6 CVE numbers and continuously negotiated with respective package maintainers (via Snyk and GitHub) for reporting and patching the remaining vulnerabilities.}
}


@article{DBLP:journals/compsec/SumanK24,
	author = {Suman and
                  Raees Ahmad Khan},
	title = {An optimized neural network for prediction of security threats on
                  software testing},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103626},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103626},
	doi = {10.1016/J.COSE.2023.103626},
	timestamp = {Fri, 09 Feb 2024 16:22:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/SumanK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software testing involves evaluating and confirming a software program or product to ensure it operates according to its intended functionality. Testing offers advantages like bug prevention, reduced development expenses, and improved performance. The problems are dialogue gap, ecological danger, creation of software quickly, cost of operation and upkeep, inadequate assessment, and incorrect testing estimates. The structure was initially educated using internet presentation data that included intrusion information. A novel Dove Swarm-based Deep Neural Method (DSbDNM) with the required traits and stages of processing has been developed. Moving forward, feature extraction and malicious behaviour forecast have both been completed. Also, the different types of assaults and negative behaviours were categorized. The developed prediction model is also examined by initiating and detecting an unidentified assault. Finally, the performance measures' accuracy, error rate, Precision, Recall and f-measure were computed. Moreover, the proposed system implementation is done in Python. Therefore, the proposed work performance can be enhanced and attain high accuracy in low computational time. For the DSbDNM dataset, the designed prototypical achieved 94.65 accuracy, 94.95 precision, 90.16 Recall and 92.02 F-measure for the NF-UQ-NIDS-v2 Dataset. Moreover, the Intrusion Detection Dataset attained an accuracy of 98, Precision of 98.8, Recall of 94.2, and F-score of 96 in the developed model. Subsequently, the Network Intrusion Detection Dataset attained an accuracy of 99, a precision of 99.2, a Recall of 95.8 and an F-measure of 97.1}
}


@article{DBLP:journals/compsec/ShankarAKJTK24,
	author = {Deepa D. Shankar and
                  Adresya Suresh Azhakath and
                  Nesma Khalil and
                  Sajeev J and
                  Mahalakshmi T and
                  Sheeba K},
	title = {Data mining for cyber biosecurity risk management - {A} comprehensive
                  review},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103627},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103627},
	doi = {10.1016/J.COSE.2023.103627},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ShankarAKJTK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The world is currently facing the era of Cyberbiosecurity, also known as Biocybersecurity, or Digital Biosecurity, which poses a few unique security vulnerabilities. A significant percentage of the scientific, agricultural, and health communities are still unaware of the unique security complexities that have resulted from fusion of the supply chain, infrastructure, cyber, and life and medical sciences. Measurement, analysis, and mitigation of cyberattacks on biological systems are the goals of Cyberbiosecurity. Data mining is a promising avenue for further investigation as a means of mitigating cyber-attacks for research purposes. Data mining is the process of extracting useful patterns, information, and expertise from massive datasets. In the domain of Cyberbiosecurity, data mining techniques have received little attention. The purpose of this survey on data mining in cybersecurity is to determine the state of the art in cybersecurity issues, including different types of assaults and data mining methods that could be used to address these issues. This review's findings shed insight on the characteristics of security issues as well as gaps in Cyberbiosecurity. Furthermore, the review's conclusions show that most responses to Cyberbiosecurity attacks advocate for national or international government/private organizations to raise public awareness of these attacks and equip their clients/dealers with secure methods to transmit data online. These attempts to raise awareness can be divided into four distinct levels, each with its own set of techniques and objectives, resulting in a holistic strategy to addressing the difficulties of Cyberbiosecurity. A notable gap found in this review is the absence of appropriate countermeasures against cyberattacks employing data mining in the biological systems domain such as healthcare, agriculture, biomedical research, and other domains. The goal of this review is to increase knowledge among Cyberbiosecurity experts and to develop innovative solutions by utilizing cutting-edge data mining techniques in this sector.}
}


@article{DBLP:journals/compsec/PiGCSYP24,
	author = {Ben Pi and
                  Chun Guo and
                  Yunhe Cui and
                  Guowei Shen and
                  Jialong Yang and
                  Yuan Ping},
	title = {Remote access trojan traffic early detection method based on Markov
                  matrices and deep learning},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103628},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103628},
	doi = {10.1016/J.COSE.2023.103628},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/PiGCSYP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote Access Trojan (RAT) allows the attacker to gain remote control of an infected system and steal data from it. Due to over-reliance on expert experience and statistical features, most feature-based RAT detection methods perform inefficiently and can only achieve high accuracy with network traffic collected over a long period of time. Byte-based RAT detection methods often use sequence truncation to process network traffic to meet the uniform-sized input requirements of convolutional neural networks (CNNs). However, the sequence truncation brings a negative impact on detection accuracy for some information loss. Towards effective and efficient RAT detection, we define the early stage from the damage degree caused on victim hosts and propose a new RAT traffic early detection method based on Markov matrices and deep learning (RATMD). In RATMD, the byte sequence of the TCP payloads of the TCP service packets collected in the early stage is represented by a byte transition probability matrix with a fixed size of 256 × 256, and the generated matrices are used to construct a detection model using a CNN architecture. Experiments are conducted on the network traffic of 58 benign applications and 61 RATs. Employing only the byte sequences derived from the TCP payloads of the TCP service packets in the traffic between the first TCP connection established by the application client and the third TCP service packet sent by the application server, RATMD achieves a detection accuracy of 95.5%.}
}


@article{DBLP:journals/compsec/FernandoK24,
	author = {Damien Warren Fernando and
                  Nikos Komninos},
	title = {FeSAD ransomware detection framework with machine learning using adaption
                  to concept drift},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103629},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103629},
	doi = {10.1016/J.COSE.2023.103629},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/FernandoK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes FeSAD, a framework that will allow a machine learning classifier to detect evolutionary ransomware. Ransomware is a critical player in the malware space that causes hundreds of millions of dollars of damage globally and evolves quickly. The evolution of ransomware in machine learning classifiers is often calculated as concept drift. Concept drift is dangerous as changes in the behavior of ransomware can easily lead to misclassifications, and misclassification can harm individuals and businesses. Our proposed framework consists of a feature selection layer, drift calibration layer and drift decision layer that allows a machine learning classifier to detect and classify concept drift samples reliably. We evaluate the FeSAD framework in various concept drift scenarios and observe its ability to detect drifting samples effectively. The FeSAD framework is also evaluated on its ability to extend the lifespan of a classifier. The results obtained by this research show that FeSAD can successfully and reliably classify ransomware and benign samples while under concept drift and can extend the time between retraining.}
}


@article{DBLP:journals/compsec/KavrestadRN24,
	author = {Joakim K{\"{a}}vrestad and
                  Jana Rambusch and
                  Marcus Nohlberg},
	title = {Design principles for cognitively accessible cybersecurity training},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103630},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103630},
	doi = {10.1016/J.COSE.2023.103630},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KavrestadRN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Exploiting human behavior to gain unauthorized access to computer systems has become common practice for modern cybercriminals. Users are expected to adopt secure behavior to avoid those attackers. This secure behavior requires cognitive processing and is often seen as a nuisance which could explain why attacks exploiting user behavior continues to be a fruitful approach for attackers. While adopting secure behavior can be difficult for any user, it can be even more difficult for users with cognitive disabilities. This research focuses on users with cognitive disabilities with the intent of developing design principles for the development of cognitively accessible cybersecurity training. The target group is estimated to include almost 10 % of all users but is previously understudied. The results show that the target group experience cybersecurity as cognitively demanding, sometimes to a degree that becomes incapacitating. Participating in cybersecurity training requires cognitive energy which is a finite resource. Cognitively accessible cybersecurity training requires a minimalist design approach and inclusion of accessibility functions. A minimalist design approach, in this case, means that both informative and design elements should be kept to a minimum. The rationale is that all such elements require cognitive processing which should be kept to a minimum.}
}


@article{DBLP:journals/compsec/WurzenbergerHLS24,
	author = {Markus Wurzenberger and
                  Georg H{\"{o}}ld and
                  Max Landauer and
                  Florian Skopik},
	title = {Analysis of statistical properties of variables in log data for advanced
                  anomaly detection in cyber security},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103631},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103631},
	doi = {10.1016/J.COSE.2023.103631},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WurzenbergerHLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Log lines consist of static parts that characterize their structure and enable assignment of event types, and event parameters, i.e., variable parts that provide specific information on system processes, such as host and user names, IP addresses, and file operations. Many detection approaches only focus on anomalous event type occurrences, i.e., they parse log lines to derive unique event identifiers and subsequently detect anomalies in event sequences or event count vectors, but neglect variable parts of log lines entirely during analysis. This is especially problematic, when monitoring strongly structured log data that contains only a small number of distinct event types, for example, logs that consist of strict key value pairs, i.e., parameters that occur consistently throughout all log lines, such as it is case in access and audit logs. Thus, novel approaches are required, which focus on analysis of log lines' variable parts. In this paper, we propose the variable type detector (VTD), a novel unsupervised approach that autonomously analyzes variable log line parts to enable anomaly detection. It assigns data types to each variable, which also include probability distributions for discrete and continuous variables. The VTD raises an alarm if a variable's data type changes. Furthermore, it implements a robust indicator function that reduces false positives by tracking the data type history of each variable and reports only significant data type changes. Additionally, an event indicator enables event-based anomaly detection by taking into account the data types of all variables of a single event type. The evaluation conducted on open-source log data, demonstrates the effectiveness of the VTD compared to conventional anomaly detection approaches, such as time series analysis and PCA. Consequently, the VTD acts as a solution that extends the intrusion detection capabilities of security information and event management (SIEM) and integrates with modern concepts of endpoint detection and response (EDR) and extended detection and responses (XDR), while simultaneously serving as an asset for process monitoring that supports user and entity behavior analytics (UEBA).}
}


@article{DBLP:journals/compsec/GuoLX24,
	author = {Ping Guo and
                  Wenfeng Liang and
                  Shuilong Xu},
	title = {A privacy preserving four-factor authentication protocol for internet
                  of medical things},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103632},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103632},
	doi = {10.1016/J.COSE.2023.103632},
	timestamp = {Fri, 09 Feb 2024 16:22:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/GuoLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medical applications of the Internet of Things (IoT) have gained significant attention, especially in the context of monitoring health-related information for elderly individuals living alone and patients receiving home-based care, especially during the COVID-19 pandemic. These applications offer immense convenience and contribute to the reduction of infection risk. Consequently, safeguarding the privacy of patient data has become increasingly vital. However, the resource limitations inherent to IoT present challenges in implementing complex algorithms. Numerous researchers have proposed authentication schemes based on three factors: passwords, biometric features, and smart cards. While three-factor authentication protocols are generally more secure than two-factor ones, recent studies have unveiled vulnerabilities in existing protocols designed for IoT environments, particularly concerning sensor node capture attack and smart card stolen attack. Only a few protocols provide reliable solutions to address these issues. To tackle this challenge, we propose a lightweight authentication protocol that introduces the Physical Unclonable Function (PUF) as the fourth factor, enhancing the security and privacy of the system. By integrating PUF technology into servers and embedding it into the integrated circuit chips of sensors, our protocol is specifically designed to thwart attacks like sensor node capture and smart card stolen. We validate the security of our proposed protocol using formal BAN logic and ProVerif simulator tool, demonstrating its capability to provide secure mutual authentication. Moreover, through informal analysis, we illustrate that our scheme can withstand multiple attacks. Furthermore, our proposed protocol outperforms existing protocols in terms of computational cost, storage cost, communication cost, and security requirements.}
}


@article{DBLP:journals/compsec/KhalilFHM24,
	author = {Fatima Mavra Khalil and
                  Adnan Fazil and
                  Muhammad Jawad Hussain and
                  Ammar Masood},
	title = {Cross-Layer {RF} Distance Bounding Scheme for Passive and Semi-passive
                  Ubiquitous Computing Systems},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103633},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103633},
	doi = {10.1016/J.COSE.2023.103633},
	timestamp = {Fri, 22 Mar 2024 09:01:46 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KhalilFHM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distance Bounding protocols have surfaced as an appealing security measure in ubiquitous computing systems with access control provisions whereby the physical proximity of a user becomes significantly important for its explicit privileges and assurances. These systems employ cryptographic protocols to ensure security. However, security vulnerabilities have been demonstrated that exploit not only the cryptographic protocol but the physical implementation of the protocol itself. Distance Bounding resolves this problem by tightly integrating cryptographic security with the physical layer through a cross-layer security design. The core idea is to employ physical proximity as a security fingerprint to ensure that the legitimate entity (namely ‘prover’) lies within an agreed spatial range of another entity (‘verifier’). While a large number of Distance Bounding protocols have been proposed in the past, they mainly focus on designing a secure authentication scheme integrated with a suitable distance measurement approach, disregarding multiple concerns in the practical realization of these protocols – which we termed as a cross-layer problem. Only a few practical Distance Bounding realizations have been demonstrated which however focus on some selected cross-layer design parameters. As a result, either these protocols are impractical as a realizable system, or in most cases, an attacker can easily exploit cross-layer vulnerabilities especially if the prover is a resource-constrained entity such as a fully passive or battery-assisted access control token. This requires formulation of a careful prover design while ensuring that secure authentication and precise ranging are tightly integrated in a cross-layer manner for a realizable system. To resolve these issues, we first present a holistic approach to designing a secure Distance Bounding system by identifying essential cross-layer parameters. While analyzing the salient Distance Bounding realizations, we observe them to be designed for a single-bit communication channel. We optimize the communication bit rate by incorporating a high-order modulation technique in our proposed scheme to achieve higher date rates while ensuring the overall integrity of cross-layer design parameters. Besides, we specifically analyze the effects of the prover's impedance mismatch on link efficacy and security. This is a significant factor which depicts the allowable tolerances in the prover's impedance from design to manufacturing phases. Lastly, we present a comparison between prior approaches and our proposed scheme while introducing Qualitative Measure Matrix (QMM-I) and Quantitative Measure Matrix (QMM-II), which are devised from cross-layer design parameters for a secure Distance Bounding realization.}
}


@article{DBLP:journals/compsec/SunZCZ24,
	author = {Hui Sun and
                  Tianqing Zhu and
                  Wenhan Chang and
                  Wanlei Zhou},
	title = {A two-stage model extraction attack on GANs with a small collected
                  dataset},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103634},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103634},
	doi = {10.1016/J.COSE.2023.103634},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/SunZCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to their capacity for image generation, GAN models may be considered as a solution for the use of private data, which enhances their commercial value. However, unlike discriminative models such as CNNs, extraction attacks on GANs have not received significant attention, with only a few relevant works available. This paper proposes a novel two-stage extraction attack on GANs that does not require access to the victim GAN model. In the first stage, data augmentation is performed using GAN inversion techniques and vector arithmetic, tailored to scenarios with small query budgets. The second stage comprises two types of training: the innocent transfer training on unprocessed collected samples and the additional training on the augmented set. We provide three options for additional training: training of the discriminator alone (D), training of the generator alone (G), and training of both (D+G). We then conduct a quantity and quality evaluation of our extraction attacks compared to the baseline attack. Experiment results demonstrate that our proposed approach can successfully extract a GAN model, where the distribution of the extracted GAN closely resembles the distribution of the target GAN, even with a hundred generated images of the target GAN. Specifically, we achieve stable performance with better extraction, a more disentangled latent space for the extracted GAN, and significant semantic attribute editing performance using the two-stage extraction with additional training of the discriminator (D). By demonstrating that even a hundred leaked images may result in severe extraction, this study raises serious concerns regarding GAN model leakage.}
}


@article{DBLP:journals/compsec/ZhouC24,
	author = {Man Zhou and
                  Xin Che},
	title = {Stealthy attack detection based on controlled invariant subspace for
                  autonomous vehicles},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103635},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103635},
	doi = {10.1016/J.COSE.2023.103635},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhouC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous driving offers a convenient and comfortable means of transportation, while the addition of external communication interfaces renders the vehicle communication more vulnerable to cyber attacks. In contrast to conventional attacks, well-designed stealthy attacks are more adept at evading conventional detectors. To address this problem, this paper proposes a robust detector based on controlled invariant subspace to identify stealthy attacks. This paper stands out not only by relying on the vehicle dynamics model for system state estimation, but rather by employing a real-time trajectory space generation method. Our detector develops a rapidly expanding random tree method based on offline incremental learning to generate trajectory subspace, and any trajectories that diverge from this subspace are identified as anomalies. Additionally, this paper designs distance measurement method that combines the linear quadratic regulation algorithm with a radial basis function neural network while also taking into account the vehicle's dynamic performance constraints. To assess the theoretical performance of the proposed detector, this paper presents rigorous proofs that demonstrate the asymptotical optimality of the generated trajectory and the robustness of the stealthy attack detection method based on controlled invariant subspace. Finally, simulation results demonstrate that the proposed robust detector can effectively identify stealthy attacks and outperforms advanced techniques in terms of accuracy and false-positive rate.}
}


@article{DBLP:journals/compsec/WangWWS24,
	author = {Xintong Wang and
                  Zixuan Wang and
                  Enliang Wang and
                  Zhixin Sun},
	title = {Spatial-temporal knowledge distillation for lightweight network traffic
                  anomaly detection},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103636},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103636},
	doi = {10.1016/J.COSE.2023.103636},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WangWWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based network traffic anomaly detection methods have been the mainstream approaches to enhancing the accuracy performance of Network Intrusion Detection Systems (NIDSs). However, there are several problems that remain to be addressed in practical scenarios. First, the memory and computing power of intelligent terminals restrict the deployment of computationally intensive deep learning methods. Second, the depth and width of representations are of central significance for the accuracy of detection, at the cost of memory consumption and computational complexity. Third, the long tail effect spawned by the category imbalance of network traffic is prevalent in real-world fine-grained anomaly detection tasks. Therefore, we propose a Spatial-Temporal Knowledge Distillation (STKD) algorithm framework for lightweight network traffic anomaly detection to tackle the challenges. Integrating multi-scale One-Dimensional Convolutional Neural Network (1D CNN) and Long Short-Term Memory Network (LSTM), and adopting identity mapping, we propose a Multi-Scale Spatial-Temporal Residual Network (MSSTRNet) as the teacher model for deep spatial-temporal feature extraction of network traffic. Based on Knowledge Distillation (KD), we compress MSSTRNet to the lightweight student model named LENet which is suitable for deployment. Introducing Focal Loss (FL) instead of Cross Entropy (CE) Loss into the KD process, we attempt to alleviate the long tail effect in the fine-grained anomaly detection tasks. Experiments demonstrate the superiority of our proposed methods on accuracy performance, memory consumption and computation complexity.}
}


@article{DBLP:journals/compsec/MitchellMR24,
	author = {Jeff Mitchell and
                  Niall McLaughlin and
                  Jes{\'{u}}s Mart{\'{\i}}nez del Rinc{\'{o}}n},
	title = {Generating sparse explanations for malicious Android opcode sequences
                  using hierarchical {LIME}},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103637},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103637},
	doi = {10.1016/J.COSE.2023.103637},
	timestamp = {Mon, 08 Jul 2024 08:01:52 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MitchellMR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In malware analysis, understanding the reasons behind a decision is important for building trust on the system. In the case of opcode-sequence-based classifiers, when standard explanation methods, such as LIME, are applied, the resulting explanation may not provide much insight into the salient parts of the input sequence. This is because LIME treats each opcode as an independent feature, and perturbing this feature will not cause a significant change in the output, meaning the resulting explanation tends to look like random noise. In this paper, we introduce a novel method Hierarchical-LIME (H-LIME) to address this issue. We take into consideration the hierarchical structure of the program, composed of classes and methods. We show that when H-LIME is applied at the level of classes and methods the resulting explanation is sparser, vastly helping improve its interpretability. We conduct extensive experiments by evaluating our proposed method against criteria for accuracy, completeness, sparsity, stability and efficiency. We show that our method significantly improves on all the evaluation criteria compared to other explainability methods.}
}


@article{DBLP:journals/compsec/CasolaBMO24,
	author = {Valentina Casola and
                  Alessandra De Benedictis and
                  Carlo Mazzocca and
                  Vittorio Orbinato},
	title = {Secure software development and testing: {A} model-based methodology},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103639},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103639},
	doi = {10.1016/J.COSE.2023.103639},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CasolaBMO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern industries widely rely upon software and IT services, in a context where cybercrime is rapidly spreading in more and more sectors. Unfortunately, despite greater general awareness of security risks and the availability of security tools that can help to cope with those risks, many organizations (especially medium/small-size ones) still lag when it comes to building security into their services. This is mainly due to the limited security skills of common developers/IT project managers and to the typically high costs of security procedures. In fact, while automated tools exist to perform code analysis, vulnerability scanning, or security testing, the manual intervention of security experts is still required not only for security analysis and design, but also to configure and elaborate the output of the security testing tools.}
}


@article{DBLP:journals/compsec/JiaLL24,
	author = {Chengkun Jia and
                  Min Long and
                  Yongchao Liu},
	title = {Enhanced face morphing attack detection using error-level analysis
                  and efficient selective kernel network},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103640},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103640},
	doi = {10.1016/J.COSE.2023.103640},
	timestamp = {Mon, 15 Jul 2024 13:39:06 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/JiaLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face morphing attack detection is a research hotspot in the field of biometrics. However, existing methods cannot balance accuracy and complexity well due to their inability to effectively capture crucial feature distinctions. To solve this problem, this paper proposes a detection method based on error-level analysis and an efficient selective kernel network. Specifically, the proposed method performs error-level analysis on the R, G, and B color channels to accurately capture crucial feature differences and enhance face detection accuracy. Meanwhile, an efficient selective kernel network is designed with further improvements and optimizations. This network can adaptively adjust the size of the receptive field, thereby providing higher classification accuracy without significantly increasing the number of parameters. Besides, the shallow feature enhancement module and feature fusion module are designed to improve the model's detection performance. Finally, the proposed method is evaluated on standard databases and compared to existing detection methods. The results demonstrate that the proposed method achieves superior detection performance to existing methods.}
}


@article{DBLP:journals/compsec/ZhangY24,
	author = {Longwen Zhang and
                  Qiao Yan},
	title = {Detect malicious websites by building a neural network to capture
                  global and local features of websites},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103641},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103641},
	doi = {10.1016/J.COSE.2023.103641},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of the digital age, the Internet has become an integral part of our daily lives. However, it has also brought about a series of security challenges, among which malicious websites are particularly prominent. These websites often lure ignorant users by disguising themselves as legitimate services or through various fraudulent means to commit identity theft, distribute malware, or launch other forms of cyberattacks. Therefore the detection of malicious websites is very necessary. Traditionally, many malicious website detection methods rely on machine learning techniques, some of which require manual extraction of features, which may result in a time-consuming prediction process. Despite the existence of machine learning models that can automatically extract features, including unsupervised ones, capturing the subtleties of malicious website features is still a challenge. In recent years, deep learning has been gaining attention as a method for automated feature learning. It is capable of capturing and understanding the content of a website in greater depth, thus making classification and detection more accurate and efficient. Although deep learning shows its potential in capturing advanced features, its performance depends on the input data and the chosen model architecture. Both efficiently constructing feature representations of input data and building efficient model architectures to capture features are currently major challenges. For this reason, we propose a new approach for malicious website detection. This method uses wordpiece-level features to represent the information of malicious websites. Combination of multi-filter text convolutional neural network and multi-head self-attention mechanism is used for model construction. This enables the model to capture both global and local features of the input data. Compared to common deep learning methods, our approach captures the features of malicious websites better.}
}


@article{DBLP:journals/compsec/Zhao24,
	author = {Rui Zhao},
	title = {Toward the flow-centric detection of browser fingerprinting},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103642},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103642},
	doi = {10.1016/J.COSE.2023.103642},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/Zhao24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Browser fingerprinting has become a prevalent technique employed by websites for advertising and analytics. It utilizes JavaScript objects and APIs to gather traditional and non-traditional browser attributes and creates unique identifiers for online user tracking. While previous research has examined the invocation of the browser's built-in JavaScript objects and APIs to retrieve browser attribute values, it overlooks the use and flow of those values within scripts.}
}


@article{DBLP:journals/compsec/AvolaCMFFMM24,
	author = {Danilo Avola and
                  Luigi Cinque and
                  Maria De Marsico and
                  Alessio Fagioli and
                  Gian Luca Foresti and
                  Maurizio Mancini and
                  Alessio Mecca},
	title = {Signal enhancement and efficient DTW-based comparison for wearable
                  gait recognition},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103643},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103643},
	doi = {10.1016/J.COSE.2023.103643},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AvolaCMFFMM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The popularity of biometrics-based user identification has significantly increased over the last few years. User identification based on the face, fingerprints, and iris, usually achieves very high accuracy only in controlled setups and can be vulnerable to presentation attacks, spoofing, and forgeries. To overcome these issues, this work proposes a novel strategy based on a relatively less explored biometric trait, i.e., gait, collected by a smartphone accelerometer, which can be more robust to the attacks mentioned above. According to the wearable sensor-based gait recognition state-of-the-art, two main classes of approaches exist: 1) those based on machine and deep learning; 2) those exploiting hand-crafted features. While the former approaches can reach a higher accuracy, they suffer from problems like, e.g., performing poorly outside the training data, i.e., lack of generalizability. This paper proposes an algorithm based on hand-crafted features for gait recognition that can outperform the existing machine and deep learning approaches. It leverages a modified Majority Voting scheme applied to Fast Window Dynamic Time Warping, a modified version of the Dynamic Time Warping (DTW) algorithm with relaxed constraints and majority voting, to recognize gait patterns. We tested our approach named MV-FWDTW on the ZJU-gaitacc, one of the most extensive datasets for the number of subjects, but especially for the number of walks per subject and walk lengths. Results set a new state-of-the-art gait recognition rate of 98.82% in a cross-session experimental setup. We also confirm the quality of the proposed method using a subset of the OU-ISIR dataset, another large state-of-the-art benchmark with more subjects but much shorter walk signals.}
}


@article{DBLP:journals/compsec/YuanHHYKZ24,
	author = {Xinwei Yuan and
                  Shu Han and
                  Wei Huang and
                  Hongliang Ye and
                  Xianglong Kong and
                  Fan Zhang},
	title = {A simple framework to enhance the adversarial robustness of deep learning-based
                  intrusion detection system},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103644},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103644},
	doi = {10.1016/J.COSE.2023.103644},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YuanHHYKZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning based intrusion detection systems (DL-based IDS) have emerged as one of the best choices for providing security solutions against various network intrusion attacks. However, due to the emergence and development of adversarial deep learning technologies, it becomes challenging for the adoption of DL models into IDS. In this paper, we propose a novel IDS architecture that can enhance the robustness of IDS against adversarial attacks by combining conventional machine learning (ML) models and Deep Learning models. The proposed DLL-IDS consists of three components: DL-based IDS, adversarial example (AE) detector, and ML-based IDS. We first develop a novel AE detector based on the local intrinsic dimensionality (LID). Then, we exploit the low attack transferability between DL models and ML models to find a robust ML model that can assist us in determining the maliciousness of AEs. If the input traffic is detected as an AE, the ML-based IDS will predict the maliciousness of input traffic, otherwise the DL-based IDS will work for the prediction. The fusion mechanism can leverage the high prediction accuracy of DL models and low attack transferability between DL models and ML models to improve the robustness of the whole system. In our experiments, we observe a significant improvement in the prediction performance of the IDS when subjected to adversarial attack, achieving high accuracy with low resource consumption.}
}


@article{DBLP:journals/compsec/Dubin24,
	author = {Ran Dubin},
	title = {Content Disarm and Reconstruction of Microsoft Office {OLE} files},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103647},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103647},
	doi = {10.1016/J.COSE.2023.103647},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/Dubin24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Content Disarm and Reconstruction (CDR) is an advanced, zero-trust strategy for neutralizing potential threats in documents and media files. This paper introduces OLECDR, the first Microsoft Object Linking and Embedding (OLE) file format CDR system. This work measures OLECDR prevention rates and verifies that they are similar to the original file. Furthermore, we introduce a novel method for dealing with emerging threats by automatically converting detection rules into disarm and reconstruction rules. Those detection rules are needed in cases where the vulnerability is found in the file reader rather than in the file itself. Microsoft OLE file format is a highly popular format structure of Word, PowerPoint, and Excel file types. In our study, OLECDR successfully disarmed and reconstructed most of the threats while leaving the benign and malicious dataset fully functional and similar to the original source files.}
}


@article{DBLP:journals/compsec/HuangZZHC24,
	author = {Haoxiang Huang and
                  Jianbiao Zhang and
                  Lei Zhang and
                  Jun Hu and
                  Yihao Cao},
	title = {{SABDTM:} Security-first architecture-based dynamic trusted measurement
                  scheme for operating system of the virtual computing node},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103648},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103648},
	doi = {10.1016/J.COSE.2023.103648},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HuangZZHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the cloud environment, the virtual computing node has become the dominant form of cloud services used by users. Hence, it is increasingly critical to guarantee the trusted operation of the virtual computing node's operating system (VCNOS). However, previous schemes suffer a lot, such as insufficient consideration of the comprehensive of the measured objects, ignoring the dynamic of trusted, and the trusted measurement mechanisms rarely consider their security. Thus, a three-dimensional dynamic trusted measurement model SABDTM, which integrates the integrity measurement of kernel static data, trusted evaluation of operating system behavior (OSB), and the feedback trust of interacting nodes, is proposed. First, SABDTM divided OSB into multiple atomic behaviors and introduced the Bayesian decision theory to predict trusted expectations of OSBs. Second, the feedback trust of interacting nodes is considered to improve the comprehensiveness of the trusted measurement and evaluate its value based on the Euclidean distance function to reduce the impact of inaccurate feedback from malicious nodes. Subsequently, we set the appropriate weight for trusted measurement values of different moments based on Induced Ordered Weighted Averaging to accurately portray the actual state of VCNOS. Moreover, we designed a lightweight and independent subsystem to perform the trusted measurement, which guarantees the security of the measurement service. The security of our model is proved rigorously based on the non-interference theory. Finally, the experiments and comparative analysis demonstrated our model has better functionality and superiority.}
}


@article{DBLP:journals/compsec/HoffmanHPMA24,
	author = {Cameron John Hoffman and
                  C. Jordan Howell and
                  Robert C. Perkins and
                  David Maimon and
                  Olena Antonaccio},
	title = {Predicting new hackers' criminal careers: {A} group-based trajectory
                  approach},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103649},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103649},
	doi = {10.1016/J.COSE.2023.103649},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/HoffmanHPMA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The current study employs group-based trajectory modeling to assess the longitudinal attack patterns of new hackers involved in website defacement. Specifically, we track the activity of 241 emergent hackers for one year following their first verified website defacement. In doing so, we find four distinct criminal trajectories: low threat (29.0%), naturally desisting (26.5%), increasingly prolific (22.3%), and persistent threat (22.1%). Hackers classified as low threats engage in few defacements, whereas persistent threats engage in high-frequency attacks. Those labeled as naturally desisting begin their careers with velocity but become less prolific with time. Conversely, those classified as increasingly prolific engage in more attacks as they advance in their criminal careers. Using a series of regression models, we find that digital artifacts and open-source intelligence are predictive of group involvement. The findings presented in this study contribute to our theoretical understanding of the developmental trajectories of hackers, while providing valuable insights in fostering targeted intervention strategies aimed at effectively mitigating and preventing cyber-attacks.}
}


@article{DBLP:journals/compsec/CaoYLZG24,
	author = {Yu Cao and
                  Ang Yang and
                  Hanning Li and
                  Qingcheng Zeng and
                  Jing Gao},
	title = {A comprehensive knowledge map for {AI} improving security management
                  of cyber-physical system enabled smart manufacturing},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103650},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103650},
	doi = {10.1016/J.COSE.2023.103650},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CaoYLZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The enhancement of security management for smart manufacturing has garnered considerable attention, prompting extensive research efforts that explore AI-based secure Cyber-Physical System (CPS) methods. While previous studies have made valuable contributions to this field, the current state of literature reviews still requires a comprehensive examination to construct the knowledge map for future research. This study employed scientometric analyses, including collaboration network analysis, co-occurrence network analysis, and co-citation network analysis, to examine 1133 previous articles conducted between 2015 and 2023 concerning the research topic of AI application in secure CPS-enabled smart manufacturing. The findings reveal that the academic communities in this field comprise influential authors affiliated with leading academic institutions in China, India, and the USA. The key research topics of AI application in secure CPS-enabled smart manufacturing show evolutionary trends during different research periods. Existing research on AI application in secure CPS-enabled smart manufacturing is supported by classical references, which can be divided into four significant co-citation clusters, including the theory of security and privacy in CPS, DL-based IDS, DDoS attacks on CPS by botnet, and FL method for privacy-preserved data sharing. Finally, this study predicted four potential future research directions for the research field of AI application in secure CPS-enabled smart manufacturing: the well-structured and representative dataset for model training, methods for resisting PUF attacks against ML techniques, DL-based methods for detecting and resisting botnets, and lightweight FL-based methods for privacy-preserved data sharing. The findings of this study can guide researchers in this field for future collaboration and work.}
}


@article{DBLP:journals/compsec/YangWZCH24,
	author = {Hongyu Yang and
                  Youwei Wang and
                  Liang Zhang and
                  Xiang Cheng and
                  Ze Hu},
	title = {A novel Android malware detection method with {API} semantics extraction},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103651},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103651},
	doi = {10.1016/J.COSE.2023.103651},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/YangWZCH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the continuous evolution of both the Android framework and malware, conventional malware detection methods that have been trained using outdated apps are inadequate in effectively identifying sophisticated evolved malware. To address this issue, in this paper, we propose a novel Android malware detection method with API semantics extraction (AMDASE), it can effectively identify evolved malware instances. Firstly, AMDASE performs API clustering to obtain cluster centers representing API functions before malware detection. We design API sentence to summarize API features and employ natural language processing (NLP) tools to acquire embeddings of API sentence for clustering. With the help of API sentence, it becomes possible to effectively extract the semantics of API contained in features like method name that accurately represents its intended functionality, which also makes the clustering results more accurate. Secondly, AMDASE extracts call graph from each app and optimizes the call graph by removing nodes corresponding to unknown functions, while ensuring the preservation of connectivity between their predecessor and successor nodes. The optimized call graph can extract more robust API contextual information that accurately represents the behavior of each app. Thirdly, in order to maintain resilience against the evolution of Android malware, AMDASE extracts function call pairs from the optimized call graph and abstracts the APIs in function call pairs into cluster centers obtained in API clustering. Finally, feature vectors are generated using one-hot mapping and machine learning classifiers are used for malware detection. We evaluate AMDASE on a dataset of 42,154 benign and 42,450 malicious apps developed over a seven-year period. The experimental results demonstrate that AMDASE greatly outperforms the existing state-of-the-art methods and has a significantly slower aging speed.}
}


@article{DBLP:journals/compsec/LiuPZF24,
	author = {Side Liu and
                  Guojun Peng and
                  Haitao Zeng and
                  Jianming Fu},
	title = {A survey on the evolution of fileless attacks and detection techniques},
	journal = {Comput. Secur.},
	volume = {137},
	pages = {103653},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103653},
	doi = {10.1016/J.COSE.2023.103653},
	timestamp = {Sat, 10 Feb 2024 18:05:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiuPZF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fileless attacks have gained significant prominence and have become the prevailing type of attack in recent years. The exceptional level of stealthiness and difficulty in detection inherent in fileless attacks has made them highly favored by attackers. In this paper, we have conducted a comprehensive review of the historical development of fileless attack techniques, systematically analyzed various technical aspects and characteristics of fileless attacks, and proposed a comprehensive fileless threat model. Additionally, we have introduced a novel perspective for classifying fileless attack techniques based on their leverage in the system hierarchy. Furthermore, we conduct a systematic review of research on various fileless attack detection techniques, summarize the challenges in fileless attack detection, and discuss future directions for research in fileless attack detection.}
}
