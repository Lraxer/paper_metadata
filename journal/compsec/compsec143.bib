@article{DBLP:journals/compsec/HuLXZW24,
	author = {Yanfei Hu and
                  Shuai Li and
                  Wenchao Xue and
                  Yanlong Zhao and
                  Yu Wen},
	title = {CarePlus: {A} general framework for hardware performance counter based
                  malware detection under system resource competition},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103884},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103884},
	doi = {10.1016/J.COSE.2024.103884},
	timestamp = {Mon, 05 Aug 2024 21:42:42 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HuLXZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hardware performance counter (HPC) has been used for malware detection because of its lightweight overhead. Unfortunately, such detection models including their software implementation and hardware implementation suffer from performance decline in environments where resource competition among programs exists in the operating system. In this paper, we propose a framework called CarePlus, which enables two kinds of implementations of hardware performance counter-based malware detection (HMD) resilient to resource competition. The core idea is to detect malware by using invariants extracted from HPC-level behaviors in resource competition environments. To achieve this, a benchmark-based resource pressure generator is designed to generate controlled resource competition environments for observing typical HPC-level behavior of a program. Then, a behavior representation network is trained to map HPC-level behaviors in any competition environment into low-dimensional representations, which allows software-implemented HMD models built on them to detect malware regardless of resource competition. Finally, an adapter is introduced to project behavior representation in the competition environment into data that conforms to the training distribution of the hardware-implemented HMD model. Using three datasets collected in different application systems (e.g., server or desktop) with different resource competition types or levels, the experimental results show that compared with existing detection models, CarePlus is helpful to improve the performance of software-implemented HMD classifier and hardware-implemented HMD classifier in the competition environment. We also prove that the classifier using CarePlus is insensitive to different application systems. Finally, we demonstrate the computational overhead.}
}


@article{DBLP:journals/compsec/LinHGYGLGX24,
	author = {Xinjie Lin and
                  Longtao He and
                  Gaopeng Gou and
                  Jing Yu and
                  Zhong Guan and
                  Xiang Li and
                  Juncheng Guo and
                  Gang Xiong},
	title = {{CETP:} {A} novel semi-supervised framework based on contrastive pre-training
                  for imbalanced encrypted traffic classification},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103892},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103892},
	doi = {10.1016/J.COSE.2024.103892},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LinHGYGLGX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encrypted traffic classification (ETC) requires differentiated and robust traffic representation captured from content-agnostic and imbalanced traffic data for accurate classification, which is challenging but indispensable for enabling network security and network management. Some existing deep-learning based ETC approaches have achieved promising results, but have limitations in real-world network environments: (1) label bias caused by traffic class imbalance and (2) traffic homogeneity due to component sharing. How to leverage open-domain unlabeled imbalanced traffic data to learn representation with strong generalization ability remains a key challenge. In this paper, we propose a novel imbalanced traffic representation model, called Contrastive Encrypted Traffic Pre-training (CETP), which pre-trains deep multi-granularity traffic representation from imbalanced data without directly using application labels. The pre-trained model can be further mitigated against label bias due to imbalance by semi-supervised continual fine-tuning via pseudo-label iterations and dynamic loss-weighting algorithms. CETP achieves state-of-the-art performance across four imbalanced encrypted traffic classification tasks, remarkably improving the F1 to 96.31% (2.74%\n↑\n) for CP-Android, 93.86% (3.58%\n↑\n) for CIC-2019, and 84.16% (10.19%\n↑\n) for ISCX-VPN. Meanwhile, we further validate the effectiveness of CETP in QUIC-based imbalanced encrypted traffic. Notably, we verify through analytical experiments that CETP not only effectively relieves label bias and homogeneous flow misclassification, but also extends to ETC methods with diverse feature extractors.}
}


@article{DBLP:journals/compsec/BinguADKPS24,
	author = {Rajesh Bingu and
                  Salina Adinarayana and
                  Jagjit Singh Dhatterwal and
                  Sadam Kavitha and
                  Eswar Patnala and
                  Hrushikesava Raju Sangaraju},
	title = {Performance comparison analysis of classification methodologies for
                  effective detection of intrusions},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103893},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103893},
	doi = {10.1016/J.COSE.2024.103893},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BinguADKPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intrusion detection systems (IDS) are critical in many applications, including cloud environments. The intrusion poses a security threat and extracts privacy data and information from the cloud. Additionally, intrusions can cause damage to system hardware, resulting in significant financial losses and exposing critical IT infrastructure to risk. To overcome these issues, this study employs the performance comparison analysis for IDS, which has been performed with different models like Autoencoder Convolutional neural network (AE+CNN), Random forest K-means clustering assisted deep neural network (RF+K-means+DNN), Autoencoder K-means clustering assisted long short term memory (AE+K-means+LSTM), Alexnet+Bi-GRU, AE+Alexnet+Bi-GRU and Wild horse AlexNet assisted Bi-directional Gated Recurrent Unit (WABi-GRU) models to choose the best methodology for effective detection of intrusions. The data needed for the analysis is collected from CICIDS2018, UNSW-NB15, NSL-KDD and ToN-IoT datasets. The collected data are pre-processed using data normalization and data cleaning. Finally, the best model has been chosen for effective intrusion detection, which is used for further processes. Various performances, such as accuracy, precision, recall, and f1-score, are analyzed for various existing and proposed models. From this performance comparison of six models such as AE+CNN, RF+K-means+DNN, AE+K-means+LSTM, Alexnet+Bi-GRU, AE+Alexnet+Bi-GRU and WABi-GRU. WABi-GRU can attain an accuracy of 99.890 % for multi-class classification in the CICIDS 2018 dataset, 99.7 % in the NSL-KDD dataset, 99.53 % in the UNSW-NB 15 dataset and 99.988 % for the ToN-IoT dataset. In this analysis, the models containing AlexNet Bi-GRU-based models can obtain better performances than other existing models. The WABi-GRU model can obtain better results than other models.}
}


@article{DBLP:journals/compsec/JanovskyJSCMM24,
	author = {Adam Janovsky and
                  Jan Jancar and
                  Petr Svenda and
                  Lukasz Chmielewski and
                  Jiri Michalik and
                  Vashek Matyas},
	title = {sec-certs: Examining the security certification practice for better
                  vulnerability mitigation},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103895},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103895},
	doi = {10.1016/J.COSE.2024.103895},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/JanovskyJSCMM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Products certified under security certification frameworks such as Common Criteria undergo significant scrutiny during the costly certification process. Yet, critical vulnerabilities, including private key recovery (ROCA, Minerva, TPM-Fail...), get discovered in certified products with high assurance levels. Furthermore, assessing which certified products are impacted by such vulnerabilities is complicated due to the large amount of unstructured certification-related data and unclear relationships between the certified products. To address these problems, we conducted a large-scale automated analysis of Common Criteria certificates. We trained unsupervised models to learn which vulnerabilities from NIST’s National Vulnerability Database impact existing certified products and how certified products reference each other. Our tooling automates the analysis of tens of thousands of certification-related documents, extracting machine-readable features where manual analysis is unattainable. Further, we identify the security requirements that are associated with products being affected by fewer and less severe vulnerabilities. This indicates which aspects of certification correlate with higher security. We demonstrate how our tool can be used for better vulnerability mitigation on four case studies of known, high-profile vulnerabilities. All tools and continuously updated results are available at https://sec-certs.org.}
}


@article{DBLP:journals/compsec/ThompsonMN24,
	author = {Nik Thompson and
                  Tanya McGill and
                  Nidhi Narula},
	title = {"No point worrying" - The role of threat devaluation in
                  information security behavior},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103897},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103897},
	doi = {10.1016/J.COSE.2024.103897},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ThompsonMN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extant information security research is characterized by a focus on problem-focused security behaviours, while overlooking the internal, and emotion-focused coping responses that humans exhibit. Threat devaluation, where severity is downplayed, is an established dimension of risk perception, and yet it has not been considered in information security research to date. We address this gap by developing and empirically testing a research model of how threat and coping factors from Protection Motivation Theory influence both problem-focused and emotion-focused coping responses. Data was collected from 518 users and PLS was used to reveal the determinants of, and the relationship between, problem-focused and emotion-focused coping behaviors. The results demonstrate that threat devaluation is a measurable outcome of all threat and coping appraisals considered, providing evidence that multiple coping strategies may be involved in a security threat situation. We also find that many of the well-established determinants of information security behavior, such as self-efficacy, are significantly related to emotion-focused responses. This has implications for researchers and practitioners who seek to create secure environments where users are more likely to enact constructive and problem-focused security behaviors.}
}


@article{DBLP:journals/compsec/LiZNZ24,
	author = {Chaofei Li and
                  Ziyuan Zhu and
                  Ruicheng Niu and
                  Yuting Zhao},
	title = {Enhancing adversarial robustness for deep metric learning via neural
                  discrete adversarial training},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103899},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103899},
	doi = {10.1016/J.COSE.2024.103899},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiZNZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the security concerns arising from adversarial vulnerability in deep metric learning models, it is essential to enhance their adversarial robustness for secure neural network software development. Existing defense strategies utilize adversarial triplets to enhance adversarial robustness but sacrifice benign performance. This paper proposes a novel framework for enhancing adversarial robustness and maintaining benign performance by introducing the concept of Neural Discrete Adversarial Training (NDAT) for deep metric learning. NDAT employs VQGAN to transform the adversarial triplets into discrete inputs and then minimizes metric loss function on discrete adversarial triplets. NDAT aligns discrete adversarial examples more closely with clean samples, significantly reducing distribution deviation from their clean counterparts. Moreover, the visual explanations reveal that NDAT maintains consistent attention maps between benign and adversarial triplets and concentrates on structure details and object location perturbations. To demonstrate the effectiveness of our approach, we combine NDAT with popular adversarial methods under various perturbation iterations and intensities. Experiment evaluations on three benchmark databases illustrate that our proposed framework for deep metric learning significantly outperforms state-of-the-art defense approaches in terms of both adversarial robustness and benign performance.}
}


@article{DBLP:journals/compsec/AyaburiALS24,
	author = {Emmanuel W. Ayaburi and
                  Francis Kofi Andoh{-}Baidoo and
                  Jaeung Lee and
                  Mikko T. Siponen},
	title = {Investigating the use of protective technologies after data breach:
                  The roles of psychological distance, technological service type and
                  organizational justice},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103900},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103900},
	doi = {10.1016/J.COSE.2024.103900},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AyaburiALS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Protective information technologies (PITs) are crucial for preventing security and privacy issues, but their application by customers following a data breach has not been thoroughly studied in the past. In this work, we define post-data breach protective technologies (PDPT), an initiative-taking protective technology, as the use of PIT in the aftermath of a data breach. Based on the kinds of services violated, we hypothesize that users' psychological understanding of protective technology and the organization's justice procedures affect victims' intent to use PDPT. We validate two theoretical hypotheses for PDPT adoption by utilizing survey responses from consumers across utility-benefit and social-benefit services after data breaches. For practice, our research provides guidance for planning and encouraging the implementation of protective technology in the wake of a privacy crisis or data breach. In general, we draw the conclusion that a data breach tends to heighten the victims’ awareness of the breach, impact justice perceptions, and alter the distant psychological knowledge about the service benefits of protective technologies post data breach.}
}


@article{DBLP:journals/compsec/GuggilamCNMZG24,
	author = {Naga Venkata Rishika Guggilam and
                  Rupa Chiramdasu and
                  Akhil Babu Nambur and
                  Naveena Mikkineni and
                  Yaodong Zhu and
                  Thippa Reddy Gadekallu},
	title = {An expert system for privacy-driven vessel detection harnessing YOLOv8
                  and strengthened by {SHA-256}},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103902},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103902},
	doi = {10.1016/J.COSE.2024.103902},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GuggilamCNMZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The integration of deep learning with security is undergoing rapid and substantial growth across numerous fields. This combination has led to propelled advancements in securing maritime surveillance data. Applications utilizing deep learning require large amounts of data to deliver precise results. However, Deep learning applications face significant issues like low accuracy, high computational complexity, and GPU utilization. Moreover, security features such as integrity and authenticity are notably absent. Hence, in this paper privacy preserved deep learning-based vessel monitoring system is developed which includes evaluation of integrity and authenticity-based surveillance. This model ensures accuracy without compromising on one way authenticity while also optimizing GPU utilization. Therefore, the YOLOv8 model is integrated with SHA-256 for tracking and classification, also ensuring data integrity and authentication of vessel data. The model is fed with class-balanced, unstructured dataset comprising 693 photo-realistic video sequences. It has three phases which are used for feature extraction and bounding box prediction and also includes CSPDarkNet53 as backbone, Spatial Pyramid Pooling (SPP) as neck layer and detection is done using head layer. They employ a 3 × 3 convolution for better feature extraction. The proposed model provides better performance than other state-of-the-art methods. Specifically, YOLOv8 achieves a 9.3 % increase in precision over YOLOv7.}
}


@article{DBLP:journals/compsec/ChafjiriLHT24,
	author = {Sadegh Bamohabbat Chafjiri and
                  Phil Legg and
                  Jun Hong and
                  Michail{-}Antisthenis I. Tsompanas},
	title = {Vulnerability detection through machine learning-based fuzzing: {A}
                  systematic review},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103903},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103903},
	doi = {10.1016/J.COSE.2024.103903},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChafjiriLHT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern software and networks underpin our digital society, yet the rapid growth of vulnerabilities that are uncovered within these threaten our cyber security posture. Addressing these issues at scale requires automated proactive approaches that can identify and mitigate these vulnerabilities in a suitable time frame. Fuzzing techniques have emerged as crucial methods to preemptively tackle these risks. However, traditional fuzzing methods encounter various challenges, such as a lack of strategy for deep bug identification, time-intensive bug analysis, quality of inputs, seed scheduling and others. To overcome these challenges, diverse Machine Learning (ML) models and optimisation techniques have been employed, including advanced feature engineering, optimised seed selection, refined predictive/fitness models, and Gradient-based optimisation. Furthermore, the use of ML architectures such as Long Short-Term Memory (LSTM), Generative Adversarial Network (GAN), Sequence-to-Sequence (Seq2Seq), and Generative Randomised Unit (GRU), have demonstrated greater effectiveness within ML-based fuzzing. In this paper, we delve into this paradigm shift, aiming to address fundamental challenges across different ML categories. We survey popular ML categories such as Traditional Machine Learning (TML), Deep Learning (DL), Reinforcement Learning (RL), and Deep Reinforcement Learning (DRL), to investigate their potential for enhancing traditional fuzzing approaches. We explore the respective advantages in each category of ML-based fuzzing, while also analysing the challenges unique to each category. Our work provides a comprehensive survey across the fuzzing domain and how machine learning techniques have been utilised, that we believe will be of use to future researchers in this domain.}
}


@article{DBLP:journals/compsec/KimL24,
	author = {Hee Yeon Kim and
                  Dong Hoon Lee},
	title = {CatchFuzz: Reliable active anti-fuzzing techniques against coverage-guided
                  fuzzer},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103904},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103904},
	doi = {10.1016/J.COSE.2024.103904},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KimL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fuzzing techniques that can automatically detect software vulnerabilities are used widely today. However, attackers also abuse these fuzzing techniques to find software vulnerabilities in target programs. Researchers have proposed a number of anti-fuzzing techniques in response to this issue, but most of them cause significant computational overhead regardless of whether programs operate under the fuzzing environment or not. To this point, we develop a new anti-fuzzer called CatchFuzz, in which an anti-fuzzing algorithm is loaded only after detecting the fuzzing environment. CatchFuzz then breaks down the fuzzing strategy by directly disordering information used by the fuzzing system. These features ensure that there is little performance degradation during normal usage and make a fuzzer interpret an interesting input value as uninteresting. Also, CatchFuzz surpasses existing anti-fuzzing techniques by significantly reducing the number of detected crashes, while also addressing their current limitations. We conduct multiple empirical tests with nine real-world programs to evaluate CatchFuzz and compare our method with existing anti-fuzzers. Our tests show that CatchFuzz identifies the fuzzing environment with an accuracy of 99.6% and a false positive rate of 0.5%. CatchFuzz exhibits highly improved anti-fuzzing performance, as demonstrated by the significant reduction in the number of detected unique crashes by 95.39%.}
}


@article{DBLP:journals/compsec/IbrahimSP24,
	author = {Omar Adel Ibrahim and
                  Savio Sciancalepore and
                  Roberto Di Pietro},
	title = {MAG-PUFs: Authenticating IoT devices via electromagnetic physical
                  unclonable functions and deep learning},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103905},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103905},
	doi = {10.1016/J.COSE.2024.103905},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/IbrahimSP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The challenge of authenticating Internet of Things (IoT) devices, particularly in low-cost deployments with constrained nodes that struggle with dynamic re-keying solutions, renders these devices susceptible to various attacks. This paper introduces a robust alternative mitigation strategy based on Physical-Layer Authentication (PLA), which leverages the intrinsic physical layer characteristics of IoT devices. These unique imperfections, stemming from the manufacturing process of IoT electronic integrated circuits (ICs), are difficult to replicate or falsify and vary with each function executed by the IoT device. We propose a novel lightweight authentication scheme, MAG-PUFs, that uses the unintentional Electromagnetic (EM) emissions from IoT devices as Physical Unclonable Functions (PUFs). MAG-PUFs operate by collecting these unintentional EM emissions during the execution of pre-defined reference functions by the IoT devices. The authentication is achieved by matching these emissions with profiles recorded at the time of enrollment, using state-of-the-art Deep Learning (DL) approaches such as Neural Networks (NN) and Autoencoders. Notably, MAG-PUFs offer compelling advantages: (i) it preserves privacy, as it does not require direct access to the IoT devices; and, (ii) it provides unique flexibility, permitting the selection of numerous and varied reference functions. We rigorously evaluated MAG-PUFs using 25 Arduino devices and a diverse set of 325 reference function classes. Employing a DL framework, we achieved a minimum authentication F1-Score of 0.99. Furthermore, the scheme’s efficacy in detecting impostor EM emissions was also affirmed, achieving a minimum F1-Score of 0.99. We also compared our solution to other solutions in the literature, showing its remarkable performance. Finally, we discussed code obfuscation techniques and the impact of Radio Frequency (RF) interference on the IoT authentication process.}
}


@article{DBLP:journals/compsec/ZhengZWLM24,
	author = {Luxin Zheng and
                  Jian Zhang and
                  Xiangyi Wang and
                  Faxin Lin and
                  Zheng Meng},
	title = {Multimodal-based abnormal behavior detection method in virtualization
                  environment},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103908},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103908},
	doi = {10.1016/J.COSE.2024.103908},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhengZWLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing prevalence of cloud computing, various industries worldwide are relying on it to provide a wide range of services. However, anomalies in cloud environment can pose security risks such as data leakage and privacy concern. Virtualization technology is at the core of cloud computing, and abnormal behavior exhibited by virtual machines (VMs) running in cloud environment is one of the primary causes of platform disruption. Traditional methods for detecting VM anomalies in cloud platform currently face multiple challenges, including privacy protection and semantic gap. To address these issues, this paper introduces a multimodal-based abnormal behavior detection method in virtualization environment. This method initially obtains virtual hardware features of the VM at virtualization level, then acquires real hardware features and system call features at physical machine level, and finally captures memory snapshot of the VM at runtime to obtain memory features. Next, the method combines hardware features and system call features obtained from various levels as one modality input. Then, it uses a differential algorithm to identify memory modified area and visualizes them as an image, which serves as the other modality input. Finally, this paper feeds the two inputs into a multimodal model. This approach allows for the extraction of more comprehensive VM behavior information from multiple modalities, resulting in improved detection accuracy. Our experimental results demonstrate that this method can effectively detect abnormal behavior in VMs, achieving an accuracy as high as 99.24%.}
}


@article{DBLP:journals/compsec/ShaoZLGW24,
	author = {Jun{-}Min Shao and
                  Guo{-}Qiang Zeng and
                  Kang{-}Di Lu and
                  Guang{-}Gang Geng and
                  Jian Weng},
	title = {Automated federated learning for intrusion detection of industrial
                  control systems based on evolutionary neural architecture search},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103910},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103910},
	doi = {10.1016/J.COSE.2024.103910},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ShaoZLGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, federated learning has been applied to the security of the Internet of Things and Industrial Control Systems (ICS) due to its advantages in communication cost and privacy preserving. However, the existing deep learning models used in federated learning-based intrusion detection systems (IDS) are manually designed by relying on the extensive experiences of designers and are not applicable in different scenarios flexibly. In this paper, we make the first attempt to automatically design a lightweight federated learning model termed as Fed-GA-CNN-IDS for the IDS issue in ICS by evolutionary neural architecture search (NAS). Five lightweight neural architectures of Convolutional Neural Network (CNN) are considered as the basic blocks to be combined and optimized in federated NAS for ICS intrusion detection. An efficient discrete encoding strategy is developed to describe the combination of five basic lightweight blocks and the specific discrete evolutionary operations under the framework of genetic algorithm (GA) are designed elaborately to guide the evolutionary process of an automated federated learning model. The experimental results on three widely-used intrusion detection datasets in ICSs such as Gas Pipeline, SWaT and WADI, demonstrate that the proposed Fed-GA-CNN-IDS method can obtain more lightweight models and better or at least competitive intrusion detection performance than three state-of-the-art manually-designed federated learning-based IDS methods, two federated NAS methods originally developed for traditional image classification tasks, and four lightweight IDS methods.}
}


@article{DBLP:journals/compsec/WeiR24,
	author = {Qianjin Wei and
                  Gang Rao},
	title = {{EPFL-DAC:} Enhancing Privacy in Federated Learning with Dynamic Aggregation
                  and Clipping},
	journal = {Comput. Secur.},
	volume = {143},
	pages = {103911},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103911},
	doi = {10.1016/J.COSE.2024.103911},
	timestamp = {Mon, 05 Aug 2024 21:42:42 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WeiR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning achieves data privacy protection by uploading only users’ local updates. However, recent research has shown that privacy data can still be inferred from local updates. Privacy-preserving federated learning also faces challenges related to the confidentiality and privacy of local updates, the robustness of dynamic membership schemes, and the determination of appropriate clipping threshold in differentially private federated learning. To address these issues, this paper presents the EPFL-DAC scheme: Enhancing Privacy in Federated Learning with Dynamic Aggregation and Clipping. Firstly, Paillier homomorphic encryption is employed to securely aggregate local updates, ensuring that the server can only access the aggregated information. Secondly, a dynamic robustness algorithm is designed to ensure the robustness of the aggregation scheme when user states change. Lastly, a dynamic threshold determination method is introduced to introduce more accurate noise, while also providing resistance against collusive attacks in differentially private settings. Experimental results demonstrate the effectiveness, low computational overhead, and preservation of accuracy in the dynamic aggregation scheme. Additionally, the proposed dynamic threshold determination method exhibits good performance, especially at higher privacy protection levels and larger initial clipping threshold values.}
}
