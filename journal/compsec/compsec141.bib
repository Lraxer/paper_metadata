@article{DBLP:journals/compsec/LiCHZDSW24,
	author = {Qiao Li and
                  Jing Chen and
                  Kun He and
                  Zijun Zhang and
                  Ruiying Du and
                  Jisi She and
                  Xinxin Wang},
	title = {Model-agnostic adversarial example detection via high-frequency amplification},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103791},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103791},
	doi = {10.1016/J.COSE.2024.103791},
	timestamp = {Tue, 16 Jul 2024 15:14:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiCHZDSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image classification based on Deep Neural Networks (DNNs) is vulnerable to adversarial examples, which make the classifier output incorrect predictions. One approach to defending against this attack is to detect whether the input is an adversarial example. Unfortunately, existing adversarial example detection methods heavily rely on the underlying classifier and may fail when the classifier is upgraded. In this paper, we propose a model-agnostic detection method that leverages high-frequency signals from adversarial noises in adversarial examples and does not need interactions with the underlying classifier. We amplify redundant high-frequency signals brought by adversarial noises and represent object boundaries with these signals in an image. Our key insight is that the boundaries extracted by redundant high-frequency signals have a strong correlation with the boundaries of images in adversarial examples, while this correlation does not exist in clean images. Furthermore, adversarial examples of large images have more high-frequency signals and make adversarial detection easier on large image datasets. Experimental results show that our method has good transferability and can accurately detect various adversarial examples on different datasets.}
}


@article{DBLP:journals/compsec/BoffaDMVGVB24,
	author = {Matteo Boffa and
                  Idilio Drago and
                  Marco Mellia and
                  Luca Vassio and
                  Danilo Giordano and
                  Rodolfo V. Valentim and
                  Zied Ben{-}Houidi},
	title = {LogPr{\'{e}}cis: Unleashing language models for automated malicious
                  log analysis},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103805},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103805},
	doi = {10.1016/J.COSE.2024.103805},
	timestamp = {Sun, 04 Aug 2024 19:48:14 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BoffaDMVGVB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Security logs are the key to understanding attacks and diagnosing vulnerabilities. Often coming in the form of text logs, their analysis remains a daunting challenge. Language Models (LMs) have demonstrated unmatched potential in understanding natural and programming languages. The question arises as to whether and how LMs could be also used to automatise the analysis of security logs. We here systematically study how to benefit from the state-of-the-art LM to support the analysis of text-like Unix shell attack logs automatically. For this, we thoroughly designed LogPrécis. LogPrécis receives as input malicious shell sessions. It then automatically identifies and assigns the attacker tactic to each portion of the session, i.e., unveiling the sequence of the attacker's goals. This creates a unique attack fingerprint. We demonstrate LogPrécis capability to support the analysis of two large datasets containing about 400,000 unique Unix shell attacks recorded in a 2-year-long honeypot deployment. LogPrécis reduces the analysis to about 3,000 unique fingerprints. Such abstraction lets us better understand attacks, extract attack prototypes, detect novelties, and track families and mutations. Overall, LogPrécis, released as open source, demonstrates the potential of adopting LMs for security analysis and paves the way for better and more responsive defence against cyberattacks.}
}


@article{DBLP:journals/compsec/YiCLZ24,
	author = {Tao Yi and
                  Xingshu Chen and
                  Qindong Li and
                  Yi Zhu},
	title = {An anomaly behavior characterization method of network traffic based
                  on Spatial Pyramid Pool {(SPP)}},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103809},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103809},
	doi = {10.1016/J.COSE.2024.103809},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YiCLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {APT attacks have the characteristics of low frequency, stealth, and persistence. Achieving attack objectives and preventing trace-back often involve diverse tactics, various tools, and changing processes and patterns. Additionally, the goals of APT attacks are diverse. Apart from service disruptions or network outages, the main goals include remotely penetrating target hosts through the network to steal information, unauthorized encryption, and destructive wiping. Existing methods for characterizing attack features lack sufficient research on the communication methods and data transmission patterns used in attacks. In particular, due to the non-associated addresses, low frequency, fragmentation, and silent requirements of attacks, the features exhibited in a single session are increasingly minimal. Traditional approaches are no longer sufficient to address these challenges that relying solely on single-sample statistical features and "packet-sniffing" windowed traffic grouping detection methods. To tackle these issues, we propose a innovative approach to characterize network attack traffic based on Spatial Pyramid Pooling (SPP) by analyzing the attack communication methods and data transmission patters in the network session traffic of APT attacks with the remote information theft. Specifically, it employs derived feature attributes that integrate mean, total, and concentration characteristics to longitudinally extract multi-level spatiotemporal correlated behavioral features from aggregated multi-session sets. These features are then fused with single-session characteristics, ensuring that each session sample possesses both current traffic features and correlated properties of contextual session traffic. Additionally, this approach meets the requirements of fixed-length input for heterogeneous data in deep learning. Extensive experiments have been conducted to demonstrate that this method enhances the effective detection of APT attacks by deep learning models. Experiments results show that this approach exhibits superior timeliness, precision, and specificity when compared to Principal Component Analysis (PCA) artificial feature engineering methods and other methods based on fixed-length deep learning for raw data.}
}


@article{DBLP:journals/compsec/WanyanLLC24,
	author = {Hanxiao Wanyan and
                  Yingxu Lai and
                  Jing Liu and
                  Hao Chen},
	title = {NCMFuzzer: Using non-critical field mutation and test case combination
                  to improve the efficiency of {ICS} protocol fuzzing},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103811},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103811},
	doi = {10.1016/J.COSE.2024.103811},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WanyanLLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial control systems (ICSs) have many vulnerabilities owing to the lack of protective measures. Once exploited, such vulnerabilities can result in significant economic loss and security concerns because an ICS controls the entire production process. Although fuzzing is a prevalent technique for finding potential vulnerabilities, current approaches have the disadvantages of blind mutations and low efficiency in vulnerability mining. In this study, we propose a personalized fuzzing method for ICS protocols based on non-critical field mutations and test case combinations. In our approach, we select appropriate protocol fields for personalized mutations based on the information entropy of each output, which can increase the diversity of test cases while preserving their availability. We developed a novel test case sending method that improves the efficiency of finding specific vulnerabilities by grouping related test cases. Our approach also introduces a detection method based on expected message validation to locate triggered vulnerabilities quickly. Compared to Peach and Boofuzz, our method improved the test target anomaly rate by 63.53% and 34.95%, respectively, and found one 0-day vulnerability and five n-day vulnerabilities.}
}


@article{DBLP:journals/compsec/FatokiSM24,
	author = {Jimoh Fatoki and
                  Zixing Shen and
                  Carlo A. Mora Monge},
	title = {Optimism amid risk: How non-IT employees' beliefs affect cybersecurity
                  behavior},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103812},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103812},
	doi = {10.1016/J.COSE.2024.103812},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/FatokiSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study delves into the interplay between personal dispositions and cybersecurity behaviors within organizational settings. It investigates how optimism bias influences attitudes toward cybersecurity and subsequently affects cybersecurity behavior. Additionally, it examines the moderating role of information security awareness in shaping the relationship between attitude and risky cybersecurity behavior.}
}


@article{DBLP:journals/compsec/TangYZKW24,
	author = {Gaigai Tang and
                  Lin Yang and
                  Long Zhang and
                  Hongyu Kuang and
                  Huiqiang Wang},
	title = {MRC-VulLoc: Software source code vulnerability localization based
                  on multi-choice reading comprehension},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103816},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103816},
	doi = {10.1016/J.COSE.2024.103816},
	timestamp = {Fri, 24 May 2024 10:34:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/TangYZKW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, automatic vulnerability detection approaches based on machine learning (ML) have outperformed traditional rule-based approaches in terms of detection performance. Existing ML-based approaches typically concentrate on function or line granularity, which fail to realize accurate vulnerability localization and are insufficient to support effective root cause analysis of vulnerability. To address this issue, we propose a new approach that maps the multi-choice reading comprehension (MRC) task to the vulnerability localization task at the granularity of vulnerability triggering path named MRC-VulLoc. Initially, we design six large datasets (including C/C++ and Java languages) in the form of MRC. Subsequently, we introduce a novel pre-trained vulnerability localization model, combining the effective code semantic comprehension ability of pre-trained model with the advantages of Bidirectional Short-Term Memory Network (Bi-LSTM) and Convolutional Neural Network (CNN) models. Lastly, we conduct experiments to evaluate the vulnerability localization with several state-of-the-art MRC approaches and vulnerability detectors. Experimental results demonstrate the effectiveness of the proposed datasets in evaluating MRC approaches for vulnerability localization. Furthermore, MRC-VulLoc achieves higher precision on vulnerability localization compared to comparative vulnerability detectors.}
}


@article{DBLP:journals/compsec/HanLCHWBHW24,
	author = {Xu Han and
                  Qiang Li and
                  Hongbo Cao and
                  Lei Han and
                  Bin Wang and
                  Xuhua Bao and
                  Yufei Han and
                  Wei Wang},
	title = {BFS2Adv: Black-box adversarial attack towards hard-to-attack short
                  texts},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103817},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103817},
	doi = {10.1016/J.COSE.2024.103817},
	timestamp = {Thu, 15 Aug 2024 07:54:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HanLCHWBHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advent of Machine Learning as a Service (MLaaS) and deep learning applications has increased the susceptibility of models to adversarial textual attacks, particularly in black-box settings. Prior work on black-box adversarial textual attacks generally follows a stable strategy that involves leveraging char-level, world-level, and sentence-level perturbations, as well as using queries to the target model to find adversarial examples in the search space. However, existing approaches prioritize query efficiency by reducing the search space, thereby overlooking hard-to-attack textual instances. To address this issue, we propose BFS2Adv, a brute force algorithm that generates adversarial examples for both easy-to-attack and hard-to-attack textual inputs. BFS2Adv, starting with an original text, employs word-level perturbations and synonym substitution to construct a comprehensive search space, with each node representing a potential adversarial example. The algorithm systematically explores this space through a breadth-first search, combined with queries to the target model, to effectively identify qualified adversarial examples. We implemented and evaluated a prototype of BFS2Adv against renowned models such as ALBERT and BERT, utilizing the SNLI and MR datasets. Our results demonstrate that BFS2Adv outperforms state-of-the-art algorithms and effectively improves the success rate of short-text adversarial attacks. Furthermore, we provide detailed insights into the robustness of BFS2Adv by analyzing those hard-to-attack examples.}
}


@article{DBLP:journals/compsec/MaliniK24,
	author = {P. Malini and
                  Dr. K. R. Kavitha},
	title = {An efficient deep learning mechanisms for IoT/Non-IoT devices classification
                  and attack detection in SDN-enabled smart environment},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103818},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103818},
	doi = {10.1016/J.COSE.2024.103818},
	timestamp = {Fri, 24 May 2024 10:34:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MaliniK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the development of Internet of Things (IoT) applications has increased, resulting in higher demands for sufficient bandwidth, data rates, latency, and quality of service (QoS). In advanced communications, managing network resources for allocating IoT services and identifying the exact IoT devices connected to a network is a major concern. The existing studies have introduced various methods for classifying IoT devices in a network. However, the previous studies faced challenges like limited attributes, low efficiency, inappropriate features, and computational complexities. Also, the existing studies failed to concentrate on IoT/Non-IoT classification along with attack detection. Detecting attacks on IoT devices is critical for making network services more effective. Thus, the proposed study introduces an efficient IoT device classification and attack detection mechanism using software defined networking (SDN)-enabled fiber-wireless access networks internet of things (FiWi IoT) architecture. Initially, an effective resource allocation process is performed to mitigate the delay constraint issues by introducing a hybrid parallel neural network-based dynamic bandwidth allocation (DBA) method. Then, the input traffic information is gathered from the resource-efficient SDN-enabled FiWi IoT network, and the input data is pre-processed to eliminate unwanted noises using min-max normalization and standardization. Next, the essential attributes are extracted to attain enhanced classification performance. To reduce the feature dimensionality problem and thereby solve complexity issues, the most optimal features are selected by a new chaotic seagull optimization (CSO) approach. After that, IoT/non-IoT classification is performed using a transformer-driven deep intelligent model. Finally, the attacks are detected and classified by introducing a novel slice attention-based deep capsule autoencoder (SA_DCAE) model. For experimentation, the Python 3.7.0 tool is used in this work, and the performance of proposed classifiers is measured by evaluating varied matrices. Also, the comparison analysis proves the superiority of the proposed techniques to other existing methods.}
}


@article{DBLP:journals/compsec/SinghT24,
	author = {Narendra Singh and
                  Somanath Tripathy},
	title = {It's too late if exfiltrate: Early stage Android ransomware detection},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103819},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103819},
	doi = {10.1016/J.COSE.2024.103819},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SinghT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ransomware attacks disrupt and disable systems, demanding a ransom from the victim to restore functionality. Most of the state-of-the-art approaches focus on analyzing their behaviour at the post-infection, to identify ransomware and therefore, fails to detect at the early stage. This work proposes a ransomware detection mechanism named Weapon, to identify the threat at the pre-operational stage in Android system. Weapon extracts the key features from the behavioural characteristics (permissions and API calls) of the APK file and generates semantic features. Consequently, the MITRE ATT&CK framework is used to correlate with the semantic features to detect ransomware before its operational stage efficiently. The experimental results demonstrate that our approach could successfully identify 89.82% ransomware samples at the pre-operational stage.}
}


@article{DBLP:journals/compsec/AJPK24,
	author = {Nitish A and
                  Hanumanthappa J and
                  S. P. Shiva Prakash and
                  Kirill Krinkin},
	title = {Class imbalance and concept drift invariant online botnet threat detection
                  framework for heterogeneous IoT edge},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103820},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103820},
	doi = {10.1016/J.COSE.2024.103820},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AJPK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous networks (HetIoT) of high-capacity and resource-constrained IoT devices and their edge associations for on-device distributed critical workloads—called the edge-of-things (EoT)—attract short-burst, botnet-based zero-day attacks that exploit latent vulnerabilities due to heterogeneous device properties, dynamic operational contexts, and insufficient security scrutiny of the constituent proprietary devices. Such a scenario necessitates a device-specific network intrusion detection (NID) technique for localizing the threat space and updated rule learning through online (real-time) model retraining. Furthermore, scarce labeled knowledge base and high levels of class imbalance of NID datasets complicate the ID system design process for EoT environments, as online detection cannot afford computationally expensive data balancing techniques; this necessitates a class imbalance invariant traffic inference technique for data preprocessing. Therefore, we propound the ONIDS online NID technique, which consists of a two-fold solution for the above problems. First, we propose a Beta distribution-based inference technique for efficient traffic behavior approximation—invariant of class imbalance and capable of non-cumulative traffic processing of smaller sample sizes. Then, we put forth an online ID technique called ELMO for class imbalance invariant time-bound training of smaller sample sizes on resource-constrained device-specific network traffic. Together, they are invariant of traffic class imbalances and adaptable to resultant concept drift categories exhibited by HetIoT attack behaviors. ONIDS has low memory and compute footprints and can efficiently process large and small amounts of traffic, making it suitable for online and offline NID. It also exhibits qualitative and quantitative superiority—particularly on smaller data samples.}
}


@article{DBLP:journals/compsec/ZhongLZX24,
	author = {Meihui Zhong and
                  Mingwei Lin and
                  Chao Zhang and
                  Zeshui Xu},
	title = {A survey on graph neural networks for intrusion detection systems:
                  Methods, trends and challenges},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103821},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103821},
	doi = {10.1016/J.COSE.2024.103821},
	timestamp = {Sun, 06 Oct 2024 21:22:23 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhongLZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intrusion detection systems (IDS) play a crucial role in maintaining network security. With the increasing sophistication of cyber attack methods, traditional detection approaches are encountering more challenges. In recent years, graph neural networks (GNNs) have garnered significant attention in the field of intrusion detection due to their unique ability to capture the relationships within the graph structure of data communications. In this review, we propose a novel taxonomy that categorizes advanced research into three distinct areas: tasks related to graph construction, network design, and GNN models deployment. We detail a generalized design process for GNN-based intrusion detection models, discussing the challenges encountered at each stage. Building upon these discussions, we conduct a systematic survey of existing works. Ultimately, we delve into a thorough exploration of the future research directions and the pending issues in this domain. By adopting a problem-oriented taxonomy and conducting a targeted survey, this review aims to provide scholars with a clear, systematic framework for deepening their understanding and further exploration of the field.}
}


@article{DBLP:journals/compsec/JiangZLKY24,
	author = {Guangshang Jiang and
                  Hanlin Zhang and
                  Jie Lin and
                  Fanyu Kong and
                  Leyun Yu},
	title = {Optimized verifiable delegated private set intersection on outsourced
                  private datasets},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103822},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103822},
	doi = {10.1016/J.COSE.2024.103822},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/JiangZLKY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Private Set Intersection (PSI) has been applied in various fields, such as human genome research, advertising conversion rate analysis, etc. Traditional PSI has the drawback of requiring local devices to be constantly online and needing high storage capacity of the devices. To overcome these issues, many researchers have focused on delegating PSI computation to cloud servers. However, third-party clouds may bring many new challenges. One of the primary concerns is ensuring that the cloud server does not obtain sensitive data when the client outsources their dataset. Additionally, ensuring clients verify the correctness of the results is also a critical issue. In this paper, we propose the optimized verifiable delegated private set intersection protocol on outsourced private datasets (VO-PSI). Our protocol enables clients to verify the correctness of intersection with a negligible probability of incorrect results while being able to guarantee data privacy. Compared with previous research, the verifiability of the protocol has been dramatically improved. We analyze the security of the protocol under the malicious model and conduct experiments to evaluate its efficiency and feasibility.}
}


@article{DBLP:journals/compsec/PascualARD24,
	author = {Hugo Pascual and
                  Jos{\'{e}} M. del {\'{A}}lamo and
                  David Rodr{\'{\i}}guez Torrado and
                  Juan C. Due{\~{n}}as},
	title = {Hunter: Tracing anycast communications to uncover cross-border personal
                  data transfers},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103823},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103823},
	doi = {10.1016/J.COSE.2024.103823},
	timestamp = {Sun, 17 Nov 2024 20:22:33 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/PascualARD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-border personal data transfers are heavily regulated worldwide, with data protection authorities imposing huge fines on organizations that fail to meet their strict compliance requirements. However, network-level optimizations such as anycast addresses were not designed with personal data in mind, and their use may unwittingly divert personal data out of a legal boundary. This paper describes Hunter, an automated method to trace anycast communications and identify those threatening data protection compliance. We have applied Hunter in the wild to a set of Android apps to discover that all apps observed sending personal data to anycast addresses eventually carry out international transfers but fail to disclose them in their privacy policies. Our findings suggest that using anycast addresses to transmit personal data generally results in data protection compliance issues.}
}


@article{DBLP:journals/compsec/WangLHBWZ24,
	author = {Gaosheng Wang and
                  Peipei Liu and
                  Jintao Huang and
                  Haoyu Bin and
                  Xi Wang and
                  Hongsong Zhu},
	title = {KnowCTI: Knowledge-based cyber threat intelligence entity and relation
                  extraction},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103824},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103824},
	doi = {10.1016/J.COSE.2024.103824},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangLHBWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Structured cyber threat intelligence enables security researchers to know the occurrence of cyber threats in time, thereby improving the efficiency of security defense and analysis. Previous works usually use general deep learning and NLP techniques to extract intelligence. Such methods suffer from insufficient semantic understanding in the field of security. To address these issues, we propose a novel method called Knowledge-based Cyber Threat Intelligence Entity and Relation Extraction (KnowCTI), which incorporates cybersecurity knowledge into the model to enhance the understanding of the realm of cybersecurity and has a full picture of threats with the threat intelligence graph generation. Specifically, we first build a cybersecurity knowledge base and train cybersecurity-aware knowledge embeddings based on the base. Secondly, we refine the most related knowledge triples by attention mechanism and gate mechanism, and then construct a sentence tree through these triples. Next, we employ graph attention networks to incorporate knowledge information into the sentence by considering the sentence tree as a graph. Finally, we consider entity extraction as a sequence labeling problem and relation extraction as a classification problem to decode the entities and relation triples according to the threat intelligence ontology we designed. Experimental results demonstrate the superior performance with the F1 score exceeding 90.16 and 81.83 on entity and relation extraction separately.}
}


@article{DBLP:journals/compsec/YangHS24,
	author = {Xue Yang and
                  Enda Howley and
                  Michael Schukat},
	title = {{ADT:} Time series anomaly detection for cyber-physical systems via
                  deep reinforcement learning},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103825},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103825},
	doi = {10.1016/J.COSE.2024.103825},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YangHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-physical systems (CPS) play a vital role in modern society across various sectors, ranging from smart grid to water treatment, and their security has become one of the major concerns. Due to the significantly growing complexity and scale of CPS and cyber-attacks, it is imperative to develop defense and prevention strategies specifically for CPS that are adaptive, scalable, and robust. An important research and application direction in this domain is time series anomaly detection within CPS utilizing advanced machine learning techniques, such as deep learning and reinforcement learning. However, many anomaly detectors fail to balance between detection performance and computational overhead, limiting their applicability in CPS. In this paper, we introduce a novel agent-based dynamic thresholding (ADT) method based on the deep reinforcement learning technique, i.e. deep Q-network (DQN), to model thresholding in anomaly detection as a Markov decision process. By utilizing anomaly scores generated from an autoencoder and other useful information perceived from a simulated environment, ADT performs the optimal dynamic thresholding control, facilitating real-time adaptive anomaly detection for time series. Rigorous evaluations were conducted on realistic datasets from water treatment and industrial control systems, specifically SWaT, WADI, and HAI, comparing against established benchmarks. The experimental results demonstrate ADT's superior detection performance, dynamic thresholding capability, data-efficient learning, and robustness. Notably, ADT, even when trained on minimal labeled data, consistently outperforms benchmarks with F1 scores ranging from 0.995 to 0.999 across all datasets. It is effective even in challenging scenarios where the environmental feedback is noisy, delayed, or partial. Beyond its direct application as an advanced anomaly detector, ADT possesses the versatility to act as a lightweight dynamic thresholding controller, boosting other anomaly detection models. This underscores ADT's considerable promise in sophisticated and dynamic CPS environments.}
}


@article{DBLP:journals/compsec/ArroyabeAAA24,
	author = {Marta F. Arroyabe and
                  Carlos F. A. Arranz and
                  Ignacio Fernandez De Arroyabe and
                  Juan Carlos Fernandez de Arroyabe},
	title = {Revealing the realities of cybercrime in small and medium enterprises:
                  Understanding fear and taxonomic perspectives},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103826},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103826},
	doi = {10.1016/J.COSE.2024.103826},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ArroyabeAAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates cybercrime in Small and Medium Enterprises (SMEs) using Cyberspace Theory as a theoretical framework for a comprehensive analysis. Cyberspace Theory enables a thorough examination of cybercrime in SMEs, covering motives and consequences of cyber incidents, and identifying existing gaps. The study also delves into SMEs' perception of cybercrime fear, interpreting fear as their concern for cybercrime risk and its potential consequences. Drawing from a robust European Union database comprising 12,863 SMEs across member countries, our research contributes by establishing a taxonomy based on SMEs' perceptions of cybercrime fear. Understanding SMEs' views on cybercrime is crucial for enhancing cybersecurity measures and comprehending the broader economic and social implications of cybercrime.}
}


@article{DBLP:journals/compsec/ItodoO24,
	author = {Cornelius Itodo and
                  Murat Ozer},
	title = {Multivocal literature review on zero-trust security implementation},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103827},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103827},
	doi = {10.1016/J.COSE.2024.103827},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ItodoO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The sudden shift from physical office location to a fully remote or hybrid work model accelerated by the COVID19 pandemic, is a phenomenon that changed how organizations traditionally operated and thereby introduced new vulnerabilities and consequently changed the cyber threat landscape. This has led organizations around the globe to seek new approaches to protect their enterprise network. One such approach is the adoption of the Zero Trust security approach due to its many advantages over the traditional/perimeter security approach. Although zero trust presents a stronger defense approach over the perimeter security model, organizations are hesitant to fully embrace it. This is partly due to the lack of a unified zero-trust implementation framework that can be used to guide its adoption. As such, we conducted a multivocal review that included literature from both academic and non-academic sources to consolidate knowledge on the state-of-the-art of zero-trust implementation and identify gaps in literature. Our result shows that existing papers tend to have a narrow viewpoint on the approach of implementing zero trust, rather than an encompassing viewpoint that can provide a more holistic view on the topic. We developed a conceptual framework that articulates the five core components involved in the implementation of zero trust security, guided by key questions designed to guide the implementation process.}
}


@article{DBLP:journals/compsec/KuznetsovZFM24,
	author = {Oleksandr Kuznetsov and
                  Dmytro Zakharov and
                  Emanuele Frontoni and
                  Andrea Maranesi},
	title = {AttackNet: Enhancing biometric security via tailored convolutional
                  neural network architectures for liveness detection},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103828},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103828},
	doi = {10.1016/J.COSE.2024.103828},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KuznetsovZFM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biometric security is the cornerstone of modern identity verification and authentication systems, where the integrity and reliability of biometric samples is of paramount importance. This paper introduces AttackNet, a bespoke Convolutional Neural Network architecture, meticulously designed to combat spoofing threats in biometric systems. Rooted in deep learning methodologies, this model offers a layered defense mechanism, seamlessly transitioning from low-level feature extraction to high-level pattern discernment. Three distinctive architectural phases form the crux of the model, each underpinned by judiciously chosen activation functions, normalization techniques, and dropout layers to ensure robustness and resilience against adversarial attacks. Benchmarking our model across diverse datasets affirms its prowess, showcasing superior performance metrics in comparison to contemporary models. Furthermore, a detailed comparative analysis accentuates the model's efficacy, drawing parallels with prevailing state-of-the-art methodologies. Through iterative refinement and an informed architectural strategy, AttackNet underscores the potential of deep learning in safeguarding the future of biometric security.}
}


@article{DBLP:journals/compsec/LuoWT24,
	author = {Peng Luo and
                  Buhong Wang and
                  Jiwei Tian},
	title = {{TTSAD:} TCN-Transformer-SVDD Model for Anomaly Detection in air traffic
                  {ADS-B} data},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103840},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103840},
	doi = {10.1016/J.COSE.2024.103840},
	timestamp = {Sun, 06 Oct 2024 21:22:23 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LuoWT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {ADS-B (Automatic Dependent Surveillance-Broadcast) is a key technology in the new generation air traffic surveillance system. However, it is vulnerable to various cyber attacks because it broadcasts data in plaintext format and lacks authentication mechanism. Previous research has rarely considered the application scenarios of ATM (Air Traffic Management) in commercial air transport, and there are the problems of low anomaly detection rate and the non-lightweight model. This paper focuses on ADS-B anomaly detection under the background of ATM. We propose the TTSAD (TCN-Transformer-SVDD Model for Anomaly Detection) model, which aims to address the problems of existing ADS-B anomaly detection methods including inadequate considerations of long-term dependencies and distribution characteristic, the non-lightweight model and the poor adaptive threshold. First, ADS-B time series is input into TCN (Temporal Convolutional Network) prediction module which predicts data in an accurate and quick way using causal convolution and dilated convolution. Then, the predicted ADS-B time series is input into Transformer reconstruction module which reconstructs data accurately and quickly based on Self-Attention and Multi-Head Attention mechanism. Finally, the difference values between the reconstructed values and the real values are input into SVDD (Support Vector Data Description) threshold determination module for an optimal threshold. Experimental results show that the TTSAD model can detect ADS-B anomaly data generated from attacks such as altitude slow offset and DOS (Denial of Service). The TTSAD model is superior to other machine learning methods in terms of recall rate, detection rate, accuracy rate, missing detection rate and false alarm rate. Furthermore, compared with other deep learning methods including LSTM, GRU and LSTM-AE, the TTSAD model has a shorter training time and a lightweight characteristic. This approach guarantees the information security of ADS-B, thereby improving the operational security of ATM.}
}


@article{DBLP:journals/compsec/LiuKLZ24,
	author = {Liang Liu and
                  Xinyu Kuang and
                  Lin Liu and
                  Lei Zhang},
	title = {Defend against adversarial attacks in malware detection through attack
                  space management},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103841},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103841},
	doi = {10.1016/J.COSE.2024.103841},
	timestamp = {Fri, 19 Jul 2024 08:34:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiuKLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the application of machine learning techniques based on byte sequences in malware detection has become a prominent research area. However, relevant studies have shown that machine learning methods are susceptible to adversarial examples, and the use of byte sequences provides attackers with a convenient avenue for manipulation. Current research efforts primarily focus on data augmentation techniques to enhance detection capabilities. But these approaches require significant computational resources and lack robustness. In this paper, we propose a novel defense mechanism against adversarial attacks in the context of malware detection. Our approach effectively thwarts adversarial attacks by scanning the functionality-preserving attack space. Unlike existing methods, our approach eliminates the need for repetitive retraining, significantly reducing computational demands. Theoretically, it can also withstand unknown adversarial perturbations. Experimental validation demonstrates that our method not only maintains the prediction accuracy of MalConv but also enhances it. Furthermore, our best method successfully defended against almost all existing black-box and white-box attacks, reducing the number of escaping files from multiple to zero.}
}


@article{DBLP:journals/compsec/GalliGMPS24,
	author = {Antonio Galli and
                  Valerio La Gatta and
                  Vincenzo Moscato and
                  Marco Postiglione and
                  Giancarlo Sperl{\`{\i}}},
	title = {Explainability in AI-based behavioral malware detection systems},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103842},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103842},
	doi = {10.1016/J.COSE.2024.103842},
	timestamp = {Sat, 08 Jun 2024 13:15:47 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GalliGMPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, our security and privacy are strongly threatened by malware programs which aim to steal our confidential data and make our systems out of service, among other things. While traditional signature-based malware detection methods or statistical analysis have proven to be ineffective and time-consuming, recently data-driven Artificial Intelligence (AI) techniques, i.e. Machine Learning (ML) and Deep Learning (DL) approaches, have been successfully applied leveraging the behavior of malware in terms of API calls, and achieving promising performances. However, their black-box behavior leads to a lack of explainability thus preventing their application in real world scenarios. In light of this, eXplainable Artificial Intelligence (XAI) methodologies and tools can be effectively embedded within an AI-based malware detection process in order to make more understandable the produced results. In this paper, we propose a XAI framework for behavioral malware detection problems and evaluate the usefulness of four XAI methods (SHAP, LIME, LRP and Attention mechanism) on three datasets with different size, sequence length and number of classes, by which we could evaluate the strengths and weaknesses – from effectiveness and efficiency point of views – of recurrent deep architectures (i.e. Long-Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) models), and their applicability in the modern Cyber Security (CS) scenarios.}
}


@article{DBLP:journals/compsec/AsiriXAL24,
	author = {Sultan Asiri and
                  Yang Xiao and
                  Saleh Alzahrani and
                  Tieshan Li},
	title = {PhishingRTDS: {A} real-time detection system for phishing attacks
                  using a Deep Learning model},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103843},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103843},
	doi = {10.1016/J.COSE.2024.103843},
	timestamp = {Sun, 04 Aug 2024 19:48:14 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AsiriXAL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, phishing attacks have become more intelligent and more challenging to detect using typical phishing methods. Moreover, attackers have leveraged some web development techniques to increase the website's legitimacy in victims' eyes, such as using JFrame to design a window that looks like a browser inside the webpage. In this paper, we design a system that detects three types of phishing attacks: Tiny Uniform Resource Locators (TinyURLs), Browsers in the Browser (BiTB), and regular phishing attacks. In this system, we aim to protect victims from mistakenly downloading malicious software into their systems. We split our system into three parts: Deep Learning model (DL), browser extension, and docker container. First, we design a DL model using bidirectional long short-term memory (BiLSTM) and an attention mechanism to classify the URL as phishing or benign. Our model shows 99% in its precision, recall, and F1 score. Second, we design a browser extension to extract the original URL from the suspect webpage and then send it to the docker container. Then, the docker container opens the webpage and extracts all URLs from its HyperText Markup Language (HTML) and JavaScript. Then, each URL passes to a DL model for classification, resulting in a list of labels for each webpage. Therefore, we use three decision strategies: Single Phishing Strategy (SPhS), Mean Sum Strategy (MSS), and Weighted Average Strategy (WeAS) to decide whether the webpage is phishing or benign. Our findings indicate that the best results among the three strategies were WeAS.}
}


@article{DBLP:journals/compsec/KernLSW24,
	author = {Manuel Kern and
                  Max Landauer and
                  Florian Skopik and
                  Edgar R. Weippl},
	title = {A logging maturity and decision model for the selection of intrusion
                  detection cyber security solutions},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103844},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103844},
	doi = {10.1016/J.COSE.2024.103844},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KernLSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many modern cyber attack techniques cannot be prevented. Logging and monitoring, however, offer a means to at least detect these techniques early, and therefore become increasingly important for defense. Many companies are unfortunately reluctant to invest more in cyber security logging and monitoring or hire additional security staff to operate detective solutions. There is a need for a methodology to pick appropriate cyber security solutions from the vast pool of available products. Our model takes requirements mandated by common standards from ISO, NIST, BSI and the like into account. While standards and guidelines remain at a high abstraction level and are applicable to different organizations over a long period of time, guidance on implementation becomes outdated comparatively quickly. We propose a novel logging maturity and decision model for the selection of the best fitting cyber security solutions for an organization. The novelty is that this model accounts for constraints in the selection process, such as cost, complexity, compliance, and relevance to the organization's assets. We validate the model with MITRE ATT&CK framework data and apply it to illustrative use cases based on our survey.}
}


@article{DBLP:journals/compsec/AldaajehA24,
	author = {Saleh H. Aldaajeh and
                  Saed Alrabaee},
	title = {Strategic cybersecurity},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103845},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103845},
	doi = {10.1016/J.COSE.2024.103845},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AldaajehA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the contemporary ever-evolving digital landscape, the paramount importance of fortifying national cybersecurity for safeguarding national security is unequivocal. Cybersecurity stands as a critically strategic field, demanding in-depth strategic planning. This research delves into the complexities of cybersecurity strategy, evaluation, and its myriad challenges, moving beyond conventional methodologies to illuminate this essential sector. A key contribution of our work is the creation of an innovative taxonomy that precisely classifies and categorizes strategic cybersecurity challenges, thereby enriching the discipline's lexicon and deepening the understanding of the cybersecurity environment. Additionally, this study conducts a thorough review of prevailing guidelines, models, standards, and frameworks for the assessment of cybersecurity, its maturity, and cyber power, rendering this research indispensable for decision-makers. It also methodically examines and presents a mathematical formulation for assessment indices. This provision of critical insights supports the crafting of holistic and adaptable cybersecurity strategies, promoting a robust cyber ecosystem. Consequently, nations are better positioned to adeptly manage the shifting sands of cyber threats, bolstering their global cybersecurity stature and ensuring the protection of national and international digital security interests.}
}


@article{DBLP:journals/compsec/ShenFX24,
	author = {Lina Shen and
                  Mengqi Fang and
                  Jian Xu},
	title = {GHGDroid: Global heterogeneous graph-based android malware detection},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103846},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103846},
	doi = {10.1016/J.COSE.2024.103846},
	timestamp = {Fri, 24 May 2024 10:34:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ShenFX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the most popular mobile platform, Android has become the major attack target of malware, and thus there is an urgent need to effectively thwart them. Recently, the graph-based technique has been a promising solution for malware detection, which highly depends on graph structures to capture behaviors separating the malware from the benign apps. However, existing graph-based malware detection approaches still suffer from high computation cost in constructing or updating a graph for APK under detection, high false negative and false positive. To cope with these issues, we propose a novel global heterogeneous graph-based Android malware detection approach, named GHGDroid. A global heterogeneous graph (GHG) with a good updatability is first built on large-scale Android applications to characterize complex relationships among APKs and sensitive APIs. And then, using the GHG, a multi-layer graph convolutional network based embedding method is proposed to learn APK embeddings for well capturing behaviors that can separate malware from benign. Finally, using APK embeddings as well their labels, a malware classifier is trained. Experiments on real-world Android applications show that GHGDroid achieves 99.17 % F1-score, which outperforms the state-of-the-art approaches. Moreover, GHGDroid spends about 8 s on detecting an APK, which shows that it has a good potential as a practical tool for the Android malware detection task.}
}


@article{DBLP:journals/compsec/RoshanZ24,
	author = {Khushnaseeb Roshan and
                  Aasim Zafar},
	title = {Black-box adversarial transferability: An empirical study in cybersecurity
                  perspective},
	journal = {Comput. Secur.},
	volume = {141},
	pages = {103853},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103853},
	doi = {10.1016/J.COSE.2024.103853},
	timestamp = {Fri, 31 May 2024 21:07:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RoshanZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid advancement of artificial intelligence within the realm of cybersecurity raises significant security concerns. The vulnerability of deep learning models in adversarial attacks is one of the major issues. In adversarial machine learning, malicious users try to fool the deep learning model by inserting adversarial perturbation inputs into the model during its training or testing phase. Subsequently, it reduces the model confidence score and results in incorrect classifications. The novel key contribution of the research is to empirically test the black-box adversarial transferability phenomena in cyber attack detection systems. It indicates that the adversarial perturbation input generated through the surrogate model has a similar impact on the target model in producing the incorrect classification. To empirically validate this phenomenon, surrogate and target models are used. The adversarial perturbation inputs are generated based on the surrogate-model for which the hacker has complete information. Based on these adversarial perturbation inputs, both surrogate and target models are evaluated during the inference phase. We have done extensive experimentation over the CICDDoS-2019 dataset, and the results are classified in terms of various performance metrics like accuracy, precision, recall and f1-score. The findings indicate that any deep learning model is highly susceptible to adversarial attacks, even if the attacker does not have access to the internal details of the target model. The results also indicate that white-box adversarial attacks have a severe impact compared to black-box adversarial attacks. There is a need to investigate and explore adversarial defence techniques to increase the robustness of the deep learning models against adversarial attacks.}
}
