@article{DBLP:journals/compsec/JingadeK23,
	author = {Raghuram Raghavendra Jingade and
                  Rajaram Sanjeev Kunte},
	title = {Extended right-angle difference ternary co-relation pattern: {A} new
                  feature descriptor for face anti-spoofing},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103421},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103421},
	doi = {10.1016/J.COSE.2023.103421},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/JingadeK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Presently, in many applications face recognition is commonly used as an authentication security system. However, an intruder can spoof the face recognition system by using genuine user photos or video to gain access. Therefore, there is a need for a superior technique for face anti-spoofing to handle all kinds of spoofing attacks in any environment. This paper presents a novel descriptor called extended right-angle difference ternary co-relation pattern (ERDTCP) for face anti-spoofing. The ERDTCP is calculated based on the division of a given image into 4 blocks at an angle of 0°, 90°, 180° and 270° from the center pixel. The effectiveness of the proposed method is evaluated on three publically available databases using KNN and SVM classifiers. Experiments were conducted using SOTA approaches and the proposed method using ERDTCP and the results were compared. The proposed face anti-spoofing approach performs better than SOTA approaches.}
}


@article{DBLP:journals/compsec/CosciaDGMP23,
	author = {Antonio Coscia and
                  Vincenzo Dentamaro and
                  Stefano Galantucci and
                  Antonio Maci and
                  Giuseppe Pirlo},
	title = {An innovative two-stage algorithm to optimize Firewall rule ordering},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103423},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103423},
	doi = {10.1016/J.COSE.2023.103423},
	timestamp = {Tue, 07 May 2024 20:21:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CosciaDGMP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Packet classification activity performed by a FireWall (FW) introduces high latency in network communications due to the computation time required to check whether any packet matches one of the FW rules. Such a classification process is done by sequentially checking the list of rules until a match is found or the end of the list is reached. Given the complexity of FW rules in some environments, this latency could become relevant. This problem is addressed by ordering the list of FW rules to minimize the classification latency, where the rules with higher activation frequencies are placed accordingly starting from the top of the list. This is not always feasible because dependency constraints between rules could exist: swapping the positions of dependent rules results in a loss of the integrity of the implemented security policy. For this reason, the FW rule ordering problem belongs to the realm of constrained combinatorial optimization.}
}


@article{DBLP:journals/compsec/McIntoshLSANNW23,
	author = {Timothy R. McIntosh and
                  Tong Liu and
                  Teo Susnjak and
                  Hooman Alavizadeh and
                  Alex Ng and
                  Raza Nowrozy and
                  Paul A. Watters},
	title = {Harnessing {GPT-4} for generation of cybersecurity {GRC} policies:
                  {A} focus on ransomware attack mitigation},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103424},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103424},
	doi = {10.1016/J.COSE.2023.103424},
	timestamp = {Mon, 08 Jul 2024 08:23:14 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/McIntoshLSANNW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study investigated the potential of Generative Pre-trained Transformers (GPTs), a state-of-the-art large language model, in generating cybersecurity policies to deter and mitigate ransomware attacks that perform data exfiltration. We compared the effectiveness, efficiency, completeness, and ethical compliance of GPT-generated Governance, Risk and Compliance (GRC) policies, with those from established security vendors and government cybersecurity agencies, using game theory, cost-benefit analysis, coverage ratio, and multi-objective optimization. Our findings demonstrated that GPT-generated policies could outperform human-generated policies in certain contexts, particularly when provided with tailored input prompts. To address the limitations of our study, we conducted our analysis with thorough human moderation, tailored input prompts, and the inclusion of legal and ethical experts. Based on these results, we made recommendations for corporates considering the incorporation of GPT in their GRC policy making.}
}


@article{DBLP:journals/compsec/FernandezFuentesPC23,
	author = {Xos{\'{e}} Fern{\'{a}}ndez{-}Fuentes and
                  Tom{\'{a}}s F. Pena and
                  Jos{\'{e}} Carlos Cabaleiro},
	title = {Digital forensic analysis of the private mode of browsers on Android},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103425},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103425},
	doi = {10.1016/J.COSE.2023.103425},
	timestamp = {Wed, 01 Nov 2023 08:59:33 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/FernandezFuentesPC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The smartphone has become an essential electronic device in our daily lives. We carry our most precious and important data on it, from family videos of the last few years to credit card information so that we can pay with our phones. In addition, in recent years, mobile devices have become the preferred device for surfing the web, already representing more than 50% of Internet traffic. As one of the devices we spend the most time with throughout the day, it is not surprising that we are increasingly demanding a higher level of privacy. One of the measures introduced to help us protect our data by isolating certain activities on the Internet is the private mode integrated in most modern browsers. Of course, this feature is not new, and has been available on desktop platforms for more than a decade. Reviewing the literature, one can find several studies that test the correct functioning of the private mode on the desktop. However, the number of studies conducted on mobile devices is incredibly small. And not only is it small, but also most of them perform the tests using various emulators or virtual machines running obsolete versions of Android. Therefore, in this paper we apply the methodology we presented in a previous work to Google Chrome, Brave, Mozilla Firefox, and Tor Browser running on a tablet with Android 13 and on two virtual devices created with Android Emulator. The results confirm that these browsers do not store information about the browsing performed in private mode in the file system. However, the analysis of the volatile memory made it possible to recover the username and password used to log in to a website or the keywords typed in a search engine, even after the devices had been rebooted.}
}


@article{DBLP:journals/compsec/CaoWWZFC23,
	author = {Dongliang Cao and
                  Kaimin Wei and
                  Yongdong Wu and
                  Jilian Zhang and
                  Bingwen Feng and
                  Jinpeng Chen},
	title = {FePN: {A} robust feature purification network to defend against adversarial
                  examples},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103427},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103427},
	doi = {10.1016/J.COSE.2023.103427},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CaoWWZFC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) have been demonstrated to be vulnerable to adversarial attacks. Existing defenses can defend against a variety of adversarial examples. However, as the perturbation budget used to create adversarial examples increases, their adversarial robustness decreases dramatically. To solve this problem, we develop a Feature Purification Network (FePN), which is based on the fact that adversarial examples are closely associated with non-robust features of data. Specifically, an adversarial learning mechanism is proposed to learn robust features by removing non-robust features from inputs. Meanwhile, two linear branches and a discriminator are designed to reconstruct high-quality natural images by exploiting robust features. FePN is a preprocessing approach that can be utilized to safeguard other models without altering them. We conduct a series of experiments on MNIST, CIFAR-10 and ImageNet. Experimental results have proven that FePN can provide effective protection compared to previous state-of-the-art approaches, as well as superior robustness against attacks with considerable perturbations.}
}


@article{DBLP:journals/compsec/ChenWHH23,
	author = {Shouhong Chen and
                  Tao Wang and
                  Zhentao Huang and
                  Xingna Hou},
	title = {Detection method of Golden Chip-Free Hardware Trojan based on the
                  combination of ResNeXt structure and attention mechanism},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103428},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103428},
	doi = {10.1016/J.COSE.2023.103428},
	timestamp = {Tue, 24 Oct 2023 15:07:19 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenWHH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since 2007, the use of side-channel data to detect hardware Trojans (HT) has been widely studied. Machine learning methods are widely used in the detection of hardware Trojans, but with the development of integrated circuits (IC), machine learning methods are not able to obtain a higher accuracy rate compared to deep learning. In this paper, we propose to use an architecture inspired by the ResNeXt network architecture and combine it with an attention mechanism, referred to as the Attention-Res-Attention (ARA) network. Firstly, the side channel data are extracted by convolutional layer with features and focus on important points under the attention module; then, the feature map enters the ResNeXt architecture that achieves classification accuracy improvement by adding the attention module; finally, the data are classified by the fully connected layer. Our proposed solution is observable to natural variations that may occur in side-channel measurements, and can accurately detect abnormal behavior of the chip when HT is triggered. And using a self-referential method for HT detection eliminates the need for a golden chip. The effectiveness of the method proposed in this paper is evaluated based on the AES series hardware Trojans publicly provided by TrustHub. Experimental results show that the method proposed in this paper has a high accuracy rate when a single Trojan exists, and can effectively detect the existence of hardware Trojans. And when a variety of hardware Trojans exist at the same time, the method used in this paper can effectively distinguish the types of hardware Trojans, and the highest average accuracy rate reached 97% during the experiment. Compared with the existing deep learning methods, the network model in this paper has higher classification accuracy.}
}


@article{DBLP:journals/compsec/WangLKT23,
	author = {Xuan Wang and
                  Yaojie Li and
                  Hanieh Javadi Khasraghi and
                  Cherie Courseault Trumbach},
	title = {The mediating role of security anxiety in internet threat avoidance
                  behavior},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103429},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103429},
	doi = {10.1016/J.COSE.2023.103429},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangLKT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the prior technology threat avoidance literature, inconsistent results are found in examining the relationships between individuals’ perceived susceptibility, perceived severity, and perceived threat, as well as the intention to avoid security threats. One possible explanation for this paradox is lacking consideration of the role of individuals’ negative emotions while facing threats, which is rarely studied before. Therefore, the current study aims to extend the landscape of technology threat avoidance theory by exploring the role of security anxiety in individuals’ responses to security threats from the Internet. Our results demonstrate that Internet users’ risk aversion is strongly influenced by their perception of security threats, response efficacy, and security self-efficacy within the online environment. Also, our results indicate that individuals’ security anxiety can partially mediate the relationship between perceived threat and Internet threat avoidance behavior.}
}


@article{DBLP:journals/compsec/BayerFR23,
	author = {Markus Bayer and
                  Tobias Frey and
                  Christian Reuter},
	title = {Multi-level fine-tuning, data augmentation, and few-shot learning
                  for specialized cyber threat intelligence},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103430},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103430},
	doi = {10.1016/J.COSE.2023.103430},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BayerFR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gathering cyber threat intelligence from open sources is becoming increasingly important for maintaining and achieving a high level of security as systems become larger and more complex. However, these open sources are often subject to information overload. It is therefore useful to apply machine learning models that condense the amount of information to what is necessary. Yet, previous studies and applications have shown that existing classifiers are not able to process information about emerging cybersecurity events, such as new malware names or novel attack contexts, due to their low generalisation capability. Therefore, we propose a system to overcome this problem by training a new classifier for each new incident. Since this requires a lot of labelled data using standard training methods, we combine three different low-data regime techniques – transfer learning, data augmentation, and few-shot learning – to train a high-quality classifier from very few labelled instances. We evaluated our approach using a novel dataset derived from the Microsoft Exchange Server data breach of 2021 which was labelled by three experts. Our findings reveal an increase in F1 score of more than 21 points compared to standard training methods and more than 18 points compared to a state-of-the-art method in few-shot learning. Furthermore, the classifier trained with this method and 32 instances is only less than 5 F1 score points worse than a classifier trained with 1800 instances.}
}


@article{DBLP:journals/compsec/LiHX23,
	author = {Jiachun Li and
                  Yuchao Hu and
                  Fei Xia},
	title = {A variable adversarial attack method based on filtering},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103431},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103431},
	doi = {10.1016/J.COSE.2023.103431},
	timestamp = {Tue, 24 Oct 2023 15:07:19 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiHX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Previous works have pointed out that deep learning models are vulnerable to adversarial examples crafted by adding negligible confusing noise to clean images. However, adversarial examples are hard to transfer to attack other defense models or do not conform to human-imperceptible under the black-box setting. To bridge this gap, a variable adversarial attack method based on filtering called VFI-FGSM is proposed. Variable Step Size Method (VSSM) is designed to adaptively control perturbation to avoid overfitting, the Filtering based Iterative Fast Gradient Sign Method (FI-FGSM) is explored to enhance robustness of attack, an auxiliary loss of high-level representation is added to get a more precise gradient direction and improve the attack success rate, and a new tactic named the contribution for reducing perturbation size(CRPS) are presented to measure the performance of attack algorithms in the paper. The results show that scheme proposed increases the attack success rate by an average of 14.36% in ensemble attack method and 7.9% on combined trained model for defense models in black-box setting. Fortunately, the noise is perceptually small in both\nL\n1\nand\nL\n2\nmetrics.}
}


@article{DBLP:journals/compsec/SrivastavaSK23,
	author = {Arpita Srivastava and
                  Ditipriya Sinha and
                  Vikash Kumar},
	title = {{WCGAN-GP} based synthetic attack data generation with {GA} based
                  feature selection for {IDS}},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103432},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103432},
	doi = {10.1016/J.COSE.2023.103432},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SrivastavaSK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-attack is one of the alarming issues in today's era. Firewalls, Intrusion Detection Systems (IDSs), and other techniques are popularly applied to prevent those attacks. Intrusion Detection System (IDS) works as the watchdog to monitor the network traffic and identify an alert when an unauthorized action is detected. However, most IDSs are designed on traditional datasets, which do not address the data imbalance problem. As a result, their performance is not good enough against minority class samples. In order to overcome the aforementioned problem and detect cyber-attacks with higher precision, this paper proposes a novel IDS applying Wasserstein Conditional Generative Adversarial Network – Gradient Penalty (WCGAN-GP) and Genetic Algorithm (GA). The objective of the two components- WCGAN-GP and Genetic Algorithm are introduced in the proposed work for synthetic data generation, feature optimization, and attack detection system. The proposed model generates synthetic samples that follow the underlying data distribution of actual data. This paper uses a novel fitness function for the convergence of the Genetic algorithm and produces an optimal feature vector for the classification problem. In this work, an extensive experimental study applying NSL-KDD and UNSW-NB15 datasets in combination with generated samples and reduced feature set from the proposed model is carried out to evaluate the performance of different machine learning models. Observations show that Xgboost gives the best performances among others. To justify using a genetic algorithm for feature optimization, this paper has compared the proposed model with other traditional feature selection approaches such as PCA, Autoencoder, and T-SNE on the proposed model. It is found that the proposed GA-based feature selection outperforms others. The reason behind it is that the GA-based feature selection technique offers certain advantages over PCA and Autoencoder-based dimensionality reduction techniques, such as the ability to handle non-linearity between features in the data, enhanced flexibility in feature selection, interpretability, and human insight, handling high-dimensional data, robustness to noise and outliers. It also offers an advantage over T-SNE, a nonlinear dimensionality reduction technique in terms of computational efficiency. Furthermore, the model is also compared with other state-of-the-art which address data imbalance problems. Our proposed model with Xgboost classifier gives better results than other existing approaches in terms of accuracy (95.54%), precision (92.61%), recall (95.54%), F1-score (93.41%), and false alarm rate (4.30%) on the NSL-KDD dataset and accuracy (89.58%), precision (89.46%), recall (89.58%), F1-score (88.89%) and false alarm rate (1.18%) on the UNSW-NB15 dataset.}
}


@article{DBLP:journals/compsec/VitorinoPM23,
	author = {Jo{\~{a}}o Vitorino and
                  Isabel Pra{\c{c}}a and
                  Eva Maia},
	title = {SoK: Realistic adversarial attacks and defenses for intelligent network
                  intrusion detection},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103433},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103433},
	doi = {10.1016/J.COSE.2023.103433},
	timestamp = {Tue, 07 May 2024 20:21:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/VitorinoPM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) can be incredibly valuable to automate anomaly detection and cyber-attack classification, improving the way that Network Intrusion Detection (NID) is performed. However, despite the benefits of ML models, they are highly susceptible to adversarial cyber-attack examples specifically crafted to exploit them. A wide range of adversarial attacks have been created and researchers have worked on various defense strategies to safeguard ML models, but most were not intended for the specific constraints of a communication network and its communication protocols, so they may lead to unrealistic examples in the NID domain. This Systematization of Knowledge (SoK) consolidates and summarizes the state-of-the-art adversarial learning approaches that can generate realistic examples and could be used in ML development and deployment scenarios with real network traffic flows. This SoK also describes the open challenges regarding the use of adversarial ML in the NID domain, defines the fundamental properties that are required for an adversarial example to be realistic, and provides guidelines for researchers to ensure that their experiments are adequate for a real communication network.}
}


@article{DBLP:journals/compsec/WuFLX23,
	author = {Anbin Wu and
                  Zhiyong Feng and
                  Xiaohong Li and
                  Jianmao Xiao},
	title = {ZTWeb: Cross site scripting detection based on zero trust},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103434},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103434},
	doi = {10.1016/J.COSE.2023.103434},
	timestamp = {Tue, 24 Oct 2023 15:07:19 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WuFLX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Policy defense technology is the mainstream XSS defense technology. However, defense mechanisms with fixed policies may hardly cover the attack surface persistently in dynamic environments. Moreover, the undifferentiated policy makes the malicious code and developer code have the same resource authorization, which leads to the game between the security and usability of the page. To tackle this problem, we propose a zero trust-based defense model - ZTWeb, which constructs differentiated and dynamic policies to balance the security and usability of the website. Specifically, ZTWeb micro-segments the protect surface code into the trust domain, executing different authorization policies based on the trust level of the code subject. The key of ZTWeb is to break the control risk of static policy authorization and create dynamic trust by continuously evaluating the behavior of untrusted domains. Trust evaluation takes the call sequence of sensitive resources as the judgment element. We associate the parent-child relationship between domains and divide the behavior branches within the domain to construct a complete, accurate, context-containing behavior sequence. Furthermore, the extracted sequence is regarded as a piece of text, and the TextCNN model is introduced to identify XSS attacks. We evaluate ZTWeb using real datasets collected from GitHub. The experimental results show that the model can achieve an accuracy of 99.7%, the overall performance overhead is low, and strong security is maintained without destroying the website's usability.}
}


@article{DBLP:journals/compsec/EbertSASZK23,
	author = {Nico Ebert and
                  Thierry Schaltegger and
                  Benjamin Ambuehl and
                  Lorin Sch{\"{o}}ni and
                  Verena Zimmermann and
                  Melanie Knieps},
	title = {Learning from safety science: {A} way forward for studying cybersecurity
                  incidents in organizations},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103435},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103435},
	doi = {10.1016/J.COSE.2023.103435},
	timestamp = {Wed, 01 Nov 2023 08:59:33 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/EbertSASZK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the aftermath of cybersecurity incidents within organizations, explanations of their causes often revolve around isolated technical or human events such as an Advanced Persistent Threat or a “bad click by an employee.” These explanations serve to identify the responsible parties and inform efforts to improve security measures. However, safety science researchers have long been aware that explaining incidents in socio-technical systems and determining the role of humans and technology in incidents is not an objective procedure but rather an act of social constructivism: what you look for is what you find, and what you find is what you fix. For example, the search for a technical “root cause” of an incident might likely result in a technical fix, while from a sociological perspective, cultural issues might be blamed for the same incident and subsequently lead to the improvement of the security culture. Starting from the insights of safety science, this paper aims to extract lessons on what general explanations for cybersecurity incidents can be identified and what methods can be used to study causes of cybersecurity incidents in organizations. We provide a framework that allows researchers and practitioners to proactively select models and methods for the investigation of cybersecurity incidents.}
}


@article{DBLP:journals/compsec/ZhangLCLL23,
	author = {Guiqi Zhang and
                  Qi Liu and
                  Chenhong Cao and
                  Jiangtao Li and
                  Yufeng Li},
	title = {Bit scanner: Anomaly detection for in-vehicle {CAN} bus using binary
                  sequence whitelisting},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103436},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103436},
	doi = {10.1016/J.COSE.2023.103436},
	timestamp = {Wed, 20 Mar 2024 16:47:58 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangLCLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the vulnerability of in-vehicle networks, particularly the Controller Area Network (CAN), malicious remote intrusion into vehicles has been a prominent public concern in recent years. The majority of existing technologies disregard the importance of the frame payload, making it difficult to detect tampered frames. In this paper, we propose Bit Scanner, a whitelist-based anomaly detection method that employs fine-grained checking for frame payload. Bit Scanner has no dependency on the CAN periodicity or CAN protocol. Its detection capabilities are evaluated using genuine CAN traffic collected from an autonomous bus. The results show that the proposed method has a malicious frames detection rate improvement of about 20% under replay attack scenarios, and a malicious packets detection rate improvement of at least 20% under tampering attack situations compared to the state-of-art methods.}
}


@article{DBLP:journals/compsec/KimSC23,
	author = {Suryeon Kim and
                  Seungwon Shin and
                  Hyunwoo Choi},
	title = {{AVX-TSCHA:} Leaking information through {AVX} extensions in commercial
                  processors},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103437},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103437},
	doi = {10.1016/J.COSE.2023.103437},
	timestamp = {Wed, 01 Nov 2023 08:59:33 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KimSC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern x86 processors support an AVX instruction set to boost performance. However, this extension set may also cause security issues. We discovered that there are vulnerable properties in the implementation of the masked load/store instructions. First, these instructions can suppress exceptions caused by invalid or inaccessible memory access. Second, the execution time of these instructions leaks the current state of the page mappings, permissions, and TLB states.}
}


@article{DBLP:journals/compsec/KumarBAG23,
	author = {Chandan Kumar and
                  Soham Biswas and
                  Md. Sarfaraj Alam Ansari and
                  Mahesh Chandra Govil},
	title = {Nature-inspired intrusion detection system for protecting software-defined
                  networks controller},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103438},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103438},
	doi = {10.1016/J.COSE.2023.103438},
	timestamp = {Fri, 27 Oct 2023 20:40:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KumarBAG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software Defined Networks (SDN) is a new emerging networking architecture facilitated by a separate controller. It has a centralized architecture that serves network management and demand fulfillment from a single point. Architecturally, SDN provides lofty benefits, but security measures are a severe concern that prevents universal adoption. If the SDN controller gets compromised, the intruders could ensign the route of network traffic based on their requirements which causes damage to the entire network. These security limitations of SDN get rectified by employing the network intrusion detection system (NIDS). Deploying ML techniques for NIDS helps us to detect the anomalies within SDN. Selecting a minimal number of features is important as it decreases the computation overhead and accelerates the NIDS performances. For feature selection, a combination of k optimal features is selected using the hit-and-trial approach. As a result, it influences the system's durability for intrusion detection and pushes the model toward poor performance. In this study, we present a new hybrid framework for feature selection using Whale Optimisation Algorithm (WOA), Fisher Score (FS), and Information gain (IG), named Whale Optimization Algorithm-Fisher Feature Importance (WOA-F2I). WOA-F2I addresses the challenge of selecting the k number of an optimal subset of features. The evaluation result manifests the WOA-F2I feature selection technique that enhances the performance of the NIDS model, which backs the input for various classifiers- support vector machine, Naive Bayes, logistic regression, and stochastic gradient descent. The proposed feature selection technique also provides better performance for binary class and multi-class attack detection.}
}


@article{DBLP:journals/compsec/ImranSRRRA23,
	author = {Muhammad Ali Imran and
                  Hafeez Ur Rehman Siddiqui and
                  Ali Raza and
                  Muhammad Amjad Raza and
                  Furqan Rustam and
                  Imran Ashraf},
	title = {A performance overview of machine learning-based defense strategies
                  for advanced persistent threats in industrial control systems},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103445},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103445},
	doi = {10.1016/J.COSE.2023.103445},
	timestamp = {Sat, 28 Oct 2023 13:59:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ImranSRRRA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybersecurity incident response is a very crucial part of the cybersecurity management system. Adversaries emerge and evolve with new cybersecurity tactics, techniques, and procedures (TTPs). It is essential to detect the TTPs in a timely manner to respond effectively and mitigate the vulnerabilities to secure business operations. This research focuses on TTP identification and detection based on a machine learning approach. Early identification and detection are paramount in protecting, responding to, and recovering from such adversarial attacks. Analyzing use cases is a critical tool to ensure proper and in-depth evaluation of sector-specific cybersecurity challenges. In this regard, this study investigates existing known methodologies for cyber-attacks such as Mitre attacks, and developed a method for identifying threat cases. In addition, Windows-based threat cases are implemented, comprehensive datasets are generated, and supervised machine learning models are applied to detect threats effectively and efficiently. Random forest outperforms other models with the highest accuracy of 99%. Future work can be done for generating threat cases based on multiple log sources, including network security and endpoint protection device, and achieve high accuracy by removing false positives using machine learning. Similarly, real-time threat detection is also envisioned for future work.}
}


@article{DBLP:journals/compsec/LiCAGPZ23,
	author = {Jingjin Li and
                  Chao Chen and
                  Mostafa Rahimi Azghadi and
                  Hossein Ghodosi and
                  Lei Pan and
                  Jun Zhang},
	title = {Security and privacy problems in voice assistant applications: {A}
                  survey},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103448},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103448},
	doi = {10.1016/J.COSE.2023.103448},
	timestamp = {Wed, 01 Nov 2023 08:59:33 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiCAGPZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Voice assistant applications have become omniscient nowadays. Two models that provide the two most important functions for real-life applications (i.e., Google Home, Amazon Alexa, Siri, etc.) are Automatic Speech Recognition (ASR) models and Speaker Identification (SI) models. According to recent studies, security and privacy threats have also emerged with the rapid development of the Internet of Things (IoT). The security issues researched include attack techniques toward machine learning models and other hardware components widely used in voice assistant applications. The privacy issues include technical-wise information stealing and policy-wise privacy breaches. The voice assistant application takes a steadily growing market share every year, but their privacy and security issues never stopped causing huge economic losses and endangering users' personal sensitive information. Thus, it is important to have a comprehensive survey to outline the categorization of the current research regarding the security and privacy problems of voice assistant applications. This paper concludes and assesses five kinds of security attacks and three types of privacy threats in the papers published in the top-tier conferences of cyber security and voice domain.}
}


@article{DBLP:journals/compsec/YangL23,
	author = {Xiaohui Yang and
                  Xiang Li},
	title = {{ATDAD:} One-class adversarial learning for tabular data anomaly detection},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103449},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103449},
	doi = {10.1016/J.COSE.2023.103449},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YangL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The detection of tabular data anomalies is widely used in cybersecurity, medicine, and other fields. However, modelling tabular data is challenging. Unlike images and videos, tabular data have unknown structures and are of mixed type. Although most anomaly detection methods focus on images and videos, we propose a one-class adversarial learning method for tabular data anomaly detection (ATDAD). ATDAD changes the structure of generative adversarial networks (GANs) to better model high-dimensional complex tabular data. ATDAD adds dual encoders to stabilize the training and ensure cycle consistency of the samples and their reconstructions. ATDAD does not require any anomalous samples as prior knowledge in either the training or testing phases. To the best of our knowledge, ATDAD is the first study that focuses on the detection of tabular data anomalies using a GAN. Experiments show that ATDAD outperforms existing unsupervised anomaly detection methods for tabular data.}
}


@article{DBLP:journals/compsec/PamiesEstremsG23,
	author = {David P{\`{a}}mies{-}Estrems and
                  Joaqu{\'{\i}}n Garc{\'{\i}}a{-}Alfaro},
	title = {On the self-adjustment of privacy safeguards for query log streams},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103450},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103450},
	doi = {10.1016/J.COSE.2023.103450},
	timestamp = {Sat, 28 Oct 2023 13:59:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/PamiesEstremsG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet-based services process and store numerous search queries around the globe. The use of web search engines, such as Bing and Google, as well as personal assistants (e.g., Alexa and Cortana) and task specific systems (e.g., YouTube, Netflix, Amazon) are relevant examples. The queries associated to such services may be stored and sold out for profit. Before doing so, personal and sensitive information must be sanitized, as requested by current regulations. This can be cumbersome for some organizations. We present an automated solution for anonymizing unstructured data, like the one used within query logs. Our solution uses a light-weight probabilistic k-anonymity approach, which allows verifiable real-time privacy protection. It addresses previous limitations and improves performance. We validate the feasibility of the approach, under some evaluation metrics including data utility, privacy and speed.}
}


@article{DBLP:journals/compsec/OlimpioCMF23,
	author = {Gilberto Olimpio and
                  L{\'{a}}saro J. Camargos and
                  Rodrigo Sanches Miani and
                  Elaine Ribeiro de Faria},
	title = {Model update for intrusion detection: Analyzing the performance of
                  delayed labeling and active learning strategies},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103451},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103451},
	doi = {10.1016/J.COSE.2023.103451},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/OlimpioCMF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intrusion Detection Systems (IDS) help protect computer networks by identifying and detecting attempts to obtain unauthorized access to data via computer networks by inspecting packets separately or in the context of flows. Intrusion detection is a classification task performed on continuously generated packets with a non-stationary distribution (data stream). As such, the decision models used for Intrusion Detection must be constantly updated to account for changes in what constitutes normal traffic of a network and correctly identify attacks. This work evaluates two approaches concerning label availability to update the intrusion detection classifier. First, we analyze the impact of delayed labeling of samples on the classifiers' performance, and second, we evaluate the impact of using active learning strategies on the classifiers. Our experimental evaluation uses two datasets (CIC-IDS2017 and CSE-CIC-IDS2018) to compare different data stream classification algorithms under different evaluation measures. Based on comparison results, we studied different active learning techniques to estimate the impact of delayed labeling on packet-based IDS. We found that the performance of the classifiers is inversely proportional to the label delivery rate. Besides, the active learning strategies helped keep the performance compatible with the baselines, even with a small set of labeled instances.}
}


@article{DBLP:journals/compsec/GuoPDZZ23,
	author = {Taolin Guo and
                  Shunshun Peng and
                  Kai Dong and
                  You Zhao and
                  Mingliang Zhou},
	title = {{RDPCF:} Range-based differentially private user data perturbation
                  for collaborative filtering},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103452},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103452},
	doi = {10.1016/J.COSE.2023.103452},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GuoPDZZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative filtering recommends potentially interesting content to users based on historical data that it collects from users, which can lead to privacy breaches by untrusted servers. Differential privacy is a strict definition of privacy, and user privacy protection in collaborative filtering through differential privacy methods has drawn widespread attention from researchers. However, perturbing user data in collaborative filtering through existing differential privacy techniques will lead to the problem of poor recommendation accuracy. This is because differential privacy techniques generally perturb user data independently and will destroy the data similarity required by collaborative filtering. This paper proposes a differentially private user data perturbation method RDPCF, which perturbs the user data within a given content similarity range, and constrains the perturbation probability by differential privacy definition, thus ensuring both the accuracy of using the perturbation results for collaborative filtering and user privacy protection. Experimental results show that the RDPCF considerably outperforms the existing methods regarding privacy protection level and recommendation accuracy.}
}


@article{DBLP:journals/compsec/ShakedCBM23,
	author = {Avi Shaked and
                  Yulia Cherdantseva and
                  Pete Burnap and
                  Peter Maynard},
	title = {Operations-informed incident response playbooks},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103454},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103454},
	doi = {10.1016/J.COSE.2023.103454},
	timestamp = {Mon, 05 Feb 2024 07:40:04 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ShakedCBM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber security incident response playbooks are critical for establishing an effective incident response capability within organizations. We identify a significant conceptual gap in the current research and practice of cyber security playbook design: the lack of ability to communicate the operational impact of an incident and of incident response on an organization. In this paper, we present a mechanism to address the gap by introducing the operational context into an incident response playbook. This conceptual contribution calls for a shift from playbooks that consist only of process models to playbooks that consist of process models closely linked with a model of operations. We describe a novel approach to embed a model of operations into the incident response playbook and link it with the playbook's incident response activities. This allows to reflect, in an accurate and systematic way, the interdependencies and mutual influences of incident response activities on operations and vice versa. The approach includes the use of a new metric for evaluating the change in operations in coordination with critical thresholds, supporting decision-making during cyber security incident response. We demonstrate the application of the proposed approach to playbook design in the context of a ransomware attack incident response, using a newly developed open-source tool.}
}


@article{DBLP:journals/compsec/JinJWLJYZ23,
	author = {Xin Jin and
                  Xin Jin and
                  Ruxin Wang and
                  Shin{-}Jye Lee and
                  Qian Jiang and
                  Shaowen Yao and
                  Wei Zhou},
	title = {Adversarial attacks on multi-focus image fusion models},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103455},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103455},
	doi = {10.1016/J.COSE.2023.103455},
	timestamp = {Sun, 18 Feb 2024 17:03:32 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/JinJWLJYZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-focus image fusion aims to create an all-in-focus clear image by fusing a set of partially focused images. In recent years, various multi-focus image fusion methods based on deep learning have been proposed, but there is no thorough study evaluating their robustness for adversarial attacks. In this paper, we investigate the robustness of deep learning based multi-focus image fusion models to adversarial attacks. First, we generated adversarial examples which can significantly reduce the fusion quality of image fusion models. Then, a metric defocus attack intensity (DAI) was proposed to quantitatively evaluate the robustness of different models for adversarial attacks. At last, we analyzed the factors affecting model robustness, including model size and post-processing steps. Besides, we successfully attacked recent image fusion models in the black-box scene by utilizing the transferability of adversarial examples. Experimental results show that state-of-the-art image fusion models are also vulnerable to adversarial attacks, and some observations in image classifier robustness studies are not transferable to image fusion task.}
}


@article{DBLP:journals/compsec/NgwobiaRKK23,
	author = {Sunday Cosmos Ngwobia and
                  Anca L. Ralescu and
                  David Kapp and
                  Temesgen Kebede},
	title = {Detection of malicious {PE} files using synthesized {DNA} artifacts},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103457},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103457},
	doi = {10.1016/J.COSE.2023.103457},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NgwobiaRKK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The availability of sophisticated IT tools has provided computer system attackers with the capacity to develop dangerous metamorphic or polymorphic malware. Such malware presents behaviors similar to biological viruses enabling them to evade detection from conventional anti-malware methods. To circumvent this challenge, we carried out this research experiment to build and train machine learning models, and our proposed models achieved 99% & 99.6% accuracy in detecting and classifying PE-oriented malware. This excellent performance of our proposed models is undoubtedly a function of several factors but majorly on the synthesized DNA datasets (from our previous research works), which we used to train our proposed models. The synthesized DNA datasets are composed of salient features (dynamic and static) extracted from behaviors of nonmalicious programs (.exe, .dll, etc.) before and after infection by malware using reverse engineering and tracing tools. Then using a encoding algorithm and bioinformatics tools, we synthesized these features into a DNA-like representation (data sets) akin to the biological Deoxyribonucleic acid(DNA).}
}


@article{DBLP:journals/compsec/SharmaSC23,
	author = {Shreyansh Sharma and
                  Anil K. Saini and
                  Santanu Chaudhury},
	title = {A survey on biometric cryptosystems and their applications},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103458},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103458},
	doi = {10.1016/J.COSE.2023.103458},
	timestamp = {Tue, 24 Oct 2023 15:07:19 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SharmaSC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biometric systems (BSs) have shown prominent results in providing secure authentication protocols and a unique identification ecosystem for various applications. Over the years, plentiful research has been done to enhance the security of BSs. However, traditional BSs pose security & privacy concerns related to biometric templates, and the research community has been exploring cryptographic schemes to solve these issues. Particularly, Biometric Cryptosystems (BCSs) can address these concerns and enhance the protection of the biometric template. However, BCSs have several associated challenges which provide many research opportunities. Therefore, this survey focuses on BCS techniques and the various Cryptography schemes used to control the security & privacy issues of the biometric templates. We further investigate the potential security threats in BCS and report various attack vectors. We also present the performance analysis of different BCS schemes. Additionally, we explore the use of Blockchain technology for BCS to provide a robust system over a decentralized network. Based on the analysis and identified limitations, we explored the Decentralization of BCS, which aims to address the current challenges in BCS. We also report some potential use cases and future directions to use BCS in Web 3.0 applications built on Blockchain. Finally, we provide a summary of the most pressing issues that still need to be addressed in order to provide reliable privacy and robust security solutions for BCS.}
}


@article{DBLP:journals/compsec/RashidS23,
	author = {Aqib Rashid and
                  Jose M. Such},
	title = {StratDef: Strategic defense against adversarial attacks in ML-based
                  malware detection},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103459},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103459},
	doi = {10.1016/J.COSE.2023.103459},
	timestamp = {Mon, 05 Feb 2024 20:23:23 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/RashidS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the years, most research towards defenses against adversarial attacks on machine learning models has been in the image recognition domain. The ML-based malware detection domain has received less attention despite its importance. Moreover, most work exploring these defenses has focused on several methods but with no strategy when applying them. In this paper, we introduce StratDef, which is a strategic defense system based on a moving target defense approach. We overcome challenges related to the systematic construction, selection, and strategic use of models to maximize adversarial robustness. StratDef dynamically and strategically chooses the best models to increase the uncertainty for the attacker while minimizing critical aspects in the adversarial ML domain, like attack transferability. We provide the first comprehensive evaluation of defenses against adversarial attacks on machine learning for malware detection, where our threat model explores different levels of threat, attacker knowledge, capabilities, and attack intensities. We show that StratDef performs better than other defenses even when facing the peak adversarial threat. We also show that, of the existing defenses, only a few adversarially-trained models provide substantially better protection than just using vanilla models but are still outperformed by StratDef.}
}


@article{DBLP:journals/compsec/QinZP23,
	author = {Yingxin Qin and
                  Kejia Zhang and
                  Haiwei Pan},
	title = {Adversarial attack for object detectors under complex conditions},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103460},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103460},
	doi = {10.1016/J.COSE.2023.103460},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QinZP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, deep learning security has become a hot research topic, and attackers often use well-designed adversarial examples as input to trick the deep learning model, especially in object detection. Recently, the adversarial patch has been widely used in the attack of the object detector by adding a continuous region of noise to the image. However, current research on the adversarial patch for object detectors has certain limitations. The adversarial attack performance tends to degrade when certain regions of the adversarial patch are accidentally obscured. So the two-stage method based on Generative Adversarial Network (TS-GAN) is proposed to address this issue. To train the generator, the TS-GAN uses the occlusion rule to simulate various situations where patches are occluded in physical scenes. Then the generator's parameters are fixed, and the optimization method is adopted to select the latent variables to generate the most effective adversarial patches. The results of extensive experiments in the digital world and physical environments show that our method achieves stable attack performance under complex conditions which are different occlusion.}
}


@article{DBLP:journals/compsec/LeeKL23,
	author = {Jiyeon Lee and
                  Hyosu Kim and
                  Kilho Lee},
	title = {VRKeyLogger: Virtual keystroke inference attack via eavesdropping
                  controller usage pattern in WebVR},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103461},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103461},
	doi = {10.1016/J.COSE.2023.103461},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LeeKL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WebVR is an emerging technology that allows users to experience VR (Virtual Reality) through typical web browsers, providing an integrated environment for various VR applications. One important problem of the VR technology is how to securely interact with users, in particular, implementing secure text input. A promising approach is to use a virtual keyboard rendered as a VR object. The VR user can enter certain text by clicking a sequence of virtual keys through the VR controllers, and the input text is handled in a secure way. However, despite the sensitivity of the input text, we found that there is a critical vulnerability that the VR controllers are not properly protected. The VR controller status can be disclosed to malicious entities, imposing a severe threat that an attacker's website can infer the input text by eavesdropping and analyzing the VR controller's movements. To accurately infer the input, the attacker should address two challenges: 1) determining which clicks correspond to the virtual keyboard and 2) identifying which key is pressed. In this paper, we propose a new keystroke inference attack framework, VRKeyLogger, that addresses such challenges with two key components: key-click classifier and key-click identifier. The key-click classifier effectively distinguishes clicks on the virtual keyboard based on the SVM classifier trained by the major features of the VR controller uses. The key-click identifier then accurately identifies which key is pressed by transforming the clicked position into the local coordinate system of the virtual keyboard. We implemented a proof-of-concept prototype and conducted a user study with nine participants. In the extensive user study with three real-world WebVR applications, our VRKeyLogger results in classification and identification accuracy of 93.98 and 96.8% on average, respectively. This implies that the proposed attack poses a serious threat to WebVR security.}
}


@article{DBLP:journals/compsec/RibeiroFS23,
	author = {Marcos Aur{\'{e}}lio Ribeiro and
                  Mauro S{\'{e}}rgio Pereira Fonseca and
                  Juliana de Santi},
	title = {Detecting and mitigating DDoS attacks with moving target defense approach
                  based on automated flow classification in {SDN} networks},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103462},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103462},
	doi = {10.1016/J.COSE.2023.103462},
	timestamp = {Wed, 10 Apr 2024 10:43:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RibeiroFS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Distributed Denial of Service (DDoS) coordinates synchronized attacks on systems on the Internet using a set of infected hosts (bots). Bots are programmed to attack a determined target by firing a lot of synchronized requests, causing slowness or unavailability of the service. This type of attack has recently grown in magnitude, diversity, and economic cost. Thus, this paper presents a DDoS detection and mitigation architecture based on Software Defined Networking (SDN). It considers the Moving Target Defense (MTD) approach, redirecting malicious floods to expendable low-capacity servers to protect the main server while discouraging the attacker. The redirecting decision is based on a sensor, that employs Machine Learning (ML) algorithms for flow classification. When malicious flows are detected, the sensor notifies the SDN controller to include them in the malicious hosts lists and to realize the redirection. The validation and evaluation of the proposed architecture are conducted by simulation. Results considering different classification models (probabilistic, linear model, neural networks, and trees) and attack types indicate that the proposed architecture is efficient in detecting and mitigating DDoS attacks in approximately 3 seconds.}
}


@article{DBLP:journals/compsec/CaoSZQ23,
	author = {Wei Cao and
                  Wenting Shen and
                  Zhixiang Zhang and
                  Jing Qin},
	title = {Privacy-preserving healthcare monitoring for IoT devices under edge
                  computing},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103464},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103464},
	doi = {10.1016/J.COSE.2023.103464},
	timestamp = {Fri, 27 Oct 2023 20:40:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CaoSZQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of the Internet of Things (IoT) technology, e-healthcare has received extensive attention because it is able to provide real-time health status feedback for users. Due to the exponential growth of health data and the expensive cost of training the healthcare monitoring model, outsourcing the healthcare monitoring service to the edge servers becomes a popular way in e-healthcare. How to accomplish healthcare monitoring without leaking users' privacy to the edge servers is the key element of e-healthcare. In this paper, we propose a privacy-preserving healthcare monitoring framework based on long short-term memory (LSTM) neural network for IoT devices, which is performed on edge servers. In our framework, to reduce the computational burden, we outsource the complicated computations to the edge servers. To protect the privacy of health data and healthcare monitoring model, we design a series of secure interactive protocols based on replicated secret sharing and use three edge servers to collaboratively implement secure inference and model training for LSTM. We demonstrate the security of the proposed protocols and give the performance evaluation. Numerical experiments show that the proposed protocols are able to produce results with fine accuracy while requiring low computation and communication overheads.}
}


@article{DBLP:journals/compsec/FujsVV23,
	author = {Damjan Fujs and
                  Simon Vrhovec and
                  Damjan Vavpotic},
	title = {Balancing software and training requirements for information security},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103467},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103467},
	doi = {10.1016/J.COSE.2023.103467},
	timestamp = {Wed, 01 Nov 2023 08:59:33 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/FujsVV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information security is one of the key areas of consideration to assure reliable and dependable information systems (IS). Achieving an appropriate level of IS security requires concurrent consideration of the technical aspects of IS and the human aspects related to the end users of IS. These aspects can be described in the form of information security requirements. We propose an approach that helps select and balance information security software requirements (iSSR) and information security training requirements (iSTR) according to the information security performance of end users. The approach was tested in an experiment involving 128 IS professionals. The results showed that using the proposed approach helps IS professionals with limited experience in information security make significantly better decisions regarding iSSR and iSTR.}
}


@article{DBLP:journals/compsec/KitkowskaSMW23,
	author = {Agnieszka Kitkowska and
                  Yefim Shulman and
                  Leonardo A. Martucci and
                  Erik W{\"{a}}stlund},
	title = {Designing for privacy: Exploring the influence of affect and individual
                  characteristics on users' interactions with privacy policies},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103468},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103468},
	doi = {10.1016/J.COSE.2023.103468},
	timestamp = {Wed, 01 Nov 2023 08:59:33 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KitkowskaSMW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Consenting to digital services' privacy policies is standard practice. It often occurs at the early stage of interactions with a given service—during the sign-up process. Still, the most common way of acquiring consent from users is through their acknowledgment of policies by ticking a box. Consequently, users consent, mostly blindly, as they are unlikely to review the full text of policies. The current article presents research investigating factors that may impact user interaction with privacy policies, focusing on the underresearched topic of affective states (valence and arousal). The results of an online experiment (\nN\n=\n88\n) indicate that privacy policy design can elicit specific affective responses and, when accounting for some characteristics of individuals (e.g., personality traits), it can influence users' attitudes and behaviors. Particularly, the findings show that privacy awareness and willingness to disclose information might be impacted. Additionally, the analysis of collected data suggests significant associations between some personality traits and affective states, as well as a strong relationship between privacy concerns and willingness to disclose information, contradicting the concept of privacy paradox, often discussed in the privacy literature. Moreover, the results of our qualitative inquiry, where the study respondents had a chance to elaborate on their decisions to agree or disagree with the privacy policy by answering an open-ended question, confirm the quantitative findings, and reveal some of the users needs considering the sign-up process.}
}


@article{DBLP:journals/compsec/WuZYWZ23,
	author = {Bolun Wu and
                  Futai Zou and
                  Ping Yi and
                  Yue Wu and
                  Liang Zhang},
	title = {SlicedLocator: Code vulnerability locator based on sliced dependence
                  graph},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103469},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103469},
	doi = {10.1016/J.COSE.2023.103469},
	timestamp = {Fri, 27 Oct 2023 20:40:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WuZYWZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning-based fine-grained vulnerability detection is an important technique for locating vulnerable statements, which assists engineers in efficiently analyzing and fixing the vulnerabilities. However, due to insufficient code representations, code embeddings, and neural network design, current methods suffer low vulnerability localization performance. In this paper, we propose to address these shortcomings by presenting SlicedLocator, a novel fine-grained code vulnerability detection model that is trained in a dual-grained manner and can predict both program-level and statement-level vulnerabilities. We design the sliced dependence graph, a new code representation that not only preserves rich interprocedural relations but also eliminates vulnerability-irrelevant statements. We create attention-based code embedding networks that are trained with the entire model to extract vulnerability-aware code features. In addition, we present a new LSTM-GNN model as a fusion of semantic modeling and structural modeling. Experiment results on a large-scale C/C++ vulnerability dataset reveal that SlicedLocator outperforms state-of-the-art machine learning-based vulnerability detectors, especially in terms of localization metrics.}
}


@article{DBLP:journals/compsec/AlhelalyDO23,
	author = {Yasser Alhelaly and
                  Gurpreet Dhillon and
                  Tiago Oliveira},
	title = {When expectation fails and motivation prevails: the mediating role
                  of awareness in bridging the expectancy-capability gap in mobile identity
                  protection},
	journal = {Comput. Secur.},
	volume = {134},
	pages = {103470},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103470},
	doi = {10.1016/J.COSE.2023.103470},
	timestamp = {Mon, 05 Feb 2024 20:23:22 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/AlhelalyDO23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identity theft poses a significant threat to mobile users, yet mobile identity protection is often overlooked in cybersecurity literature. Despite various technical solutions proposed, little attention has been given to the motivational aspects of protection. Moreover, the disparity between individuals' expectations and their ability to safeguard their mobile identities exacerbates the problem. This study adopts a mixed-methods approach and draws on expectancy-value theory to address these gaps and explore the impact of expectations, capabilities, motivational values, technical measures, and awareness on individuals' intentions to achieve mobile identity protection. Our research reveals that protection awareness acts as a crucial mediator between individuals' expectations and capabilities. Additionally, motivational values not only enhance technical protection measures but also significantly influence identity protection intentions. Furthermore, we identify the moderating effect of protection experience on individuals' expectations and perceived value of identity protection. This study contributes to mobile security literature by highlighting the pivotal role of protection awareness in bridging the divide between individual expectations and actual capabilities in mobile identity protection.}
}
