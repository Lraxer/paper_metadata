@article{DBLP:journals/compsec/SrijayanthiS23,
	author = {S. Srijayanthi and
                  T. Sethukarasi},
	title = {Design of privacy preserving model based on clustering involved anonymization
                  along with feature selection},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103027},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103027},
	doi = {10.1016/J.COSE.2022.103027},
	timestamp = {Sun, 19 Mar 2023 00:07:21 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/SrijayanthiS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Healthcare services has become a hug transformation due to the number of disease emerging at presently. Accordingly, enormous amount of data is generated regarding on the patient data. Hence, preserving privacy of patient data is the major concern to meet privacy requirements and to prevent healthcare data from numerous privacy attacks. To protect the information from privacy attack, various studies were performed to safeguard the patient's data but, these methods have several issues when preserving privacy that increases proportionally as the data dimension increased in multiple approaches, which produces less data quality, more information loss and more execution time.Thus, selecting relevant attributes plays an important factor for improving the efficiency of any preserving algorithm. In order to overcome these concerns, in this paper proposed a privacy preserving model based on clustering involved anonymization along with feature selection approaches. The proposed model consist of two phases such as, feature selection and anonymization. In the initial phase, the relevant features are selected using Symmetrical Uncertainty (SU) and the redundant features present in the dataset are removed utilizing Spearman's Correlation Coefficient. In the second phase, the privacy preservation is performed using Utility Preserved Anonymization (UPA) algorithm. Also, the proposed algorithm reduces the dimensionality of data to ease the process of forming clusters for anonymization. The experimental analysis using real time datasets to verifies the effectiveness of the proposed method. The results show high sensitivity (up to 98.63%) and high accuracy (up to 98%), allowing us to claim efficient attribute selection for anonymization. Hence proved the proposed method reduces clustering's complexity by removing the irrelevant attributes effectively.}
}


@article{DBLP:journals/compsec/ChenHZXZ23,
	author = {Jinyin Chen and
                  Shulong Hu and
                  Haibin Zheng and
                  Chang{-}you Xing and
                  Guomin Zhang},
	title = {{GAIL-PT:} An intelligent penetration testing framework with generative
                  adversarial imitation learning},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103055},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103055},
	doi = {10.1016/J.COSE.2022.103055},
	timestamp = {Tue, 28 Mar 2023 19:51:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenHZXZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Penetration testing (PT) is an efficient tool for network testing and vulnerability mining by simulating the hackers’ attacks to obtain valuable information applied in operating and database systems. Most of the traditional manual solutions are strongly relying on the domain knowledge of human experts with high penetration costs. Therefore, solutions based on the artificial intelligent algorithm such as reinforcement learning (RL) and deep reinforcement learning (DRL), with less time-consuming and lower labor costs, become a great solution to address the challenge. However, there are still a few challenges for RL/DRL-based PT in real penetration scenarios, such as the large dimension size of the agent’s discrete action space usually causing difficulties in convergence. To address the above issue, this paper proposes a novel framework named Generative Adversarial Imitation Learning based intelligent Penetration Testing (GAIL-PT), which utilizes expert knowledge base and GAIL network to guide the policy generation of RL/DRL agents with lower costs. Specifically, we first construct the expert knowledge bases by collecting state-action pairs from the successful exploitations of pre-trained RL/DRL models. Secondly, we feed the expert knowledge bases generated by different RL/DRL models online into the discriminator of GAIL-PT to guide its training process. Besides, we integrate the losses of the generator and the discriminator in GAIL-PT to optimize the overall objective and use the discriminator’s discounted rewards for policy generation. The extensive experiments conducted on the practical target hosts and simulated network scenarios demonstrate that GAIL-PT achieves outstanding performance, and outperforms the state-of-art method DeepExploit in exploiting Metasploitable2 and Q-learning in different scale networks. It also verified that GAIL-PT is a general leading framework suitable for RL/DRL-based methods. The code of GAIL-PT is open-sourced at\nhttps://github.com/Shulong98/GAIL-PT//\n.}
}


@article{DBLP:journals/compsec/KwonN23,
	author = {Hyun Kwon and
                  Seung{-}Hun Nam},
	title = {Audio adversarial detection through classification score on speech
                  recognition systems},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103061},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103061},
	doi = {10.1016/J.COSE.2022.103061},
	timestamp = {Tue, 21 Mar 2023 21:08:32 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KwonN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) provide effective performance for many computer vision problems. However, DNNs are vulnerable to adversarial examples, generated by adding an imperceptible noise to a normal sample. To address this problem, we propose a method of defense that detects audio adversarial examples without the need for a separate module or process. When adversarial examples are generated, there will be a pattern in the classification scores between the incorrect class and the normal class, which arises because there is a point at which misclassification of the normal data is induced using the minimal amount of distortion. The proposed method uses this characteristic of the classification scores to detect audio adversarial examples. For testing, Mozilla test data and LibriSpeech test data were used as experimental test data, and a DeepSpeech model was used as the speech recognition model. In addition, as the experimental environment, a limited environment without noise in the process of voice transmission was assumed. The experimental results show that the proposed method can detect audio adversarial examples with a detection rate of 91% and 93% (Mozilla voice dataset and LibriSpeech dataset) while reducing the error rate on normal samples to 8% and 7% (Mozilla voice dataset and LibriSpeech dataset). A comparison of the proposed method with three state-of-the-art defense methods shows that the proposed method had a high detection rate on the demonstrably advanced white-box adversarial examples.}
}


@article{DBLP:journals/compsec/FasciFLQ23,
	author = {Lara Saidia Fasc{\`{\i}} and
                  Marco Fisichella and
                  Gianluca Lax and
                  Chenyin Qian},
	title = {Disarming visualization-based approaches in malware detection systems},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103062},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103062},
	doi = {10.1016/J.COSE.2022.103062},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/FasciFLQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visualization-based approaches have recently been used in conjunction with signature-based techniques to detect variants of malware files. Indeed, it is sufficient to modify some byte of executable files to modify the signature and, thus, to elude a signature-based detector. In this paper, we design a GAN-based architecture that allows an attacker to generate variants of a malware in which the malware patterns found by visualization-based approaches are hidden, thus producing a new version of the malware that is not detected by both signature-based and visualization-based techniques. The experiments carried out on a well-known malware dataset show a success rate of 100% in generating new variants of malware files that are not detected from the state-of-the-art visualization-based technique.}
}


@article{DBLP:journals/compsec/BojarajuluTS23,
	author = {Balaganesh Bojarajulu and
                  Sarvesh Tanwar and
                  Thipendra Pal Singh},
	title = {Intelligent IoT-BOTNET attack detection model with optimized hybrid
                  classification model},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103064},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103064},
	doi = {10.1016/J.COSE.2022.103064},
	timestamp = {Sun, 12 Nov 2023 02:17:58 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/BojarajuluTS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The botnet have developed into a severe risk to Internet of Things (IoT) systems as a result of manufacturers ‘insufficient security policies and end users’ lack of security awareness. By default, several ports are open and user credentials are left unmodified. ML and DL strategies have been suggested in numerous latest research for identifying and categorising botnet assaults in the IoT context, but still, it has a few issues like high error susceptibility, working only with a large amount of data, poor quality, and data acquisition. This research provided use of a brand-new IoT botnet detector built on an improved hybrid classifier. The proposed work\'s main components are "pre-processing, feature extraction, feature selection, and attack detection." Following that, the improved Information Gain (IIG) model is used to choose the most reliable characteristics from the received information. To detect an attack, a hybrid classifier is utilized which can be constructed by integrating the optimized Bi-GRU with the Recurrent Neural Network (RNN). To increase the detection accuracy of IoT-BOTNETS, a novel hybrid optimization approach called SMIE (Slime Mould with Immunity Evolution) is created by conceptually integrating two conventional optimization modes: Coronavirus herd immunity optimizer (CHIO) and the Slime mould algorithm. The final output of the hybrid classifier displays the presence or absence of IoT-BOTNET attacks. The projected model\'s accuracy is 97%, which is 22.6%, 18.5%, 27.8%, 22.6%, and 24.8% higher than the previous models like GWO+ HC, SSO+ HC, WOA+ HC, SMA+ HC, and CHIO+ HC, respectively.}
}


@article{DBLP:journals/compsec/AlacaC23,
	author = {Yusuf Alaca and
                  Y{\"{u}}ksel {\c{C}}elik},
	title = {Cyber attack detection with {QR} code images using lightweight deep
                  learning models},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103065},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103065},
	doi = {10.1016/J.COSE.2022.103065},
	timestamp = {Tue, 28 Mar 2023 19:51:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AlacaC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As information technologies evolve rapidly, servers are being attacked by cyberattacks due to their high values such as cloud, IoT, mobile and desktop applications. Therefore, cyber-attacks have caused great concern in many areas. Although intrusion detection systems play an important role in cyber security, it has become an important data analysis object because it consists of complex system operating data. Traditional intrusion detection systems detect cyber attacks by recording previously detected attacks and comparing them with new attacks or looking for system anomalies. Intrusion detection data is huge, attack types are diverse, and due to the development of hacking skills, traditional detection methods are inefficient. In recent years, many intrusion detection mechanisms, especially machine learning and deep learning, have been proposed to improve traditional intrusion detection technology. In this study, we propose a multi-objective optimization-based hybrid method that enables the use of the most convenient features of light deep learning models in detecting cyber attacks. First, QR code images of bulky data with multiple classes were created. Then, QR code images were trained using MobileNetV2 and ShuffleNet CNN models. Deep CNN models and features of the trained images were extracted, and Harris Hawk Optimization (HHO) algorithm was used to select the most effective features for classification purposes. As a result, as a result of the classification of the selected features with the proposed hybrid model HHO, attack types were detected with an accuracy rate of 95.89%, and it provided superior performance compared to CNN models.}
}


@article{DBLP:journals/compsec/AlSlaimanSSW23,
	author = {Muhanned AlSlaiman and
                  Mohammed I. Salman and
                  Mariam M. Saleh and
                  Bin Wang},
	title = {Enhancing false negative and positive rates for efficient insider
                  threat detection},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103066},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103066},
	doi = {10.1016/J.COSE.2022.103066},
	timestamp = {Wed, 21 Jun 2023 21:04:56 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AlSlaimanSSW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Insider threats on information security can become a burden for organizations. However, outsider attacks have received more attention compared to insider attacks. Many researchers studied insider threats and proposed various approaches (such as signature based, machine learning based, and deep learning based) to alleviate this type of threats. In this work, we present a novel insider threat detection system based on a deep learning network of Long Short Term Memory (LSTM). The developed detection system aims to analyze and mitigate the negative effect of insiders by differentiating benign activities from malicious ones. The detection system utilizes sentiment analysis to classify the users’ activities and gray encoding to maintain temporal behavior between activities (especially correlated activities). This allows us to reform a dataset in which each row represents a variable length sample to train a deep learning based detection system. Different data representations, such as binary encoding (BE), real-valued data, without encoding (WE), were used to test the effectiveness of gray encoding in maintaining the temporal relationships between activities. The proposed detection techniques were evaluated using log files from CERT r4.2 insiders’ dataset that represent activities of employees for eighteen working months. The evaluation results have shown enhanced false positive of 0.29%, false negative of 2.47% and an AUC value of 97%.}
}


@article{DBLP:journals/compsec/HeidingSOL23,
	author = {Fredrik Heiding and
                  Emre S{\"{u}}ren and
                  Johannes Oleg{\aa}rd and
                  Robert Lagerstr{\"{o}}m},
	title = {Penetration testing of connected households},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103067},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103067},
	doi = {10.1016/J.COSE.2022.103067},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HeidingSOL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Connected devices have become an integral part of modern homes and household devices, such as vacuum cleaners and refrigerators, are now often connected to networks. This connectivity introduces an entry point for cyber attackers. The plethora of successful cyber attacks against household IoT indicates that the security of these devices, or the security of applications related to these devices, is often lacking. Existing penetration testing studies usually focus on individual devices, and recent studies often mention the need for more extensive vulnerability assessments. Therefore, this study investigates the cyber security of devices commonly located in connected homes. Systematic penetration tests were conducted on 22 devices in five categories related to connected homes: smart door locks, smart cameras, smart car adapters/garages, smart appliances, and miscellaneous smart home devices. In total, 17 vulnerabilities were discovered and published as new CVEs. Some CVEs received critical severity rankings from the National Vulnerability Database (NVD), reaching 9.8/10. The devices are already being sold and used worldwide, and the discovered vulnerabilities could lead to severe consequences for residents, such as an attacker gaining physical access to the house. In addition to the published CVEs, 52 weaknesses were discovered that could potentially lead to new CVEs in the future. To our knowledge, this is the most comprehensive study on penetration testing of connected household products.}
}


@article{DBLP:journals/compsec/ChengYLSS23,
	author = {Yiran Cheng and
                  Shouguo Yang and
                  Zhe Lang and
                  Zhiqiang Shi and
                  Limin Sun},
	title = {{VERI:} {A} Large-scale Open-Source Components Vulnerability Detection
                  in IoT Firmware},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103068},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103068},
	doi = {10.1016/J.COSE.2022.103068},
	timestamp = {Wed, 12 Jun 2024 21:04:42 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChengYLSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT device manufacturers integrate open-source components (OSCs) to serve necessary and common functions for facilitating firmware development. However, outdated versions of OSC conceal N-day vulnerabilities and continue to function on IoT devices. The security risks can be predicted once we can identify the OSC versions employed in the firmware. Existing works make attempts at OSC version identification but fail to perform vulnerability detection on a large-scale IoT firmware due to i) unsuitable version identification method for IoT firmware scenario. ii) the lack of a large-scale version-vulnerability relation database. To this end, we propose a system VERI for large-scale vulnerability detection based on lightweight version identification. First, for OSC version identification, VERI leverages symbolic execution with static analysis to identify exact OSC versions even though there are many version-like strings in OSC. Second, VERI employs a deep learning-based method to extract OSC names and vulnerable version ranges from vulnerability descriptions, constructs and maintains an OSC version-vulnerability relation database to serve the vulnerability detection. Finally, VERI polls the relation database to confirm the N-day security risk of the OSC with identified version. The evaluation results show that VERI achieves 96.43% accuracy with high efficiency in OSC version identification. Meanwhile, the deep learning model accurately extracts the OSC names and versions from vulnerability descriptions dataset with 97.19% precision and 96.56% recall. Based on the model, we build a large-scale version-vulnerability relation database. Furthermore, we utilize VERI to conduct a large-scale analysis on 28,890 firmware and find 38,654 vulnerable OSCs with 266,109 N-day vulnerabilities, most of which are with high risks. From the detection results, we find that after the official patch for the vulnerability is released, manufacturers delay an average of 473 days to patch the firmware.}
}


@article{DBLP:journals/compsec/OfteK23,
	author = {H{\aa}vard Jakobsen Ofte and
                  Sokratis K. Katsikas},
	title = {Understanding situation awareness in SOCs, a systematic literature
                  review},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103069},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103069},
	doi = {10.1016/J.COSE.2022.103069},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/OfteK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Situation awareness is shown through human factors research to be a valuable construct to understand and improve how humans perform while operating complex systems in critical environments. Within cyber security one such environment is the Security Operations Center (SOC). With the increasing threat of hybrid warfare, knowledge about situation awareness within SOC environments, where human error or low performance may be detrimental, must be developed. This paper reports on the results of a Systematic Descriptive Literature Review of the current research on situation awareness within SOCs. The goal of the paper is to analyze how situation awareness is understood in the current research. To achieve this goal three aspects of understanding were addressed: Theoretical foundations; levels of conceptualization; and measurement of situation awareness. Theoretical foundations in the literature were assessed by how situation awareness was defined and the presence of references to theoretical models of SA. The results show a clear trend of basing the research on Endsley's three level situation awareness model; this model has been developed into a domain specific formulation called “Cyber Situation Awareness”. Some parts of the literature, particularly in research aimed at developing tools for improving situation awareness, lack a theoretical foundation; some refer to alternative theoretical foundations of situation awareness like Stanton et al.’s Distributed Situation Awareness. Further, a balance between conceptualizations on the individual, group and system level has been identified. Within research aimed at developing tools for improving situation awareness there are some examples of specialized and precise measurements of situation awareness, but in general the research seems too reliant on indirect measures of situation awareness. The paper concludes with the proposition of connecting the systems-based theoretical perspective of distributed situation awareness into the research, utilizing a systems level conceptualization of situation awareness. This might prove to be a useful bridge between the human cognitive perspective of situation awareness and the development of the complex technical environment of critical importance that SOCs represent.}
}


@article{DBLP:journals/compsec/WangGRZ23,
	author = {Qian Wang and
                  Yuying Gao and
                  Jiadong Ren and
                  Bing Zhang},
	title = {An automatic classification algorithm for software vulnerability based
                  on weighted word vector and fusion neural network},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103070},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103070},
	doi = {10.1016/J.COSE.2022.103070},
	timestamp = {Thu, 31 Aug 2023 16:23:36 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangGRZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To address the problem that the traditional vectored representation of software vulnerability data has high-dimensional sparsity and leads to unsatisfactory automatic classification, this paper proposes an automatic classification algorithm for software vulnerabilities based on weighted word vectors and fusion neural network. Firstly, the Term Frequency-Inverse Document Frequency (TF-IDF) algorithm is improved to generate the weighted word vector with low dimension and density according to the category distribution. Secondly, the vulnerability classification model TCNN-BiGRU consists of TextCNN (TCNN) and Bidirectional GRU (BiGRU) is constructed, which has made full use of the advantages of convolutional neural network (CNN) and gate recurrent unit neural network (GRU). TextCNN is used to extract local features of vulnerability description text, BiGRU is used to extract global features of vulnerability description text, and the output feature vectors are fused to achieve dimensionality reduction. Finally, the Dropout method and Early Stopping method are introduced to suppress overfitting, and a Softmax classifier is used to classify the vulnerability category. The classification performance of the proposed algorithm is verified by ablation experiments, sparsity problem expriments and comparative experiments on the vulnerability data from NVD dataset on the indicators of accuracy, macro precision rate, macro recall rate and macro F1-score.}
}


@article{DBLP:journals/compsec/SchyffF23,
	author = {Karl van der Schyff and
                  Stephen Flowerday},
	title = {The mediating role of perceived risks and benefits when self-disclosing:
                  {A} study of social media trust and FoMO},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103071},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103071},
	doi = {10.1016/J.COSE.2022.103071},
	timestamp = {Wed, 21 Jun 2023 21:04:56 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SchyffF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-disclosure as influenced by perceived risks and benefits plays an important role within the context of social media use and the associated privacy risk. Some social media platforms, like Facebook (now part of Meta Platforms Inc.), provide users with elaborate means to control privacy risk. Conversely, Instagram (also part of Meta) provides users with fewer such mechanisms as a function of self-disclosure. Therefore, self-disclosure as a product of risk and benefit assessment may differ considerably as a function of the technological affordances that control such disclosure. This is particularly the case considering that such a benefit and risk assessment is further influenced by a user's trust in that provider, not to mention their proclivity for disclosing without any rational risk and benefit assessments, as is the case when disclosing as a function of fear of missing out (FoMO). Given the influence that provider trust and FoMO might have when assessing risks and benefits, this study evaluated the extent to which perceived risks and benefits mediate self-disclosure on Facebook and Instagram, in particular within the context of provider trust and FoMO. Based on an adapted version of privacy calculus, we evaluated our research model by analyzing 720 survey responses using partial least squares path modeling. Our results indicate that perceived benefits mediate the relationship between FoMO and intention to self-disclose when using Instagram, but not when using Facebook. Additionally, we found perceived benefits and perceived risks to mediate the relationship between trust in provider and intention to self-disclose for Facebook and Instagram. Surprisingly, we found no evidence to suggest that the relationship between FoMO and intention to self-disclose is mediated by perceived risks when using Facebook, with the converse being true when using Instagram. We conclude that the transitory (ephemeral) nature of some methods of self-disclosure on Instagram are used as a means to mitigate privacy risks.}
}


@article{DBLP:journals/compsec/MiculanV23,
	author = {Marino Miculan and
                  Nicola Vitacolonna},
	title = {Automated verification of Telegram's MTProto 2.0 in the symbolic model},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103072},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103072},
	doi = {10.1016/J.COSE.2022.103072},
	timestamp = {Tue, 21 Mar 2023 21:08:31 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MiculanV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {MTProto 2.0 is the suite of security protocols for instant messaging at the core of the popular Telegram messenger application. In this paper we analyse MTProto 2.0 using ProVerif, a state-of-the-art symbolic security protocol verifier based on the Dolev–Yao model. We provide the first formal symbolic model of MTProto 2.0; in this model, we provide fully automated proofs of the soundness of authentication, normal chat, end-to-end encrypted chat, and rekeying mechanisms with respect to several security properties, including authentication, integrity, secrecy and perfect forward secrecy. At the same time, we discover that the rekeying protocol is vulnerable to an unknown key-share (UKS) attack. To achieve these results, we proceed in an incremental way: each protocol is examined in isolation, relying only on the guarantees provided by the previous ones and the robustness of the basic cryptographic primitives. The importance of this research is threefold. First, it proves the formal correctness of MTProto 2.0 with respect to most relevant security properties. Secondly, we isolate the aspects of cryptographic primitives that escape the symbolic model and thus require further investigation in the computational model. Finally, our modelisation can serve as a reference for the implementation and analysis of clients and servers.}
}


@article{DBLP:journals/compsec/MeidanBBAS23,
	author = {Yair Meidan and
                  Daniel Benatar and
                  Ron Bitton and
                  Dan Avraham and
                  Asaf Shabtai},
	title = {D-Score: An expert-based method for assessing the detectability of
                  IoT-related cyber-attacks},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103073},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103073},
	doi = {10.1016/J.COSE.2022.103073},
	timestamp = {Tue, 21 Mar 2023 21:08:32 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MeidanBBAS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices are known to be vulnerable to various cyber-attacks, such as data exfiltration and the execution of flooding attacks as part of a DDoS attack. When it comes to detecting such attacks using network traffic analysis, it has been shown that some attack scenarios are not always equally easy to detect if they involve different IoT models. That is, when targeted at some IoT models, a given attack can be detected rather accurately, while when targeted at others the same attack may result in too many false alarms. In this research, we attempt to explain this variability of IoT attack detectability and devise a risk assessment method capable of addressing a key question: how easy is it for an anomaly-based network intrusion detection system to detect a given cyber-attack involving a specific IoT model? In the process of addressing this question we (a) investigate the predictability of IoT network traffic, (b) present a novel taxonomy for IoT attack detection which also encapsulates traffic predictability aspects, (c) propose an expert-based attack detectability estimation method which uses this taxonomy to derive a detectability score (termed ‘D-Score’) for a given combination of IoT model and attack scenario, and (d) empirically evaluate our method while comparing it with a data-driven method.}
}


@article{DBLP:journals/compsec/Zenitani23,
	author = {Kengo Zenitani},
	title = {Attack graph analysis: An explanatory guide},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103081},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103081},
	doi = {10.1016/J.COSE.2022.103081},
	timestamp = {Tue, 21 Mar 2023 21:08:33 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/Zenitani23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attack graph analysis is a model-based approach for network-security analysis. It analyzes a directed graph called an attack graph. Usually, each node in it corresponds to a malicious event caused by attackers, and the edges correspond to the causal relations between events. We can obtain an attack graph from the network topology, its configuration, and the distribution of vulnerabilities. An attack graph gives us various information relevant to network security. Also, there are several relevant algorithms to find desirable security controls applicable to the network. Over twenty years of research have made much progress in this field. However, it comprises a breadth of definitions and discussions, and it is difficult for people new to this field to comprehend the key ideas. This article aims to briefly introduce this method to prospective researchers by summarizing their progress by selecting and reviewing foundational studies. We elaborate on the essential concepts, such as exploit dependency, AND/OR graph, monotonicity, and cycle handling.}
}


@article{DBLP:journals/compsec/LuoLL23,
	author = {Shiyao Luo and
                  Yingxu Lai and
                  Jing Liu},
	title = {Selective forwarding attack detection and network recovery mechanism
                  based on cloud-edge cooperation in software-defined wireless sensor
                  network},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103083},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103083},
	doi = {10.1016/J.COSE.2022.103083},
	timestamp = {Tue, 21 Mar 2023 21:08:32 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LuoLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A software-defined wireless sensor network can dynamically configure the nodes in a network according to the demand of the application layer. In practical applications, such as environmental monitoring, the nodes in a wireless sensor network(WSN) are deployed in the field environment on a large scale, and the data rely on multihop transmission to reach the sink node. The data extremely easy to selective forwarding attacks during data transmission. Therefore, this study analyzes the models of selective forwarding attacks and proposes an abnormal node detection method, which includes a node behavior measurement scheme and trust-value evaluation mechanism. In addition, the application of a software-defined network (SDN) presents increasing network delay. Hence, herein a network recovery mechanism was designed based on cloud-edge cooperation to ensure the rapid recovery of the network after identifying the abnormal nodes. Moreover, experiments were conducted using simulation software and actual hardware. We verified the effectiveness of the proposed scheme. The experimental results revealed that the proposed method can effectively identify abnormal nodes, reduce the packet dropping ratio and shorten the network recovery delay by 77.2%. The research in this paper solves the security problem of SDWSN.}
}


@article{DBLP:journals/compsec/DengGSCP23,
	author = {Huaxin Deng and
                  Chun Guo and
                  Guowei Shen and
                  Yunhe Cui and
                  Yuan Ping},
	title = {{MCTVD:} {A} malware classification method based on three-channel
                  visualization and deep learning},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103084},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103084},
	doi = {10.1016/J.COSE.2022.103084},
	timestamp = {Tue, 28 Mar 2023 19:51:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/DengGSCP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid increase in the number of malware, the detection and classification of malware have become more challenging. In recent years, many malware classification methods based on malware visualization and deep learning have been proposed. However, the malware images generated by these methods do not retain the semantic and statistical properties with a small and uniform size. This article gives definitions of extracted content and filling mode to characterize the critical factors for the malware visualization task and proposes a new malware visualization method based on assembly instructions and Markov transfer matrices to characterize malware. Thus, a malware classification method based on three-channel visualization and deep learning (MCTVD) is proposed. In MCTVD, its malware image has a small and uniform size, and its convolutional neural network has few convolutional and pooling layers. Experimental results show that MCTVD can achieve an accuracy of 99.44% on Microsoft’s public malware dataset under 10-fold cross-validation and thus could be a highly competitive candidate for malware classification.}
}


@article{DBLP:journals/compsec/NayfehLSDK23,
	author = {Mohammad Nayfeh and
                  Yuchen Li and
                  Khair Al Shamaileh and
                  Vijay Kumar Devabhaktuni and
                  Naima Kaabouch},
	title = {Machine Learning Modeling of {GPS} Features with Applications to {UAV}
                  Location Spoofing Detection and Classification},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103085},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103085},
	doi = {10.1016/J.COSE.2022.103085},
	timestamp = {Thu, 17 Aug 2023 08:27:52 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NayfehLSDK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, machine learning (ML) modeling is proposed for the detection and classification of global positioning system (GPS) spoofing in unmanned aerial vehicles (UAVs). Three testing scenarios are implemented in an outdoor yet controlled setup to investigate static and dynamic attacks. In these scenarios, authentic sets of GPS signal features are collected, followed by other sets obtained while the UAV is under spoofing attacks launched with a software-defined radio (SDR) transceiver module. All sets are standardized, analyzed for correlation, and reduced according to feature importance prior to their exploitation in training, validating, and testing different multiclass ML classifiers. The resulting performance evaluation of these classifiers shows a detection rate (DR), misdetection rate (MDR), and false alarm rate (FAR) better than 92%, 13%, and 4%, respectively, together with a sub-millisecond detection time. Hence, the proposed modeling facilitates accurate real-time GPS spoofing detection and classification for UAV applications.}
}


@article{DBLP:journals/compsec/LiuL23,
	author = {Xiaojian Liu and
                  Kehong Liu},
	title = {A permission-carrying security policy and static enforcement for information
                  flows in Android programs},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103090},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103090},
	doi = {10.1016/J.COSE.2022.103090},
	timestamp = {Tue, 21 Mar 2023 21:08:32 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiuL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To detect information leaks in Android programs, existing taint analysis approaches usually specify and enforce (statically or dynamically) the two-level information flow policy, represented by a lattice\n(\n{\n⊤\n,\n⊥\n}\n,\n⊑\n)\nwith\n⊥\n⊑\n⊤\n. However, this policy leaves permissions (an access control mechanism built in the Android system) out of consideration, causing a too coarse-grained analysis result in some scenarios. In fact, the existing information flow controls should integrate permissions to develop a more refined flow policy. Following this intuition, in this paper, we propose a permission-carrying secure information flow policy and accomplish a static enforcement mechanism for this policy. We first devise a small language to capture typical features of Android programs. On this base, we define the permission-carrying security policy using a subset lattice of permissions, and offer a group of rules to certify the security of information flows. Secondly, we implement a static enforcement mechanism for this policy, which allows us to detect potential insecure information flows by analysing programs in component-level. To illustrate the usefulness of this policy, we further examine two typical security threats, confused deputy and collusive data leaks, as the running cases to show how to detect security attacks in our theoretical framework. The final experiment shows that our approach is effective and scalable for real-world apps. Compare with several leading tools, our approach is applicable to checking both intra-app and inter-app vulnerabilities, and achieves a more precise detection result due to the superiority of our fine-grained security policy.}
}


@article{DBLP:journals/compsec/ParkJL23,
	author = {Sung Bum Park and
                  Hyo Jin Jo and
                  Dong Hoon Lee},
	title = {Flooding attack mitigator for in-vehicle {CAN} using fault confinement
                  in {CAN} protocol},
	journal = {Comput. Secur.},
	volume = {126},
	pages = {103091},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103091},
	doi = {10.1016/J.COSE.2023.103091},
	timestamp = {Tue, 28 Mar 2023 19:51:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ParkJL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For driver convenience and safety, a number of electronic control units (ECUs) have been installed on modern vehicles. To support communications among ECUs, the controller area network (CAN) is commonly used as in-vehicle network for several decades. However, the CAN protocol lacks security mechanisms, which means that it can be damaged by a number of cyber attacks. In particular, message flooding is one type of DoS attack known to be the easiest to perform because it continuously broadcasts a large number of CAN messages to the in-vehicle CAN without any CAN traffic analysis. To handle message flooding on the in-vehicle CAN, several countermeasures including intrusion detection and prevention have been studied, but unfortunately, these solutions could produce false positive detection rates or cause the communication failures of benign ECUs. In this paper, we introduce a message flooding attack mitigation method for the first time that does not accidentally cause the communication failures of benign ECUs. The proposed method can mitigate flooding attack attempts by using the fault confinement rule that is defined in the CAN protocol. Since the proposed method does not violate the rules of the CAN standard during mitigating, no system modifications are required. Experimental results show that the proposed mitigator guarantees a transmission rate up to 79.22% of normal messages that were not sent due to a flooding attack.}
}
