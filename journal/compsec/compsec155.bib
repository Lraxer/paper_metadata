@article{DBLP:journals/compsec/ZhangCLLO25,
	author = {Bonan Zhang and
                  Chao Chen and
                  Ickjai Lee and
                  Kyungmi Lee and
                  Kok{-}Leong Ong},
	title = {A survey on security and privacy issues in wearable health monitoring
                  devices},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104453},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104453},
	doi = {10.1016/J.COSE.2025.104453},
	timestamp = {Fri, 09 May 2025 20:27:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangCLLO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent developments in mobile computing power and  wireless communication  speeds have significantly improved the efficiency of medical systems. This paper focuses on passive  wearable sensor  devices, which are integral to noninvasive monitoring of physiological data in healthcare observation. Beyond data collection, some wearables play an active role  in patient treatment , underscoring the critical importance of protecting their security and privacy. Breach in these areas can severely affect  patient health . However, the distinctive characteristics of  wearable technologies  introduce unique security and privacy challenges, including the potential for unauthorized access to sensitive location, medical, and physiological data. This review delves into the security and privacy concerns associated with wearable devices and proposes potential remedies. Its value lies in providing insights for researchers and manufacturers, aiming to advance the development of safer and more effective wearable medical technologies.}
}


@article{DBLP:journals/compsec/SkandylasA25,
	author = {Charilaos Skandylas and
                  Mikael Asplund},
	title = {Automated penetration testing: Formalization and realization},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104454},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104454},
	doi = {10.1016/J.COSE.2025.104454},
	timestamp = {Thu, 01 May 2025 20:32:43 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SkandylasA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent changes in  standards and regulations , driven by the increasing importance of software systems in meeting societal needs, mandate increased security testing of software systems.  Penetration testing  has been shown to be a reliable method to asses software system security. However, manual penetration testing is labor-intensive and requires highly skilled practitioners. Given the shortage of cybersecurity experts and current societal needs, increasing the degree of automation involved in penetration testing can aid in fulfilling the demands for increased security testing. In this work, we formally express the penetration  testing problem  at the  architectural level  and suggest a general self-organizing architecture that can be instantiated to automate penetration testing of real systems. We further describe and implement a specialization of the architecture in ADAPT, an  architecture-driven automated penetration testing  tool, targeting systems composed of hosts and services. We evaluate and demonstrate the feasibility of ADAPT by automatically performing  penetration tests  with success against: Metasploitable2, Metasploitable3, and a realistic virtual network used as a lab environment for  penetration tester  training.}
}


@article{DBLP:journals/compsec/AkandeHFL25,
	author = {Ayodeji James Akande and
                  Zhe Hou and
                  Ernest Foo and
                  Qinyi Li},
	title = {LTL-based runtime verification framework for cyber-attack anomaly
                  prediction in cyber-physical systems},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104455},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104455},
	doi = {10.1016/J.COSE.2025.104455},
	timestamp = {Fri, 09 May 2025 20:27:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AkandeHFL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An anomaly is any unexpected or abnormal behaviour, event, or data pattern within a network of physical and computational components caused by data errors, cyber-attacks, hardware failures, or other unforeseen events.  Anomaly detection  analyses events after they occur, while anomaly prediction forecasts them before they manifest. The increasing complexity of Cyber-Physical Systems (CPS) presents challenges in fault management and vulnerability to advanced attacks, highlighting the need for early intervention through anomaly prediction. Existing anomaly prediction methods often fail due to a lack of formal guarantees required for safety-critical applications. In this paper, we introduce our anomaly prediction framework which merges the advantages of  data analytics  and the derivation of  Linear Temporal Logic  (LTL) formulas. LTL-based runtime monitoring and checking is a well-established technique efficient for tackling challenges in real-time and promptly. The framework processes historical data, clusters them to extract predictive patterns, and forms data sequences that represent these trends. These sequences are fed into an LTL learning algorithm to produce a formula that represents the pattern. This formula functions as a security property programmed into a runtime checker to verify system correctness and predict the possibility of anomalies. We evaluated our framework using three datasets collected from a cyber-physical system  testbed  and the experimental findings demonstrate a minimum accuracy of 90% in predicting anomalies.}
}


@article{DBLP:journals/compsec/ChenKLZMLT25,
	author = {Xuefei Chen and
                  Jinfeng Kou and
                  Haiqiang Li and
                  Yuqi Zhang and
                  Junchao Ma and
                  Chen Li and
                  Bibo Tu},
	title = {End-to-end anomaly detection of service function chain through multi-source
                  data in cloud-native systems},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104461},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104461},
	doi = {10.1016/J.COSE.2025.104461},
	timestamp = {Thu, 27 Nov 2025 07:55:28 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ChenKLZMLT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud native technology enables  Network Functions Virtualization  (NFV) to dynamically provide and deploy  network services  to meet specific requirements in Industrial  Internet of Things  (IIoTs). However, compared to traditional hardware solutions, Service Function Chains (SFCs) are more prone to faults in complex and dynamically changing cloud environments. Existing  anomaly detection  methods exhibit several shortcomings, including high overhead, low accuracy, and limited detection scope. To address these challenges and ensure service quality, we propose an end-to-end SFC  anomaly detection  architecture, cSFCAD. First, to overcome the limitations of detection range and single-function detection, the cSFCAD architecture integrates multi-source data from both the data plane and control plane, enabling the effective detection of various types of SFC anomalies. Second, to better capture the spatial relationships of Cloud-Native Network Functions (CNFs) within the SFC, we adopt an encoder based on the self-attention mechanism, which models the behaviour of CNFs and their  interdependencies . Finally, to improve the stability of model in dynamic cloud environment, we use  adversarial training  in order to achieve self-conditioning for robust multi-modal feature extraction and enhanced stability. Additionally, through data reconstruction, we can precisely identify the key metrics contributing most to the anomalies. The difference between the input data and its reconstructed output helps in analysing the underlying causes of the anomalies. Extensive experimental research on two public datasets demonstrates that cSFCAD architecture outperforms existing anomaly  detection algorithms .}
}


@article{DBLP:journals/compsec/DingSDZD25,
	author = {Ruiyang Ding and
                  Lei Sun and
                  Zhiyi Ding and
                  Weifei Zang and
                  Leyu Dai},
	title = {Towards targeted and universal adversarial attacks against network
                  traffic classification},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104470},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104470},
	doi = {10.1016/J.COSE.2025.104470},
	timestamp = {Sun, 27 Apr 2025 17:31:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/DingSDZD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the continuous advancement of technology,  deep learning  has become the mainstream method in the field of network  traffic classification , demonstrating excellent classification performance. However, due to the inherent vulnerability of  deep learning models , they also face the threat of  adversarial attacks . Currently, adversarial attack techniques for network  traffic classification  only remain at the level of untargeted attacks, and most of them are attack methods based on specific perturbation. These methods have high time overhead, high sample dependency, and are unable to perform targeted attacks on target categories, which poses significant limitations in practical applications. To this end, this article proposes a targeted and universal adversarial attack method against network traffic classification. It iteratively trains to minimize the distance between network traffic and the target category feature domain, thereby generating the universal perturbation vector for the target category. This maximizes the prediction probability of the model output target category, allowing the classifier to incorrectly predict any non-target category network traffic as the specified target category. Meanwhile, this article uses dynamic masking and modular operations to generate adversarial network traffic, ensuring the data reversibility and transferability of network traffic packets during  adversarial attacks . Finally, this article selected three standard network traffic datasets with different  classification tasks , CICIoT2023, ISCX2016, and USTC-TFC2016, as well as four mainstream network traffic  classification models  such as LeNet5, for experiments, and built the adversarial attack testing platform in the real network environment. The results show that the proposed method effectively implements targeted and universal adversarial attacks against network traffic classification on three datasets and four  classification models , with the average attack success rate of over 56 % and the single attack time of 1–3 ms, greatly improving the application scope and practical value of adversarial attack techniques in the field of network traffic classification.}
}


@article{DBLP:journals/compsec/ChenWYW25,
	author = {Xing Chen and
                  Jingsheng Wang and
                  Song Yan and
                  Zuyin Wang},
	title = {Anomalous identity recognition model based on vehicle driving characteristic
                  verification in typical scenarios},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104476},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104476},
	doi = {10.1016/J.COSE.2025.104476},
	timestamp = {Sun, 27 Apr 2025 17:31:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenWYW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicle-to-everything (V2X) enables the exchange and sharing of information between vehicles and the outside world, which improves driving safety, reduces traffic congestion, and enhances traffic efficiency. However, this information exchange and transmission of massive data also exposes many attack surfaces, which may result in security incidents such as vehicle theft,  information leakage , and driving failure. Traditional methods to ensure traffic information interaction through information security have limitations. This paper proposes an innovative model for anomalous identity recognition based on vehicle driving characteristic verification. The model aims to ensure consistency among the speed data from different sources, types of  transmission data , and perception data obtained by sensors. The model is based on a multi-class  support vector machine  (multi-class SVM) to identify vehicle behavior and a bidirectional  gated recurrent unit  (BiGRU)  neural network  to predict vehicle speed. A credible calculation method was designed to calculate the error between the predicted speed and the actual collected speed in the car-following and lane-changing scenarios. The Next Generation Simulation dataset was used to train and test the models. The experimental results showed that the overall  recognition accuracy  of the multi-class SVM model was 95.50 %, the predicted precision with an order of magnitude of cm/s was achieved by the BiGRU model, and the overall  recognition accuracy  of the model was >90 %. The  public key infrastructure  (PKI) scheme is currently the mainstream scheme of information security in the  Internet of Vehicles . This paper analyzes the feasibility of the proposed anomalous identity recognition model applied in the PKI framework, which can effectively identify anomalous vehicle identities by discriminating the vehicle speed and effectively ensure the security between a vehicle and the external network communication (4G/5G/V2X).}
}


@article{DBLP:journals/compsec/QuMZJW25,
	author = {Yanze Qu and
                  Hailong Ma and
                  Chaofan Zheng and
                  Yiming Jiang and
                  Wenbo Wang},
	title = {A malware traffic detection method based on Victim-Attacker interaction
                  patterns},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104487},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104487},
	doi = {10.1016/J.COSE.2025.104487},
	timestamp = {Fri, 15 Aug 2025 09:50:01 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QuMZJW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread adoption of encryption protocols has provided benefits for personal privacy, while also offering cover for the command and control (C&C) communication of  malware  such as Trojans, presenting significant challenges to existing network  monitoring systems . Existing methods exhibit limited capacity to discern threats across network flows, while neglecting the prevalent packet loss phenomenon in real-world network environments. This paper proposes a  malware  traffic detection method based on the interaction patterns between compromised hosts and C&C servers. With a novel detection unit called channel unit representing interaction patterns, compared to existing methods, our proposed method is capable of discerning threats across network flows and is more resilient to packet loss. Evaluation experiments show that our method has superior detection performance in both binary and multi-class classification scenarios, achieving accuracy rates of 99.84 % and 96.08 % respectively. In terms  of packet loss  tolerance, compared with existing methods, our method exhibits the minimal  performance degradation  under a 20 %  packet loss rate , maintaining a multi-classification accuracy of 99.63 % and a  binary classification  accuracy of 95.72 %.}
}


@article{DBLP:journals/compsec/HendaouiMTFA25,
	author = {Fatma Hendaoui and
                  Rahma Meddeb and
                  Lamia Trabelsi and
                  Ahlem Ferchichi and
                  Rawia Ahmed},
	title = {{FLADEN:} Federated Learning for Anomaly DEtection in IoT Networks},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104446},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104446},
	doi = {10.1016/J.COSE.2025.104446},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HendaouiMTFA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sensitive applications are strict in terms of data privacy. In this context,  intrusion detection systems  cannot access the data and analyze it to discover attacks signatures. As a result, it is necessary to analyze data locally without disclosing it to a third party.  Machine learning  models can achieve this task. This paper proposes a machine-learning framework for  intrusion detection  on  IoT  networks. The proposed framework enables participating entities to analyze their data more efficiently and privately. A new real-world dataset is generated using online threat intelligence sources. FLADEN updates the  federated learning  library to optimize processing time with an accuracy of 99.85%. The proposed framework was applied to machine learning models and shows a precision of 99. 89%, an F1 score of 99. 93%, and a recall of 99.91%. This work presents implications for those researchers who may focus on large-scale  anomaly detection  with  privacy preservation  in  IoT  networks.}
}


@article{DBLP:journals/compsec/DeyG25,
	author = {Debasmita Dey and
                  Nirnay Ghosh},
	title = {iQUIC: An intelligent framework for defending {QUIC} connection ID-based
                  DoS attack using advantage actor-critic {RL}},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104463},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104463},
	doi = {10.1016/J.COSE.2025.104463},
	timestamp = {Sat, 15 Nov 2025 13:51:28 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/DeyG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {QUIC (Quick  UDP  Internet Connections) is a relatively recent  transport layer protocol  that Google deployed and implemented for the first time in 2012. The key aspect of this protocol is that it is faster than TCP, more secure than  UDP , and more efficient regarding resource usage. It has been adopted by some Internet-based applications, viz., YouTube, Gmail, etc. Recent advancements in 5G/6G communication technology have enabled the integration of QUIC with many real-time applications. One of the drawbacks in the design of the QUIC protocol is its vulnerability against attacks related to connection ID, and a recent attack of this type is the  retire connection ID stuffing attack . This attack leads to a  denial of service  (DoS) condition, thus hindering network operations and services. Few preventive solutions have been proposed, but they focus on closing the connection after detecting an attack scenario, which results in  service disruption . In this paper, we attempted to render flexibility to this rigid security defense mechanism situation by proposing  iQUIC , an intelligent framework to configure a network condition monitoring QUIC server. The framework inputs the network data to a local  Advantage Actor–Critic (A2C)  Reinforcement Learning  (RL)  engine to support decision-making regarding accepting/rejecting a request from a client or issuing a warning signal to it. The framework also enables the server to stochastically suspend connections with the client(s) following in  ϵ <math><mi is="true">ϵ</mi></math> -greedy approach after a predefined observation window. To replicate a real-world QUIC-enabled network, we devised a small QUIC network consisting of two clients and a server and generated substantial QUIC traffic by implementing a U-Net-based GAN (Generative Adversarial Network) model from scratch. A simulation-based performance evaluation demonstrates that the QUIC server powered by the actor–critic RL learns to make optimal decisions with time.}
}


@article{DBLP:journals/compsec/KozakDTR25,
	author = {Matous Koz{\'{a}}k and
                  Luca Demetrio and
                  Dmitrijs Trizna and
                  Fabio Roli},
	title = {Updating Windows malware detectors: Balancing robustness and regression
                  against adversarial EXEmples},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104466},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104466},
	doi = {10.1016/J.COSE.2025.104466},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KozakDTR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial EXEmples are carefully-perturbed programs tailored to evade  machine learning  Windows  malware detectors , with an ongoing effort to develop robust models able to address detection effectiveness. However, even if robust models can prevent the majority of EXEmples, to maintain  predictive power  over time, models are fine-tuned to newer threats, leading either to  partial updates  or time-consuming retraining from scratch. Thus, even if the robustness against adversarial EXEmples is higher, the new models might suffer a regression in performance by misclassifying threats that were previously correctly detected. For these reasons, we study the trade-off between accuracy and regression when updating  Windows malware  detectors by proposing EXE-scanner, a plugin that can be chained to existing detectors to promptly stop EXEmples without causing regression. We empirically show that previously proposed hardening techniques suffer a regression of accuracy when updating non-robust models, exacerbating the gap when considering low  false positives  regimes and temporal drifts affecting data. Also, through EXE-scanner we gain evidence on the detectability of adversarial EXEmples, showcasing the presence of artifacts left inside while creating them. Due to its design, EXE-scanner can be chained to any classifier to obtain the best performance without the need for costly retraining. To foster reproducibility, we openly release the source code, along with the dataset of adversarial EXEmples based on state-of-the-art perturbation algorithms.}
}


@article{DBLP:journals/compsec/YangGKYF25,
	author = {Shanquan Yang and
                  Yansong Gao and
                  Boyu Kuang and
                  Yixuan Yang and
                  Anmin Fu},
	title = {DFirmSan: {A} lightweight dynamic memory sanitizer for Linux-based
                  firmware},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104467},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104467},
	doi = {10.1016/J.COSE.2025.104467},
	timestamp = {Tue, 05 Aug 2025 22:44:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YangGKYF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vulnerabilities in Linux-based firmware present a significant risk to  IoT  security, with memory-related issues being especially hidden and dangerous. Despite substantial efforts to uncover firmware vulnerabilities through fuzzing, these methods are often ineffective in detecting memory vulnerabilities. To address this issue, prior research introduces sanitizers integrated into  fuzzers . However, applying existing sanitizers to Linux-based firmware poses three significant challenges: First, embedded  Linux systems  lack robust memory protection and operate under tight performance constraints, making it difficult to detect “silent memory corruption”. Second, most binary sanitizers focus on executables, such as the main program (the core  backend service  programs handling requests), and fail to effectively monitor dynamically loaded libraries, which are often assumed to be trustworthy. Third, sanitizers that rely on global memory monitoring techniques, such as shadow memory or redzone, introduce substantial performance overhead. These mechanisms significantly slow down resource-constrained firmware, rendering  fuzz testing  impractical for  IoT devices . This paper introduces DFirmSan, a lightweight dynamic memory sanitizer for Linux-based firmware. DFirmSan addresses key challenges in detecting memory vulnerabilities through a two-step process. First, the pre-analysis phase identifies service programs and vendor-customized libraries, analyzing them for sensitive function calls and key parameters. In the second step, dynamic memory corruption detection, DFirmSan leverages this information to perform targeted dynamic boundary checks during runtime, focusing on detecting memory flaws, particularly silent corruptions. To minimize overhead, DFirmSan focuses on selectively monitoring sensitive function parameters influenced by untrusted data, rather than tracking all memory variables. It further reduces  false positives  by dynamically adjusting parameter boundaries. We evaluate DFirmSan on 18 real-world firmware samples. By integrating DFirmSan, two advanced  fuzzers  detect 117 and 25 additional known CVEs, respectively. Besides, it helps uncover 4 CNVD zero-day vulnerabilities. Despite this enhanced capability, the impact on fuzzing speed remains minimal, with reductions of only 16.43% and 2.69%, well within acceptable limits. Moreover, DFirmSan maintains an impressively low false positive rate of under 0.35% for detecting memory corruption, further underscoring its practicality in real-world firmware.}
}


@article{DBLP:journals/compsec/BenaADYA25,
	author = {Nicola Bena and
                  Marco Anisetti and
                  Ernesto Damiani and
                  Chan Yeob Yeun and
                  Claudio A. Ardagna},
	title = {Protecting machine learning from poisoning attacks: {A} risk-based
                  approach},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104468},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104468},
	doi = {10.1016/J.COSE.2025.104468},
	timestamp = {Sat, 06 Sep 2025 20:25:27 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BenaADYA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ever-increasing interest in and widespread diffusion of  Machine Learning  (ML)-based applications has driven a substantial amount of research into offensive and defensive ML. ML models can be attacked from different angles: poisoning attacks, the focus of this paper, inject maliciously crafted data points in the training set to modify the model behavior;  adversarial attacks  maliciously manipulate inference-time data points to fool the ML model and drive the prediction of the ML model according to the attacker’s objective. Ensemble-based techniques are among the most relevant defenses against poisoning attacks and replace the monolithic ML model with an ensemble of ML models trained on different (disjoint) subsets of the training set. They assign data points to the training sets of the models in the ensemble (routing) randomly or using a  hash function , assuming that evenly distributing poisoned data points positively influences ML robustness. Our paper departs from this assumption and implements a risk-based ensemble technique where a  risk management process  is used to perform a smart routing of data points to the training sets. An extensive experimental evaluation demonstrates the effectiveness of the proposed approach in terms of its soundness, robustness, and performance.}
}


@article{DBLP:journals/compsec/MadhusudhananJ25,
	author = {Sheema Madhusudhanan and
                  Arun Cyril Jose},
	title = {Privacy preservation techniques through data lifecycle: {A} comprehensive
                  literature survey},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104473},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104473},
	doi = {10.1016/J.COSE.2025.104473},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MadhusudhananJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing user data volume, safeguarding  sensitive information  has become more critical than ever. This survey reviews privacy-preserving techniques and models designed to protect  Personally Identifiable Information  (PII) and other sensitive data. Privacy is essential at every data  lifecycle stage , including data collection, storage, processing, sharing and transmission, retention and deletion, and access control. We discuss the challenges associated with each stage and highlight relevant research work. The survey concludes with a discussion of ongoing challenges and potential research directions in data  privacy preservation .}
}


@article{DBLP:journals/compsec/KumarS25,
	author = {Anit Kumar and
                  Dhanpratap Singh},
	title = {Securing IoT devices in edge computing through reinforcement learning},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104474},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104474},
	doi = {10.1016/J.COSE.2025.104474},
	timestamp = {Tue, 05 Aug 2025 22:44:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KumarS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The exponentially increasing demand for  IoT  devices with the expectation of maximum fulfillment of the user needs to bring the integration of the Edger server on the premise of the  IoT devices . The small size but the need for complex computation and high-end software requires the amount of additional hardware setup that can never be possible with the absence of an Edge server. Since the Edger server continuously gathers the data from the  IoT  device for further computation and permanent storage in either local storage or a cloud server, it attracts intruders to try to steal sensitive data of the  IoT devices  from the Edge server. With the presence of many  artificial intelligence  tools, an intruder can make serious attacks on the Edger server by breaking its security boundaries. Any individual autonomous entity like a robot, satellite, or self-driving vehicle has a set of interconnected IoT devices (sensors) to form a network, which needs to be so flexible that any new IoT device can easily be integrated into this network without any major difficulties. None of the organizations has ever adopted non-scalable IoT networks. To counter such security challenges, we propose a scalable, robust, and reliable Novel Reinforcement  Learning approach  having a proper  task scheduling  mechanism that is powered by using the epsilon-greedy search Q-learning method. The novelty of our proposed method is its high performance which allows the agent to take actions at the time only when it finds a noticeable drop in the network performance in terms of  packet delivery ratio , average throughput, and end-to-end delay hyperparameters. Experiments carried out by us along with simulation and real datasets, prove that our proposed security method provides outstanding results as compared to other security approaches discussed in this paper and can counter  malicious attacks  efficiently. Once our security model gets trained with a threshold amount of times, then after this threshold time, we observe that no benign data packets are lost even with the presence of any external threats and always provide stable communication to the end users. The proposed novel reinforcement learning method is more consistent, resilient, scalable, and accurate than other similar machine learning-based security methods and always has a false positive rate of <2 %.}
}


@article{DBLP:journals/compsec/CHH25,
	author = {Kiran K. C. and
                  Md. Shafaeat Hossain and
                  Carl Haberfeld},
	title = {Exploring capacitive swipe gesture for user authentication using a
                  new large dataset},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104475},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104475},
	doi = {10.1016/J.COSE.2025.104475},
	timestamp = {Thu, 22 May 2025 21:23:40 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CHH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the viability of the capacitive swipe gesture as a  biometric  modality. While the regular swipe gesture and the capacitive image have been widely explored in  biometric  literature, the capacitive swipe gesture is fairly new in this line of research. To our knowledge, only one recent study has explored the capacitive swipe gesture, and demonstrated its promise. However, that study is limited by a number of factors, such as using a very small data set in the experiments,  collecting data  in a single session, allowing the same impostor in both training and testing phases of  authentication  models, etc. In our paper, we address all these limitations, and rigorously explore the capacitive swipe gesture by creating a new large data set. Additionally, we develop a new technique to preprocess capacitive swipe gesture data, and demonstrate its effectiveness by comparing with existing techniques. A large set of experiments with four  machine learning  classifiers and two swipe directions prove that the capacitive swipe gesture can be effectively used for  user authentication  in smartphones.}
}


@article{DBLP:journals/compsec/MaldonadoR25,
	author = {Javier Maldonado and
                  Mar{\'{\i}}a Cristina Riff},
	title = {An evolutionary wrapper to support intrusion detection system configuration},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104478},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104478},
	doi = {10.1016/J.COSE.2025.104478},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MaldonadoR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting and classifying attacks is one of the  building blocks  of cybersecurity. This is a difficult task, as  classification algorithms  must deal with a profusion of data used to detect attacks which may be very time consuming. In this paper, an evolutionary approach is proposed to obtain information about a given set of features, as well as to select the best features as input for attack  classification algorithms . With this approach, each individual represents an optimized set of features, such that a cybersecurity analyst can evaluate which features and how many of them are required to obtain a suitable metric to detect a specific attack. This set of features improves the quality of attack detection while also reducing the CPU time required for the classification itself. This approach is evaluated using well-known datasets and  decision trees  generated by C4.5 and  Random Forest  algorithms for the evaluation and classification. We compare our findings with state-of-the-art results, demonstrating promising advances. Additionally, the features information that can be obtained using this approach is reported, which is useful for  making decisions  for attack discrimination.}
}


@article{DBLP:journals/compsec/GuoLCCS25,
	author = {Zihui Guo and
                  Yin Lv and
                  Ningning Cui and
                  Liwei Chen and
                  Gang Shi},
	title = {HScheduler: An execution history-based seed scheduling strategy for
                  hardware fuzzing},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104479},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104479},
	doi = {10.1016/J.COSE.2025.104479},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GuoLCCS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent emergence of hardware fuzzing has introduced significant advancements in hardware verification. However, the lack of an efficient seed (input for fuzzing) scheduling mechanism severely affects its performance. In this paper, we propose HScheduler, a novel seed scheduling strategy based on seed execution history. First, HScheduler prioritizes seeds based on the historical  coverage points , ensuring that more promising seeds are executed first. Second, it analyzes seed mutation history to guide subsequent mutations, reducing the occurrence of ineffective mutations. Our evaluation demonstrates that HScheduler significantly improves the overall efficiency of hardware  fuzzers . We implemented this design on both the state-of-the-art general-purpose hardware fuzzer RFUZZ and the processor-specific fuzzer DifuzzRTL. Experimental results demonstrate that, when fuzzing various real-world hardware designs, our approach achieves up to a  41 . 4 × <math><mrow is="true"><mn is="true">41</mn><mo is="true">.</mo><mn is="true">4</mn><mo is="true">×</mo></mrow></math>  speed improvement (with an average improvement of  7 . 4 × <math><mrow is="true"><mn is="true">7</mn><mo is="true">.</mo><mn is="true">4</mn><mo is="true">×</mo></mrow></math> ) over RFUZZ, while HScheduler significantly reduces ineffective mutations during fuzzing. Additionally, it boosts coverage speed by 5.6 × <math><mo is="true">×</mo></math>  in DifuzzRTL, with a notable increase in final coverage, detecting over 1.4 times more mismatch seeds (potential bugs). Moreover, HScheduler introduces only a 0.63% performance overhead.}
}


@article{DBLP:journals/compsec/LiQHZ25,
	author = {Jinyuan Li and
                  Guangyu Qian and
                  Wei He and
                  Wei Zhang},
	title = {Industrial control system intrusion detection method based on belief
                  rule base with gradient descent},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104488},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104488},
	doi = {10.1016/J.COSE.2025.104488},
	timestamp = {Sun, 12 Oct 2025 07:50:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiQHZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intrusion detection is important for maintaining the smooth operation of industrial control systems (ICSs). The belief  rule base  (BRB), as a hybrid information-driven model, has been widely used in various fields because of its high accuracy and good interpretability. However, when facing intrusion detection problems in ICSs with high-dimensional features, excessive rules often arise, leading to slow model inference and optimization due to the large number of rules. Therefore, this paper proposes an interval structure belief  rule base  with mini-batch  gradient descent  optimization (IBRB-MBGD) for ICS intrusion detection. First, to address the issue of rule explosion caused by high-dimensional features, a new modeling approach is proposed that uses  reference intervals  instead of single values, and the rule generation mode is changed from conjunction to disjunction, further improving the model inference method and effectively solving the combination rule explosion. Second, the large amount of  historical data  slows down the model optimization process; thus, an optimization method based on minibatch  gradient descent  is proposed to quickly optimize the parameters in the BRB. Finally, experiments were conducted on natural  gas pipeline  system and water storage tank system intrusion detection data, and the detection rate reached >90 %, verifying the effectiveness of the model.}
}


@article{DBLP:journals/compsec/ugliS25,
	author = {Alimov Abdulboriy Abdulkhay ugli and
                  Ji Sun Shin},
	title = {{SAFE-IDS:} {A} privacy-preserving framework for overcoming non-IID
                  challenges in federated intrusion detection},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104492},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104492},
	doi = {10.1016/J.COSE.2025.104492},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ugliS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning  has advanced  intrusion detection systems  (IDS) by enabling collaborative model training without requiring direct data sharing. This approach allows multiple institutions to contribute to and benefit from a shared model, enhancing detection capabilities. Despite these advances, the security of model updates remains a significant concern, as  malicious actors  may reverse-engineer the underlying data from these updates. Additionally, existing federated learning techniques struggle with non-IID (non-Independent and Identically Distributed)  data distributions  and are vulnerable to inference attacks on model updates. For example, methods like  SignSGD , while providing some privacy benefits through gradient sign manipulation, suffer from accuracy degradation, especially when dealing with non-IID data. Similarly,  FedAvg , while effective in handling non-IID data, is prone to  privacy breaches  as it transmits full model updates, potentially revealing  sensitive information . To address these challenges, we propose  SAFE-IDS , a novel framework combining gradient sign-based aggregation with the  zSignFedAvg  optimizer. Unlike  SignSGD , it incorporates a unified  learning rate  and weighted loss function to mitigate accuracy loss in non-IID settings. Additionally, while  FedAvg  shares full model updates,  SAFE-IDS  only shares gradient signs, enhancing privacy. The integration of  zSignFedAvg  balances privacy and convergence speed, accelerating convergence and improving robustness, particularly for  class imbalance . Notably,  SAFE-IDS  is the first  federated network  intrusion detection system that effectively maintains privacy while adeptly managing non-IID data. Our empirical evaluation demonstrates that  SAFE-IDS  achieves an impressive accuracy of up to 99.74% across various IDS datasets and a varying number of clients, proving its effectiveness in both securing client data and maintaining high model performance.}
}


@article{DBLP:journals/compsec/NkoomHC25,
	author = {Matilda Nkoom and
                  Sena G. Hounsinou and
                  Garth V. Crosby},
	title = {Securing the Internet of Robotic Things (IoRT) against DDoS Attacks:
                  {A} Federated Learning with Differential Privacy Clustering Approach},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104493},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104493},
	doi = {10.1016/J.COSE.2025.104493},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NkoomHC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The  exponential growth  of Internet of Robotic Things (IoRT) systems has increased the vulnerability to Distributed Denial of Service (DDoS) attacks. Centralized  intrusion detection  approaches collect sensitive data from distributed robotic devices, raising privacy concerns. While  federated learning  (FL) offers collaborative threat detection, it faces challenges due to the heterogeneous nature of the  data collected  from the diverse IoRT devices and privacy vulnerability. This paper proposes a  DDoS  detection framework for IoRT systems that addresses both challenges through: (1) applying the  Differential Privacy  (DP) mechanism to the  quantile values shared  by clients with the central server, protecting statistical information while enabling effective clustering, and (2) implementing privacy-preserving k-means clustering based on these DP  quantile  values to group devices with similar  data distributions . Using the CICIoT2023 data set and PyTorch framework, we evaluate three models and compare performance between clustered and non-clustered  FL approaches . The results from our simulated environment demonstrate that our clustered approach improves performance across all models when compared to our  baseline model :  CNN  accuracy increased from 98.10% to 98.99%,  LSTM  showed improvement from 95.38% to 98.00%, and  GRU  accuracy increased from 96.50% to 98.50%. Our evaluation demonstrates that privacy-preserving clustering effectively mitigates the challenges of  heterogeneous data  in FL while maintaining privacy guarantees.}
}


@article{DBLP:journals/compsec/MedvedevBK25,
	author = {Viktor Medvedev and
                  Arnoldas Budzys and
                  Olga Kurasova},
	title = {A decision-making framework for user authentication using keystroke
                  dynamics},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104494},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104494},
	doi = {10.1016/J.COSE.2025.104494},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MedvedevBK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increasingly sophisticated  cyber attacks  threaten critical infrastructures, requiring more trusted user  authentication mechanisms . In this work, we propose a deep learning-based  user authentication  framework that combines keystroke dynamics with  Siamese neural networks  to differentiate legitimate users from impostors. A key challenge in this area is the variability in  password lengths , which leads to different feature sizes and complicates model training. Our approach uses interpolation-based data fusion strategies to standardize the number of keystroke features, ensuring consistency across different datasets and  password lengths . Through experiments on the fused CMU and KeyRecs datasets, we have evaluated the effectiveness of the proposed decision-making framework with adaptive threshold strategies. The threshold strategy determines how the final decision boundary is set with respect to the user’s baseline typing behavior. We empirically evaluated the framework on fused data, achieving an  equal error rate  as low as 0.11–0.12, indicating strong efficacy in detecting insider threats. We show how the obtained Siamese neural network with triplet loss function can be used to distinguish genuine users from impostors even under different input conditions, contributing to more robust and scalable  intrusion detection systems .}
}


@article{DBLP:journals/compsec/GaoYZWYC25,
	author = {Yazhuo Gao and
                  Lin Yang and
                  Ran Zhu and
                  Yixuan Wu and
                  Feng Yang and
                  Yining Cao},
	title = {{IR-IDS:} {A} network intrusion detection method based on causal feature
                  selection and explainable model optimization},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104496},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104496},
	doi = {10.1016/J.COSE.2025.104496},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GaoYZWYC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid advancement of computer network technologies, the complexity of cybersecurity issues has grown significantly.  Intrusion Detection Systems  (IDS), serving as the first line of defense against network attacks, are vital components in ensuring  network security . However, traditional IDS often struggle to balance the robustness of detection capabilities with the  interpretability  of the model. To address these challenges, this paper proposes an interpretable and robust  intrusion detection  method (IR-IDS). The proposed approach begins by efficiently and accurately selecting the optimal feature subset for predicting the target variable, using a causal effect-based conditional  testing method  and a  Markov blanket  search algorithm. Subsequently, it enhances the  decision tree  algorithm using Shapley values, enabling fine-grained classification of attacks. Finally, by integrating Kolmogorov–Arnold Networks (KAN) and Conditional Variational  Autoencoders  (CVAE), the method further improves the detection of unknown attacks. Experimental results demonstrate that the proposed method outperforms existing techniques on five datasets, including CIC-IDS2017, CSE-CIC-IDS2018, CIC-DDoS2019, CIC-UNSW-NB15 and CIC-IoT-IDAD-2024, with multi-class accuracies of 98.83 %, 99.37 %, 99.57 %, 99.52 % and 97.11 %, respectively. From the results, it can be seen that this method not only ensures the interpretability of the model but also improves the accuracy and robustness of intrusion detection.}
}


@article{DBLP:journals/compsec/ColeFRB25,
	author = {Kelly A. Cole and
                  Alexander L. Francis and
                  Marcus K. Rogers and
                  Joseph Balazs},
	title = {Can individual differences in cognitive capacity predict cybersecurity
                  performance?},
	journal = {Comput. Secur.},
	volume = {155},
	pages = {104497},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2025.104497},
	doi = {10.1016/J.COSE.2025.104497},
	timestamp = {Sat, 31 May 2025 23:14:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ColeFRB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber defense analysts work in highly demanding environments, making numerous critical decisions on the basis of complex information presented at a rapid rate. Individual differences in cognitive capacity may contribute significantly to cyber performance success but researchers have yet to definitively determine what cognitive functions play the most significant role in cybersecurity performance. To further understand the role of individual differences in attention and cognition that affect cyber performance in the cybersecurity domain, this exploratory study involved collecting measures of cognitive performance from 19 experienced cybersecurity analysts using three well-established measures designed for individual differences research. The individual differences were compared with behavioral performance (accuracy and response time) in a simulated incident detection system identified as ecologically valid in cybersecurity research. Results showed a significant relationship between incident detection performance and multiple cognitive variables. Specifically, analysts with higher  working memory capacity  performed more accurately and more quickly, while those that showed more evidence of distractibility performed less well. These findings suggest that easily obtained behavioral measures of attention control may be useful for: (a) identifying individuals who may be better suited to performing specific cognitive demands of incident detection tasks, and (b) informing system design to reduce demands on specific areas of  cognitive processing  to improve incident response decisions.}
}
