@article{DBLP:journals/compsec/FathalizadehMA22,
	author = {Amir Fathalizadeh and
                  Vahideh Moghtadaiee and
                  Mina Alishahi},
	title = {On the privacy protection of indoor location dataset using anonymization},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102665},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102665},
	doi = {10.1016/J.COSE.2022.102665},
	timestamp = {Mon, 28 Aug 2023 21:25:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/FathalizadehMA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indoor positioning is becoming more popular with increasing user demands on Location-based Services (LBS) and Social Networking Services (SNS). Location fingerprinting is widely deployed in indoor localization, and extensive daily use of different kinds of mobile devices in indoor environments results in generating a huge amount of location data of people. However, publishing this location based dataset by Location Service Provider (LSP) to any third party, such as researchers or commercial organizations, potentially threatens users’ privacy. Several studies have been done to anonymize the user location data, but protecting the users’ information against various attacks in an indoor environment is still a challenging issue. This paper proposes a novel framework for publishing privacy preserving location data employing five anonymization techniques: k-anonymity,\nℓ\n-diversity, t-closeness,\n(\nα\n,\nk\n)\n-anonymity, and\nδ\n-presence. In the proposed framework, although the LSP cannot find the exact location of the users, it can provide them online location services at the same time and publish the anonymized privacy protected dataset afterward. The practical feasibility of applying the proposed framework is verified on both simulated and two real-world datasets. The results indicate that the published location dataset can protect the identity and location information of users while providing location information for third parties for further purposes.}
}


@article{DBLP:journals/compsec/AggarwalTJCLTG22,
	author = {Palvi Aggarwal and
                  Omkar Thakoor and
                  Shahin Jabbari and
                  Edward A. Cranford and
                  Christian Lebiere and
                  Milind Tambe and
                  Cleotilde Gonzalez},
	title = {Designing effective masking strategies for cyberdefense through human
                  experimentation and cognitive models},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102671},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102671},
	doi = {10.1016/J.COSE.2022.102671},
	timestamp = {Mon, 28 Aug 2023 21:25:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AggarwalTJCLTG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Masking strategies for cyberdefense (i.e., disguising network attributes to hide the real state of the network) are predicted to be effective in simulated experiments. However, it is unclear how effective they are against human attackers. We address three factors that challenge the effectiveness of the masking strategies in practice: (1) we relax the assumption of rationality of the attackers made by Game Theory/Machine Learning defense algorithms; (2) we provide a cognitive model of human attackers that can inform these defense algorithms; and (3) we provide a way to generate data on attacker’s decisions through simulation with a cognitive model. Two masking strategies of defense were generated using Game Theory and Machine Learning (ML) algorithms. The effectiveness of these two masking strategies of defense, risk averse and rational, are compared in an experiment with human attackers. We collected attacker’s decisions against the two masking strategies. With the limited human participant’s data, the results indicate that the risk averse strategy can reduce the defense losses compared to the rational masking strategy. We also propose a cognitive model based on Instance-Based Learning Theory that accurately represents and predicts the attacker’s decisions in this task. We demonstrate the model’s process by generating simulated data and comparing it to the attacker’s actual actions in the experiment. The model is able to capture the data at the aggregate and at the individual levels of attackers making decisions in both rational and risk averse defense algorithms. We propose that this model can be used to inform game theoretic defense algorithms and to produce synthetic data that can be used by ML algorithms to generate new defense strategies.}
}


@article{DBLP:journals/compsec/ChenLS22,
	author = {Tianrong Chen and
                  Jie Ling and
                  Yuping Sun},
	title = {White-box content camouflage attacks against deep learning},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102676},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102676},
	doi = {10.1016/J.COSE.2022.102676},
	timestamp = {Mon, 28 Aug 2023 21:25:47 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenLS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning has achieved remarkable success in a wide range of computer vision tasks. However, recent researches suggest that deep learning systems are vulnerable to a variety of attacks. Security concerns have been raised regarding the training or inference phase of deep learning models in the last few years, and the research field about the vulnerability of the pre-processing components in these models is still developing. In this paper, we systematically examine white-box content camouflage attacks on five types of pre-processing modules in deep learning systems: scaling, sharpening, Gamma correction, contrast adjustment, and saturation adjustment. We assume that an attacker's goal is to generate camouflage examples that show inconsistent visual semantics before and after pre-processing. Under the white-box setting (where the pre-processing algorithms and their parameters are known), we formulate content camouflage attacks as an optimization problem in which perceptual losses in the source and target images are smoothly calculated by a multi-scale discriminator to improve the camouflaging effect of the attack example. We evaluate our content camouflage attacks by conducting a series of experiments on two example groups as well as two real-world datasets, i.e., CIFAR-10 and FER-2013. The experimental results show that with good camouflaging ability, our attacks are effective against deep learning systems, and outperform prevalent scaling camouflage attacks by generating examples with better quality and a higher attack success rate. The proposed camouflage attacks are also extended to the four commonly used pre-processing algorithms, and yield good results. Furthermore, we discuss the effect of varying the parameters of several image pre-processing algorithms under our attacks and analyze' the reasons for their vulnerability.}
}


@article{DBLP:journals/compsec/HammiZKN22,
	author = {Badis Hammi and
                  Sherali Zeadally and
                  Rida Khatoun and
                  Jamel Nebhen},
	title = {Survey on smart homes: Vulnerabilities, risks, and countermeasures},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102677},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102677},
	doi = {10.1016/J.COSE.2022.102677},
	timestamp = {Mon, 28 Aug 2023 21:25:33 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HammiZKN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the last few years, the explosive growth of Internet of Things (IoT) has revolutionized the way we live and interact with each other as well as with various types of systems and devices which form part of the Information Communication Technology (ICT) infrastructure. IoT is having a significant impact on various application domains including healthcare, smart home, transportation, energy, agriculture, manufacturing, and many others. We focus on the smart home environment which has attracted a lot of attention from both academia and industry recently. The smart home provides a lot of convenience to home users but it also opens up various risks that threaten both the security and privacy of the users. In contrast to previous works on smart home security and privacy, we present an overview of smart homes from both academic and industry perspectives. Next we discuss the security requirements, challenges and threats associated with smart homes. Finally, we discuss countermeasures that can be deployed to mitigate the identified threats.}
}


@article{DBLP:journals/compsec/LuSXJ22,
	author = {Jintian Lu and
                  Jiakun Sun and
                  Ruizhi Xiao and
                  Shuyuan Jin},
	title = {{DIFCS:} {A} Secure Cloud Data Sharing Approach Based on Decentralized
                  Information Flow Control},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102678},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102678},
	doi = {10.1016/J.COSE.2022.102678},
	timestamp = {Tue, 16 Aug 2022 23:08:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LuSXJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Summary In the field of cloud computing, collaboration and data sharing among clouds have dramatically increased. How to protect the security of shared cloud data is being an urgent problem. Based on decentralized information flow control (DIFC) model, this paper presents an approach, DIFC-based data sharing approach (DIFCS), to protect both confidentiality and integrity of shared cloud data. Additionally, this paper designs a privilege protection policy for DIFCS, resulting in its capability of preventing malicious users from modifying privilege. The correctness and security properties of DIFCS are proved by formal analysis and verification, where firstly, DIFCS is formally interpreted into high-level petri net (HLPN) representation and analyzed using Z language, then is automatically verified with SMT-Lib and Z3 solver. The formal analysis and verification results reveal that DIFCS holds the security properties of confidentiality, integrity, authenticity, and privilege tamper-proof. The experimental results further demonstrate the high efficiency of DIFCS.}
}


@article{DBLP:journals/compsec/BerryK22,
	author = {Cate Berry and
                  Nikos Komninos},
	title = {Efficient optimisation framework for convolutional neural networks
                  with secure multiparty computation},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102679},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102679},
	doi = {10.1016/J.COSE.2022.102679},
	timestamp = {Mon, 28 Aug 2023 21:25:52 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BerryK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, deep learning has become an increasingly popular approach to modelling data due to its ability to detect abstract underlying patterns in data. Its practical applications have been limited, however, by data privacy concerns, restricting its use in major sectors such as healthcare and banking. Secure multiparty computation (MPC) is a scheme which allows multiple parties to perform joint computations over private data, while keeping the content of their data secret. MPC can enable privacy-preserving machine learning, however current implementations are rarely applied in practice due to the prohibitively high cost of performing thousands of computations and transmitting data between parties. In this paper we propose a framework incorporating various optimisation approaches from the wider field of privacy-preserving deep learning, including privacy-preserving batch normalisation and polynomial approximation of activation functions, and evaluate their performance when applied to a privacy-preserving convolutional neural network (CNN), discussing the trade-off each offers in terms of their accuracy and efficiency. We experiment with parametric polynomial (PPoly) activations by deriving polynomial approximations to activation functions and allowing the network to tune the coefficients as learning weights. We will show that, in shallow CNNs, the application of batch normalisation in combination with a PPoly activation layer can result in faster convergence, with testing accuracy exceeding that achieved with an unencrypted network, at the cost of longer running times.}
}


@article{DBLP:journals/compsec/HuangSK22,
	author = {Yuyao Huang and
                  Hui Shu and
                  Fei Kang},
	title = {DeMal: Module decomposition of malware based on community discovery},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102680},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102680},
	doi = {10.1016/J.COSE.2022.102680},
	timestamp = {Mon, 28 Aug 2023 21:25:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HuangSK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, malware has grown faster than ever in volume, form and harmfulness. While existing static or dynamic analysis techniques can meet the common user needs for malware detection, analysts desire a more detailed overview to uncover the program architecture. Malware often force research into difficulties due to their complex anti-analysis techniques, which call for a quick analysis of program structure and components to clarify malware functional semantics. In this paper, we use community discovery methods to automate the malware program components analysis from the intuition of modular programing principles. Specifically, we design and implement DeMal, a solution to the malware module decomposition problem. It achieves remodularization by recovering program call relationships, extracting structure-related attributes, and applying an ensemble model of multiple community discovery algorithms. DeMal takes a malicious executable as input and predicts its code composition structure. In an evaluation with 155 malware samples, DeMal performs well on achieving an average F1-score of 71.3%, and 14.5% of the samples reach an average precision of 90%. The analysis time on each sample is about 19.79s. On extended experiments with 1,621 benign programs and over 10,000 stripped malware samples, we also verify DeMal's scalability on common programs as well as the large-scale performance, respectively. The visualization of the results also strongly demonstrates DeMal's module decomposition capabilities.}
}


@article{DBLP:journals/compsec/CeragioliDG22,
	author = {Lorenzo Ceragioli and
                  Pierpaolo Degano and
                  Letterio Galletta},
	title = {Can my firewall system enforce this policy?},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102683},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102683},
	doi = {10.1016/J.COSE.2022.102683},
	timestamp = {Mon, 28 Aug 2023 21:25:52 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CeragioliDG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Firewalls are a fundamental tool for managing and protecting computer networks. They behave according to a configuration that specifies the desired policy, i.e., which packets are allowed to enter a network, possibly with modified addresses. Several tools allow the user to specify policies in various high level languages, and to compile them into different target configuration languages, as well as to automatically migrate a configuration from a system to another. Often, these tools implicitly assume that the target system can enforce any desired policy. Unexpectedly, we find that this is not always the case. In particular, we show that the most common UNIX firewall systems, i.e., iptables, ipfw, pf, are not equally expressive, in that some policies can be implemented in one system but not in another. Here, we formally investigate the expressive power of these firewall systems using techniques from programming language semantics, and set up a formal model to precisely characterize their relationships. Based on this formal model we then present F2F, a prototypical tool that predicts when a policy cannot be expressed in a given system. Our prototype gives detailed information about the unexpressible parts of a policy and provides administrators with hints for fixing the detected problems.}
}


@article{DBLP:journals/compsec/ChohraSKD22,
	author = {Aniss Chohra and
                  Paria Shirani and
                  ElMouatez Billah Karbab and
                  Mourad Debbabi},
	title = {Chameleon: Optimized feature selection using particle swarm optimization
                  and ensemble methods for network anomaly detection},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102684},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102684},
	doi = {10.1016/J.COSE.2022.102684},
	timestamp = {Tue, 07 May 2024 20:21:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChohraSKD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose an optimization approach by leveraging swarm intelligence and ensemble methods to solve the non-deterministic feature selection problem. The proposed approach is validated on two benchmark datasets, namely, NSL-KDD and UNSW-NB15, in addition to a third dataset, called IoT-Zeek dataset, which consists of Zeek network-based intrusion detection connection logs. We build the IoT-Zeek dataset by employing ensemble classification and deep learning models using publicly available malicious and benign threat intelligence on the Zeek connection logs of IoT devices. Moreover, we deploy and validate a deep learning-based anomaly detection model using autoencoders on each of the aforementioned datasets by utilizing the selected features obtained from the proposed optimization approach. The obtained results demonstrate that our approach outperform the existing state-of-the-art machine learning models in terms of\nf\n1\nscore results, with 92.092%\nf\n1\nscore on NSL-KDD dataset, 92.904\nf\n1\nscore on UNSW-NB15 dataset, and 97.302\nf\n1\nscore on IoT-Zeek dataset.}
}


@article{DBLP:journals/compsec/MaCS22,
	author = {Qian Ma and
                  Baojiang Cui and
                  Cong Sun},
	title = {A novel privacy-aware model for nonparametric decentralized detection},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102688},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102688},
	doi = {10.1016/J.COSE.2022.102688},
	timestamp = {Mon, 28 Aug 2023 21:25:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MaCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the increasing development of the Internet of Things (IoT) demands the enhancement of both network security and user privacy protection. In the decentralized IoT network, multiple sensors send local observations to a fusion center for data aggregation and authorized hypothesis detection. But at the same time, private information might be inferred illegally, which would cause privacy leakage. In this paper, a novel privacy-aware model named AL-UP is proposed for the nonparametric decentralized detection in the IoT network. It aims to design a local differential privacy and data projection based sanitization mechanism for sensors, to hide the sensitive information in raw observations and protect the data and inference privacy. Based on the adversarial learning framework and linear discriminant analysis, we propose a max-min optimization problem to design parameters of the sanitization mechanism and hypothesis detection rules. The problem is solved via the block coordinate descend method. Numerical results on various public datasets indicate that the proposed model achieves better utility-privacy trade-off than the state of the arts.}
}


@article{DBLP:journals/compsec/HaseebMMW22a,
	author = {Junaid Haseeb and
                  Saif Ur Rehman Malik and
                  Masood Mansoori and
                  Ian Welch},
	title = {Corrigendum to 'Probabilistic modelling of deception-based security
                  framework using markov decision process' [Computers {\&} Security
                  115 {(2022)/102599]}},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102689},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102689},
	doi = {10.1016/J.COSE.2022.102689},
	timestamp = {Sat, 30 Sep 2023 10:07:32 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HaseebMMW22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/compsec/Ki-AriesFDW22,
	author = {Duncan Ki{-}Aries and
                  Shamal Faily and
                  Huseyin Dogan and
                  Christopher Williams},
	title = {Assessing system of systems information security risk with OASoSIS},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102690},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102690},
	doi = {10.1016/J.COSE.2022.102690},
	timestamp = {Mon, 28 Aug 2023 21:26:11 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/Ki-AriesFDW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The term System of Systems (SoS) is used to describe the coming together of independent systems, collaborating to achieve a new or higher purpose. However, the SoS concept is often misunderstood within operational environments, providing challenges towards the secure design and operation of SoSs. Limitations in existing literature indicates a need for discovery towards identifying a combination of concepts, models, and techniques suitable for assessing SoS security risk and related human factor concerns for SoS Requirements Engineering. In this article, we present OASoSIS, representing an information security risk assessment and modelling process to assist risk-based decision making in SoS Requirements Engineering. A characterisation process is introduced to capture the SoS context, supporting a SoS security risk assessment process that extends OCTAVE Allegro towards a SoS context. Resulting risk data provides a focused means to assess and model the SoS information security risk and related human factors, integrating tool-support using CAIRIS. A medical evacuation SoS case study scenario was used to test, illustrate, and validate the alignment of concepts, models, and techniques for assessing SoS information security risks with OASoSIS, where findings provide a positive basis for future work.}
}


@article{DBLP:journals/compsec/ZhuJSWAC22,
	author = {Jinting Zhu and
                  Julian Jang{-}Jaccard and
                  Amardeep Singh and
                  Ian Welch and
                  Harith Al{-}Sahaf and
                  Seyit Camtepe},
	title = {A few-shot meta-learning based siamese neural network using entropy
                  features for ransomware classification},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102691},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102691},
	doi = {10.1016/J.COSE.2022.102691},
	timestamp = {Mon, 28 Aug 2023 21:25:58 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhuJSWAC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ransomware defense solutions that can quickly detect and classify different ransomware classes to formulate rapid response plans have been in high demand in recent years. Though the applicability of adopting deep learning techniques to provide automation and self-learning provision has been proven in many application domains, the lack of data available for ransomware (and other malware) samples has been raised as a barrier to developing effective deep learning-based solutions. To address this concern, we propose a few-shot meta-learning based Siamese Neural Network that not only detects ransomware attacks but is able to classify them into different classes. Our proposed model utilizes the entropy feature directly obtained from ransomware binary files to retain more fine-grained features associated with different ransomware signatures. These entropy features are used further to train and optimize our model using a pre-trained network (e.g. VGG-16) in a meta-learning fashion. This approach generates more accurate weight factors, compared to feature images are used, to avoid the bias typically associated with a model trained with a limited number of training samples. Our experimental results show that our proposed model is highly effective in providing a weighted F1-score exceeding the rate >86% compared to other similar methods.}
}


@article{DBLP:journals/compsec/IraqiB22,
	author = {Omar Iraqi and
                  Hanan El Bakkali},
	title = {Communizer: {A} collaborative cloud-based self-protecting software
                  communities framework - Focus on the alert coordination system},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102692},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102692},
	doi = {10.1016/J.COSE.2022.102692},
	timestamp = {Tue, 16 Aug 2022 23:08:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/IraqiB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Popular software has always been appealing to adversaries, as related vulnerabilities are synonymous with millions of exposed businesses. Collaborative intrusion detection, as well as software self-protection, try to alleviate this situation. However, they lack either autonomy and adaptation, or Internet-scale oversight and mitigation. In this work, we present Communizer: a collaborative cloud-based framework that creates communities of self-protecting software across organizations. It allows community members to turn their common weaknesses into collaborative and proactive self-protection, empowering them to detect intrusions, exchange alerts, and anticipate attacks. We start by integrating multiple autonomic MAPE-K loops through cloud-based coordination, and a novel hierarchical, regional coordination pattern (HRCP), optimizing scalability, resiliency, accuracy and privacy. Then, we design a trust-based multi-level alert coordination system (TMACS), as well as a lightweight alert coordination message exchange format (ACMEF). At its core, TMACS aggregates, validates, and shares security alerts among community members while fostering agreement and managing trust. It also addresses insider attacks by detecting and blacklisting rogue members. Moreover, TMACS identifies and neutralizes selfish members through a specifically designed probabilistic model. The analysis, optimization, and evaluation of TMACS show a good trade-off between the precision and recall of untrustworthy and selfish members detection. More importantly, we demonstrate a drastic reduction of monitoring loads on community members while ensuring a high collaborative attack detection and anticipation rate, even for small-scope attacks.}
}


@article{DBLP:journals/compsec/KumarSSL22,
	author = {Ayush Kumar and
                  Mrinalini Shridhar and
                  Sahithya Swaminathan and
                  Teng Joon Lim},
	title = {Machine learning-based early detection of IoT botnets using network-edge
                  traffic},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102693},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102693},
	doi = {10.1016/J.COSE.2022.102693},
	timestamp = {Mon, 28 Aug 2023 21:26:11 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KumarSSL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we present an IoT botnet detection solution, EDIMA, consisting of a set of lightweight modules designed to be deployed at the edge gateway installed in home networks with the remaining modules expected to be implemented on cloud servers. EDIMA targets early detection of IoT botnets prior to the launch of an attack and includes a novel two-stage Machine Learning (ML)-based detector developed specifically for IoT bot detection at the edge gateway. The ML-based bot detector first employs supervised ML algorithms for aggregate traffic classification and subsequently Autocorrelation Function (ACF)-based tests to detect individual bots. The EDIMA architecture also comprises a malware traffic database, a policy engine, a feature extractor and a traffic parser. Performance evaluation results using our testbed setup with real-world IoT malware traffic as well as other public IoT datasets show that EDIMA achieves high bot scanning and bot-CnC traffic detection accuracies with very low false positive rates. The detection performance is also shown to be robust to an increase in the number of IoT devices connected to the edge gateway where EDIMA is deployed. Further, the runtime performance analysis of a Python implementation of EDIMA deployed on a Raspberry Pi reveals low bot detection delays and low RAM consumption. EDIMA is also shown to outperform existing detection techniques for bot scanning traffic and bot-CnC server communication.}
}


@article{DBLP:journals/compsec/QinY22,
	author = {Yi Qin and
                  Chuan Yue},
	title = {Fuzzing-based hard-label black-box attacks against machine learning
                  models},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102694},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102694},
	doi = {10.1016/J.COSE.2022.102694},
	timestamp = {Mon, 28 Aug 2023 21:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QinY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning models are vulnerable to adversarial examples. We study the most realistic hard-label black-box attacks in this paper. The main limitation of the existing attacks is that they need a large number of model queries, making them inefficient and even infeasible in practice. Inspired by the very successful fuzz testing approach in traditional software engineering and computer security domains, we propose fuzzing-based hard-label black-box attacks against machine learning models. We design an AdvFuzzer to explore multiple paths between a source image and a guidance image, and design a LocalFuzzer to explore the nearby space around a given input for identifying potential adversarial examples. We demonstrate that our fuzzing attacks are feasible and effective in generating successful adversarial examples with significantly reduced number of model queries and\nL\n0\ndistance. More interestingly, given a successful example generated by either our or other attacks, LocalFuzzer can immediately generate more successful adversarial examples even with smaller\nL\n2\ndistance from the source example.}
}


@article{DBLP:journals/compsec/KwonL22,
	author = {Hyun Kwon and
                  Sanghyun Lee},
	title = {Ensemble transfer attack targeting text classification systems},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102695},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102695},
	doi = {10.1016/J.COSE.2022.102695},
	timestamp = {Mon, 28 Aug 2023 21:25:34 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KwonL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks provide good performance for image recognition, speech recognition, text recognition, and pattern recognition. However, such networks are vulnerable to attack by adversarial examples. Adversarial examples are created by adding a small amount of noise to an original sample in such a way that no problem is perceptible to humans yet the sample will be incorrectly classified by a classification model. Adversarial examples have been studied mainly in the context of images, but research has expanded to include the text domain. In the textual context, an adversarial example is a sample of text in which certain important words have been changed so that the sample will be misclassified by a model even though to humans it is the same as the original text in terms of meaning and grammar. However, studies of black box attacks using text adversarial examples are sparse. In this paper, we propose the ensemble transfer textfooler method. This method performs a black box attack on an unknown model after generating an ensemble adversarial example that simultaneously deceives several models. Experiments were conducted using a movie review dataset and with TensorFlow as the machine learning library. The experimental results show that the proposed method has an attack success rate of 71.64%, in contrast to the 19.01%, 24.29%, and 44.96% attack success rate for the conventional transfer attacks using an adversarial example generated to deceive a WordCNN, WordLSTM, and BERT model.}
}


@article{DBLP:journals/compsec/WuWWFYL22,
	author = {Songyun Wu and
                  Bo Wang and
                  Zhiliang Wang and
                  Shuhan Fan and
                  Jiahai Yang and
                  Jia Li},
	title = {Joint prediction on security event and time interval through deep
                  learning},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102696},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102696},
	doi = {10.1016/J.COSE.2022.102696},
	timestamp = {Mon, 15 Apr 2024 18:02:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WuWWFYL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, sophisticated attacks on cyberspace have occurred frequently, causing severe damage to the Internet. Predicting potential threats can assist security engineers in deploying corresponding defenses in advance to reduce the damage. Thus, threat prediction has drawn attention in communities recently. Previous works utilized merely historical security event sequences to predict the subsequent event through the recurrent neural network (RNN), yielding inaccurate results when the input sequence is corrupted by false reports from underlying detection logs. In this paper, we develop a joint predictor for security events and time intervals through attention-based LSTM (Long Short-Term Memory). To enhance the event predicting performance for corrupted input sequences, time intervals between events are incorporated into the input tuple, providing more distinguishing features. Moreover, a time discretization method is proposed to transform the skewed long-tail dwell time distribution into a predictable distribution of the time interval. In addition, the joint optimization function enables the model to predict the occurrence time of the next event simultaneously, which is supportive for security managers to select appropriate defenses. Our model is proved to be effective on four real-world datasets, outperforming previous methods on both event and time prediction. Moreover, the empirical results also validate the model’s stability.}
}


@article{DBLP:journals/compsec/Olukoya22,
	author = {Oluwafemi Olukoya},
	title = {Assessing frameworks for eliciting privacy {\&} security requirements
                  from laws and regulations},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102697},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102697},
	doi = {10.1016/J.COSE.2022.102697},
	timestamp = {Mon, 28 Aug 2023 21:25:52 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/Olukoya22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The processing of personal data has become a prominent concern for stakeholders when selecting software or service providers to serve their needs. Different laws and legislation have been introduced to standardize and strengthen data protection policies across different countries to protect such data. Therefore, businesses and organizations responsible for managing personal data are obligated to implement the privacy and security requirements established by these laws and legislation. Different methods and tools have been provided for eliciting requirements for legally compliant software based on the relevant data protection laws and legislation. However, little has been done in assessing these methodologies on regulations outside the EU and the US. This paper aims to assess these methodologies on other information security laws and regulations beyond the General Data Protection Regulation (GDPR) and Health Insurance Portability and Accountability Act (HIPAA) by eliciting security requirements explicitly focusing on the Nigerian data protection regulation. To investigate the applicability of these methodologies, we use the extracted privacy and security requirements with information communication protocols in verifying compliance in procedural practices of products and services in the financial technology sector. The analysis reports on the completeness, consistency, and utility of the frameworks. Finally, foundational research directions for interoperable standards for eliciting software requirements from legal texts are proposed.}
}


@article{DBLP:journals/compsec/KatsikeasJHL22,
	author = {Sotirios Katsikeas and
                  Pontus Johnson and
                  Simon Hacks and
                  Robert Lagerstr{\"{o}}m},
	title = {VehicleLang: {A} probabilistic modeling and simulation language for
                  modern vehicle {IT} infrastructures},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102705},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102705},
	doi = {10.1016/J.COSE.2022.102705},
	timestamp = {Mon, 28 Aug 2023 21:25:47 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KatsikeasJHL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attack simulations are a feasible means of assessing the cyber security of various systems. Simulations can replicate the steps taken by an attacker to compromise sensitive system assets, and the time required for the acquisition of assets of interests can be calculated. One widely accepted approach to such simulations is the modelling of attack steps and their dependencies in a formal manner using attack graphs. To reduce the effort of creating new attack graphs for each system in a given domain, one can employ domain-specific attack-modeling languages to codify common attack logic. The Meta Attack Language has been proposed as a framework for developing domain-specific attack languages. In this article, we propose vehicleLang as a domain-specific language for modeling vehicles in the context of corresponding information technology infrastructures and analyzing weaknesses related to known attacks. To model domain-specific attributes, we reviewed existing literature to develop a comprehensive language, which was then verified through a series of interviews with domain experts from the automotive industry. Specifically, a systematic literature review was performed to identify possible attacks against vehicles. The identified attacks served as a blueprint for the evaluation of vehicleLang’s simulation capabilities. Finally, the language was validated using the Feigenbaum test methodology.}
}


@article{DBLP:journals/compsec/QiuMCYC22,
	author = {Weicheng Qiu and
                  Yinghua Ma and
                  Xiuzhen Chen and
                  Haiyang Yu and
                  Lixing Chen},
	title = {Hybrid intrusion detection system based on Dempster-Shafer evidence
                  theory},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102709},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102709},
	doi = {10.1016/J.COSE.2022.102709},
	timestamp = {Mon, 28 Aug 2023 21:25:52 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QiuMCYC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-attacks are becoming increasingly sophisticated, posing greater challenges in accurately detecting intrusions. Failure to prevent intrusions could degrade the credibility of security services. Intrusion Detection System (IDS) is one of the most effective paradigms to identify attack behaviors. This paper proposes a novel hybrid intrusion detection system called DST-IDS. The proposed method employs both packet-based and flow-based intrusion detection techniques and combines them with Dempster-Shafer Theory (DST). DST-IDS has an ensemble-like framework. It takes both traffic flows and their first\nN\npackets as inputs; flow-based IDS aims to predict traffic flows and packet-based IDS detects attacks in the corresponding packets; DST is then applied to fuse predictions of flow-based IDS and packet-based IDS to a final detection result. We also design a novel data collection/processing tool in DST-IDS to reduce the data volume required to perform intrusion detection and enable early detection. In addition, DST-IDS is designed to work with heterogeneous data distribution where the distribution of the training dataset can differ from the data distribution during implementation. This property drastically improves the practicality of DST-IDS. We run experiments on public datasets and real networks to evaluate the proposed method. The experimental results show that DST-IDS outperforms state-of-the-art benchmarks in terms of intrusion detection accuracy and detection speed. Particularly, DST-IDS provides real-time detection in real networks and handles well heterogeneous data distribution.}
}


@article{DBLP:journals/compsec/SadiqueS22,
	author = {Farhan Sadique and
                  Shamik Sengupta},
	title = {Modeling and analyzing attacker behavior in IoT botnet using temporal
                  convolution network {(TCN)}},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102714},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102714},
	doi = {10.1016/J.COSE.2022.102714},
	timestamp = {Mon, 28 Aug 2023 21:25:47 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SadiqueS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional reactive approach of blacklisting botnets fails to adapt to the rapidly evolving landscape of cyberattacks. An automated and proactive approach to detect and block botnet hosts will immensely benefit the industry. Behavioral analysis of attackers is shown to be effective against a wide variety of attack types. Previous works, however, focus solely on anomalies in network traffic to detect bots and botnet. In this work we take a more robust approach of analyzing the heterogeneous events including network traffic, file download events, SSH logins and chain of commands input by attackers in a compromised host. We have deployed several honeypots to simulate Linux shells and allowed attackers access to the shells. We have collected a large dataset of heterogeneous threat events from the honeypots. We have then combined and modeled the heterogeneous threat data to analyze attacker behavior. Then we have used a deep learning architecture called a Temporal Convolutional Network (TCN) to do sequential and predictive analysis on the data. A prediction accuracy of\n85\n−\n97\n%\nvalidates our data model as well as our analysis methodology. In this work, we have also developed an automated mechanism to collect and analyze these data. For the automation we have used CYbersecurity information Exchange (CYBEX). Finally, we have compared TCN with Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) and have showed that TCN outperforms LSTM and GRU for the task at hand.}
}


@article{DBLP:journals/compsec/AlaniA22,
	author = {Mohammed M. Alani and
                  Ali Ismail Awad},
	title = {AdStop: Efficient flow-based mobile adware detection using machine
                  learning},
	journal = {Comput. Secur.},
	volume = {117},
	pages = {102718},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102718},
	doi = {10.1016/J.COSE.2022.102718},
	timestamp = {Mon, 28 Aug 2023 21:25:34 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AlaniA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, mobile devices have become commonly used not only for voice communications but also to play a major role in our daily activities. Accordingly, the number of mobile users and the number of mobile applications (apps) have increased exponentially. With a wide user base exceeding 2 billion users, Android is the most popular operating system worldwide, which makes it a frequent target for malicious actors. Adware is a form of malware that downloads and displays unwanted advertisements, which are often offensive and always unsolicited. This paper presents a machine learning-based system (AdStop) that detects Android adware by examining the features in the flow of network traffic. The design goals of AdStop are high accuracy, high speed, and good generalizability beyond the training dataset. A feature reduction stage was implemented to increase the accuracy of Adware detection and reduce the time overhead. The number of relevant features used in training was reduced from 79 to 13 to improve the efficiency and simplify the deployment of AdStop. In experiments, the tool had an accuracy of 98.02% with a false positive rate of 2% and a false negative rate of 1.9%. The time overhead was 5.54 s for training and 9.36 µs for a single instance in the testing phase. In tests, AdStop outperformed other methods described in the literature. It is an accurate and lightweight tool for detecting mobile adware.}
}
