@article{DBLP:journals/compsec/TangQJLD23,
	author = {Yonghe Tang and
                  Xuyan Qi and
                  Jing Jing and
                  Chunling Liu and
                  Weiyu Dong},
	title = {{BHMDC:} {A} byte and hex n-gram based malware detection and classification
                  method},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103118},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103118},
	doi = {10.1016/J.COSE.2023.103118},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/TangQJLD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, malware and their variants have proliferated, which poses a grave threat to the systems and networks’ security, so it is urgent to detect and classify malware in time to prevent the spread of malicious activities. However, the existing malware detection and classification methods can't meet the requirement of the application perfectly. Among them, machine learning-based approaches generally face the dilemma of balancing efficiency and accuracy due to imperfect feature representation, while deep learning-based methods are usually computationally intense to train and deploy. In order to solve the problem, we focus on improving the feature extraction and classification model, and propose a Byte and Hex n-gram based Malware Detection and Classification method called BHMDC in this paper. For malware detection, LightGBM is used to detect malware with just 256-dimensional byte unigram features, which achieves an accuracy of more than 99.70% on two built datasets with less time consumption. For malware classification, block byte unigram and hex n-gram are proposed and combined together as the feature, which can preserve more properties and profile executable files in a multi-granular way, then random forest is used to optimize the feature by removing redundant information and reducing the dimensionality, and LightGBM is finally utilized to identify malware families. The performance of the proposed approach is evaluated through experiments, and it is compared with state-of-the-art methods. The proposed approach produces 99.264% accuracy on Microsoft malware classification challenge dataset and 99.775% accuracy on Malimg dataset respectively, which substantially outperforms the other approaches. Promising experimental results reveal that BHMDC can be used in antivirus software to detect malware variants and help security analysts to identify malware families.}
}


@article{DBLP:journals/compsec/BeuranVBCTS23,
	author = {Razvan Beuran and
                  Jan Vykopal and
                  Daniela Belajov{\'{a}} and
                  Pavel Celeda and
                  Yasuo Tan and
                  Yoichi Shinoda},
	title = {Capability Assessment Methodology and Comparative Analysis of Cybersecurity
                  Training Platforms},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103120},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103120},
	doi = {10.1016/J.COSE.2023.103120},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BeuranVBCTS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybersecurity training is a key endeavour for ensuring that the IT workforce possess the knowledge and practical skills required to counter the ever-increasing cybersecurity threats that our society is faced with. While some related systems, such as Capture The Flag platforms, have been available for almost one decade, platforms that support full-fledged cybersecurity training exercises have only been released as open source in recent years. Given the complexity of such cybersecurity training platforms, the question that arises is how to meaningfully evaluate and compare their capabilities in order to identify the most suitable solution for a given type of organization and/or training activity. In this paper, we introduce a capability assessment methodology for cybersecurity training platforms that focuses on the three key aspects of training: content representation, environment management, and training facilitation. The assessment tool that we developed is used to evaluate two open-source cybersecurity training platforms, CyTrONE and KYPO. We then conduct a comparative analysis of these two platforms based on our first-hand developer experience with them, and discuss the lessons learned from implementing, deploying and using these platforms. The assessment tool and the detailed technical comparative analysis that we conducted are intended as instruments and references for anyone who plans to deploy or develop cybersecurity training platforms.}
}


@article{DBLP:journals/compsec/SchuckertKL23,
	author = {Felix Schuckert and
                  Basel Katt and
                  Hanno Langweg},
	title = {Insecurity Refactoring: Automated Injection of Vulnerabilities in
                  Source Code},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103121},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103121},
	doi = {10.1016/J.COSE.2023.103121},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SchuckertKL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Insecurity Refactoring is a change to the internal structure of software to inject a vulnerability without changing the observable behavior in a normal use case scenario. An implementation of Insecurity Refactoring is formally explained to inject vulnerabilities in source code projects by using static code analysis. It creates learning examples with source code patterns from known vulnerabilities.}
}


@article{DBLP:journals/compsec/PourNFB23,
	author = {Morteza Safaei Pour and
                  Christelle Nader and
                  Kurt Friday and
                  Elias Bou{-}Harb},
	title = {A Comprehensive Survey of Recent Internet Measurement Techniques for
                  Cyber Security},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103123},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103123},
	doi = {10.1016/J.COSE.2023.103123},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/PourNFB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the Internet has transformed into a critical infrastructure, society has become more vulnerable to its security flaws. Despite substantial efforts to address many of these vulnerabilities by industry, government, and academia, cyber security attacks continue to increase in intensity, diversity, and impact. Thus, it becomes intuitive to investigate the current cyber security threats, assess the extent to which corresponding defenses have been deployed, and evaluate the effectiveness of risk mitigation efforts. Addressing these issues in a sound manner requires large-scale empirical data to be collected and analyzed via numerous Internet measurement techniques. Although such measurements can generate comprehensive and reliable insights, doing so encompasses complex procedures involving the development of novel methodologies to ensure accuracy and completeness. Therefore, a systematic examination of recently developed Internet measurement approaches for cyber security must be conducted to enable thorough studies that employ several vantage points, correlate multiple data sources, and potentially leverage past successful techniques for more recent issues. Unfortunately, performing such an examination is challenging, as the literature is highly scattered. In large part, this is due to each research effort only focusing on a small portion of the many constituent parts of the Internet measurement domain. Moreover, to the best of our knowledge, no studies have offered an in-depth examination of this critical research domain in order to promote future advancements. To bridge these gaps, we explore all pertinent facets of utilizing Internet measurement techniques for cyber security, ranging from threats within specific application domains to threats themselves. We provide a taxonomy of cyber security-related Internet measurement studies across two dimensions. One dimension relates to the many vertical layers (and components) of the Internet ecosystem, while the other relates to internal normal functions vs. the negative impact of external parties in the Internet and physical world. A comprehensive comparison of the gathered studies is also offered in terms of measurement technique, scope, measurement size, vantage size, and the analysis approach that was leveraged. Finally, a discussion of the roadblocks to performing effective Internet measurements and possible future research directions is elaborated.}
}


@article{DBLP:journals/compsec/WuLZYWFC23,
	author = {Yinwei Wu and
                  Meijin Li and
                  Qi Zeng and
                  Tao Yang and
                  Junfeng Wang and
                  Zhiyang Fang and
                  Luyu Cheng},
	title = {DroidRL: Feature selection for android malware detection with reinforcement
                  learning},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103126},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103126},
	doi = {10.1016/J.COSE.2023.103126},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WuLZYWFC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the completely open-source nature of Android, the exploitable vulnerability of malware attacks is increasing. Machine learning, leading to a great evolution in Android malware detection in recent years, is typically applied in the classification phase. Since the correlation between features is ignored in some traditional ranking-based feature selection algorithms, applying wrapper-based feature selection models is a topic worth investigating. Though considering the correlation between features,  wrapper-based approaches are time-consuming for exploring all possible valid feature subsets when processing a large number of Android features. To reduce the computational expense of wrapper-based feature selection, a framework named DroidRL is proposed. The framework deploys DDQN algorithm to obtain a subset of features which can be used for effective malware classification. To select a valid subset of features over a larger range, the exploration-exploitation policy is applied in the model training phase. The recurrent neural network (RNN) is used as the decision network of DDQN to give the framework the ability to sequentially select features. Word embedding is applied for feature representation to enhance the framework’s ability to find the semantic relevance of features. The framework’s feature selection exhibits high performance without any human intervention and can be ported to other feature selection tasks with minor changes. The experiment results show a significant effect when using the Random Forest as DroidRL’s classifier, which reaches 95.6% accuracy with only 24 features selected.}
}


@article{DBLP:journals/compsec/QamarAA23,
	author = {Sara Qamar and
                  Zahid Anwar and
                  Mehreen Afzal},
	title = {A systematic threat analysis and defense strategies for the metaverse
                  and extended reality systems},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103127},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103127},
	doi = {10.1016/J.COSE.2023.103127},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QamarAA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development and evolution of immersive technologies there are growing concerns of security and privacy threats to the metaverse and extended reality (XR) systems. Immersive reality solutions are a combination of multiple vulnerable technologies allowing attackers to easily undermine security. Furthermore the deployment of appropriate security controls and defensive mechanisms for resource constrained proprietary XR products has been limited. In this paper, we provide a comprehensive overview of extended reality systems and the metaverse with emphasis on technology weaknesses, cyber security challenges and users’ safety concerns. Five major taxonomies have been presented in this research with an aim of identifying privacy inference vectors and potential cyber threats; determining the impact on human health and the extent to which cyberstalking, and digital currency scam activities proliferate when using XR. This research also proposes strategies for primary lines of defense and provides recommendations on the adoption of safety measures.}
}


@article{DBLP:journals/compsec/CharmanasMA23,
	author = {Konstantinos Charmanas and
                  Nikolaos Mittas and
                  Lefteris Angelis},
	title = {Topic and influence analysis on technological patents related to security
                  vulnerabilities},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103128},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103128},
	doi = {10.1016/J.COSE.2023.103128},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CharmanasMA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Security vulnerabilities have become a rapidly growing threat for various industries and application users. To overcome these issues and maintain their products’ credibility, organizations and individuals develop mitigating techniques that are patented for copyright protection. The goal of this study is to extract and synthesize knowledge about patented inventions that address weaknesses of information systems and are generally deployed by firms to maintain security from potential breaches. To achieve this goal, we apply a variety of techniques based on text mining and citation network analysis. The applied methodologies lead in reviewing the current state, depicting relations between the innovations, identifying the general topics extracted from the patents’ descriptions and assessing the firms’ positioning in the technological field of security vulnerabilities. The findings can be used as knowledge map for determining current trends, assessing innovation, developing novel ideas and conduct studies regarding products and competitors related to security vulnerabilities.}
}


@article{DBLP:journals/compsec/XingSK23,
	author = {Ying Xing and
                  Hui Shu and
                  Fei Kang},
	title = {PeerRemove: An adaptive node removal strategy for {P2P} botnet based
                  on deep reinforcement learning},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103129},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103129},
	doi = {10.1016/J.COSE.2023.103129},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XingSK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Botnets have become one of the major intrusion threats to cybersecurity. P2P botnets have high concealment and resilience because of their distributed structure, which are difficult to be completely dismantled and destroyed. Existing methods based on traffic statistics and vulnerability tracing cannot effectively solve the problem of P2P botnet disintegration. Although P2P networks emphasize that each node is peer-to-peer, the difference in processing power, resource distribution, and node bandwidth can lead to a certain heterogeneity. The critical nodes bridge the underlying bot nodes and the upper control server. Traditional methods for ranking the importance of nodes mainly relies on classical graph-theoretic feature statistics method, such as degree, betweenness, clustering coefficient, feature vector centrality, PageRank, etc. In this paper, botnet defense strategies are investigated from the perspective of complex network graph theory, and graph embedding and deep reinforcement learning combination optimization methods are adopted to handle the critical nodes identification problem of P2P botnets. Then, a novel adaptive node removal model called PeerRemove is proposed. The model uses Structure2vec graph embedding to characterize the network structure information as a low-dimensional embedding space, and it uses n-step Q-learning to train the model to learn complex topological patterns to find the critical nodes that effectively disintegrate the network. To evaluate the effectiveness of the proposed method, the Area Under the Curve (AUC) of the Largest Connected Component (LCC) size during node removal is used as an evaluation indicator, and six different types real or synthetic P2P botnets are selected, namely Sality, ZeroAccess, NSIS, Mozi, Gnutella, and Peer sampling service. Experiments are conducted on many real and model networks with node sizes reaching thousands and tens of thousands, and our method is compared with five classical static or dynamic node attack methods of HAD, PageRank, CI, BPD, and HPRA. The experimental results show that the overall AUC curve of the PeerRemove method is lower than that of the benchmark method, which can minimize botnet resiliency at a small cost. The proposed method is superior to the existing node removal methods and shows good robustness and feasibility. To demonstrate the generality of this method, it is tested on a centralized topological dataset and good experimental results are obtained.}
}


@article{DBLP:journals/compsec/WeickertJC23,
	author = {Tobias D. Weickert and
                  Adam N. Joinson and
                  Barnaby Craggs},
	title = {Is cybersecurity research missing a trick? Integrating insights from
                  the psychology of habit into research and practice},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103130},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103130},
	doi = {10.1016/J.COSE.2023.103130},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WeickertJC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The idea that people should form positive security habits is gaining increasing attention amongst security practitioners. Habit is a well-studied concept in psychology, but the extent to which the richness of that literature has been fully utilised for security is currently unclear. In order to address this gap, we compared usage of the term “habit”—and connected constructs —in the cybersecurity and habit fields using a co-occurrence networks-based analysis. We aimed to answer three research questions: 1. What is the context within which habit has been discussed in the habit literature and the cybersecurity literature; 2. How does the discussion in these two fields compare; and 3. What are the implications of the outcomes of this analysis for the future research agenda for cybersecurity behaviour? The analysis showed that the habit construct tended to be discussed primarily in the context of other models, rather than on its own. The depth of discussion was therefore limited; resulting gaps in knowledge have important implications for security, like the idea that habits moderate the relationship between intention and behaviour. Given the popularity of the theory of planned behaviour in security research, this represents a key omission. Furthermore, the cybersecurity literature we surveyed contained very little discussion surrounding methods for formation and changing of habits, nor of the role of cues in triggering habitual behaviours. Habits require a different behaviour change approach than intentional behaviours, and many day-to-day security behaviours may in fact be habits. For that reason, these topics represents a potentially productive avenue of research for both security and privacy behaviour.}
}


@article{DBLP:journals/compsec/WangJTWH23,
	author = {Wei Wang and
                  Songlei Jian and
                  Yusong Tan and
                  Qingbo Wu and
                  Chenlin Huang},
	title = {Robust unsupervised network intrusion detection with self-supervised
                  masked context reconstruction},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103131},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103131},
	doi = {10.1016/J.COSE.2023.103131},
	timestamp = {Tue, 02 May 2023 16:30:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangJTWH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern network intrusion detection systems always utilize deep learning to improve their intelligence and feature learning abilities. To overcome the difficulties of accessing a large amount of labeled data and achieve early warning, lots of intrusion detection systems focus on unsupervised anomaly detection methods. However, most unsupervised anomaly detection methods ignore the temporal context and anomaly contamination in network intrusion data, which leads to suboptimal detection results. By considering the above practical problems, we propose a robust unsupervised intrusion detection system, i.e, RUIDS, by introducing a masked context reconstruction module into a transformer-based self-supervised learning scheme. The self-supervised learning scheme is designed to learn the intrinsic relationship within temporal contexts. And the masked context reconstruction module can learn more robust representations which are less sensitive to anomaly contamination. Extensive experiments on four intrusion datasets are conducted to show the effectiveness and robustness of RUIDS. Specifically, RUIDS achieves 9.04% and 9.58% improvements over the second-best method on the UNSW-NB15 and CICIDS-WED datasets in terms of AUC value respectively. We also test the robustness of our method with different anomaly contamination ratios, and our algorithm’s performance has hardly decreased. The ablation study confirmed the effectiveness of the self-supervised learning scheme and the masked context reconstruction module.}
}


@article{DBLP:journals/compsec/LiangWZC23,
	author = {Jianbing Liang and
                  Suxia Wang and
                  Shuang Zhao and
                  Shuhui Chen},
	title = {{FECC:} {DNS} tunnel detection model based on {CNN} and clustering},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103132},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103132},
	doi = {10.1016/J.COSE.2023.103132},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiangWZC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the basic service of the network, the Domain Name System (DNS) is almost never blocked by the firewall. DNS tunnel takes advantage of this feature of DNS service to achieve barrier-free communication between the internal network and the external network, thereby implementing malicious network activities such as data theft and Command & Control (C2) control. As an intrusion means, DNS tunnel constitutes a serious threat to network security. At present, some research work on DNS tunnel detection is implemented based on manual features, which are “explicit” features. DNS tunnels can specifically circumvent these “explicit” features as they are designed, rendering detection methods ineffective. Additionally, the quality of these manual features also relies heavily on expert knowledge. The features extracted by the detection method based on convolutional neural network (CNN) have the characteristics of “implicit” that are not easily circumvented by DNS tunnels. However, the homogeneity and exclusivity of features are not considered in the existing research works that only perform the model training for classification tasks on datasets with limited sample types. This can cause the model to fail when detecting variants or new types of DNS tunnels. This paper proposes a novel DNS tunnel detection model, called FECC (Feature Extraction CNN and Clustering), to effectively detect various DNS Tunnel traffic. FECC takes the payload of the transport layer as input without preprocessing. The model uses a CNN-based module to extract features, then the homogeneity and exclusivity of features are evaluated based on the clustering method. FECC uses a cluster-based loss function to optimize the model parameters, which greatly improves the detection rate of the model for both classification tasks and unknown types of DNS tunnels, and further reduces the false positive rate. We have deployed a variety of DNS tunnel tools in the laboratory environment and constructed multiple datasets for sufficient comparison experiments. The experimental results show that FECC is a very effective DNS tunnel detection model.}
}


@article{DBLP:journals/compsec/CostaDGS23,
	author = {Gabriele Costa and
                  Pierpaolo Degano and
                  Letterio Galletta and
                  Simone Soderi},
	title = {Formally verifying security protocols built on watermarking and jamming},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103133},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103133},
	doi = {10.1016/J.COSE.2023.103133},
	timestamp = {Tue, 12 Sep 2023 07:58:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CostaDGS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical layer security mechanisms use primitives that exploit physical properties of the communication channel to protect data. Protecting communications at the physical layer offers some advantages, e.g., in terms of reduced computations, since complex cryptographic procedures are not executed, However, these mechanisms lack a formal specification that prevent protocols and applications that use them from being verified and compared with those based on cyptography. Here we start filling this gap by providing an axiomatization of key physical layer security primitives and proposing a variant of the Dolev–Yao attacker model that takes them into account. We show that our formalization enables applying existing automatic tools for verifying security of protocols. Then, we show that these primitives are a valuable alternative and effective complement to cryptography, because they ensure confidentiality and integrity but require a lower energy consumption and often they also reduce transmission time. Finally, we characterize the specific application domains and network features that make adopting these security mechanisms particularly profitable with respect to the AES cypher.}
}


@article{DBLP:journals/compsec/LingWZQDCQWJLWW23,
	author = {Xiang Ling and
                  Lingfei Wu and
                  Jiangyu Zhang and
                  Zhenqing Qu and
                  Wei Deng and
                  Xiang Chen and
                  Yaguan Qian and
                  Chunming Wu and
                  Shouling Ji and
                  Tianyue Luo and
                  Jingzheng Wu and
                  Yanjun Wu},
	title = {Adversarial attacks against Windows {PE} malware detection: {A} survey
                  of the state-of-the-art},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103134},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103134},
	doi = {10.1016/J.COSE.2023.103134},
	timestamp = {Tue, 11 Jun 2024 10:44:02 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LingWZQDCQWJLWW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware has been one of the most damaging threats to computers that span across multiple operating systems and various file formats. To defend against ever-increasing and ever-evolving malware, tremendous efforts have been made to propose a variety of malware detection that attempt to effectively and efficiently detect malware so as to mitigate possible damages as early as possible. Recent studies have shown that, on the one hand, existing machine learning (ML) and deep learning (DL) techniques enable superior solutions in detecting newly emerging and previously unseen malware. However, on the other hand, ML and DL models are inherently vulnerable to adversarial attacks in the form of adversarial examples, which are maliciously generated by slightly and carefully perturbing the legitimate inputs to misbehave. Adversarial attacks are initially studied in the domain of computer vision like image classification, and then quickly extended to other domains, including natural language processing, audio recognition, and even malware detection. In this paper, we focus on malware with the file format of portable executable (PE) in the family of Windows operating systems, namely Windows PE malware, as a representative case to study the adversarial attack methods in such adversarial settings. To be specific, we start by first outlining the general learning framework of Windows PE malware detection based on ML/DL and subsequently highlighting three unique challenges of performing adversarial attacks in the context of Windows PE malware. Then, we conduct a comprehensive and systematic review to categorize the state-of-the-art adversarial attacks against PE malware detection, as well as corresponding defenses to increase the robustness of Windows PE malware detection. Finally, we conclude the paper by first presenting other related attacks against Windows PE malware detection beyond the adversarial attacks and then shedding light on future research directions and opportunities.}
}


@article{DBLP:journals/compsec/HeLQD23,
	author = {Xianglong He and
                  Yuezun Li and
                  Haipeng Qu and
                  Junyu Dong},
	title = {Improving transferable adversarial attack via feature-momentum},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103135},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103135},
	doi = {10.1016/J.COSE.2023.103135},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HeLQD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transferable adversarial attackusing adversarial perturbations made on known models to attack unknown modelshas made significant progress in recent years. The feature-level adversarial approach, in particular, is one of the most common solutions and can improve transferability by disrupting intermediate features, regardless of the task-specific loss objectives. Once the intermediate features are disrupted, the subsequent prediction will naturally go wrong. To accomplish this, the existing methods often start an attack by creating a guidance map on features that shows the importance level of each feature element, and then they use an iterative strategy to disrupt the features based on the guidance map. However, the drawback of existing methods is that the guidance map is always fixed in iterations, which can not consistently reflect the importance of feature elements, limiting the performance of the attack consequently. In this paper, we describe a new method called Feature-Momentum Adversarial Attack (FMAA) to enhance transferability. The key idea is that we estimate a guidance map dynamically at each iteration using a momentum-style approach to effectively disturb the features. Extensive experiments demonstrate that our method significantly outperforms other state-of-the-art methods by a large margin on different target models.}
}


@article{DBLP:journals/compsec/OgbanufeG23,
	author = {Obi Ogbanufe and
                  Ling Ge},
	title = {A comparative evaluation of behavioral security motives: Protection,
                  intrinsic, and identity motivations},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103136},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103136},
	doi = {10.1016/J.COSE.2023.103136},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/OgbanufeG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study examines the contrast between three motivation theories (identity, protection, and intrinsic) and their impact on two forms of security behaviors (in-role and extra-role). The information security literature has informed much of our understanding of how individuals are motivated to perform security behaviors, with a predominant focus on the Protection Motivation and Intrinsic Motivation theories. We draw from recent insights from the Identity Theory and its explanation of behaviors in the workplace to compare motivations toward in-role and extra-role security behaviors. Whereas identity is influential in positively motivating in-role and extra-role behaviors, intrinsic motivation does not influence in-role behaviors, and protection motivation reduces extra-role behaviors. These results provide insights on the role that identity plays as a capable motivation with implications for research and practice.}
}


@article{DBLP:journals/compsec/ReevesCD23,
	author = {Andrew Reeves and
                  Dragana Calic and
                  Paul H. Delfabbro},
	title = {"Generic and unusable"\({}^{\mbox{1}}\): Understanding employee perceptions
                  of cybersecurity training and measuring advice fatigue},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103137},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103137},
	doi = {10.1016/J.COSE.2023.103137},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ReevesCD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Security Education Training and Awareness (SETA) programs often fail to reduce organisational cyber risk, and this is linked to the way that employees perceive and appraise such programs. Rather than improving employee awareness, a poorly implemented SETA program may cause fatigue and result in risky cyber behaviours. This paper describes two studies aimed respectively at examining how SETA programs can lead to fatigue and development of a measure of SETA Advice-Related Cybersecurity Fatigue. In Study 1, a repertory grid technique was used to examine employee responses to a series of SETA videos. A total of 24 in-depth semi-structured interviews were conducted with individuals from a variety of industries. Key themes related to the content, style, and design, of cybersecurity training videos, but also employees’ perceived characteristics of the intended audience and broader preconceptions of cybersecurity principles. In Study 2, we developed the Cybersecurity Advice Fatigue Scale (CAFS) Scale, a self-report measure of the fatigue which results from poor cybersecurity advice. A principal component analysis of CAFS scores for 457 working adults revealed a five-factor structure that broadly aligns with the themes identified by the qualitative analyses of Study 1. The results of both studies highlight that employees make inferences about the corporate motivation behind the SETA program, and this influences their receptivity to the content. From an applied perspective, cybersecurity practitioners can use the CAFS to identify features of their cybersecurity training programs which should be improved to enhance the program's efficacy.}
}


@article{DBLP:journals/compsec/DuncanC23,
	author = {Shawn P. Duncan and
                  Hui Chen},
	title = {Detecting network-based internet censorship via latent feature representation
                  learning},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103138},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103138},
	doi = {10.1016/J.COSE.2023.103138},
	timestamp = {Thu, 11 May 2023 16:52:21 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/DuncanC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet censorship is a phenomenon of societal importance and attracts investigation from multiple disciplines. Several research groups, such as Censored Planet, have deployed large scale Internet measurement platforms to collect network reachability data. However, existing studies generally rely on manually designed rules (i.e., using censorship fingerprints) to detect network-based Internet censorship from the data. While this rule-based approach yields a high true positive detection rate, it suffers from several challenges: it requires human expertise, is laborious, and cannot detect any censorship not captured by the rules. Seeking to overcome these challenges, we design and evaluate a classification model based on latent feature representation learning and an image-based classification model to detect network-based Internet censorship. To infer latent feature representations from network reachability data, we propose a sequence-to-sequence autoencoder to capture the structure and the order of data elements in the data. To estimate the probability of censorship events from the inferred latent features, we rely on a densely connected multi-layer neural network model. Our image-based classification model encodes a network reachability data record as a gray-scale image and classifies the image as censored or not using a dense convolutional neural network. We compare and evaluate both approaches using data sets from Censored Planet via a hold-out evaluation. Both classification models are capable of detecting network-based Internet censorship as we were able to identify instances of censorship not detected by the known fingerprints. Latent feature representations likely encode more nuances in the data since the latent feature learning approach discovers a greater quantity, and a more diverse set, of new censorship instances.}
}


@article{DBLP:journals/compsec/MouratidisIPSI23,
	author = {Haralambos Mouratidis and
                  Shareeful Islam and
                  Antonio Santos{-}Olmo and
                  Luis Enrique S{\'{a}}nchez and
                  Umar Mukhtar Ismail},
	title = {Modelling language for cyber security incident handling for critical
                  infrastructures},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103139},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103139},
	doi = {10.1016/J.COSE.2023.103139},
	timestamp = {Mon, 29 Apr 2024 21:26:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MouratidisIPSI23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber security incident handling is a consistent methodology with which to ensure overall business continuity. However, specifically handling incidents for critical information infrastructures is challenging owing to the inherent complexity and evolving nature of the threat. Despite the number of contributions made to cyber incident handling, there is little evidence of literature that focuses on modelling activities that will enhance developers’ abilities to model incident handling processes and activities according to different views. Modelling languages of this nature should integrate essential concepts and a descriptive implementation process in order to enable developers to analyse, represent and reason about the crucial incident handling efforts required to support critical information infrastructures. The aim of this paper is, as part of the CyberSANE EU project, to develop a Cyber Incident Handling Modelling Language (CIHML) that focuses explicitly on modelling incident handling in the context of a critical information infrastructure. The work is innovative in its approach because it consolidates concepts from various domains such as security requirements, forensics, threat intelligence, critical infrastructures and cyber incident handling. The approach will allow the phases of the incident handling lifecycle to be modelled from three different views (critical information infrastructures, threat and risk analysis, and incident response). An implementation process is also proposed, which will serve as a comprehensive guide for developers in order to create these modelling views. Finally, CIHML is evaluated using a real-life scenario from the CyberSANE project to demonstrate its applicability. The incident observed had a severe impact on the overall business continuity of the context studied. The results obtained from the study show that CIHML can help critical information infrastructure operators to identify, evaluate, represent and model cyber incidents in critical information systems, in addition to providing the support required to determine the response strategies needed in order to mitigate these cyber-attacks.}
}


@article{DBLP:journals/compsec/WongCOZ23,
	author = {Ann Yi Wong and
                  Eyasu Getahun Chekole and
                  Mart{\'{\i}}n Ochoa and
                  Jianying Zhou},
	title = {On the Security of Containers: Threat Modeling, Attack Analysis, and
                  Mitigation Strategies},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103140},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103140},
	doi = {10.1016/J.COSE.2023.103140},
	timestamp = {Mon, 26 Jun 2023 20:53:56 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WongCOZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditionally, applications that are used in large and small enterprises were deployed on “bare metal” servers installed with operating systems. Recently, the use of multiple virtual machines (VMs) on the same physical server was adopted due to cost reduction and flexibility. Nowadays, containers have become popular for application deployment due to smaller footprints than the VMs, their ability to start and stop more quickly, and their capability to pack the application binaries and their dependencies/libraries in standalone units for seamless portability. A typical container ecosystem includes a code repository (e.g., GitHub) where the container images are built from the codes and libraries and then pushed to the image registry (e.g., Docker Hub) for subsequent deployment as application containers. However, the pervasive use of containers also leads to a wide-range of security breaches such as attackers stealing credentials, source codes and sensitive data from image registry and code repository, carrying out DoS attacks on application containers, and gaining root access to misuse the underlying host resources, among others. In this paper, we first perform threat modeling on the containers ecosystem using the popular threat modeling framework, called STRIDE. Using STRIDE, we identify the vulnerabilities in each system component, and investigate potential security threats and their consequences. Then, we conduct a comprehensive survey on the existing countermeasures designed against the identified threats and vulnerabilities in containers. In particular, we assess the strengths and weaknesses of the existing mitigation strategies designed against such threats. We believe that this work will help researchers and practitioners to gain a deeper understanding of the threat landscape in containers and the state-of-the-art countermeasures. We also discuss open research problems, the research gaps and future research directions in containers security, which may ignite further research to be done in this area.}
}


@article{DBLP:journals/compsec/XiongLL23,
	author = {Wen Ding Xiong and
                  Kai Lun Luo and
                  Rui Li},
	title = {{AIDTF:} Adversarial training framework for network intrusion detection},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103141},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103141},
	doi = {10.1016/J.COSE.2023.103141},
	timestamp = {Wed, 19 Apr 2023 16:32:39 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XiongLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network Intrusion Detection Systems (IDS) have achieved high accuracy by widely applying Machine Learning (ML) models. However, most current ML-based IDSs can not cope with targeted attacks from adversaries because they are commonly trained and tested using fixed data sets. In this paper, we propose an Adversarial Intrusion Detection Training Framework (AIDTF) to improve the robustness of IDSs, which consists of an attacker model a-model, a defender model d-model, and a black-box trainer t-module. Both the a-model and d-model are multilayer perceptrons, and the t-module is the module used to train IDSs. AIDTF improves the accuracy of IDS by using an adversarial training method, which is different from traditional training methods. Taking the distribution of normal samples in the dataset as the distribution that the a-model and d-model need to learn, the goal of the a-model is to generate samples that deceive the d-model, while the goal of the d-model is to determine whether the input samples are real samples, so there is an adversarial relationship between a-model and d-model. Different types of IDSs can be trained by the t-module using the samples generated from the confrontation between the a-model and the d-model, and we call this kind of IDS the Adversarial Training Intrusion Detection System (ATIDS). The main contribution of this paper is to propose a training method that is used to obtain an IDS with high accuracy not only for known test sets but also to identify unknown disguised attack samples. We tested different types of ATIDSs using the current mainstream attack methods, which include the Fast Gradient Method, Fast Gradient Sign Method, Projected Gradient Descent, and Jacobs Saliency Map Algorithm. The experimental results prove that AIDTF outperforms other adversarial training methods with not only higher accuracy for the test set but also up to a 99% recognition rate for the attack samples.}
}


@article{DBLP:journals/compsec/GaoY23,
	author = {Chen Gao and
                  Jia Yu},
	title = {SecureRC: {A} system for privacy-preserving relation classification
                  using secure multi-party computation},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103142},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103142},
	doi = {10.1016/J.COSE.2023.103142},
	timestamp = {Wed, 19 Apr 2023 16:32:39 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GaoY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Natural Language Processing (NLP) transforms human language into machine language that can be understood by machines through computer technology. Relation classification is an important semantic extraction task in NLP, which can accurately obtain the semantic relationship between two entities in a text. It has been used extensively in many NLP applications, such as information extraction and question answering. Relation classification can extract accurately relationships between two entities from large amounts of linguistic data. However, collecting such vast amounts of data in relation classification poses serious privacy issues. As far as we know, there is no existing work that implements privacy-preserving relation classification task. In this paper, we consider how to implement privacy-preserving relation classification using attention-based gated recurrent unit (GRU) network. Specifically, we first design three basic privacy-preserving protocols for the non-linear functions (sigmoid and tanh) using secure multi-party computation (MPC). Then, we propose a secure computation protocol SecureGRU for the GRU network based on these three basic protocols. Finally, based on the SecureGRU and the attention mechanism, we obtain the privacy-preserving relation classification system SecureRC. In the semi-honest adversary model, we prove the security of these protocols. Any honest-but-curious adversary is not able to obtain anything beyond what he is allowed to learn. The proposed system is implemented in Python. Experimental results demonstrate the performance of our proposed protocols.}
}


@article{DBLP:journals/compsec/WangT23,
	author = {Zihao Wang and
                  Vrizlynn L. L. Thing},
	title = {Feature mining for encrypted malicious traffic detection with deep
                  learning and other machine learning algorithms},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103143},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103143},
	doi = {10.1016/J.COSE.2023.103143},
	timestamp = {Sun, 22 Oct 2023 11:15:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The popularity of encryption mechanisms poses a great challenge to malicious traffic detection. The reason is traditional detection techniques cannot work without the decryption of encrypted traffic. Currently, research on encrypted malicious traffic detection without decryption has focused on feature extraction and the choice of machine learning or deep learning algorithms. In this paper, we first provide an in-depth analysis of traffic features and compare different state-of-the-art traffic feature creation approaches, while proposing a novel concept for encrypted traffic feature which is specifically designed for encrypted malicious traffic analysis. In addition, we propose a framework for encrypted malicious traffic detection. The framework is a two-layer detection framework which consists of both deep learning and traditional machine learning algorithms. Through comparative experiments, it outperforms classical deep learning and traditional machine learning algorithms, such as ResNet and Random Forest. Moreover, to provide sufficient training data for the deep learning model, we also curate a dataset composed entirely of public datasets. The composed dataset is more comprehensive than using any public dataset alone. Lastly, we discuss the future directions of this research.}
}


@article{DBLP:journals/compsec/ZhangCLW23,
	author = {Tianyue Zhang and
                  Wei Chen and
                  Yuxiao Liu and
                  Lifa Wu},
	title = {An intrusion detection method based on stacked sparse autoencoder
                  and improved gaussian mixture model},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103144},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103144},
	doi = {10.1016/J.COSE.2023.103144},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangCLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The analysis of a substantial portion of network data is a requirement for almost any machine learning-based network intrusion detection method. High dimension features, a lack of labelled datasets, and inflexible feature selection are some of the difficulties it encounters. This paper proposes an intrusion detection method based on stacked sparse autoencoder and improved Gaussian mixture model (SIGMOD). The method utilizes the stacked sparse autoencoder to produce non-linear dimensionality reduction after first using the Pearson correlation coefficient to achieve linear dimensionality reduction. It can lessen redundant data, obtain low-dimensional features and generate reconstruction errors of the samples, which are subsequently fed into the improved Gaussian mixture model. The method finally judges whether it is abnormal according to the output sample energy threshold of the improved Gaussian mixture model. Unlike the traditional anomaly detection technology that performs dimensionality reduction and clustering in two separate steps, SIGMOD jointly optimizes the parameters of the stacked sparse autoencoder and the Gaussian mixture model in an end-to-end manner, avoiding the key feature loss of cluster analysis or probability density estimation in dimensionality reduction by the two-step method. The experiment results on the UNSW-NB15 dataset demonstrate that SIGMOD performs significantly better than the conventional anomaly detection approach.}
}


@article{DBLP:journals/compsec/AabyGBT23,
	author = {Peter Aaby and
                  Mario Valerio Giuffrida and
                  William J. Buchanan and
                  Zhiyuan Tan},
	title = {An omnidirectional approach to touch-based continuous authentication},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103146},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103146},
	doi = {10.1016/J.COSE.2023.103146},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AabyGBT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper focuses on how touch interactions on smartphones can provide a continuous user authentication service through behaviour captured by a touchscreen. While efforts are made to advance touch-based behavioural authentication, researchers often focus on gathering data, tuning classifiers, and enhancing performance by evaluating touch interactions in a sequence rather than independently. However, such systems only work by providing data representing distinct behavioural traits. The typical approach separates behaviour into touch directions and creates multiple user profiles. This work presents an omnidirectional approach which outperforms the traditional method independent of the touch direction - depending on optimal behavioural features and a balanced training set. Thus, we evaluate five behavioural feature sets using the conventional approach against our direction-agnostic method while testing several classifiers, including an Extra-Tree and Gradient Boosting Classifier, which is often overlooked. Results show that in comparison with the traditional, an Extra-Trees classifier and the proposed approach are superior when combining strokes. However, the performance depends on the applied feature set. We find that the TouchAlytics feature set outperforms others when using our approach when combining three or more strokes. Finally, we highlight the importance of reporting the mean area under the curve and equal error rate for single-stroke performance and varying the sequence of strokes separately.}
}


@article{DBLP:journals/compsec/LiLLWL23,
	author = {Yuzhe Li and
                  Yong Liu and
                  Bo Li and
                  Weiping Wang and
                  Nan Liu},
	title = {Towards practical differential privacy in data analysis: Understanding
                  the effect of epsilon on utility in private {ERM}},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103147},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103147},
	doi = {10.1016/J.COSE.2023.103147},
	timestamp = {Sun, 12 Nov 2023 02:17:58 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiLLWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As computation over sensitive data has been an important goal in recent years, privacy-preserving data analysis has gradually attracted more and more attention. Among various mechanisms, differential privacy has been widely studied due to its formal privacy guarantees for data analysis. As one of the most important issues, the crucial trade-off between the strength of privacy guarantee and the effect of analysis accuracy is highly concerned among the researchers. Existing theories for this issue consider that the analyst should first choose a privacy requirement and then attempt to maximize the utility. However, as differential privacy is gradually deployed in practice, a gap between theory and practice comes out: in practice, product requirements often impose hard accuracy constraints, and privacy (while desirable) may not be the over-riding concern. Thus, it is usually that the requirement of privacy guarantee is adjusted according to the utility expectation, not the other way around. This gap raises the question of how to provide maximum privacy guarantee for data analysis due to a given accuracy requirement. In this paper, we focus our attention on private Empirical Risk Minimization (ERM), which is one of the most commonly used data analysis method. We take the first step towards solving the above problem by theoretically exploring the effect of\nϵ\n(the parameter of differential privacy that determines the strength of privacy guarantee) on utility of the learning model. We trace the change of utility with modification of\nϵ\nand reveal an established relationship between\nϵ\nand utility. We then formalize this relationship and propose a practical approach for estimating the utility under an arbitrary value of\nϵ\n. Both theoretical analysis and experimental results demonstrate high estimation accuracy and broad applicability of our approach in practical applications. As providing algorithms with strong utility guarantees that also give privacy when possible becomes more and more accepted, our approach would have high practical value and may be likely to be adopted by companies and organizations that would like to preserve privacy but are unwilling to compromise on utility.}
}


@article{DBLP:journals/compsec/NirmalapriyaMLN23,
	author = {G. Nirmalapriya and
                  Balajee Maram and
                  Ramanathan Lakshmanan and
                  M. Navaneethakrishnan},
	title = {ASCA-squeeze net: Aquila sine cosine algorithm enabled hybrid deep
                  learning networks for digital image forgery detection},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103155},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103155},
	doi = {10.1016/J.COSE.2023.103155},
	timestamp = {Mon, 26 Jun 2023 20:53:56 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NirmalapriyaMLN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The basic element in resolving numerous challenges, particularly social concerns like those in court cases and Facebook, is image forgery detection. The primary objective of this study is to build and develop an effective system for detecting digital image forgery utilising the recently proposed technique called the Aquila Sine Cosine Algorithm (ASCA). The forgery from the digital image is detected in this study using a hybrid deep learning technique that incorporates Deep Convolutional Neural Network (DCNN) and Squeeze Net. Additionally, the training time and computational complexity of the detection process are decreased by updating the weight of both the DCNN and the Squeeze Net using the developed ASCA technique. Additionally, the developed ASCA is produced by combining the update functions of the Aquila Optimizer (AO) with the Sine Cosine Algorithm (SCA). As a result, the hybrid deep learning classifier provides the classified output as either the authentic image or the forged image using a copy-move forgery detection dataset. The experimentation of the developed model has provided higher performance, as shown by testing accuracy, True Positive Rate (TPR), and True Negative Rate (TNR) of 0.980, 0.976, and 0.956, respectively. Furthermore, by varying the iteration, testing accuracy, TNR, and TPR obtained by the devised technique are 0.944, 0.947, and 0.936, and by varying the population size obtained testing accuracy values of 1, TNR values of 1.003, and TPR values of 0.991, respectively, by algorithmic analysis.}
}


@article{DBLP:journals/compsec/LiLCZW23,
	author = {Li Li and
                  Tianfeng Li and
                  Hua Cai and
                  Jian Zhang and
                  Jianjun Wang},
	title = {I will only know after using it: The repeat purchasers of smart home
                  appliances and the privacy paradox problem},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103156},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103156},
	doi = {10.1016/J.COSE.2023.103156},
	timestamp = {Thu, 05 Oct 2023 17:14:09 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiLCZW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Research shows that smart home appliance consumers face a privacy paradox – consumers have a high perception of privacy disclosure risk; yet this has no obvious influence on their purchase behavior. The privacy paradox problem may be exaggerated, considering that most existing research has focused on potential purchasers who do not have corresponding purchase and usage experience. For repeat consumers, their perception of smart home appliances is based on their real usage experience, so they may not have such a “privacy paradox” problem unlike potential purchasers. To verify this, this study divided smart home appliance consumers into potential and repeat purchasers, based on the technology acceptance model, and comparatively analyzed the differences in the influence of perceived privacy disclosure risk and other factors on the willingness to purchase smart home appliance. We found repeat purchasers did not have a serious privacy paradox problem. Potential purchasers have a higher perception of privacy disclosure risk of smart home appliances, but this did not influence their willingness to purchase. Conversely, repeat purchasers had a lower perception of privacy risk, which had a weak influence on their willingness to repurchase. While somewhat unexpected, this result shows that repeat purchasers’ perceived privacy disclosure risks and behaviors are more consistent. Moreover, perceived usefulness was the most important factor that impacted potential purchasers’ willingness to purchase, perceived ease of use was the most important factor for repeat purchasers. Collectivism plays an active role in reducing consumers’ perceived privacy risk of smart home appliances and improving perceived usefulness and ease-of-use.}
}


@article{DBLP:journals/compsec/QinPLZCZS23,
	author = {Chuan Qin and
                  Jiaqian Peng and
                  Puzhuo Liu and
                  Yaowen Zheng and
                  Kai Cheng and
                  Weidong Zhang and
                  Limin Sun},
	title = {{UCRF:} Static analyzing firmware to generate under-constrained seed
                  for fuzzing {SOHO} router},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103157},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103157},
	doi = {10.1016/J.COSE.2023.103157},
	timestamp = {Wed, 12 Jun 2024 21:04:42 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QinPLZCZS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SOHO (small office and home office) routers are the key elements of the IoT, providing network services for various smart devices. Recent years have seen increased attacks targeting SOHO routers’ web applications. Numerous vulnerabilities are introduced in the process that web servers receive and handle external data directly. Fuzzing is the most popular technique for discovering such vulnerabilities. Previously proposed approaches generate fuzzing seeds in a valid format by analyzing the front-end. Unfortunately, the generated seeds are over-constrained by front-end code legality checks because malicious data can bypass the front-end inspection and be sent directly to the back-end. Moreover, such seeds ignore the semantics of the back-end, which makes the back-end’s checking logic hinder the fuzzing’s efficiency.}
}


@article{DBLP:journals/compsec/HoheiselCSJ23,
	author = {Raphael Hoheisel and
                  Guido van Capelleveen and
                  Dipti Kapoor Sarmah and
                  Marianne Junger},
	title = {The development of phishing during the {COVID-19} pandemic: An analysis
                  of over 1100 targeted domains},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103158},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103158},
	doi = {10.1016/J.COSE.2023.103158},
	timestamp = {Fri, 24 May 2024 10:34:11 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HoheiselCSJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To design preventive policy measures for email phishing, it is helpful to be aware of the phishing schemes and trends that are currently applied. How phishing schemes and patterns emerge and adapt is an ongoing field of study. Existing phishing works already reveal a rich set of phishing schemes, patterns, and trends that provide insight into the mechanisms used. However, there seems to be limited knowledge about how email phishing is affected in periods of social disturbance, such as COVID-19 in which phishing numbers have quadrupled. Therefore, we investigate how the COVID-19 pandemic influences the phishing emails sent during the first year of the pandemic. The email content (header data and html body, excl. attachments) is evaluated to assess how the pandemic influences the topics of phishing emails over time (peaks and trends), whether email campaigns correlate with momentous events and trends of the COVID-19 pandemic, and what hidden content revealed. This is studied through an in-depth analysis of the body of 500.000 phishing emails addressed to Dutch registered top-level domains collected during the start of the pandemic. The study reveals that most COVID-19 related phishing emails follow known patterns indicating that perpetrators are more likely to adapt than to reinvent their schemes.}
}


@article{DBLP:journals/compsec/YangMZWLKSH23,
	author = {Haitian Yang and
                  Xiang Meng and
                  Xuan Zhao and
                  Yan Wang and
                  Yuejun Liu and
                  Xiaoyu Kang and
                  Jiahui Shen and
                  Weiqing Huang},
	title = {{CKDAN:} Content and keystroke dual attention networks with pre-trained
                  models for continuous authentication},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103159},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103159},
	doi = {10.1016/J.COSE.2023.103159},
	timestamp = {Tue, 10 Oct 2023 09:03:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YangMZWLKSH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of digitalization, information security becomes more and more important. User authentication is a significant line of defense. During the past few years, many research works concentrating on user authentication have been published. Traditional authentication techniques (password, ID card-based authentication, or other biometrics like fingerprint or iris) basically fall into the category of one-time authentication. The disadvantage of these methods is that once an unknown user completes an authentication through forgery, the system would continue to operate without any resistance, thus putting the entire system at risk. Recently, due to the prevalence of deep learning techniques, some researchers have applied learning-based models to user authentication. However, almost all existing methods only focus on keystroke dynamics while ignoring the ”text” entered by users during keystrokes. In this paper, we propose contents and keystroke dual attention networks with pre-trained models for continuous authentication. To the best of our knowledge, our paper is the first to address user-inputted ”text” during keystrokes as an important asset beyond traditional characteristic keystroke dynamics. Specifically, we use the well-known pre-trained RoBERTa model to capture textual features. Then, we pass textual features and conventional features through our proposed dual attention networks. Our networks fuse these features and acquire final representations. Experiments show that the CKDAN model achieves state-of-the-art performance on two datasets, Clarkson II keystroke dataset and Buffalo dataset, outperforming all baseline methods.}
}


@article{DBLP:journals/compsec/McIntoshKCNW23,
	author = {Timothy R. McIntosh and
                  A. S. M. Kayes and
                  Yi{-}Ping Phoebe Chen and
                  Alex Ng and
                  Paul A. Watters},
	title = {Applying staged event-driven access control to combat ransomware},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103160},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103160},
	doi = {10.1016/J.COSE.2023.103160},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/McIntoshKCNW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advancement of modern Operating Systems (OSs), and the popularity of personal computing devices with Internet connectivity, have facilitated the proliferation of ransomware attacks. Ransomware has evolved from executable programs encrypting user files, to novel attack vectors including fileless command scripts, information exfiltration and human-operated ransomware. Many anti-ransomware studies have been published, but many of them assumed newer ransomware variants only performed file encryption, were similar to existing variants, and often did not consider those novel attack vectors. We have defined an updated ransomware threat model to include those novel attack vectors, and redefined false positives and false negatives in the context of ransomware mitigation. We proposed to apply both program-centric and user-centric access control to combat ransomware, but only delegate access control decisions that users are capable of making to users, while enforcing non-negotiable access control decisions by OS and software developers. We have designed a Staged Event-Driven Access Control (SEDAC) approach to incorporate both program-centric and user-centric access control measures, and demonstrated a prototype on Windows OS. Our prototype was able to intercept more types of ransomware attack vectors than existing proposals. We hope to convince OS and software architects to incorporate our design to better combat ransomware.}
}


@article{DBLP:journals/compsec/MottTNMSCC23,
	author = {Gareth Mott and
                  Sarah Turner and
                  Jason R. C. Nurse and
                  Jamie MacColl and
                  James Sullivan and
                  Anna Cartwright and
                  Edward J. Cartwright},
	title = {Between a rock and a hard(ening) place: Cyber insurance in the ransomware
                  era},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103162},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103162},
	doi = {10.1016/J.COSE.2023.103162},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MottTNMSCC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber insurance and ransomware are two of the most studied areas within security research and practice to date, and their interplay continues to raise concerns in industry and government. This article offers substantial new insights and analysis into the complex question of whether cyber insurance can help organisations in mitigating the threat of ransomware, particularly its impacts. Having conducted an interview or workshop with 96 industry professionals spanning the cyber insurance, cyber security, ransomware negotiations, policy, and law enforcement sectors, we identify that ransomware has been a key cause of the ‘hardening’ of the cyber insurance market, which is exhibited at almost all levels of the market. Such hardening has been beneficial in raising the security standards required prior to purchase, but has also created a situation where some organisations may not be able to acquire viable cyber insurance at all. In presenting the outcomes of our thematic analysis of the interview and workshop outputs, the paper provides significant new empirical evidence to support the theory that cyber insurance can act as a form of governance for improving cyber security amongst organisations. Nonetheless, the hardening market does nothing to increase the penetration of cyber insurance. Questions were also raised as to the likelihood of unintended unethical – and potentially illegal – outcomes given the professionalisation of a remediation process that has to determine the most cost-effective solution to an organisation being held ransom. We conclude that insurance, at best, can help to mitigate the ransomware threat for those that can access it, as part of a wider basket of actions that must also come from different stakeholders.}
}


@article{DBLP:journals/compsec/WangCWYL23,
	author = {Yu Wang and
                  Liquan Chen and
                  Ge Wu and
                  Kunliang Yu and
                  Tianyu Lu},
	title = {Efficient and secure content-based image retrieval with deep neural
                  networks in the mobile cloud computing},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103163},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103163},
	doi = {10.1016/J.COSE.2023.103163},
	timestamp = {Sat, 30 Sep 2023 10:07:34 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangCWYL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart devices offer a variety of more convenient forms to help us record our lives and generate a large amount of data in this process. Limited by the local storage capacity, many users outsource their image data directly to the cloud server. However, images stored in plaintext on the cloud server are very insecure, resulting in image privacy information can be easily leaked. Therefore, users will encrypt the images and outsource them to the cloud server, but the encrypted images cannot be retrieved. Therefore, we proposed a secure and efficient ciphertext image retrieval scheme based on image content retrieval (CBIR) and approximate homomorphic encryption (HE). First, we used approximate homomorphic encryption to encrypt images after resizing and uploaded the ciphertext images to the cloud for feature extraction of ciphertext. At the same time, the large images (size, dimension, and resolution) would generate data inflation after using homomorphic encryption. Therefore, the original images are encrypted using the chaotic image encryption scheme to reduce ciphertext size and computation costs. Second, we proposed two deepening network depth optimization strategies that address the problem of insufficient neural network depth. Finally, reducing the dimensionality of the ciphertext feature vector using locally sensitive hashing (LSH) can accelerate the retrieval of ciphertext images. Compared with other literature, our ciphertext image retrieval scheme can significantly reduce the rounds of user-server communication.}
}


@article{DBLP:journals/compsec/BansalTS23,
	author = {Gaurav Bansal and
                  Jason Thatcher and
                  Sebastian Walter Schuetz},
	title = {Where authorities fail and experts excel: Influencing internet users'
                  compliance intentions},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103164},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103164},
	doi = {10.1016/J.COSE.2023.103164},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BansalTS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber threats continue to rise because Internet users are often unwilling to adopt simple security behaviors. Public security messages sent by leaders could formally and informally influence Internet users to take action to protect themselves from threats. However, scant research has examined how leaders' power or expertise influences Internet users' willingness to comply with requested security behaviors. In this paper, we develop a research model using the bases of power theory and three related theories (social influence theory, psychological reactance theory, and attribution theory) to explain how security messages from authoritative and expert leaders, respectively, shape users' intentions to comply with the recommendations of a security message. Analysis of data gathered in a field experiment suggests that security messages from leaders can have positive and negative consequences. If sent by leaders with formal authority (i.e., those high in coercive power), security messages may backfire because they fail to stimulate security cognitions. In contrast, if sent by expert leaders (i.e., those high in expertise), security messages are more likely to work as intended. Our findings offer insights into how public security messages can be made more effective.}
}


@article{DBLP:journals/compsec/BrustSG23,
	author = {Clemens{-}Alexander Brust and
                  Tim Sonnekalb and
                  Bernd Gruner},
	title = {{ROMEO:} {A} binary vulnerability detection dataset for exploring
                  Juliet through the lens of assembly language},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103165},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103165},
	doi = {10.1016/J.COSE.2023.103165},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BrustSG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automatic vulnerability detection on C/C++ source code has benefitted from the introduction of machine learning to the field, with many recent publications targeting this combination. In contrast, assembly language or machine code artifacts receive less attention, although there are compelling reasons to study them. They are more representative of what is executed, more easily incorporated in dynamic analysis, and in the case of closed-source code, there is no alternative.}
}


@article{DBLP:journals/compsec/NicheliniPLCZ23,
	author = {Alessandro Nichelini and
                  Carlo Alberto Pozzoli and
                  Stefano Longari and
                  Michele Carminati and
                  Stefano Zanero},
	title = {CANova: {A} hybrid intrusion detection framework based on automatic
                  signal classification for {CAN}},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103166},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103166},
	doi = {10.1016/J.COSE.2023.103166},
	timestamp = {Tue, 12 Sep 2023 07:58:16 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NicheliniPLCZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the years, vehicles have become increasingly complex and an attractive target for malicious adversaries. This raised the need for effective and efficient Intrusion Detection Systemss (IDSs) for onboard networks able to work with the stringent requirements and the heterogeneity of information transmitted on the Controller Area Network. While state-of-the-art solutions are effective in detecting specific types of anomalies and work on a subset of the CAN signals, no single method can perform better than the others on all types of attacks, particularly if they need to provide predictions to comply with the domain’s real-time constraints. In this paper, we present CANova, a modular framework that exploits the characteristics of the different Controller Area Network (CAN) packets to select the Intrusion Detection Systemss (IDSs) that better fits them. In particular, it uses flow- and payload-based IDSs to analyze the packets’ content and arrival time. We evaluate CANova by comparing its performance against state-of-the-art Intrusion Detection Systemss (IDSs) for in-vehicle network and a comprehensive set of synthetic and real attacks in real-world CAN datasets. We demonstrate that our approach can achieve good performances in terms of detection, false positive rates, and temporal performances.}
}


@article{DBLP:journals/compsec/BovenziACMPP23,
	author = {Giampaolo Bovenzi and
                  Giuseppe Aceto and
                  Domenico Ciuonzo and
                  Antonio Montieri and
                  Valerio Persico and
                  Antonio Pescap{\`{e}}},
	title = {Network anomaly detection methods in IoT environments via deep learning:
                  {A} Fair comparison of performance and robustness},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103167},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103167},
	doi = {10.1016/J.COSE.2023.103167},
	timestamp = {Tue, 07 May 2024 20:21:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BovenziACMPP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is a key enabler in closing the loop in Cyber-Physical Systems, providing “smartness” and thus additional value to each monitored/controlled physical asset. Unfortunately, these devices are more and more targeted by cyberattacks because of their diffusion and of the usually limited hardware and software resources. This calls for designing and evaluating new effective approaches for protecting IoT systems at the network level (Network Intrusion Detection Systems, NIDSs). These in turn are challenged by the heterogeneity of IoT devices and the growing volume of transmitted data.}
}


@article{DBLP:journals/compsec/KoKK23,
	author = {Kyoungmin Ko and
                  Sunghwan Kim and
                  Hyun Kwon},
	title = {Multi-targeted audio adversarial example for use against speech recognition
                  systems},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103168},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103168},
	doi = {10.1016/J.COSE.2023.103168},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KoKK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks are widely used in fields such as image recognition, speech recognition, text recognition, and pattern recognition. However, such networks exhibit weakness against adversarial examples. An adversarial example is a sample that is correctly recognized by humans but is misclassified by the target model; it is typically created by adding a minimal amount of noise to an original sample. In this paper, we propose a method for creating a multi-targeted audio adversarial example that is designed to be misinterpreted differently by each of several models. The proposed method configures the loss function so that the probability of misclassification into the desired class for each model is highest, in order to insert the optimal amount of adversarial noise into the original sample. In the experimental evaluation, the Mozilla Voice dataset was used as the test data source, and TensorFlow was used as the machine learning library. The results show that the proposed method creates a multi-targeted adversarial example that has a 98.02% attack success rate with different classes for the three models while minimizing the distortion from the original sample to an average value of 137.28.}
}


@article{DBLP:journals/compsec/LeeLJL23,
	author = {Sun{-}Jin Lee and
                  Yu{-}Rim Lee and
                  So{-}Eun Jeon and
                  Il{-}Gu Lee},
	title = {Machine learning-based jamming attack classification and effective
                  defense technique},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103169},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103169},
	doi = {10.1016/J.COSE.2023.103169},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LeeLJL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fourth industrial revolution has resulted in the intelligent Internet of Things being widely used for home networking applications and smart infrastructure. Consequently, wireless connectivity has become essential in industrial and daily-life applications. Wireless communication is a continuously evolving technology that satisfies high-speed and ultra-low latency requirements. However, as multiple users utilize a single channel by sharing frequency and time, the service quality cannot be ensured owing to the interference from a congested network. Additionally, malicious attackers can compromise communication availability or destroy data integrity through jamming attacks, threatening human life and safety. Conventional jamming attack detection and response technology respond to attacks without detecting the type of jammer, exhibiting certain limitations in detecting and defending against an intelligent attack. This study proposes a novel jammer classification and effective defense (JCED) algorithm that can classify jamming attack types using machine learning (ML) and provide differential responses based on the jamming types. Depending on the jammer type, the JCED algorithm can adaptively select various response methods, ranging from simple retransmission to active battery-draining attacks. The experimental results verify that JCED exhibits 24.9% higher effective throughput and 23.4% lower energy consumption than the countermeasure detection and consistency algorithm (CDCA). Moreover, JCED improves the effective throughput by an average of approximately three times compared to CDCA in an environment with integrity violation attacks. Thus, the JCED is an effective defense mechanism against jamming attacks, ensuring digital information safety and high throughput.}
}


@article{DBLP:journals/compsec/SanchezGarciaGC23,
	author = {Isaac Daniel Sanchez{-}Garcia and
                  Tom{\'{a}}s San Feliu Gilabert and
                  Jos{\'{e}} Antonio Calvo{-}Manzano},
	title = {Countermeasures and their taxonomies for risk treatment in cybersecurity:
                  {A} systematic mapping review},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103170},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103170},
	doi = {10.1016/J.COSE.2023.103170},
	timestamp = {Sat, 30 Sep 2023 10:07:33 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SanchezGarciaGC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybersecurity continues to be one of the principal issues in the computing environment. Organizations and researchers have made various efforts to mitigate the risks of cyberspace. The treatment of cyber risk is a fundamental stage in risk management. In the risk treatment stage, countermeasures are carried out to reduce the probability of risk materialization. This article presents a systematic mapping review of the principal catalogues/taxonomies of countermeasures applied in cybersecurity, involving studies between 2010 and 2021. Seventy-four (74) studies were assessed, and 25 studies were selected for further analysis. We identified 26 catalogues/taxonomies used to address cybersecurity-related risks. After analyzing these 26 catalogues/taxonomies, we identified: (1) the related trends, (2) the type of risks and sectors that these catalogues/taxonomies focus on, (3) the complexity of these taxonomies, and (4) what mentions they make about residual risk. We have identified that institutional taxonomies, which were not created for cybersecurity risks, are fitted for this purpose. The predominant risks in these taxonomies are those related to awareness and cyber-attacks. We note that the complexity of the catalogues/taxonomies is defined by the number of taxa and the number of countermeasures. Another relevant result is the lack of complexity in non-institutional catalogues/taxonomies. Finally, we have identified a lack of relevant information on residual risk in the studies.}
}


@article{DBLP:journals/compsec/HanCLZJL23,
	author = {Xueying Han and
                  Susu Cui and
                  Song Liu and
                  Chen Zhang and
                  Bo Jiang and
                  Zhigang Lu},
	title = {Network intrusion detection based on n-gram frequency and time-aware
                  transformer},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103171},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103171},
	doi = {10.1016/J.COSE.2023.103171},
	timestamp = {Tue, 27 Feb 2024 16:41:39 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/HanCLZJL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network intrusion detection system plays a critical role in protecting the target network from attacks. However, most existing detection methods cannot fully utilize the information contained in raw network traffic, such as information loss in the feature extraction process and incomplete feature dimensions, which lead to performance bottlenecks. In this paper, we propose a novel intrusion detection model based on n-gram frequency and time-aware transformer called GTID. GTID can learn traffic features from packet-level and session-level hierarchically and can minimize information as much as possible. To extract packet-level features effectively, GTID considers the different roles of packet header and payload, and processes them in different ways, where n-gram frequency is used to represent payload contextual information because of its conciseness. Then, GTID uses the proposed time-aware transformer to learn session-level features for intrusion detection. The time-aware transformer considers the time intervals between packets, and learns the temporal features of a session for classification. For evaluation, several solid experiments are conducted on the ISCX2012 dataset and the CICIDS2017 dataset, and the results show the effectiveness and robustness of GTID.}
}


@article{DBLP:journals/compsec/AratA23,
	author = {Ferhat Arat and
                  Sedat Akleylek},
	title = {Attack Path Detection for IIoT Enabled Cyber Physical Systems: Revisited},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103174},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103174},
	doi = {10.1016/J.COSE.2023.103174},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AratA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a generic vulnerability and risk assessment method for IIoT-enabled critical systems. We focus on reducing risk factors and vulnerable structures in order to provide security issues for the IIoT and enabled complex systems. In addition to the existing risk assessment and related methods, we represent the IIoT-enabled network topology as a directed graph, and we develop an attack tree-based approach using graph theory. We assume that each device is a potential critical node due to the existing vulnerabilities, which are defined in the National Vulnerability Database (NVD), and we establish directed relations between nodes, considering cyber and physical interactions. We improve existing attack path-identifying methods using the Depth First Search (DFS) algorithm to find all the paths from the source to the target nodes. In the generated topology, each node has the pre-assigned Common Vulnerability Scoring System (CVSS) scores acting as a weight. We also implement the Floyd-Warshall algorithm to identify path risk levels. Finally, we assess the identified vulnerable paths from varying source and target pairs via path and node-reducing procedures, considering risk thresholds. We perform our simulation on a custom Python simulator, considering the transportation and supply sectors. We compare our results with the previous ones. Simulation results show that our proposed methods and procedures outperform existing risk assessment and filtering methods in terms of running time and attack path identification and filtering.}
}


@article{DBLP:journals/compsec/MaZWJGW23,
	author = {Xiuli Ma and
                  Wenbin Zhu and
                  Jieling Wei and
                  Yanliang Jin and
                  Dongsheng Gu and
                  Rui Wang},
	title = {{EETC:} An extended encrypted traffic classification algorithm based
                  on variant resnet network},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103175},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103175},
	doi = {10.1016/J.COSE.2023.103175},
	timestamp = {Wed, 27 Sep 2023 09:08:31 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MaZWJGW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advent of big data, encrypted traffic is widely used, and it is gradually becoming a new challenge for network security and management. Many researchers have obtained good results by converting encrypted traffic into images and feeding them to deep learning-based classification models. However, these methods have some limitations in that they cannot do sustainable learning. They have to retrain a new classifier when new traffic is encountered. To tackle this issue, we propose an extended encrypted traffic classification algorithm based on incremental learning. This approach extracts content and statistical information from encrypted traffic and supports multi-label prediction for VPN channels and applications. We can add new classes to the model without completely retraining and accelerate the update cycle of the model. The results show that the proposed model performs well in classification experiments, which can achieve 98.1% and 96.0% classification accuracy on ISCXVPN2016 and self-collected dataset respectively. In addition, our method can retain high accuracy under the situation of limited memory space while the number of new classes of data increases gradually. It demonstrates the superiority of constructing a generic unforgetting basis for classifying encrypted communication.}
}


@article{DBLP:journals/compsec/YangGCLY23,
	author = {Wang Yang and
                  Mingzhe Gao and
                  Ligeng Chen and
                  Zhengxuan Liu and
                  Lingyun Ying},
	title = {RecMaL: Rectify the malware family label via hybrid analysis},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103177},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103177},
	doi = {10.1016/J.COSE.2023.103177},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YangGCLY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intelligent applications can be significantly impacted by incorrectly categorized data. Recently, artificial intelligence technology has been deployed in an increasing number of security-related scenarios, but the issue of data mislabeling has received little attention. We concentrate on the problem of malware mislabeling in this paper. Unfortunately, in the security field, the mislabeling issue of malware is not taken seriously. Existing work attempts to aggregate the AV labels to alleviate malware mislabeling. This will mislead the security analyst and pass the error to subsequent data-driven applications. Therefore, we conduct an in-depth analysis to explore the severity of the malware mislabel issue, and try to rectify the description of malware generated from anti-virus engines. We first propose a malware label correction tool called RecMaL. It employs hybrid analyses for malware label rectifying.}
}


@article{DBLP:journals/compsec/SahayEMJB23,
	author = {Rishikesh Sahay and
                  Daniel A. Sepulveda Estay and
                  Weizhi Meng and
                  Christian Damsgaard Jensen and
                  Michael Bruhn Barfod},
	title = {A comparative risk analysis on CyberShip system with STPA-Sec, {STRIDE}
                  and {CORAS}},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103179},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103179},
	doi = {10.1016/J.COSE.2023.103179},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SahayEMJB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of software-intensive cyber systems in critical infrastructures such as ships (CyberShips) has brought huge benefits, yet it has also opened new avenues for cyber attacks to potentially disrupt operations. Cyber risk assessment plays a vital role in identifying cyber threats and vulnerabilities that can be exploited to compromise cyber systems. Understanding the nature of cyber threats and their potential risks and impact is essential to improve the security and resilience of cyber systems, and to build systems that are secure by design and better prepared to detect and mitigate cyber attacks. A number of methodologies have been proposed to carry out these analyses. This paper evaluates and compares the application of three risk assessment methodologies: system theoretic process analysis (STPA-Sec), STRIDE and CORAS for identifying threats and vulnerabilities in a CyberShip system. We specifically selected these three methodologies because they identify threats not only at the component level, but also threats or hazards caused due to the interaction between components, resulting in sets of threats identified with each methodology and relevant differences. Moreover, STPA-Sec, which is a variant of the STPA, is widely used for safety and security analysis of cyber physical systems (CPS); CORAS offers a framework to perform cyber risk assessment in a top-down approach that aligns with STPA-Sec; and STRIDE (Spoofing, Tampering, Repudiation,Information disclosure, Denial of Service, Elevation of Privilege) considers threat at the component level as well as during the interaction that is similar to STPA-Sec.  As a result of this analysis, this paper highlights the pros and cons of these methodologies, illustrates areas of special applicability, and suggests that their complementary use as threats identified through STRIDE can be used as an input to CORAS and STPA-Sec to make these methods more structured.}
}


@article{DBLP:journals/compsec/HuangSQH23,
	author = {Yinghui Huang and
                  Wenting Shen and
                  Jing Qin and
                  Huiying Hou},
	title = {Privacy-preserving certificateless public auditing supporting different
                  auditing frequencies},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103181},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103181},
	doi = {10.1016/J.COSE.2023.103181},
	timestamp = {Wed, 02 Aug 2023 10:13:00 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HuangSQH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Public auditing enables a verifier, say a third party auditor (TPA), to verify whether the cloud correctly stores the user’s cloud data. To date, a lot of public auditing schemes have been proposed. However, none of them consider the problem of auditing frequency. In practice, to reduce the cost of auditing service and avoid waste of resources, the users prefer to frequently verify the integrity of high-value data and check the integrity of low-value data with low frequency. In this paper, we propose a privacy-preserving certificateless public auditing scheme supporting different auditing frequencies. In this scheme, a novel auditing strategy is provided, in which the TPA is allowed to complete auditing tasks on high-value and low-value files with different auditing frequencies. The user’s privacy can be achieved by utilizing permutation technology to confuse the real file index. Hence, the TPA cannot distinguish the files with high value. We also use the random masking technology to mask the auditing proof, which guarantees the privacy of user data. The proposed scheme avoids the complicated certificate management and key escrow since it is designed in the certificateless cryptography. We prove that the proposed scheme is secure. The experimental results are shown to validate the efficiency of the proposed scheme.}
}


@article{DBLP:journals/compsec/NieCWZCS23,
	author = {Xiaofan Nie and
                  Liwei Chen and
                  Haolai Wei and
                  Yuantong Zhang and
                  Ningning Cui and
                  Gang Shi},
	title = {{KPDFI:} Efficient data flow integrity based on key property against
                  data corruption attack},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103183},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103183},
	doi = {10.1016/J.COSE.2023.103183},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NieCWZCS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data corruption attack (DCA) poses a severe threat to computer systems, corrupting in-memory data to subvert the intended control/data flow and impose arbitrary behavior. Data-Flow Integrity (DFI) guarantees legal data memory write to prevent it. Unfortunately, DFIs for all data adopt imprecise analysis and generate frequent memory access. Although enforcing DFI for partial data implies fewer checks and less cost, it weakens security. Therefore, existing DFIs suffer from an unsolved paradox: protecting all data limits its performance, and protecting partial data degrades its security. This paper presents KPDFI, a DFI only for DCA-related data, to resolve this paradox. We first propose the Key Property (KP) based on the DCA and a KP-based data selection strategy to define the DCA-related data, called key_data. KPDFI ameliorates the redundancy of the key_data legal write sets with a more precise field-sensitive and context-sensitive pointer analysis and propagation analysis. Since DCA only makes the data flow of key_data abnormal, KPDFI requires code instrumentation of only a small portion of the program code for DFI checking. We implement a KPDFI enforcement framework based on LLVM. We conduct numerous assessments for KPDFI. The experimental results prove that KPDFI is a security-enhanced and lightweight approach that mitigates the widespread DCA with an acceptable performance overhead (9.53%).}
}


@article{DBLP:journals/compsec/RayDowlingHS23,
	author = {Aratrika Ray{-}Dowling and
                  Daqing Hou and
                  Stephanie Schuckers},
	title = {Stationary mobile behavioral biometrics: {A} survey},
	journal = {Comput. Secur.},
	volume = {128},
	pages = {103184},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2023.103184},
	doi = {10.1016/J.COSE.2023.103184},
	timestamp = {Sat, 29 Apr 2023 19:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RayDowlingHS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current security mechanisms in mobile devices such as PINs, passwords, patterned passwords, and biometrics are one-time entry-point authentication and vulnerable to attacks. Furthermore, advanced mechanisms like Multi-Factor Authentication (MFA) introduce friction in the user experience. In contrast, behavioral biometrics rely on user interaction with computing devices to authenticate a user and thus, can be continuous, non-intrusive, and cost-effective, representing a promising direction that complements existing authentication techniques. This survey focuses on stationary/non-walking (sitting, standing) mobile behavioral biometrics through motion events like acceleration, gyroscope, magnetometer, and orientation (rotation) with the optional support of other non-motion, sporadic modalities such as swipes and keystrokes. The focus on stationary behaviors can be justified because such behaviors represent the major way a user interacts with mobile devices. To help readers understand the broad landscape of user activities/behaviors, we categorize the state of the art into natural and designed behaviors and describe the underpinning of behavioral biometrics in cognitive psychology. Furthermore, we categorize the surveyed studies into three groups based on the fusion of motion modalities and characterize each study along dimensions such as task, datasets, modality, algorithms, and performance. Based on our survey, we identify several future directions of research.}
}
