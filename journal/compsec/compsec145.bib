@article{DBLP:journals/compsec/NautiyalR24,
	author = {Lata Nautiyal and
                  Awais Rashid},
	title = {A framework for mapping organisational workforce knowledge profile
                  in cyber security},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103925},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103925},
	doi = {10.1016/J.COSE.2024.103925},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NautiyalR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A cyber security organisation needs to ensure that its workforce possesses the necessary knowledge to fulfil its cyber security business functions. Similarly, where an organisation chooses to delegate their cyber security tasks to a third-party provider, they must ensure that the chosen entity possesses robust knowledge capabilities to effectively carry out the assigned tasks. Building a comprehensive cyber security knowledge profile is a distinct challenge; the field is ever evolving with a range of professional certifications, academic qualifications and on-the-job training. So far, there has been a lack of a well-defined methodology for systematically evaluating an organisation’s cyber security knowledge, specifically derived from its workforce, against a standardised reference point. Prior research on knowledge profiling across various disciplines has predominantly utilised established frameworks such as SWEBOK. However, within the domain of cyber security, the absence of a standardised reference point is notable. In this paper, we advance a framework leveraging Cyber Security Body of Knowledge (CyBOK), to construct an organisation’s knowledge profile. The framework enables a user to identify areas of coverage and where gaps may lie, so that an organisation can consider targeted recruitment or training or, where such expertise may be outsourced, drawing in knowledge capability from third parties. In the latter case, the framework can also be used as a basis for assessing the knowledge capability of such a third party. We present the knowledge profiling framework, discussing three case studies in organisational teams underpinning its initial development, followed by its refinement through workshops with cyber security practitioners.}
}


@article{DBLP:journals/compsec/LykousasP24,
	author = {Nikolaos Lykousas and
                  Constantinos Patsakis},
	title = {Decoding developer password patterns: {A} comparative analysis of
                  password extraction and selection practices},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103974},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103974},
	doi = {10.1016/J.COSE.2024.103974},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LykousasP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Passwords play a crucial role in authentication, ensuring that only authorised entities can access sensitive information. However, user password choices are often weak and predictable, making them susceptible to cyber-attacks. Additionally, hard-coded credentials in source code can expose organisations and infrastructure to significant risks. This paper explores the patterns of passwords used by developers, examining their similarities to those of typical users. We also investigate the efficacy of large language models (LLMs) in identifying hard-coded credentials in source code. Our findings suggest that developers foster more complex and, hence, more secure password selection patterns than regular users. Nevertheless, they can use worse patterns when the context allows them. The latter, combined with the ample commits in public code repositories containing secrets, exemplifies the need for more targeted awareness campaigns and tighter integration of code security tools in the development lifecycle. Finally, we explore the capacity of LLMs to detect hard-coded credentials, highlighting their differences and limitations.}
}


@article{DBLP:journals/compsec/PandiRSDKB24,
	author = {S. Senthil Pandi and
                  D. Roja Ramani and
                  A. Senthil Selvi and
                  S. Dhanasekaran and
                  B. Kalpana and
                  N. Alangudi Balaji},
	title = {Advancing IoT security with flame: {A} hybrid approach combining fuzzy
                  logic and artificial lizard search optimization},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103984},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103984},
	doi = {10.1016/J.COSE.2024.103984},
	timestamp = {Sun, 06 Oct 2024 21:22:23 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/PandiRSDKB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing usage of Internet of Things (IoT) devices has created a need for secure and efficient solutions to protect sensitive data from unauthorized access. However, the complicated and massive structure of IoT systems poses various security risks and challenges, especially in dynamic scenarios with high signaling overhead caused by subscriber mobility. So, in this paper, a Fuzzy-based Lightweight Authentication and Management of Encryption approach called ‘FLAME’ is proposed to solve the decentralized lightweight group key management problem by measuring the degree of security using fuzzy logic (FL) based on various factors like device and user behavior, network conditions, and resource availability. For effective key-based authentication, adopted an Artificial Lizard Search Optimization (ALSO) based RSA (Rivest, Shamir, Adleman) algorithm that generates private and public keys based on security evaluation outcome. The publishers and subscribers obtain encryption keys from the group key manager based on their security level, and dissemination is optimized by the ALSO algorithm. By leveraging the FL and ALSO based RSA algorithm, the system offers secure communication with limited utilization and protects confidential data in IoT environments. According to the analysis, results signify that the FLAME approach has a faster key generation, dissemination, and revocation time compared to existing approaches, along with reduced overhead during key management operations, and increased attack detection capacity of 98.7 %.}
}


@article{DBLP:journals/compsec/ArikkatVANNTC24,
	author = {Dincy R. Arikkat and
                  P. Vinod and
                  Rafidha Rehiman K. A. and
                  Serena Nicolazzo and
                  Antonino Nocera and
                  Georgiana Timpau and
                  Mauro Conti},
	title = {{OSTIS:} {A} novel Organization-Specific Threat Intelligence System},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103990},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103990},
	doi = {10.1016/J.COSE.2024.103990},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ArikkatVANNTC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing complexity and frequency of cyber attacks, organizations recognize the need for a proactive and targeted approach to safeguard their digital assets and operations. Every industry faces a distinct array of threats shaped by factors such as its industrial objective, geographic footprint, workforce size, revenue, partnerships, and the extent of its digital assets. This results in a wide heterogeneity in threat landscapes, which necessitates tailored threat intelligence sources. While some security practitioners may gravitate towards extensive sources, relying solely on volume-based solutions often leads to “alert fatigue”. For this reason, organization-specific threat intelligence has acquired a growing importance in cybersecurity defense.}
}


@article{DBLP:journals/compsec/WolfTLHS24,
	author = {Maximilian Wolf and
                  Julian Tritscher and
                  Dieter Landes and
                  Andreas Hotho and
                  Daniel Schl{\"{o}}r},
	title = {Benchmarking of synthetic network data: Reviewing challenges and approaches},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103993},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103993},
	doi = {10.1016/J.COSE.2024.103993},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WolfTLHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of Network Intrusion Detection Systems (NIDS) requires labeled network traffic, especially to train and evaluate machine learning approaches. Besides the recording of traffic, the generation of traffic via generative models is a promising approach to obtain vast amounts of labeled data. There exist various machine learning approaches for data generation, but the assessment of the data quality is complex and not standardized. The lack of common quality criteria complicates the comparison of synthetic data generation approaches and synthetic data.}
}


@article{DBLP:journals/compsec/WangXTJSJ24,
	author = {Rongcun Wang and
                  Senlei Xu and
                  Yuan Tian and
                  Xingyu Ji and
                  Xiaobing Sun and
                  Shujuan Jiang},
	title = {{SCL-CVD:} Supervised contrastive learning for code vulnerability
                  detection via GraphCodeBERT},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103994},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103994},
	doi = {10.1016/J.COSE.2024.103994},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangXTJSJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting vulnerabilities in source code is crucial for protecting software systems from cyberattacks. Pre-trained language models such as CodeBERT and GraphCodeBERT have been applied in multiple code-related downstream tasks such as code search and code translation and have achieved notable success. Recently, this pre-trained and fine-tuned paradigm has also been applied to detect code vulnerabilities. However, fine-tuning pre-trained language models using cross-entropy loss has several limitations, such as poor generalization performance and lack of robustness to noisy labels. In particular, when the vulnerable code and the benign code are very similar, it is difficult for deep learning methods to differentiate them accurately. In this context, we introduce a novel approach for code vulnerability detection using supervised contrastive learning, namely SCL-CVD, which leverages GraphCodeBERT. This method aims to enhance the effectiveness of existing vulnerable code detection approaches. SCL-CVD represents the source code as data flow graphs. These graphs are then processed by GraphCodeBERT, which has been fine-tuned using a supervised contrastive loss function combined with R-Drop. This fine-tuning process is designed to generate more resilient and representative code embedding. Additionally, we incorporate LoRA (Low-Rank Adaptation) to streamline the fine-tuning process, significantly reducing the time required for model training. Finally, a Multilayer Perceptron (MLP) is employed to detect vulnerable code leveraging the learned representation of code. We designed and conducted experiments on three public benchmark datasets, i.e., Devign, Reveal, Big-Vul, and a combined dataset created by merging these sources. The experimental results demonstrate that SCL-CVD can effectively improve the performance of code vulnerability detection. Compared with the baselines, the proposed approach has a relative improvement of 0.48%\n∼\n3.42% for accuracy, 0.93%\n∼\n45.99% for precision, 35.68%\n∼\n67.48% for recall, and 16.31%\n∼\n49.67% for F1-score, respectively. Furthermore, compared to baselines, the model fine-tuning time of the proposed approach is reduced by 16.67%\n∼\n93.03%. In conclusion, our approach SCL-CVD offers significantly greater cost-effectiveness over existing approaches.}
}


@article{DBLP:journals/compsec/MaT24,
	author = {Yi{-}Wei Ma and
                  Chia{-}Wei Tsou},
	title = {A novel passive-active detection system for false data injection attacks
                  in industrial control systems},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103996},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103996},
	doi = {10.1016/J.COSE.2024.103996},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MaT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing occurrence of incidents causing significant damage due to attacks on Industrial Control Systems (ICSs), people pay attention to the cyber security of ICSs. This study improves existing active detection mechanisms and proposes an integrated passive-active detection system to detect False Data Injection Attacks (FDIA) for ICS. Since it is challenging to detect FDIA in current operational practices, the method presented in this research not only compares passive received system data with predefined rules to detect attacks but also launches active detection by controlling actuators to find attackers and achieve comprehensive detection of FDIA targeting ICS. This work dynamically adjusts the frequency of launching active detection through risk assessment, aiming to minimize the impact on operational efficiency during low-risk periods and reduce the time required for detecting attacks during high-risk periods. The experimental results show that using the proposed system, when false data differs by 10 % from accurate data, the detection rate can reach 99.9 %, which is 22.5 % higher than active detection by the random launch method when false data differs by 5 % from accurate data, the detection rate can reach 95.4 %, which is 18.2 % higher than active detect by randomly launch method, and even if false data only differs by 3 % from accurate data, the detection rate can reach 92.9 %, which is 16.5 % higher than active detect by randomly launch method.}
}


@article{DBLP:journals/compsec/WoodringPA24,
	author = {Justin Woodring and
                  Katherine Perez and
                  Aisha I. Ali{-}Gombe},
	title = {Enhancing privacy policy comprehension through Privacify: {A} user-centric
                  approach using advanced language models},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103997},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103997},
	doi = {10.1016/J.COSE.2024.103997},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WoodringPA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the digital age advances, the collection, usage, and dissemination of personal data have become critical concerns for users, regulators, and the cybersecurity community. Questions surrounding the extent of identifiable data collection, its usage, sharing, selling, and the mechanisms of consent are increasingly central to discussions on user data privacy. These issues highlight the need for effective management and comprehension of privacy policies. To this end, this paper introduces Privacify— a production-ready web application designed to enhance the accessibility and understandability of privacy policies, thus empowering users to make more informed decisions about their data. At its backend, Privacify leverages a combination of text segmentation, summarization using Large Language Model (LLM), and map-reduce technologies to facilitate BASE analysis for single-document insights and WRT and REV for comprehensive cross-document analysis. Designed with a user-centric approach, Privacify features an intuitive interface that presents all relevant user privacy information in easy-to-understand language, complete with a detailed explainability component. This design not only simplifies privacy policies but also aids users in effortlessly navigating complex privacy terms, significantly boosting their ability to protect and manage their personal information. Our evaluation employs robust methodologies, including reliability and accuracy assessments, alongside rigorous functionality verification through ROUGE metrics and human analysis, validating the system’s efficacy and performance. Privacify’s architecture promotes scalability, replicability, and seamless deployment, advancing the domain of user data protection through improved privacy comprehension.}
}


@article{DBLP:journals/compsec/AnidjarMDDH24,
	author = {Or Haim Anidjar and
                  Revital Marbel and
                  Ran Dubin and
                  Amit Dvir and
                  Chen Hajaj},
	title = {Extending limited datasets with GAN-like self-supervision for {SMS}
                  spam detection},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103998},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103998},
	doi = {10.1016/J.COSE.2024.103998},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AnidjarMDDH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Short Message Service (SMS) spamming is a harmful phishing attack on mobile phones. That is, fraudsters are trying to misuse personal user information, using tricky text messages, sometimes included with a fake URL that asks for this personal information, such as passwords, usernames, etc. In the world of Machine Learning, several approaches have tried to attitudinize this problem, but the lack of available data resources was commonly the main drawback towards a good enough solution. Therefore, in this paper, we suggest a dataset extension technique for small datasets, based on an Out Of Distribution (OOD) metric. Hence, different approaches such as Generative Adversarial Networks (GANs) were suggested, yet GANs are hard to train whenever datasets are limited in terms of sample size. In this paper, we present a GAN-like method that imitates the generator concept of GANs for the purpose of limited datasets extension, using the OOD concept. By using a sophisticated text generation method, we show how to apply it over datasets from the domain of fraud and spam detection in SMS messages, and achieve over 25% relative improvement, compared to two other solutions. In addition, due to the class imbalance in typical spam datasets, our approach is being examined over another dataset, in order to verify that the false alarm rate is low enough.}
}


@article{DBLP:journals/compsec/HuZHSW24,
	author = {Yuelin Hu and
                  Futai Zou and
                  Jiajia Han and
                  Xin Sun and
                  Yilei Wang},
	title = {{LLM-TIKG:} Threat intelligence knowledge graph construction utilizing
                  large language model},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103999},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103999},
	doi = {10.1016/J.COSE.2024.103999},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HuZHSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open-source threat intelligence is often unstructured and cannot be directly applied to the next detection and defense. By constructing a knowledge graph through open-source threat intelligence, we can better apply this information to intrusion detection. However, the current methods for constructing knowledge graphs face limitations due to the domain-specific attributes of entities and the analysis of lengthy texts, and they require large amounts of labeled data. Furthermore, there is a lack of authoritative open-source annotated threat intelligence datasets, which require significant manual effort. Moreover, it is noteworthy that current research often neglects the textual descriptions of attack behaviors, resulting in the loss of vital information to understand intricate cyber threats. To address these issues, we propose LLM-TIKG that applies the large language model to construct a knowledge graph from unstructured open-source threat intelligence. The few-shot learning capability of GPT is leveraged to achieve data annotation and augmentation, thereby creating the datasets for fine-tuning a smaller language model (7B). Using the fine-tuned model, we perform topic classification on the collected reports, extract entities and relationships, and extract TTPs from the attack description. This process results in the construction of a threat intelligence knowledge graph, enabling automated and universal analysis of textualized threat intelligence. The experimental results demonstrate improved performance in both named entity recognition and TTP classification, achieving the precision of 87.88% and 96.53%, respectively.}
}


@article{DBLP:journals/compsec/XuY24,
	author = {Zisheng Xu and
                  Qiao Yan},
	title = {Boosting the transferability of adversarial CAPTCHAs},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104000},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104000},
	doi = {10.1016/J.COSE.2024.104000},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XuY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA) is a test to distinguish humans and computers. Since attackers can achieve high accuracy in recognizing the CAPTCHAs using deep learning models, geometric transformations are added to the CAPTCHAs to disturb deep learning model recognition. However, excessive geometric transformations might also affect humans’ recognition of the CAPTCHA. Adversarial CAPTCHAs are special CAPTCHAs that can disrupt deep learning models without affecting humans. Previous works of adversarial CAPTCHAs mainly focus on defending the filtering attack. In real-world scenarios, the attackers’ models are inaccessible when generating adversarial CAPTCHAs, and the attackers may use models with different architectures, thus it is crucial to improve the transferability of the adversarial CAPTCHAs. We propose CFA, a method to generate more transferable adversarial CAPTCHAs focusing on altering content features in the original CAPTCHA. We use the attack success rate as our metric to evaluate the effectiveness of our method when attacking various models. A higher attack success rate means a higher level of preventing models from recognizing the CAPTCHAs. The experiment shows that our method can effectively attack various models, even when facing possible defense methods that the attacker might use. Our method outperforms other feature space attacks and provides a more secure version of adversarial CAPTCHAs.}
}


@article{DBLP:journals/compsec/AshrifSHAAW24,
	author = {Fatma Foad Ashrif and
                  Elankovan A. Sundararajan and
                  Mohammad Kamrul Hasan and
                  Rami Ahmad and
                  Salwani Abdullah and
                  Raniyah Wazirali},
	title = {Secured lightweight authentication for 6LoWPANs in machine-to-machine
                  communications},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104002},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104002},
	doi = {10.1016/J.COSE.2024.104002},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AshrifSHAAW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of machine-to-machine (M2M) technologies is becoming increasingly important in the rapidly growing domain of wireless sensor networks (WSNs) and the Internet of Things (IoT). Adopting IPv6 over 6LoWPANs (Low-Power Wireless Personal Area Networks) is instrumental in communicating across diverse domains within WSNs, albeit with its challenges. Particularly, resource limitations and security vulnerabilities remain significant concerns. 6LoWPAN-based M2M protocols that rely on authentication and key establishment schemes (AKE) often fall short due to inadequate security issues and excessive resource requirements. This paper addresses these challenges by introducing a secure and resource-efficient framework—Lightweight AKE for 6LoWPAN Nodes (LAKE-6LN). LAKE-6LN capitalizes on the clustering architecture's merits and contrasts conventional router-centric approaches. To ensure lightweight and efficient operation, it uses hash functions, XOR functions, and symmetric encryption techniques. Pseudo-identity, sequence tracking numbers, and secure parameters ensure privacy and protection against attacks, including traceability, perfect forward secrecy, ephemeral secret leakage, and secure the session key. An informal analysis of LAKE-6LN's security confirms that compliance with all essential security properties has been achieved. In addition, the framework's logical robustness and security analysis are rigorously verified using BAN logic, AVISPA, and Scyther tools. LAKE-6LN has demonstrated superior performance over related schemes, demonstrating a reduction in storage costs (by 33.33 % to 85.71 %), computational overhead (by 14.28 % to 95.97 %), communication overhead (by 16.12 % to 51.85 %), and energy consumption (by 22.04 % to 99.40 %). In our comparative analysis, LAKE-6LN demonstrates its resilience against various security threats, demonstrating its potential to secure 6LoWPAN networks in M2M.}
}


@article{DBLP:journals/compsec/QinYYH24,
	author = {Yang Qin and
                  Xiaofan Yang and
                  Lu{-}Xing Yang and
                  Kaifan Huang},
	title = {Modeling and study of defense outsourcing against advanced persistent
                  threat through impulsive differential game approach},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104003},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104003},
	doi = {10.1016/J.COSE.2024.104003},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QinYYH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced persistent threat (APT) poses serious threat to organizations with rich digital assets. APT detection programs designed for quickly finding possibly hijacked hosts are now commercially available. This greatly reduces the workload of APT defense. In practice, the identification and repair of APT-hijacked hosts are out of a system administrator’s capability and have to be outsourced to an established cybersecurity firm. Owing to the limited security budget, the APT defense can be outsourced only in a small number of maintenance periods. We refer to the sequence of outsourcing costs paid in these maintenance periods as an impulsive defense (ID) strategy. On the other hand, APT is time-continuous. We refer to the growth rate function of the attack cost over time as a continuous attack (CA) strategy. In the context that the APT actor is strategic and pursues a cost-effective CA strategy, the organization faces the problem of finding a cost-effective ID strategy (the single-impulsive defense (SID) problem). This paper addresses the SID problem through game-theoretic modeling. Based on an impulsive state evolutionary model, the SID problem is boiled down to a single-impulsive differential game model (the SID model). By applying single-impulsive differential game theory, an iterative algorithm of solving the SID problem is presented. The ID strategy obtained by running the algorithm is corroborated to be cost-effective under the Nash equilibrium solution concept. Therefore, we recommend the ID strategy. This work takes the first step toward the theoretic study of APT defense outsourcing in the presence of strategic attacker.}
}


@article{DBLP:journals/compsec/ZhaoFT24,
	author = {Xinxing Zhao and
                  Kar{-}Wai Fok and
                  Vrizlynn L. L. Thing},
	title = {Enhancing network intrusion detection performance using generative
                  adversarial networks},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104005},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104005},
	doi = {10.1016/J.COSE.2024.104005},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhaoFT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network intrusion detection systems (NIDS) play a pivotal role in safeguarding critical digital infrastructures against cyber threats. Machine learning-based detection models applied in NIDS are prevalent today. However, the effectiveness of these machine learning-based models is often limited by the evolving and sophisticated nature of intrusion techniques as well as the lack of diverse and updated training samples. In this research, a novel approach for enhancing the performance of an NIDS through the integration of Generative Adversarial Networks (GANs) is proposed. By harnessing the power of GANs in generating synthetic network traffic data that closely mimics real-world network behavior, we address a key challenge associated with NIDS training datasets, which is the data scarcity. Three distinct GAN models (Vanilla GAN, Wasserstein GAN and Conditional Tabular GAN) are implemented in this work to generate authentic network traffic patterns specifically tailored to represent the anomalous activity. We demonstrate how this synthetic data resampling technique can significantly improve the performance of the NIDS model for detecting such activity. By conducting comprehensive experiments using the CIC-IDS2017 benchmark dataset, augmented with GAN-generated data, we offer empirical evidence that shows the effectiveness of our proposed approach. Our findings show that the integration of GANs into NIDS can lead to enhancements in intrusion detection performance for attacks with limited training data, making it a promising avenue for bolstering the cybersecurity posture of organizations in an increasingly interconnected and vulnerable digital landscape.}
}


@article{DBLP:journals/compsec/AlSabehFKCB24,
	author = {Ali AlSabeh and
                  Kurt Friday and
                  Elie F. Kfoury and
                  Jorge Crichigno and
                  Elias Bou{-}Harb},
	title = {On {DGA} Detection and Classification Using {P4} Programmable Switches},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104007},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104007},
	doi = {10.1016/J.COSE.2024.104007},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AlSabehFKCB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain Generation Algorithms (DGAs) are highly effective strategies employed by malware to establish connections with Command and Control (C2) servers. Mitigating DGAs in high-speed networks can be challenging, as it often requires resource-intensive tasks such as extracting high-dimensional features from domain names or collecting extensive network heuristics. In this paper, we propose an innovative framework leveraging the flexibility, per-packet granularity, and Terabits per second (Tbps) processing capabilities of P4 programmable data plane switches for the rapid and accurate detection and classification of DGA families. Specifically, we use P4 switches to extract a combination of unique network heuristics and domain name features through shallow and Deep Packet Inspection (DPI) with minimal impact on throughput. We employ a two-fold approach, comprising a line-rate compact Machine Learning (ML) classifier in the data plane for DGA detection and a more comprehensive classifier in the control plane for DGA detection and classification. To validate our approach, we collected malware samples totaling hundreds of Gigabytes (GBs), representing over 50 DGA families, and utilized campus traffic from normal benign users. Our results demonstrate that our proposed approach can swiftly and accurately detect DGAs with an accuracy of 97% and 99% in the data plane and the control plane, respectively. Furthermore, we present promising findings and preliminary results for detecting DGAs in encrypted Domain Name System (DNS) traffic. Our framework enables the immediate halting of malicious communications, empowering network operators to implement effective mitigation, incident management, and provisioning strategies.}
}


@article{DBLP:journals/compsec/TatarKKF24,
	author = {Unal Tatar and
                  Bilge Karabacak and
                  Omer F. Keskin and
                  Dominick P. Foti},
	title = {Charting new waters with {CRAMMTS:} {A} survey-driven cybersecurity
                  risk analysis method for maritime stakeholders},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104015},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104015},
	doi = {10.1016/J.COSE.2024.104015},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/TatarKKF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article presents a novel survey-based cybersecurity risk assessment model, CRAMMTS (Cyber Risk Analysis Method for Maritime Transportation Systems), specifically designed for the maritime sector, addressing a critical gap in the literature. Our study contributes significantly in three ways: firstly, through a comprehensive critical literature review of 31 maritime guidelines and 95 scholarly articles, identifying the need for a new cybersecurity risk assessment method; secondly, by developing CRAMMTS, an adaptation of the ISRAM risk analysis method, incorporating the International Maritime Organization's criteria and enabling participation from maritime professionals, especially policymakers and leaders. The third contribution is a case study, the practical application of CRAMMTS in surveying 80 maritime professionals, assessing their perception of cybersecurity risks, and identifying varying risk levels, with the highest associated with cyber threat actors. This approach proved effective in assessing risks at both tactical and strategic levels and providing a clear, quantitative risk metric for decision-making. Our research underscores the maritime sector's need for a holistic, easily implementable cybersecurity risk analysis method that engages leaders and adapts to various Maritime Transportation System scopes, thereby enhancing cybersecurity risk assessment in this crucial domain.}
}


@article{DBLP:journals/compsec/Niemimaa24,
	author = {Marko Niemimaa},
	title = {Incorrect compliance and correct noncompliance with information security
                  policies: {A} framework of rule-related information security behaviour},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103986},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103986},
	doi = {10.1016/J.COSE.2024.103986},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/Niemimaa24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information security policy (ISP) compliance is recognized as a key measure for dealing with human errors when protecting information. A considerable and growing body of literature has studied the persuasive, deterrent, and coercive antecedents of compliant and noncompliant behaviour. Simultaneously, research indicates that real life situations are too complex and varied to prescribe in terms of a priori rules of acceptable behaviour, and create situations where compliance is in fact harmful for achieving organisational security and business goals. Thus, regarding ISP compliance as inherently “correct” and noncompliance as inherently “incorrect”, may contribute to creating problems that compliance research seeks to alleviate. In this research perspective, we argue that ISP compliance and noncompliance cannot be universally and invariably determined as “correct” or “incorrect” but that they become meaningful only when evaluated against organisational outcomes. We draw on organisational accident theorists to develop our arguments and propose a framework of rule-related information security behaviour (RISB) in order to conceptualize different types of ISP compliant and noncompliant behaviour and their organisational outcomes. Our research argues that compliance and noncompliance are nor inherently correct or incorrect and that making the judgement on the correctness of these actions requires considering the rule, the action, and the outcome.}
}


@article{DBLP:journals/compsec/JedrzejewskiTFGML24,
	author = {Felix Viktor Jedrzejewski and
                  Lukas Thode and
                  Jannik Fischbach and
                  Tony Gorschek and
                  Daniel M{\'{e}}ndez and
                  Niklas Lavesson},
	title = {Adversarial Machine Learning in Industry: {A} Systematic Literature
                  Review},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103988},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103988},
	doi = {10.1016/J.COSE.2024.103988},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/JedrzejewskiTFGML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial Machine Learning (AML) discusses the act of attacking and defending Machine Learning (ML) Models, an essential building block of Artificial Intelligence (AI). ML is applied in many software-intensive products and services and introduces new opportunities and security challenges. AI and ML will gain even more attention from the industry in the future, but threats caused by already-discovered attacks specifically targeting ML models are either overseen, ignored, or mishandled. Current AML research investigates attack and defense scenarios for ML in different industrial settings with a varying degree of maturity with regard to academic rigor and practical relevance. However, to the best of our knowledge, a synthesis of the state of academic rigor and practical relevance is missing. This literature study reviews studies in the area of AML in the context of industry, measuring and analyzing each study’s rigor and relevance scores. Overall, all studies scored a high rigor score and a low relevance score, indicating that the studies are thoroughly designed and documented but miss the opportunity to include touch points relatable for practitioners.}
}


@article{DBLP:journals/compsec/RajeshD24,
	author = {Arunachalam Rajesh and
                  Kanmani Ruby Erode Dhanapal},
	title = {Detection and mitigation of vampire attacks with secure routing in
                  {WSN} using weighted {RNN} and optimal path selection},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {103991},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103991},
	doi = {10.1016/J.COSE.2024.103991},
	timestamp = {Wed, 28 Aug 2024 10:56:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RajeshD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Wireless Sensor Networks (WSNs), one of the most significant threats is vampire attacks in sensor nodes. These attacks are marked by malicious behaviors within sensor nodes, often exploiting vulnerabilities inherent in routing protocols. These attacks can disrupt the connectivity of the network and significantly impact the energy resources. However, these intermediate nodes can introduce security vulnerabilities, making network security in WSN is challenging task. To address this issue, a novel deep learning-based vampire attack detection model is proposed. The developed deep learning-based vampire attack detection model is performed by following steps like data collection, attack detection, mitigation, and optimal path selection. Initially, the data attributes for all sensor nodes in the WSN system are collected. Further, the vampire attack detection is carried out by a Weighted Recurrent Neural Network (WRNN), here the weight values are optimized using Enhanced Golf Optimization Algorithm (EGOA). The detected vampire nodes are effectively separated based on different characteristics of nodes like node broadcast count, node energy, and node Packet Received Ratio (PRR). The attack mitigation process is executed by the separation of the vampire nodes from the network, the remaining nodes are considered for the routing process. The optimal paths are chosen by the proposed EGOA. Finally, the result of the suggested vampire attack detection model is compared with the conventional techniques in terms of various evaluation indices.}
}


@article{DBLP:journals/compsec/QuSA24,
	author = {Aiyan Qu and
                  Qiuhui Shen and
                  Gholamreza Ahmadi},
	title = {Towards intrusion detection in fog environments using generative adversarial
                  network and long short-term memory network},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104004},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104004},
	doi = {10.1016/J.COSE.2024.104004},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QuSA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, fog computing has been developed to complement cloud computing, which can provide cloud services at the edge of the network with real-time processing. However, the computational power of fog nodes is limited and this leads to security issues. On the other hand, cyber-attacks have become common with the exponential growth of Internet of Things (IoT) connected devices. This fact necessitates the development of Intrusion Detection Systems (IDSs) in fog environments with the aim of detecting attacks. In this paper, we develop an IDS named GAN-LSTM for fog environments that uses Generative Adversarial Networks (GANs) and Long Short-Term Memory Networks (LSTMs). GAN-LSTM is used to identify anomalies in network traffic to specific types of attacks or non-attacks. In general, GAN-LSTM consists of three components: data preprocessing, generation of real traffic patterns, and sequence analysis of real traffic data. Data preprocessing ensures data quality by removing noise and irrelevant features. The pre-processed data is fed to the GAN to generate real traffic as a baseline for normal behavior. Finally, the LSTM component is applied to detect anomalous anomalies in fog computing. The proposed algorithm was evaluated on public databases and experimental results showed that GAN-LSTM improves the accuracy of attack detection compared to equivalent approaches.}
}


@article{DBLP:journals/compsec/HamadFKRMPS24,
	author = {Mohammad Hamad and
                  Andreas Finkenzeller and
                  Michael K{\"{u}}hr and
                  Andrew Roberts and
                  Olaf Maennel and
                  Vassilis Prevelakis and
                  Sebastian Steinhorst},
	title = {{REACT:} Autonomous intrusion response system for intelligent vehicles},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104008},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104008},
	doi = {10.1016/J.COSE.2024.104008},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HamadFKRMPS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous and connected vehicles are rapidly evolving, integrating numerous technologies and software. This progress, however, has made them appealing targets for cybersecurity attacks. As the risk of cyber threats escalates with this advancement, the focus is shifting from solely preventing these attacks to also mitigating their impact. Current solutions rely on vehicle security operation centers, where attack information is analyzed before deciding on a response strategy. However, this process can be time-consuming and faces scalability challenges, along with other issues stemming from vehicle connectivity. This paper proposes a dynamic intrusion response system integrated within the vehicle. This system enables the vehicle to respond to a variety of incidents almost instantly, thereby reducing the need for interaction with the vehicle security operation center. The system offers a comprehensive list of potential responses, a methodology for response evaluation, and various response selection methods. The proposed solution was implemented on an embedded platform. Two distinct cyberattack use cases served as the basis for evaluating the system. The evaluation highlights the system’s adaptability, its ability to respond swiftly, its minimal memory footprint, and its capacity for dynamic system parameter adjustments. The proposed solution underscores the necessity and feasibility of incorporating dynamic response mechanisms in smart vehicles. This is a crucial factor in ensuring the safety and resilience of future smart mobility.}
}


@article{DBLP:journals/compsec/ChenCWCYJLL24,
	author = {Yiren Chen and
                  Mengjiao Cui and
                  Ding Wang and
                  Yiyang Cao and
                  Peian Yang and
                  Bo Jiang and
                  Zhigang Lu and
                  Baoxu Liu},
	title = {A survey of large language models for cyber threat detection},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104016},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104016},
	doi = {10.1016/J.COSE.2024.104016},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenCWCYJLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing complexity of cyber threats and the expanding scope of cyberspace, there exist progressively more challenges in cyber threat detection. It is proven that most previous threat detection models may become inadequate due to the escalation of hacker attacks. However, recent research has shown that some of these problems can be effectively addressed by Large Language Models (LLMs) directly or indirectly. Nowadays, a growing number of security researchers are adopting LLMs for analyzing various cyber threats. According to the investigation, we found that while there are numerous emerging reviews on the utilization of LLMs in some fields of cyber security, there is currently a lack of a comprehensive review on the application of LLMs in the threat detection stage. Through retrieving and collating existing works in recent years, we examined various threat detection and monitoring tasks for which LLMs may be well-suited, including cyber threat intelligence, phishing email detection, threat prediction, logs analysis, and so on. Additionally, the review explored the specific stages of different detection tasks in which LLMs are involved, evaluating the points at which LLMs are optimized. For instance, LLMs have been found to enhance the interpretability of log analysis in real-time anomaly event discovery. Additionally, we discussed some tasks where LLMs may not be suitable and explored future directions and challenges in this field. By providing a detailed status update and comprehensive insights, this review aims to assist security researchers in leveraging LLMs to enhance existing detection frameworks or develop domain-specific LLMs.}
}


@article{DBLP:journals/compsec/ZhangL24,
	author = {Guiqi Zhang and
                  Yufeng Li},
	title = {Voltage inspector: Sender identification for in-vehicle {CAN} bus
                  using voltage slice},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104017},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104017},
	doi = {10.1016/J.COSE.2024.104017},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Controller Area Network (CAN) serves as the neural system of modern cars, connecting and coordinating various electronic control units (ECUs) responsible for vehicle operation. However, the inherent features of CAN, such as broadcast communication and lack of authentication, make it increasingly vulnerable to cyberattacks. Although existing intrusion detection systems (IDSs) perform well in detecting malicious attacks, they often lack the ability to accurately locate the senders of these malicious messages. In this paper, we propose an efficient sender identification method called Voltage Inspector, which leverages physical voltage signal slice to accurately identify the source of messages for CAN bus. We start by extracting voltage slices from the raw physical signals of the CAN bus. Next, we leverage clustering technology to infer the ECU mapping information, which is typically considered confidential. This mapping information, combined with a machine learning classifier, is then utilized to construct an identification model capable of accurately identifying the sender of each message. To validate the effectiveness of our proposed method, we conducted extensive experiments using a publicly available voltage dataset collected from ten real vehicles. The experimental results demonstrate the remarkable accuracy of our approach, achieving a minimum identification accuracy of 99%. Furthermore, our method significantly reduces the data volume by half and reduces the identification time by a quarter when compared to state-of-the-art methods. Our research reveals that even a small portion of the voltage signal can be used to uniquely fingerprint an ECU. We emphasize that our method serves as an alternative identification approach and can complement existing works in the field.}
}


@article{DBLP:journals/compsec/AnnabiZM24,
	author = {Malak Annabi and
                  Abdelhafid Zeroual and
                  Nadhir Messai},
	title = {Towards zero trust security in connected vehicles: {A} comprehensive
                  survey},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104018},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104018},
	doi = {10.1016/J.COSE.2024.104018},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AnnabiZM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Zero Trust is the new cybersecurity model that challenges the traditional one by promoting continuous verification of users, devices, and applications, whatever their position or origin. This model is critical for reducing the attack surface and preventing lateral movement without relying on implicit trust. Adopting the zero trust principle in Intelligent Transportation Systems (ITS), especially in the context of connected vehicles (CVs), presents an adequate solution in the face of increasing cyber threats, thereby strengthening the ITS environment. This paper offers an understanding of Zero Trust security through a comprehensive review of existing literature, principles, and challenges. It specifically examines its applications in emerging technologies, particularly within connected vehicles, addressing potential issues and cyber threats faced by CVs. Inclusion/exclusion criteria for the systematic literature review were planned alongside a bibliometric analysis. Moreover, keywords co-occurrence analysis has been done, which indicates trends and general themes in the whole for Zero Trust model, Zero Trust implementation, and Zero Trust application. Furthermore, the paper explores various ZT models proposed in the literature for connected vehicles, shedding light on the challenges associated with their integration into CV systems. Future directions of this research will focus on incorporating Zero Trust principles within Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) communication paradigms. This initiative intends to enhance the security posture and safety protocols within interconnected vehicular networks. The proposed research seeks to address the unique cybersecurity vulnerabilities inherent in the highly dynamic nature of vehicular communication systems.}
}


@article{DBLP:journals/compsec/MaLXC24,
	author = {Yuxiang Ma and
                  Zhaodi Li and
                  Haoming Xue and
                  Jike Chang},
	title = {A balanced supervised contrastive learning-based method for encrypted
                  network traffic classification},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104023},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104023},
	doi = {10.1016/J.COSE.2024.104023},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MaLXC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encrypted network traffic classification plays an important role in enhancing network security and improving network performance. However, the imbalanced nature of traffic data makes the classification of encrypted network traffic challenging and may result in poor classification performance. Existing encrypted network traffic classification studies attempt to rebalance the data distribution through resampling strategies, which suffer from information loss, overfitting, and increased model complexity. Motivated by this, we propose an improved supervised contrastive learning approach to improve the classification performance of supervised contrastive learning classifiers for the traffic class imbalance problem in encrypted network traffic classification. Our method consists of two parts: data processing and traffic classification. In the data processing stage, we transform the raw network traffic data into grayscale images. In the traffic classification stage, we design optimized class-complement and class-averaging schemes in supervised contrastive learning. The construction of contrastive tasks is a critical link in contrastive learning. However, when constructing the set of positive and negative samples of network traffic, the samples generated by traditional methods do not conform to the salient features of network traffic. Traditional methods typically involve color modification, cropping, rotation, noise injection, and random erasure. When these traditional methods are applied to images generated from network traffic data, they may alter significant features of the network traffic data, such as changing the distribution of packet sizes. This is detrimental to maintaining the characteristics of traffic classes and does not aid the learning process. Therefore, we preprocess the traffic into images in a particular format suitable for contrastive learning, and then design a novel contrastive task construction method. The evaluation results on public datasets show that the proposed method can significantly improve the classification performance of encrypted traffic classification on imbalanced datasets.}
}


@article{DBLP:journals/compsec/HanHL24,
	author = {Jiaxuan Han and
                  Cheng Huang and
                  Jiayong Liu},
	title = {bjCnet: {A} contrastive learning-based framework for software defect
                  prediction},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104024},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104024},
	doi = {10.1016/J.COSE.2024.104024},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HanHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Defect prediction based on deep learning is proposed to provide practitioners with reliable and practical tools to determine whether an area of code is defective. Compared with traditional code features, semantic features of source codes automatically extracted by neural networks can better reflect the semantic differences between codes. However, the small difference between some bug codes and clean codes poses a challenge for deep learning models in distinguishing them, leading to a low accuracy in defect prediction. In this paper, we propose bjCnet, a software defect prediction framework based on contrastive learning. It fine-tunes the pre-trained Transformer-based code large language model via a supervised contrastive learning network, achieving accurate defect prediction. We evaluate the prediction effect of bjCnet, the results demonstrate that the highest accuracy and f1-score achieved by bjCnet are both 0.948, surpassing the performance of the state-of-the-art approaches selected for comparison.}
}


@article{DBLP:journals/compsec/ChidukwaniZK24,
	author = {Alladean Chidukwani and
                  Sebastian Zander and
                  Polychronis Koutsakis},
	title = {Cybersecurity preparedness of small-to-medium businesses: {A} Western
                  Australia study with broader implications},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104026},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104026},
	doi = {10.1016/J.COSE.2024.104026},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChidukwaniZK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study was prompted by the scarcity of focused quantitative research on the cybersecurity of SMBs. Our research aimed to understand the factors influencing SMBs' approach to cybersecurity, their level of threat awareness and the importance placed on cybersecurity. It also explored the extent to which NIST CSF practices are implemented by SMBs while also detecting and ranking the prevalent challenges faced by SMBs. Additionally, resources that SMBs turn to for help and guidance were also evaluated. While the survey-based study was on Western Australian SMBs, the results are of more general and wider interest. Our study found the lack of funds to be the biggest hindrance to cybersecurity, along with a lack of knowledge on where to start implementing good security practices. SMBs also lacked familiarity with relevant regulations and frameworks. The study highlights areas for improvement, such as access control mechanisms, individual user accounts, formalised policies and procedures, and dedicated budgets. SMBs heavily rely on Google search for cybersecurity information, emphasising the need for optimised search results from authoritative sources. IT service providers and informal networks also emerge as important sources of cybersecurity guidance, while local universities could assist SMBs but remain underutilised in this regard. Interestingly, factors such as organisational size, industry sector, and revenue level did not significantly impact SMBs' perception of vulnerability to cyber threats. However, further investigation is needed to evaluate the effectiveness of different IT service models for SMBs' cybersecurity needs. Overall, the research provides valuable insights into the specific gaps and challenges faced by SMBs in the cybersecurity domain, as well as their preferred methods of seeking and consuming cybersecurity assistance. The findings can guide the development of targeted strategies and policies to enhance the cybersecurity posture of SMBs.}
}


@article{DBLP:journals/compsec/HeKA24,
	author = {Ke He and
                  Dan Dongseong Kim and
                  Muhammad Rizwan Asghar},
	title = {NIDS-Vis: Improving the generalized adversarial robustness of network
                  intrusion detection system},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104028},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104028},
	doi = {10.1016/J.COSE.2024.104028},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HeKA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network Intrusion Detection Systems (NIDSes) are crucial for securing various networks from malicious attacks. Recent developments in Deep Neural Networks (DNNs) have encouraged researchers to incorporate DNNs as the underlying detection engine for NIDS. However, DNNs are susceptible to adversarial attacks, where subtle modifications to input data result in misclassification, posing a significant threat to security-sensitive domains such as NIDS. Existing efforts in adversarial defenses predominantly focus on supervised classification tasks in Computer Vision, differing substantially from the unsupervised outlier detection tasks in NIDS. To bridge this gap, we introduce a novel method of generalized adversarial robustness and present NIDS-Vis, an innovative black-box algorithm that traverses the decision boundary of DNN-based NIDSes near given inputs. Through NIDS-Vis, we can visualize the geometry of the decision boundaries and examine their impact on performance and adversarial robustness. Our experiment uncovers a tradeoff between performance and robustness, and we propose two novel training techniques, feature space partition and distributional loss function, to enhance the generalized adversarial robustness of DNN-based NIDSes without significantly compromising performance.}
}


@article{DBLP:journals/compsec/JiangWGYLY24,
	author = {Xunzhi Jiang and
                  Shen Wang and
                  Yuxin Gong and
                  Tingyue Yu and
                  Li Liu and
                  Xiangzhan Yu},
	title = {HAformer: Semantic fusion of hex machine code and assembly code for
                  cross-architecture binary vulnerability detection},
	journal = {Comput. Secur.},
	volume = {145},
	pages = {104029},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104029},
	doi = {10.1016/J.COSE.2024.104029},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/JiangWGYLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Binary vulnerability detection is a significant area of research in computer security. The existing methods for detecting binary vulnerabilities primarily rely on binary code similarity analysis, detecting vulnerabilities by comparing the similarities embedded in binary codes. Recently, Transformer-based models have achieved significant progress in this field, leveraging their advantage in handling sequential data to better understand the semantics of assembly code. However, to prevent the out-of-vocabulary (OOV) problems, assembly code typically needs to be normalized, which would lose some important numerical and jump information. In this paper, we propose HAformer, a Transformer-based model, which semantically fuses hexadecimal machine codes and assembly codes to extract richer semantic information from binary codes. By incorporating the hexadecimal machine code and a newly designed assembly code normalization method, HAformer can alleviate the problem of numerical information loss caused by traditional assembly code normalization, thereby addressing the issue of OOV. Evaluation results demonstrate that our HAformer outperforms the baseline method in the Recall@1 metric by 16.9%, 25.5% and 19.2% in cross-optimization level, cross-compiler and cross-architecture environments, respectively. In real-world vulnerability detection experiments, HAformer exhibits the highest accuracy.}
}
