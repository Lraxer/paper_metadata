@article{DBLP:journals/compsec/LiuJJ22,
	author = {Yujia Liu and
                  Ming Jiang and
                  Tingting Jiang},
	title = {Transferable adversarial examples based on global smooth perturbations},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102816},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102816},
	doi = {10.1016/J.COSE.2022.102816},
	timestamp = {Fri, 08 Mar 2024 17:35:46 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiuJJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although the attack rate and the imperceptibility of perturbations are two main concerns of adversarial attacks, the transferability of adversarial examples is an emerging topic due to the need for applications. It is known from previous work that adversarial examples with low-frequency perturbations have better transferability than those with high-frequency perturbations. In this paper, we propose a method to generate global smooth low-frequency perturbations with parameterized smooth functions, unlike previous pixel-wise local methods. We optimize perturbations by minimizing a proposed loss function that fulfills the attack task and meets the requirement of imperceptibility for perturbations. The global smoothness of perturbations ensures the spectrum of low-frequency and hence increases adversarial examples’ transferability. In the implementation, the Gaussian mixture model is used as the prototype of parameterized smooth functions to evaluate the proposed method. Extensive experiments on ImageNet and CIFAR-10 demonstrate that our method significantly improves the transferability by 10–20% over other state-of-the-art methods with a comparable attack rate.}
}


@article{DBLP:journals/compsec/LuLLC22,
	author = {Shiwei Lu and
                  Ruihu Li and
                  Wenbin Liu and
                  Xuan Chen},
	title = {Defense against backdoor attack in federated learning},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102819},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102819},
	doi = {10.1016/J.COSE.2022.102819},
	timestamp = {Mon, 28 Aug 2023 21:25:34 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LuLLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a new distributed machine learning framework, Federated Learning (FL) effectively solves the problems of data silo and privacy protection in the field of artificial intelligence. However, for its independent devices, heterogeneous data and unbalanced data distribution, it is more vulnerable to adversarial attack, especially backdoor attack. In this paper, we investigate typical backdoor attacks in FL, containing model replacement attack and adaptive backdoor attack. Based on attack initiating round, we divide backdoor attack into convergence-round attack and early-round attack. In addition, we respectively design a defense scheme with model pre-aggregation and similarity measurement to detect and remove backdoor model under convergence-round attack and a defense scheme with backdoor neuron activation to remove backdoor under early-round attack. Experiments and performance analysis show that compared to benchmark schemes, our defense scheme with similarity measurement obtains the highest backdoor detection accuracy under model replacement attack (25% increase) and adaptive backdoor attack (67% increase) at the convergence round. Moreover, detection effect is the most stable. Compared to defense of participant-level differential privacy and adversarial training, our defense scheme with backdoor neuron activation can rapidly remove malicious effects of backdoor without reducing the main task accuracy under early-round attack. Thus, the robustness of FL can be improved greatly with our defense schemes. We make our key codes public at Github\nhttps://github.com/lsw3130104597/Backdoor_detection\n.}
}


@article{DBLP:journals/compsec/GuoFHOLG22,
	author = {Wenbo Guo and
                  Yong Fang and
                  Cheng Huang and
                  Haoran Ou and
                  Chun Lin and
                  Yongyan Guo},
	title = {HyVulDect: {A} hybrid semantic vulnerability mining system based on
                  graph neural network},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102823},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102823},
	doi = {10.1016/J.COSE.2022.102823},
	timestamp = {Mon, 05 Feb 2024 20:23:23 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/GuoFHOLG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, software programs tend to be large and complex, software has become the infrastructure of modern society, but software security issues can not be ignored. software vulnerabilities have become one of the main threats to computer security. There are countless cases of exploiting source code vulnerabilities to launch attacks. At the same time, the development of open source software has made source code vulnerability detection more and more critical. Traditional vulnerability mining methods have been unable to meet the security analysis needs of complex software because of the high false-positive rate and false-negative rate. To resolve the existing problems, we propose a graph neural network vulnerability mining system named HyVulDect based on hybrid semantics, which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. A gated graph neural network is used to extract deep semantic information. Since most of the vulnerabilities are data flow associated, we use taint analysis to extract the taint propagation chain, use the BiLSTM model to extract the token-level features of the context, and finally use the classifier to classify the fusion features. We introduce a dual-attention mechanism that allows the model to focus on vulnerability-related code, making it more suitable for vulnerability mining tasks. The experimental results show that HyVulDect outperforms existing state-of-the-art methods and can achieve an accuracy rate of 92% on the benchmark dataset. Compared with the rule-based static mining tools Flawfinder, RATS, and Cppcheck, it has better performance and can effectively detect the actual CVE source code vulnerabilities.}
}


@article{DBLP:journals/compsec/JerbiDBS22,
	author = {Manel Jerbi and
                  Zaineb Chelly Dagdia and
                  Slim Bechikh and
                  Lamjed Ben Said},
	title = {Android malware detection as a Bi-level problem},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102825},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102825},
	doi = {10.1016/J.COSE.2022.102825},
	timestamp = {Mon, 28 Aug 2023 21:26:05 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/JerbiDBS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware detection is still a very challenging topic in the cybersecurity field. This is mainly due to the use of obfuscation techniques. To solve this issue, researchers proposed to extract frequent API (Application Programming Interface) call sequences and then use them as behavior indicators. Several methods aiming at generating malware detection rules have been proposed with the goal to come up with a set of rules that is able to accurately detect malicious code patterns. However, the rules generation process heavily depends on the training database content which will affect the detection rate of the model when confronted to new variants of malicious patterns. In order to assess a rule’s detection accuracy, we need to execute the rule on the whole malware database which makes the detection rule quality evaluation very sensitive to the database content. To solve this issue, we suggest in this paper to consider the detection rules generation process as a BLOP (Bi-Level Optimization Problem), where a lower-level optimization task is embedded within the upper-level one. The goal of the upper-level is to generate a set of detection rules in the form of: trees of combined patterns. Those rules are able to detect not only the real patterns from the base of examples but also the artificial patterns generated by the lower-level. The lower-level aims to generate a set of artificial malicious patterns that escape the rules of the upper-level. An efficient co-evolutionary algorithm is adopted as a search engine to ensure optimization at both levels. Such an automated competition between the two levels makes our new method BMD (Bi-level Malware Detection) able to produce effective detection rules that are capable of detecting new predictable malicious behaviors in addition to existing ones. Based on the statistical analysis of the experimental results, our BMD method has shown its merits when compared to several relevant state-of-the-art malware detection techniques on different Android malware datasets.}
}


@article{DBLP:journals/compsec/QayyumJQ22,
	author = {Adnan Qayyum and
                  Muhammad Umar Janjua and
                  Junaid Qadir},
	title = {Making federated learning robust to adversarial attacks by learning
                  data and model association},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102827},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102827},
	doi = {10.1016/J.COSE.2022.102827},
	timestamp = {Mon, 28 Aug 2023 21:25:39 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/QayyumJQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the key challenges in federated learning (FL) is the detection of malicious parameter updates. In a typical FL setup, the presence of malicious client(s) can potentially demolish the overall training of the shared global model by influencing the aggregation process of the server. In this paper, we present a hybrid learning-based method for the detection of poisoned/malicious parameter updates from malicious clients. Furthermore, to highlight the effectiveness of the proposed method, we provide empirical evidence by evaluating the proposed method against a well-known label flipping attack on three different image classification tasks. The results suggest that our method can effectively detect and discard poisoned parameter updates without causing a significant drop in the performance of the overall learning of the FL paradigm. Our proposed method has achieved an average malicious parameters updates detection accuracy of 97.57%, 92.35%, and 89.42% for image classification task on MNIST, CIFAR, and APTOS diabetic retinopathy (DR) detection. Our method provides a performance gain of approximately 2% as compared to a recent similar state of the art method on MNIST classification and provided a comparable performance on federated extended MNIST (FEMNIST).}
}


@article{DBLP:journals/compsec/KurniawanEKQT22,
	author = {Kabul Kurniawan and
                  Andreas Ekelhart and
                  Elmar Kiesling and
                  Gerald Quirchmayr and
                  A Min Tjoa},
	title = {{KRYSTAL:} Knowledge graph-based framework for tactical attack discovery
                  in audit data},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102828},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102828},
	doi = {10.1016/J.COSE.2022.102828},
	timestamp = {Mon, 28 Aug 2023 21:26:03 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KurniawanEKQT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attack graph-based methods are a promising approach towards discovering attacks and various techniques have been proposed recently. A key limitation, however, is that approaches developed so far are monolithic in their architecture and heterogeneous in their internal models. The inflexible custom data models of existing prototypes and the implementation of rules in code rather than declarative languages on the one hand make it difficult to combine, extend, and reuse techniques, and on the other hand hinder reuse of security knowledge – including detection rules and threat intelligence. KRYSTAL tackles these challenges by providing a knowledge graph-based, modular framework for threat detection, attack graph and scenario reconstruction, and analysis based on RDF as a standard model for knowledge representation. This approach provides query options that facilitate contextualization over internal and external background knowledge, as well as the integration of multiple detection techniques, including tag propagation, attack signatures, and graph queries. We implemented our framework in an openly available prototype and demonstrate its applicability on multiple scenarios of the DARPA Transparent Computing dataset. Our evaluation shows that the combination of different threat detection techniques within our framework improved detection capabilities. Furthermore, we find that RDF provenance graphs are scalable and can efficiently support a variety of threat detection techniques.}
}


@article{DBLP:journals/compsec/LeeGWGR22,
	author = {Jaeung Lee and
                  Melchor C. de Guzman and
                  Jingguo Wang and
                  Manish Gupta and
                  H. Raghav Rao},
	title = {Investigating perceptions about risk of data breaches in financial
                  institutions: {A} routine activity-approach},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102832},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102832},
	doi = {10.1016/J.COSE.2022.102832},
	timestamp = {Mon, 05 Feb 2024 20:23:22 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LeeGWGR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data breaches in financial institutions could produce extensive damage to an organization's operations. Therefore, it is critical for organizations to identify and assess threats in their operational environment to be able to implement prevention and mitigation strategies. Applying Routine Activity Theory (RAT), this paper develops a risk assessment model using employees’ perceptions of risks relative to potential breaches of sensitive data in their organizations. This paper empirically examines the roles of motivated offenders, suitable targets, and the influences of capable guardianship within the organization. Analyses of surveyed employees show that perceptions of value (using a multi-dimensional perspective), inertia, and accessibility of targeted sensitive data along with presence of guardians have an impact on assessment of risk about data breaches in financial institutions. The paper also extends RAT to account for the amount of information (both online and offline) available regarding the data influence the relationship between value of the sensitive data and suitability for data breach. Theoretical and practical implications are discussed.}
}


@article{DBLP:journals/compsec/MuzaffarHLZ22,
	author = {Ali Muzaffar and
                  Hani Ragab Hassen and
                  Michael A. Lones and
                  Hind Zantout},
	title = {An in-depth review of machine learning based Android malware detection},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102833},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102833},
	doi = {10.1016/J.COSE.2022.102833},
	timestamp = {Mon, 28 Aug 2023 21:25:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MuzaffarHLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is estimated that around 70% of mobile phone users have an Android device. Due to this popularity, the Android operating system attracts a lot of malware attacks. The sensitive nature of data present on smartphones means that it is important to protect against these attacks. Classic signature-based detection techniques fall short when they come up against a large number of users and applications. Machine learning, on the other hand, appears to work well, and also helps in identifying zero-day attacks, since it does not require an existing database of malicious signatures. In this paper, we critically review past works that have used machine learning to detect Android malware. The review covers supervised, unsupervised, deep learning and online learning approaches, and organises them according to whether they use static, dynamic or hybrid features.}
}


@article{DBLP:journals/compsec/YunXLZS22,
	author = {Xiaochun Yun and
                  Jiang Xie and
                  Shuhao Li and
                  Yongzheng Zhang and
                  Peishuai Sun},
	title = {Detecting unknown HTTP-based malicious communication behavior via
                  generated adversarial flows and hierarchical traffic features},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102834},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102834},
	doi = {10.1016/J.COSE.2022.102834},
	timestamp = {Mon, 28 Aug 2023 21:25:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YunXLZS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malicious communication behavior is the network communication behavior generated by malware (botnet, spyware, etc.) after victim devices are infected. Experienced adversaries often hide malicious information in HTTP traffic to evade detection. However, related detection methods have inadequate generalization ability because they are usually based on artificial feature engineering and outmoded datasets. In this paper, we propose an HTTP-based Malicious Communication traffic Detection Model (HMCD-Model) based on generated adversarial flows and hierarchical traffic features. HMCD-Model consists of two parts. The first is a generation algorithm based on WGAN-GP to generate HTTP-based malicious communication traffic for data enhancement. The second is a hybrid neural network based on CNN and LSTM to extract hierarchical spatial-temporal features of traffic. In addition, we collect and publish a dataset, HMCT-2020, which consists of large-scale malicious and benign traffic during three years (2018–2020). Taking the data in HMCT-2020(18) as the training set and the data in other datasets as the test set, the experimental results show that the HMCD-Model can effectively detect unknown HTTP-based malicious communication traffic. It can reach F1\n≈\n98.66% in the dataset HMCT-2020(19–20), F1\n≈\n90.69% in the public dataset CIC-IDS-2017 and F1\n≈\n83.66% in the real traffic, which is 20+% higher than other representative methods on average. This validates that HMCD-Model has the ability to discover unknown HTTP-based malicious communication behavior.}
}


@article{DBLP:journals/compsec/TianWLK22,
	author = {Jiwei Tian and
                  Buhong Wang and
                  Jing Li and
                  Charalambos Konstantinou},
	title = {Datadriven false data injection attacks against cyber-physical power
                  systems},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102836},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102836},
	doi = {10.1016/J.COSE.2022.102836},
	timestamp = {Mon, 28 Aug 2023 21:25:45 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/TianWLK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Power systems are accelerating towards the transition to cyber-physical power systems (CPPS). Such CPPS include myriads of sensors that generate huge amounts of data. The information collected from all these sensing components enables, not only the enhancement of CPPS performance in terms of efficiency and reliability, but also the expansion of the threat landscape. Among the attack vectors, false data injection attacks (FDIAs) demonstrated that can severely impact energy management routines of CPPS. Existing data-driven approaches used to design FDIAs are often based on different assumptions and environmental conditions which could make them not realistic, and more importantly, detectable by bad data detection (BDD) algorithms. In this paper, we present existing data-driven FDIA methods evaluated under different conditions of measurement data. In addition, we propose a novel data-driven attack strategy based on robust linear regression (RLR). For all data-driven attacks, appropriate conditions are considered in terms of measurement data to develop evaluation case studies. The results show that our proposed RLR method performs better than other data-driven methods in most scenarios, even in the presence of outliers.}
}


@article{DBLP:journals/compsec/LiuQH22,
	author = {Yuanzhen Liu and
                  Umair Mujtaba Qureshi and
                  Gerhard Petrus Hancke},
	title = {Keypad entry inference with sensor fusion from mobile and smart wearables},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102837},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102837},
	doi = {10.1016/J.COSE.2022.102837},
	timestamp = {Mon, 28 Aug 2023 21:25:34 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiuQH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the threat of password leakage from sensors on mobile phones and smart wearables. We investigate attack methods for recovering a short random number entered on PEDs using a combination of data collected by from microphone, accelerometer and gyroscope in devices on the person entering the number. We take into consideration features based on keypress sounds, from either phone and/or smart watch, in addition to hand movement acceleration and angular velocity captured by the smart watch. We used the fusion features from these three sensor sources to train a Neural Network to recover key entries on a keypad. Our method b}
}


@article{DBLP:journals/compsec/FinderSN22,
	author = {Ido Finder and
                  Eitam Sheetrit and
                  Nir Nissim},
	title = {A time-interval-based active learning framework for enhanced {PE}
                  malware acquisition and detection},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102838},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102838},
	doi = {10.1016/J.COSE.2022.102838},
	timestamp = {Mon, 28 Aug 2023 21:25:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/FinderSN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware increasingly threatens users around the world on a variety of cybernetic platforms, resulting in damages of billions of dollars each year. In recent years, in order to improve the detection capabilities of widely used antivirus (AV) tools, machine learning (ML) algorithms and dynamic malware analysis have been leveraged for the extraction and learning of rich multivariate time-series data (MTSD) associated with behavioral information. Such MTSD can be exploited using a time-interval temporal pattern (TP) mining approach, however this approach has not been widely explored for the task of malware detection. The use of TPs enables the discovery of complex temporal relations between different variables, improves the ability to cope with missing values and noisy data, and provides explainability. In light of the continuous creation of new unknown malware on a daily basis, detection mechanisms require frequent updating to keep pace with the changing reality. Active learning (AL) can address the updatability gap by efficiently selecting and acquiring a small yet informative set of new samples while reducing the labeling efforts of experts; AL also provides maximal improvement of machine-learning-based detection models, which can further contribute to the updatability of antimalware tools. However, the use of AL methods for the acquisition of time-interval TP-based samples has yet to be explored. In this paper, we present novel AL methods and a detection framework for improved malware detection based on dynamic analysis, time-interval TPs, and ML algorithms. The proposed framework is capable of both prioritizing the acquisition of malicious samples and improving the malware detection capabilities of ML classifiers and antimalware tools. Our proposed framework was evaluated in an extensive set of experiments on a comprehensive data collection of 9,328 portable executables (5,000 benign and 4,328 malicious) that were executed in the Windows 10 environment. The results demonstrated our AL methods’ ability to prioritize the acquisition of malware and managed to acquire up to 93.5% of the malicious files each day, allowing frequent updating of antimalware tools. In addition, our framework was shown to be effective in improving the detection capabilities of several ML classifiers over time, with the best results (AUC of 95.15%) achieved by the SVM classifier. Our framework also showed that TPs can be used to identify emerging trends in malicious behavior.}
}


@article{DBLP:journals/compsec/WangSWXZTZQ22,
	author = {Jie Wang and
                  Jiaming Shi and
                  Xin Wen and
                  Liang Xu and
                  Ke Zhao and
                  Fuyang Tao and
                  Wenbiao Zhao and
                  Xiuying Qian},
	title = {The effect of signal icon and persuasion strategy on warning design
                  in online fraud},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102839},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102839},
	doi = {10.1016/J.COSE.2022.102839},
	timestamp = {Sat, 30 Sep 2023 10:07:34 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangSWXZTZQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid increase in the use of mobile technology and online communication has facilitated more opportunities for social interactions as well as for online fraud. Warnings are one of the last lines of defense in transaction security. Many warnings used in anti-fraud processes are often ineffective due to habituation and the trial-and-error method used in their design. Following psychological theories of persuasion and warning design principles, in this paper, we design fourteen warnings and examine their effectiveness in an eye-tracker experiment (Study 1) and in an online A/B test on the Alipay platform (Study 2). Based on the communication-human information processing (C-HIP) model, Study 1 found that pictorial signal icons and persuasion strategies significantly improved the effectiveness of warnings. Specifically, pictorial signal icons attracted users’ attention better than the conventional signal icons, and warnings with authority, social influence, diversion, questioning, and multiple strategies performed better than those without a persuasion strategy. Study 2 showed that our warnings performed better than the original Alipay warnings. The overall case rate was reduced by 33.2%, avoiding at least 30 million yuan in economic losses. Our work contributes to the field of security warning design with both theoretical and practical value and provides an important reference for future research.}
}


@article{DBLP:journals/compsec/GaleBS22,
	author = {Megan Gale and
                  Ivano Bongiovanni and
                  Sergeja Slapnicar},
	title = {Governing cybersecurity from the boardroom: Challenges, drivers, and
                  ways ahead},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102840},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102840},
	doi = {10.1016/J.COSE.2022.102840},
	timestamp = {Mon, 28 Aug 2023 21:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GaleBS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Overall, the responsibility to oversee cyber-risk management in modern organisations lies with Boards of Directors. However, evidence suggests that boards are not nearly as engaged in cybersecurity as they are in other areas of oversight. Through the lens of neo-institutional theory, we investigated key drivers and major impediments to directors’ engagement with cybersecurity. We conducted 18 interviews with non-executive directors from 43 organisations to cast light on current cybersecurity practices and on the factors that drive directors’ engagement. Our findings emphasise that regulations are the most influential driver (coercive pressures). However, directors are not always completely aware of their duties and liability concerning cybersecurity oversight. Further, our study highlights that personal experience and background shape a director's engagement with cybersecurity (normative forces). Our analysis also shows a frequent over-reliance on a single board member with cyber-experience. Lastly, the secrecy that characterises cybersecurity reduces the opportunity for directors to replicate best practices across organisations (mimetic forces). Directors’ engagement with cybersecurity is marginally driven by holding multiple board roles and by the influence of external consultants. A stronger role is played by the mediatic nature of some cyber-breaches and by a prominent “push reporting” approach in cybersecurity (organisational factors). We offer a series of evidence-based practical recommendations to enhance directors’ engagement in this crucial area, ranging from strengthening existing regulations, to codifying best practices in cyber-reporting.}
}


@article{DBLP:journals/compsec/MathovSSE22,
	author = {Yael Mathov and
                  Tal Ben Senior and
                  Asaf Shabtai and
                  Yuval Elovici},
	title = {Stop bugging me! Evading modern-day wiretapping using adversarial
                  perturbations},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102841},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102841},
	doi = {10.1016/J.COSE.2022.102841},
	timestamp = {Mon, 28 Aug 2023 21:25:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MathovSSE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mass surveillance systems for voice over IP (VoIP) conversations pose a great risk to privacy. These automated systems use learning models to analyze conversations, and calls that involve specific topics are routed to a human agent for further examination. In this study, we present an adversarial-learning-based framework for privacy protection for VoIP conversations. We present a novel method that finds a universal adversarial perturbation (UAP), which, when added to the audio stream, prevents an eavesdropper from automatically detecting the conversation’s topic. As shown in our experiments, the UAP is agnostic to the speaker or audio length, and its volume can be changed in real time, as needed. Our real-world solution uses a Teensy microcontroller that acts as an external microphone and adds the UAP to the audio in real time. We examine different speakers, VoIP applications (Skype, Zoom, Slack, Google Meet, and Microsoft Teams), and audio lengths. Our results in the real world suggest that our approach is a feasible solution for privacy protection.}
}


@article{DBLP:journals/compsec/LiQHLLG22,
	author = {Yanan Li and
                  Tao Qin and
                  Yongzhong Huang and
                  Jinghong Lan and
                  ZanHao Liang and
                  Tongtong Geng},
	title = {{HDFEF:} {A} hierarchical and dynamic feature extraction framework
                  for intrusion detection systems},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102842},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102842},
	doi = {10.1016/J.COSE.2022.102842},
	timestamp = {Mon, 28 Aug 2023 21:26:11 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiQHLLG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network intrusion detection plays a vital role in modern cyberspace security systems. Although deep learning has been widely used for automatic feature extraction in intrusion detection, capturing effective feature representations in network flows is still challenging using current methods due to the increasing complexity of real-world network environments. Network flows have a clear hierarchical structure, which has not been fully considered by existing methods. Additionally, most existing methods are coarse-grained methods that only leverage a single packet or network flow. As a result, the maliciousness of an attack cannot be fully reflected, which may lead to unsatisfactory detection performance. To address the aforementioned issues, we propose a novel network intrusion detection method based on a hierarchical and dynamic feature extraction framework (HDFEF). Specifically, a complete network activity is defined as a sequence of packets with multiple network flows. Then, a hierarchical network model, which dynamically adjusts the distribution of the feature representations of multiple temporally correlated network packets with an attention mechanism, is designed. Finally, after combining the vectors obtained from the multispace mapping, the final discriminant vectors are obtained and used for classification. The superiority of our HDFEF over other state-of-the-art methods is shown through the results of the experiments on the CSE-CIC-IDS2018, CIC-IDS2017 and UNSW-NB15 datasets.}
}


@article{DBLP:journals/compsec/CalzavaraCLMO22,
	author = {Stefano Calzavara and
                  Lorenzo Cazzaro and
                  Claudio Lucchese and
                  Federico Marcuzzi and
                  Salvatore Orlando},
	title = {Beyond robustness: Resilience verification of tree-based classifiers},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102843},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102843},
	doi = {10.1016/J.COSE.2022.102843},
	timestamp = {Mon, 28 Aug 2023 21:26:11 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CalzavaraCLMO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper we criticize the robustness measure traditionally employed to assess the performance of machine learning models deployed in adversarial settings. To mitigate the limitations of robustness, we introduce a new measure called resilience and we focus on its verification. In particular, we discuss how resilience can be verified by combining a traditional robustness verification technique with a data-independent stability analysis, which identifies a subset of the feature space where the model does not change its predictions despite adversarial manipulations. We then introduce a formally sound data-independent stability analysis for decision trees and decision tree ensembles, which we experimentally assess on public datasets and we leverage for resilience verification. Our results show that resilience verification is useful and feasible in practice, yielding a more reliable security assessment of both standard and robust decision tree models.}
}


@article{DBLP:journals/compsec/HuangZ22,
	author = {Linan Huang and
                  Quanyan Zhu},
	title = {{RADAMS:} Resilient and adaptive alert and attention management strategy
                  against Informational Denial-of-Service (IDoS) attacks},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102844},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102844},
	doi = {10.1016/J.COSE.2022.102844},
	timestamp = {Mon, 28 Aug 2023 21:25:52 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HuangZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attacks exploiting human attentional vulnerability have posed severe threats to cybersecurity. In this work, we identify and formally define a new type of proactive attentional attacks called Informational Denial-of-Service (IDoS) attacks that generate a large volume of feint attacks to overload human operators and hide real attacks among feints. We incorporate human factors (e.g., levels of expertise, stress, and efficiency) and empirical psychological results (e.g., the Yerkes-Dodson law and the sunk cost fallacy) to model the operators’ attention dynamics and their decision-making processes along with the real-time alert monitoring and inspection. To assist human operators in dismissing the feints and escalating the real attacks timely and accurately, we develop a Resilient and Adaptive Data-driven alert and Attention Management Strategy (RADAMS) that de-emphasizes alerts selectively based on the abstracted category labels of the alerts. RADAMS uses reinforcement learning to achieve a customized and transferable design for various human operators and evolving IDoS attacks. The integrated modeling and theoretical analysis lead to the Product Principle of Attention (PPoA), fundamental limits, and the tradeoff among crucial human and economic factors. Experimental results corroborate that the proposed strategy outperforms the default strategy and can reduce the IDoS risk by as much as\n20\n%\n. Besides, the strategy is resilient to large variations of costs, attack frequencies, and human attention capacities. We have recognized interesting phenomena such as attentional risk equivalency, attacker’s dilemma, and the half-truth optimal attack strategy.}
}


@article{DBLP:journals/compsec/Garcia-TeodoroG22,
	author = {Pedro Garc{\'{\i}}a{-}Teodoro and
                  Jos{\'{e}} Antonio G{\'{o}}mez{-}Hern{\'{a}}ndez and
                  Alberto Abell{\'{a}}n{-}Galera},
	title = {Multi-labeling of complex, multi-behavioral malware samples},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102845},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102845},
	doi = {10.1016/J.COSE.2022.102845},
	timestamp = {Mon, 28 Aug 2023 21:25:58 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/Garcia-TeodoroG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of malware samples is usually required to test cyber security solutions. For that, the correct typology of the samples is of interest to properly estimate the exhibited performance of the tools under evaluation. Although several malware datasets are publicly available at present, most of them are not labeled or, if so, only one class or tag is assigned to each malware sample. We defend that just one label is not enough to represent the usual complex behavior exhibited by most of current malware. With this hypothesis in mind, and based on the varied classification generally provided by automatic detection engines per sample, we introduce here a simple multi-labeling approach to automatically tag the usual multiple behavior of malware samples. In the paper, we first analyze the coherence between the behaviors exhibited by a specific number of well-known malware samples dissected in the literature and the multiple tags provided for them by our labeling proposal. After that, the automatic multi-labeling scheme is executed over four public Android malware datasets, the different results and statistics obtained regarding their composition and representativeness being discussed. We share in a GitHub repository the multi-labeling tool developed, for public usage.}
}


@article{DBLP:journals/compsec/DemirkiranCUD22,
	author = {Ferhat Demirkiran and
                  Aykut {\c{C}}ayir and
                  Ugur {\"{U}}nal and
                  Hasan Dag},
	title = {An ensemble of pre-trained transformer models for imbalanced multiclass
                  malware classification},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102846},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102846},
	doi = {10.1016/J.COSE.2022.102846},
	timestamp = {Mon, 28 Aug 2023 21:26:05 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/DemirkiranCUD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Classification of malware families is crucial for a comprehensive understanding of how they can infect devices, computers, or systems. Hence, malware identification enables security researchers and incident responders to take precautions against malware and accelerate mitigation. API call sequences made by malware are widely utilized features by machine and deep learning models for malware classification as these sequences represent the behavior of malware. However, traditional machine and deep learning models remain incapable of capturing sequence relationships among API calls. Unlike traditional machine and deep learning models, the transformer-based models process the sequences in whole and learn relationships among API calls due to multi-head attention mechanisms and positional embeddings. Our experiments demonstrate that the Transformer model with one transformer block layer surpasses the performance of the widely used base architecture, LSTM. Moreover, BERT or CANINE, the pre-trained transformer models, outperforms in classifying highly imbalanced malware families according to evaluation metrics: F1-score and AUC score. Furthermore, our proposed bagging-based random transformer forest (RTF) model, an ensemble of BERT or CANINE, reaches the state-of-the-art evaluation scores on the three out of four datasets, specifically it captures a state-of-the-art F1-score of 0.6149 on one of the commonly used benchmark dataset.}
}


@article{DBLP:journals/compsec/LongGXZ22,
	author = {Teng Long and
                  Qi Gao and
                  Lili Xu and
                  Zhangbing Zhou},
	title = {A survey on adversarial attacks in computer vision: Taxonomy, visualization
                  and future directions},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102847},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102847},
	doi = {10.1016/J.COSE.2022.102847},
	timestamp = {Mon, 29 Jan 2024 17:56:10 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LongGXZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning has been widely applied in various fields such as computer vision, natural language processing, and data mining. Although deep learning has achieved significant success in solving complex problems, it has been shown that deep neural networks are vulnerable to adversarial attacks, resulting in models that fail to perform their tasks properly, which limits the application of deep learning in security-critical areas. In this paper, we first review some of the classical and latest representative adversarial attacks based on a reasonable taxonomy of adversarial attacks. Then, we construct a knowledge graph based on the citation relationship relying on the software VOSviewer, visualize and analyze the subject development in this field based on the information of 5923 articles from Scopus. In the end, possible research directions for the development about adversarial attacks are proposed based on the trends deduced by keywords detection analysis. All the data used for visualization are available at:\nhttps://github.com/NanyunLengmu/Adversarial-Attack-Visualization\n.}
}


@article{DBLP:journals/compsec/WangZXZH22,
	author = {Chuanwang Wang and
                  Junjie Zhang and
                  Ming Xu and
                  Haodong Zhang and
                  Weili Han},
	title = {{\#}Segments: {A} Dominant Factor of Password Security to Resist against
                  Data-driven Guessing},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102848},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102848},
	doi = {10.1016/J.COSE.2022.102848},
	timestamp = {Mon, 28 Aug 2023 21:25:27 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangZXZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Understanding which factors dominate password security is vital for users to create their secure passwords. Prior works generally consider the password length and the number of character classes as the dominant factors. However, creating secure passwords based on the above two factors becomes much more challenging than before due to the emergence of powerful data-driven guessing methods, e.g., the Probabilistic Context-free Grammars (PCFG) and its variations, Markov-based methods, and neural-network-based methods. In this paper, inspired by the segments used in PCFG, where a segment is a continuous string whose characters have a strong correlation, we conduct a comprehensive empirical analysis and find that the number of segments (# Segments for short) is a dominant factor of password security to resist against data-driven guessing. That is, the increase of # Segments generally leads to a significant improvement of password security. The observation helps us explore an optimised identification method for segments, referred to as re-segment, which reduces # Segments as much as possible to obtain accurate # Segments by leveraging five popular patterns (i.e., keyboard, abbreviation, leet, mixture, and component), to evaluate password security more accurately from an adversary’s viewpoint. Then we propose an efficient data-driven guessing method, referred to as ReSeg-PCFG, by leveraging re-segment based on the latest version of PCFG. Our study shows that ReSeg-PCFG outperforms the state-of-the-art data-driven guessing methods in almost all scenarios; e.g., it outperforms the latest version of PCFG by up to\n79.34\n% at\n10\n14\nguesses, a commonly used threshold of off-line attacks.}
}


@article{DBLP:journals/compsec/Villalon-Huerta22,
	author = {Antonio Villal{\'{o}}n{-}Huerta and
                  Hector Marco{-}Gisbert and
                  Ismael Ripoll{-}Ripoll},
	title = {A Taxonomy for Threat Actors' Persistence Techniques},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102855},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102855},
	doi = {10.1016/J.COSE.2022.102855},
	timestamp = {Mon, 28 Aug 2023 21:26:10 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/Villalon-Huerta22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The main contribution of this paper is to provide an accurate taxonomy for Persistence techniques, which allows the detection of novel techniques and the identification of appropriate countermeasures. Persistence is a key tactic for advanced offensive cyber operations. The techniques that achieve persistence have been largely analyzed in particular environments, but there is no suitable platform–agnostic model to structure persistence techniques. This lack causes a serious problem in the modeling of activities of advanced threat actors, hindering both their detection and the implementation of countermeasures against their activities. In this paper we analyze previous work in this field and propose a novel taxonomy for persistence techniques based on persistence points, a key concept we introduce in our work as the basis for the proposed taxonomy. Our work will help analysts to identify, classify and detect compromises, significantly reducing the amount of effort needed for these tasks. It follows a logical structure that can be easy to expand and adapt, and it can be directly used in commonly accepted industry standards such as MITRE ATT&CK.}
}


@article{DBLP:journals/compsec/LiMDXZ22,
	author = {Kehong Li and
                  Wengang Ma and
                  Huawei Duan and
                  Han Xie and
                  Juanxiu Zhu},
	title = {Few-shot IoT attack detection based on {RFP-CNN} and adversarial unsupervised
                  domain-adaptive regularization},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102856},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102856},
	doi = {10.1016/J.COSE.2022.102856},
	timestamp = {Mon, 28 Aug 2023 21:25:47 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiMDXZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of things (IoT) has attracted extensive research attention in recent years. Cyber-attack protection for IoT devices has become critically important. Malicious users or attackers can take control of IoT devices, thereby putting a wide range of IoT security and privacy data at risk. Thus, the detection and prevention of new attack types are critical in IoT environments. Big data samples are used to train current IoT attack detection models. In certain cases, only few-shot network attack samples can be intercepted. They are susceptible to malicious traffic in an IoT environment, with a reduction in their detection efficiency and accuracy. In this paper, we propose an adversarial unsupervised domain-adaptive regularization and an improved Cascade R-CNN (RFP-CNN) to detect IoT attacks more effectively. First, a feature extraction network (RFP-CNN) is designed. By employing recursive feature pyramids and neural architecture search, the Cascade R-CNN is optimized, and it can extract high-level attack features. Subsequently, an adversarial unsupervised domain-adaptive regularization model is developed, which is known as global cluster center structure regularization. Its purpose is to enable attacks with fewer samples to transfer from other attacks. The model is decoupled into a feature extractor and a domain discriminator using a Siamese network. Finally, our method is validated using four network intrusion datasets pertaining to the IoT. The results demonstrate that our method is capable of extracting time-frequency features. The proposed method exhibits the highest detection accuracy when only a few attack samples are available. It provides excellent anti-noise performance and a short running time when noise is added to the IoT environment. Furthermore, it can be used to detect few-shot IoT attacks in real time.}
}


@article{DBLP:journals/compsec/GaoLZWWS22,
	author = {Yansong Gao and
                  Qun Li and
                  Yifeng Zheng and
                  Guohong Wang and
                  Jiannan Wei and
                  Mang Su},
	title = {{SEDML:} Securely and efficiently harnessing distributed knowledge
                  in machine learning},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102857},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102857},
	doi = {10.1016/J.COSE.2022.102857},
	timestamp = {Wed, 27 Sep 2023 19:51:44 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GaoLZWWS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Training high-performing machine learning models require a rich amount of data which is usually distributed among multiple data sources in practice. Simply centralizing these multi-sourced data for training would raise critical security and privacy concerns, and might be prohibited given the increasingly strict data regulations. To resolve the tension between privacy and data utilization in distributed learning, a machine learning framework called private aggregation of teacher ensembles (PATE) has been recently proposed. PATE harnesses the knowledge (label predictions for an unlabeled dataset) from distributed teacher models to train a student model, obviating access to distributed datasets. Despite being enticing, PATE does not offer protection for the individual label predictions from teacher models, which still entails privacy risks. In this paper, we propose SEDML, a new protocol which allows to securely and efficiently harness the distributed knowledge in machine learning. SEDML builds on lightweight cryptography and provides strong protection for the individual label predictions, as well as differential privacy guarantees on the aggregation results. Extensive evaluations show that while providing privacy protection, SEDML preserves the accuracy as in the plaintext baseline. Meanwhile, SEDML outperforms the state-of-the-art work of Xiang et al. (ICDCS’20) by\n43\n×\nin computation and\n1.23\n×\nin communication.}
}


@article{DBLP:journals/compsec/LiuRLLZ22,
	author = {Zhenpeng Liu and
                  Lele Ren and
                  Ruilin Li and
                  Qiannan Liu and
                  Yonggang Zhao},
	title = {ID-based sanitizable signature data integrity auditing scheme with
                  privacy-preserving},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102858},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102858},
	doi = {10.1016/J.COSE.2022.102858},
	timestamp = {Mon, 28 Aug 2023 21:25:39 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiuRLLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {More and more companies, institutions and organizations are choosing to put vast amounts of data on the cloud. However, applications such as multimedia office, e-government and e-health systems need to withhold some data in order to hide highly confidential information when uploading to the cloud. A new data integrity auditing scheme is proposed to protect the privacy information and share the data. The idea of sanitizable signature is used to sanitize the private data to protect the privacy and generate effective signatures to verify the integrity of the data. At the same time, the identity-based encryption auditing mechanism simplifies the complex certificate management and improves the audit efficiency. The stability of the scheme is verified by calculating the Computational Diffie-Hellman Problem (CDHP) and Discrete Logarithm Problem (DLP) in the stochastic prediction model. The performance of the proposed scheme is evaluated by simulation experiments, which proves that the proposed scheme is safe and effective.}
}


@article{DBLP:journals/compsec/ArshadBC22,
	author = {Elham Arshad and
                  Michele Benolli and
                  Bruno Crispo},
	title = {Practical attacks on Login {CSRF} in OAuth},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102859},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102859},
	doi = {10.1016/J.COSE.2022.102859},
	timestamp = {Mon, 28 Aug 2023 21:25:47 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ArshadBC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {OAuth 2.0 is an important and well studied protocol. However, despite the presence of guidelines and best practices, the current implementations are still vulnerable and error-prone. This research mainly focused on the Cross-Site Request Forgery (CSRF) attack. This attack is one of the dangerous vulnerabilities in OAuth protocol, which has been mitigated through state parameter. However, despite the presence of this parameter in the OAuth deployment, many websites are still vulnerable to the OAuth-CSRF (OCSRF) attack. We studied one of the most recurrent type of OCSRF attack through a variety range of novel attack strategies based on different possible implementation weaknesses and the state of the victim’s browser at the time of the attack. In order to validate them, we designed a repeatable methodology and conducted a large-scale analysis on 395 high-ranked sites to assess the prevalence of OCSRF vulnerabilities. Our automated crawler discovered about 36% of targeted sites are still vulnerable and detected about 20% more well-hidden vulnerable sites utilizing the novel attack strategies. Based on our experiment, there was a significant rise in the number of OCSRF protection compared to the past scale analyses and yet over 25% of sites are exploitable to at least one proposed attack strategy. Despite a standard countermeasure exists to mitigate the OCSRF, our study shows that lack of awareness about implementation mistakes is an important reason for a significant number of vulnerable sites.}
}


@article{DBLP:journals/compsec/AlmashhadaniCKS22,
	author = {Ahmad O. Almashhadani and
                  Domhnall Carlin and
                  Mustafa Kaiiali and
                  Sakir Sezer},
	title = {{MFMCNS:} a multi-feature and multi-classifier network-based system
                  for ransomworm detection},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102860},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102860},
	doi = {10.1016/J.COSE.2022.102860},
	timestamp = {Tue, 07 May 2024 20:21:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AlmashhadaniCKS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ransomware is a type of advanced malware that can encrypt a user’s files or lock a computer system until a ransom has been paid. Ransomworm is a type of malware that combines the payload of ransomware with the propagation feature of a computer worm. Most host-based detection methods require the host to be infected and the payload to be executed first to be able to identify anomalies and detect the malware. By the time of infection, it might too late as some of the system’s assets would have been already encrypted or exfiltrated by the malware. On the contrary, the network-based methods can be one of the crucial means in detecting ransomworm activities when it attempts to spread to infect other networks before executing the payload. Therefore, a thorough analysis of ransomworm network traffic can be one of the essential means for early detection. This paper presents a comprehensive behavioral analysis of ransomworm network traffic, taking WannaCry, which launched a worldwide cyberattack, and NotPetya as a case study. Two sets of related features were extracted based on two independent flow levels: session-based and time-based. On top of each set, an independent classifier was built. Moreover, to improve the reliability, a multi-feature and multi-classifier network-based system, MFMCNS, has been proposed. MFMCNS employs these classifiers working in parallel on different flow levels, then it adopts a fusion rule to combine the classifiers’ decisions. The experimental results prove that MFMCNS is reliable and has high detection accuracy.}
}


@article{DBLP:journals/compsec/ZhangJWWLY22,
	author = {Chunying Zhang and
                  Donghao Jia and
                  Liya Wang and
                  Wenjie Wang and
                  Fengchun Liu and
                  Aimin Yang},
	title = {Comparative research on network intrusion detection methods based
                  on machine learning},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102861},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102861},
	doi = {10.1016/J.COSE.2022.102861},
	timestamp = {Sat, 30 Sep 2023 10:07:34 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangJWWLY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network intrusion detection system is an essential part of network security research. It detects intrusion behaviors through active defense technology and takes emergency measures such as alerting and terminating intrusions. With the rapid development of machine learning technology, more and more researchers apply machine learning algorithms to network intrusion detection to improve detection efficiency and accuracy. Due to the different principles of various algorithms, they also have their advantages and disadvantages. To construct the dominant algorithm model in the field of network intrusion detection and provide the accuracy value, this paper systematically combs the application literature of machine learning algorithms in intrusion detection in the past ten years. A review is made from three categories: traditional machine learning, ensemble learning, and deep learning. Then, this paper selects the KDD CUP99 and NSL-KDD datasets to conduct comparative experiments on decision trees, Naive Bayes, support vector machines, random forests, XGBoost, convolutional neural networks, and recurrent neural networks. The detection accuracy, F1, AUC, and other indicators of these algorithms on different data sets are compared. The experimental results show that the effect of the ensemble learning algorithm is generally better. The Naive Bayes algorithm has low accuracy in recognizing the learned data, but it has obvious advantages when facing new types of attacks, and the training speed is faster. The deep learning algorithm is not particularly prominent in this experiment, but its optimal results are affected by the structure, hyperparameters, and the number of training iterations, which need further in-depth study. Finally, the main challenges facing the current network intrusion detection field are summarized, and the future research directions have been prospected.}
}


@article{DBLP:journals/compsec/FrimpongMU22,
	author = {Eugene Frimpong and
                  Antonis Michalas and
                  Amjad Ullah},
	title = {Footsteps in the fog: Certificateless fog-based access control},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102866},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102866},
	doi = {10.1016/J.COSE.2022.102866},
	timestamp = {Mon, 28 Aug 2023 21:26:05 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/FrimpongMU22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferating adoption of the Internet of Things (IoT) paradigm has fuelled the need for more efficient and resilient access control solutions that aim to prevent unauthorized resource access. The majority of existing works in this field follow either a centralized approach (i.e. cloud-based) or an architecture where the IoT devices are responsible for all decision-making functions. Furthermore, the resource-constrained nature of most IoT devices make securing the communication between these devices and the cloud using standard cryptographic solutions difficult. In this paper, we propose a distributed access control architecture where the core components are distributed between fog nodes and the cloud. To facilitate secure communication, our architecture utilizes a Certificateless Hybrid Signcryption scheme without pairing. We prove the effectiveness of our approach by providing a comparative analysis of its performance in comparison to the commonly used cloud-based centralized architectures. Our implementation uses Azure – an existing commercial platform, and Keycloak – an open-source platform, to demonstrate the real-world applicability. Additionally, we measure the performance of the adopted encryption scheme on two types of resource-constrained devices to further emphasize the applicability of the proposed architecture. Finally, the experimental results are coupled with a theoretical analysis that proves the security of our approach.}
}


@article{DBLP:journals/compsec/XieLZSX22,
	author = {Jiang Xie and
                  Shuhao Li and
                  Yongzheng Zhang and
                  Peishuai Sun and
                  Hongbo Xu},
	title = {Analysis and Detection against Network Attacks in the Overlapping
                  Phenomenon of Behavior Attribute},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102867},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102867},
	doi = {10.1016/J.COSE.2022.102867},
	timestamp = {Mon, 28 Aug 2023 21:26:05 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XieLZSX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of network attacks poses a significant threat. Researchers propose datasets for network attacks to support research in related fields. Then, many attack detection methods based on these datasets are proposed. These detection methods, whether two-classification or multi-classification, belong to single-label learning, i.e., only one label is given to each sample. However, we discover that there is a noteworthy phenomenon of behavior attribute overlap between attacks, The presentation of this phenomenon in a dataset is that there are multiple samples with the same features but different labels. In this paper, we verify the phenomenon in well-known datasets(UNSW-NB15, CCCS-CIC-AndMal-2020) and re-label these data. In addition, detecting network attacks in a multi-label manner can obtain more information, providing support for tracing the attack source and building IDS. Therefore, we propose a multi-label detection model based on deep learning, MLD-Model, in which Wasserstein-Generative-Adversarial-Network-with-Gradient-Penalty (WGAN-GP) with improved loss performs data enhancement to alleviate the class imbalance problem, and Auto-Encoder (AE) performs classifier parameter pre-training. Experimental results demonstrate that MLD-Model can achieve excellent classification performance. It can achieve\nF\n1\n=80.06% in UNSW-NB15 and\nF\n1\n=83.63% in CCCS-CIC-AndMal-2020. Especially, MLD-Model is 5.99%\n∼\n7.97% higher in\nF\n1\ncompared with the related single-label methods.}
}


@article{DBLP:journals/compsec/Ray-DowlingHSB22,
	author = {Aratrika Ray{-}Dowling and
                  Daqing Hou and
                  Stephanie Schuckers and
                  Abbie Barbir},
	title = {Evaluating multi-modal mobile behavioral biometrics using public datasets},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102868},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102868},
	doi = {10.1016/J.COSE.2022.102868},
	timestamp = {Mon, 28 Aug 2023 21:25:52 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/Ray-DowlingHSB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Behavioral biometric-based continuous user authentication is promising for securing mobile phones while complementing traditional security mechanisms. However, the existing state of art perform continuous authentication to evaluate deep learning models, but lacks examining different feature sets over the data. Therefore, we evaluate the performance of user authentication based on acceleration, gyroscope (angular velocity), and swipe data from two public mobile datasets, HMOG (Hand-Movement, Orientation, and Grasp) (Sitová et al., (2015) dataset et al. (2015)) and BB-MAS (Behavioral Biometrics Multi-device and multi-Activity data from Same users) (Belman et al., (2019) dataset et al. (2019)) extracted with different feature sets to observe the variation in authentication performance. We evaluate the performances of both individual modalities and their fusion. Since the swipe data is intermittent but the motion event data continuous, we evaluate fusion of swipes with motion events that occur within the swipes versus fusion of motion events outside of swipes. Moreover, we extract Frank et al.’s (2012) Touchalytics features Frank et al. (2012) on the swipe data but three different feature sets (median, HMOG (Sitová et al. (2015)), and Shen’s (Shen et al. (2017))) on the motion event data, among which the Shen’s features were shown to perform the best. More specifically, we perform score-level fusion for a single modality utilizing binary SVMs (Support Vector Machine). Furthermore, we evaluate the fusion of multiple modalities using Nandakumar’s likelihood ratio-based score fusion (Nandakumar et al. (2007)) by utilizing both one-class and binary SVMs. The best EERs (Equal Error Rates) of fusing all three modalities when using the one-class SVMs are 8.8% and 0.9% for HMOG and BB-MAS respectively. On the other hand, the best EERs in the case of binary SVMs are 1.5% and 0.2% respectively. Observing the better performances of BB-MAS compared to HMOG in swipe-based experiments, we examine the difference of swipe trajectory between the two datasets and find that BB-MAS has longer swipes than HMOG which would explain the performance difference in the experiments.}
}


@article{DBLP:journals/compsec/ZhongHZLC22,
	author = {Fangtian Zhong and
                  Pengfei Hu and
                  Guoming Zhang and
                  Hong Li and
                  Xiuzhen Cheng},
	title = {Reinforcement learning based adversarial malware example generation
                  against black-box detectors},
	journal = {Comput. Secur.},
	volume = {121},
	pages = {102869},
	year = {2022},
	url = {https://doi.org/10.1016/j.cose.2022.102869},
	doi = {10.1016/J.COSE.2022.102869},
	timestamp = {Tue, 19 Sep 2023 16:49:24 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhongHZLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in machine learning offer attractive tools for sophisticated adversaries. An attacker could transform malware into its adversarial version but retain its malicious functionality by employing a dedicated perturbation method. These adversarial malware examples have demonstrated the effectiveness to bypass antivirus engines. However, recent works only leverage a single perturbation method to generate adversarial examples, which cannot defeat advanced detectors. In this paper, we propose a reinforcement learning-based framework called\nMalInfo\n, which could generate powerful adversarial malware examples to evade the third-party detectors via an adaptive selection of a perturbation path for each malware in our collected dataset with 1000 diverse malware. To cope with limited computation,\nMalInfo\napplies either dynamic programming or temporal difference learning to choose the optimal perturbation path where each path is formed by the combination of Obfusmal, Stealmal, and Hollowmal. We provide a proof-of-concept implementation and extensive evaluation of our framework. Both the detection rate and evasive rate have substantially been improved compared with the state-of-art research\nMalFox\nZhong et al. (2021). To be specific, The average detection rates for dynamic programming and temporal difference learning are\n23.2\n%\n(\n21.9\n%\nlower than\nMalFox\n) and\n27.5\n%\n(\n7.4\n%\nlower than\nMalFox\n), respectively, and the average evasive rates are\n65.8\n%\n(\n17.1\n%\nhigher than\nMalFox\n) and\n59.4\n%\n(\n5.7\n%\nhigher than\nMalFox\n), respectively.}
}
