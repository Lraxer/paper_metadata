@article{DBLP:journals/compsec/MersinasBF25,
	author = {Konstantinos Mersinas and
                  Maria Bada and
                  Steven Furnell},
	title = {Cybersecurity behavior change: {A} conceptualization of ethical principles
                  for behavioral interventions},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104025},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104025},
	doi = {10.1016/J.COSE.2024.104025},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MersinasBF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The importance of changing behaviors is gradually being acknowledged in cybersecurity, and the reason is the realization that a notable portion of security incidents have a human-related component. Thus, enhancing behaviors at individual level, can bring a significant reduction in security breaches overall. Behavior change refers to any modification of human behavior through some type of intervention. Interventions from behavioral economics and psychology are being increasingly introduced in the field, however, the ethics surrounding such interventions are largely neglected. In this paper, we raise the ethical issues associated with behavioral intervention approaches. We draw on the traditionally more mature field of biomedical ethics and propose six clusters of ethical principles suitable for cybersecurity behavior change. We conducted a survey ( N  = 141) to identify individuals’ perceptions on the proposed ethical principles and validate their perceived usefulness. We analyze an existing intervention in the light of our six-principle conceptualization to showcase how it can be used as a practical apparatus. Our set of ethical principles are aimed for cybersecurity professionals, policy makers, and behavioral intervention designers, and can serve as a starting point for best-practice development in cybersecurity behavior change ethics.}
}


@article{DBLP:journals/compsec/SahinV25,
	author = {Zeynep Sahin and
                  Anthony Vance},
	title = {What do we need to know about the Chief Information Security Officer?
                  {A} literature review and research agenda},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104063},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104063},
	doi = {10.1016/J.COSE.2024.104063},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SahinV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since its establishment in the 1990s, the role of chief information security officer (CISO) has become critical to organizations in managing cybersecurity risks. However, despite widespread recognition of the importance of this role in industry, research about CISOs and the problems they face in protecting organizations is nascent. We review the academic and practitioner literature on CISOs to identify existing themes and highlight a range of challenges related to CISOs in which further research is needed, such as establishing legitimacy within C-suite executive teams, appropriate accountability for cybersecurity incidents, CISO turnover, and promoting security in the face of human factors, business realities, and budget constraints. We also propose a research agenda to address these challenges using potential theoretical lenses. In these ways, this study lays the groundwork for future research on CISOs and their essential role in ensuring the cybersecurity of organizations.}
}


@article{DBLP:journals/compsec/RaiDPR25,
	author = {Anuj Rai and
                  Somnath Dey and
                  Pradeep Patidar and
                  Prakhar Rai},
	title = {MoSFPAD: An end-to-end ensemble of MobileNet and Support Vector Classifier
                  for fingerprint presentation attack detection},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104069},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104069},
	doi = {10.1016/J.COSE.2024.104069},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RaiDPR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automatic fingerprint recognition systems are the most extensively used systems for person authentication although they are vulnerable to Presentation attacks. Artificial artifacts created with the help of various materials are used to deceive these systems causing a threat to the security of fingerprint-based applications. This paper proposes a novel end-to-end model to detect fingerprint Presentation attacks. The proposed model incorporates MobileNet as a feature extractor and a Support Vector Classifier as a classifier to detect presentation attacks in cross-material and cross-sensor paradigms. The feature extractor’s parameters are learned with the loss generated by the support vector classifier. The proposed model eliminates the need for intermediary data preparation procedures, unlike other static hybrid architectures. The performance of the proposed model has been validated on benchmark LivDet 2011, 2013, 2015, 2017, and 2019 databases, and overall accuracy of 98.64%, 99.50%, 97.23%, 95.06%, and 95.20% are achieved on these databases, respectively. The performance of the proposed model is compared with state-of-the-art methods and is able to reduce the average classification error of 3.63%, 1.86%, 1.83%, 0.05%, 0.93% on LivDet 2011, 2013, 2015, 2017, and 2019 databases, respectively for same and cross material protocols in intra-sensor paradigm. The proposed method also reduced the average classification error of 1.59%, 1.41%, and 2.29% for LivDet 2011, 2013, and 2017 databases, respectively for the cross-sensor paradigm. It is evident from the results that the proposed method outperforms state-of-the-art methods in intra-sensor as well as cross-sensor paradigms in terms of average classification error.}
}


@article{DBLP:journals/compsec/RoumaniA25,
	author = {Yaman Roumani and
                  Mais Alraee},
	title = {Examining the factors that impact the severity of cyberattacks on
                  critical infrastructures},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104074},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104074},
	doi = {10.1016/J.COSE.2024.104074},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RoumaniA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In light of the rising threats of cyberattacks on critical infrastructures, cybersecurity has become a high priority for government agencies worldwide. In particular, the severity of cyberattacks could lead to devastating consequences for national security, economic growth, and public health and safety. While earlier studies have examined several factors related to detecting, preventing, and predicting cyberattacks on critical infrastructures, they have largely neglected to consider the severity aspect of these attacks. This study aims to bridge this research gap by examining the factors that influence the severity of cyberattacks on critical infrastructures. To achieve this, we analyze 897 reported attacks on critical infrastructures to examine the impact of incident type, ransomware, zero-day vulnerability, attacker type, conflict type, initial access vector, and the number of targeted countries on the severity of these cyberattacks. The results show that cyberattacks employing ransomware and initiated by nation-state actors have the most impact on severity. On the contrary, cyberattacks that include data theft, disruption, hijacking with or without misuse, involve multiple types of conflict, and target the energy and finance sectors have the least impact on the severity of attacks. To gain further insight into these results, we perform sub-analyses on the metrics that makeup severity. Findings show that cyberattacks on the health sector are more vulnerable to data theft of sensitive information compared to other sectors. Also, nation-state-led attacks are more likely to involve data theft of sensitive information and long-term disruptions. Finally, as years progress, the results generally indicate a decreasing likelihood of attacks involving data theft of sensitive information and hijacking with misuse.}
}


@article{DBLP:journals/compsec/RoseSGHR25,
	author = {Anthony J. Rose and
                  Christine M. Schubert{-}Kabban and
                  Scott R. Graham and
                  Wayne C. Henry and
                  Christopher M. Rondeau},
	title = {Malware classification through Abstract Syntax Trees and L-moments},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104082},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104082},
	doi = {10.1016/J.COSE.2024.104082},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/RoseSGHR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ongoing evolution of malware presents a formidable challenge to cybersecurity: identifying unknown threats. Traditional detection methods, such as signatures and various forms of static analysis, inherently lag behind these evolving threats. This research introduces a novel approach to malware detection by leveraging the robust statistical capabilities of L-moments and the structural insights provided by Abstract Syntax Trees (ASTs) and applying them to PowerShell. L-moments, recognized for their resilience to outliers and adaptability to diverse distributional shapes, are extracted from network analysis measures like degree centrality, betweenness centrality, and closeness centrality of ASTs. These measures provide a detailed structural representation of code, enabling a deeper understanding of its inherent behaviors and patterns. This approach aims to detect not only known malware but also uncover new, previously unidentified threats. A comprehensive comparison with traditional static analysis methods shows that this approach excels in key performance metrics such as accuracy, precision, recall, and  F 1 <math><msub is="true"><mrow is="true"><mi is="true">F</mi></mrow><mrow is="true"><mn is="true">1</mn></mrow></msub></math>  score. These results demonstrate the significant potential of combining L-moments derived from network analysis with ASTs in enhancing malware detection. While static analysis remains an essential tool in cybersecurity, the integration of L-moments and advanced network analysis offers a more effective and efficient response to the dynamic landscape of cyber threats. This study paves the way for future research, particularly in extending the use of L-moments and network analysis into additional areas.}
}


@article{DBLP:journals/compsec/PunithaRPS25,
	author = {A. Punitha and
                  P. Ramani and
                  Ezhilarasi P and
                  Sridhar S},
	title = {Dynamically stabilized recurrent neural network optimized with intensified
                  sand cat swarm optimization for intrusion detection in wireless sensor
                  network},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104094},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104094},
	doi = {10.1016/J.COSE.2024.104094},
	timestamp = {Mon, 03 Mar 2025 21:31:11 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/PunithaRPS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless Sensor Networks (WSNs) are susceptible to various security threats owing to its deployment in hostile environments. Intrusion detection system (IDS) contributes a critical role on securing WSNs by identifying malevolent activities and ensuring data integrity. Traditional IDS techniques often struggle with the dynamic and resource-constrained nature of WSNs. In this paper, Dynamically Stabilized Recurrent Neural Network Optimized with Intensified Sand Cat Swarm Optimization for Wireless Sensor Network Intrusion identification (DSRNN-ISCOA-ID-WSN) is proposed. Initially, the input data is amassed from WSN-DS dataset. After that, the pre-processing segment receives the data. In pre-processing stage, redundant and biased records are removed from input data with the help of Adaptive multi-scale improved differential filter (AMSIDF). Then the optimal are selected by utilizing Wolf-Bird Optimization Algorithm (WBOA). DSRNN is used to classify the data as Normal, Grey hole, Black hole, Time division multiple access (TDMA), and Flooding attacks. Then Intensified Sand Cat Swarm Optimization (ISCOA) is employed to optimize the weight parameters of DSRNN for accuracte classification. The proposed DSRNN-ISCOA-ID-WSN technique is implemented Python. The performance of the proposed DSRNN-ISCOA-ID-WSN approach attains 29.24 %, 33.45 %, and 28.73 % high accuracy; 30.53 %, 27.64 %, and 26.25 % higher precision when compared with existing method such as Machine Learning-Powered Stochastic Gradient Descent Intrusions Detection System for WSN Attacks (SGDA-ID-WSN), An updated dataset to identify threats in WSN (CNN-ID-WSN) and Denial-of-Service attack detection in WSN: a Low-Complexity Machine Learning Model (DTA-ID-WSN) respectively.}
}


@article{DBLP:journals/compsec/RaniKKK25,
	author = {Sita Rani and
                  Aman Kataria and
                  Sachin Kumar and
                  Vinod Karar},
	title = {A new generation cyber-physical system: {A} comprehensive review from
                  security perspective},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104095},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104095},
	doi = {10.1016/J.COSE.2024.104095},
	timestamp = {Mon, 03 Mar 2025 21:31:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/RaniKKK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-physical systems (CPSs) are essential to the contemporary industrial landscape, performing a central role in improving productivity, mechanization, and innovation across several sectors. These systems are the conflux of physical processes and digital mechanics, developing a symbiotic integration with numerous benefits. Communication technologies play a very significant role in CPSs by facilitating real-time data exchange, coordination, and coherent integration. 5G and Beyond communication technologies are contributing significantly to CPS by facilitating ultra-fast, low-latency connectedness. They also improve real-time transfer, enabling better control and supervision of physical processes. In this paper, the authors emphasized the security aspects of 5G and beyond CPSs. The significance of the domain is derived by studying the various application domains of the CPSs and literature published on CPS security. The major threats attempted on 5G and beyond CPS are discussed in detail along with the taxonomy of the exiting security solutions by covering the aspects of assessment of cyber-attacks emanation, CPS attack prototyping, attack identification, and development of security architectures. The authors also presented the major challenges occurring in the deployment of CPS applications, key research domains, and major issues in 5G and beyond CPS security. The security landscape of 6G CPS applications is also discussed in brief with key challenges.}
}


@article{DBLP:journals/compsec/ZhouSL25,
	author = {Hao Zhou and
                  Wenting Shen and
                  Jinlu Liu},
	title = {Certificate-based multi-copy cloud storage auditing supporting data
                  dynamics},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104096},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104096},
	doi = {10.1016/J.COSE.2024.104096},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhouSL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advent of cloud computing, users are increasingly choosing to store their data on cloud. As a result, data integrity and availability have emerged as key concerns for data owners. Users expect to store multiple copies of their data to cloud and ensure the integrity of these data copies. Currently, numerous multi-copy cloud storage auditing schemes have been proposed. However, most of them depend on public key infrastructure, identity-based cryptography, or certificateless cryptography. These schemes encounter challenges such as complicated certificate management, key escrow, or the necessity for a secure channel for distributing keys, respectively. Furthermore, most of them are not resilient to copy-summation attack. To address the above problems, we propose a certificate-based multi-copy cloud storage auditing scheme supporting data dynamics. We design a novel dynamic structure named Leaves Merkle hash tree (LMHT) to achieve multi-copy dynamic updates. Different from traditional Merkle hash trees, LMHT has significant advantages in data deletion. In addition, the proposed scheme can resist copy-summation attack, in which cloud cannot pass the verification if it only stores summation of all copies without storing data blocks’ all copies. Security analysis and performance evaluation demonstrate that the proposed scheme is secure and efficient.}
}


@article{DBLP:journals/compsec/SunWWFL25,
	author = {Pan Jun Sun and
                  Yi Wan and
                  Zongda Wu and
                  Zhaoxi Fang and
                  Qi Li},
	title = {A survey on privacy and security issues in IoT-based environments:
                  Technologies, protection measures and future directions},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104097},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104097},
	doi = {10.1016/J.COSE.2024.104097},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SunWWFL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the continuous development of information technology, privacy protection in the Internet of Things (IoT) has attracted people 's attention. This paper summarizes and discusses the privacy and security issues faced by various levels of the IoT, and proposes an overall framework for privacy and security protection; investigates the research progress of ABE search security in the IoT, summarizes the types of firmware implementation defects in the IoT, analyzes the typical defect generation mechanisms, and summarizes the existing firmware defect detection methods from the perspectives of static analysis, symbol execution, fuzzy testing, program validation, and machine learning; analyzes the existing mainstream access control models in the IoT, and summarizes the issues that need to be addressed in the future for blockchain based access control in the IoT. It further studies the recent achievements and progress of machine learning in the security protection of the IoT, and summarizes the privacy laws, especially the information protection law of the European Union (EU) in enterprises. Finally, we propose the main challenges that current research still faces and point out the direction of future research development.}
}


@article{DBLP:journals/compsec/LiangWDWJ25,
	author = {Chen Liang and
                  Qiang Wei and
                  Jiang Du and
                  Yisen Wang and
                  Zirui Jiang},
	title = {Survey of source code vulnerability analysis based on deep learning},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104098},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104098},
	doi = {10.1016/J.COSE.2024.104098},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiangWDWJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Amidst the rapid development of the software industry and the burgeoning open-source culture, vulnerability detection within the software security domain has emerged as an ever-expanding area of focus. In recent years, the rapid advancement of artificial intelligence, particularly the notable progress in deep learning for pattern recognition and natural language processing, has catalyzed a surge in research endeavors exploring the integration of deep learning for the enhancement of vulnerability detection techniques. In this paper, we investigate contemporary deep learning-based source code analysis methods, with a concentrated emphasis on those pertaining to static code vulnerability detection. We categorize these methods based on various representations of source code employed during the preprocessing stage, including token-based and graph-based representations of source code, and further subdivided based on the types of deep learning algorithms or graph representations employed. We summarize the basic processes of model training and vulnerability detection under these different representation formats. Furthermore, we explore the limitations inherent in current approaches and provide insights into future trends and challenges for research in this field.}
}


@article{DBLP:journals/compsec/WangPZW25,
	author = {Chiheng Wang and
                  Jianshan Peng and
                  Junhu Zhu and
                  Qingxian Wang},
	title = {AugPersist: Automatically augmenting the persistence of coverage-based
                  greybox fuzzing for persistent software},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104099},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104099},
	doi = {10.1016/J.COSE.2024.104099},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangPZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fuzzing is one of the most successful approaches for verifying software functionalities and discovering security vulnerabilities. However, the software with persistent runtime characteristics (e.g., web service programs) cannot be effectively tested by current coverage-based greybox (CG) fuzzers, which strictly rely on the termination state of the target software to feed test cases synchronously and obtain code coverage. The present approach requires delicate analysis and modification of the target to eliminate its persistence, but leads to excessive non-essential restarts during testing, resulting in low throughput. To improve the convenience and efficiency of CG fuzzing for persistent software, we propose augmenting persistence (AugPersist) as a complementary method. AugPersist introduces the concept of persistent basic block (PBB) to leverage the inherent code features of persistent software. PBB can be found automatically and quickly before fuzzing based on the execution flow graph (EFG). On this basis, we develop a low- delay synchronous communication so that after regular test cases are fed into the target, the fuzzer can derive code coverage without rebooting the target, thus significantly minimizing extraneous restarts. Additionally, by utilizing the self-adaptive forkserver, we can dynamically adjust the re-execution point of the target to the PBB position, which further minimizes losses when test cases trigger exceptions and cause necessary restarts. To show the potential of augmenting persistence, we create two implementations, AFL-AugPersist and AFLNet-AugPersist, using AFL and AFLNet as baselines. We evaluate both with their respective baselines on different benchmarks. AFL-AugPersist makes stateless persistent software easier to be fuzzed than AFL and provides 4.9 × to 71.1 × throughput improvement compared to AFL. The throughput of AFLNet-AugPersist improves by a maximum of 210.0 × and a minimum of 3.3 × compared to AFLNet. These results show that AugPersist significantly contributes to the convenience and efficiency of CG fuzzing on persistent software.}
}


@article{DBLP:journals/compsec/ZhangHL25,
	author = {Shunliang Zhang and
                  Weiqing Huang and
                  Yinlong Liu},
	title = {A systematic survey on physical layer security oriented to reconfigurable
                  intelligent surface empowered 6G},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104100},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104100},
	doi = {10.1016/J.COSE.2024.104100},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangHL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 6G system is envisioned to support various new applications with diverse requirements in terms of quality and security. To fulfill diverse and stringent requirements, reconfigurable intelligent surfaces (RIS) have been extensively studied as a 6G enabling technology. RIS can be used to secure communications and boost the system performance, but it leads to new security threats as well. Due to the open nature of the wireless channel, smart radio environment, dynamic network topology, and adversarial machine learning (ML), 6G will face various unprecedented security threats. Given stringent requirements on quality of service (QoS), security, and massive low-cost Internet of Thing (IoT) devices, physical layer security (PLS) by exploiting the random nature of the wireless channel and/or intrinsic hardware imperfection emerges as a complementary approach to secure wireless communications. Meanwhile, the rapid development of artificial intelligence (AI) promotes the development of intelligent PLS solutions and smart attacks. In this paper, we make a comprehensive overview of PLS for RIS-based 6G systems from both defensive and offensive perspectives. We first introduce the vision of the RIS-enabled 6G smart radio environment. Then, typical security risks and requirements on RIS-based 6G are analyzed. After that, the state-of-the-art techniques on PLS are presented. Subsequently, major academic works on the physical layer security solution oriented to RIS are systematically reviewed. Moreover, the latest studies on attacks based on adversarial RIS are discussed in depth. Finally, we identify multiple open issues and research opportunities to inspire further studies for more intelligent PLS to secure the RIS-enabled 6G system.}
}


@article{DBLP:journals/compsec/LiCXZW25,
	author = {Qingyun Li and
                  Wei Chen and
                  Xiaotang Xu and
                  Yiting Zhang and
                  Lifa Wu},
	title = {Precision strike: Precise backdoor attack with dynamic trigger},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104101},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104101},
	doi = {10.1016/J.COSE.2024.104101},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiCXZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks have advanced significantly in the last several years and are now widely employed in numerous significant real-world applications. However, recent research has shown that deep neural networks are vulnerable to backdoor attacks. Under such attacks, attackers release backdoor models that achieve satisfactory performance on benign samples while behaving abnormally on inputs with predefined triggers. Successful backdoor attacks can have serious consequences, such as attackers using backdoor generation methods to bypass critical face recognition authentication systems. In this paper, we propose PBADT, a precise backdoor attack with dynamic trigger. Unlike existing work that uses static or random trigger masks, we design an interpretable trigger mask generation framework that places triggers at positions that have the most significant impact on the prediction results. Meanwhile, backdoor attacks are made more efficient by using forgettable events to improve the efficiency of backdoor attacks. The proposed backdoor method is extensively evaluated on three face recognition datasets, LFW, CelebA, and VGGFace, while further evaluated on two general image datasets, CIFAR-10 and GTSRB. Our approach achieves almost perfect attack performance on backdoor data.}
}


@article{DBLP:journals/compsec/LiLDZL25,
	author = {Heqing Li and
                  Xinde Li and
                  Fir Dunkin and
                  Zhentong Zhang and
                  Xiaoyan Lu},
	title = {Adaptive multi-granularity trust management scheme for {UAV} visual
                  sensor security under adversarial attacks},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104108},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104108},
	doi = {10.1016/J.COSE.2024.104108},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiLDZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The big data provided by unmanned aerial vehicle (UAV) visual sensors offers essential information resources for activities across various industries. However, various adversarial threats are inevitable throughout the lifecycle of data generation, transmission, and utilization, leading to serious security risks. Trust assessment of visual sensors is a prerequisite for securing UAVs, but the multidimensionality of the trust elements and the uncertainty of the evidence limit its practical application. To advance this research, we innovatively propose a trust management scheme based on multi-granularity evidence fusion within the framework of belief functions (BFs) theory to adaptively respond to both known and unknown threats. We first propose a direct trust assessment model for known threats, which constructs multidimensional coarse-grained trust elements (MCTEs) and integrates multiple lightweight sub-models for basic belief assignment (BBA) to meet the need for fast response. Then, to address the unknown threats, we introduce pre-trained models to build multidimensional fine-grained trust elements (MFTEs) to construct trust recommendation models for indirect trust assessment for visual sensors. In addition, to accurately characterize the trustworthiness of visual sensors, we also introduce a BBA-weighted fusion method to achieve more reasonable trust aggregation by weakening highly conflicting evidence sources. Finally, to validate the effectiveness of the proposed method, we conducted a comprehensive trust assessment and security experiment on UAV aerial images. The results indicate that the proposed method demonstrates excellent performance and is beneficial for enhancing UAV security in adversarial attack scenarios.}
}


@article{DBLP:journals/compsec/KumarJI25,
	author = {Prabhat Kumar and
                  Alireza Jolfaei and
                  A. K. M. Najmul Islam},
	title = {An enhanced Deep-Learning empowered Threat-Hunting Framework for software-defined
                  Internet of Things},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104109},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104109},
	doi = {10.1016/J.COSE.2024.104109},
	timestamp = {Mon, 03 Mar 2025 21:31:11 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KumarJI25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Software-Defined Networking (SDN) powered Internet of Things (IoT) offers a global perspective of the network and facilitates control and access of IoT devices using a centralized high-level network approach called Software Defined-IoT (SD-IoT). However, this integration and high flow of data generated by IoT devices raises serious security issues in the centralized control intelligence of SD-IoT. Motivated by the aforementioned challenges, we present a new Deep-Learning empowered Threat Hunting Framework named DLTHF to protect SD-IoT data and detect (binary and multi-vector) attack vectors. First, an automated unsupervised feature extraction module is designed that combines data perturbation-driven encoding and normalization-driven scaling with the proposed Long Short-Term Memory Contractive Sparse AutoEncoder (LSTMCSAE) method to filter and transform dataset values into the protected format. Second, using the encoded data, a novel Threat Detection System (TDS) using Multi-head Self-attention-based Bidirectional Recurrent Neural Networks (MhSaBiGRNN) is designed to detect cyber threats and their types. In particular, a unique TDS strategy is developed in which each time instances is analyzed and allocated a self-learned weight based on the degree of relevance. Further, we also design a deployment architecture for DLTHF in the SD-IoT network. The framework is rigorously evaluated on two new SD-IoT data sources to show its effectiveness.}
}


@article{DBLP:journals/compsec/SuttonT25,
	author = {Anna Sutton and
                  Lisa Tompson},
	title = {Towards a cybersecurity culture-behaviour framework: {A} rapid evidence
                  review},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104110},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104110},
	doi = {10.1016/J.COSE.2024.104110},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/SuttonT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A strong organisational cybersecurity culture (CSC) is critical to the success of any cybersecurity effort, and understanding and measuring CSC is essential if it is to succeed. To facilitate the framing and measurement of CSC we conducted a rapid evidence assessment (REA) to synthesise relevant studies on CSC. The systematic search identified 1,768 records. 59 studies were eligible for the final synthesis. Thematic analysis of the CSC definitions in the included studies highlighted that CSC should not be viewed solely as a technical problem but as a management issue too; CSC requires top management involvement and role modelling, with full organisational support for the desired employee behaviours. We identify both theoretically and empirically derived models of CSC in the REA, along with a range of methods to develop and test these models. Integrative analysis of these models provides detailed information about CSC dimensions, including employee attitudes towards CS; compliance with policies; the role of security education, training and awareness; monitoring of behaviour and top management commitment. The evidence indicates that CSC should be understood both in the context of the wider organisational culture as well as in the shared employee understanding of CS that leads to behaviour. Based on the findings of this review, we propose a novel integrated framework of CSC consisting of cultural values, the culture-to-behaviour link, and behaviour itself. We also make measurement recommendations based on this CSC framework, ranging from simple, broad-brush tools through to suggestions for multi-dimensional measures, which can be applied in a variety of sectors and organisations.}
}


@article{DBLP:journals/compsec/ChenBPW25,
	author = {Wei Chen and
                  Zhiyuan Bai and
                  Gaoyuan Pan and
                  Jian Wang},
	title = {A fast modularity hardware Trojan detection technique for large scale
                  gate-level netlists},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104111},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104111},
	doi = {10.1016/J.COSE.2024.104111},
	timestamp = {Mon, 30 Sep 2024 22:34:14 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenBPW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hardware Trojans (HTs) are a kind of malicious circuit implanted by adversaries and induce malfunction under rare situations. Attackers may insert HTs into untrusted third-party intellectual properties (3PIPs), thus severely threatening the hardware security of ICs. To overcome this issue, state-of-art HT detection techniques are proposed based on feature extraction of gate-level netlists (GLNs). However, these techniques may take a long time to extract HT signals for large scale GLNs. In this paper, we propose a fast modularity HT detection (FMTD) method for large scale GLNs. The GLN modularity algorithm can divide the whole GLN into several small modules with the boundaries of D flip-flops (DFFs) of each module. By analyzing the transition rate of critical signals, preserving suspicious DFFs, and repairing the ring circuit, we can ensure the integrity of HT circuits during the GLN modularity process. Then, the calculation of the testability of each module is conducted in parallel with our self-designed tool. In the self-designed tool, we repair the ring circuit, calculate the testability values, and calibrate the testability values of module boundary signals. Compared with the EDA tools, our self-designed tool has no upper limit of testability values. Then, the testability values are sent to the unsupervised K-means clustering simultaneously to diagnose the HT signals. Facilitated by the modularity of the GLN, the detection time of 10 5  order signals sample is reduced by up to 90 % when compared to the traditional COTD method, while our MFTD method shows a similar HT detection performance to that of the traditional COTD method. For all 20 kinds of GLN samples in Trust-hub, our FMTD method can obtain a detection accuracy of 100 %, and signal diagnosis precision of more than 93 % with a diagnosis false positive rate lower than 1 %.}
}


@article{DBLP:journals/compsec/VasalouBSGBTGPRMBLCIPL25,
	author = {Asimina Vasalou and
                  Laura Benton and
                  Ana Luisa Serta and
                  Andrea Gauthier and
                  Ceylan Besevli and
                  Sarah Turner and
                  Rea Gill and
                  Rachael Payler and
                  Etienne B. Roesch and
                  Kevin McAreavey and
                  Kim Bauters and
                  Weiru Liu and
                  Hsueh{-}Ju Chen and
                  Dennis Ivory and
                  Manos Panaousis and
                  Georgios Loukas},
	title = {Doing cybersecurity at home: {A} human-centred approach for mitigating
                  attacks in AI-enabled home devices},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104112},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104112},
	doi = {10.1016/J.COSE.2024.104112},
	timestamp = {Mon, 03 Mar 2025 21:31:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/VasalouBSGBTGPRMBLCIPL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {AI-enabled devices are increasingly introduced in the home context and cyber-attacks targeting their AI component are becoming more frequent. Moving away from seeing the user as the problem to recognising the user as part of the solution, our research reports on a novel cybersecurity intervention (comprising Explainable AI features, assisted remediation) designed to support users to identify, diagnose and mitigate cyber-attacks on the AI component of their smart devices. We carried out a case study of a bespoke smart heating device inclusive of this intervention and conducted fieldwork with ten households who experienced simulated integrity cyber-attacks over a month. Our research contributes an understanding of how to design AI-enabled devices and their ecosystems to support users to perceive integrity cyber-attacks, offering new considerations for intervention design that exploits multimodal indicators and supports users to troubleshoot themselves the causes as well as actions of cyber-attacks. Contributing to the growing area of human-centred cybersecurity, we evidence the distinctive challenges users face when evaluating integrity attacks on the AI component in the home context.}
}


@article{DBLP:journals/compsec/WangTHL25,
	author = {Xiaoqing Wang and
                  Yuanjing Tian and
                  Keman Huang and
                  Bin Liang},
	title = {Practically implementing an LLM-supported collaborative vulnerability
                  remediation process: {A} team-based approach},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104113},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104113},
	doi = {10.1016/J.COSE.2024.104113},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangTHL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incorporating LLM into cybersecurity operations, a typical real-world high-stakes task, is critical but non-trivial in practice. Using cybersecurity as the study context, we conduct a three-step mix-method study to incorporate LLM into the vulnerability remediation process effectively. Specifically, we deconstruct the deficiencies in user satisfaction within the existing process (Study 1). This inspires us to design, implement, and empirically validate an LLM-supported collaborative vulnerability remediation process through a field study (Study 2). Given LLM’s diverse contributions, we further investigate LLM’s double-edge roles through the analysis of remediation reports and follow-up interviews (Study 3). In essence, our contribution lies in promoting an efficient LLM-supported collaborative vulnerability remediation process. These first-hand, real-world pieces of evidence suggest that when incorporating LLMs into practical processes, facilitating the collaborations among all associated stakeholders, reshaping LLMs’ roles according to task complexity, as well as approaching the short-term side effects of improved user engagement facilitated by LLMs with a rational mindset.}
}


@article{DBLP:journals/compsec/WehbeAPA25,
	author = {Nathalie Wehbe and
                  Hyame Assem Alameddine and
                  Makan Pourzandi and
                  Chadi Assi},
	title = {Empowering 5G {SBA} security: Time series transformer for {HTTP/2}
                  anomaly detection},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104114},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104114},
	doi = {10.1016/J.COSE.2024.104114},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WehbeAPA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fifth Generation (5G) networks adopt the security-by-design principle to provide highly secure and robust services. 5G Core (5GC) uses the Hypertext Transfer Protocol version 2 (HTTP/2) for enabling signaling between different Network Functions (NFs) of its Service-Based Architecture (SBA). HTTP/2 introduces new features that pose security risks on the 5G SBA. The HTTP/2 Stream Multiplexing Attack (HTTP/2 SMA) is one of the known HTTP/2 attacks during which an attacker exploits the stream multiplexing feature, by sending malicious requests over a single TCP connection. These requests may belong to the same or different 5G procedures, thus leading to multiple attack variations, causing a Denial of Service (DoS) on the target NF and even overloading some other NFs contributing to the fulfillment of the triggered 5G procedure. In this work, we propose 5GGuardian, an anomaly detection framework that leverages a time series transformer trained on 5G-Stream features. The 5G-Stream features capture fine-grained details of NFs behavior and enable robust anomaly detection of HTTP/2 SMA. Experiments on our 5GC datasets that are collected from the open-source Free5GC testbed and UERANSIM simulator, reveal that our proposed approach achieves an average F1-score of 0.98 in identifying the HTTP/2 SMA variations. We evaluate the performance of 5GGuardian and emphasize its robustness in the presence of contaminated training data, as well as its ability to outperform application-layer anomaly detection solutions.}
}


@article{DBLP:journals/compsec/ChengQLW25,
	author = {Yu Cheng and
                  Xiaofang Qi and
                  Yanhui Li and
                  Yumeng Wang},
	title = {ReckDroid: Detecting red packet fraud in Android apps},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104117},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104117},
	doi = {10.1016/J.COSE.2024.104117},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChengQLW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, red packets have appeared widely in various mobile apps. Related security issues like fraud are gradually coming into the public eye. As a new means of fraud, red packet fraud has not yet been explored or addressed. In this paper, based on our empirical study on red packets, we propose a novel approach ReckDroid for red packet fraud detection. Our approach adopts a heuristic algorithm to identify red packets and then detects red packet fraud by analyzing the network traffic dynamically generated during the automated exploration of mobile apps. Our experiments are performed on hundreds of labeled real-world apps. Experimental results show that ReckDroid identifies red packets with a precision of 98.0% and a recall of 93.3%, and detects red packet fraud with a precision of 88.6% and a recall of 92.5%. By applying ReckDroid to over 1000 Android apps in the wild, we find that apps with red packets account for 17.6% of apps from seven app markets (including Google Play) while red packet fraud mainly occurs in Chinese app markets.}
}


@article{DBLP:journals/compsec/LiXLL25,
	author = {Jiacheng Li and
                  Yang Xiao and
                  Shuhui Li and
                  Tieshan Li},
	title = {Designing accountable IoT systems to overcome IoT storage limitation},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104118},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104118},
	doi = {10.1016/J.COSE.2024.104118},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiXLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices have been widely used in diverse environments, bringing more and more benefits to people. However, the security issues surrounding these IoT devices raise significant concerns about their level of security. Researchers have proposed many prevention and detection methods for security issues. However, these methods may only partially address the challenges of IoT devices. Accountability can be used as an additional method to enhance security, which is vital in improving security. This article proposes robust accountability methods for IoT devices lacking permanent storage to ensure accountability. We prove that our proposed accountability methods successfully achieve completeness, correctness, and accuracy. To assess their effectiveness, we integrate our accountability methods into a temperature humidity monitor, revealing that the overhead incurred by these methods showcases their practical applicability with a reasonable impact on performance.}
}


@article{DBLP:journals/compsec/AlamC25,
	author = {A. K. M. Mubashwir Alam and
                  Keke Chen},
	title = {{TEE-MR:} Developer-friendly data oblivious programming for trusted
                  execution environments},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104119},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104119},
	doi = {10.1016/J.COSE.2024.104119},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AlamC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trusted execution environments (TEEs) enable efficient protection of integrity and confidentiality for applications running on untrusted platforms. They have been deployed in cloud servers to attract users who have concerns on exporting data and computation. However, recent studies show that TEEs’ side channels, including memory, cache, and micro-architectural features, are still vulnerable to adversarial exploitation. As many such attacks utilize program access patterns to infer secret information, data oblivious programs have been considered a practical defensive solution. However, they are often difficult to develop and optimize via either manual or automated approaches. We present the  oblivious TEE with MapReduce  (TEE-MR) approach that uses application frameworks, an approach between fully manual and fully automated, to hide the details of access-pattern protection to significantly minimize developers’ efforts. We have implemented the approach with the MapReduce application framework for data-intensive applications. It can regulate application dataflows and hide application-agnostic access-pattern protection measures from developers. Compared to manual composition approaches, it demands much less effort for developers to identify access patterns and to write code. Our approach is also easy to implement, less complicated than fully automated approaches, for which we have not seen a working prototype yet. Our experimental results show that TEE-MR-based applications have good performance, comparable to those carefully developed with time-consuming manual composition approaches.}
}


@article{DBLP:journals/compsec/MouicheS25,
	author = {Inoussa Mouiche and
                  Sherif Saad},
	title = {Entity and relation extractions for threat intelligence knowledge
                  graphs},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104120},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104120},
	doi = {10.1016/J.COSE.2024.104120},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MouicheS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced persistent threats (APTs) represent a complex challenge in cybersecurity as they infiltrate networks stealthily to conduct espionage, steal data, and maintain a long-term presence. To combat these threats, security professionals increasingly rely on cyber knowledge graphs (CKGs), which provide scalable solutions to analyze and structure vast amounts of cyber threat intelligence (CTI) from diverse sources in real-time, enabling the automation of proactive security measures. Developing CKGs requires extracting entity and their relationships from unstructured CTI reports. However, existing approaches face significant limitations, such as difficulties with the nuances of cybersecurity language, diverse threat terminologies, and high rates of error propagation, resulting in low accuracy and poor generalizability. This paper introduces a novel Threat Intelligence Knowledge Graph (TiKG) pipeline designed to address these challenges. The TiKG framework leverages SecureBERT, a domain-specific transformer-based model optimized for cybersecurity, and integrates it with an attention-based BiLSTM to capture the context and nuances of security texts, reducing error propagation and improving extraction accuracy. Additionally, the pipeline incorporates a domain-specific ontology and inference model to ensure precise relation mapping in relation extraction. Using three large-scale TI open-source datasets (DNRTI, STUCCO, and CYNER) and a curated CTI dataset, extensive evaluations demonstrate the effectiveness of our framework, showing significant improvements over existing methods in detecting and linking cyber threats. These contributions provide a robust platform for security professionals to analyze and predict potential attacks, develop effective defenses, and enhance the strategic capabilities of cybersecurity operations.}
}


@article{DBLP:journals/compsec/CaiTCHG25,
	author = {Saihua Cai and
                  Han Tang and
                  Jinfu Chen and
                  Yikai Hu and
                  Wuhao Guo},
	title = {{CDDA-MD:} An efficient malicious traffic detection method based on
                  concept drift detection and adaptation technique},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104121},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104121},
	doi = {10.1016/J.COSE.2024.104121},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CaiTCHG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of network environment, cyber attacks have become one of the major threats to network security, and maintaining network security requires accurate detection of malicious traffic generated by cyber attacks. However, due to the dynamic nature of network behavior, data distribution in network traffic may change over time, i.e., appearing concept drift phenomenon, and the emergence of concept drift causes existing malicious traffic detection models to suffer from the problem of decreased detection efficiency. To address this challenge, we propose a  C oncept  D rift  D etection and  A daptation-based  M alicious traffic  D etection method called CDDA-MD. Firstly, the network traffic is segmented using sliding window technique and the data samples are analyzed on the basis of each window. And then, a long short-term memory network (LSTM) is utilized to capture the long-term dependencies in the time-series features of network traffic; At the same time, a multi-head self-attention mechanism is introduced to provide larger weights for the important features. Moreover, we replace the ReLU activation function in LSTM with Tanh to overcome the neuron “death” problem, and replace the Adam optimizer with Nadam to accelerate convergence, thereby improving the detection performance. Next, the concept drift is detected based on the idea of error rate, and the detected concept drift data is used for incremental learning to make the model adapt to current network environment. Finally, based on the detected concept drift, malicious traffic detection operations are performed to effectively maintain the security of cyberspace. Experiments on four network traffic show that compared with existing state-of-the-art methods, the proposed CDDA-MD method improves 0.3%, 1.2% , 1.16% and 1.9% in F1-measure, 0.25%, 1.1%, 1.44% and 1.72% in TPR, respectively; It also has better stability.}
}


@article{DBLP:journals/compsec/BotacinG25,
	author = {Marcus Botacin and
                  Heitor Murilo Gomes},
	title = {Towards more realistic evaluations: The impact of label delays in
                  malware detection pipelines},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104122},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104122},
	doi = {10.1016/J.COSE.2024.104122},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BotacinG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Developing and evaluating malware classification pipelines to reflect real-world needs is as vital to protect users as it is hard to achieve. In many cases, the experimental conditions when the approach was developed and the deployment settings mismatch, which causes the solutions not to achieve the desired results. In this work, we explore how unrealistic project and evaluation decisions in the literature are. In particular, we shed light on the problem of label delays, i.e., the assumption that ground-truth labels for classifier retraining are always available when in the real world they take significant time to be produced, which also causes a significant attack opportunity window. In our analyses, among diverse aspects, we address: (1) The use of metrics that do not account for the effect of time; (2) The occurrence of concept drift and ideal assumptions about the amount of drift data a system can handle; and (3) Ideal assumptions about the availability of oracle data for drift detection and the need for relying on pseudo-labels for mitigating drift-related delays. We present experiments based on a newly proposed exposure metric to show that delayed labels due to limited analysis queue sizes impose a significant challenge for detection (e.g., up to a 75% greater attack opportunity in the real world than in the experimental setting) and that pseudo-labels are useful in mitigating the delays (reducing the detection loss to only 30% of the original value).}
}


@article{DBLP:journals/compsec/PrasadD25,
	author = {Y. Bhanu Prasad and
                  Venkatesulu Dondeti},
	title = {{PDSMV3-DCRNN:} {A} novel ensemble deep learning framework for enhancing
                  phishing detection and {URL} extraction},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104123},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104123},
	doi = {10.1016/J.COSE.2024.104123},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/PrasadD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing is a cyber-attack that exploits victims\' technical ignorance or naivety and commonly involves a Uniform Resources Locator (URL). As a result, it is beneficial to examine URLs before accessing them to spot a phishing assault. Several algorithms based on machine learning have been presented to detect phishing attempts. However, these approaches often suffer from lower performance outcomes, such as lower accuracy, longer response times, and higher false positive rates. Furthermore, many existing methods rely heavily on predefined feature sets, which may limit their adaptability and robustness. In contrast, our proposed method leverages a more dynamic feature selection process, which includes the Conditional Wasserstein Generative Adversarial Network (CWGAN) for addressing data imbalance and the Binary Grey Goose Optimization Algorithm (BGGOA) for optimal feature selection. This dynamic approach enhances the model\'s ability to adapt to varying data characteristics, improving detection performance. The proposed solution is divided into two stages: pre-deployment and deployment. During the pre-deployment stage, the dataset is preprocessed, including data transformation, handling irrelevant and redundant data, and ensuring data balancing. Minority samples are increased using CWGAN to avoid class imbalance. Features are then selected using BGGOA, resulting in a feature-reduced dataset used for training and testing ensemble deep learning classifiers, specifically the Novel Pyramid Depth-wise Separable-MobileNetV3 (PyDS-MV3) and Deformable Convolutional Residual Neural Network (DCRNN), termed PDSMV3-DCRNN. During the deployment phase, the Boosted ConvNeXt approach extracts URL features fed into the trained classifier to predict "phishing" or "benign". According to experimental findings, the proposed solution outperforms all other tested approaches, displaying a faster training time of 0.11 s and achieving an optimal accuracy of 99.21%.}
}


@article{DBLP:journals/compsec/KumariT25,
	author = {Matta Krishna Kumari and
                  Nikhil Tripathi},
	title = {Detecting interest flooding attacks in {NDN:} {A} probability-based
                  event-driven approach},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104124},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104124},
	doi = {10.1016/J.COSE.2024.104124},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KumariT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The foundational concepts of the Internet were developed in the 1960s and 1970s with the goal of interconnecting hosts using the TCP/IP architecture. While this architecture has significantly impacted communication and commerce, it struggles to accommodate the Internet’s vast user base and diverse applications. Named Data Network (NDN), a next-generation Internet architecture is designed to overcome the current TCP/IP based Internet architecture’s limitations. NDN’s basic operations make it resilient against several traditional DoS/DDoS attacks. However, NDN remains vulnerable to Interest Flooding Attack (IFA), a class of DoS attacks that can exhaust the routers’ as well as the producers’ resources to disrupt network functionality. To detect these attacks, researchers came up with a few approaches. However, existing detection techniques focus on specific IFA variants but struggle to detect other variants. To address this challenge, in this paper, we propose a statistical abnormality detection scheme to identify all variants of IFA. Additionally, we generate a comprehensive NDN traffic dataset through our experiments and use it to evaluate the performance of the detection scheme. The experimental results show that our scheme can detect all variants of IFA with high accuracy. Towards the end, we also present a sensitivity analysis study that shows the impact of varying a few parameters on the detection performance of the proposed scheme.}
}


@article{DBLP:journals/compsec/MaiLBHEKT25,
	author = {Khang Mai and
                  Jongmin Lee and
                  Razvan Beuran and
                  Ryosuke Hotchi and
                  Ooi Sian En and
                  Takayuki Kuroda and
                  Yasuo Tan},
	title = {{RAF-AG:} Report analysis framework for attack path generation},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104125},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104125},
	doi = {10.1016/J.COSE.2024.104125},
	timestamp = {Thu, 01 May 2025 20:32:43 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MaiLBHEKT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information sharing is a key practice in cybersecurity for coping with the ever-changing cyberattacks that are targeting computer systems. Thus, when cyber incidents happen, cyber threat intelligence (CTI) reports are prepared and shared among cybersecurity practitioners to help them get up-to-date information about those incidents. However, reading and analyzing the report text to comprehend the included information is a cumbersome process. Although techniques based on deep learning were proposed to speed up report analysis in order to obtain the enclosed essential information, such as attack path, training data insufficiency makes these methods inefficient in practical circumstances. This paper presents RAF-AG, a report analysis framework for attack path generation. To analyze CTI reports, RAF-AG utilizes the sentence dependency tree for entity and relation extraction, and a weak supervision approach for entity labeling. This is followed by graph building and graph alignment for generating the attack paths. Our approach resolves the data insufficiency problem in the cybersecurity domain by lowering the need for expert involvement. We evaluated RAF-AG by comparing the generated attack paths with those produced by AttacKG, a state-of-the-art automatic report analysis framework. RAF-AG was able to identify cyberattack steps by matching their appearance order inside the report, and link them with techniques from the MITRE ATT&CK knowledge base with an improved F1 score compared to AttacKG (0.708 versus 0.393).}
}


@article{DBLP:journals/compsec/FeiZZGFLWC25,
	author = {Kexiong Fei and
                  Jiang Zhou and
                  Yucan Zhou and
                  Xiaoyan Gu and
                  Haihui Fan and
                  Bo Li and
                  Weiping Wang and
                  Yong Chen},
	title = {LaAeb: {A} comprehensive log-text analysis based approach for insider
                  threat detection},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104126},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104126},
	doi = {10.1016/J.COSE.2024.104126},
	timestamp = {Thu, 01 May 2025 20:32:43 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/FeiZZGFLWC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Insider threats have increasingly become a critical issue that modern enterprises and organizations faced. They are mainly initiated by insider attackers, which may cause disastrous impacts. Numerous research studies have been conducted for insider threat detection. However, most of them are limited due to a small number of malicious samples. Moreover, as existing methods often concentrate on feature information or statistical characteristics for anomaly detection, they still lack effective use of comprehensive textual content information contained in logs and thus will affect detection efficiency. We propose  LaAeb , a novel unsupervised insider threat detection framework that leverages rich linguistic information in log contents to enable conventional methods, such as an Isolation Forest-based anomaly detection, to better detect insider threats besides using various features and statistical information. To find malicious acts under different scenarios, we consider three patterns of insider threats, including  attention ,  emotion , and  behavior anomaly . The attention anomaly detection analyzes textual contents of operation objects (e.g., emails and web pages) in logs to detect threats, where the textual information reflects the areas that employees focus on. When the attention seriously deviates from daily work, an employee may involve malicious acts. The emotion anomaly detection analyzes all dialogs between every two employees’ daily communicated texts and uses the degree of negative to find potential psychological problems. The behavior anomaly detection analyzes the operations of logs to detect threats. It utilizes information acquired from attention and emotion anomalies as ancillary features, integrating them with features and statistics extracted from log operations to create log embeddings. With these log embeddings,  LaAeb  employs anomaly detection algorithm like Isolation Forest to analyze an employee’s malicious operations, and further detects the employee’s behavior anomaly by considering all employees’ acts in the same department. Finally,  LaAeb  consolidates detection results of three patterns indicative of insider threats in a comprehensive manner. We implement the prototype of  LaAeb  and test it on CERT and LANL datasets. Our evaluations demonstrate that compared with state-of-the-art unsupervised methods,  LaAeb  reduces FPR by 50% to reach 0.05 on CERT dataset under the same AUC  ( 0 . 93 ) <math><mrow is="true"><mo is="true">(</mo><mn is="true">0</mn><mo is="true">.</mo><mn is="true">93</mn><mo is="true">)</mo></mrow></math> , and gets the best AUC  ( 0 . 97 ) <math><mrow is="true"><mo is="true">(</mo><mn is="true">0</mn><mo is="true">.</mo><mn is="true">97</mn><mo is="true">)</mo></mrow></math>  with 0.06 higher value on LANL dataset.}
}


@article{DBLP:journals/compsec/ZhouYGL25,
	author = {Luchen Zhou and
                  Wei{-}Chuen Yau and
                  Yee Siang Gan and
                  Sze{-}Teng Liong},
	title = {E-WebGuard: Enhanced neural architectures for precision web attack
                  detection},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104127},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104127},
	doi = {10.1016/J.COSE.2024.104127},
	timestamp = {Thu, 03 Oct 2024 00:46:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhouYGL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web applications have become a favored tool for organizations to disseminate vast amounts of information to the public. With the increasing adoption and inherent openness of these applications, there is an observed surge in web-based attacks exploited by adversaries. However, most of the web attack detection works are based on public datasets that are outdated or do not cover a sufficient quantity of web application attacks. Furthermore, most of them are binary detection (i.e., normal or attack) and there is little work on multi-class web attack detection. This highlights the crucial need for automated web attack detection models to bolster web security. In this study, a suite of integrated machine learning and deep learning models is designed to detect web attacks. Specifically, this study employs the Character-level Support Vector Machine (Char-SVM), Character-level Long Short-Term Memory (Char-LSTM), Convolutional Neural Network - SVM (CNN-SVM), and CNN-Bi-LSTM models to differentiate between standard HTTP requests and HTTP-based attacks in both the CSIC 2010 and SR-BH 2020 datasets. Note that the CSIC 2010 dataset involves binary classification, while the SR-BH 2020 dataset involves multi-class classification, specifically with 13 classes. Notably, the input data is first converted to the character level before being fed into any of the proposed model architectures. In the binary classification task, the Char-SVM model with a linear kernel outperforms other models, achieving an accuracy rate of 99.60%. The CNN-Bi-LSTM model closely follows with a 99.41% accuracy, surpassing the performance of the CNN-LSTM model presented in previous research. In the context of multi-class classification, the CNN-Bi-LSTM model demonstrates outstanding performance with a 99.63% accuracy rate. Furthermore, the multi-class classification models, namely Char-LSTM and CNN-Bi-LSTM, achieve validation accuracies above 98%, outperforming the two machine learning-based methods mentioned in the original research.}
}


@article{DBLP:journals/compsec/HalgamugeN25,
	author = {Malka N. Halgamuge and
                  Dusit Niyato},
	title = {Adaptive edge security framework for dynamic IoT security policies
                  in diverse environments},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104128},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104128},
	doi = {10.1016/J.COSE.2024.104128},
	timestamp = {Mon, 09 Dec 2024 22:47:46 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/HalgamugeN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid expansion of Internet of Things (IoT) technologies has introduced significant cybersecurity challenges, particularly at the network edge where IoT devices operate. Traditional security policies designed for static environments fall short of addressing the dynamic, heterogeneous, and resource-constrained nature of IoT ecosystems. Existing dynamic security policy models lack versatility and fail to fully integrate comprehensive risk assessments, regulatory compliance, and AI/ML (artificial intelligence/machine learning)-driven adaptability. We develop a novel adaptive edge security framework that dynamically generates and adjusts security policies for IoT edge devices. Our framework integrates a dynamic security policy generator, a conflict detection and resolution in policy generator, a bias-aware risk assessment system, a regulatory compliance analysis system, and an AI-driven adaptability integration system. This approach produces tailored security policies that adapt to changes in the threat landscape, regulatory requirements, and device statuses. Our study identifies critical security challenges in diverse IoT environments and demonstrates the effectiveness of our framework through simulations and real-world scenarios. We found that our framework significantly enhances the adaptability and resilience of IoT security policies. Our results demonstrate the potential of AI/ML integration in creating responsive and robust security measures for IoT ecosystems. The implications of our findings suggest that dynamic and adaptive security frameworks are essential for protecting IoT devices against evolving cyber threats, ensuring compliance with regulatory standards, and maintaining the integrity and availability of IoT services across various applications.}
}


@article{DBLP:journals/compsec/SturmanAM25,
	author = {Daniel Sturman and
                  Jaime C. Auton and
                  Ben W. Morrison},
	title = {Security awareness, decision style, knowledge, and phishing email
                  detection: Moderated mediation analyses},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104129},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104129},
	doi = {10.1016/J.COSE.2024.104129},
	timestamp = {Mon, 09 Dec 2024 22:47:46 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/SturmanAM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study examines whether the negative relationship between email information security awareness and phishing email susceptibility is mediated by less intuitive decision-making when assessing emails, and whether this relationship is moderated by phishing email knowledge. Participants ( N  = 291) completed an online email sorting task, a measure of email use information security awareness, a measure of preference for intuitive decision-making with emails, and a measure of phishing email knowledge. Moderated mediation analyses indicated that information security awareness predicted positive behavioural intentions directly and indirectly through lower preference for intuitive decision-making, and these relationships were stronger when phishing email knowledge was lower. Further, both the direct and indirect relationships between information security awareness and sensitivity through intuitive decision styles were moderated by phishing email knowledge, with information security awareness positively predicting ability to discriminate phishing from genuine emails when phishing knowledge was average or high but not low. These findings suggest that in the absence of phishing knowledge, information security awareness and less intuitive decision styles reduce susceptibility to phishing attacks through increased caution. Further, the findings provide strong support for the proposition that some level of phishing knowledge is required before email security behaviours and decision-making processes aid in the detection of phishing emails. From an applied perspective, the outcomes suggest that focusing on a combination of awareness, knowledge, and decision-making processes could increase the effectiveness of anti-phishing and cybersecurity training programs.}
}


@article{DBLP:journals/compsec/YangWL25,
	author = {Libin Yang and
                  Menghan Wang and
                  Wei Lou},
	title = {An automated dynamic quality assessment method for cyber threat intelligence},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104079},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104079},
	doi = {10.1016/J.COSE.2024.104079},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/YangWL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of cyber threat intelligence (CTI) is a promising approach for alleviating malicious activities. However, the effectiveness of CTIs is heavily dependent on their quality. Current literature develops the CTI quality assessment ontology mainly from the perspective of CTI source or content separately, regardless of their availability in practice. In this paper, we propose an automated CTI quality assessment method that synthesizes the trustworthiness of CTI sources and the availability of CTI contents. Specifically, we model the interactions of CTI feeds as a correlation graph and propose an iterative algorithm to well discriminate the feeds’ trustworthiness. We elaborate a CTI content assessment together with a machine learning algorithm to automatically classify CTIs’ availability from a set of content metrics. A comprehensive CTI quality assessment is proposed by jointly considering the feed trustworthiness and content availability. Extensive experimental results on real datasets demonstrate that our proposed method can quantitatively as well as effectively assess CTI quality.}
}


@article{DBLP:journals/compsec/AbudurexitiHZL25,
	author = {Yilixiati Abudurexiti and
                  Guangjie Han and
                  Fan Zhang and
                  Li Liu},
	title = {An explainable unsupervised anomaly detection framework for Industrial
                  Internet of Things},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104130},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104130},
	doi = {10.1016/J.COSE.2024.104130},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/AbudurexitiHZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial Internet of Things (IIoT) systems require effective anomaly detection techniques to ensure optimal operational efficiency. However, constructing a suitable anomaly detection framework for IIoT poses challenges due to the scarcity of labeled data. Additionally, most existing anomaly detection frameworks lack interpretability. To tackle these issues, an innovative unsupervised framework based on time series data analysis is proposed. This framework initially detects anomalous patterns in IIoT sensor data by extracting local features. An improved Time Convolutional Network (TCN) and Kolmogorov–Arnold Network (KAN) based Variational Auto-Encoder (VAE) is then constructed to capture long-term dependencies. The framework is trained in an unsupervised manner and interpreted using Explainable Artificial Intelligence (XAI) techniques. This approach offers insightful explanations regarding the importance of features, thereby facilitating informed decision-making and enhancements. Experimental results demonstrate that the framework is capable of extracting informative features and capturing long-term dependencies. This enables efficient anomaly detection in complex, dynamic industrial systems, surpassing other unsupervised methods.}
}


@article{DBLP:journals/compsec/ArenasFLR25,
	author = {M{\'{o}}nica P. Arenas and
                  Georgios Fotiadis and
                  Gabriele Lenzini and
                  Mohammadamin Rakeei},
	title = {Remote secure object authentication: Secure sketches, fuzzy extractors,
                  and security protocols},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104131},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104131},
	doi = {10.1016/J.COSE.2024.104131},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ArenasFLR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Coating objects with microscopic droplets of liquid crystals makes it possible to identify and authenticate objects as if they had biometric-like features: this is extremely valuable as an anti-counterfeiting measure. How to extract features from images has been studied elsewhere, but exchanging data about features is not enough if we wish to build secure cryptographic authentication protocols. What we need are authentication tokens (i.e., bitstrings), strategies to cope with noise, always present when processing images, and solutions to protect the original features so that it is impossible to reproduce them from the tokens. Secure sketches and fuzzy extractors are the cryptographic toolkits that offer these functionalities, but they must be instantiated to work with the peculiar specific features extracted from images of liquid crystals. We show how this can work and how we can obtain uniform, error-tolerant, and random strings, and how they are used to authenticate liquid crystal coated objects. Our protocol reminds an existing biometric-based protocol, but only apparently. Using the original protocol as-it-is would make the process vulnerable to an attack that exploits certain physical peculiarities of our liquid crystal coatings. Instead, our protocol is robust against the attack. We prove all our security claims formally, by modeling and verifying in Proverif, our protocol and its cryptographic schemes. We implement and benchmark our solution, measuring both the performance and the quality of authentication.}
}


@article{DBLP:journals/compsec/DengH25,
	author = {Ping Deng and
                  Yong Huang},
	title = {Edge-featured multi-hop attention graph neural network for intrusion
                  detection system},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104132},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104132},
	doi = {10.1016/J.COSE.2024.104132},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/DengH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of the Internet, the application of computer technology has rapidly become widespread, driving the progress of Internet of Things (IoT) technology. The attacks present on networks have become more complex and stealthy. However, traditional network intrusion detection systems with singular functions are no longer sufficient to meet current demands. While some machine learning-based network intrusion detection systems have emerged, traditional machine learning methods cannot effectively respond to the complex and dynamic nature of network attacks. Intrusion detection systems utilizing deep learning can better enhance detection capabilities through diverse data learning and training. To capture the topological relationships in network data, using graph neural networks (GNNs) is most suitable. Most existing GNNs for intrusion detection use multi-layer network training, which may lead to over-smoothing issues. Additionally, current intrusion detection solutions often lack efficiency. To mitigate the issues mentioned above, this paper proposes an  E dge-featured  M ulti-hop  A ttention Graph Neural Network for  I ntrusion  D etection  S ystem (EMA-IDS), aiming to improve detection performance by capturing more features from data flows. Our method enhances computational efficiency through attention propagation and integrates node and edge features, fully leveraging data characteristics. We carried out experiments on four public datasets, which are NF-CSE-CIC-IDS2018-v2, NF-UNSW-NB15-v2, NF-BoT-IoT, and NF-ToN-IoT. Compared with existing models, our method demonstrated superior performance.}
}


@article{DBLP:journals/compsec/LakshmiT25,
	author = {Vimitha R. Vidhya Lakshmi and
                  Gireesh Kumar T},
	title = {Enhancing data integrity in opportunistic mobile social network: Leveraging
                  Berkle Tree and secure data routing against attacks},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104133},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104133},
	doi = {10.1016/J.COSE.2024.104133},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LakshmiT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Opportunistic Mobile Social Networks (OMSNs), ensuring data integrity is crucial. The anonymous and opportunistic nature of node communication makes these networks vulnerable to data integrity attacks. The existing literature identified significant shortcomings in effectively addressing data integrity attacks with high efficiency and accuracy. This paper addresses these issues by proposing the "Berkle Tree", a novel data structure designed to mitigate data integrity attacks in OMSNs. The Berkle Tree leverages the EvolvedBloom filter, which is a variant of the bloom filter with a negligible False Positive Rate (FPR). The key contributions of this study include i) an innovative application of EvolvedBloom for membership testing and Berkle Tree root validation, and ii) comparative analysis with existing data structures like Merkle and Verkle Trees. The Berkle Tree demonstrates superior performance, reducing tree generation and integrity validation times and leading to substantial computational cost reductions of 79.50 % and 90.57 %, respectively. The proposed method integrates the Berkle Tree into OMSN routing models and evaluates performance against Packet Drop, Modification, and Fake Attacks (PDA, PMA, PFA). Results show average Malicious Node Detection Accuracy of 98.2 %, 85.2 %, and 94.4 %; Malicious Path Detection Accuracy of 98.6 %, 86.6 %, and 90.2 %; Malicious Data Detection Accuracy of 98.4 %, 80.2 %, and 93.4 %; and False Negative Rates of 1.8 %, 14.8 %, and 5.6 % for PDA, PMA, and PFA, respectively. The major findings demonstrate that the proposed approach significantly improves OMSN routing models by reducing Packet Dropping, Modifying, and Faking Rates by 48.62 %, 28.99 %, and 31.2 %, respectively. Compared to existing methods, the Berkle Tree achieves a substantial reduction in filter size by approximately 25 %–40 %, while maintaining a negligible FPR. These advancements contribute to the state-of-the-art of OMSNs by providing robust solutions for data integrity with significant implications for enhancing security and trustworthiness in OMSNs.}
}


@article{DBLP:journals/compsec/OkonkwoFHLJ25,
	author = {Zulu Okonkwo and
                  Ernest Foo and
                  Zhe Hou and
                  Qinyi Li and
                  Zahra Jadidi},
	title = {A graph representation framework for encrypted network traffic classification},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104134},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104134},
	doi = {10.1016/J.COSE.2024.104134},
	timestamp = {Mon, 03 Mar 2025 21:31:11 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/OkonkwoFHLJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network Traffic Classification (NTC) is crucial for ensuring internet security, but encryption presents significant challenges to this task. While Machine Learning (ML) and Deep Learning (DL) methods have shown promise, issues such as limited representativeness leading to sub-optimal generalizations and performance remain prevalent. These problems become more pronounced with advanced obfuscation, network security, and privacy technologies, indicating a need for improved model robustness. To address these issues, we focus on  feature extraction  and  representation  in NTC by leveraging the expressive power of graphs to represent network traffic at various granularity levels. By modeling network traffic as interconnected graphs, we can analyze both flow-level and packet-level data. Our graph representation method for encrypted NTC effectively preserves crucial information despite encryption and obfuscation. We enhance the robustness of our approach by using cosine similarity to exploit correlations between encrypted network flows and packets, defining relationships between abstract entities. This graph structure enables the creation of structural embeddings that accurately define network traffic across different encryption levels. Our end-to-end process demonstrates significant improvements where traditional NTC methods struggle, such as in Tor classification, which employs anonymization to further obfuscate traffic. Our packet-level classification approach consistently outperforms existing methods, achieving accuracies exceeding 96%.}
}


@article{DBLP:journals/compsec/HeWDLW25,
	author = {Dalin He and
                  Huanyu Wang and
                  Tuo Deng and
                  Jishi Liu and
                  Junnian Wang},
	title = {Improving IIoT security: Unveiling threats through advanced side-channel
                  analysis},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104135},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104135},
	doi = {10.1016/J.COSE.2024.104135},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/HeWDLW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread deployment of IIoT edge devices makes them attractive victims for malicious activities. Consequently, how to implement trustworthy operations becomes a realistic topic in embedded systems. While most current physical systems for detecting malicious activities primarily focus on identifying known intrusion codes at the block level, they ignore that even an unnoticeable injected function can result in system-wide loss of security. In this paper, we propose a framework called CNDSW built on deep-learning side-channel analysis for function-level industrial control flow integrity monitoring. By collaboratively utilizing correlation analysis and deep-learning techniques, the dual window sliding monitoring mechanism in the proposed CNDSW framework demonstrates a real-time code intrusion tracking capacity on embedded controllers with a 99% detection accuracy on average. Instead of focusing on known block-level intrusions, we experimentally show that our model is feasible to detect function-level code intrusions without knowing the potential threat type. Besides, we further explore how different configurations of the CNDSW framework can help the monitoring process with different emphases and to which extent the model can concurrently detect multiple code intrusion activities. All our experiments are conducted on 32-bit ARM Cortex-M4 and 8-bit RISC MCUs across five different control flow programs, providing a comprehensive evaluation of the framework’s capabilities.}
}


@article{DBLP:journals/compsec/BaiWZZSZG25,
	author = {Fenhua Bai and
                  Zikang Wang and
                  Kai Zeng and
                  Chi Zhang and
                  Tao Shen and
                  Xiaohui Zhang and
                  Bei Gong},
	title = {{ZKSA:} Secure mutual Attestation against {TOCTOU} Zero-knowledge
                  Proof based for IoT Devices},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104136},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104136},
	doi = {10.1016/J.COSE.2024.104136},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/BaiWZZSZG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread adoption of Internet of Things (IoT) devices, remote attestation is crucial for ensuring their security. However, current schemes that require a central verifier or interactive approaches are expensive and inefficient for collaborative autonomous systems. Furthermore, the security of the software state cannot be guaranteed before or between successive attestations, leaving devices vulnerable to Time-Of-Check-Time-Of-Use (TOCTOU) attacks, as well as confidentiality issues arising from pre-sharing software information with the verifier. Therefore, we propose the Secure mutual Attestation against TOCTOU Zero-Knowledge proof based for IoT devices (ZKSA), which allows devices to mutually attest without a central verifier, and the attestation result is transparent while preserving confidentiality. We implement a ZKSA prototype on a Raspberry Pi 3B, demonstrating its feasibility and security. Even if malware is removed before the next attestation, it will be detected and the detection time is typically constant. Simulations show that compared to other schemes for mutual attestation, such as DIAT and CFRV, ZKSA exhibits scalability. When the prover attests to numerous verifier devices, ZKSA reduces the verification time from linear to constant.}
}


@article{DBLP:journals/compsec/WaelchliW25,
	author = {Sandro Waelchli and
                  Yoshija Walter},
	title = {Reducing the risk of social engineering attacks using {SOAR} measures
                  in a real world environment: {A} case study},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104137},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104137},
	doi = {10.1016/J.COSE.2024.104137},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WaelchliW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The global cost of successful cyberattacks is increasing annually, with there being a shift towards social engineering threats in recent years. Cybercriminals are increasingly targeting humans rather than technical systems, recognizing data as a critical resource, especially in the finance industry where breaches can lead to substantial losses and reputational damage. The present case study proposes measures to reduce human susceptibility to social engineering attacks, leveraging SOAR (Security Automation, Orchestration, and Response) technology for incident response automation. The study covers various issues in cybersecurity, SOAR, and social engineering, through analyzing interviews with expert practitioners in the field, addressing cybersecurity skills shortages and current cyber threats. Four social engineering vignettes were developed, representing real threats, along with specific SOAR measures implemented using Microsoft Sentinel. These measures were simulated to demonstrate their effectiveness by reducing the employee's vulnerability to social engineering attacks. The risk of social engineering attacks was successfully reduced by implementing a responsive approach through the developed SOAR measures. Some of the measures reduced the risk by locking user accounts or forcing password changes after a detected cyber incident while another measure was developed for awareness enhancements. Given the current shortage of cybersecurity professionals, technologies like SOAR are becoming increasingly relevant for security teams. However, SOAR alone cannot address all challenges posed by social engineering and should be viewed as a complementary measure rather than a standalone solution.}
}


@article{DBLP:journals/compsec/KalamK25,
	author = {Sidra Kalam and
                  Ajit Kumar Keshri},
	title = {Advancing IoMT security: {A} two-factor authentication model employing
                  {PUF} and Fuzzy logic techniques},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104138},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104138},
	doi = {10.1016/J.COSE.2024.104138},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KalamK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid integration of Internet of Things technologies in healthcare has catalyzed the development of the Internet of Medical Things, markedly enhanced patient care while posing significant security risks. This paper introduces a comprehensive computational framework to safeguard Internet of Medical Things devices and healthcare providers through a sophisticated registration and authentication process. Our model incorporates cryptographic technologies such as Physical Unclonable Functions, fuzzy extractors, and hash functions to bolster the security during the registration and authentication processes for Internet of Medical Things devices and healthcare providers. The Physical Unclonable Function module enhances device security by producing unique, non-replicable responses for device authentication, significantly reinforcing the system's defense against physical and cloning attacks. Furthermore, the model leverages fuzzy logic for the real-time classification of patient health states, enhancing the decision-making accuracy. A comparative analysis confirms that our model exceeds existing models in communication cost, computational efficiency and security. The proposed scheme has been rigorously tested against various attacks using the Scyther tool. By employing a unique identifier generation method through Physical Unclonable Function and utilizing fuzzy logic for secure data transmission and patient classification, our framework addresses vulnerabilities such as man-in-the-middle, denial of service, impersonation, identity guessing, password guessing and replay attacks, which are prevalent in current Internet of Medical Things frameworks.}
}


@article{DBLP:journals/compsec/HeWWLY25,
	author = {Haitao He and
                  Sheng Wang and
                  Yanmin Wang and
                  Ke Liu and
                  Lu Yu},
	title = {VulTR: Software vulnerability detection model based on multi-layer
                  key feature enhancement},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104139},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104139},
	doi = {10.1016/J.COSE.2024.104139},
	timestamp = {Wed, 30 Oct 2024 16:48:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/HeWWLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software vulnerabilities pose a huge threat to current network security, which continues to lead to data leaks and system damage. In order to effectively identify and patch these vulnerabilities, researchers have proposed automated detection methods based on deep learning. However, most of the existing methods only rely on single-dimensional data representation and fail to fully explore the composite characteristics of the code. Among them, the sequence embedding method fails to effectively capture the structural characteristics of the code, while the graph embedding method focuses more on the global characteristics of the overall graph structure and is still insufficient in optimizing the representation of nodes. In view of this, this paper constructs the VulTR model, which incorporates an importance assessment mechanism to strengthen the key syntax levels of the source code (from lexical elements to nodes and graph-level structures), significantly improving the importance of key vulnerability features in classification decisions. At the same time, a relationship connection diagram is constructed to describe the spatial characteristics of the correlations between functions. Experimentally verified, VulTR's F1 scores on both synthetic and real data sets exceed those of the compared models (VulDeePecker, SySeVR, Devign, VulCNN, IVDetect, and mVulPreter).}
}


@article{DBLP:journals/compsec/NguyenHFB25,
	author = {Huynh Phuong Thanh Nguyen and
                  Kento Hasegawa and
                  Kazuhide Fukushima and
                  Razvan Beuran},
	title = {PenGym: Realistic training environment for reinforcement learning
                  pentesting agents},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104140},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104140},
	doi = {10.1016/J.COSE.2024.104140},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/NguyenHFB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Penetration testing, or pentesting, refers to assessing network system security by trying to identify and exploit any existing vulnerabilities. Reinforcement Learning (RL) has recently become an effective method for creating autonomous pentesting agents. However, RL agents are typically trained in a simulated network environment. This can be challenging when deploying them in a real network infrastructure due to the lack of realism of the simulation-trained agents. In this paper, we present PenGym, a framework for training pentesting RL agents in realistic network environments. The most significant features of PenGym are its support for real pentesting actions, full automation of the network environment creation, and good execution performance. The results of our experiments demonstrated the advantages and effectiveness of using PenGym as a realistic training environment in comparison with a simulation approach (NASim). For the largest scenario, agents trained in the original NASim environment behaved poorly when tested in a real environment, having a high failure rate. In contrast, agents trained in PenGym successfully reached the pentesting goal in all our trials. Even after fixing logical modeling issues in simulation to create the revised version NASim(rev.), experiment results with the largest scenario indicated that agents trained in PenGym slightly outperformed, and were more stable, than those trained in NASim(rev.). Thus, the average number of steps required to reach the pentesting goal was 1.4 to 8 steps better for PenGym. Consequently, PenGym provides a reliable and realistic training environment for pentesting RL agents, eliminating the need to model agent actions via simulation.}
}


@article{DBLP:journals/compsec/AlvesFAS25,
	author = {Renan C. A. Alves and
                  Ot{\'{a}}vio F. Freitas and
                  Bruno C. Albertini and
                  Marcos A. Simpl{\'{\i}}cio Jr.},
	title = {Testing the limits of {SPDM:} Authentication of intermittently connected
                  devices},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104142},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104142},
	doi = {10.1016/J.COSE.2024.104142},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/AlvesFAS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Security Protocol and Data Model (SPDM) is an open standard for authentication, attestation, and key exchange among hardware units, such as CPUs and peripheral components. In principle, SPDM was designed to operate over a somewhat stable communication channel, meaning that connection losses usually require the re-execution of the entire protocol. This puts into question SPDM’s suitability for battery-powered devices, which may keep only intermittent communications aiming to save energy. To address this question, we evaluate different authentication approaches that build upon and extend SPDM’s native key bootstrapping capabilities to handle intermittent authentication. In particular, we show that the combination of SPDM and a Time-based One-Time Password (TOTP) protocol is a promising solution for this scenario. We analyze the performance of the proposed authentication schemes using a proof-of-concept virtual device. The TOTP-based scheme was shown to be the fastest, the reconnection step being at least twice and up to  900 × <math><mrow is="true"><mn is="true">900</mn><mo is="true">×</mo></mrow></math>  faster than possible straightforward applications of SPDM. Also, our scheme requires less memory to operate. Finally, we discuss the possibility of integrating intermittent authentication capabilities into the SPDM standard itself.}
}


@article{DBLP:journals/compsec/AlanaziMC25,
	author = {Manar Alanazi and
                  Abdun Mahmood and
                  Mohammad Jabed Morshed Chowdhury},
	title = {{ICS-LTU2022:} {A} dataset for {ICS} vulnerabilities},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104143},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104143},
	doi = {10.1016/J.COSE.2024.104143},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/AlanaziMC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial control systems (ICS) are a collection of control systems and associated instrumentation for controlling and monitoring industrial processes. Critical infrastructure relies on supervisory control and data acquisition (SCADA), a subset of ICS specifically designed for monitoring and controlling industrial processes over large geographic areas. Cyberattacks like the Colonial Pipeline ransomware case have demonstrated how an adversary may compromise critical infrastructure. The Colonial Pipeline ransomware attack led to a week’s pipeline shutdown, causing a gas shortage in the United States. As existing vulnerability assessment tools cannot be used in the context of ICS systems, vulnerability datasets specified for ICSs are needed to evaluate the security weaknesses. Our secondary metadata, ICS-LTU2022, consists of multiple features that can be used for vulnerability assessment and risk evaluation in industrial control systems. A description of the dataset, its characteristics, and data analysis are also presented in this paper. Vulnerability analysis was conducted based on the top 10 vulnerabilities in terms of severity, frequency by year, impact, components of the ICS, and common weaknesses. The ICS-LTU2022 vulnerabilities dataset is updated biannually. Our proposed dataset provides security researchers with the most recent ICS critical vulnerabilities.}
}


@article{DBLP:journals/compsec/ZambiancoFS25,
	author = {Marco Zambianco and
                  Claudio Facchinetti and
                  Domenico Siracusa},
	title = {A Proactive Decoy Selection Scheme for Cyber Deception using {MITRE}
                  ATT{\&}CK},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104144},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104144},
	doi = {10.1016/J.COSE.2024.104144},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZambiancoFS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber deception allows compensating the late response of defenders countermeasures to the ever evolving tactics, techniques, and procedures (TTPs) of attackers. This proactive defense strategy employs decoys resembling legitimate system components to lure stealthy attackers within the defender environment, slowing and/or denying the accomplishment of their goals. In this regard, the selection of decoys that can expose the techniques used by malicious users plays a central role to incentivize their engagement. However, this is a difficult task to achieve in practice, since it requires an accurate and realistic modeling of the attacker capabilities and his possible targets. In this work, we tackle this challenge and we design a decoy selection scheme that is supported by an adversarial modeling based on empirical observation of real-world attackers. We take advantage of a domain-specific threat modeling language using MITRE ATT&CK© framework as source of attacker TTPs targeting enterprise systems. In detail, we extract the information about the execution preconditions of each technique as well as its possible effects on the environment to generate attack graphs modeling the adversary capabilities. Based on this, we formulate a graph partition problem that minimizes the number of decoys detecting a corresponding number of techniques employed in various attack paths directed to specific targets. We compare our optimization-based decoy selection approach against several benchmark schemes that ignore the preconditions between the various attack steps. Results reveal that the proposed scheme provides the highest interception rate of attack paths using the lowest amount of decoys.}
}


@article{DBLP:journals/compsec/DangZSL25,
	author = {Xiaorui Dang and
                  Guiqi Zhang and
                  Ke Sun and
                  Yufeng Li},
	title = {A trust model for VANETs using malicious-aware multiple routing},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104145},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104145},
	doi = {10.1016/J.COSE.2024.104145},
	timestamp = {Tue, 12 Nov 2024 07:57:54 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/DangZSL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular ad hoc networks (VANETs) enable multi-hop communication among vehicles, promoting information sharing and smarter collaborative driving. However, VANETs are facing several challenges due to the open wireless communication environment. Attackers may maliciously drop or alter packets so that the receiver cannot obtain correct information. In addition, the high mobility of vehicles may lead to link failures, consequently resulting in packet loss. In this paper, we propose a multipath-based trust model (MPTM), in which the reliability of packet transmission is guaranteed by data redundancy and the detection of potential attackers is achieved by trust evaluation. Specifically, we present a route discovery mechanism to find multiple routes that avoid potential attackers, which reduces the risk of attacks on redundant packets. The receivers identify correct information based on two factors including content consistency and route information. An attacker detection module is presented to evaluate the trustworthiness of vehicles involved in packet transmission and vehicles with trust value below a threshold are detected as attackers. We conducted extensive experiments using OMNeT++ simulation platform, considering various attack scenarios. Experiment results show that MPTM can reach 90% packet delivery ratio and effectively detect attackers in terms of 90% detection precision.}
}


@article{DBLP:journals/compsec/BamberKSA25,
	author = {Sukhvinder Singh Bamber and
                  Aditya Vardhan Reddy Katkuri and
                  Shubham Sharma and
                  Mohit Angurala},
	title = {A hybrid {CNN-LSTM} approach for intelligent cyber intrusion detection
                  system},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104146},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104146},
	doi = {10.1016/J.COSE.2024.104146},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/BamberKSA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the technology is advancing more and more in the era of increasing digitalization, safeguarding networks from cyber threats is crucial. As cyber-attacks on critical infrastructure are becoming more and more sophisticated, enhancing cyber intrusion detection systems (IDS) is imperative. This paper proposes and evaluates a deep learning-based IDS using the NSL-KDD dataset, a benchmark for intrusion detection. The system pre-processes data with Recursive Feature Elimination (RFE) and a Decision Tree classifier to identify the most significant features, optimizing model performance. Various deep learning models, including ANN, LSTM, BiLSTM, CNN-LSTM, GRU, and BiGRU, have been evaluated. The CNN-LSTM model outperformed the others, with 95 % accuracy, 0.89 recall, and 0.94 f1-score. These results prove the effectiveness of the proposed IDS in accurately distinguishing between malicious and benign network traffic. Future research can explore ensemble techniques like boosting or bagging to further enhance IDS performance.}
}


@article{DBLP:journals/compsec/BurkeSO25,
	author = {Wendy Burke and
                  Andrew Stranieri and
                  Taiwo Oseni},
	title = {From Dis-empowerment to empowerment: Crafting a healthcare cybersecurity
                  self-assessment},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104148},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104148},
	doi = {10.1016/J.COSE.2024.104148},
	timestamp = {Mon, 09 Dec 2024 22:47:46 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/BurkeSO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the valuable and sensitive nature of its data, the Australian healthcare sector is increasingly targeted by cyberattacks. Existing cybersecurity evaluation methods often lack the specificity required to address the unique vulnerabilities within this sector, especially in terms of engaging stakeholders and fostering a proactive security culture. These evaluations often overlook psychological empowerment, which enhances individuals’ confidence in managing cybersecurity. This study aims to develop a tailored cybersecurity self-assessment index for the Australian healthcare system. It will focus on enhancing psychological empowerment alongside technical assessments to improve overall sector resilience against cyber threats. Using a design science research approach, the index was developed using expert reviews, online surveys, and in-depth interviews with key stakeholders, including healthcare providers, consumers, and government entities. This iterative process involved identifying gaps in existing cybersecurity measures and designing an index to address technical and human factors. The index’s evaluation through a pilot study revealed that it effectively raised awareness and empowered individuals within the healthcare sector to take ownership of cybersecurity practices. Participants reported increased confidence in managing cybersecurity risks and found the index’s actionable recommendations helpful in improving their security posture. However, challenges related to its applicability across diverse healthcare environments and regulatory constraints were identified. The Australian Healthcare Cybersecurity Self-Assessment Index shows promise as a tool for strengthening cybersecurity in the healthcare sector by integrating psychological empowerment with technical assessments. Further research is needed to refine the tool, incorporate quantitative data, and explore its scalability across different healthcare settings and global applications.}
}


@article{DBLP:journals/compsec/MiaoSLCT25,
	author = {Zujia Miao and
                  Cuiping Shao and
                  Huiyun Li and
                  Yunduan Cui and
                  Zhimin Tang},
	title = {Adaptive sensor attack detection and defense framework for autonomous
                  vehicles based on density},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104149},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104149},
	doi = {10.1016/J.COSE.2024.104149},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MiaoSLCT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The security of autonomous vehicles heavily depends on localization systems that integrate multiple sensors, which are vulnerable to sensor attacks and increase the risk of accidents. Given the diversity of sensor attacks and the dynamic changing of driving scenarios of autonomous vehicles, an adaptive and effective attack detection and defense framework faces a considerable challenge. This paper proposes a novel real-time adaptive attack detection and defense framework based on density, which can detect and identify attacked sensors and effectively recover data. We first develop a reinforcement learning multi-armed Bandit-based Density-Based Spatial Clustering of Applications with Noise (BDBSCAN) algorithm that selects hyperparameters adaptively. The Adaptive Extended Kalman Filter (AEKF) combines with the vehicle dynamic model on the localization system and extracts data features used for the BDBSCAN algorithm to monitor potential sensor attacks. If attack detection indicates possible system compromise, AEKF is further employed on localization sensors with anomalies identified through the BDBSCAN algorithm of the attacked sensors. To ensure precision and reliability, the data recovery incorporates a redundancy mechanism to apply a decision tree to select the optimal state estimation between AEKF and Extended Kalman Filter (EKF) to replace corrupted sensor data. To evaluate the effectiveness and adaptability of the proposed framework, we conducted 15,000 experiments using the real-world KITTI and V2V4Real datasets across various driving and sensor attack scenarios. The results demonstrate that our proposed framework achieves 100% accuracy and 0% false alarm rate in various driving scenarios for attack detection within 0.15 s, with a recovery time of 0.08 s.}
}


@article{DBLP:journals/compsec/CastiglioneBS25,
	author = {Gianpietro Castiglione and
                  Giampaolo Bella and
                  Daniele Francesco Santamaria},
	title = {SecOnto: Ontological Representation of Security Directives},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104150},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104150},
	doi = {10.1016/J.COSE.2024.104150},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/CastiglioneBS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The current digital landscape demands robust security requirements and, for doing so, the institutions enact complex security directives to protect the citizens and the infrastructures, particularly in the European Union. These directives aim to safeguard data and harmonise security across the European region, and institutions must navigate this evolving legal landscape in order to implement and keep up-to-date the prescribed security measures. However, understanding and implementing these directives towards full compliance can be difficult and expensive. Ontological representation can be employed to represent and operationalise such security directives, ultimately contributing to the effectiveness and efficiency of the compliance process. Ontologies in fact promote a structured approach to represent knowledge, making the applicable directives more simply understandable by humans and more readily processable by machines. This article introduces SecOnto, a novel methodology for representing security directives as ontologies. SecOnto breaks down the process of transforming the juridical language of modern security directives into full-fledged ontologies by means of five semi-automated steps: Preprocessing, Interpretation, Structuring, Representation and Verification. Each step is described and validated by means of operational examples based upon Directive 2022/2555 of the European Parliament and of the Council of the European Union on security of network and information systems, better known as NIS 2.}
}


@article{DBLP:journals/compsec/MechriFD25,
	author = {Abdechakour Mechri and
                  Mohamed Amine Ferrag and
                  M{\'{e}}rouane Debbah},
	title = {SecureQwen: Leveraging LLMs for vulnerability detection in python
                  codebases},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104151},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104151},
	doi = {10.1016/J.COSE.2024.104151},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MechriFD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identifying vulnerabilities in software code is crucial for ensuring the security of modern systems. However, manual detection requires expert knowledge and is time-consuming, underscoring the need for automated techniques. In this paper, we present SecureQwen, a novel vulnerability detection tool leveraging large language models (LLMs) with a context length of 64K tokens to identify potential security threats in large-scale Python codebases. Utilizing a decoder-only transformer architecture, SecureQwen captures complex relationships between code tokens, enabling accurate classification of vulnerable code sequences across 14 common weakness enumerations (CWEs), including OS Command Injection, SQL Injection, Improper Check or Handling of Exceptional Conditions, Path Traversal, Broken or Risky Cryptographic Algorithm, Deserialization of Untrusted Data, and Cleartext Transmission of Sensitive Information. Therefore, we evaluate SecureQwen on a large Python dataset with over 1.875 million function-level code snippets from different sources, including GitHub repositories, Codeparrot’s dataset, and synthetic data generated by GPT4-o. The experimental evaluation demonstrates high accuracy, with F1 scores ranging from 84% to 99%. The results indicate that SecureQwen effectively detects vulnerabilities in human-written and AI-generated code.}
}


@article{DBLP:journals/compsec/LvWSPSZZLS25,
	author = {Fei Lv and
                  Hangyu Wang and
                  Rongkang Sun and
                  Zhiwen Pan and
                  Shuaizong Si and
                  Meng Zhang and
                  Weidong Zhang and
                  Shichao Lv and
                  Limin Sun},
	title = {Detection of cyberattack in Industrial Control Networks using multiple
                  adaptive local kernel learning},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104152},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104152},
	doi = {10.1016/J.COSE.2024.104152},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LvWSPSZZLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The data of Industrial Control Networks presents high-dimensional and nonlinear characteristics, making cyberattack detection a challenging problem. Multiple kernel learning (MKL) provided an attractive performance in dealing with the problem through the  kernel trick . However, each kernel in traditional MKL usually adopts global features for high-dimensional space mapping. The local-related feature whereas, is ignored, resulting in the missing of the local implicit information. To tackle this problem, this article proposes an MKL-based cyberattack detection method combining both global and local kernels. First, information theory-based feature selection is used for local feature grouping. After that, different kinds of deep neural networks are used to generate local kernels for each group. Moreover, an adaptive method is designed for ensembling the local kernels into the global kernel during the learning process. Extensive experiments are conducted on diverse datasets and the performances are comprehensively evaluated. The results indicate that our proposed method is outstanding in the cyberattack detection of Industrial Control Networks.}
}


@article{DBLP:journals/compsec/ZhangM25,
	author = {Yunxiao Zhang and
                  Pasquale Malacaria},
	title = {Dealing with uncertainty in cybersecurity decision support},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104153},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104153},
	doi = {10.1016/J.COSE.2024.104153},
	timestamp = {Wed, 21 May 2025 16:26:08 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The mathematical modeling of cybersecurity decision-making heavily relies on cybersecurity metrics. However, achieving precision in these metrics is notoriously challenging, and their inaccuracies can significantly influence model outcomes. This paper explores resilience to uncertainties in the effectiveness of security controls. We employ probabilistic attack graphs to model threats and introduce two resilient models: minmax regret and min-product of risks, comparing their performance. Building on previous Stackelberg game models for cybersecurity, our approach leverages totally unimodular matrices and linear programming (LP) duality to provide efficient solutions. While minmax regret is a well-known approach in robust optimization, our extensive simulations indicate that, in this context, the lesser-known min-product of risks offers superior resilience. To demonstrate the practical utility and robustness of our framework, we include a multi-dimensional decision support case study focused on home IoT cybersecurity investments, highlighting specific insights and outcomes. This study illustrates the framework’s effectiveness in real-world settings.}
}


@article{DBLP:journals/compsec/RendallMVG25,
	author = {Kieran Rendall and
                  Alexios Mylonas and
                  Stilianos Vidalis and
                  Dimitris Gritzalis},
	title = {{MIDAS:} Multi-layered attack detection architecture with decision
                  optimisation},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104154},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104154},
	doi = {10.1016/J.COSE.2024.104154},
	timestamp = {Mon, 09 Dec 2024 22:47:47 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/RendallMVG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of cyber attacks has led to the use of data-driven detection countermeasures, in an effort to mitigate this threat. Machine learning techniques, such as the use of neural networks, have become mainstream and proven effective in attack detection. However, these data-driven solutions are limited by:  a)  high computational overhead associated with data pre-processing and inference cost,  b)  inability to scale beyond a centralised deployment to cope with environmental variances, and c) requirement to use multiple bespoke detection models for effective attack detection coverage across the cyber kill chain. In this context, this paper introduces MIDAS, a cost-effective framework for attack detection, which introduces a dynamic decision boundary that is used in a multi-layered detection architecture. This is achieved by modelling the decision confidence of the participating detection models and judging its benefits using a novel reward policy. Specifically, a reward is assigned to a set of available actions, corresponding to a decision boundary, based on its cost-to-performance, where an  overall  cost-saving is prioritised. We evaluate our approach on two widely used datasets representing two of the most common threats today,  i.e.,  phishing and malware. MIDAS shows that it effectively reduces the expenditure on detection inference and processing costs by controlling the frequency of expensive detection operations. This is achieved without significant sacrifice of attack detection performance.}
}


@article{DBLP:journals/compsec/HanLZWYCSHL25,
	author = {Yufei Han and
                  Chao Li and
                  Jianbiao Zhang and
                  Yifan Wang and
                  Lehao Yu and
                  Yihao Cao and
                  Hong Shen and
                  Weixing Hou and
                  Hailin Luo},
	title = {{DMSCTS:} Dynamic measurement scheme for the containers-hybrid-deployment
                  based on trusted subsystem},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104158},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104158},
	doi = {10.1016/J.COSE.2024.104158},
	timestamp = {Tue, 01 Apr 2025 19:00:05 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HanLZWYCSHL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hybrid deployment of containers with different kernel types offers a novel solution for cloud service providers. While extensive research has been conducted on shared kernel containers, the security risks associated with diverse kernel types in hybrid deployment scenarios present more complex challenges. Establishing trusted relationships from hardware to containers for hybrid deployment has become a primary concern. Additional challenges include the lack of measurement and communication methods for independent kernel containers and insufficient dynamic measurement capabilities for containers. To address these issues, we propose a novel approach of achieving secure hybrid deployment of containers through the provision of trusted assurance in three layers: container infrastructure, container application environment, and container runtime. We propose the corresponding measurement schemes for each trust layer. Through functional verification and performance evaluation, we demonstrate that our architecture exhibits improved feasibility and effectiveness.}
}


@article{DBLP:journals/compsec/RenG25,
	author = {Jiafeng Ren and
                  Rong Geng},
	title = {Provenance-based {APT} campaigns detection via masked graph representation
                  learning},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104159},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104159},
	doi = {10.1016/J.COSE.2024.104159},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/RenG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced Persistent Threats (APTs) are well-planned, persistent, and highly stealthy cyberattacks designed to steal confidential information or disrupt specific target systems. Recent studies have used system audit logs to construct provenance graphs that describe system interactions to detect potentially malicious activities. Although they are effective, they still suffer from problems such as the need for a priori knowledge, lack of attack data, and high computational overhead that limit their application. In this paper, we propose a self-supervised learning-based APT detection model, APT-MGL, which learns the embedded representations of nodes through a graph mask self-encoder and transforms the detection problem into an outlier detection problem for malicious nodes. APT-MGL characterizes the behavior of nodes based on node type, action, and interaction frequency, and fuses the features through a multi-head self-attention mechanism. Then the node embedding is obtained by combining graph features and structural information using masked graph representation learning. Finally, the unsupervised outlier detection method is used to analyze the computed embeddings and obtain the final detection results. The experimental results show that APT-MGL outperforms existing monitoring models and achieves a small overhead.}
}


@article{DBLP:journals/compsec/ShafiLR25,
	author = {MohammadMoein Shafi and
                  Arash Habibi Lashkari and
                  Arousha Haghighian Roudsari},
	title = {NTLFlowLyzer: Towards generating an intrusion detection dataset and
                  intruders behavior profiling through network and transport layers
                  traffic analysis and pattern extraction},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104160},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104160},
	doi = {10.1016/J.COSE.2024.104160},
	timestamp = {Wed, 06 Nov 2024 22:18:56 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ShafiLR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network security remains a critical concern in modern computing systems due to the constant emergence of threats and attacks. This paper introduces a comprehensive behavioral profiling solution to address the limitations of current intrusion detection methods in identifying zero-day attacks and novel malicious behaviors. Beginning with raw network data, the proposed framework progresses through multiple stages, ultimately culminating in the creation of activity-specific profiles. Central to this approach is NTLFlowLyzer, a novel network traffic analyzer, which generates an updated dataset, BCCC-CIC-IDS2017, for enhanced profile generation. The core of the profiling system leverages the distinct behaviors exhibited by individual features and the diverse correlations observed across various activities. The profiling procedure attains accuracy and robustness by integrating a novel feature selection algorithm and a pattern extraction process. Furthermore, behavior similarity is introduced to quantify the resemblance between activities based on their features and behaviors. We rigorously evaluate the effectiveness of our model by subjecting it to comprehensive testing, followed by meticulous comparison with previous works. Our proposed framework proficiently characterizes eight malicious activities with an accuracy rate surpassing 99.8%, while displaying promising performance in profiling various other activities. These findings, derived from our comprehensive experiments, provide valuable guidance for accurately implementing behavioral profiling.}
}


@article{DBLP:journals/compsec/LiXZZ25,
	author = {Yan{-}zi Li and
                  Li Xu and
                  Jing Zhang and
                  Liao{-}ru{-}xing Zhang},
	title = {{WF-LDPSR:} {A} local differential privacy mechanism based on water-filling
                  for secure release of trajectory statistics data},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104165},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104165},
	doi = {10.1016/J.COSE.2024.104165},
	timestamp = {Wed, 30 Oct 2024 16:48:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiXZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open Data Processing Services are used to solve the bottleneck of big data storage and operation. At the same time, massive trajectory data is generated, and the basic information of users’ spatio-temporal historical data is provided, including points of interest and movement patterns. Improving the availability of published trajectory statistics data without compromising user privacy is critical. Differential privacy technology is a standard technology to realize the secure release of trajectory statistics data. Several research efforts have focused on secure publication of trajectory statistics data in a central environment by adding noise to a trusted third-party server. However, this central approach is vulnerable to privacy breaches, where adversaries can access real data by locking down the third-party server. The local differential privacy, based on a distributed architecture, overcomes this form of attack by allowing users to scramble personal data records before they are sent to third-party server. However, the existing distributed privacy protection schemes still have the balance problem of poor availability of data when ensuring privacy, as well as the problem of excessive operation cost. Therefore, a local differential privacy mechanism based on water-filling for secure release of trajectory statistics data (WF-LDPSR) is proposed in this paper. Firstly, in order to protect user privacy individually, a user automatic personalized segmentation method is proposed to determine the effective user sensitivity level automatically. Secondly, a distributed privacy protection model based on local differential privacy is designed to resist the attacks on the third-party server. Finally, in order to achieve the optimal allocation of privacy budget, the water-filling theorem in the field of communication is introduced. An adaptive privacy budget allocation algorithm based on water-filling theorem is proposed to realize the adaptive privacy budget allocation. In addition, to further improve data availability, a group processing idea based on user set sampling is proposed, which divides users into multiple disjoint subsets randomly, thus reducing the differential privacy noise effectively. Experiments prove that compared with other advanced mechanisms, the WF-LDPSR mechanism can improve the availability of published data by 84.92% while protecting user privacy.}
}


@article{DBLP:journals/compsec/YuanAC25,
	author = {Ying Yuan and
                  Giovanni Apruzzese and
                  Mauro Conti},
	title = {Beyond the west: Revealing and bridging the gap between Western and
                  Chinese phishing website detection},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104115},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104115},
	doi = {10.1016/J.COSE.2024.104115},
	timestamp = {Mon, 03 Mar 2025 21:31:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/YuanAC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing attacks are on the rise, and phishing  websites  are everywhere, denoting the brittleness of security mechanisms reliant on blocklists. To cope with this threat, many works proposed to enhance Phishing Website Detectors (PWD) with data-driven techniques powered by Machine Learning (ML). Despite achieving promising results both in research and practice, existing solutions mostly focus “on the West”, e.g., they consider websites in English, German, or Italian. In contrast, phishing websites targeting “Eastern” countries, such as China, have been mostly neglected—despite phishing being rampant also in this side of the world. In this paper, we scrutinize whether current PWD can simultaneously work against Western and Chinese phishing websites. First, after highlighting the difficulties of practically testing PWD on Chinese phishing websites, we create CghPghrg—a dataset which enables assessment of PWD on Chinese websites. Then, we evaluate 72 PWD developed by industry practitioners and 10 ML-based PWD proposed in recent research on Western and Chinese websites: our results highlight that existing solutions, despite achieving low false positive rates, exhibit unacceptably low detection rates (sometimes inferior to 1%) on phishing websites of different  regions . Next, to bridge the gap we brought to light, we elucidate the differences between Western and Chinese websites, and devise an enhanced feature set that accounts for the unique characteristics of Chinese websites. We empirically demonstrate the effectiveness of our proposed feature set by replicating (and testing) state-of-the-art ML-PWD: our results show a small but statistically significant improvement over the baselines. Finally, we review all our previous contributions and combine them to develop practical PWD that simultaneously work on Chinese and Western websites, achieving over 0.98 detection rate while maintaining only 0.01 false positive rate in a cross-regional setting. We openly release all our tools, disclose all our benchmark results, and also perform proof-of-concept experiments revealing that the problem tackled by our paper extends to other “Eastern” countries that have been overlooked by prior research on PWD.}
}


@article{DBLP:journals/compsec/MaJZLJYYF25,
	author = {Chunyan Ma and
                  Zhengwei Jiang and
                  Kai Zhang and
                  Zhiting Ling and
                  Jun Jiang and
                  Yizhe You and
                  Peian Yang and
                  Huamin Feng},
	title = {TIMFuser: {A} multi-granular fusion framework for cyber threat intelligence},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104141},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104141},
	doi = {10.1016/J.COSE.2024.104141},
	timestamp = {Wed, 05 Mar 2025 08:16:10 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MaJZLJYYF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber attack campaigns with multiple technical variants are becoming increasingly sophisticated and diverse, posing great threats to institutions and every individual. Cyber Threat Intelligence (CTI) offers a novel technical solution to transition from passive to active defense against cyber attacks. To counter these attacks, security practitioners need to condense CTIs from extensive CTI sources, primarily in the form of unstructured CTI reports. Unstructured CTI reports provide detailed threat information and describe multi-step attack behaviors, which are essential for uncovering complete attack scenarios. Nevertheless, automatic analysis of unstructured CTI reports is challenging. Furthermore, manual analysis is often limited to a few CTI sources. In this paper, we propose a multi-granular fusion framework for CTIs from massive CTI sources, comprising a comprehensive pipeline with six subtasks. Many current CTI extraction systems are limited by mining intelligence from a single source, thereby leading to challenges such as producing a fragmented view of attack campaigns and lower value density. We fuse the attack behaviors and attack techniques of the attack campaigns using innovative and improved multi-granular fusion methods and offer a comprehensive view of the attack. TIMFuser fills a critical gap in the automated analysis and fusion of multi-source CTIs, especially in the multi-granularity aspect. In our evaluation of 739 real-world CTI reports from 542 sources, experimental results demonstrate that TIMFuser can enable security analysts to obtain a complete view of real-world attack campaigns, in terms of fused attack behaviors and attack techniques.}
}


@article{DBLP:journals/compsec/LvZ25,
	author = {Liuying Lv and
                  Peng Zhou},
	title = {TrojanProbe: Fingerprinting Trojan tunnel implementations by actively
                  probing crafted {HTTP} requests},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104147},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104147},
	doi = {10.1016/J.COSE.2024.104147},
	timestamp = {Tue, 04 Mar 2025 08:09:55 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LvZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trojan is a well-known hidden tunnel protocol widely used to bypass Internet censorship and thus presents a big challenge to transparent network management and forensics. As claimed by the protocol designer, Trojan maintains its anti-identifiability by proxying real HTTPS/TLS traffic to react to unauthenticated requests, eliminating any subtle differences between the Trojan traffic and the legitimate HTTPS. Despite such a protocol seeming unidentifiable by design, the diverse Trojan implementations adopting very different programming languages will likely have varied coding logic and networking API calls, opening a new door to be identified and fingerprinted from the implementation level. In this paper, we propose  TrojanProbe , a new class of active probing methods that can be used to fingerprint Trojan implementations by triggering their identifiable responses. Our basic idea is to audit the source code of the Trojan programs and discover the subtle logic discrepancy compared with the legitimate HTTPS counterparts, to craft specific HTTP requests as probes to trigger these differences for fingerprinting. By this idea, we choose the five most popular open-source Trojan programs off-the-shelf as our targets to audit, covering the majority of Trojan market share and the mainstream programming languages from traditional C++ to the cutting-edge Go and Rust, and design a suite of novel HTTP probes to differentiate them from their web server masquerades. Our probes exploit either the different responding/buffering logic to the malformed HTTP requests and the different HTTP versions, or the varied timeouts set in the different networking APIs by default. To this end, we have conducted extensive experiments to evaluate the TrojanProbe against a comprehensive set of configuration and networking conditions. The experimental results show that our TrojanProbe can effectively fingerprint our selected Trojan targets in most conditions, but leave a single Rust implementation with a minority market occupied that can only be identified in some constraint cases. Despite such an exception, our research sheds light on a new kind of possibility to fingerprint Trojans at their implementation level, even if such a hidden tunnel is widely known as unidentifiable at the protocol level.}
}


@article{DBLP:journals/compsec/ZhouXWLLLZ25,
	author = {Weidong Zhou and
                  Chunhe Xia and
                  Tianbo Wang and
                  Xiaopeng Liang and
                  Wanshuang Lin and
                  Xiaojian Li and
                  Song Zhang},
	title = {{HIDIM:} {A} novel framework of network intrusion detection for hierarchical
                  dependency and class imbalance},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104155},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104155},
	doi = {10.1016/J.COSE.2024.104155},
	timestamp = {Mon, 03 Mar 2025 21:31:13 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhouXWLLLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based network intrusion detection has been extensively explored as a data-driven approach. Therefore, paying attention to the data’s characteristics is essential. By analyzing the attribute dependence and sample distribution of intrusion data, there are the following problems: “hierarchical dependency omission” and “decision boundary discontinuity.” The former means the previous attribute embedding models failed to incorporate network protocol hierarchy. The latter indicates that the small disjuncts distribution leads to sub-concept fragmentation, exacerbating the difficulty in handling class imbalance. To address these problems, we propose a novel detection framework for  Hi erarchical  D ependency and Class  Im balance (HIDIM). First, we treat semantic attributes as words and introduce the protocol hierarchy of attributes into a paragraph embedding model. Second, we design a synthetic oversampling method. It adopts a mutual nearest neighbor approach to determine the boundaries of each disjunct. Then, it synthesizes high-quality samples within those boundary areas by crossing or mutating features based on their importance. The experimental results on multiple real-world datasets demonstrate that the proposed framework is superior to other state-of-the-art models in terms of accuracy, F1-score, and false negative rate by 2.23%, 2.12%, and 1.43% on average, respectively.}
}


@article{DBLP:journals/compsec/MalviyaMSJ25,
	author = {Vikas Kumar Malviya and
                  Wei Minn and
                  Lwin Khin Shar and
                  Lingxiao Jiang},
	title = {Fuzzing drones for anomaly detection: {A} systematic literature review},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104157},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104157},
	doi = {10.1016/J.COSE.2024.104157},
	timestamp = {Mon, 03 Mar 2025 21:31:11 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MalviyaMSJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Drones, also referred to as Unmanned Aerial Vehicles (UAVs), are becoming popular today due to their uses in different fields and recent technological advancements which provide easy control of UAVs via mobile apps. However, UAVs may contain vulnerabilities or software bugs that cause serious safety and security concerns. For example, the communication protocol used by the UAV may contain authentication and authorization vulnerabilities, which may be exploited by attackers to gain remote access over the UAV. Drones must therefore undergo extensive testing before being released or deployed to identify and fix any software bugs or security vulnerabilities. Fuzzing is one commonly used technique for finding bugs and vulnerabilities in software programs and protocols. This article reviews various approaches where fuzzing is applied to detect bugs and vulnerabilities in UAVs. Our goal is to assess the current state-of-the-art fuzzing approaches for UAVs, which are yet to be explored in the literature. We identified open challenges that call for further research to improve the current state-of-the-art.}
}


@article{DBLP:journals/compsec/LiLLDR25,
	author = {Yong Li and
                  Tongtong Liu and
                  Haichao Ling and
                  Wei Du and
                  Xianglin Ren},
	title = {A robust federated learning algorithm for partially trusted environments},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104161},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104161},
	doi = {10.1016/J.COSE.2024.104161},
	timestamp = {Mon, 03 Mar 2025 21:31:11 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiLLDR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the distributed nature of federated learning, it is vulnerable to poisoning attacks during the training process. The model’s resistance to poisoning attacks can be improved using robust aggregation algorithms. Current research on federated learning to resist poisoning attacks is mainly based on two settings: No trust or Byzantine robustness. However, both settings are not close enough to reality in practical scenarios. In many practical applications, some participants in federated learning are trustworthy. For example, participants who have participated in the training of this model before and performed very well, or participants with strong compliance and credibility such as governments and some national agencies participate in the training. In existing research, these trusted participants still have to accept the judgment of the aggregation node, which generates unnecessary computation, increases overhead, and does not take advantage of a trusted environment. Since there is no attack behavior on the trusted client, its training results are used to classify the trustworthiness of other untrusted clients and identify attack nodes with higher accuracy. Therefore, this paper proposes a robust federated learning algorithm for partially trusted environments. The proposed scheme uses the experimental results of trusted clients to judge the behavior of untrustworthy clients by the cosine similarity and the Local Outlier Factor and further identify and detect malicious clients. Experiments are performed on MNIST and CIFAR datasets. Comparison with other six aggregation algorithms under 30% attack scenario. And compared with the other four aggregation algorithms under 70% attack conditions. Our algorithm is more accurate than almost all of the other aggregation algorithms. The paper is the first to conduct robust research on federated learning in a partially trusted environment, and the proposed algorithm can more effectively resist poisoning attacks.}
}


@article{DBLP:journals/compsec/XiangLHDLL25,
	author = {Dongming Xiang and
                  Shuai Lin and
                  Ke Huang and
                  Zuohua Ding and
                  Guanjun Liu and
                  Xiaofeng Li},
	title = {A fine-grained approach for Android taint analysis based on labeled
                  taint value graphs},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104162},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104162},
	doi = {10.1016/J.COSE.2024.104162},
	timestamp = {Mon, 03 Mar 2025 21:31:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/XiangLHDLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Static taint analysis is a widely used method to identify vulnerabilities in Android applications. However, the existing tools for static analysis often struggle with processing times, particularly when dealing with complex real-world programs. To reduce time consumption, some tools choose to sacrifice analytical precision, e.g., FastDroid sets an upper limit for analysis iterations in Android applications. In this paper, we propose a labeled taint value graph (LTVG) to store taint flows, and implement a fine-grained analysis tool called  LabeledDroid . This graph is constructed based on the  taint value graph  (TVG) of FastDroid, and takes into account both precision and time consumption. That is, we decompile an Android app into Jimple statements, develop fine-grained propagation rules to handle  List , and construct LTVGs according to these rules. Afterwards, we traverse LTVGs to obtain high-precision taint flows. An analysis of 39 apps from the TaintBench benchmark shows that LabeledDroid is 0.87 s faster than FastDroid on average. Furthermore, if some common accuracy parameters are adapted in both LabeledDroid and FastDroid, the experiment demonstrates that the former is more scalable. Moreover, the maximum analysis time of LabeledDroid is less than 200 s and its average time is 46.25 s, while FastDroid sometimes experiences timeouts with durations longer than 600 s. Additionally, LabeledDroid achieves a precision of 70% in handling lists, while FastDroid and TaintSA achieve precisions of 38.9% and 41.2%, respectively.}
}


@article{DBLP:journals/compsec/KhanEMASM25,
	author = {Raviha Khan and
                  Hossien B. Eldeeb and
                  Brahim Mefgouda and
                  Omar Alhussein and
                  Hani H. Saleh and
                  Sami Muhaidat},
	title = {Encoder decoder-based Virtual Physically Unclonable Function for Internet
                  of Things device authentication using split-learning},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104164},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104164},
	doi = {10.1016/J.COSE.2024.104164},
	timestamp = {Mon, 03 Mar 2025 21:31:10 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KhanEMASM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) networks have been deployed widely making device authentication a crucial requirement that poses challenges related to security vulnerabilities, power consumption, and maintenance overheads. While current cryptographic techniques secure device communication; storing keys in Non-Volatile Memory (NVM) poses challenges for edge devices. Physically Unclonable Functions (PUFs) offer robust hardware-based authentication but introduce complexities such as hardware production and conservation expenses and susceptibility to aging effects. This paper’s main contribution is a novel scheme based on split learning, utilizing an encoder–decoder architecture at the device and server nodes, to first create a Virtual PUF (VPUF) that addresses the shortcomings of the hardware PUF and secondly perform device authentication. The proposed VPUF reduces maintenance and power demands compared to the hardware PUF while enhancing security by transmitting latent space representations of responses between the node and the server. Also, since the encoder is placed on the node, while the decoder is on the server, this approach further reduces the computational load and processing time on the resource-constrained node. The obtained results demonstrate the effectiveness of the proposed VPUF scheme in modeling the behavior of the hardware-based PUF. Additionally, we investigate the impact of Gaussian noise in the communication channel between the server and the node on the system performance. The obtained results further reveal that the achieved authentication accuracy of the proposed scheme is 100%, as measured by the validation rate of the legitimate nodes. This highlights the superior performance of the proposed scheme in emulating the capabilities of a hardware-based PUF while providing secure and efficient authentication in IoT networks.}
}


@article{DBLP:journals/compsec/DP25,
	author = {Sunitha D and
                  Latha Ph},
	title = {A secure routing and black hole attack detection system using coot
                  Chimp Optimization Algorithm-based Deep {Q} Network in {MANET}},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104166},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104166},
	doi = {10.1016/J.COSE.2024.104166},
	timestamp = {Wed, 04 Dec 2024 22:33:41 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/DP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A Mobile Ad hoc Network (MANET) is a widely used and vibrant network, which is unevenly distributed in the environment. It is a set of self-organized independent mobile nodes interconnected without any centralized infrastructure. However, this topology nature makes the network prompt to various network security attacks. To address this issue, this paper proposes a Coot Chimp Optimization Algorithm- Deep Q-Network (CChOA-DQN) for detecting the black hole attacks in MANET. Here, the designed CChOA is used for the identification of the optimal route in the MANET for transmitting data, which takes into fitness parameters, such as energy, distance, neighbourhood quality, link quality, and trust. The features are extracted using the Fisher score and augmented using the over-sampling technique, which is further allowed for the detection process using DQN. Also, the weights of the DQN are enhanced using the CChOA algorithmic technique to enhance the detection performance. Additionally, the results gathered from the experiment revealed that CChOA attained high performance with a maximum of 0.983 Mbps throughput, 93.70 % Packet Delivery Ratio (PDR), and minimum end-end delay of 0.096Sec, Residual energy of 0.119 J, and Control overhead of 4473.11. Also, the CChOA-DQN technique achieved the minimum False Positive Rate (FPR) of 0.122, False Negative Rate (FNR) of 0.121, Computation time of 0.153 and Run time of 0.094.}
}


@article{DBLP:journals/compsec/GaberAJ25,
	author = {Matthew G. Gaber and
                  Mohiuddin Ahmed and
                  Helge Janicke},
	title = {Zero day ransomware detection with Pulse: Function classification
                  with Transformer models and assembly language},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104167},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104167},
	doi = {10.1016/J.COSE.2024.104167},
	timestamp = {Mon, 03 Mar 2025 21:31:10 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/GaberAJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding automated AI techniques to proactively defend against malware has become increasingly critical. The ability of an AI model to correctly classify novel malware is dependent on the quality of the features it is trained with and the authenticity of the features is dependent on the analysis tool. Peekaboo, a Dynamic Binary Instrumentation tool defeats evasive malware to capture its genuine behaviour. The ransomware Assembly instructions captured by Peekaboo, follow Zipf’s law, a principle also observed in natural languages, indicating Transformer models are particularly well-suited to binary classification. We propose Pulse, a novel framework for zero day ransomware detection with Transformer models and Assembly language. Pulse, trained with the Peekaboo ransomware and benign software data, uniquely identify truly new samples with high accuracy. Pulse eliminates any familiar functionality across the test and training samples, forcing the Transformer model to detect malicious behaviour based solely on context and novel Assembly instruction combinations.}
}


@article{DBLP:journals/compsec/MathinaV25,
	author = {P. A. Mathina and
                  K. Valarmathi},
	title = {Advancing IoT security: {A} novel intrusion detection system for evolving
                  threats in industry 4.0 using optimized convolutional sparse Ficks
                  law graph point trans-Net},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104169},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104169},
	doi = {10.1016/J.COSE.2024.104169},
	timestamp = {Wed, 04 Dec 2024 22:33:41 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MathinaV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid advancement of Industry 4.0, the integration of Internet of Things (IoT) strategies in industrial environments has increased exponentially. While this integration enhances productivity and efficiency, it also introduces significant security vulnerabilities. Previous research has employed several deep learning approaches for intrusion detection; however, these methods often suffer from insufficient accuracy, increased computational time, complexity, and higher error rates. To address these issues, this work proposes an innovative solution: "Advancing IoT Security: A Novel Intrusion Detection System (IDS) for Evolving Threats in Industry 4.0 using optimized Convolutional Sparse Fick\'s Law Graph Pointtrans-Net (CSFLGPtrans-Net)." The proposed system utilizes a comprehensive intrusion detection dataset composed of four different datasets: ToN-IoT, NSL-KDD, CSE‑CIC‑IDS2018, and IoT_bot. Initially, the input data undergoes a pre-processing stage that includes cleaning columns and rows, encoding features, and normalizing data. Following this, a hybrid optimization method, combining the Fire Hawk Optimizer with the Spider Wasp Optimizer, is applied for feature selection. This step is crucial for identifying the most significant features to enhance classification accuracy. The refined data is then classified using the CSFLGPtrans-Net model. To ensure secure data transfer, Fuzzy-based Elliptic Curve Cryptography (FECC) is employed. Experimental simulations conducted on the Python platform demonstrate that the proposed method outperforms existing approaches across various performance metrics, achieving a higher accuracy of 98% and a recall of 0.993. These results highlight the method\'s superior efficiency and potential for further advancement in securing Industry 4.0 environments.}
}


@article{DBLP:journals/compsec/OmolaraA25,
	author = {Abiodun Esther Omolara and
                  Moatsum Alawida},
	title = {DaE2: Unmasking malicious URLs by leveraging diverse and efficient
                  ensemble machine learning for online security},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104170},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104170},
	doi = {10.1016/J.COSE.2024.104170},
	timestamp = {Wed, 04 Dec 2024 22:33:41 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/OmolaraA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over 5.44 billion people now use the Internet, making it a vital part of daily life, enabling communication, e-commerce, education, and more. However, this huge Internet connectivity also raises concerns about online privacy and security, particularly with the rise of malicious Uniform Resource Locators (URLs). Recently, conventional ensemble models have attracted attention due to their notable benefits of reducing the variance in models, enhancing predictive performance, improving prediction accuracy, and demonstrating high generalization potential. But, its application in addressing the challenge of malicious URLs is still an open problem. These URLs often hide behind static links in emails or web pages, posing a threat to individuals and organizations. Despite blacklisting services, many harmful sites evade detection due to inadequate scrutiny or recent creation. Hence, to improve URL detection, a Diverse and Efficient Ensemble (DaE2) machine learning algorithm was developed using four ensemble models, that is, AdaBoost, Bagging, Stacking, and Voting to classify URLs. After preprocessing, the experimental result shown that all models achieved over 80 % accuracy, with AdaBoost reaching 98.5 % and Stacking offering the fastest runtime. AdaBoost and Bagging also delivered strong performance, with F1 scores of 0.980 and 0.976, respectively.}
}


@article{DBLP:journals/compsec/ZhaoFWDH25,
	author = {Jingwen Zhao and
                  Yan Fu and
                  Yanxia Wu and
                  Jibin Dong and
                  Ruize Hong},
	title = {Thread-sensitive fuzzing for concurrency bug detection},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104171},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104171},
	doi = {10.1016/J.COSE.2024.104171},
	timestamp = {Thu, 01 May 2025 20:32:43 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhaoFWDH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fuzzing is a commonly used method for identifying bugs and vulnerabilities in software. However, current methods for improving fuzzing in concurrency environments often lack a detailed analysis of the program’s concurrent state space. This leads to inefficient execution of previously verified concurrent states and missed information. We have developed TSAFL, a novel concurrency fuzzing framework that aims to detect the running state of concurrency programs and uncover hard-to-find vulnerabilities. TSAFL builds upon AFL’s concurrency vulnerability detection capabilities by incorporating three new techniques. Firstly, we introduce two new coverage metrics to measure concurrency: concurrent behavior window and CFG prediction. These metrics enhance the TSAFL’s capabilities to explore more thread interleavings. The second technique adds efficient thread-interleaved scheduling to fuzzing combined with period scheduling. Several methods are proposed to avoid problems caused by simply using period scheduling to accurately detect and verify all concurrent state spaces. Thirdly, we propose a multi-objective optimization mechanism based on the characteristics of concurrent fuzz testing to fully utilize the information in the seed files. Using these three techniques, our concurrency fuzzing approach effectively covers infrequent thread interleavings with concrete context information. We evaluated TSAFL on user-level applications, and experiments show that TSAFL outperforms AFL++ and MOPT in multithreading-related seed generation and concurrent vulnerability detection.}
}


@article{DBLP:journals/compsec/WuBZLY25,
	author = {Zhijun Wu and
                  Yun Bai and
                  Yuan Zhang and
                  Liang Liu and
                  Meng Yue},
	title = {TrustCNAV: Certificateless aggregate authentication of civil navigation
                  messages in {GNSS}},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104172},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104172},
	doi = {10.1016/J.COSE.2024.104172},
	timestamp = {Wed, 29 Jan 2025 17:54:21 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WuBZLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Global Navigation Satellite System (GNSS) is capable of accurate positioning because it can provide high-precision data. These data are transmitted to the receiver in the form of navigation messages, called civil navigation messages (CNAV). As it is transmitted in an open, transparent environment without data integrity protection mechanisms and secure data transmission measures, the CNAV is suspected to spoofing attacks. In 2023, the OPSGROUP has received approximately 50 reports of GPS spoofing activity. A spoofed plane's navigation system will show it as being in a different place - a security risk if a jet is guided to fly into a hostile country's airspace. To prevent the forging of GNSS positioning data by spoofing attacks targeting CNAV, we propose a certificateless aggregation authentication for CNAV by using the elliptic curve discrete logarithm problem and the combination of the GNAV structural characteristics, called TrustCNAV. Security proof and performance analysis indicate that this authentication scheme can resist spoofing attacks and ensure data security of CNAV, also it avoids pairing operations with high computational complexity, thus meeting security requirements without causing too much time and communication consumption.}
}


@article{DBLP:journals/compsec/LiuFWDW25,
	author = {Taotao Liu and
                  Yu Fu and
                  Kun Wang and
                  Xueyuan Duan and
                  Qiuhan Wu},
	title = {A multiscale approach for network intrusion detection based on variance-covariance
                  subspace distance and {EQL} v2},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104173},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104173},
	doi = {10.1016/J.COSE.2024.104173},
	timestamp = {Wed, 04 Dec 2024 22:33:41 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiuFWDW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an important network defense approach, network intrusion detection is mainly used to identify anomaly traffic behavior. However, dominant network intrusion detection approaches are now struggling to identify the complex and variable means of attack, leading to high false alarm rate. Additionally, the feature redundancy and class imbalance problem in the intrusion detection dataset also constrain the performance of detection methods. This paper proposes a multiscale intrusion detection approach based on variance–covariance subspace distance and Equalization Loss v2 (EQL v2). Firstly, the variance–covariance subspace distance is used for feature selection on the preprocessed dataset to determine a set of representative feature subsets that can effectively approximate the original feature space. Secondly, the loss function, EQL v2, is adopted to balance the positive and negative gradients, addressing the class imbalance problem. Finally, a pyramid depthwise separable convolution model is proposed to capture the multiscale information of the traffic, and the convolutional layer in the depthwise convolution is replaced with self-supervised predictive convolutional attention block to compensate for the performance loss caused by the parameter reduction. Extensive experiments demonstrated that the proposed approach exhibits better performance on the three datasets of NSL-KDD, UNSW_NB15, and CIC-IDS-2017, with accuracy rates of 99.19%, 97.81%, and 99.83%, respectively, effectively improve the intrusion detection performance.}
}


@article{DBLP:journals/compsec/JiangXYF25,
	author = {Xuefeng Jiang and
                  Liuquan Xu and
                  Li Yu and
                  Xianjin Fang},
	title = {{MFT:} {A} novel memory flow transformer efficient intrusion detection
                  method},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104174},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104174},
	doi = {10.1016/J.COSE.2024.104174},
	timestamp = {Mon, 03 Mar 2025 21:31:10 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/JiangXYF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intrusion detection is a critical field in network security research that is devoted to detecting malicious traffic or attacks on networks. Even with the advances in today's Internet environment, a lot of intrusion detection techniques still fail to take into account the long-term characteristics present in network data, which results in a high false alarm rate. Some researchers have tried to address this problem by using the traditional transformer model; however, it is not very effective when dealing with complex relationships and the subtle classification requirements of large amounts of sequential data. This work presents a novel solution called the memory flow transformer (MFT) in response to the limitations of the conventional transformer model. By utilizing a carefully designed memory flow structure, MFT transcends traditional limitations and makes it possible to obtain complex long-term features from network traffic. This innovation enables the model to identify deep connections at a finer level between a wide variety of network traffic data. Extensive experiments were carried out on the complex CICIDS 2017 and NSL-KDD datasets to validate the effectiveness of the MFT model. The results were outstanding, demonstrating MFT's powerful detection abilities. With regard to performance metrics like accuracy, F1 score, false alarm rate, and training time, MFT is superior to current state-of-the-art approaches. Network security is greatly strengthened by MFT, which provides practitioners in the intrusion detection field with novel and effective techniques.}
}


@article{DBLP:journals/compsec/LuLPL25,
	author = {Hongyu Lu and
                  Jiajia Liu and
                  Jimin Peng and
                  Jiazhong Lu},
	title = {Adversarial attacks based on time-series features for traffic detection},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104175},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104175},
	doi = {10.1016/J.COSE.2024.104175},
	timestamp = {Mon, 03 Mar 2025 21:31:11 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LuLPL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To enhance the robustness of intrusion detection classifiers, we propose a Time Series-based Adversarial Attack Framework (TSAF) targeting the temporal characteristics of network traffic. Initially, adversarial samples are generated using the gradient calculations of CNNs, with updates iterated based on model loss. Different attack schemes are then applied to various traffic types and saved as generic adversarial perturbations. These time series-based perturbations are subsequently injected into the traffic stream. To precisely implement the adversarial perturbations, a masking mechanism is utilized. Our adversarial sample model was evaluated, and the results indicate that our samples can reduce the accuracy and recall rates for detecting four types of malicious network traffic, including botnets, brute force, port scanning, and web attacks, as well as degrade the detection performance of DDoS traffic. The CNN model’s accuracy dropped by up to 72.76%, and the SDAE model’s accuracy by up to 78.77% with minimal perturbations. Our adversarial sample attack offers a new perspective in the field of cybersecurity and lays the groundwork for designing AI models that can resist adversarial attacks more effectively.}
}


@article{DBLP:journals/compsec/ZhangXHWC25,
	author = {Jie Zhang and
                  Lei Xie and
                  Lang He and
                  Zhongmin Wang and
                  Jing Chen},
	title = {Enhanced cell phone security: An ultrasonic and sensor fusion-based
                  persistent cell phone protection method integrating anti-theft {\&}
                  identity authentication},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104176},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104176},
	doi = {10.1016/J.COSE.2024.104176},
	timestamp = {Tue, 04 Mar 2025 08:09:48 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangXHWC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of the Internet of Things, cell phones inevitably involve people’s privacy and property information. Therefore, ensuring cell phone security is of great importance. Current cell phone protection methods include cell phone anti-theft and identity authentication, but each has limitations. Cell phone anti-theft methods focus on preventing cell phone loss but do not adequately address privacy security. Identity authentication emphasizes privacy protection but overlooks the cell phone’s security. Previous studies have achieved these two methods through ultrasonic or sensors. However, ultrasonic-based methods are limited by sensing distance and are inconvenient to use. Sensor-based methods do not detect subtle movements and may have shortcomings in terms of security. This study proposes an ultrasonic and sensor fusion-based persistent cell phone protection method integrating anti-theft and identity authentication. Unlike past work, this study uses ultrasonic and inertial sensors to capture motion data of users with different granularity, and provide multifaceted protection for cell phones through anti-theft when taking up the cell phone (ATWTP) and gait identity authentication (GTIA). Our intuition in the design is that each individual has unique movements and gait patterns, resulting in differences in the collected data from ultrasonic and inertial sensors. These differences can be used to achieve persistent protection of the cell phone. This study combines the strengths of sensors and ultrasonic through multimodal fusion and designs a system that incorporates system-triggered event detection (STED), ATWTP, and GTIA. The results demonstrate that the proposed design achieves an accuracy of 96.88% in protecting cell phones.}
}


@article{DBLP:journals/compsec/WuGSWP25,
	author = {Peng Wu and
                  Mohan Gao and
                  Fuhui Sun and
                  Xiaoyan Wang and
                  Li Pan},
	title = {Multi-perspective {API} call sequence behavior analysis and fusion
                  for malware classification},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104177},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104177},
	doi = {10.1016/J.COSE.2024.104177},
	timestamp = {Tue, 04 Mar 2025 12:28:06 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WuGSWP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing variety of malicious software, i.e., malware, has caused great damage and economic loss to computer systems. The API call sequence of malware reflects its dynamic behavior during execution, which is difficult to disguise. Therefore, API call sequence can serve as a robust feature for the detection and classification of malware. The statistical analysis presented in this paper reveals two distinct characteristics within the API call sequences of different malware: (1) the API existence feature caused by frequent calls to the APIs with some special functions, and (2) the API transition feature caused by frequent calls to some special API subsequence patterns. Based on these two characteristics, this paper proposes MINES, a Multi-perspective apI call sequeNce bEhavior fuSion malware classification Method. Specifically, the API existence features from different perspectives are described by two graphs that model diverse rich and complex existence relationships between APIs, and we adopt the graph contrastive learning framework to extract the consistent shared API existence feature from two graphs. Similarly, the API transition features of different hops are described by the multi-order transition probability matrices. By treat each order as a channel, a CNN-based contrastive learning framework is adopted to extract the API transition feature. Finally, the two kinds of extracted features are fused to classify malware. Experiments on five datasets demonstrate the superiority of MINES over various state-of-the-arts by a large margin.}
}


@article{DBLP:journals/compsec/GilPF25,
	author = {C{\'{e}}sar Gil and
                  Javier Parra{-}Arnau and
                  Jordi Forn{\'{e}}},
	title = {Privacy protection against user profiling through optimal data generalization},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104178},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104178},
	doi = {10.1016/J.COSE.2024.104178},
	timestamp = {Mon, 03 Mar 2025 21:31:10 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/GilPF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized information systems are information-filtering systems that endeavor to tailor information-exchange functionality to the specific interests of their users. The ability of these systems to profile users based on their search queries at Google, disclosed locations at Twitter or rated movies at Netflix, is on the one hand what enables such intelligent functionality, but on the other, the source of serious privacy concerns. Leveraging on the principle of data minimization, we propose a data-generalization mechanism that aims to protect users’ privacy against non-fully trusted personalized information systems. In our approach, a user may like to disclose personal data to such systems when they feel comfortable. But when they do not, they may wish to replace specific and sensitive data with more general and thus less sensitive data, before sharing this information with the personalized system in question. Generalization therefore may protect user privacy to a certain extent, but clearly at the cost of some information loss. In this work, we model mathematically an optimized version of this mechanism and investigate theoretically some key properties of the privacy-utility trade-off posed by this mechanism. Experimental results on two real-world datasets demonstrate how our approach may contribute to privacy protection and show it can outperform state-of-the-art perturbation techniques like data forgery and suppression by providing higher utility for a same privacy level. On a practical level, the implications of our work are diverse in the field of personalized online services. We emphasize that our mechanism allows each user individually to take charge of their own privacy, without the need to go to third parties or share resources with other users. And on the other hand, it provides privacy designers/engineers with a new data-perturbative mechanism with which to evaluate their systems in the presence of data that is likely to be generalizable according to a certain hierarchy, highlighting spatial generalization, with practical application in popular location based services. Overall, a data-perturbation mechanism for privacy protection against user profiling, which is optimal, deterministic, and local, based on a untrusted model towards third parties.}
}


@article{DBLP:journals/compsec/XiaoCYHJTJ25,
	author = {Fengrui Xiao and
                  Shuangwu Chen and
                  Jian Yang and
                  Huasen He and
                  Xiaofeng Jiang and
                  Xiaobin Tan and
                  Dong Jin},
	title = {{GRAIN:} Graph neural network and reinforcement learning aided causality
                  discovery for multi-step attack scenario reconstruction},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104180},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104180},
	doi = {10.1016/J.COSE.2024.104180},
	timestamp = {Mon, 03 Mar 2025 21:31:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/XiaoCYHJTJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Correlating individual alerts to reconstruct attack scenarios has become a critical issue in identifying multi-step attack paths. Most of existing reconstruction approaches depend on external expertise, such as attack templates or attack graphs, to identify known attack patterns, which are incapable of uncovering unknown attack patterns that exceed prior knowledge. Recently, several expertise-independent methods utilize alert similarity or statistical correlations to reconstruct multi-step attacks. However, these methods often miss rare but high-risk events. The key to overcoming these drawbacks lies in discovering the potential causalities between security alerts. In this paper, we propose GRAIN, a novel graph neural network and reinforcement learning aided causality discovery approach for multi-step attack scenario reconstruction, which does not rely on any external expertise or prior knowledge. By matching the similarity between alerts’ attack semantics, we first remove redundant alerts to alleviate alert fatigue. Then, we correlate these alerts as alert causal graphs that embody the causalities between attack incidents via causality discovery. Afterwards, we employ a graph neural network to evaluate the causal effect between correlated alerts. In light of the fact that the alerts triggered by multi-step attacks have the maximum causal effect, we utilize reinforcement learning to screen out authentic causal relationships. Extensive evaluations on 4 public multi-step attack datasets demonstrate that GRAIN significantly outperforms existing methods in terms of accuracy and efficiency, providing a robust solution for identifying and analyzing sophisticated multi-step attacks.}
}


@article{DBLP:journals/compsec/WooCL25,
	author = {Seunghoon Woo and
                  Eunjin Choi and
                  Heejo Lee},
	title = {A large-scale analysis of the effectiveness of publicly reported security
                  patches},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104181},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104181},
	doi = {10.1016/J.COSE.2024.104181},
	timestamp = {Mon, 03 Mar 2025 21:31:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WooCL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Public vulnerability reports assist developers in mitigating recurring threats caused by software vulnerabilities. However, security patches that lack effectiveness (1) may fail to completely resolve target vulnerabilities after application ( i.e. , require supplementary patches), or (2) cannot be directly applied to the codebase without modifying the patch code snippets. In this study, we systematically assessed the effectiveness of security patches from the perspective of their reliability and flexibility. We define a security patch as reliable or flexible, respectively, if it can resolve the vulnerability (1) without being complemented by additional patches or (2) without modifying the patch code snippets. Unlike previous studies that relied on manual inspection, we assess the reliability of a security patch by determining the presence of supplementary patches that complement the security patch. To evaluate flexibility, we first locate vulnerable codes in popular open-source software programs and then determine whether the security patch can be applied without any modifications. Our experiments on 8,100 security patches obtained from the National Vulnerability Database confirmed that one in ten of the collected patches lacked effectiveness. We discovered 476 (5.9%) unreliable patches that could still produce security issues after application; for 84.6% of the detected unreliable patches, the fact that a supplementary patch is required is not disclosed through public security reports. Furthermore, 377 (4.6%) security patches were observed to lack flexibility; we confirmed that 49.1% of the detected vulnerable codes required patch modifications owing to syntax diversity. Our findings revealed that the effectiveness of security patches can directly affect software security, suggesting the need to enhance the vulnerability reporting process.}
}


@article{DBLP:journals/compsec/JafarYL25,
	author = {Mousa Tayseer Jafar and
                  Lu{-}Xing Yang and
                  Gang Li},
	title = {An innovative practical roadmap for optimal control strategies in
                  malware propagation through the integration of {RL} with {MPC}},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104186},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104186},
	doi = {10.1016/J.COSE.2024.104186},
	timestamp = {Mon, 03 Mar 2025 21:31:10 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/JafarYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While there has been considerable research into optimal control formulations for mitigating cyber threats, a significant gap persists between the theoretical and numerical insights derived from such research and the practical implementation of these optimal mitigation strategies in real-time scenarios. This paper introduces a multifaceted approach to enhance and optimize optimal control strategies by seamlessly integrating reinforcement learning (RL) algorithms with model predictive control (MPC) techniques for the purpose of malware propagation control. Optimal control is a critical aspect of various domains, ranging from industrial processes and robotics to epidemiological modeling and cybersecurity. The traditional approaches to optimal control, particularly open-loop strategies, have limitations in adapting to dynamic and uncertain environments. This paper addresses these limitations by proposing a novel roadmap that leverages RL algorithms to fine-tune and adapt MPC parameters within the context of malware propagation containment. In sum, this practical roadmap is anticipated to serve as a valuable resource for researchers and practitioners engaged in the development of cybersecurity solutions.}
}


@article{DBLP:journals/compsec/VidyasriS25,
	author = {P. Vidyasri and
                  S. Suresh},
	title = {{FDN-SA:} Fuzzy deep neural-stacked autoencoder-based phishing attack
                  detection in social engineering},
	journal = {Comput. Secur.},
	volume = {148},
	pages = {104188},
	year = {2025},
	url = {https://doi.org/10.1016/j.cose.2024.104188},
	doi = {10.1016/J.COSE.2024.104188},
	timestamp = {Wed, 04 Dec 2024 22:33:41 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/VidyasriS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing attacks have emerged as a major social engineering threat that affects businesses, governments, and general internet users. This work proposes a social engineering phishing detection technique based on Deep Learning (DL). Initially, website data is taken from the dataset. Then, the features of Natural Language Processing (NLP) like bag of words, n-gram, hashtags, sentence length, Term Frequency- Inverse Document Frequency of records (TF-IDF), and all caps are extracted and then web feature extraction is carried out. Later, the feature fusion is done using the Neyman similarity with Deep Belief Network (DBN). Afterwards, oversampling is used for data augmentation to enhance the number of training samples. Lastly, the detection of phishing attacks is performed by employing the proposed Fuzzy Deep Neural-Stacked Autoencoder (FDN-SA). Here, the proposed FDN-SA is developed by combining a Deep Neural Network (DNN), and Deep Stacked Autoencoder (DSA). Further, the investigation of FDN-SA is accomplished based on the accuracy, True Positive Rate (TPR), and True Negative Rate (TNR) and is observed to compute values of 0.920, 0.925, and 0.921, respectively.}
}
