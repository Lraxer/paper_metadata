@article{DBLP:journals/compsec/KambleM24,
	author = {Naresh Kamble and
                  Nilamadhab Mishra},
	title = {Hybrid optimization enabled squeeze net for phishing attack detection},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103901},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103901},
	doi = {10.1016/J.COSE.2024.103901},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KambleM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, phishing attacks are considered as one of the most common cyber-attacks which generally harm the security of various internet and communication systems. The phishing websites are produced with the intention of determining the user's financial information by creating cyber threats. The loss of valuable user assets occurs due to the frequent creation and circulation of fake websites all over the internet. The negative impacts of phishing websites include financial loss, loss of intellectual property, reputational harm, and interruption of daily operations. To identify and lessen these attempts, several anti-phishing strategies have been put forth during the past ten years. However, they are still inaccurate and inefficient. To overcome this problem, intelligent approaches, like Deep Learning (DL) is used, which can accurately learn the inherent characteristics of the websites and identify phishing websites. In this paper, the phishing websites are determined effectively using the Fractional Dingo Hunter Prey Optimization-SqueezeNet (FDHPO-SqueezeNet) technique. The different features, like web features, ocular features, and Natural Language Processing (NLP) features are extracted separately from the website data. Later, the optimal features are selected, fused, and augmented, and allowed for the detection of phishing websites using SqueezeNet. Finally, the phishing detection is performed using SqueezeNet, where the detection performance of the SqueezeNet is increased by training using the FDHPO technique. The investigation results revealed that the designed FDHPO-SqueezeNet technique recorded greater performance when compared with other prevailing phishing detection approaches with a maximal of 93.05 % accuracy, 94.26 % sensitivity, and 93.75 % specificity, respectively.}
}


@article{DBLP:journals/compsec/ChangZSW24,
	author = {Heyu Chang and
                  Xiaobing Zhang and
                  Nianwen Si and
                  Ping Wu},
	title = {A lightweight packet forwarding verification in {SDN} using sketch},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103906},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103906},
	doi = {10.1016/J.COSE.2024.103906},
	timestamp = {Mon, 05 Aug 2024 21:42:42 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChangZSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By decoupling the control plane and the data plane, Software Defined Networking (SDN) has reshaped the ossified network architecture and improved the programmability of the network. However, SDN is also susceptible to malicious injection, tampering, dropping and hijacking attacks against forwarding packets, and the SDN architecture cannot perceive the real behavior of switches in the data plane. Packet forwarding verification and exception localization are recognized as effective and promising methods, enabling reliable packet delivery in the data plane and allowing the controller in SDN to identify abnormal links. While existing mechanisms embed the linear-scale cryptographic tags into the packet header space as the transmission path lengthens to realize packet verification and exception localization, which cannot achieve a feasible tradeoff between efficiency and security. Leveraging the central controllability of SDN, we propose a lightweight packet forwarding verification mechanism. This mechanism splits the runtime of a flow into consecutive epochs by address hopping. The switches in the data plane forward packets based on hopping address, collecting the information of packets forwarded in a compact data structure, namely traffic sketch. The controller verifies traffic sketches and localizes exception in the epoch. We further prototype the proposed mechanism based on simulation network. The analysis and experiments demonstrate that the cost of proposed scheme is lower than the similar mechanisms, introducing no more than 9 % additional forwarding delay and less than 8 % throughput degradation.}
}


@article{DBLP:journals/compsec/RKAK24,
	author = {Uma Mageswari R and
                  N. Zafar Ali Khan and
                  M. M. Gowthul Alam and
                  S. Jerald Nirmal Kumar},
	title = {Addressing security challenges in industry 4.0: {AVA-MA} approach
                  for strengthening SDN-IoT network security},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103907},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103907},
	doi = {10.1016/J.COSE.2024.103907},
	timestamp = {Mon, 05 Aug 2024 21:42:42 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RKAK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the context of Industry 4.0, the convergence of the Internet of Things (IoT) and Software Defined Networking (SDN) represents a challenging yet pivotal avenue for bolstering network security. This amalgamation facilitates the establishment of an integrated SDN-IoT platform that adeptly confronts the security intricacies arising from the evolving landscape of interconnected devices and industrial networks. Through the strategic application of SDN, the network architecture undergoes dynamic segmentation, responsive to diverse parameters encompassing device attributes, application contexts, and security imperatives. This segmentation strategy effectively isolates IoT devices, constricting the potential attack surface and correspondingly diminishing the ramifications of security breaches. Therefore, this paper proposed a novel Adaptive Variational Autoencoder-based Modified Archery (AVA-MA) method to enhance the security of IoT devices. In this study, samples are collected and used from both the TON-IoT dataset and the SDN dataset to determine the effectiveness of the proposed AVA-MA method. The evaluation measures such as AUC, F1-score, recall, accuracy, and precision are used to evaluate the performance of the proposed AVA-MA method. The results depict the AVA-MA method attained an accuracy of 98.95 %, precision of 97.54 %, recall of 95.64 %, and F1-score of 98.86 % respectively.}
}


@article{DBLP:journals/compsec/YangQL24,
	author = {Tengfei Yang and
                  Yuansong Qiao and
                  Brian Lee},
	title = {Towards trustworthy cybersecurity operations using Bayesian Deep Learning
                  to improve uncertainty quantification of anomaly detection},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103909},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103909},
	doi = {10.1016/J.COSE.2024.103909},
	timestamp = {Sun, 06 Oct 2024 21:22:23 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YangQL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Uncertainty quantification of cybersecurity anomaly detection results provides critical guidance for decision makers on whether or not to accept the results. Improving the trustworthiness of anomaly predictions can reduce the amount of alert false positives that security teams have to process. In this work we investigate the use of Bayesian Autoencoder (BAE) models for uncertainty quantification in anomaly detection. A novel heteroscedastic aleatoric uncertainty modelling method is explored that jointly considers aleatoric and epistemic uncertainty. Heteroscedastic aleatoric uncertainty is modelled on the latent layer of the BAE and further explored through considering the variational lower bound. An uncertainty quantification framework for cybersecurity is designed and verified on UNSW-NB15 and CIC-IDS-2017 data sets. This research enhances the modelling of uncertainty in the BAE model and expands its application in cybersecurity.}
}


@article{DBLP:journals/compsec/ZhaoW24,
	author = {Yongxin Zhao and
                  Chundong Wang},
	title = {Protecting privacy and enhancing utility: {A} novel approach for personalized
                  trajectory data publishing using noisy prefix tree},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103922},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103922},
	doi = {10.1016/J.COSE.2024.103922},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhaoW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the widespread adoption of location-based software has significantly improved people’s daily lives. However, this convenience has brought about an increasingly severe concern: the risk of data privacy breaches. To tackle this issue, a novel scheme for personalized trajectory data publishing is proposed, leveraging a noisy prefix tree structure. The scheme begins by constructing multiple trajectory equivalence classes based on the spatiotemporal characteristics of trajectories, followed by the calculation of distinct Hilbert curve orders for each equivalence class. Subsequently, the Hilbert curve is employed to partition the location points within each equivalence class, with the aid of a scoring function that selects optimal center points to replace other location points effectively. Additionally, appropriate encoding levels are determined for each partitioned region, facilitating the conversion of the center points into binary encoded characters using Hilbert-Geohash. This conversion process safeguards against data privacy leakage by obfuscating the original latitude and longitude coordinates. Ultimately, a noisy prefix tree is constructed to store the binary encoding in its nodes. To ensure data privacy preservation, a novel privacy budget allocation approach is introduced, applying suitable Laplace noise to each node. The effectiveness of the proposed algorithm is confirmed through experimental comparisons with existing schemes, employing real datasets and demonstrating its notable performance in terms of both data privacy and utility.}
}


@article{DBLP:journals/compsec/ZhouCJZCJZDSH24,
	author = {Qihang Zhou and
                  Wenzhuo Cao and
                  Xiaoqi Jia and
                  Shengzhi Zhang and
                  Jiayun Chen and
                  Nan Jiang and
                  Weijuan Zhang and
                  Haichao Du and
                  Zhenyu Song and
                  Qingjia Huang},
	title = {HClave: An isolated execution environment design for hypervisor runtime
                  security},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103923},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103923},
	doi = {10.1016/J.COSE.2024.103923},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhouCJZCJZDSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtualization is the cornerstone of cloud computing, but the hypervisor, the crucial software component that enables virtualization, is known to suffer from various attacks. It is challenging to secure the hypervisor due to at least two reasons. On one hand, commercial hypervisors are usually integrated into a privileged Operating System (OS), which brings in a larger attack surface. On the other hand, multiple Virtual Machines (VM) share a single hypervisor, thus a malicious VM could leverage the hypervisor as a bridge to launch “cross-VM” attacks. In this work, we propose HClave, an isolated execution environment (IEE) design for hypervisor runtime. We decouple the virtualization layer into a tiny trusted computing base (TCB), a large non-secure OS, and multiple HClave IEEs through a bidirectional isolation approach. HClave extends the nested kernel approach to deprive the traditional OS from accessing the tiny TCB’s memory and creates an IEE for hypervisor runtime. We implemented HClave based on KVM and evaluated its effectiveness and efficiency through case studies. Experimental results show that HClave can significantly improve the security of the hypervisor with reasonable runtime overhead.}
}


@article{DBLP:journals/compsec/RoseAAM24,
	author = {Luca De Rose and
                  Giuseppina Andresini and
                  Annalisa Appice and
                  Donato Malerba},
	title = {{VINCENT:} Cyber-threat detection through vision transformers and
                  knowledge distillation},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103926},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103926},
	doi = {10.1016/J.COSE.2024.103926},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RoseAAM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vision Transformers (ViTs) denote a family of attention-based deep learning techniques that have recently achieved amazing results in various problems related to the field of computer vision. In this paper, we explore the use of ViTs in problems of cyber-threat detection related to malware and network intrusion detection. In particular, we propose VINCENT, that is a novel deep neural method, which resorts to a color imagery representation of cyber-data by encoding related cyber-data features into neighboring color pixels. ViTs are trained from cyber-data images as teacher models, to extract explainable imagery signatures of cyber-data classes. This knowledge is extracted by leveraging the self-attention mechanism to give paired attention values between pairs of imagery patches. The signature knowledge, extracted through the ViT teacher, is, finally, used to train a smaller neural student model according to the knowledge distillation theory. Experiments with various benchmark cybersecurity datasets assess the accuracy of the student model VINCENT also compared to that of several state-of-the-art methods. In addition, it shows that VINCENT can obtain insights from explanations recovered through the self-attention mechanism of the ViT teacher.}
}


@article{DBLP:journals/compsec/AlEiadehA24,
	author = {Mohammad Ryiad Al{-}Eiadeh and
                  Mustafa Abdallah},
	title = {GeniGraph: {A} genetic-based novel security defense resource allocation
                  method for interdependent systems modeled by attack graphs},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103927},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103927},
	doi = {10.1016/J.COSE.2024.103927},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AlEiadehA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We design a resource allocation framework for securing interdependent systems managed by multiple defenders. Our framework models these multi-defender interdependent systems with the notion of attack graphs. We propose three defense scenarios that are derived from the top attack paths that defenders predict, based on their system knowledge, which attackers may consider to launch their attacks. Furthermore, we propose a defense method with low sensitivity to the number of concurrent attacks, based on a graph-theoretical notion known as the Markov random field (MRF). We elucidate the advantages gained from our decision-making framework through comprehensive evaluation experiments on fourteen attack graphs (that includes multiple real-world interdependent systems). In our evaluation, we compare different defense scenarios and provide information about the most effective resource allocation approach against each attack scenario. In particular, we quantify the level of security improvement under our defense methods compared to three well-known resource allocation algorithms. Our experimental results show that our framework surpasses these resource allocation algorithms. In particular, our proposed defense leads to an average relative reduction in the expected security cost of 72% under equal initial investments on all edges. Moreover, it leads to an average relative reduction in the expected security cost of 78% under random initial investments on all edges. Under high security budget, our proposed defense approach has a relative reduction above 94% for 10 of the 14 attack graphs. These results signify notable enhancements in security resource allocation which contributes to improved security decision-making.}
}


@article{DBLP:journals/compsec/HoreGSB24,
	author = {Soumyadeep Hore and
                  Jalal Ghadermazi and
                  Ankit Shah and
                  Nathaniel D. Bastian},
	title = {A sequential deep learning framework for a robust and resilient network
                  intrusion detection system},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103928},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103928},
	doi = {10.1016/J.COSE.2024.103928},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HoreGSB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ensuring the security and integrity of computer and network systems is of utmost importance in today’s digital landscape. Network intrusion detection systems (NIDS) play a critical role in continuously monitoring network traffic and identifying unauthorized or potentially malicious activities that could compromise the confidentiality, availability, and integrity of these systems. However, traditional NIDS face a daunting challenge in effectively adapting to the evolving tactics of cyber attackers. To address this challenge, we propose a multistage artificial intelligence enabled framework for intrusion detection in network traffic, capable of handling zero-day, out-of-distribution, and adversarial evasion attacks. Our framework comprises three sequential deep neural network (DNN) architectures: one for the classifier and two for specific autoencoders, designed to effectively detect both known attack patterns and novel, previously unseen samples. We introduce an innovative transfer learning technique where specific combinations of neurons and layers in the DNN architectures are frozen during one-shot learning to enhance the framework’s robustness to novel attacks. To validate the effectiveness of our framework, we conducted extensive experimentation using publicly available benchmark intrusion detection data sets. Leveraging the one-shot learning approach in the transfer learning component of the framework, we demonstrate continuous improvement in detection accuracy for both known and novel network traffic patterns. The results demonstrate the effectiveness of the multiple stages in the framework by achieving, on average, 98.5% accuracy in detecting various attacks.}
}


@article{DBLP:journals/compsec/MonkamLB24,
	author = {Galamo Monkam and
                  Michael J. De Lucia and
                  Nathaniel D. Bastian},
	title = {A topological data analysis approach for detecting data poisoning
                  attacks against machine learning based network intrusion detection
                  systems},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103929},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103929},
	doi = {10.1016/J.COSE.2024.103929},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MonkamLB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data poisoning attacks pose a significant security risk to network security software that utilizes machine learning (ML) for network intrusion detection. As network traffic continues to surge, ML becomes indispensable in detecting and characterizing malicious actors attempting to infiltrate computer networks. However, conventional ML assumes a benign environment, leaving room for adversaries to violate this assumption during the training phase. Detecting data poisoning attacks proves to be a challenging task, as attackers employ subtle alterations in the training data to create backdoors, trojans or triggers. Traditional techniques for addressing data poisoning attacks often focus only on enhancing ML model robustness rather than detecting poisoned data, necessitating the development of novel, more effective approaches. Hence, there is an urgent need to develop new methods for identifying poisoned data, ensuring the security of ML. We introduce a novel approach that harnesses the power of topological data analysis and unsupervised learning, enabling the early identification of poisoned data before training an ML model for network intrusion detection. Leveraging our approach, the extraction of topological features and subsequent application of clustering techniques leads to the creation of new clusters exclusively composed of poisoned data for removal prior to ML model training.}
}


@article{DBLP:journals/compsec/ZhengSWT24,
	author = {Weining Zheng and
                  Xiaohong Su and
                  Hongwei Wei and
                  Wenxin Tao},
	title = {SVulDetector: Vulnerability detection based on similarity using tree-based
                  attention and weighted graph embedding mechanisms},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103930},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103930},
	doi = {10.1016/J.COSE.2024.103930},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhengSWT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vulnerability detection by comparing similarities with known vulnerable code is an important method for improving code security, and is particularly effective in detecting vulnerabilities caused by code reuse. However, vulnerability detection is made difficult by the existence of some different and vulnerability-unrelated statements between codes with the same vulnerability pattern, as well as the small differences between vulnerable and fixed non-vulnerable codes. To address these challenges, we believe that more attention needs to be paid to some core syntactic and semantic information about vulnerabilities, which can help models more accurately identify vulnerable code. Hence, we propose a novel code-similarity-based vulnerability detection approach named SVulDetector. First, it contains a code representation, called Slice Composite Graphs (SCGs), which can represent rich syntactic and semantic information related to vulnerable statements while minimizing the interference from similar vulnerability irrelevant information as much as possible. Next, a tree-based attention mechanism is used to highlight certain key syntactic information in vulnerable code and fixed non-vulnerable code. Finally, SVulDetector highlights key vulnerable node information in the graph-based code representation via a weighted graph embedding mechanism. We extensively evaluated SVulDetector on an improved real-world dataset using both two-class and multi-class vulnerability detection tasks, and the proposed SVulDetector outperforms existing state-of-the-art detection methods.}
}


@article{DBLP:journals/compsec/TaoLKSYYZ24,
	author = {Yunting Tao and
                  Yuqun Li and
                  Fanyu Kong and
                  Yuliang Shi and
                  Ming Yang and
                  Jia Yu and
                  Hanlin Zhang},
	title = {Privacy-preserving outsourcing scheme of face recognition based on
                  locally linear embedding},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103931},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103931},
	doi = {10.1016/J.COSE.2024.103931},
	timestamp = {Sat, 31 Aug 2024 20:43:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/TaoLKSYYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face recognition is a biometric-based technology that identifies or verifies a person’s identity by analyzing and comparing patterns in their facial features. Among kinds of face recognition algorithms, Locally Linear Embedding (LLE) algorithm has the advantage of preserving the local structure of face data. However, the LLE algorithm requires some computationally intensive matrix calculations, which might introduce latency to the device. In this paper, we propose a privacy-preserving outsourcing scheme of face recognition based on LLE algorithm for the first time. By outsourcing matrix multiplication, linear equations, and eigenvalue decomposition of the LLE algorithm to a cloud server, we reduce the computational load on the client device. To ensure data security, we generate a novel type of sparse orthogonal matrix through square root application and random permutation of diagonal elements, used as secret keys to blind the client’s data. Meanwhile, due to the sparsity of key matrices, the complexity of client-side computation complexity is reduced from\nO\n(\nn\n3\n)\nto\nO\n(\nn\n2\n)\n. The experimental results show that our proposed scheme reduces computational costs while maintaining almost identical face recognition accuracy as the original LLE-based algorithm.}
}


@article{DBLP:journals/compsec/YuSZ24,
	author = {Jingze Yu and
                  Wenting Shen and
                  Xi Zhang},
	title = {Cloud storage auditing and data sharing with data deduplication and
                  private information protection for cloud-based {EMR}},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103932},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103932},
	doi = {10.1016/J.COSE.2024.103932},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YuSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the cloud-based electronic medical records (EMRs) system, the doctors upload EMRs to the cloud for storage and sharing. However, the integrity of EMRs stored in the cloud cannot be guaranteed and sharing EMRs may leak the patients’ private information. Furthermore, shared EMRs contain a lot of duplicate data, leading to data redundancy. To solve the above issues, we propose a cloud storage auditing and data sharing scheme with data deduplication and private information protection for cloud-based EMR. In our proposed scheme, we introduce the sanitizer to sanitize the data blocks containing the private information in EMR, and transform these blocks’ authenticators into the authenticators of sanitized EMR. The authenticators are utilized to check the data integrity. Using the above method, the EMR stored in the cloud can be shared with researchers while ensuring the privacy of private information and the integrity of EMR. In addition, our scheme can achieve block-level deduplication, in which only one copy of the deduplicated blocks in EMR needs to be stored. The conducted security analysis and performance evaluation affirm the security and efficiency of the proposed scheme.}
}


@article{DBLP:journals/compsec/DingMZ24,
	author = {Hongli Ding and
                  Zhao Ma and
                  Jing Zhu},
	title = {Local graph smoothing for link prediction against universal attack},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103935},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103935},
	doi = {10.1016/J.COSE.2024.103935},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/DingMZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Link prediction, a crucial research topic in complex network studies, involves estimating the likelihood of links between two nodes based on known network information. This area has garnered widespread attention due to its theoretical significance and practical applications. However, existing unsupervised graph link prediction models face challenges in handling complex graph data due to their sensitivity to noise, irregularities, and varying connectivity. They frequently encounter difficulties in capturing nuanced relationships within graph structures particularly in the face of adversarial attacks. To overcome these challenges, we propose a novel approach called Local Graph Smoothing based on GNN (LGS-GNN). The main contributions of this paper include the introduction of the LGS-GNN algorithm, a GNN-based local graph smoothing method, applied to downstream tasks such as link prediction. The paper also implements and discusses universal attack strategy on the original graph data, evaluates the feasibility of the framework through theoretical discussions. Additionally, the robustness of the GNN-based LGS model is evaluated using adversarial attack methods. Experimental results demonstrate the effectiveness of the proposed approach against imperceptible perturbations, highlighting its potential for enhancing the stability and reliability of unsupervised graph link prediction models in real-world scenarios.}
}


@article{DBLP:journals/compsec/LiWYG24,
	author = {Xuan Li and
                  Naiyu Wang and
                  Shuai Yuan and
                  Zhitao Guan},
	title = {FedIMP: Parameter Importance-based Model Poisoning attack against
                  Federated learning system},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103936},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103936},
	doi = {10.1016/J.COSE.2024.103936},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiWYG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In federated learning systems, the participants collaboratively train a joint model without sharing their raw data. However, these systems are susceptible to poisoning attacks, due to the difficulty in supervising local training processes. Most existing model poisoning attacks target all parameters, resulting in significant model modifications that can be easily detected by checking statistical similarity. We therefore propose FedIMP, an innovative untargeted model poisoning attack method that introduces the concept of parameter importance to enhance stealthiness and effectiveness. We first assess the parameter importance using the Fisher information to selectively poison only those with high importance. Furthermore, we formulate an optimization problem to derive the optimal malicious boosting coefficient such that the attack can evade defense mechanisms while enhancing attack's impact. The experimental results validate the effectiveness of FedIMP, demonstrating its ability to deteriorate model performance and slow down convergence across various aggregation algorithms. Our approach highlights the critical vulnerability in federated learning systems and provides insights for developing more robust defense strategies against poisoning attacks.}
}


@article{DBLP:journals/compsec/ZankeWDE24,
	author = {Anna Zanke and
                  Thorsten Weber and
                  Peter Dornheim and
                  Mathias Engel},
	title = {Assessing information security culture: {A} mixed-methods approach
                  to navigating challenges in international corporate {IT} departments},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103938},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103938},
	doi = {10.1016/J.COSE.2024.103938},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZankeWDE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the digital era, fostering a strong information security culture in organizations, especially multinational IT departments, is essential to combat cyber threats. This study examines the effectiveness of a mixed-methods approach that combines quantitative surveys with qualitative insights from semi-structured interviews to assess information security culture comprehensively. Through a systematic literature review, the research identifies gaps and opportunities within the academic exploration of information security culture. Using semi-structured interviews with IT professionals from a multinational software company, the study complements an existing quantitative survey to delve deeper into six predefined dimensions of security culture. The qualitative data obtained from the interviews were analyzed using Mayring’s qualitative content analysis. The results provided nuanced insights into the organization’s security culture, with particular emphasis on aspects such as the accessibility of policies, the commitment of management, and the adequacy of training programs. Confirming the validity of the integrated approach, a comparative analysis of the qualitative findings with the survey data revealed no significant statistical differences in most dimensions. However, differences in certain areas highlighted the need for more transparent communication and specialized training initiatives. The study underscores the complexities involved in cultivating a resilient information security culture. It also demonstrates the value of a mixed-methods approach for a rigorous assessment. This study contributes to the academic discussion of information security culture and provides practical insights for organizations seeking to strengthen their security posture. It advocates further research into different organizational contexts and the cost-effectiveness of qualitative assessments.}
}


@article{DBLP:journals/compsec/Berg24,
	author = {Bibi van den Berg},
	title = {Dealing with uncertainty in cyberspace},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103939},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103939},
	doi = {10.1016/J.COSE.2024.103939},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/Berg24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While cyberspace as a globally interconnected network offers economic, social and informational potential, at the same time this space also produces a wide variety of risks, for which no easy solutions exist. For the international community, for nation states, for organizations and even for individuals, uncertainty is a common thread for interaction, communication and the general use of (systems connected to) cyberspace. This research shows that there are five different common reactions to dealing with this uncertainty in cyberspace: (1) using risk management to control uncertainty; (2) recovering from uncertainty through resilience; (3) influencing uncertainty with laws and regulation; (4) suspending uncertainty by engaging in trust; and (5) ignoring uncertainty through inaction. Some of these approaches are used more often than others. For instance, risk management is currently the dominant way of responding to uncertainty in cyberspace, with resilience gaining prominence. Other strategies, such as relying on trust or inaction, are less common. Oftentimes, using a mixture of strategies may be helpful, because some strategies may strengthen one another, for instance when a combination of risk management and resilience approaches is used. Each strategy has particular use for specific contexts, but since we lack an overview of which strategies are being used, we also cannot establish under which conditions which strategy is most beneficial. Solving this lack of knowledge can help us be more effective in dealing with uncertainties of a wide variety in cyberspace.}
}


@article{DBLP:journals/compsec/BaltuttisT24,
	author = {Dennik Baltuttis and
                  Timm Teubner},
	title = {Effects of visual risk indicators on phishing detection behavior:
                  An eye-tracking experiment},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103940},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103940},
	doi = {10.1016/J.COSE.2024.103940},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BaltuttisT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybersecurity vulnerability ranks among the foremost global business risks. Phishing attempts, in particular through email, persistently challenge organizations despite substantial investments in IT security and awareness training. Recognizing the limitations of unilateral technology- or human-centered approaches, this study explores how visual risk indication can support employees in detecting phishing attempts. To do so, we conducted an eye-tracking lab experiment in which participants rated the trustworthiness of emails with varying levels of credibility. Our analysis focuses on human information processing in identifying phishing attempts, indicating that the availability of a visual risk indicator can significantly influence trust and response behavior, without incapacitating implicit phishing cues (such as conspicuous senders or anonymous recipients). Our findings suggest that organizations should appropriately calibrate visual risk indicators to achieve the intended guiding effects. However, the calibration remains a trade-off and depends on the organization’s environment. We discuss implications for integrative cybersecurity approaches to mitigate phishing attempts more effectively.}
}


@article{DBLP:journals/compsec/NehmeLW24,
	author = {Alaa Nehme and
                  Meng (Leah) Li and
                  Merrill Warkentin},
	title = {Adaptive and maladaptive factors behind password manager use: {A}
                  hope-extended protection motivation perspective},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103941},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103941},
	doi = {10.1016/J.COSE.2024.103941},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NehmeLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robust password management is crucial for users’ information security. The use of password manager technology, which constitutes adaptive coping, is the dominant method for robust password management. Nonetheless, many users engage in maladaptive coping, adopting poor password management behaviors, such as using easy-to-remember passwords and using the same password across multiple accounts. Against this backdrop, this paper considers both adaptive and maladaptive coping factors for studying password manager use. As such, we incorporate the adaptive coping factor of password manager trustworthiness and the maladaptive coping factor of password mismanagement convenience into a research model that draws upon Hope-extended Protection Motivation Theory. We tested our model with a survey of US users. Our main findings indicate that password manager trustworthiness drives users’ appraised coping potential and that password mismanagement convenience has a context-specific (i.e., specific to the password manager use context) intricacy in how it reduces password manager use. Our theoretical contributions include expanding the range of Protection Motivation Theory's input sources, expanding the range of the studied context-specific factors in the password manager use context, and unveiling the uniqueness of the password manager context. This work also informs practice, especially with respect to how messages that aim to promote password manager use may be designed.}
}


@article{DBLP:journals/compsec/LingCL24,
	author = {Jie Ling and
                  Jinhui Chen and
                  Honglei Li},
	title = {{FDT:} Improving the transferability of adversarial examples with
                  frequency domain transformation},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103942},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103942},
	doi = {10.1016/J.COSE.2024.103942},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LingCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of Deep Neural Networks (DNNs) has facilitated profound advancements in computer vision. While DNNs demonstrate substantial capabilities, their susceptibility to adversarial attacks can introduce significant errors and hinder their applicability in real-world scenarios. The characteristic of black-box attacks is that they rely on the input–output mapping of the model without accessing its parameters or gradients. Due to the disparities between the substitute and target models, black-box attacks typically exhibit reduced success rates. To address the challenges outlined previously, we propose the Frequency Domain Transformation (FDT) method that employs the Discrete Cosine Transform (DCT) for transforming the input image into the frequency domain. It innovatively applies a grid mask to generate adversarial samples within the frequency domain. This transformation diminishes the spatial correlation among the image pixels and offers a fresh perspective for enhancing the transferability of adversarial examples. Experiments on adversarial attacks using the ImageNet dataset reveal that adversarial examples, when created through methods that transform data in the frequency domain, show enhanced transferability compared to those produced by transformations in the spatial domain. In attacks on six classification models using the single-model approach, FDT achieved an average success rate of 82.9%, corresponding to a 14.4% improvement over the spectrum simulation attack (SSA) method. For ensemble-model attacks with momentum-based techniques, the average success rate using the proposed strategy was 94.4%, corresponding to a 5.7% improvement over the SSA method.}
}


@article{DBLP:journals/compsec/BaoLCMWTLW24,
	author = {Huaifeng Bao and
                  Wenhao Li and
                  Huashan Chen and
                  Han Miao and
                  Qiang Wang and
                  Zixian Tang and
                  Feng Liu and
                  Wen Wang},
	title = {Stories behind decisions: Towards interpretable malware family classification
                  with hierarchical attention},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103943},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103943},
	doi = {10.1016/J.COSE.2024.103943},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BaoLCMWTLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware family classification is essential for understanding malware code and behavioral characteristics, significantly reducing analysis time and response time for emerging malware. However, existing malware family classification methods are limited for two reasons. (1) The feature representation learned from a single information source is not sufficiently discriminative for large-scale malware family classification. (2) The lack of interpretability of classification results makes it difficult to provide intuitive guidance for malware analysis. To tackle the issues, we propose MalAtt, a novel malware family classification method for interpretable and large-scale classification. Specifically, a unified feature engineering approach is proposed to obtain integrated embedding from heterogeneous static and dynamic information. Then, a hierarchical attention encoder module is employed to progressively extract semantic features from the static and dynamic embedding. A collaborative attention module is introduced to model the association between high-level static and dynamic features. Finally, MalAtt is pluggable for different classifiers, such as SVM and RF, to implement malware family classification. For evaluations, we carefully collected a dataset from 62 malware families containing over 20,070 in-the-wild samples. MalAtt is proved to be effective when classifying large-scale malware families, with an accuracy of 93.26%. Besides, the ablation study demonstrates the rationality of the proposed modules. Additionally, we provide a case study to show how MalAtt intuitively guides in-depth malware analysis by highlighting partial input features with high attention scores.}
}


@article{DBLP:journals/compsec/GoncalvesZ24,
	author = {Lu{\'{\i}}s Gon{\c{c}}alves and
                  Cleber Zanchettin},
	title = {Detecting abnormal logins by discovering anomalous links via graph
                  transformers},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103944},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103944},
	doi = {10.1016/J.COSE.2024.103944},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GoncalvesZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomalous authentications are a critical indicator of advanced persistent threats (APTs), in which adversaries exploit network vulnerabilities to gain unauthorized access and move stealthily between devices using stolen credentials. As the set of interactions between entities in a network essentially forms graph-structured data, state-of-the-art algorithms such as graph neural networks (GNNs) can be used to detect anomalous interactions that may indicate an ongoing attack. However, the success of detecting anomalous authentications using GNNs is conditioned on the representational power and performance of those models. A crucial problem is how to aggregate the node embeddings so that the GNN can better represent the network topology. Existing graph neural networks traditionally use simple functions (e.g., sum, max, mean) on the node embeddings to preserve permutation invariance and achieve consistent node representations. However, we argue that an effective aggregation of node features into a graph-level representation cannot be achieved through simple sum or mean operations. In this work, we propose a residual soft-attention scheme that facilitates the aggregation of node representations through a weighted sum, resulting in enhanced node representations and improved filtration of irrelevant information. Experimental results on three relevant datasets have shown the proposed method can detect abnormal authentications with lower false positives than competitors.}
}


@article{DBLP:journals/compsec/WangLZHY24,
	author = {Zhenduo Wang and
                  Saifei Li and
                  Lijie Zhang and
                  Chunduo Hu and
                  Lianshan Yan},
	title = {A Red Team automated testing modeling and online planning method for
                  post-penetration},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103945},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103945},
	doi = {10.1016/J.COSE.2024.103945},
	timestamp = {Mon, 05 Aug 2024 21:42:42 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangLZHY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Post-penetration red team automation testing effectively addresses the pain points of traditional manual red teams, including manpower, time costs, and the high level of professional knowledge required, thereby improving the efficiency and effectiveness of red team penetration testing. However, introducing automation technology into the red team testing domain still faces numerous technical challenges. These challenges include accurately simulating real attack environments, coordinating complex attack actions, and effectively resolving uncertainties during the attack process. These challenges remain critical issues that require urgent solutions. In this context, we propose a post-penetration-oriented automated red team penetration test modeling and planning approach. The objective of this approach is to automatically generate attack paths, coordinate attack behaviors, and adjust attack behaviors based on feedback, enabling attacks on real target networks through corresponding operations. We conducted analysis and performance testing on our solution, comparing it with other available planners. Our experimental results demonstrate the effectiveness of the proposed planner in achieving automated penetration testing. Compared to other available planners, ours can generate valid attack paths more quickly and exhibits excellent performance in planning effectiveness and quality. Furthermore, our planner possesses wide applicability across various penetration testing scenarios.}
}


@article{DBLP:journals/compsec/LiCZLCM24,
	author = {Chao Li and
                  Jian Chen and
                  Zhaoxin Zhang and
                  Zhiping Li and
                  Yanan Cheng and
                  Chendi Ma},
	title = {{DNS} root server resolution anomaly detection},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103946},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103946},
	doi = {10.1016/J.COSE.2024.103946},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiCZLCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The DNS root server is at the top of the hierarchical structure of the DNS system and is the initial node that bootstraps all DNS queries. If the root server resolves abnormally, all domain name resolutions will fail, and many users cannot access the Internet. For this reason, this paper detects the root server itself resolution anomalies and non-self resolution anomalies by constructing high-confidence root zone file and anomaly judgment rules. First, we use the weighted voting statistics method to build high-confidence root zone file by calculating the confidence of multi-source root zone files. Based on high-confidence root zone files, we construct three types of anomaly detection judgment rules: (1) root-side resolution anomaly judgment rules based on feature value matching, (2) response hijacking judgment rules by correlating response anomaly features and resolution routing information, (3) root zone file synchronization anomaly judgment rules by calculating the relative synchronization delay of multi-source root zone files. Finally, using three anomaly judgment rules, we perform anomaly detection on the root resolution data obtained by active measurement. Our detection results show that root zone file synchronization delay distributions of different root server instances vary greatly. Some instances even show minute-level convergence, resulting in incorrect resolution for some TLDs. We also detect one response hijacking incident for 2 TLDs resolution, caused by the domain takeover mechanism adopted by the ISP to reduce inter-domain traffic settlement and decrease resolution latency. Except for the unresponsive exception caused by network packet loss, no root-side resolution anomaly is found, indicating that there is no artificial manipulation of TLD resolution on the root server and reflecting the responsibility of each root server operator aiming to maintain global Internet interconnection. The detection results show that the detection rules proposed in this paper can effectively achieve the anomaly detection of root server resolution and help to maintain the health and stability of the DNS system.}
}


@article{DBLP:journals/compsec/XuWJFFX24,
	author = {Haoran Xu and
                  Yongjun Wang and
                  Zhiyuan Jiang and
                  Shuhui Fan and
                  Shaojing Fu and
                  Peidai Xie},
	title = {Fuzzing JavaScript engines with a syntax-aware neural program model},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103947},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103947},
	doi = {10.1016/J.COSE.2024.103947},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XuWJFFX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Neural network language modeling has become a remarkable approach in the generation of test cases for fuzzing JavaScript engines. Fuzzers built upon neural language models offer several advantages. They obviate the need for manually developing code generation rules, enable the extraction of patterns from high-quality seed sets, and exhibit commendable portability. Nevertheless, existing works confront challenges in three key aspects: diminished language modeling performance attributable to extensive vocabularies, potential semantic errors within generated test cases, and the limitation of black-box fuzzing, which fails to leverage the internal feedback from the target engine.}
}


@article{DBLP:journals/compsec/ZuoLL24,
	author = {Chu{-}Xiao Zuo and
                  Jia{-}Yi Leng and
                  Wu{-}Jun Li},
	title = {{SUETA:} Speaker-specific utterance ensemble based transfer attack
                  on speaker identification system},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103948},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103948},
	doi = {10.1016/J.COSE.2024.103948},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZuoLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread application of speaker identification (SI) systems in security-related tasks, the robustness of SI systems against adversarial examples has garnered increasing attention. Existing works have demonstrated the vulnerability of SI systems to transfer-based black-box attacks, wherein attackers generate adversarial examples with a surrogate model and then transfer them to attack the target system. However, the attack success rate (ASR) of transfer-based black-box attacks is limited by the transferability of adversarial examples. As far as we know, few works have investigated enhancing the transferability of adversarial examples for speech utterances to attack SI systems. Furthermore, existing works only utilize a single utterance in the attack process, but in practical situations, an attacker can usually collect multiple utterances of a speaker. In this paper, we propose a novel transfer-based black-box attack method, called speaker-specific utterance ensemble based transfer attack (SUETA), to attack SI systems. To the best of our knowledge, SUETA is the first transfer-based black-box attack method that utilizes multiple utterances instead of a single one. Furthermore, we also propose an improved variant of SUETA, called SUETA+, by sharing gradients of utterances at the speaker-embedding level. Empirical results show that both SUETA and SUETA+ improve the ASR compared to the baselines under the classical cross-model situation. SUETA+ further shows additional improvement over SUETA, especially in the case of the untargeted attack. SUETA+ also outperforms the baselines in cross-dataset and cross-preprocessor situations, although the ASR for all transfer-based attacks decreases compared to that in the cross-model situation. Moreover, SUETA+ can significantly improve the ASR against commercial APIs (iFlytek and TalentedSoft) and the voice assistant (Tmall Genie) for the untargeted attack compared to the baselines.}
}


@article{DBLP:journals/compsec/ZhangSL24,
	author = {Huijie Zhang and
                  Weizhen Sun and
                  Ling Lv},
	title = {A frequency-injection backdoor attack against DNN-Based finger vein
                  verification},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103956},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103956},
	doi = {10.1016/J.COSE.2024.103956},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research has demonstrated that deep neural networks, typically used in finger vein recognition, are susceptible to different types of attacks, such as adversarial attacks, data poisoning attacks, and backdoor attacks. Among the attacks, backdoor attacks occur in almost every stage of the deep learning pipeline. Finger vein recognition has extensively been used in real-world applications for personal identity authentication. To develop a secure finger vein recognition system, one must study possible backdoor attacks, which can embed hidden malicious behaviors into the system. Existing backdoor attacks are as easily perceptible as conspicuous spatial triggers and difficult-to-resist data augmentation. To address this issue, we propose a novel frequency-injection-based backdoor attack method capable of delivering attacks in finger vein recognition. Specifically, images are transformed from the spatial domain to the frequency domain by discrete wavelet transform (DWT), and the trigger injects several times in the high-frequency part in the vertical direction. Experimental results of public finger vein datasets validate the proposed method's effectiveness, showing good attack performance and bypassing backdoor defense.}
}


@article{DBLP:journals/compsec/BrownBZS24,
	author = {Dennis Brown and
                  Gunjan Batra and
                  Humayun Zafar and
                  Khawaja Saeed},
	title = {Reducing fraud in organizations through information security policy
                  compliance: An information security controls perspective},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103958},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103958},
	doi = {10.1016/J.COSE.2024.103958},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/BrownBZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As more business processes and information assets are digitized, computer resources are increasingly being misused to perpetrate fraudulent activities. Research shows that fraud committed by (or with) trusted insiders (called occupational fraud or internal organizational fraud) is responsible for significantly more damage than that committed by external actors (for example, cyber fraud). Current fraud research has primarily focused on the person perpetuating the fraud instead of the internal mechanisms organizations can employ in reducing fraud. The study examines the relationship between compliance with organizations' technology controls (primarily focused on information security) and its impact on computer-based occupational fraud. Based on general deterrence and fraud triangle theories, the study proposes information security control proficiency (ISCP) modeled as an integration of the quality of information security policy and its enforcement as a key factor that influences information security policy compliance. We further postulate that compliance with information security policy mediates the relationship between information security control proficiency and computer-based-occupational fraud. Empirical assessment supports the structure of the information security control proficiency construct. Model testing shows that information security control proficiency positively impacts information security policy compliance, which further deters the use of a company's computer systems and resources to conduct fraudulent activities. Thus, if an organization establishes high-quality information security policies and supports the policies with effective enforcement, it correspondingly leads to better compliance. Furthermore, less fraud is committed when compliance with information security controls is high. We offer various managerial implications and future research extension ideas.}
}


@article{DBLP:journals/compsec/WangYPWH24,
	author = {Xiaoyan Wang and
                  Jingjing Yang and
                  Zixiao Peng and
                  Shunfang Wang and
                  Ming Huang},
	title = {Hilbert signal envelope-based multi-features methods for {GNSS} spoofing
                  detection},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103959},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103959},
	doi = {10.1016/J.COSE.2024.103959},
	timestamp = {Sun, 20 Oct 2024 22:28:29 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangYPWH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Global Navigation Satellite System (GNSS) provides precise Positioning, Navigation, and Timing (PNT) service for various industries such as military and national economy. However, civil GNSS is fragile and vulnerable to spoofing for the weak signal strength and the open architecture. To address the problem of limited performance of existing detection methods due to the strong concealment of spoofing, this paper proposes a novel scheme using Hilbert Signal Envelope-based multi-features. Firstly, multi-features are picked and calculated from the receiving signal, especially we propose a Tweaked Signal Quality Monitoring (TSQM) metric in this step. Secondly, an algorithm for extracting Hilbert Signal Envelope (HSE) is proposed for enhancing the features, which reduces features redundancy and pushes clean and spoofing samples away from each other. Thirdly, the enhanced features are sent to train and test the Machine Learning (ML) models. Finally, experimental validation is conducted on the Texas Spoofing Test Battery (TEXBAT) dataset and measurement data collected by low-cost Software-Defined Radio (SDR). The Area Under Curve (AUC) of the proposed method improves by 5.34 % and 3.07 % (reaching 97.34 % and 98.44 %) compared to the latest multi-parameters method on TEXBAT and measurement data, respectively, which provides an effective scheme for spoofing detection.}
}


@article{DBLP:journals/compsec/XiaoLWC24,
	author = {Nan Xiao and
                  Bo Lang and
                  Ting Wang and
                  Yikai Chen},
	title = {{APT-MMF:} An advanced persistent threat actor attribution method
                  based on multimodal and multilevel feature fusion},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103960},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103960},
	doi = {10.1016/J.COSE.2024.103960},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XiaoLWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Threat actor attribution is a crucial defense strategy for combating advanced persistent threats (APTs). Cyber threat intelligence (CTI), which involves analyzing multisource heterogeneous data from APTs, plays an important role in APT actor attribution. The current attribution methods extract features from different CTI perspectives and employ machine learning models to classify CTI reports according to their threat actors. However, these methods usually extract only one kind of feature and ignore heterogeneous information, especially the attributes and relations of indicators of compromise (IOCs), which form the core of CTI. To address these problems, we propose an APT actor attribution method based on multimodal and multilevel feature fusion (APT-MMF). First, we leverage a heterogeneous attributed graph to characterize APT reports and their IOC information. Then, we extract and fuse multimodal features, including attribute type features, natural language text features and topological relationship features, to construct comprehensive node representations. Furthermore, we design multilevel heterogeneous graph attention networks to learn the deep hidden features of APT report nodes; these networks integrate IOC type-level, metapath-based neighbor node-level, and metapath semantic-level attention. Utilizing multisource threat intelligence, we construct a heterogeneous attributed graph dataset and various variant datasets for verification purposes. Extensive experimental results show that our method not only outperforms the existing methods, but also demonstrates its considerable robustness to incomplete and noise information and good explainability for attribution analysis tasks.}
}


@article{DBLP:journals/compsec/TuLYJG24,
	author = {Fei{-}Fan Tu and
                  Dongjie Liu and
                  Zhiwei Yan and
                  Xiao{-}Bo Jin and
                  Guang{-}Gang Geng},
	title = {{STFT-TCAN:} {A} TCN-attention based multivariate time series anomaly
                  detection architecture with time-frequency analysis for cyber-industrial
                  systems},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103961},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103961},
	doi = {10.1016/J.COSE.2024.103961},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/TuLYJG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Networks and industrial systems play a pivotal role in modern society, and their security has garnered increasing attention. Anomalies within industrial equipment may propagate through fault transmission, leading to a cascade of failures. Additionally, cyberattacks on equipment can result in significant losses. Therefore, in the realm of industrial and cyberspace domains, an effective multivariate time series anomaly detection system for monitoring equipment is instrumental in ensuring the healthy operation of the machinery. Nevertheless, detecting anomalies in numerous time series remains challenging, stemming from the absence of anomaly labels and the complexity of the data patterns. Existing algorithms predominantly concentrate on modeling within the time domain, falling short in fully leveraging the informative features present in frequency domain data, resulting in diminished detection performance. This paper introduces STFT-TCAN, a model for anomaly detection in time series that seamlessly integrates information from both time and frequency domains for extracting data features. Sliding windows and the Short Time Fourier Transform (STFT) are utilized to construct a frequency matrix, effectively amalgamating the characteristics of both time and frequency domains within the time series. Furthermore, the model employs Temporal Convolutional Networks (TCN) and Transformer attention mechanisms (which combined to form the TCAN module) to capture the features of multivariate time series, thereby resulting in heightened detection accuracy. The proposed model undergoes validation on six publicly available datasets, showcasing the superior performance of the STFT-TCAN model in comparison to current baseline methods. It adeptly extracts features from both frequency and time domains in sequential data, thereby achieving state-of-the-art performance in tasks related to anomaly detection in multivariate time series.}
}


@article{DBLP:journals/compsec/AnleyGAP24,
	author = {Mulualem Bitew Anley and
                  Angelo Genovese and
                  Davide Agostinello and
                  Vincenzo Piuri},
	title = {Robust DDoS attack detection with adaptive transfer learning},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103962},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103962},
	doi = {10.1016/J.COSE.2024.103962},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AnleyGAP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the evolving cybersecurity landscape, the rising frequency of Distributed Denial of Service (DDoS) attacks requires robust defense mechanisms to safeguard network infrastructure availability and integrity. Deep Learning (DL) models have emerged as a promising approach for DDoS attack detection and mitigation due to their capability of automatically learning feature representations and distinguishing complex patterns within network traffic data. However, the effectiveness of DL models in protecting against evolving attacks depends also on the design of adaptive architectures, through the combination of appropriate models, quality data, and thorough hyperparameter optimizations, which are scarcely performed in the literature. Also, within adaptive architectures for DDoS detection, no method has yet addressed how to transfer knowledge between different datasets to improve classification accuracy. In this paper, we propose an innovative approach for DDoS detection by leveraging Convolutional Neural Networks (CNN), adaptive architectures, and transfer learning techniques. Experimental results on publicly available datasets show that the proposed adaptive transfer learning method effectively identifies benign and malicious activities and specific attack categories.}
}


@article{DBLP:journals/compsec/ShafeiGT24,
	author = {Hassan A. Shafei and
                  Hongchang Gao and
                  Chiu C. Tan},
	title = {Measuring privacy policy compliance in the Alexa ecosystem: In-depth
                  analysis},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103963},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103963},
	doi = {10.1016/J.COSE.2024.103963},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ShafeiGT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual Personal Assistant (VPA) services such as Amazon Alexa are quickly and seamlessly integrating into people’s daily lives. The Alexa ecosystem allows third-party developers to build new skills and publish them to the skill market. These skills can be either standalone skills, operating independently without external linking, or skills with account linking, necessitating the user connect to external services to access the skill’s functionality. Skill developers are required to provide privacy policies to disclose their skills’ data practices. The popularity of these skills raises privacy concerns in data handling practices. Privacy policy documents play an important role in addressing users’ privacy concerns and informing them about the data practices. These documents are complex for users to comprehend, and skill developers may intentionally or unintentionally fail to comply. Previous investigations have predominantly focused on scrutinizing the privacy policies of standalone skills, overlooking those associated with companion services and developers with multiple skills. This study aims to bridge this gap by examining the privacy policies of both the skills and their companion services, along with multiple skills published by the same developer, to explore potential differences in data practices. We conduct the first study on the Alexa ecosystem for skills with account linking, where we compare the policy of the skills and their companion services. We automatically extract the data types from both privacy policies for comparison using a machine learning technique. Mismatches between skill and companion service privacy practices were unveiled, with 975 instances of data type collection mismatches between skills and their companion services, along with 692 instances of data type sharing mismatches. We uncover differences in privacy practices among developers; 13 developers publish skills in different categories and three of them employ different privacy policies on their published skills. Among 35 developers who publish skills in the same category ten provide different privacy policies.}
}


@article{DBLP:journals/compsec/McIntoshSLWXLNH24,
	author = {Timothy R. McIntosh and
                  Teo Susnjak and
                  Tong Liu and
                  Paul A. Watters and
                  Dan Xu and
                  Dongwei Liu and
                  Raza Nowrozy and
                  Malka N. Halgamuge},
	title = {From {COBIT} to {ISO} 42001: Evaluating cybersecurity frameworks for
                  opportunities, risks, and regulatory compliance in commercializing
                  large language models},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103964},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103964},
	doi = {10.1016/J.COSE.2024.103964},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/McIntoshSLWXLNH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study investigated the integration readiness of four predominant cybersecurity Governance, Risk and Compliance (GRC) frameworks – NIST CSF 2.0, COBIT 2019, ISO 27001:2022, and the latest ISO 42001:2023 – for the opportunities, risks, and regulatory compliance when adopting Large Language Models (LLMs), using qualitative content analysis and expert validation. Our analysis, with both LLMs and human experts in the loop, uncovered potential for LLM integration together with inadequacies in LLM risk oversight of those frameworks. Comparative gap analysis has highlighted that the new ISO 42001:2023, specifically designed for Artificial Intelligence (AI) management systems, provided most comprehensive facilitation for LLM opportunities, whereas COBIT 2019 aligned most closely with the European Union AI Act. Nonetheless, our findings suggested that all evaluated frameworks would benefit from enhancements to more effectively and more comprehensively address the multifaceted risks associated with LLMs, indicating a critical and time-sensitive need for their continuous evolution. We propose integrating human-expert-in-the-loop validation processes as crucial for enhancing cybersecurity frameworks to support secure and compliant LLM integration, and discuss implications for the continuous evolution of cybersecurity GRC frameworks to support the secure integration of LLMs.}
}


@article{DBLP:journals/compsec/GlasMP24,
	author = {Magdalena Glas and
                  Gerhard Messmann and
                  G{\"{u}}nther Pernul},
	title = {Complex yet attainable? An interdisciplinary approach to designing
                  better cyber range exercises},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103965},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103965},
	doi = {10.1016/J.COSE.2024.103965},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GlasMP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The global shortage of cybersecurity professionals poses a daunting challenge for organizations seeking to protect their assets and data. To counteract this workforce shortage, cyber range exercises (CRXs) can equip individuals with the necessary knowledge and skills to become security professionals. However, the complexity of CRXs tends to overwhelm trainees with little prior cybersecurity experience, resulting in ineffective learning experiences. To address this issue, we take an interdisciplinary approach, leveraging established models on learning and motivation for cybersecurity. In this pursuit, we propose a literature-based framework of six design principles that aim to facilitate CRX designers in creating more effective CRXs. To illustrate the framework’s utility, we introduce a CRX for incident response built upon these principles. To evaluate the effectiveness of this principle-driven CRX design, we conducted a user study with\nN\n=\n89\nparticipants. The results of this study showed that the design provided an engaging learning experience that enabled participants to effectively acquire incident response knowledge and skills.}
}


@article{DBLP:journals/compsec/MaYW24,
	author = {Yukun Ma and
                  Chunlin Yu and
                  Chuliang Weng},
	title = {Morpheus: An efficient timing-based attestation framework for safeguarding
                  hypervisor integrity with dynamic trust},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103966},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103966},
	doi = {10.1016/J.COSE.2024.103966},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MaYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hypervisor, the core software in cloud computing, is susceptible to malicious intrusions, potentially jeopardizing overall platform security. Physical hosts within the cloud computing environment constantly face persistent attacks, and not all hosts are equipped with essential security hardware. The prolonged latency of previous software-based detection methods could not comprehensively address these cloud threats. Furthermore, the widespread deployment of security hardware incurs substantial costs for hardware-based detection. To address these challenges, we introduce Morpheus, an efficient framework ensuring hypervisor integrity in the current cloud. This framework rapidly employs software-based methods to detect malicious hosts, utilizing a subset of hosts equipped with security hardware as the Root of Trust. Efficiency is augmented through a Neural Network scheduling module, and an embedded exponential aging mechanism fortifies time-aging trust against consistent cloud threats. Evaluation results demonstrate that it can promptly identify threatened hosts with acceptable system overhead loss, solidifying its position as a robust cloud security solution.}
}


@article{DBLP:journals/compsec/JeongCHS24,
	author = {Hoyong Jeong and
                  Kiwon Chung and
                  Sung Ju Hwang and
                  Sooel Son},
	title = {Targeted Model Inversion: Distilling style encoded in predictions},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103967},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103967},
	doi = {10.1016/J.COSE.2024.103967},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/JeongCHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Previous model inversion (MI) research has demonstrated the feasibility of reconstructing images representative of specific classes, inadvertently revealing additional feature information. However, there are two remaining challenges for practical black-box MI: (1) minimizing the number of queries to the target model, and (2) reconstructing a high-quality input image tailored to an observed prediction vector. We introduce Targeted Model Inversion (TMI), a practical black-box MI attack. Our approach involves altering the mapping network in StyleGAN, which projects an observed prediction vector into a StyleGAN latent representation. Later, TMI leverages a surrogate model that is also derived from StyleGAN to guide instance-specific MI by optimizing the latent representation. These mapping and surrogate networks work together to conduct high-fidelity MI while significantly decreasing the number of necessary queries. Our experiments demonstrate that TMI outperforms state-of-the-art MI methods, demonstrating a new upper bound on the susceptibility to black-box MI attacks.}
}


@article{DBLP:journals/compsec/FrancisKPRA24,
	author = {Saneesh P. Francis and
                  Vysakh Kani Kolil and
                  Vipin Pavithran and
                  Indrakshi Ray and
                  Krishnashree Achuthan},
	title = {Exploring gender dynamics in cybersecurity education: {A} self-determination
                  theory and social cognitive theory perspective},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103968},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103968},
	doi = {10.1016/J.COSE.2024.103968},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/FrancisKPRA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cybersecurity industry is facing two major challenges as cyber threats get more serious: a shortage of skilled workers to defend against these attacks and a noticeable underrepresentation of women in the field, underscoring the critical need for diversity and skill development. This research explores variations in cybersecurity learning based on gender using the frameworks of self-determination and social cognitive theories. Conducted over two years, the research utilized a Capture The Flag (CTF) platform to facilitate learning and assess outcomes. This study explores the gender disparities in key areas such as intrinsic and extrinsic motivation, self-efficacy, conceptual grasp, and performance across five distinct cybersecurity subdomains: web exploitation, cryptography, cyber forensics, binary exploitation, and reverse engineering. The comprehensive evaluation included participant interaction with learning materials, their adeptness in practical exercises, and their achievements in a comprehensive contest covering five essential cross-domain cybersecurity concepts. Pre- and post-study surveys were instrumental in tracking shifts in motivation and self-efficacy levels. Findings pointed to notable gender-based differences in motivational aspects and self-belief following the learning phase, with conceptual understanding and the ability to replicate challenges also varying significantly between genders, highlighting disparities in educational outcomes. Domain-based analysis reveals notable gender differences: male participants excelled in solving reverse engineering and cryptography problems, whereas female participants performed better in cyber forensics and web exploitation challenges. These findings underscore the importance of tailored educational strategies in cybersecurity training to bridge the gender gap and foster a more diverse and capable workforce, addressing both the skill shortage and the need for broader representation in the field.}
}


@article{DBLP:journals/compsec/DuanLCSC24,
	author = {Guoyun Duan and
                  Haopeng Liu and
                  Minjie Cai and
                  Jianhua Sun and
                  Hao Chen},
	title = {MaDroid: {A} maliciousness-aware multifeatured dataset for detecting
                  android malware},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103969},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103969},
	doi = {10.1016/J.COSE.2024.103969},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/DuanLCSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {System call sequences representing the runtime behavior of an application is particularly useful for anomaly detection in mobile applications. However, one of the main obstacles in this area is the lack of publicly available high-quality datasets. Because of the low computational power and storage constraints of mobile application platforms, a single mobile device cannot accomplish the task of massively installing applications and extracting interaction details with the operating system, making it extremely challenging to build large-scale fine-grained system call datasets. In this paper, we present the MaDroid dataset. It is the first comprehensive dataset and benchmark for anomaly detection in mobile applications using high-dimensional feature sequence data and maliciousness, and the first to incorporate virus total rating (VT) values into dataset features. It is constructed based on an automated collection framework that collects system call sequences from simulation environments at a fine-grained level for both normal and malicious mobile applications. The dataset is 457 GB in size and consists of 50,429 labeled system call sequences. The dataset covers mobile applications released at different times over the past 14 years, and the selected applications span across 10 major mainstream APP markets. We extract different feature subsets from the dataset and perform evaluations using RF, MLP, and GBDT to show the effectiveness and accuracy in detecting malicious mobile APPs. Our dataset can be a useful resource for security and machine learning community.}
}


@article{DBLP:journals/compsec/SathiyaY24,
	author = {R. Sathiya and
                  N. Yuvaraj},
	title = {Swarm optimized differential evolution and probabilistic extreme learning
                  based intrusion detection in {MANET}},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103970},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103970},
	doi = {10.1016/J.COSE.2024.103970},
	timestamp = {Mon, 05 Aug 2024 21:42:42 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SathiyaY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {MANETs are an attracting mechanism foSr several applications, to name a few being rescue functioning, environmental surveillance and so on due to the reason that they allow users to communicate without the utilization of persistent framework. This pliability, although creates additional security proneness. As a consequence of its advantages and growing insistence, MANETs have fascinated a lot of attentiveness from the scientific research community. In spite of that, exposed or unprotected to be more susceptible to several attacks that perpetrate destruction on their performance than any network. Conventional cryptography mechanisms cannot completely safeguard MANETs in terms of susceptibility owing to dispersed nature however these issues can be addressed by using optimization and deep learning techniques-based Intrusion Detection System (IDS). In this work, we develop a Binary Swarm Optimized Differential and Method of Moments Probabilistic Extreme Learning (BSOD-MMPEL) node behavior-based IDS for intrusion detection in MANET with minimum training time, misclassification and high precision, accuracy is proposed. Initially, network samples are collected from KDD-CUP-1999 dataset. To ensure robust and significant balance between exploration and exploitation with high probability of convergence to local sub-optima Gudermannian Activation Binary Swarm Optimized Differential Evolution-based Feature Selection is applied. Next, with the selected features, early detection of intrusion employing Method of Moments Probabilistic Extreme Learning Node Behavior-based IDS is designed. Simulations are performed to validate the result. The performance evaluation in terms of precision, accuracy, sensitivity, training time and misclassification rate show that the proposed method outperforms existing IDS in MANET. The proposed BSOD-MMPEL method is achieved to improve precision of 23 % and accuracy of 27 % and reduce training time of 62 % and misclassification rate of 68 % than existing conventional methods.}
}


@article{DBLP:journals/compsec/YeFCZWZ24,
	author = {Junjian Ye and
                  Xincheng Fei and
                  Xavier de Carn{\'{e}} de Carnavalet and
                  Lianying Zhao and
                  Lifa Wu and
                  Mengyuan Zhang},
	title = {Detecting command injection vulnerabilities in Linux-based embedded
                  firmware with LLM-based taint analysis of library functions},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103971},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103971},
	doi = {10.1016/J.COSE.2024.103971},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/YeFCZWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularization of IoT devices, embedded firmware security has attracted people’s attention. Command injection (CI) is one of the most common types of vulnerabilities in Linux-based embedded firmware. It is caused by user input being propagated to functions responsible for command execution without strict sanitization, which can be detected by static taint analysis. Unfortunately, single-binary taint analysis tools cannot find vulnerabilities caused by custom dynamically linked library functions (DLLFs) that are implemented in external library files, while multi-binary analysis tools are time-consuming. In this paper, we present SLFHunter, an approach that leverages Large Language Model (LLM) to analyze sensitive custom DLLFs separately, and imports their information into single-binary taint analysis tools to overcome this challenge. Our approach follows filtering rules to find out sensitive DLLFs that call common sink functions, and analyzes them with LLMs to find sink library functions (SLFs) where input parameters can be passed to executed command strings. Finally, SLFs are marked as new sinks to help existing tools discover CI vulnerabilities caused by them. We implemented SLFHunter as a ChatGPT-based module for EmTaint and evaluated it with a dataset consisting of 100 Linux-based embedded firmware samples from 13 vendors. The results show that our prompts can guide ChatGPT 4.0 to identify SLFs with 95% accuracy after being improved with a trick we dubbed “double-check”. SLFHunter can help EmTaint find 42 additional CI vulnerabilities with an average time cost increase of 89 s on our dataset, which demonstrates the effectiveness and efficiency of our approach.}
}


@article{DBLP:journals/compsec/ChenHALWP24,
	author = {Shengshan Chen and
                  Ren{-}Hung Hwang and
                  Asad Ali and
                  Ying{-}Dar Lin and
                  Yu{-}Chih Wei and
                  Tun{-}Wen Pai},
	title = {Improving quality of indicators of compromise using {STIX} graphs},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103972},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103972},
	doi = {10.1016/J.COSE.2024.103972},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenHALWP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybersecurity relies on Indicators of Compromise (IoCs) to detect and address threats. Although Threat Intelligence Platforms (TIPs) and Open Source Intelligence (OSINT) are common sources for gathering IoCs, their reliability varies. In our study, we enhance the management of IoCs and OSINT by introducing a novel method that reliably assesses IoC’s threat severity and confidence scores, focusing on Structured Threat Information eXpression (STIX) for threat associations. Our approach, implemented on OpenCTI, significantly enhances IoC value, as it aggregates threat intelligence from diverse sources utilizing a STIX graph-based approach, which is a unique feature among TIPs. Additionally, our method employs heuristic analysis to optimize IoC scoring. It takes into account factors such as relevance, completeness, timeliness, accuracy, and consistency while emphasizing the confidence of the source. Notably, the proposed method has enhanced the precision of the confidence score, achieving a 25.18% reduction in the average difference of confidence scores compared to the benchmarked platform. The Emotet and Medusa case studies underscore the importance of source credibility in confidence scores, emphasizing our TIP’s precision in cybersecurity threat assessment and defense enhancement.}
}


@article{DBLP:journals/compsec/WangCZWL24,
	author = {Wenpeng Wang and
                  Zhixiang Chen and
                  Ziyang Zheng and
                  Hui Wang and
                  Junxing Luo},
	title = {{MTA} Fuzzer: {A} low-repetition rate Modbus {TCP} fuzzing method
                  based on Transformer and Mutation Target Adaptation},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103973},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103973},
	doi = {10.1016/J.COSE.2024.103973},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangCZWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread application of industrial control systems has driven the development of industrial control protocols. However, traditional industrial control protocols suffer from issues such as a lack of security mechanisms, resulting in the existence of many dangerous vulnerabilities in industrial control systems. Fuzzing, as a commonly used technique for vulnerability discovery, has its own set of issues, including low testing efficiency, lack of adaptive capability, and high repetition rate of generated test cases. To solve the existing problems, we propose a low-repetition rate Modbus TCP fuzzing method based on Transformer and Mutation Target Adaptation. Firstly, the syntactic features of the industrial control protocol Modbus TCP are learned by using a simplified Transformer model. The model effectively reduces the training and generation time without decreasing the acceptance rate of test cases; Secondly, in the test case generation phase, in order to improve the mutation efficiency of test cases, the byte mutation probability adaptive strategy is introduced to replace the greedy strategy of Transformer. This strategy can dynamically adjust the mutation probability of each byte in the newly generated test cases, so as to improve the abnormal rate and reduce the repetition rate of test cases; Finally, the mutation results are selected by the mutation byte adaptive selection strategy, which not only improves the mutation adaptivity, but also maintains the diversity of mutations. The experimental results indicate that, compared to traditional methods, our approach has improved acceptance rates and abnormal rates by at least 10%. In comparison to AI-based fuzzing methods, our approach maintains a similar acceptance rate while increasing the abnormal rate by 3% to 25%.}
}


@article{DBLP:journals/compsec/DenisLC24,
	author = {Nathana{\"{e}}l Denis and
                  Maryline Laurent and
                  Sophie Chabridon},
	title = {A decentralized model for usage and information flow control in distributed
                  systems},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103975},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103975},
	doi = {10.1016/J.COSE.2024.103975},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/DenisLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data usage control enables data owners to enforce policies for their data, by defining authorizations, but also obligations, which are actions to be performed before, during or after being granted access such as accepting web cookies, and conditions bearing on the system and environment attributes, e.g., the time. Usage control is often coupled with information flow control to monitor how data are propagated. While usage control is well established and modeled in centralized systems, the literature has only partially addressed usage control for distributed systems, for instance by distributing the usage control system components. However, when it comes to assigning policy to certain data, it is always enforced by a central authority. This paper proposes an extended usage control model to integrate decentralized information flow control (DIFC), which enables users to decide collectively which policy to apply to their common data. Functions to handle connection status aspects are also considered, for dynamic Internet of Things (IoT) or peer-to-peer networks where parts of the distributed network can be disconnected. Architectural aspects and formal definitions to enable decentralized policies for shared data are proposed as a novelty, resulting from the integration of DIFC. We used the TLA+ formal specification language on the proposed model and its attached model checker TLC to detect potential issues. We detected potential deadlocks due to the new connection functions as well as temporal ordering issues then suggested mitigations accordingly. A privacy analysis is provided using a car-sharing scenario to highlight the benefits of usage control.}
}


@article{DBLP:journals/compsec/XieGXLX24,
	author = {Yibo Xie and
                  Gaopeng Gou and
                  Gang Xiong and
                  Zhen Li and
                  Wei Xia},
	title = {DomEye: Detecting network covert channel of domain fronting with throughput
                  fluctuation},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103976},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103976},
	doi = {10.1016/J.COSE.2024.103976},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XieGXLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain fronting, a typical network covert channel, hides malicious information inside encrypted network connections, which are usually established with cloud-hosted domain names. Due to these domain names such as microsoft.com with high reputation, domain fronting realizes the imitation of normal network connections naturally. At present, the common way for domain fronting detection is using imitation flaws to distinguish it from normal network connections. Unlike existing approaches using packet-level flaws, in the paper, we propose DomEye, a novel method using flow-level flaws to detect domain fronting. The DomEye detector exploits a flow-level imitation flaw that domain fronting connections usually exhibit different throughput than normal connections, for example, meek, a domain fronting-based tool for covert darknet access, only reaches a throughput about 10.7 KB at the 50th packet, significantly less than file, image and other normal network requests. According to the imitation flaw, we extract statistical features of throughput fluctuation and feed them into machine learning algorithms to train DomEye detector. Experiments on real-world network traffic prove that DomEye can accurately identify three kinds of domain fronting-based tools with lower false positive rate and lesser computation overhead than the state-of-the-art methods. In conclusion, we propose a superior method for domain fronting detection based on the throughput imitation flaw. As this flaw is at the flow level, we hope more attention could be paid to mining flow-level flaws in the future.}
}


@article{DBLP:journals/compsec/NahumGMMBEES24,
	author = {Mor Nahum and
                  Edita Grolman and
                  Inbar Maimon and
                  Dudu Mimran and
                  Oleg Brodt and
                  Aviad Elyashar and
                  Yuval Elovici and
                  Asaf Shabtai},
	title = {OSSIntegrity: Collaborative open-source code integrity verification},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103977},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103977},
	doi = {10.1016/J.COSE.2024.103977},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/NahumGMMBEES24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open-source software (OSS) libraries have become popular among developers due to their ability to reduce development time and costs. However, OSS can also be exploited and used as a means of conducting OSS supply chain attacks. In OSS attacks, malicious code is injected into libraries used by the target. Previous studies have proposed various methods for preventing and detecting such attacks, however most of them focused on untargeted attacks. In contrast, this paper focuses on targeted OSS supply chain attacks which are performed by skilled and persistent attackers with strong technical aptitude. Targeted OSS attacks are crafted towards a specific target (i.e., developer). Since these attacks do not target general OSS repositories, they tend to go under the radar for a long period of time, allowing an attacker to gain access to sensitive data or systems. In this paper, we propose\n(\nS\nC\n)\n2\nV\n— secure crowdsource-based code verification, a novel distributed and scalable framework for verifying OSS libraries.\n(\nS\nC\n)\n2\nV\nis aimed at preventing targeted supply chain attacks and is integrated in the build phase of software production, serving as an additional code verification step before packaging the application and deploying it.\n(\nS\nC\n)\n2\nV\ninvolves both users (developers seeking to verify an OSS library) and verifiers that contribute to the collaborative verification effort.\n(\nS\nC\n)\n2\nV\nconsiders a library as verified and safe when a consensus is reached among the verifiers. We evaluated the proposed method using eight different attack scenarios (including cold start and edge cases), on around 900 popular OSS libraries and their dependencies, each of which included an average of 10 files and was verified by at least five participants; a total of 127,000 files were evaluated, and the results indicate that it took our framework an average of just 26 s to issue an alert against the attacks.}
}


@article{DBLP:journals/compsec/XuCLTJS24,
	author = {Zhenwu Xu and
                  Xingshu Chen and
                  Xiao Lan and
                  Rui Tang and
                  Shuyu Jiang and
                  Changxiang Shen},
	title = {Empowering Data Owners: An Efficient and Verifiable Scheme for Secure
                  Data Deletion},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103978},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103978},
	doi = {10.1016/J.COSE.2024.103978},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XuCLTJS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud services have attracted numerous enterprises, organizations, and individual users due to their exceptional computing power and almost limitless storage capacity. A vast amount of business data and private data are continuously uploaded to the cloud platform, driven by a series of attractive services offered by the cloud. Unfortunately, once data is uploaded to the cloud, its owner has no way of ensuring that it is actually deleted as intended. This obviously increases the concerns of data owners about the security of their data, because it is related to the privacy of users. Therefore, there must be a reliable solution to prove that data is deleted as requested by users, to prevent data leakage or abuse. In existing data deletion schemes, most are designed based on cryptographic knowledge rather than erasure or overwrite techniques, in order not to cause incalculable damage to the storage medium. However, most cryptographic-based data deletion schemes, particularly attribute-based encryption, involve numerous complex bilinear mapping operations, which are expensive for most devices. To address this issue, the paper proposes an Efficient and Verifiable Scheme for Secure Data Deletion (EVSD). Firstly, Elliptic Curve Cryptography (ECC) is introduced to achieve efficient encryption of data. Then, leveraging Linear Secret Sharing Scheme (LSSS), fine-grained data deletion policies supporting logical operations are implemented. Finally, the deletion of the data is efficiently verified using the root of the Merkle Hash Tree (MHT) generated by the defined illegal and legal attributes, while the deletion proof is also generated. Satisfactorily, security analysis shows that the EVSD scheme is much more advantageous compared to existing schemes, and a trait likewise is also observed in the performance evaluation.}
}


@article{DBLP:journals/compsec/LyuXWCCW24,
	author = {Qiuyun Lyu and
                  Huihui Xie and
                  Wei Wang and
                  Yanyu Cheng and
                  Yongqun Chen and
                  Zhen Wang},
	title = {{TFAN:} {A} Task-adaptive Feature Alignment Network for few-shot website
                  fingerprinting attacks on Tor},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103980},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103980},
	doi = {10.1016/J.COSE.2024.103980},
	timestamp = {Wed, 07 Aug 2024 07:51:19 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LyuXWCCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Few-shot website fingerprinting (WF) attacks aim to infer which website a user browsed through anonymity networks, such as Tor, using limited labeled traces. Recent methods either adopt complex metric strategies or perform time-consuming transfer learning, neither of which yields the most efficient performance in dynamic network environments. In this paper, we introduce a novel Task-adaptive Feature Alignment Network (TFAN) following the meta-learning paradigm. TFAN regards the few-shot WF attack as a feature alignment problem in class latent space, aiming to depict each location in the query feature map as a weighted sum of support features of a given class. Ridge regression provides a closed-form solution without extra parameters or techniques, ensuring high computational efficiency. Moreover, we also propose a Task-adaptive Modulation Unit (TMU), which activates the differences between support prototypes to generate task-level channel weights, making channels with significant discriminative details for each task contribute more to alignment. Extensive experiments on public Tor datasets demonstrate the superiority of TFAN in different scenarios. Notably, it is the only method that maintains over 90% accuracy in the 1-shot setting even 42 days later. Our code is available at https://github.com/Crybaby98/TFAN.}
}


@article{DBLP:journals/compsec/LiYHC24,
	author = {Xiaohui Li and
                  Xiang Yang and
                  Yizhao Huang and
                  Yue Chen},
	title = {Combating temporal composition inference by high-order camouflaged
                  network topology obfuscation},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103981},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103981},
	doi = {10.1016/J.COSE.2024.103981},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiYHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Topology inference driven by non-collaborative or incomplete prior knowledge is widely used in pivotal target network sieving and completion. However, perceivable topology also allows attackers to identify the fragile bottlenecks and perform efficacious attacks that are difficult to defend against by injecting indistinguishable low-volume attacks. Most existing countermeasures are proposed to obfuscate network data or set up honeypots with adversarial examples. However, there are two challenges when adding perturbations to live network links or nodes. Firstly, the perturbations imposed on the network cannot be conveniently projected to the original network with poor scalability. Secondly, applying significant changes to network information is laborious and impractical. In short, making a good trade-off between concealment and complexity is challenging. To address the above issues, we propose a fraudulent proactive defending tactic, namely HBB-TSP, to protect live network privacy by combating attacks of temporal network inference. Specifically, to penetrate the critical network structures, HBB-TSP first brings in the Statistical Validation of Hypergraph (SVH) method to identify the pivotal connection information of the network and extract the deep backbone structure. Then, the Temporal Simple Decomposition Weighting (TSDW) strategy is introduced, which can predict the backbone network with evolution rules and add highly obfuscated features at a minimized overhead. Finally, a discriminator with multiple centrality models is used to evaluate the deceptiveness and, in turn, affect the TSDW prediction. The entire process ensures the consistency and robustness of network changes while ensuring effective adversarial resistance. Experimental results on two scale real-world datasets demonstrate the effectiveness and generalization of adversarial perturbations. In particular, it is encouraging that our proposed defending scheme outperforms the advanced countermeasures. It ensures the realization of a deceptive obfuscated network at minimum overhead and is suitable for widespread deployment in scenarios of different scales.}
}


@article{DBLP:journals/compsec/FarrukhWKB24,
	author = {Yasir Ali Farrukh and
                  Syed Wali and
                  Irfan Khan and
                  Nathaniel D. Bastian},
	title = {{AIS-NIDS:} An intelligent and self-sustaining network intrusion detection
                  system},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103982},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103982},
	doi = {10.1016/J.COSE.2024.103982},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/FarrukhWKB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ever-evolving landscape of network security is continually molded by the dynamic evolution of attack vectors and the relentless emergence of new, highly sophisticated attacks. Attackers consistently employ increasingly advanced techniques, rendering their actions elusive and formidable. In response to this ever-growing threat, the demand for intelligent and autonomous security systems has reached paramount importance. In this paper, we introduce AIS-NIDS (An Intelligent and Self-Sustaining Network Intrusion Detection System), an innovative network intrusion detection system (NIDS) that delves into the realm of packet-level analysis. By doing so, AIS-NIDS is capable of identifying threats with intricate payload-level details, a level of granularity that traditional NIDS relying solely on flow-level data may overlook. The defining feature of AIS-NIDS is its dual functionality, driven by autonomous and intelligent learning. It not only autonomously distinguishes between benign and unknown attacks using machine learning models but also conducts incremental learning, adapting to new attack classes. In essence, AIS-NIDS bridges the gap between traditional NIDS and the next generation of intelligent systems, endowing the system with the capacity for independent decision-making and real-time adaptability in the face of evolving threats. Our extensive experiments stand as a testament to AIS-NIDS’ ability to efficiently manage and identify new attack classes, thus establishing it as a valuable asset in the reinforcement of network infrastructures. Through our experimentation, we have demonstrated the practical efficacy of the proposed approach by simulating a real-world scenario in which certain attack classes are unknown. AIS-NIDS not only effectively identified these unknown threats but also autonomously learned to recognize them as it encountered them, enhancing the system’s capabilities for future encounters with these threats.}
}


@article{DBLP:journals/compsec/GargT24,
	author = {Sonakshi Garg and
                  Vicen{\c{c}} Torra},
	title = {Privacy in manifolds: Combining k-anonymity with differential privacy
                  on Fr{\'{e}}chet means},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103983},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103983},
	doi = {10.1016/J.COSE.2024.103983},
	timestamp = {Sun, 08 Sep 2024 16:07:25 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GargT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While anonymization techniques have improved greatly in allowing data to be used again, it is still really hard to get useful information from anonymized data without risking people’s privacy. Conventional approaches such as k-Anonymity and Differential Privacy have limitations in preserving data utility and privacy simultaneously, particularly in high-dimensional spaces with manifold structures. We address this challenge by focusing on anonymizing data existing within high-dimensional spaces possessing manifold structures. To tackle these issues, we propose and implement a hybrid anonymization scheme termed as the (\nβ\n,\nk\n,\nb\n)-anonymization method that combines elements of both differential privacy and k-anonymity. This approach aims to produce high-quality anonymized data that closely resembles real data in terms of knowledge extraction while safeguarding privacy. The Fréchet mean, an operation applicable in metric spaces and meaningful in the manifold setting, serves as a key aspect of our approach. It provides insight into the geometry of data points within high-dimensional spaces. Our goal is to anonymize this Fréchet mean using our proposed approach and minimize the distance between the original and anonymized Fréchet mean to achieve data privacy without significant loss of information. Additionally, we introduce a novel Fréchet mean clustering model designed to enhance the clustering process for high-dimensional spaces. Through theoretical analysis and practical experiments, we demonstrate that our approach outperforms traditional privacy models both in terms of preserving data utility and privacy. This research contributes to advancing privacy-preserving techniques for complex and non-linear data structures, ensuring a balance between data utility and privacy protection.}
}


@article{DBLP:journals/compsec/MothannaEHKS24,
	author = {Yusuf Mothanna and
                  Wael Elmedany and
                  Mustafa Hammad and
                  Riadh Ksantini and
                  Mhd Saeed Sharif},
	title = {Adopting security practices in software development process: Security
                  testing framework for sustainable smart cities},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103985},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103985},
	doi = {10.1016/J.COSE.2024.103985},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/MothannaEHKS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The dependence on smart city applications has expanded in recent years. Consequently, the number of cyberattack attempts to exploit smart application vulnerabilities significantly increases. Therefore, improving smart application security during the software development process is mandatory to ensure sustainable smart cities. But the challenge is how to adopt security practices in the software development process. There are Several established and mature security testing frameworks exist that consider security requirements and testing during Several already established and mature security testing frameworks exist that consider security requirements and testing during Software Development Life Cycle (SDLC), but there is a unique challenges posed by smart city applications and the need for a comprehensive approach to address the evolving threat landscape in this context. This paper proposed a framework that adopts security testing practices in all phases of the software development process. The proposed framework identifies several security activities and steps that can be applied in each phase of the software development process.}
}


@article{DBLP:journals/compsec/ChenWZLLLZ24,
	author = {Zigang Chen and
                  Zhen Wang and
                  Yuening Zhou and
                  Fan Liu and
                  Yuhong Liu and
                  Tao Leng and
                  Haihua Zhu},
	title = {A method for recovering adversarial samples with both adversarial
                  attack forensics and recognition accuracy},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103987},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103987},
	doi = {10.1016/J.COSE.2024.103987},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenWZLLLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial samples deceive machine learning models through small but elaborate modifications that lead to erroneous outputs. The severity of the adversarial sample problem has come to the forefront with the widespread use of machine learning in areas such as security systems, autonomous driving, speech recognition, finance, and medical diagnostics. Malicious attackers can use adversarial samples to circumvent security detection systems, interfere with autonomous driving perception, mislead speech recognition, defraud financial systems, and even cause medical diagnosis errors. The emergence of adversarial samples exposes the vulnerability of existing models and poses challenges for information tracing and forensics after the incident. The main goal of current adversarial sample restoration methods is to improve model robustness. Traditional approaches focus only on improving the model’s classification accuracy, ignoring the importance of adversarial information, which is crucial for understanding the attack mechanism and strengthening future defenses. To address this issue, we propose an adversarial sample restoration method based on the similarity between clean and adversarial sample blocks to balance the needs of adversarial forensics and recognition accuracy. We implement the Fast Gradient Sign Method (FGSM), Basic Iterative Method (BIM), and Momentum Iterative Attack (MIA) attacks on MNIST, F-MNIST, and EMNIST datasets and perform experimental validation. The results demonstrate that our restoration method significantly enhances the model’s classification accuracy across various datasets and attack scenarios. Comparative analysis shows that the restored samples maintain a high similarity with the original adversarial samples, proving the method’s effectiveness. In addition, we performed performance tests on pre- and post-recovery samples. Taking the MNIST dataset as an example, we observed that the model performance metrics, such as MAPE, MAE, RMSE, and VAPE, of the restored samples improved by 88%, 88%, 65%, and 82%, respectively, after using the FGSM attack. This indicates that our restoration method successfully preserves the information of the generation mechanism of the adversarial samples and improves the model’s performance. This approach balances forensic capability and prediction accuracy, demonstrates a new direction in adversarial sample research, and substantially impacts security defense in practical applications.}
}


@article{DBLP:journals/compsec/KimHG24,
	author = {Yoonjib Kim and
                  Saqib Hakak and
                  Ali A. Ghorbani},
	title = {Detecting Distributed Denial-of-Service (DDoS) attacks that generate
                  false authentications on Electric Vehicle {(EV)} charging infrastructure},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103989},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103989},
	doi = {10.1016/J.COSE.2024.103989},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KimHG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, smart grid-based Electric Vehicle (EV) charging systems have increasingly faced vulnerabilities to Distributed Denial of Service (DDoS) attacks, especially through malicious authentication failures. These attacks typically involve monopolizing the Grid Server (GS), thereby hindering the authentication process for legitimate EVs. Despite the severity of this issue, no research (to the best of our knowledge) has focused on detecting DDoS attacks exploiting weaknesses in EV authentication. This study introduces a DDoS attack detection model specifically designed for EV authentication. The approach involves developing a machine learning model involving unique feature selection and combination. The proposed approach has been evaluated using a new DDOS attack dataset. The model is engineered to optimize feature combination, aiming for high sampling resolution, minimal information loss, and robust performance under 16 distinct attack scenarios. The feature combination used in this study shows improved accuracy over traditional DDoS detection methods based on access time variation while minimizing information loss.}
}


@article{DBLP:journals/compsec/ZhengLXCYW24,
	author = {Tianming Zheng and
                  Haojun Liu and
                  Hang Xu and
                  Xiang Chen and
                  Ping Yi and
                  Yue Wu},
	title = {Few-VulD: {A} Few-shot learning framework for software vulnerability
                  detection},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103992},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103992},
	doi = {10.1016/J.COSE.2024.103992},
	timestamp = {Thu, 22 Aug 2024 20:25:15 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhengLXCYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of artificial intelligence (AI) has led to the introduction of numerous software vulnerability detection methods based on deep learning algorithms. However, a significant challenge is their dependency on large volumes of code samples for effective training. This requirement poses a considerable hurdle, particularly when adapting to diverse software application scenarios and various vulnerability types, where gathering sufficient and relevant training data for different classification tasks is often arduous. To address the challenge, this paper introduces Few-VulD, a novel framework for software vulnerability detection based on few-shot learning. This framework is designed to be efficiently trained with a minimal number of samples from a variety of existing classification tasks. Its key advantage lies in its ability to rapidly adapt to new vulnerability detection tasks, such as identifying new types of vulnerabilities, with only a small set of learning samples. This capability is particularly beneficial in scenarios where available vulnerability samples are limited. We compare Few-VulD with five state-of-the-art methods on the SySeVR and Big-Vul datasets. On the SySeVR dataset, Few-VulD outperforms all other methods, achieving a recall rate of 87.9% and showing an improvement of 11.7% to 57.8%. On the Big-Vul dataset, Few-VulD outperforms three of the methods, including one that utilizes a pretrained large language model (LLM), with recall improvements ranging from 8.5% to 40.1%. The other two methods employ pretrained LLMs from Microsoft CodeXGLUE (Lu et al., 2021). Few-VulD reaches 78.7% and 95.5% of their recall rates without the need for extensive data pretraining. The performance proves the effectiveness of Few-VulD in vulnerability detection tasks with limited samples.}
}


@article{DBLP:journals/compsec/GuoYLHWC24,
	author = {Chunjie Guo and
                  Lin You and
                  Xingyu Li and
                  Gengran Hu and
                  Shengguo Wang and
                  Chengtang Cao},
	title = {A novel biometric authentication scheme with privacy protection based
                  on {SVM} and {ZKP}},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {103995},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.103995},
	doi = {10.1016/J.COSE.2024.103995},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GuoYLHWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biometric authentication is a very convenient and user-friendly method. The popularity of this method requires strong privacy-preserving technology to prevent the disclosure of template information. Most of the existing privacy protection technologies rely on classic encryption techniques, such as homomorphic encryption, which incur huge system overhead and cannot be popularized. To address these issues, we propose a novel biometric authentication scheme with privacy protection based on support vector machine and zero knowledge proof (BioAu–SVM+ZKP). BioAu–SVM+ZKP allows users to authenticate themselves to different service providers without disclosing any biometric template information. The evidence is generated through the zero-knowledge proof utilizing polynomial commitments. Our approach for generating a unique and repeatable biometric identifier from the user’s fingerprint image leverages the multi-classification property of SVM. Notably, our scheme not only reduces the communication overhead but also provides the privacy protection features. Besides, the communication overhead of BioAu–SVM+ZKP is constant. We have simulated the authentication scheme on the common dataset NIST, analyzed the performance and proved the security.}
}


@article{DBLP:journals/compsec/WangLL24,
	author = {Xiaodi Wang and
                  Zhonglin Liu and
                  Jiayong Liu},
	title = {Joint relational triple extraction with enhanced representation and
                  binary tagging framework in cybersecurity},
	journal = {Comput. Secur.},
	volume = {144},
	pages = {104001},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2024.104001},
	doi = {10.1016/J.COSE.2024.104001},
	timestamp = {Mon, 05 Aug 2024 21:42:43 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cyber threat intelligence (CTI) knowledge graph is a valuable tool for aiding security practitioners in the identification and analysis of cyberattacks. These graphs are constructed from CTI data, organized into relational triples, where each triple comprises two entities linked by a particular relation. However, as the volume of CTI data is expanding at a faster rate than predicted, existing technologies are unable to extract relational triples quickly and accurately. This work mainly focuses on the extraction of relational triples in CTI data, which is achieved by an enhanced representation and binary tagging framework (ERBTF). Firstly, we introduce embedding representations for relations and concatenate these with word embeddings to obtain the initial hidden representation. Subsequently, we employ a novel dilated convolutional encoder that consists of a dilated convolution neural network, gate mechanism and residual connection to enhance the learned contextual representation. Afterwards, we adopt an attention module that includes multi-head self-attention and position-wise feed-forward neural network to allocate greater attention to words that significantly influence the specific relation. Additionally, we utilize the straightforward yet efficient binary entity tagger to identify subject and object entities under different relations for constructing relational triples. We conduct massive experiments on relational triple extraction from CTI data, the results show that ERBTF is superior to the existing relation extraction models, and achieves state-of-the-art performance.}
}
