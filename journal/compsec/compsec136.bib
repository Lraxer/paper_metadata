@article{DBLP:journals/compsec/MikuleticVSZ24,
	author = {Samanta Mikuletic and
                  Simon Vrhovec and
                  Brigita Skela{-}Savic and
                  Bostjan Zvanut},
	title = {Security and privacy oriented information security culture {(ISC):}
                  Explaining unauthorized access to healthcare data by nursing employees},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103489},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103489},
	doi = {10.1016/J.COSE.2023.103489},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MikuleticVSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Protecting sensitive healthcare data is particularly challenging. Nursing employees are critical in protecting healthcare data since they make up a large portion of the healthcare workforce and have direct access to healthcare data. Information security culture (ISC) plays a prominent role in protection of healthcare data albeit their relationship remains unclear. In this study, we first define and operationalize two new dimensions of organizational ISC related to security and privacy. Then, a survey of Slovenian nursing employees (n = 527) was conducted to validate the measurement instrument and examine the associations between the newly developed ISC dimensions and unauthorized access to healthcare data by nursing employees based on the theory of planned behavior (TPB). The measurement instrument was first validated with an exploratory and then with a confirmatory factor analysis. Both analyses indicate adequate validity and reliability of the newly developed ISC dimensions. The results of PLS-SEM analysis show that security oriented ISC is negatively associated with subjective norm and normative beliefs while privacy oriented ISC is negatively associated with attitude towards behavior. Additionally, they indicate that TPB explains well unauthorized access to healthcare data. The results of our study thus indicate an indirect relation between ISC and unauthorized access to healthcare data. Awareness training is considered as essential means for ensuring proper practical implementations of ethical norms, such as privacy-preserving behavior, by nursing employees. Our study suggests that such awareness interventions may aim either to strengthen the social influence on nursing employees, their attitudes or both. Awareness interventions aiming to strengthen the social influence of nursing employees may focus on established organizational data protection practices and other important organizational values, norms, and accepted ways of working in an organization. Attitudes of nursing employees may be strengthened with awareness interventions focusing on their personal beliefs and ethics.}
}


@article{DBLP:journals/compsec/WangZW24,
	author = {Meng Wang and
                  Yahao Zhang and
                  WeiPing Wen},
	title = {Improved capsule networks based on Nash equilibrium for malicious
                  code classification},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103503},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103503},
	doi = {10.1016/J.COSE.2023.103503},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WangZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the cutting-edge technology and artificial intelligence, various types of malware have seriously attacked cyberspace, thus relying on the deep learning to maintain high accuracy on malware classification was the solution. After the malware binaries are changed into grayscale images as network inputs, most of the existing methods deal with the observed substantial visual similarities in image texture for malware as if they were from the same family. In addition, the patterns among the different families should include exclusive features, which are prerequisite for malicious code classification. However, the previous methods do not focus on the feature extraction. To solve this problem, we propose an improved capsule network based on the Nash equilibrium for malicious code classification. From the perspective of game theory, extracting of the exclusive features can be viewed as a noncooperative game through a novel dynamic routing embedded with the Nash equilibrium process in the proposed method. The three most recent datasets are used in the evaluation period. Five indicators are calculated to test the general performance and ability to distinguish the malware categories between the Nash capsule networks, traditional capsule network and CNN. Experiments show that the classification effect of the proposed method is better than that of the traditional machine learning methods.}
}


@article{DBLP:journals/compsec/QinJDD24,
	author = {Xingsheng Qin and
                  Frank Jiang and
                  Chengzu Dong and
                  Robin Doss},
	title = {A hybrid cyber defense framework for reconnaissance attack in industrial
                  control systems},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103506},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103506},
	doi = {10.1016/J.COSE.2023.103506},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/QinJDD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The convergence of information technology (IT) and operation technology (OT) has made Industrial Control Systems (ICS) a popular target for cyberattacks in recent years. Unlike traditional networks, enhancing availability is the ICS network's top priority rather than confidentiality in the CIA scheme. We propose a bio-inspired adaptive defense framework based on dissimilar redundancy, diversity, and adaptive defense strategies to achieve this aim. The proposed mechanism mixed optimal network shuffling and cyber deception techniques to maximise the time attackers spend on the decoys. Besides, to provide an extra layer of protection for system availability, we introduce dual heterogeneous subnets in the proposed framework that could be regenerated once compromised. We evaluate the performance of the proposed defense framework in a typical industrial manufacturing network using an SDN-based platform and test the defense framework in various scenarios. Compared with previous research, the simulation shows a considerable improvement in defense performance in the adaptive defense mode.}
}


@article{DBLP:journals/compsec/BerensBDKKV24,
	author = {Benjamin Maximilian Berens and
                  Mark Bohlender and
                  Heike Dietmann and
                  Chiara Krisam and
                  Oksana Kulyk and
                  Melanie Volkamer},
	title = {Cookie disclaimers: Dark patterns and lack of transparency},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103507},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103507},
	doi = {10.1016/J.COSE.2023.103507},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/BerensBDKKV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While cookie disclaimers on websites have been proposed to ensure that users make informed decisions regarding consenting to data collection via cookies, such informed consent is hindered by several factors. One of them is the presence of so-called dark patterns, that is, design elements that are used to lead users to accept more cookies than needed and more than they are aware of. The second factor is lack of transparency on behalf of the service providers with regards to what happens if the user does not consent to cookie usage even despite dark patterns nudging them to do so. The contributions of this paper are (1) evaluating the efficacy of several of these factors while measuring actual behaviour; (2) identifying users' attitude towards cookie disclaimers including how they decide which cookies to accept or reject; (3) assessing the behaviour of websites regarding storing non-necessary cookies despite user's consent. We show that different visual representation of the reject/accept option have a significant impact on users' decision. We also found that the labelling of the reject option has a significant impact. In addition, we confirm previous research regarding biasing text (which has no significant impact on users' decision). Our results on users' attitude towards cookie disclaimers indicate that for several user groups the design of the disclaimer only plays a secondary role when it comes to decision making. We furthermore show that even without user's explicit consent, the majority of websites we investigated still uses non-necessary cookies. We provide recommendations on how to improve the situation for different stakeholders, namely, for developers and policy makers.}
}


@article{DBLP:journals/compsec/SongSZHWXZ24,
	author = {Haina Song and
                  Hua Shen and
                  Nan Zhao and
                  Zhangqing He and
                  Minghu Wu and
                  Wei Xiong and
                  Mingwu Zhang},
	title = {{APLDP:} Adaptive personalized local differential privacy data collection
                  in mobile crowdsensing},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103517},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103517},
	doi = {10.1016/J.COSE.2023.103517},
	timestamp = {Mon, 22 Jul 2024 08:24:24 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/SongSZHWXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Local differential privacy (LDP) enables terminal participants to share their private data safely while controlling the privacy disclosure at the source. In the majority of current works, they assumed that the privacy preservation parameter is totally determined by the data collector and then dispatched to all participants in mobile crowdsensing. However, in the real world, due to different privacy preferences of participants, it is inelegant and unpromising for all participants to accept the same privacy preservation level during data collection. To address such issue, an adaptive personalized local differential privacy (APLDP) data collection scheme is proposed to realize personalized privacy preservation while achieving higher data utility, in which two different LDP perturbation methods (basic RAPPOR and k-RR) are adaptively chosen by the participants according to their different privacy preferences, as well as the best perturbation probability is adaptively adopted by the participants to perturb their private data. In such case, the adaptive boundary based on the minimum mean square error (MSE) is theoretically derived to allow the participant to adaptively choose the best perturbation method, and meanwhile, it allows the participant to adaptively choose the best perturbation probability. Then, two estimation mergence methods named the direct combination (DC) and the weighted combination (WC) are demonstrated to do efficient data aggregation. Experiments on both synthetic and real data sets show that the proposed APLDP scheme performs better than previous non-personalized proposals in terms of the MSE and the average error rate (AER), especially using WC estimation method.}
}


@article{DBLP:journals/compsec/ChenZLZ24,
	author = {Tieming Chen and
                  Huan Zeng and
                  Mingqi Lv and
                  Tiantian Zhu},
	title = {{CTIMD:} Cyber threat intelligence enhanced malware detection using
                  {API} call sequences with parameters},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103518},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103518},
	doi = {10.1016/J.COSE.2023.103518},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ChenZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic malware analysis that monitors the sequences of API calls of the program in a sandbox has been proven to be effective against code obfuscation and unknown malware. However, most existing works ignore the run-time parameters by only considering the API names, or lack an effective way to capture the correlations between parameter values and malicious activities. In this paper, we propose CTIMD, a deep learning based dynamic malware detection method, which integrates the threat knowledge from CTIs (Cyber Threat Intelligences) into the learning on API call sequences with run-time parameters. It first extracts IOCs (Indicators of Compromise) from CTIs and uses IOCs to assist the identification of the security-sensitive levels of API calls. Then, it embeds API calls and the associated security-sensitive levels into a unified feature space. Finally, it feeds the feature vector sequences into deep neural networks to train the malware detection model. We conducted experiments on two datasets. The experiment results show that CTIMD significantly outperforms existing methods depending on raw API call sequences (F1-score is improved by 4.0 %∼41.3 %), and also has advantage over existing state-of-the-art methods that consider both API calls and run-time parameters (F1-score is improved by 1.2 %∼6.5 %).}
}


@article{DBLP:journals/compsec/NajafiPCM24,
	author = {Pejman Najafi and
                  Wenzel P{\"{u}}nter and
                  Feng Cheng and
                  Christoph Meinel},
	title = {You are your friends: Detecting malware via guilt-by-association and
                  exempt-by-reputation},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103519},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103519},
	doi = {10.1016/J.COSE.2023.103519},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/NajafiPCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increase in the prevalence of Security Information and Event Management Systems (SIEMs) in today's organizations, there is a growing interest in data-driven threat detection.}
}


@article{DBLP:journals/compsec/HeSXHTZ24,
	author = {Ying He and
                  Zhili Shen and
                  Chang Xia and
                  Jingyu Hua and
                  Wei Tong and
                  Sheng Zhong},
	title = {{SGBA:} {A} stealthy scapegoat backdoor attack against deep neural
                  networks},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103523},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103523},
	doi = {10.1016/J.COSE.2023.103523},
	timestamp = {Tue, 07 May 2024 20:21:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HeSXHTZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outsourced deep neural networks have been demonstrated to suffer from patch-based trojan attacks, in which an adversary poisons the training sets to inject a backdoor in the obtained model so that regular inputs can be still labeled correctly while those carrying a specific trigger are falsely given a target label. Due to the severity of such attacks, many backdoor detection and containment systems have recently, been proposed for deep neural networks. One major category among them are various model inspection schemes, which hope to detect backdoors before deploying models from non-trusted third-parties. In this paper, we show that such state-of-the-art schemes can be defeated by a so-called Scapegoat Backdoor Attack, which introduces a benign scapegoat trigger in data poisoning to prevent the defender from reversing the real abnormal trigger. In addition, it confines the values of network parameters within the same variances of those from clean model during training, which further significantly enhances the difficulty of the defender to learn the differences between legal and illegal models through machine-learning approaches. Our experiments on 3 popular datasets show that it can escape detection by all five state-of-the-art model inspection schemes. Moreover, this attack brings almost no side-effects on the attack effectiveness and guarantees the universal feature of the trigger compared with original patch-based trojan attacks.}
}


@article{DBLP:journals/compsec/ZhaoJHLP24,
	author = {Xiaojuan Zhao and
                  Rong Jiang and
                  Yue Han and
                  Aiping Li and
                  Zhichao Peng},
	title = {A survey on cybersecurity knowledge graph construction},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103524},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103524},
	doi = {10.1016/J.COSE.2023.103524},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhaoJHLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of key technologies of knowledge graph (KG) has promoted the development of machine cognition technology, and the combination of KG and industry as well as scenario-based landing have also made breakthroughs in succession. In the field of cybersecurity, with the intelligent upgrading of defense technology, there is an urgent need for a mature and effective technical system to provide knowledge and intelligent reasoning support for the offensive and defensive games in strong adversarial and high dynamic environment. As a domain KG, cybersecurity KG (CKG) just meets this requirement. KG for cybersecurity is not a recent invention; its predecessor is the earliest semantic networks and ontologies, and the KG is small in scale and the relations are relatively simple. Through investigation, we found that most studies that explicitly mentioned CKG, still tend to construct a cybersecurity ontology first, and then extract semantic triples based on ontology. Of course, there are also some studies that try to build such a graph from a higher dimension to express the rich semantics. In order to apply mature techniques of KG construction and reasoning, we believe that the construction of CKG should also follow the Open-domain KG. Therefore, we conducted a comprehensive review and detailed comparison of CKG-related works, discussed the dilemma of CKG application, and then proposed future research opportunities for CKG. This work can help researchers keep up with recent research trends.}
}


@article{DBLP:journals/compsec/RekaKRS24,
	author = {R. Reka and
                  R. Karthick and
                  R. Saravana Ram and
                  Gurkirpal Singh},
	title = {Multi head self-attention gated graph convolutional network based
                  multi{\unicode{8209}}attack intrusion detection in {MANET}},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103526},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103526},
	doi = {10.1016/J.COSE.2023.103526},
	timestamp = {Mon, 05 Feb 2024 20:23:22 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/RekaKRS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Designing of intrusion detection system (IDS), and mobile ad hoc networks (MANET) prevention technique with examined detection rate, memory consumption with minimum overhead are vital concerns. Node mobility and node energy are the two optimization problems in MANETs wherein nodes travel uncertainly in any direction, evolving in a continuous change of topology. With the proposed approach, a Centrality Coati Optimization Algorithm based Cluster Gradient for multi attack intrusion identification is devised. This study focuses on the problems of node mobility and energy to develop a clustering algorithm for cluster head selection in MANET that is incited by Dual Network Centrality. Compact cluster formation is carried out by Coati Optimization Algorithm (COA). The Multi-head Self-Attention based Gated Graph Convolutional Network (MSA-GCNN) with a hybrid type of IDS recognizes several attacks, including DoS and Zero-Day attacks. The proposed technique is implemented in NS-2 network simulator. The performance of proposed approach is examined under some parameters, like attack detection rate, memory consumption, computational time for detecting the intruder. The outcomes display that the proposed technique decreases the IDS traffic and entire consumption of memory and sustains a higher attack identification rate with less computational time. The proposed technique attains 4.299 %, 10.375 % and 6.935 % Accuracy, 5.262 %, 8.375 % and 7.945 % Precision, 7.282 %, 10.365 % and 5.935 % Recall, 9.272 %, 5.355 % and 8.965 % ROC is higher compared with the existing methods such as, Epsilon Swarm Optimized Cluster Gradient along deep belief classifier for multiple attack intrusion detection (ESOC-MA-ID-MANET), Intrusion Detection secure solution for intrusion detection in cloud computing utilizing hybrid deep learning approach called EOS-IDS and improved heap optimization (IHO-MA-ID-MANET) for induction detection technique respectively.}
}


@article{DBLP:journals/compsec/WangYJZC24,
	author = {Wenbo Wang and
                  Peng Yi and
                  Junfang Jiang and
                  Peng Zhang and
                  Xiang Chen},
	title = {Transformer-based framework for alert aggregation and attack prediction
                  in a multi-stage attack},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103533},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103533},
	doi = {10.1016/J.COSE.2023.103533},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WangYJZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the growing threat of cyber attacks has made more researchers focus on the study of alert correlation and attack prediction. While numerous solutions have been proposed, the existing works still have some shortcomings. Without aggregation, previous approaches directly put the excessive and duplicate alerts into models, ignoring the internal logic between adjacent payloads, which we believe is a significant clue to distinguish different types of attacks. In this paper, we propose a similarity based aggregation algorithm to correlate and aggregate alerts, then train a Transformer based model to handle input with variable length and complete the attack prediction. Additionally, a threat estimation method as well as its practical application has been proposed to assess the predicted output. Experimental results demonstrate that our proposed framework has the capability to effectively aggregate alerts, predict different attack intelligence in good mode as well as assess how much threat the administrator would face in the near future.}
}


@article{DBLP:journals/compsec/CheeGBK24,
	author = {Kok Onn Chee and
                  Mengmeng Ge and
                  Guangdong Bai and
                  Dan Dongseong Kim},
	title = {IoTSecSim: {A} framework for modelling and simulation of security
                  in Internet of things},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103534},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103534},
	doi = {10.1016/J.COSE.2023.103534},
	timestamp = {Sun, 04 Aug 2024 19:48:14 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/CheeGBK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of the Internet of Things (IoT) devices has provided attackers with tremendous opportunities to launch various cyber-attacks. It has been challenging to analyse the impact of cyber-attacks and evaluate the effectiveness of defences in real IoT environments due to the scale and heterogeneity of IoT networks. In this work, we propose a novel simulation framework and a software tool, IoT Security Simulator (IoTSecSim). IoTSecSim is operated based on a framework we propose for modelling and simulating cyber-attacks and various defences in IoT networks. IoTSecSim is not only able to support the creation of an IoT network with flexible settings of IoT devices and topology information but also models the attack behaviours, node-level, and network-level defences. Moreover, a systematic security evaluation can be performed by comparing the results based on the calculation of security metrics. We perform simulations with case studies on Mirai malware and its variants to model cyber-attack behaviours on IoT networks and evaluate the impact of these attacks and the effectiveness of defence techniques via IoTSecSim. Then, we carry out a sensitivity analysis to justify that the simulation results produced by IoTSecSim are accurate and feasible when compared with related works. We also perform a comparative performance analysis with four combinations of cyber-attack behaviours and show that these behaviours can influence IoT malware propagation in different situations. We consider multiple attacker models and deploy conventional defence techniques (including firewall, intrusion detection, and vulnerability patching) to investigate the effectiveness of defence techniques. IoTSecSim provides a generalised and extensible simulation framework that enables users to model emerging cyber-attacks against IoT networks and evaluate the effectiveness of defences against these attacks. This helps users focus on the design and performance evaluation of new defences before the actual implementation and deployment of the defences are required.}
}


@article{DBLP:journals/compsec/HeXZXY24,
	author = {Xinlong He and
                  Yang Xu and
                  Sicong Zhang and
                  Weida Xu and
                  Jiale Yan},
	title = {Enhance membership inference attacks in federated learning},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103535},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103535},
	doi = {10.1016/J.COSE.2023.103535},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HeXZXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Federated learning, models in training will unintentionally memorize detailed information about private data, and the aggregation process on the central server requires users to upload their model parameters, making the models still susceptible to membership inference attacks. However, the existing membership inference attacks in federated learning have been less effective. This paper proposes a new membership inference attack method in federated learning that utilizes data poisoning and sequence prediction confidence. By injecting toxic data, the model can remember the detailed information of specific classes in the target private dataset to the maximum extent. The privacy data detailed information of the target clients contained in the model will be represented through the output confidence vector. Afterward, we aggregate the confidence information obtained from multiple epochs in federated learning and utilize the AdaBoost classifier to learn the details from it. Finally, we use different thresholds to partition the predicted confidence scores output by the AdaBoost classifier obtaining the membership information. We conducted experiments on multiple datasets and models to validate the effectiveness of our attack method. The results showed a high attack effectiveness with minimal overall model performance degradation.}
}


@article{DBLP:journals/compsec/OuytselDL24,
	author = {Charles{-}Henry Bertrand Van Ouytsel and
                  Khanh{-}Huu{-}The Dam and
                  Axel Legay},
	title = {Analysis of machine learning approaches to packing detection},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103536},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103536},
	doi = {10.1016/J.COSE.2023.103536},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/OuytselDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Packing is a widely used obfuscation technique by which malware hides content and behavior. Much research explores how to detect a packed program via such varied approaches as entropy analysis, syntactic signatures, and, more recently, machine learning classifiers using various features. Yet no robust results indicate which algorithms perform best or which features are most significant. Reviews of these results highlight how accuracy, cost, generalization of capabilities, and other measures complicate evaluations. Our work addresses deficiencies by assessing nine different machine-learning approaches using 119 features to identify which features are most significant for packing detection, which algorithms offer the best performance, and which algorithms are most economical.}
}


@article{DBLP:journals/compsec/ShenS24,
	author = {Quan Shen and
                  Yanming Shen},
	title = {Endpoint security reinforcement via integrated zero-trust systems:
                  {A} collaborative approach},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103537},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103537},
	doi = {10.1016/J.COSE.2023.103537},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ShenS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the rapidly evolving field of information technology, network security, especially enterprise endpoint security, has emerged as a major challenge. This paper presents a comprehensive and interactive method for network access and user authentication utilizing a zero-trust framework. This method integrates key elements, including the Network Access (NA) Agent, Identity and Access Management (IAM) Agent, Policy Enforcement Point (PEP) Agent, and Situational Awareness (SA) Agent, to mitigate security risks associated with critical business information exposure and unauthorized network access. Leveraging a zero-trust approach, the method dynamically controls user permissions, thereby enhancing endpoint security. It also introduces an efficient solution that coexists with legacy infrastructures, balancing security necessities with user accessibility, and offering a unified solution for both internal corporate networks and the Internet. We present a thorough analysis of potential risks associated with this method and propose preventative measures to minimize these threats. We conclude that our method provides a more secure and efficient approach to enterprise network security compared to traditional static rule-based systems, offering a promising direction for future research and implementation.}
}


@article{DBLP:journals/compsec/MayerHE24,
	author = {Rudolf Mayer and
                  Markus Hittmeir and
                  Andreas Ekelhart},
	title = {Distance-based linkage of personal microbiome records for identification
                  and its privacy implications},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103538},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103538},
	doi = {10.1016/J.COSE.2023.103538},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MayerHE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to its high potential for analysis in clinical settings, research on the human microbiome has been flourishing for several years. As an increasing amount of data on the microbiome is gathered and stored, analysing the temporal and individual stability of microbiome readings, and the succeeding privacy risks, has gained importance. In 2015, Franzosa et al. demonstrated the feasibility of matching and linking individuals in microbiome-based datasets from the Human Microbiome Project, which could lead to re-identification of individuals, and thus poses privacy implications for microbiome study designs. Their technique is based on the construction of body site-specific metagenomic codes that maintain a certain stability over time.}
}


@article{DBLP:journals/compsec/ChenJCZZYY24,
	author = {Ruoxi Chen and
                  Haibo Jin and
                  Jinyin Chen and
                  Haibin Zheng and
                  Shilian Zheng and
                  Xiaoniu Yang and
                  Xing Yang},
	title = {AdvCheck: Characterizing adversarial examples via local gradient checking},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103540},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103540},
	doi = {10.1016/J.COSE.2023.103540},
	timestamp = {Tue, 07 May 2024 20:21:12 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChenJCZZYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks (DNNs) are vulnerable to adversarial examples, which may lead to catastrophe in security-critical domains. Numerous detection methods are proposed to characterize the feature uniqueness of adversarial examples, or to distinguish DNN's behavior activated by the adversarial examples. Detections based on features may be compromised when faced with stronger attacks. Besides, they require a large amount of specific adversarial examples. Another mainstream, model-based detections, which characterize input properties by model behaviors, suffer from heavy computation cost. To address the issues, we introduce the concept of local gradient, and reveal that adversarial examples have a quite larger bound of local gradient than the benign ones. Inspired by the observation, we leverage local gradient for detecting adversarial examples, and propose a general framework AdvCheck. Specifically, by calculating the local gradient from a few benign examples and noise-added misclassified examples to train a detector, adversarial examples and even misclassified natural inputs can be precisely distinguished from benign ones. Through extensive experiments, we have validated the AdvCheck's superior performance to the state-of-the-art (SOTA) baselines, with detection rate (∼×1.2) on general adversarial attacks and (∼×1.4) on misclassified natural inputs on average, with average 1/200 time cost. We also provide interpretable results for successful detection.}
}


@article{DBLP:journals/compsec/HuangWWB24,
	author = {Jiahao Huang and
                  Mi Wen and
                  Minjie Wei and
                  Yanbing Bi},
	title = {Enhancing the transferability of adversarial samples with random noise
                  techniques},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103541},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103541},
	doi = {10.1016/J.COSE.2023.103541},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/HuangWWB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural networks have achieved remarkable success in the field of computer vision. However, they are susceptible to adversarial attacks. The transferability of adversarial samples has made practical black-box attacks feasible, underscoring the importance of research on transferability. Existing work indicates that adversarial samples tend to overfit to the source model, getting trapped in local optima, thereby reducing the transferability of adversarial samples. To address this issue, we propose the Random Noise Transfer Attack (RNTA) to search for adversarial samples in a larger data distribution, seeking the global optimum. Specifically, we suggest injecting multiple random noise perturbations into the sample before each iteration of sample optimization, effectively exploring the decision boundary within an extended data distribution space. By aggregating gradients, we identify a better global optimum, mitigating the issue of overfitting to the source model. Through extensive experiments on the large-scale visual classification task on ImageNet, we demonstrate that our method increases the success rate of momentum-based attacks by an average of 20.1%. Furthermore, our approach can be combined with existing attack methods, achieving a success rate of 94.3%, which highlights the insecurity of current models and defense mechanisms.}
}


@article{DBLP:journals/compsec/LiuSLL24,
	author = {Ming Liu and
                  Xiao Song and
                  Yong Li and
                  Wenxin Li},
	title = {Correlated differential privacy based logistic regression for supplier
                  data protection},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103542},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103542},
	doi = {10.1016/J.COSE.2023.103542},
	timestamp = {Sun, 04 Aug 2024 19:48:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiuSLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a crucial participant in the supply chain, the supplier's every action affects the supply chain's status, making predictions about whether a supplier will be listed or not essential. However, the large amount of sensitive data used in machine learning generates the problem of privacy leakage. Due to the data relevance, traditional differential privacy is prone to leakage of information of correlated data. To effectively tackle this problem, in the scenario of supplier listing prediction, we introduce the correlated differential privacy mechanism for the logistic regression model, propose the feature selection scheme DC-FBFS, and further explore different noise addition methods. The experiments show that the proposed scheme can improve the utility of data, increase the prediction accuracy, and reduce the error in data query while effectively protecting data.}
}


@article{DBLP:journals/compsec/KhalilBK24,
	author = {Shaymaa Mamdouh Khalil and
                  Hayretdin Bahsi and
                  Tarmo Kor{\~{o}}tko},
	title = {Threat modeling of industrial control systems: {A} systematic literature
                  review},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103543},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103543},
	doi = {10.1016/J.COSE.2023.103543},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KhalilBK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Threat modeling is the process of identifying and mitigating potential threats to a system. It was originally developed to enhance software security during the design phase but has since been adapted for Industrial Control Systems (ICSs). ICSs are complex and interconnected systems that control critical infrastructure, such as power plants, water treatment facilities, and manufacturing plants. As such, they are major targets for cyberattacks, which may lead to human casualties, severe national security impacts, and financial instability. This systematic literature review explores the existing threat modeling methodologies for ICSs and emphasizes the importance of employing methodical frameworks that cover safety, security, and privacy aspects with clear procedural guidelines. The review reveals that ICSs threat modeling often lacks validation to ensure that the used methodologies are effective in identifying and mitigating threats. This study emphasizes the need to develop and apply better validation metrics in case studies. The main goal of this review is to help cyber security researchers and practitioners in selecting a suitable threat modeling approach that facilitates the creation of ICSs with an acceptable level of security.}
}


@article{DBLP:journals/compsec/ZhaoYGH24,
	author = {Xuan Zhao and
                  Jia Yu and
                  Xinrui Ge and
                  Rong Hao},
	title = {Towards efficient Secure Boolean Range Query over encrypted spatial
                  data},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103544},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103544},
	doi = {10.1016/J.COSE.2023.103544},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhaoYGH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the development of mobile application services and geographic positioning technology has promoted the rapid growth of spatio-textual data. Boolean Range Query (BRQ) can return all objects containing all query keywords within the query range. In order to save the overhead of storage and management, users usually encrypt their spatio-textual data and outsource them to the cloud server. We focus on how to realize efficient secure boolean range query over encrypted spatio-textual data, and propose a Secure Boolean Range Query scheme (SBRQ) in this paper. To realize efficient range query over high-dimensional space, Hilbert curve is employed to reduce the dimension of space. The secure index based on the Quadtree structure is built to further improve the query efficiency, which avoids scanning the whole database, and therefore achieves sub-linear query complexity. The secure KNN algorithm is adopted to ensure data security. The security of SBRQ is analyzed from the index security and the token security, which shows that SBRQ is IND-SCPA secure with different leakage functions. Based on a series of experiments, SBRQ provides better query efficiency than other typical schemes.}
}


@article{DBLP:journals/compsec/PrasadC24,
	author = {Arvind Prasad and
                  Shalini Chandra},
	title = {PhiUSIIL: {A} diverse security profile empowered phishing {URL} detection
                  framework based on similarity index and incremental learning},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103545},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103545},
	doi = {10.1016/J.COSE.2023.103545},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/PrasadC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of the World Wide Web and the increasing sophistication of cyber threats, phishing attacks have emerged as a significant concern for individuals and organizations alike. Phishing attacks, commonly executed through deceptive URLs, aim to deceive users into divulging sensitive information, leading to financial loss, identity theft, or compromising sensitive data. It continues to pose a significant threat to individuals and organizations in today's digital landscape, necessitating the development of effective and efficient detection frameworks. This article presents PhiUSIIL, a Phishing URL detection framework based on Similarity Index and Incremental Learning. The similarity index helps effectively identify visual similarity-based attacks such as zero-width characters, homograph, punycode, homophone, bit squatting, and combosquatting attacks. The incremental learning approach allows the framework to continuously update its knowledge base with new data. Further, implementing diverse security profiles accommodates diverse security requirements of users or organizations. PhiUSIIL extracts URL features, downloads the webpage from URL to extract HTML features, and derives new features from existing information to construct a phishing URL dataset, named PhiUSIIL phishing URL dataset, encompassing 134850 legitimate and 100945 phishing URLs. The proposed phishing URL detection framework has extensively experimented with the PhiUSIIL phishing URL dataset. The constructed dataset helps to improve the detection accuracy when used during pre-training approach. PhiUSIIL achieved an accuracy of 99.24% when experimented with a fully incremental training approach and 99.79% when experimented with a pre-training approach. The experimental results show its effectiveness and ensure the framework remains effective and up-to-date against emerging and sophisticated phishing techniques.}
}


@article{DBLP:journals/compsec/PayaAGG24,
	author = {Antonio Paya and
                  Sergio Arroni and
                  Vicente Garc{\'{\i}}a{-}D{\'{\i}}az and
                  Alberto G{\'{o}}mez},
	title = {Apollon: {A} robust defense system against Adversarial Machine Learning
                  attacks in Intrusion Detection Systems},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103546},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103546},
	doi = {10.1016/J.COSE.2023.103546},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/PayaAGG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of Adversarial Machine Learning (AML) attacks is presenting a significant challenge to Intrusion Detection Systems (IDS) and their ability to detect threats. To address this issue, we introduce Apollon, a novel defense system that can protect IDS against AML attacks. Apollon utilizes a diverse set of classifiers to identify intrusions and employs Multi-Armed Bandits (MAB) with Thompson sampling to dynamically select the optimal classifier or ensemble of classifiers for each input. This approach enables Apollon to prevent attackers from learning the IDS behavior and generating adversarial examples that can evade the IDS detection. We evaluate Apollon on several of the most popular and recent datasets, and show that it can successfully detect attacks without compromising its performance on traditional network traffic. Our results suggest that Apollon is a robust defense system against AML attacks in IDS.}
}


@article{DBLP:journals/compsec/MaG24,
	author = {Zihan Ma and
                  Tianchong Gao},
	title = {Federated learning backdoor attack detection with persistence diagram},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103557},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103557},
	doi = {10.1016/J.COSE.2023.103557},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/MaG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is an emerging decentralized machine learning method that allows multiple clients to participate in a joint mission by merging the local models into a global model. While FL provides the ultimate data privacy for each participant, the service providers can hardly verify the validity of local datasets, which gives malicious clients an opportunity to undermine the functionality of the global model, i.e., perpetrate the backdoor attack. To find the potential attackers among the clients, we propose a topological data analysis tool called Persistence Homology (PH). PH reveals the correlation between topological properties and the neurons' status, which tells us whether the model is well generalized or overfits on some specific samples. We trained a classifier based on the PH features of neural network models, eventually composing a secure federated learning mechanism. The results illustrated that our method can detect malicious clients with different types of backdoor attacks with high accuracy, even under the highly unbalanced non-i.i.d. data distribution condition.}
}


@article{DBLP:journals/compsec/RibeiroGC24,
	author = {Liliana Ribeiro and
                  In{\^{e}}s Sousa Guedes and
                  Carla Sofia Cardoso},
	title = {Which factors predict susceptibility to phishing? An empirical study},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103558},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103558},
	doi = {10.1016/J.COSE.2023.103558},
	timestamp = {Sun, 06 Oct 2024 21:22:23 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RibeiroGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing is a cybercrime in active growth that victimizes a large number of individuals and organizations.}
}


@article{DBLP:journals/compsec/TahaYAMY24,
	author = {Kamal Taha and
                  Paul D. Yoo and
                  Yousof Al{-}Hammadi and
                  Sami Muhaidat and
                  Chan Yeob Yeun},
	title = {Learning a deep-feature clustering model for gait-based individual
                  identification},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103559},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103559},
	doi = {10.1016/J.COSE.2023.103559},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/TahaYAMY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gait biometrics which concern with recognizing individuals by the way they walk are of a paramount importance these days. Human gait is a candidate pathway for such identification tasks since other mechanisms can be concealed. Most common methodologies rely on analyzing 2D/3D images captured by surveillance cameras. Thus, the performance of such methods depends heavily on the quality of the images and the appearance variations of individuals. In this study, we describe how gait biometrics could be used in individuals' identification using a deep feature learning and inertial measurement unit (IMU) technology. We propose a model that recognizes the biological and physical characteristics of individuals, such as gender, age, height, and weight, by examining high-level representations constructed during its learning process. The effectiveness of the proposed model has been demonstrated by a set of experiments with a new gait dataset generated using a shoe-type based on a gait analysis sensor system. The experimental results show that the proposed model can achieve better identification accuracy than existing models, while also demonstrating more stable predictive performance across different classes. This makes the proposed model a promising alternative to current image-based modeling.}
}


@article{DBLP:journals/compsec/LilhoreDS24,
	author = {Umesh Kumar Lilhore and
                  Surjeet Dalal and
                  Sarita Simaiya},
	title = {A cognitive security framework for detecting intrusions in IoT and
                  5G utilizing deep learning},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103560},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103560},
	doi = {10.1016/J.COSE.2023.103560},
	timestamp = {Sun, 04 Aug 2024 19:48:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LilhoreDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fast growth of Internet of Things (IoT) gadgets and 5G networks has increased linkage and accessibility. However, growing interconnectivity poses new threat levels in these environments, making intrusion detection critical. In this article, we introduce a novel security framework that centres on deep learning and is tailored to support the particular risks posed by IoT channels and 5G networks. Deep neural networks are used in our proposed framework to effectively analyze network activity patterns and recognize any possible breaches in real-time communication. Deep learning autonomously learns complicated features and patterns, facilitating the proposed model's adaptability to changing threat vectors and traffic features. This research proposed a Hybrid model using enhanced light-weight CNNs architecture (MobileNetV3-SVM) and Transfer learning (TL) for intrusion detection in 5G communication. The proposed model utilizes the advantages of a multi-layered structure, which enables it to acquire knowledge from raw network information hierarchically. It provides the ability to distinguish between authentic and malicious behaviour efficiently. We have implemented several cutting-edge strategies to maximize the effectiveness of intrusion detection in environments characterized by limited availability of resources, such as those associated with the IoT and high-speed 5G networks. The proposed hybrid model processes network packets in real-time using light-weight MobileNet, reducing the computational overhead and making it suitable for IoT and 5G edge devices. In the proposed model, a MobileNetV3-SVM auto-classifies the network's intrusion images, enhancing the overall accuracy. In addition, to address the issue of limited labelled data in dynamic and constantly changing systems, we use a transfer learning strategy to deal with this issue. The proposed hybrid model and existing CNN- architectures, i.e., VGG-16, VGG-19, Efficient-Net and Inception-Net, are tested on CICIDS-2017, 2018 and UNSW-NB15 IoT 5G security datasets. During the experimental assessment, we demonstrated the strength of the proposed model by simulating a wide range of network settings and intrusion scenarios. Experimental findings show considerable improvements by the proposed hybrid model in accuracy, precision, false positive rates, Matthew's Correlation Coefficient (MCC) and AUC-ROC over existing approaches.}
}


@article{DBLP:journals/compsec/ZhuCZW24,
	author = {Erzhou Zhu and
                  Kang Cheng and
                  Zhizheng Zhang and
                  Huabin Wang},
	title = {{PDHF:} Effective phishing detection model combining optimal artificial
                  and automatic deep features},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103561},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103561},
	doi = {10.1016/J.COSE.2023.103561},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhuCZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Currently, the increasing number of high-volume phishing attacks is among the largest threats to networking environments on a daily basis. During such a severe attack, researchers prefer to extract numerous features to improve the accuracy of phishing detection. However, the redundant features that may exist in the extracted feature set may be adapted by phishing attackers, not only degrading detection performance but also shortening the effective time of the constructed detection models. To address these problems, this study proposes phishing detection based on hybrid features (PDHF), a novel phishing detection model based on a combination of optimal artificial and automatic deep learning features. The optimal artificial phishing features are obtained by removing redundant features based on the newly designed feature importance evaluation index and an improved bidirectional search algorithm. To extend the effective time of phishing detection, deep features are learned from URLs using a one-dimensional character convolutional neural network (CNN) and a disorderly quantized attention mechanism. The experimental results show that PDHF outperforms many state-of-the-art methods and achieves an accuracy of 0.9965, precision of 0.9942, recall of 0.9940, and\nF\n1\n-score of 0.9941. These results can help in the development of a security plug-in for clients, browsers, and various instant messaging tools that run on network edges, personal computers, smartphones, and other personal terminals.}
}


@article{DBLP:journals/compsec/HuangYZDYY24,
	author = {Yuxian Huang and
                  Geng Yang and
                  Hao Zhou and
                  Hua Dai and
                  Dong Yuan and
                  Shui Yu},
	title = {{VPPFL:} {A} verifiable privacy-preserving federated learning scheme
                  against poisoning attacks},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103562},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103562},
	doi = {10.1016/J.COSE.2023.103562},
	timestamp = {Thu, 16 May 2024 14:37:24 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/HuangYZDYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) allows users to train a global model without sharing original data, enabling data to be available and invisible. However, not all users are benign and malicious users can corrupt the global model by uploading poisonous parameters. Compared with other machine learning schemes, two reasons make it easier for poisoning attacks to succeed in FL: 1) Malicious users can directly poison the parameters, which is more efficient than data poisoning; 2) Privacy preserving techniques, such as homomorphic encryption (HE) or differential privacy (DP), give poisonous parameters a cover, which makes it difficult for the server to detect outliers. To solve such a dilemma, in this paper, we propose VPPFL, a verifiable privacy-preserving federated learning scheme (VPPFL) with DP as the underlying technology. The VPPFL can defend against poisoning attacks and protect users' privacy with small computation and communication cost. Specifically, we design a verification mechanism, which can verify parameters that are perturbed by DP Noise, thus finding out poisonous parameters. In addition, we provide comprehensive analysis from the perspectives of security, convergence and complexity. Extensive experiments show that our scheme maintains the detection capability compared to prior works, but it only needs 15%-30% computation cost and 7%-14% communication cost.}
}


@article{DBLP:journals/compsec/LiangHZZ24,
	author = {Chuang Liang and
                  Jie Huang and
                  Zeping Zhang and
                  Shuaishuai Zhang},
	title = {Defending against model extraction attacks with {OOD} feature learning
                  and decision boundary confusion},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103563},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103563},
	doi = {10.1016/J.COSE.2023.103563},
	timestamp = {Mon, 05 Feb 2024 20:23:23 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiangHZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have demonstrated that Deep Neural Networks (DNNs) are vulnerable to model extraction attacks. In these attacks, the malicious users utilize Out-Of-Distribution (OOD) data as attack data to query the victim model and then use the obtained predictions to create a clone model with similar accuracy to the victim model. These attacks occur because the victim models rely on the decision boundary of training data to analyze attack data and generate prediction vectors that reveal information about the decision boundary. To counter model extraction attacks, we propose a novel defense method by performing additional training on auxiliary data to form a defense model with a confused decision boundary. Specifically, when facing attack data that contain auxiliary features, the defense model can identify them and produce predictions detrimental to the construction of the decision boundary of the training data. Therefore, the defense model can reduce the accuracy of the clone model while causing minimal impact on the accuracy of benign data. Moreover, defenders can detect attack samples from malicious users and prohibit these users from accessing the victim model. We further analyze the impact of various auxiliary data on defense effectiveness and present a methodology for designing auxiliary data. Through evaluation against several extraction attacks, our approach successfully achieves a combination of decreased accuracy in clone models and detection of attack samples. Also, our defense performance outperforms existing state-of-the-art methods.}
}


@article{DBLP:journals/compsec/RustamJ24,
	author = {Furqan Rustam and
                  Anca Delia Jurcut},
	title = {Malicious traffic detection in multi-environment networks using novel
                  {S-DATE} and {PSO-D-SEM} approaches},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103564},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103564},
	doi = {10.1016/J.COSE.2023.103564},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/RustamJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid advancement of network architectures, protocols, and tools poses significant challenges to network security, especially due to the use of AI-based tools by cybercriminals. It is crucial to develop a versatile malicious traffic detection system capable of identifying attacks across diverse traffic types. This paper presents an enhanced system for detecting malicious traffic in multi-environment (M-En) networks, including IoT, SDN, and traditional IP-based traffic. Existing techniques often under-utilize diversity in network traffic, limiting their effectiveness. To address this, we propose a comprehensive approach that combines the power of Synthetic Data Augmentation TEchnique (S-DATE) and Particle Swarm Optimizer (PSO)-based Diverse-Self Ensemble Model (D-SEM). Our approach proposes the M-En dataset, a combination of three different network architectures datasets including InSDN, UNSWNB-15, and IoTID-20 that accurately represent real-world scenarios. S-DATE is then employed to address imbalanced data distribution in novel generated M-En dataset, enabling better model convergence and enhancing the detection rate of normal and abnormal traffic. Additionally, we introduce PSO-D-SEM, a novel ensemble model that leverages the diversity provided by PSO to handle the complexity of M-En networks. The PSO-D-SEM combines individual models trained on a subset of the M-En dataset, resulting in improved overall performance. The experimental results demonstrate the superiority of our enhanced system, achieving a significant accuracy score of 0.989. Further, we also deploy a statistical T-test to demonstrate the significance of the proposed PSO-D-SEM approach in comparison with state-of-the-art methods.}
}


@article{DBLP:journals/compsec/RodriguezKS24,
	author = {Jes{\'{u}}s Garc{\'{\i}}a Rodr{\'{\i}}guez and
                  Stephan Krenn and
                  Daniel Slamanig},
	title = {To pass or not to pass: Privacy-preserving physical access control},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103566},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103566},
	doi = {10.1016/J.COSE.2023.103566},
	timestamp = {Sat, 08 Jun 2024 13:15:46 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RodriguezKS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymous or attribute-based credential (ABC) systems are a versatile and important cryptographic tool to achieve strong access control guarantees while simultaneously respecting the privacy of individuals. A major problem in the practical adoption of ABCs is their transferability, i.e., such credentials can easily be duplicated, shared or lent. One way to counter this problem is to tie ABCs to biometric features of the credential holder and to require biometric verification on every use. While this is certainly not a viable solution for all ABC use-cases, there are relevant and timely use-cases, such as vaccination credentials as widely deployed during the COVID-19 pandemic. In such settings, ABCs that are tied to biometrics, which we call Biometric-Bound Attribute-Based Credentials (bb-ABC ), allow to implement scalable and privacy-friendly systems to control physical access to (critical) infrastructure and facilities.}
}


@article{DBLP:journals/compsec/VoDN24,
	author = {Hoang V. Vo and
                  Hanh Phuong Du and
                  Hoa Ngoc Nguyen},
	title = {{APELID:} Enhancing real-time intrusion detection with augmented {WGAN}
                  and parallel ensemble learning},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103567},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103567},
	doi = {10.1016/J.COSE.2023.103567},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/VoDN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes an AI-powered intrusion detection method that improves intrusion detection performance by increasing the quality of the training set and employing numerous potent AI models. Composed of the Augmented Wasserstein Generative Adversarial Networks (AWGAN) and Parallel Ensemble Learning-based Intrusion Detection (PELID) algorithms, it is referred to as APELID. First, to augment the training set quality, AWGAN combines a clustering algorithm to select representative samples from the majority classes and WGAN to generate more realistic samples from the minority classes. Second, PELID employs a weighted ensemble of multiple efficient AI models in parallel to improve the efficacy of AI-powered intrusion detection. In addition, APELID also incorporates a sandbox-based malware analyzer. It aims to enrich the indicators of compromise for preventing malicious files that have been transferred over the network. Rigorous experiments utilizing well-known datasets, such as CSE-CIC-IDS2018 and NSL-KDD, are conducted in order to evaluate APELID. Hence, it achieves an outstanding F1-score of 99.99% and 99.65% and a remarkably low false negative rate of 0.00% and 0.34%, respectively, which is superior to state-of-the-art methods. In addition, the average PELID-based detection time (i.e.,\n22.29\nμ\ns\n/\nf\nl\no\nw\n) for a single network traffic flow is fast enough to detect intrusions in real-time.}
}


@article{DBLP:journals/compsec/ChoiSLK24,
	author = {Wonwoo Choi and
                  Minjae Seo and
                  Seongman Lee and
                  Brent ByungHoon Kang},
	title = {SuM: Efficient shadow stack protection on {ARM} Cortex-M},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103568},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103568},
	doi = {10.1016/J.COSE.2023.103568},
	timestamp = {Fri, 26 Jan 2024 07:56:44 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ChoiSLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {System software written in unsafe languages such as C/C++ is susceptible to various types of security vulnerabilities. Historically, backward-edges such as return addresses have been an attractive target for control-flow hijacking attacks due to the severity and ease of exploitation. Although various backward-edge control-flow integrity schemes have been proposed over the years, most of them mainly focus on protecting desktop/server-class systems, leaving embedded systems unprotected. Even worse, bringing their defense mechanisms into resource-constrained embedded systems is undesirable because they were originally designed for high-end computing systems and thus are not directly applicable to embedded systems without compromising performance and real-time constraints.}
}


@article{DBLP:journals/compsec/YehASKXN24,
	author = {Jyh{-}haw Yeh and
                  Md Mashrur Arifin and
                  Ning Shen and
                  Ujwal Karki and
                  Yi Xie and
                  Archana Nanjundarao},
	title = {Integrity coded databases - protecting data integrity for outsourced
                  databases},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103569},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103569},
	doi = {10.1016/J.COSE.2023.103569},
	timestamp = {Fri, 26 Jan 2024 07:56:45 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/YehASKXN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, cloud storage has become a viable option for businesses to store and retrieve information. This storage service allows its clients releasing from financial burden of hiring professionals to maintain local databases. However, it comes at a cost of requiring the clients to relinquish control of their data to cloud service providers. There remains the possibility of malicious attacks to make the data no longer correct, fresh nor complete. This paper presents a novel database model called the Integrity Coded Database (ICDB), where the model allows the client to insert Integrity Codes (ICs), as well as fake tuples, to an outsourced database, run queries against the server, and verify that the queried data from the cloud is both correct, fresh and complete. We have benchmarked and evaluated six ICDB schemes with different combinations of three IC generation algorithms and two integrity verification modes.}
}


@article{DBLP:journals/compsec/ChenWZYTP24,
	author = {Shi Chen and
                  Wennan Wang and
                  Yubin Zhong and
                  Zuobin Ying and
                  Weixuan Tang and
                  Zijie Pan},
	title = {{HP-MIA:} {A} novel membership inference attack scheme for high membership
                  prediction precision},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103571},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103571},
	doi = {10.1016/J.COSE.2023.103571},
	timestamp = {Fri, 26 Jan 2024 07:56:45 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ChenWZYTP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Membership Inference Attacks (MIAs) have been considered as one of the major privacy threats in recent years, especially in machine learning models. Most canonical MIAs identify whether a specific data point was presented in the confidential training set of a neural network by analyzing its output pattern on such data point. However, these methods heavily rely on overfitting and are difficult to achieve high precision. Although some recent works, such as difficulty calibration techniques, have tried to tackle this problem in a tentative manner, identifying members with high precision is still a difficult task.}
}


@article{DBLP:journals/compsec/ParkKPC24,
	author = {Eun Hee Park and
                  Jongwoo Kim and
                  Young Soon Park and
                  Kyung Hee Chun},
	title = {Facilitating and impeding factors to insiders' prosocial rule
                  breaking in South Korea},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103572},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103572},
	doi = {10.1016/J.COSE.2023.103572},
	timestamp = {Fri, 26 Jan 2024 07:56:45 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ParkKPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Insiders’ security breach in healthcare is a serious issue both to healthcare organizations and to patients. Investigating factors affecting prosocial intention to disclose committed by insiders helps better understand and manage these breaches in healthcare. This study identifies the factors, including contextual factors, personal factors, job factors, and security countermeasures. A research model was developed by incorporating factors that affect student nurse trainees’ security breaches. A scenario-based experiment was conducted to empirically test the model, with student nurse trainees in South Korea. This study found that one contextual factor and several personal factors affect the prosocial intention to disclose.}
}


@article{DBLP:journals/compsec/WangSW24,
	author = {Wenjie Wang and
                  Yuanhai Shao and
                  Yiju Wang},
	title = {Optimization-based adversarial perturbations against twin support
                  vector machines},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103573},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103573},
	doi = {10.1016/J.COSE.2023.103573},
	timestamp = {Fri, 12 Jan 2024 22:05:28 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WangSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To investigate the adversarial perturbations to twin support vector machines (TWSVMs) and hence increase the deviation of separating hyperplanes, we establish an optimization framework for adversarial perturbations of linear TWSVMs by taking the minimal perturbation that may cause the original label changes into account. By transforming the problem into a distance problem from point to intersecting hyperplane, we respectively obtain the explicit solutions to the model for the sample-adversarial perturbations case and for the class-universal adversarial perturbations case. The explicit solution obtained, it increases the interpretability of the conclusion and provides great convenience for calculation. Some numerical experiments are conducted on datasets MNIST and CIFAR-10 with Gaussian noise and trained SVM perturbations, which shows the efficiency of our proposed adversarial perturbations model.}
}


@article{DBLP:journals/compsec/DunstonR24,
	author = {Snofy D. Dunston and
                  V. Mary Anita Rajam},
	title = {{AIPA:} An Adversarial Imperceptible Patch Attack on Medical Datasets
                  and its Interpretability},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103574},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103574},
	doi = {10.1016/J.COSE.2023.103574},
	timestamp = {Fri, 26 Jan 2024 07:56:45 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/DunstonR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning is one of the most prominent computational techniques used for automated disease detection in the medical domain. In the field of deep learning, the performance and reliability of deep learning models have been compromised due to adversarial attacks. In this work, a novel Adversarial Imperceptible Patch Attack (AIPA) is proposed. Adversarial noise, which is created as a small rectangular patch of noise, is added to an original image to synthesise the adversarial image. The Diabetic Retinopathy 2015 Data Colored Resized dataset and the SARS-COV-2 CT-Scan dataset have been used in this experimentation. It is found that for both the datasets, the adversarial image synthesised by the proposed technique is capable of misleading a customised VGG16 in terms of its classification. Interpretability plots generated using the Gradient Shap, Integrated Gradients, Occlusion and Saliency techniques are also studied. The proposed adversarial attack has influenced the interpretability plots, irrespective of whether the adversarial attack is successful in misclassification or not. When the attack is successful with respect to classification, the interpretability plots seem to favour misprediction. In addition, when the attack is unsuccessful, interpretability plots are inconsistent. The susceptibility of the deep learning models revealed by this work would be beneficial for the research community to devise better defence mechanisms and interpretability methods.}
}


@article{DBLP:journals/compsec/LiCCZ24,
	author = {Junchen Li and
                  Guang Cheng and
                  Zongyao Chen and
                  Peng Zhao},
	title = {Protocol clustering of unknown traffic based on embedding of protocol
                  specification},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103575},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103575},
	doi = {10.1016/J.COSE.2023.103575},
	timestamp = {Sun, 06 Oct 2024 21:22:22 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LiCCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Protocol Reverse Engineering (PRE) has been widely studied in recent years as the most direct approach for analyzing unknown traffic, which is predominantly generated by private protocols. With the increase in private protocols, network traffic keeps deepening the unknown, leading to supervised learning methods struggling to obtain effective models when prior knowledge is absent. Furthermore, the unknown traffic captured in the real-world environment is actually mixed, and it cannot be directly provided to PRE for further analysis due to the lack of labels associated with private protocols. To address this issue in PRE, we propose an approach for dividing the unknown traffic into clusters with the labels of different private protocols in this paper, named FEAC. Firstly, we propose the general structure of protocol specification through an extensive investigation of protocols. Then, the unknown traffic is characterized as the Protocol Specification Fusion Vector (PSFV) based on word embedding, fusing the multidimensional information of protocol specification introduced before. After that, representation learning is employed in refining the information of the PSFVs to compress the dimension, reducing the complexity of computation. Finally, we combine the refined PSFVs and DBSCAN algorithm to implement the protocol clustering of unknown traffic, improving the analysis ability of PRE on unknown traffic. We carry out comprehensive experiments for comparison on real-world network traffic, and the experimental results demonstrate that FEAC achieves the ideal clustering performance and has advantages over previous work.}
}


@article{DBLP:journals/compsec/WengLLL24,
	author = {Juanjuan Weng and
                  Zhiming Luo and
                  Dazhen Lin and
                  Shaozi Li},
	title = {Comparative evaluation of recent universal adversarial perturbations
                  in image classification},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103576},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103576},
	doi = {10.1016/J.COSE.2023.103576},
	timestamp = {Fri, 26 Jan 2024 07:56:45 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WengLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The vulnerability of Convolutional Neural Networks (CNNs) to adversarial samples has recently garnered significant attention in the machine learning community. Furthermore, recent studies have unveiled the existence of universal adversarial perturbations (UAPs) which are image-agnostic and highly transferable across different CNN models. In this survey, our primary focus revolves around the recent advancements in UAPs specifically within the image classification task. We categorize UAPs into two distinct categories, i.e., noise-based attacks and generator-based attacks, thereby providing a comprehensive overview of representative methods within each category. After presenting the computational details of these methods, we summarize their strengths and weaknesses. Next, we also summarize various loss functions employed for learning UAPs. Furthermore, we conduct a comprehensive evaluation of different loss functions within consistent training frameworks, including noise-based and generator-based. The evaluation covers a wide range of attack settings, including black-box and white-box attacks, targeted and untargeted attacks, as well as the examination of defense mechanisms. Our quantitative evaluation results yield several important findings pertaining to the effectiveness of different loss functions, the selection of surrogate CNN models, the impact of training data and data size, and the training frameworks involved in crafting universal attackers. Additionally, we provide visualizations of the perturbations. Finally, we delineate potential avenues for future research in three key areas: Crafting UAPs, Understanding UAPs, and Defending against UAPs.}
}


@article{DBLP:journals/compsec/XiaoZYYZLL24,
	author = {Xi Xiao and
                  Xiang Zhou and
                  Zhenyu Yang and
                  Le Yu and
                  Bin Zhang and
                  Qixu Liu and
                  Xiapu Luo},
	title = {A comprehensive analysis of website fingerprinting defenses on Tor},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103577},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103577},
	doi = {10.1016/J.COSE.2023.103577},
	timestamp = {Mon, 22 Jul 2024 08:24:23 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/XiaoZYYZLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Website fingerprinting (WF) enables eavesdroppers to identify the website a user is visiting by network surveillance, even if the traffic is protected by anonymous communication technologies such as Tor. To avoid this, several defense schemes have been proposed to protect users from the hazard of website fingerprinting attacks. However, some defenses are defeated by new attacks soon since they can not provide provable security guarantees; some defenses can not be deployed in practice since they incur high bandwidth overhead and latency overhead. In this paper, we survey existing WF defense schemes and make a comprehensive analysis. First, we divide WF defenses into four categories and introduce their principles and characteristics separately. Then, we point out some unreasonable settings in previous works and use a new experimental setting to evaluate WF defenses on a public dataset. We find many WF defenses are not as effective as they claim to be. Besides, we investigate the deployment of WF defenses and discuss some potential problems. Finally, we make some suggestions for researchers to design a feasible WF defense and make suggestions for users to protect their privacy.}
}


@article{DBLP:journals/compsec/ZhuCZZ24,
	author = {Zhengwei Zhu and
                  Miaojie Chen and
                  Chenyang Zhu and
                  Yanping Zhu},
	title = {Effective defense strategies in network security using improved double
                  dueling deep Q-network},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103578},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103578},
	doi = {10.1016/J.COSE.2023.103578},
	timestamp = {Fri, 26 Jan 2024 07:56:45 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhuCZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network security is a critical discipline in the contemporary digital world, encompassing diverse technologies and strategies aimed at safeguarding computer systems, networks, and data resources against malicious activities. The attackers and defenders are vital components in the context of network security and defense. Attackers employ various means to steal sensitive information, compromise system functionality, and potentially lead to substantial economic and societal damages. To address these challenges, various network attack and defense scenarios were constructed within the CybORG framework in this paper. In various scenarios, attacks were carried out by different attackers. This was done to investigate the diverse strategies employed by defenders in response to network intrusions across different scenarios. Additionally, real-time assessments of the effectiveness of defensive measures were conducted. To assess the efficacy of defense strategies, we propose DDQN-Dueling-Noisy-Experience Replay (DDQN-DNER), a deep reinforcement learning algorithm that trains the defense agent to take appropriate actions to protect the network as it transitions into various states of being under attack. Built upon the Deep Q-Network (DQN) algorithm, the DDQN-DNER method incorporates noise networks, additional experience replay, and distinguishes outputs into value functions and advantage functions, enabling the proactive updating of Q-network parameters based on optimal actions. Simultaneously, Gaussian noise is incorporated into the actions undertaken by the agents. Research findings indicate that as network complexity increases, it becomes more challenging for agents to formulate effective strategies, while lower network security enhances agent capability in strategic decision-making. Compared to the DDQN algorithm, the DDQN-DNER algorithm accelerates the convergence of the model. In all scenarios, this algorithm consistently achieves the highest scores, indicating that the defensive strategies and measures generated by the blue agent are highly effective. The blue agent can promptly detect potential threats and attacks and take appropriate actions to address and mitigate these attacks, thereby ensuring network security.}
}


@article{DBLP:journals/compsec/AhmedKH24,
	author = {Kashan Ahmed and
                  Syed Khaldoon Khurshid and
                  Sadaf Hina},
	title = {CyberEntRel: Joint extraction of cyber entities and relations using
                  deep learning},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103579},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103579},
	doi = {10.1016/J.COSE.2023.103579},
	timestamp = {Fri, 08 Mar 2024 13:22:12 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/AhmedKH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cyber threat intelligence (CTI) knowledge graph is beneficial for making robust defense strategies for security professionals. These are built from cyber threat intelligence data based on relation triples where each relation triple contains two entities associated with one relation. The main problem is that the CTI data is increasing more rapidly than expected and existing techniques are becoming ineffective for extracting the CTI information. This work mainly focuses on the extraction of cyber relation triples in an effective way using the joint extraction technique, which resolves the issues in the classical pipeline technique. Firstly, the ‘BIEOS’ tagging scheme was applied to CTI data using the joint tagging technique and then the relation triples were jointly extracted. This study utilized the attention-based RoBERTa-BiGRU-CRF model for sequential tagging. Finally, the relation triples were extracted using the relation-matching technique after matching the best suitable relation for the two predicted entities. The experimental results showed that this technique outperformed the state-of-the-art models in knowledge triple extraction on CTI data. Furthermore, a 7% increase in the F1 score also proved the effectiveness of this technique for the information extraction task on CTI data.}
}


@article{DBLP:journals/compsec/CaiXLCZ24,
	author = {Saihua Cai and
                  Han Xu and
                  Mingjie Liu and
                  Zhilin Chen and
                  Guofeng Zhang},
	title = {A malicious network traffic detection model based on bidirectional
                  temporal convolutional network with multi-head self-attention mechanism},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103580},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103580},
	doi = {10.1016/J.COSE.2023.103580},
	timestamp = {Fri, 26 Jan 2024 07:56:45 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/CaiXLCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasingly frequent network intrusions have brought serious impacts to the production and life, thus malicious network traffic detection has received more and more attention in recent years. However, the traditional rule matching-based and machine learning-based malicious network traffic detection methods have the problems of relying on human experience as well as low detection efficiency. The continuous development of deep learning technology provides new ideas to solve malicious network traffic detection, and the deep learning models are also widely used in the field of malicious network traffic detection. Compared with other deep learning models, bidirectional temporal convolutional network (BiTCN) has achieved better detection results due to its ability to obtain bidirectional semantic features of network traffic, but it does not consider the different meanings as well as different importance of different subsequence segments in network traffic sequences; In addition, the loss function used in BiTCN is the negative log likelihood function, which may lead to overfitting problems when facing multi-classification problems and data imbalance problems. To solve these problems, this paper proposes a malicious network traffic detection model based on BiTCN and multi-head self-attention (MHSA) mechanism, namely BiTCN_MHSA, it innovatively uses the MHSA mechanism to assign different weights to different subsequences of network traffic, thus making the model more focused on the characteristics of malicious network traffic as well as improving the efficiency of processing global network traffic; Moreover, it also changes its loss function to a cross-entropy loss function to penalize misclassification more severely, thereby speeding up the convergence. Finally, extensive experiments are conduced to evaluate the efficiency of proposed BiTCN_MHSA model on two public network traffic, the experimental results verify that the proposed BiTCN_MHSA model outperforms six state-of-the-arts in precision, recall, F1-measure and accuracy.}
}


@article{DBLP:journals/compsec/PrummerSB24,
	author = {Julia Pr{\"{u}}mmer and
                  Tommy van Steen and
                  Bibi van den Berg},
	title = {A systematic review of current cybersecurity training methods},
	journal = {Comput. Secur.},
	volume = {136},
	pages = {103585},
	year = {2024},
	url = {https://doi.org/10.1016/j.cose.2023.103585},
	doi = {10.1016/J.COSE.2023.103585},
	timestamp = {Sun, 04 Aug 2024 19:48:13 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/PrummerSB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybersecurity continues to be a growing issue, with cyberattacks causing financial losses and loss of productivity and reputation. Especially in an organisational setting, end-user behaviour plays an essential role in achieving a high level of cybersecurity. One way to improve end-user cybersecurity behaviour is through comprehensive training programmes.}
}
