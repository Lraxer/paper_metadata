@article{DBLP:journals/compsec/KumarS23,
	author = {Yogendra Kumar and
                  Basant Subba},
	title = {Stacking \emph{ensemble-based} {HIDS} framework for detecting anomalous
                  system processes in \emph{Windows} based operating systems using multiple
                  word embedding},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {102961},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.102961},
	doi = {10.1016/J.COSE.2022.102961},
	timestamp = {Mon, 28 Aug 2023 21:25:28 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KumarS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Globally, more than 80% of end-user devices run on Microsoft’s Windows-based operating systems. Therefore, majority of the cyber-attack payloads are crafted explicitly for exploiting various vulnerabilities that exist across different software modules of Windows-based operating systems. To address this security issue, a stacking ensemble-based HIDS framework for detecting anomalous system processes is proposed in this paper. The proposed HIDS framework analyzes the process files comprising sequence of dll instruction calls made by various application and system processes to the Windows operating system’s kernel for detecting anomalous processes. The framework initially transforms the system process files comprising sequence of dll invocations into their corresponding n-gram feature vectors. It then uses two different state-of-the-art word embedding techniques namely, Word2Vec and GloVe to learn the contextual inter-dependencies between n-gram terms of the feature vectors, and generate fixed length word embedding vectors for each n-gram terms. These learned numeric word embedding vectors along with the n-gram feature vectors corresponding to the system process files are then provided as input to train an ensemble-based classifier model comprising LSTM, Bi-LSTM, GRU and Bi-GRU based base-level classifiers, and a fully connected neural network based meta-level classifier for classification of system process files as either normal or anomalous. The proposed HIDS framework is capable of detecting wide range of Windows-based attacks with high accuracy and precision. Experimental results show that the proposed HIDS framework achieves high accuracy and precision of 91.00% and 93.30%, respectively on the benchmark binary class Australian Defense Force Academy Windows Dataset (ADFA-WD) dataset. It also achieves an accuracy and precision of 68.70% and 67.80%, respectively on the multi-class ADFA-WD dataset, which are significantly higher than other similar HIDS frameworks proposed in the literature.}
}


@article{DBLP:journals/compsec/PattnaikLN23,
	author = {Nandita Pattnaik and
                  Shujun Li and
                  Jason R. C. Nurse},
	title = {Perspectives of non-expert users on cyber security and privacy: An
                  analysis of online discussions on twitter},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103008},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103008},
	doi = {10.1016/J.COSE.2022.103008},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/PattnaikLN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many researchers have studied non-expert users’ perspectives of cyber security and privacy aspects of computing devices at home, but their studies are mostly small-scale empirical studies based on online surveys and interviews and limited to one or a few specific types of devices, such as smart speakers. This paper reports our work on an online social media analysis of a large-scale Twitter dataset, covering cyber security and privacy aspects of many different types of computing devices discussed by non-expert users in the real world. We developed two new machine learning based classifiers to automatically create the Twitter dataset with 435,207 tweets posted by 337,604 non-expert users in January and February of 2019, 2020 and 2021. We analyzed the dataset using both quantitative (topic modeling and sentiment analysis) and qualitative analysis methods, leading to various previously unknown findings. For instance, we observed a sharp (more than doubled) increase of non-expert users’ tweets on cyber security and privacy during the pandemic in 2021, compare to in the pre-COVID years (2019 and 2020). Our analysis revealed a diverse range of topics discussed by non-expert users, including VPNs, Wi-Fi, smartphones, laptops, smart home devices, financial security, help-seeking, and roles of different stakeholders. Overall negative sentiment was observed across almost all topics in all the three years. Our results indicate the multi-faceted nature of non-expert users’ perspectives on cyber security and privacy and call for more holistic, comprehensive and nuanced research on their perspectives.}
}


@article{DBLP:journals/compsec/KimJPP23,
	author = {Sung{-}Kyung Kim and
                  Eun{-}Tae Jang and
                  Hanjin Park and
                  Ki{-}Woong Park},
	title = {Pwnable-Sherpa: An interactive coaching system with a case study of
                  pwnable challenges},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103009},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103009},
	doi = {10.1016/J.COSE.2022.103009},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/KimJPP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To improve their cybersecurity knowledge and skills, students participate in a competitive game called capture the flag (CTF). CTF is used as an educational tool to improve students’ cybersecurity competency by solving challenges. As system vulnerabilities are the leading cause of cyberattacks on critical systems, cybersecurity personnel with knowledge and skills to detect system vulnerabilities are increasingly in demand. In this context, the importance of challenges concerning system vulnerabilities, such as pwnable, is gradually increasing in CTF competitions. Unlike other CTF challenges, solving a pwnable challenge requires considerable knowledge and skill. However, traditional evaluation methods in CTF (i.e., pass or non-pass) provide limited feedback regarding knowledge and skill gaps. To investigate this issue, we analyzed the results of the CTF competitions held by our research team over the past three years (2017, 2018, and 2020). Our analysis revealed the necessity for a new evaluation system that can provide detailed feedback to students, while reducing the grading burden on educators. Thus, to provide detailed feedback, we propose a cybersecurity training platform, Pwnable-Sherpa, which sets three detailed evaluation points for a given pwnable challenge. In addition, we designed our training platform with a multi-container architecture and an LLVM dummy pass, thereby saving time by grading each detailed assessment simultaneously rather than sequentially.}
}


@article{DBLP:journals/compsec/AzzamPPN23,
	author = {Mazen Azzam and
                  Liliana Pasquale and
                  Gregory M. Provan and
                  Bashar Nuseibeh},
	title = {Forensic readiness of industrial control systems under stealthy attacks},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103010},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103010},
	doi = {10.1016/J.COSE.2022.103010},
	timestamp = {Tue, 21 Mar 2023 21:08:32 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/AzzamPPN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyberattacks against Industrial Control Systems (ICS) can have harmful physical impacts. Investigating such attacks can be difficult, as evidence could be lost to physical damage. This is especially true with stealthy attacks; i.e., attacks that can evade detection. In this paper, we aim to engineer Forensic Readiness (FR) in safety-critical, geographically distributed ICS, by proactively collecting potential evidence of stealthy attacks. The collection of all data generated by an ICS at all times is infeasible due to the large volume of such data. Hence, our approach only triggers data collection when there is the possibility for a potential stealthy attack to cause damage. We determine the conditions for such an event by performing predictive, model-based, safety checks. Furthermore, we use the geographical layout of the ICS and the safety predictions to identify data that is at risk of being lost due to damage, i.e., relevant data. Finally, to reduce the control performance overhead resulting from real-time data collection, we select a subset of relevant data to collect by performing a trade-off between expected impact of the attack and the estimated cost of collection. We demonstrate these ideas using simulations of the widely-used Tennessee–Eastman Process (TEP) benchmark. We show that the proposed approach does not miss relevant data and results in a reduced control performance overhead compared to the case when all data generated by the ICS is collected. We also showcase the applicability of our approach in improving the efficiency of existing ICS forensic log analysis tools.}
}


@article{DBLP:journals/compsec/AlghamdiB23,
	author = {Rubayyi Alghamdi and
                  Martine Bella{\"{\i}}che},
	title = {A cascaded federated deep learning based framework for detecting wormhole
                  attacks in IoT networks},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103014},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103014},
	doi = {10.1016/J.COSE.2022.103014},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/AlghamdiB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growth of the internet over the years has resulted in massive use and spread of the Internet of Things (IoT) in many areas. From home networks to industrial IoT, from medicine to transportation, IoT is everywhere. This massive usage has come with a price as attackers make use of sophisticated techniques and malware to target these heterogeneous IoT networks. Moreover, the low processing power and minimal resources of the IoT devices make security and privacy a major challenge. This weakness has motivated attackers to target IoT networks in a wide variety of ways by launching different types of attacks. One such kind of attack is the Wormhole attack which belongs to the family of routing attacks and disturbs the normal routing and flow of network packets in the IoT network. Many techniques involving rule-based, trust-based, machine learning-driven and deep learning assisted have been devised to counter wormhole attacks. The proposed research work presents a cascaded wormhole detection technique for IoT networks which is based on the federated deep learning technique and a Dynamic Trust Factor (DTF). The DTF is based on two trust attributes, whereas Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM) deep learning models have been trained using the federated approach, which guarantees data security and privacy at the node level. The proposed technique achieves the accuracy of 96% and is lightweight due to the cascaded and federated learning approach.}
}


@article{DBLP:journals/compsec/LiXZYC23,
	author = {Xin Li and
                  Yang Xin and
                  Hongliang Zhu and
                  Yixian Yang and
                  Yuling Chen},
	title = {Cross-domain vulnerability detection using graph embedding and domain
                  adaptation},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103017},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103017},
	doi = {10.1016/J.COSE.2022.103017},
	timestamp = {Mon, 06 Nov 2023 17:16:40 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/LiXZYC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vulnerability detection is an effective means to maintain cyberspace security. Machine learning methods have risen much attention in software security due to their advantage of accuracy and automation. However, current researches mainly focus on in-domain vulnerability detection where the training data and test data belong to the same domain. Due to application scenarios, coding habits, and other factors, vulnerabilities in different software projects may obey different probability distributions. This discrepancy compromises the performance of machine learning methods when they are applied to a brand-new project. To address this cold start problem, we propose a cross-domain vulnerability detection framework using graph embedding and deep domain adaption (VulGDA). It works in a variety of cross-domain fashions, including the Zero-Shot fashion that no labeled data in the target domain is available for training. VulGDA is decomposed to graph embedding and domain adaptation. At the graph embedding stage, we transform the samples in source code into graph representations where elements are directly concatenated according to their syntactic and semantic relationships. Then, we aggregate information from neighbors and edges defined in the graph into real-valued vectors. By graph embedding, VulGDA extracts comprehensive vulnerability features and compromises the challenge of long-term dependency. Aiming at the discrepancy between training data and test data, domain adaption is used to train a feature generator. This feature generator maps the graph embedding to a “deep” feature that is discriminative for vulnerability detection, and invariant to the shift between domains. We perform a systematic experiment to validate the effectiveness of VulGDA. The results show that combining graph embedding and deep domain adaptation promotes VulGDA's performance in cross-domain vulnerability detection. Compared with the state-of-the-art methods, our method has better performance under the cold start condition.}
}


@article{DBLP:journals/compsec/GuanLXLG23,
	author = {Zhong Guan and
                  Chang Liu and
                  Gang Xiong and
                  Zhen Li and
                  Gaopeng Gou},
	title = {FlowTracker: Improved flow correlation attacks with denoising and
                  contrastive learning},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103018},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103018},
	doi = {10.1016/J.COSE.2022.103018},
	timestamp = {Tue, 07 May 2024 20:21:11 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/GuanLXLG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tor is the most widely used anonymous network which provides anonymity by using proxy nodes to route data. However, many researches have proved that flow correlation attacks can break the anonymity of users’ communication relationships: once attackers have access to the ingress and egress traffic flows at both ends of the network, they will find the specific user who is visiting a monitored Internet service by observing the traffic shape. Existing flow correlation attacks have limited effects because of insufficient traffic shape features, network noise influence and lack of differentiated learning on unrelated flows. In this paper, we propose an improved flow correlation attacking model named FlowTracker which contains four modules: In flow cumulative representation module, raw and normalized cumulative sequences are combined to construct robust traffic shape features. In noise resistant mapping module, stacked auto-encoders are adopted to learn the mapping relationship between related ingress and egress cumulative representations and filter out the network noise. Moreover, we leverage contrast learning in distance optimization module to generate the optimized representation in which difference between unrelated representations is amplified, further reducing the false correlation rate with similar but unrelated flows. Finally, the target flow is reported through a multi-layer decision process in the hierarchical judgment module. We evaluate FlowTracker and other advanced comparison methods on the public and self-built datasets with the more realistic unidirectional setting, experiment results demonstrate that FlowTracker has the highest attacking success rate under general and targeted scenarios, especially when the traffic shape is seriously destroyed by traffic obfuscation.}
}


@article{DBLP:journals/compsec/ZhangJYWK23,
	author = {Wenfang Zhang and
                  Heng Jiao and
                  Zhuoqun Yan and
                  Xiaomin Wang and
                  Muhammad Khurram Khan},
	title = {Security analysis and improvement of a public auditing scheme for
                  secure data storage in fog-to-cloud computing},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103019},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103019},
	doi = {10.1016/J.COSE.2022.103019},
	timestamp = {Sat, 30 Sep 2023 10:07:34 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangJYWK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human society has drastically changed as a result of the widespread application of Internet of Things (IoT) technology, particularly in various industrial fields. In spite of the advantages brought by IoT services, the underlying security challenges cannot be underestimated. Cloud-based IoT data collection poses a number of challenges, including how to ensure its integrity. In order to address this issue, Tian et al. have proposed a fog-to-cloud computing-based public auditing scheme in IoT scenarios, which provides the data-privacy preserving mechanism and tag transformation strategy. However, in this paper, we show that Tian et al.’s scheme fails to achieve soundness, an essential security property, by giving two attacks. In the first attack, the malicious cloud server can delete all the data and then deceive the Third Party Auditor (TPA) into believing that the data is well-preserved. In the second attack, the malicious cloud server can modify the outsourced data and then deceive TPA into believing that all the data is kept intact. We further provide a simple but effective solution for Tian et al.’s scheme to resist the above-mentioned attacks. Security analysis and performance evaluation are also given to demonstrate the robustness and high efficiency of the improved scheme.}
}


@article{DBLP:journals/compsec/JohnstonGBCSWS23,
	author = {Allen C. Johnston and
                  Paul Michael Di Gangi and
                  France B{\'{e}}langer and
                  Robert E. Crossler and
                  Mikko T. Siponen and
                  Merrill Warkentin and
                  Tripti Singh},
	title = {Seeking rhetorical validity in fear appeal research: An application
                  of rhetorical theory},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103020},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103020},
	doi = {10.1016/J.COSE.2022.103020},
	timestamp = {Fri, 10 Feb 2023 23:35:03 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/JohnstonGBCSWS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A significant focus of behavioral security research has been on understanding employees’ motives for protecting sensitive assets. To date, theorizing efforts in this space have focused on appraisal processes and nomological models that are designed to capture the responses to the security threats articulated within fear appeals. Because fear appeals are persuasive messages used to generate a sense of urgency about a specific threat that influences protective information security behaviors, they are an important focus in behavioral security research. However, we suggest that theoretical guidance is needed to facilitate further research in this area. We argue that ultimately, fear appeals are treatments intended to serve as catalysts of behavioral change. Therefore, fear appeals should have rhetorical validity, which is a specialized form of ecological validity in which contextualization has been included to ensure that the language embedded in the stimulus is consistent with the threat environment and the expectations of its audience. The rhetorical validity of a fear appeal should account for its exigence, the audience, and any constraints that shape the presentation and reception of the discourse. Using the illustrative example of a well-known behavioral security theory, protection motivation theory, this study provides a framework for behavioral security scholars in designing fear appeals that have rhetorical validity.}
}


@article{DBLP:journals/compsec/SunLL23,
	author = {Yanan Sun and
                  Hengjian Li and
                  Nianqiang Li},
	title = {A novel cancelable fingerprint scheme based on random security sampling
                  mechanism and relocation bloom filter},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103021},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103021},
	doi = {10.1016/J.COSE.2022.103021},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/SunLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The existing cancellable fingerprint template based on the bloom filter either suffers from a lack of template security or low recognition performance. To solve the above problems, the paper proposes a novel cancelable fingerprint protection scheme based on a random sampling mechanism and relocation bloom filter. The security matrix is generated by a random sampling mechanism to increase the security and recognition accuracy of the scheme. The structure of a random sampling mechanism is as follows. Firstly, we use the key management system to generate keys and a chaotic matrix with randomness. Secondly, the key is used as a random initial address to extract overlapping feature sub-blocks from fingerprint features. Then the feature sub-blocks are combined to generate a feature matrix. Therefore, the feature matrix has richer fingerprint information than the original fingerprint features. Finally, a security matrix is generated by the XOR fusion of features matrix and chaotic matrix. Furthermore, we designed a relocation bloom filter with a parallel structure, which provides a way to avoid the decrease in performance caused by hash conflicts. What is more, it increased the security of the scheme that the relocatable bloom uses an irreversible function mapping function to transform the security matrix into a cancelable fingerprint template. The experimental results demonstrate that this scheme has state-of-the-art accuracy performance on benchmark FVC2002 and FVC2004 fingerprint databases. The security analysis shows that the scheme meets the cancellable biometrics protection scheme criteria and has higher security.}
}


@article{DBLP:journals/compsec/Al-SarairehA23,
	author = {Jaafer Al{-}Saraireh and
                  Mohammad Rasool AlJa'afreh},
	title = {Keystroke and swipe biometrics fusion to enhance smartphones authentication},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103022},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103022},
	doi = {10.1016/J.COSE.2022.103022},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/Al-SarairehA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Several authentication techniques are required to preserve smartphone users' privacy. Part of these authentication mechanisms are based on Keystroke Dynamics (KD) or Swipe Dynamics (SD); however, these mechanisms have performance challenges due to the following; limited capability in handling user behavioral variations, inefficient feature extraction, and alternate usages that are not restricted to a specific method typing or swiping. This work presents an improved smartphone continuous authentication model by integrating free text-based KD and SD. The proposed model adopts feature-level fusion by concatenating free-text KD and SD features. This Feature level fusion was evaluated based on a comprehensive and benchmark dataset and Random Forest (RF) classifier. Results have confirmed the proposed model's performance, in which accuracy was 99.98%, with the lowest Equal Error Rate (EER) rate of 0.02% based on multi-class classification.}
}


@article{DBLP:journals/compsec/WangJPHL23,
	author = {Yan Wang and
                  Peng Jia and
                  Xi Peng and
                  Cheng Huang and
                  Jiayong Liu},
	title = {BinVulDet: Detecting vulnerability in binary program via decompiled
                  pseudo code and BiLSTM-attention},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103023},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103023},
	doi = {10.1016/J.COSE.2022.103023},
	timestamp = {Sun, 31 Dec 2023 00:37:07 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WangJPHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Static detection of security vulnerabilities in binary programs is an important research field in software supply chain security. However, existing vulnerability detection methods based on code similarity can only detect known vulnerabilities. Vulnerability features generated by vulnerability pattern-based detection methods are low robust due to the influence of manually defined patterns, compiler diversity, and irrelevant function instructions. In this paper, we propose BinVulDet, which is a binary level vulnerability detection tool for accurate known and unknown vulnerability detection. BinVulDet uses decompilation techniques to obtain pseudo code containing high-level semantic information against the impact of compilation diversity. Then the program slicing technique is used to extract the statements with data dependencies and control dependencies related to the vulnerability. A BiLSTM-attention neural network is used to extract rich contextual semantic information from slice codes to generate more robust vulnerability patterns to detect vulnerabilities. The experimental results show that BinVulDet outperforms the state-of-the-art binary vulnerability detection methods. The FPR and FNR of BinVulDet are 1.04% and 0.89% on average, respectively, which are 3.93% and 22.86% lower than the baseline model on average. BinVulDet can effectively against the influence of compilation diversity and successfully be used for real-world vulnerability detection by being evaluated in three CVE vulnerability projects.}
}


@article{DBLP:journals/compsec/CaoCHHY23,
	author = {Yungui Cao and
                  Jiazhen Chen and
                  Liqing Huang and
                  Tianqian Huang and
                  Feng Ye},
	title = {Three-classification face manipulation detection using attention-based
                  feature decomposition},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103024},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103024},
	doi = {10.1016/J.COSE.2022.103024},
	timestamp = {Fri, 20 Jan 2023 20:27:09 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/CaoCHHY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face manipulation detection has become a recent research hotpot, and many detection methods have been proposed. Most existing detection methods treat face manipulation detection as a vanilla binary classification problem. However, according to the visual effects of facial manipulation, face manipulation approaches are divided into face replacement and face reenactment. In this study, we propose a three-classification face manipulation detection method(TFMD). To implement three-classification face manipulation detection, we introduce a new face forgery feature representation, where the face forgery features are jointly represented by the identity-changing features and the face real-fake features. To decompose the face forgery features into the identity-changing features and the face real-fake features, we design an attention-based feature decomposition module (AFDM). Moreover, we extract high-frequency noise features from the shallow features of the RGB stream to enrich high-frequency information. Through extensive experiments on two datasets, FaceForensics++ and Celeb-DF, we achieve state-of-the-art performance and demonstrate the effectiveness and robustness of our proposed method.}
}


@article{DBLP:journals/compsec/ZhangTKSSKST23,
	author = {Jie Zhang and
                  Min{-}Yen Tsai and
                  Kotcharat Kitchat and
                  Min{-}Te Sun and
                  Kazuya Sakai and
                  Wei{-}Shinn Ku and
                  Thattapon Surasak and
                  Tipajin Thaipisutikul},
	title = {A secure annuli {CAPTCHA} system},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103025},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103025},
	doi = {10.1016/J.COSE.2022.103025},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangTKSSKST23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many websites and applications rely on CAPTCHA for protection from bot attacks. Otherwise, users and businesses will be exposed to risks. Although several different CAPTCHA systems have been proposed, the development of deep learning algorithms allows attackers to create more efficient and accurate attack methods. Many studies have shown that existing CAPTCHA systems are no longer safe, especially text-based CAPTCHA. To resolve this issue, a simple, secure, and effective annuli CAPTCHA system is proposed in this paper. In the proposed system, the annuli CAPTCHA image containing the overlapping of circles and ovals is randomly generated. The user wishing to gain access to the system is required to answer correctly the total number of circles and ovals in the image to prove that he/she is not a bot. The security of our proposed CAPTCHA system is verified by three attack methods. Additionally, the usability survey of our CAPTCHA system conducted by anonymous questionnaires shows that our system is user friendly. In other words, the proposed system maintains a high level of usability under the premise of high security. Compared with the existing CAPTCHA system, our CAPTCHA system is significantly better in terms of security, usability and ease of implementation.}
}


@article{DBLP:journals/compsec/DongMMSJGT23,
	author = {Xingbo Dong and
                  Zhihui Miao and
                  Lan Ma and
                  Jiajun Shen and
                  Zhe Jin and
                  Zhenhua Guo and
                  Andrew Beng Jin Teoh},
	title = {Reconstruct face from features based on genetic algorithm using {GAN}
                  generator as a distribution constraint},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103026},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103026},
	doi = {10.1016/J.COSE.2022.103026},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/DongMMSJGT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face recognition based on deep convolutional neural networks (CNN) shows superior accuracy performance attributed to the high discriminative features extracted. Yet, the security and privacy of the extracted features from deep learning models (deep features) have often been overlooked. This paper proposes the reconstruction of face images from deep features without accessing the CNN network configurations as a constrained optimization problem. Such optimization minimizes the distance between the features extracted from the original face image and the reconstructed face image. Instead of directly solving the optimization problem in the image space, we innovatively reformulate the problem by looking for a latent vector of a generative adversarial networks (GAN) generator, then use it to generate the face image. The GAN generator serves a dual role in this novel framework, i.e., face distribution constraint of the optimization goal and a face generator. To solve this optimization problem, We present an optimization approach based on a Genetic Algorithm. On top of the novel optimization task, we also propose an attack pipeline to impersonate the target user based on the generated face image. Our results show that the generated face images can achieve a state-of-the-art successful attack rate of 99.33% on Labeled Faces in the Wild (LFW) under type-I attack at a false accept rate of 0.1%. Our work sheds light on biometric deployment to meet privacy-preserving and security policies.}
}


@article{DBLP:journals/compsec/AlanaziMC23,
	author = {Manar Alanazi and
                  Abdun Mahmood and
                  Mohammad Jabed Morshed Chowdhury},
	title = {{SCADA} vulnerabilities and attacks: {A} review of the state-of-the-art
                  and open issues},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103028},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103028},
	doi = {10.1016/J.COSE.2022.103028},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/AlanaziMC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Supervisory control and data acquisition (SCADA) serves as the backbone of several critical infrastructures, including water supply systems, oil pipelines, transportation and electricity. It accomplishes essential functions, such as monitoring data from pumps, valves and transmitters. Across different generations, SCADA has undergone a significant evolution from a typically isolated environment to a highly interconnected network. Although this conversion has benefits for SCADA, such as enhanced performance efficiency and the cost reduction of heavy equipment, it has made SCADA more vulnerable to various cyber-attacks. Several SCADA security approaches are still provided by IT-based systems that are possibly not efficient enough to deflect the risks and threats originating from SCADA field operations. As a result, it is critically important to analyse cyber risks associated with the industrial SCADA system. The goal of this survey is to explore the security vulnerabilities of SCADA systems and classify the threats accordingly. In this project, we initially reviewed SCADA systems from different scopes, including architecture, vulnerabilities, attacks, intrusion detection techniques (IDS) and testbeds. We proposed taxonomies of vulnerabilities, attacks, IDS and testbeds according to predefined criteria. We concluded the survey by highlighting the research challenges and open issues for future research in the field of SCADA security.}
}


@article{DBLP:journals/compsec/HouNZFZ23,
	author = {Lihe Hou and
                  Weiwei Ni and
                  Sen Zhang and
                  Nan Fu and
                  Dongyue Zhang},
	title = {Wdt-SCAN: Clustering decentralized social graphs with local differential
                  privacy},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103036},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103036},
	doi = {10.1016/J.COSE.2022.103036},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/HouNZFZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social network users scatter geographically, where each maintains a self-centered star graph (i.e., relationships directed related to them). Clustering on such subgraphs can provide valuable insights into the graph structure. Despite its significance, one could not simply collect the unfettered star graph information from users due to privacy concerns. Local differential privacy (LDP), as an emerging privacy model, has been widely adopted in privacy-preserving data collection and analysis. Most existing LDP-based graph analysis methods encode star graphs via adjacency bit vector and suffer from heavy noise due to the sparsity of social networks. Besides, they cluster all nodes indifferently yet ignore that nodes with different degrees are affected differently by noise injection, making the clustering results unsatisfactory. To tackle these issues, we propose Wdt-SCAN, a degree vector based private graph clustering scheme to achieve high quality clustering without compromising individual privacy. Concretely, we design a degree vector encoding model with optimal length to represent star graphs, which reduces the massive noise caused by sparsity. To improve the clustering accuracy, a two-round agglomeration-based decentralized graph clustering method is proposed, which partitions nodes into core nodes and ordinary nodes, and then clusters core nodes to form a graph skeleton as prior knowledge to alleviate the impact of noise injection on ordinary nodes. Theoretical analysis and experiments on real-world datasets show that our proposed method can obtain desirable clustering result while satisfying edge LDP.}
}


@article{DBLP:journals/compsec/VrhovecBM23,
	author = {Simon Vrhovec and
                  Igor Bernik and
                  Blaz Markelj},
	title = {Explaining information seeking intentions: Insights from a Slovenian
                  social engineering awareness campaign},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103038},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103038},
	doi = {10.1016/J.COSE.2022.103038},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/VrhovecBM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The human factor remains one of the key challenges in cybersecurity despite effective technical countermeasures in place. This study aims to determine what motivates individuals to seek information about social engineering by investigating the determinants of behavioral intention to follow the materials of a social engineering awareness campaign in Slovenia. A quantitative survey of individuals in Slovenia (\nN\n=\n542\n) aged 15 or older was administered with participants recruited through University of Maribor students. Data were collected on constructs related to the protection motivation theory (PMT) and the theory of planned behavior (TPB) as well as privacy concerns and perceived performance of authorities. The survey instrument was validated with a confirmatory factor analysis. Covariance-based structural equation modeling (CB-SEM) was used to determine relationships between constructs and analysis of differences between students and employed individuals. Results indicate perceived threat, subjective norm, attitude toward behavior and authorities performance are all significant predictors of behavioral intention. The associations between perceived threat and behavioral intention, and privacy concern and attitude towards behavior was not significant among employed individuals. Among students, trust in authorities was not a significant predictor of authorities performance. This study has several implications. The results of this study suggest that fear appeals may be effective in motivating individuals to seek information about social engineering attacks thus improving the effectiveness of awareness campaigns. They also offer some insights into how to improve messaging towards the target populations. Messaging emphasizing perceived threat may directly increase information seeking intention while messaging emphasizing coping with social engineering may do so indirectly through attitude towards behavior. This study also indicates that messaging should be tailored to the target population (e.g., messaging emphasizing perceived threat may be much less effective for employed individuals than students).}
}


@article{DBLP:journals/compsec/ZhangZRXC23,
	author = {Zhiqiu Zhang and
                  Tianqing Zhu and
                  Wei Ren and
                  Ping Xiong and
                  Kim{-}Kwang Raymond Choo},
	title = {Preserving data privacy in federated learning through large gradient
                  pruning},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103039},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103039},
	doi = {10.1016/J.COSE.2022.103039},
	timestamp = {Wed, 06 Sep 2023 17:12:33 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ZhangZRXC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In federated learning, the server trains a global learning model based on gradient information shared by multiple clients; thus, protecting client data privacy. However, it has been shown that training data can be reconstructed from the shared gradients, which can result in serious privacy breaches (e.g., also known as gradient-based inversion attacks). Popular privacy-preserving methods include those that are perturbation-related, such as differential privacy. However, these methods can result in high utility loss. In this paper, we reveal that large magnitude gradients play an important role in the image reconstructing process, and thus propose two pruning based defense mechanisms (i.e., SLGP and RLGP) for different model architectures. As only very few gradients have been affected, the utility can be maintained. To demonstrate efficiency, We evaluate the impact of our mechanisms on preventing the reconstruction of input images on various model architectures and datasets using state-of-the-art attack methods. The reconstructed images obtained using the gradient processed by our method are unrecognizable while maintaining the original performance of the models.}
}


@article{DBLP:journals/compsec/LeeCL23,
	author = {Sunwoo Lee and
                  Wonsuk Choi and
                  Dong Hoon Lee},
	title = {The vibration knows who you are! {A} further analysis on usable authentication
                  for smartwatch users},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103040},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103040},
	doi = {10.1016/J.COSE.2022.103040},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/LeeCL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {These days, smartwatches are becoming more common and can even operate in stand-alone mode. This increases the need for smartwatches to authenticate users independently without paired smartphones. Currently, password or pattern-based methods can authenticate the smartwatch users in stand-alone mode, but these methods are known to be vulnerable to simple attacks such as shoulder-surfing and password dictionary attacks. In addition, biometric-based methods, which are expected to release on smartwatches in the near future, require inconvenient user interaction or special sensors for measurement. In light of this, we propose a smartwatch user authentication method that does not require any additional sensors or user interaction. Based on the fact that the human body structure affects the way vibrations are absorbed, reflected, and propagated, we designed a smartwatch user authentication method based on a challenge-response structure using vibrations. In our method, a challenge is a set of fresh random vibrations, which are provided by default in current smartwatches, and a response to the challenge is measured by built-in gyroscope and accelerometer sensors. Our earlier study demonstrated that commercial smartwatch users can be authenticated with a low equal error rate (EER) of 1.37 %. In this paper, we extended the analysis of our method on various vibration types by using a prototype setup. As a result, we discovered an outperformed vibration type for user authentication. We conducted further analysis for users with heavier body weights as these individuals are more vulnerable to a not-in-wear attack. Finally, we conducted more advanced impersonation attacks on test participants with one or more similar physical indicators to demonstrate that our method is also secure against a wider range of more complex attacks.}
}


@article{DBLP:journals/compsec/FrankJR23,
	author = {Muriel Frank and
                  Lennart Jaeger and
                  Lukas Manuel Ranft},
	title = {Using contextual factors to predict information security overconfidence:
                  {A} machine learning approach},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103046},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103046},
	doi = {10.1016/J.COSE.2022.103046},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/FrankJR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite increasing investments in workforce security education and training, many organizations still face the challenge that their employees overestimate their knowledge and abilities to prevent security incidents. Since these misperceptions regarding one's competencies may entail serious consequences for business, the present paper investigates contextual influences on overconfidence susceptibility. For this purpose, we first surveyed more than 5,500 employees of an international pharmaceutical company and then applied machine learning techniques to classify them according to their likelihood of exhibiting overconfidence. Results demonstrate the significance of factors like training commitment, salary band, team size, and job experience are helping managers to adjust and improve awareness measures.}
}


@article{DBLP:journals/compsec/RaoCA23,
	author = {Siddharth Prakash Rao and
                  Hsin Yi Chen and
                  Tuomas Aura},
	title = {Threat modeling framework for mobile communication systems},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103047},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103047},
	doi = {10.1016/J.COSE.2022.103047},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/RaoCA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a domain-specific threat-modeling framework for the cellular mobile networks. We survey known attacks against mobile communication and organize them into attack phases, tactical objectives, and techniques. The Bhadra framework aims to provide a structured way to analyze and communicate threats on a level that abstracts away the technical details but still provides meaningful insights into the adversarial behavior. Our goals are similar to existing threat modeling frameworks for enterprise information systems, but with a focus on mobile operator networks. The framework fills a gap that has existed in tools and methodology for sharing of threat intelligence within and between organizations in the telecommunications industry. The paper includes concrete case studies of applying the framework. It can also be read as a survey of attacks against mobile networks.}
}


@article{DBLP:journals/compsec/XuLGLBCWWLWML23,
	author = {Guangquan Xu and
                  Wenqing Lei and
                  Lixiao Gong and
                  Jian Liu and
                  Hongpeng Bai and
                  Kai Chen and
                  Ran Wang and
                  Wei Wang and
                  Kaitai Liang and
                  Weizhe Wang and
                  Weizhi Meng and
                  Shaoying Liu},
	title = {{UAF-GUARD:} Defending the use-after-free exploits via fine-grained
                  memory permission management},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103048},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103048},
	doi = {10.1016/J.COSE.2022.103048},
	timestamp = {Fri, 01 Dec 2023 09:55:17 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/XuLGLBCWWLWML23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The defense of Use-After-Free (UAF) exploits generally could be guaranteed via static or dynamic analysis, however, both of which are restricted to intrinsic deficiency. The static analysis has limitations in loop handling, optimization of memory representation and constructing a satisfactory test input to cover all execution paths. While the lack of maintenance of pointer information in dynamic analysis may lead to defects that cannot accurately identify the relationship between pointers and memory. In order to successfully exploit a UAF vulnerability, attackers need to reference freed memory. However, main existing schemes barely defend all types of UAF exploits because of the incomplete check of pointers. To solve this problem, we propose UAF-GUARD to defend against the UAF exploits via fine-grained memory permission management. Specially, we design two key data structures to enable the fine-grained memory permission management to support efficient relationship search for pointers and memory, which is the key design of our defending scheme against UAF exploits. In addition, UAF-GUARD can precisely locate the position of UAF vulnerabilities, so that malicious programs can be terminated in the place where the abnormality is discovered. We implement UAF-GUARD on a 64-bit Linux system, and further use UAF-GUARD to transform a program into a suitable version that can defend against UAF vulnerabilities exploits. Compared with main existing schemes UAF-GUARD is able to effectively and efficiently defend against all the three types of UAF exploits with acceptable space overhead (26.4% for small programs and 0.3% for large programs) and time complexity (21.9%).}
}


@article{DBLP:journals/compsec/KhanIMJ23,
	author = {Naurin Farooq Khan and
                  Naveed Ikram and
                  Hajra Murtaza and
                  Mehwish Javed},
	title = {Evaluating protection motivation based cybersecurity awareness training
                  on Kirkpatrick's Model},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103049},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103049},
	doi = {10.1016/J.COSE.2022.103049},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KhanIMJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybersecurity behavioral literature has a significant number of studies on training and awareness. However, there is lack of theoretical underpinnings in developing intervention to allow for positive behavioral change and evaluating them. The evaluation of theory based cybersecurity training warrants the use of program evaluation techniques.}
}


@article{DBLP:journals/compsec/BitzerHLOSS23,
	author = {Michael Bitzer and
                  Bj{\"{o}}rn H{\"{a}}ckel and
                  Daniel Leuthe and
                  Joshua Ott and
                  Bastian Stahl and
                  Jacqueline Strobel},
	title = {Managing the Inevitable - {A} Maturity Model to Establish Incident
                  Response Management Capabilities},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103050},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103050},
	doi = {10.1016/J.COSE.2022.103050},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/BitzerHLOSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although the ongoing digital transformation offers new opportunities for organizations, more emphasis on information security is needed due to the evolving cyber-threat landscape. Despite all preventive measures, security incidents cannot entirely be mitigated. Organizations must establish incident response management to treat inevitable incidents in a structured manner and under considerable time pressure. If not handled, incidents can result in reputational or financial losses and disrupt business continuity. Especially organizations that have not addressed incident response management extensively need to understand which capabilities are required to develop their incident response management. However, research still lacks a practice-grounded and socio-technical conceptualization of those capabilities and their development. For such challenges, maturity models have proven valuable in practice and research. This paper follows a design science research approach to develop an incident response management maturity model (IRM3) closely aligned with practice requirements under a socio-technical lens. Iteratively applying and evaluating the IRM3 with seven real-world organizations leverages its comprehensive view based on four focus areas and 29 capability dimensions to understand which capabilities organizations need to approach incident response management. Building on existing research, this work provides a comprehensive perspective on incident response management and its associated capabilities. For practitioners, especially in organizations with initial incident response maturity, the IRM3 offers descriptive value when used as a status quo assessment tool and prescriptive value by outlining capabilities for successful incident response management.}
}


@article{DBLP:journals/compsec/ChatzoglouKKKG23,
	author = {Efstratios Chatzoglou and
                  Vasileios Kouliaridis and
                  Georgios Kambourakis and
                  Georgios Karopoulos and
                  Stefanos Gritzalis},
	title = {A hands-on gaze on {HTTP/3} security through the lens of {HTTP/2}
                  and a public dataset},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103051},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103051},
	doi = {10.1016/J.COSE.2022.103051},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ChatzoglouKKKG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Following QUIC protocol ratification on May 2021, the third major version of the Hypertext Transfer Protocol, namely HTTP/3, was published around one year later in RFC 9114. In light of these consequential advancements, the current work aspires to provide a full-blown coverage of the following issues, which to our knowledge have received feeble or no attention in the literature so far. First, we provide a complete review of attacks against HTTP/2, and elaborate on if and in which way they can be migrated to HTTP/3. Second, through the creation of a testbed comprising the at present six most popular HTTP/3-enabled servers, we examine the effectiveness of a quartet of attacks, either stemming directly from the HTTP/2 relevant literature or being entirely new. This scrutiny led to the assignment of at least one CVE ID with a critical base score by MITRE. No less important, by capitalizing on a realistic, abundant in devices testbed, we compiled a voluminous, labeled corpus containing traces of ten diverse attacks against HTTP and QUIC services. An initial evaluation of the dataset mainly by means of machine learning techniques is included as well. Given that the 30 GB dataset is made available in both pcap and CSV formats, forthcoming research can easily take advantage of any subset of features, contingent upon the specific network topology and configuration.}
}


@article{DBLP:journals/compsec/GeHZS23,
	author = {Zhaocheng Ge and
                  Hanping Hu and
                  Tengfei Zhao and
                  Dingmeng Shi},
	title = {Reading is not believing: {A} multimodal adversarial attacker for
                  Chinese-NLP model},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103052},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103052},
	doi = {10.1016/J.COSE.2022.103052},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/GeHZS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The research of adversarial examples has extended from image to text in the last few years. However, these attacks are typically limited to the English language and simple substitution strategies. To further expose the vulnerability of NLP models, we study the linguistic characteristics of Chinese, the quintessential ideogram with over 1.2 billion native speakers. Accordingly, a novel attack framework named ZH-Deceiver is proposed to generate Chinese adversarial examples from the perspective of morphology, phonetics, semantics, and basic transformation. In particular, a CNN-based Siamese Network is integrated to ameliorate the quality of adversarial examples. To elaborate the validity of ZH-Deceiver, extensive experiments are conducted on two datasets. Compared with four benchmarks such as Genetic, PWWS, TextBugger, and SememePSO, our attack achieves impressive performance on effectiveness, efficiency, imperceptibility, and human evaluation by deceiving seven AI models including CNN and BERT. Furthermore, the transferability, as well as the robustness, is further analyzed and the former is successfully applied to attack three commercial APIs: Tencent, ALi, and Baidu. ZH-Deceiver acts as a wake-up call for multilingual processing models, and tangibly extends the application and methodology of adversarial textual attack.}
}


@article{DBLP:journals/compsec/SaqibM23,
	author = {Manasha Saqib and
                  Ayaz Hassan Moon},
	title = {A Systematic Security Assessment and Review of Internet of Things
                  in the Context of Authentication},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103053},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103053},
	doi = {10.1016/J.COSE.2022.103053},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/SaqibM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things is emerging globally as an intriguing trend expected to connect 15 billion devices by the end of 2022. Its ability to bring intelligence and automation to various application domains provides a plethora of opportunities while posing severe security challenges. Lack of proper authentication has been attributed to data disclosure's perils over wireless communication channels. Therefore, authentication as an essential security tenet continues to be a highly researched area, especially in resource constraint networks like IoT and IIoT. This paper constructs a comprehensive systematic literature review to identify and synthesize security issues in IoT from the perspective of authentication mechanisms. Initially, the prevalent security and privacy issues are identified, followed by the explanation of security threats across various layers of the IoT architecture. Additionally, the countermeasures available for addressing security issues are also covered. The highlight of the review is to present a literature review of various authentication mechanisms and different formal security evaluations holistically required for IoT authentication. Moreover, a comparative analysis of some of the popular existing authentication mechanisms designed for the IoT in terms of various performance parameters like computational, communication overhead, and energy consumption has also been covered. Finally, the paper discusses the typical methods for assessing network security and network simulator tools used to evaluate the performance parameters of authentication schemes. This review paper attempts to assist researchers in identifying the existing research gaps in various forms of authentication employed in a typical resource constraint network like IoT that would lead them to develop new solutions. The protocol provided by Kitchenham and Charters has been used to perform this Systematic Literature Review.}
}


@article{DBLP:journals/compsec/KumarS23a,
	author = {Vikash Kumar and
                  Ditipriya Sinha},
	title = {Synthetic attack data generation model applying generative adversarial
                  network for intrusion detection},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103054},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103054},
	doi = {10.1016/J.COSE.2022.103054},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/KumarS23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting a large number of attack classes accurately applying machine learning (ML) and deep learning (DL) techniques depends on the number of representative samples available for each attack class. In most cases, the data samples are highly imbalanced that results in a biased intrusion detection model towards the majority classes. Under-sampling, over-sampling and SMOTE are some techniques among the solutions that turn the imbalanced dataset to balanced one. These techniques have not had much impact on the improvement of detection accuracy. To deal with this problem, this paper proposes a Wasserstein Conditional Generative Adversarial Network (WCGAN) combined with an XGBoost Classifier. Gradient penalty along with the WCGAN is used for stable learning of the model. The proposed model is evaluated with some other GAN models (i.e., standard/vanilla GAN, Conditional GAN) which shows the significance of applying WCGAN in this paper. The loss on generated and real data shows a similar pattern and is lower for the Wasserstein variants of GAN compared to the other variants of the GAN model. The performance is benchmarked on three datasets NSL-KDD, UNSW-NB15 and BoT-IoT. The comparison of performance metrics before and after using the proposed framework with XGBoost classifier shows improvement in terms of higher precision, recall and F-1 score. However, comparatively less improvement is observed in FAR compared to other classifiers such as Random Forest (RF), Decision Tree (DT), Support Vector Machine (SVM). The proposed work is also compared with a recent similar technique called DGM, which uses conditional GAN along with different ML classification models. The performance of the proposed model outperforms DGM. The proposed model creates a significant footprint (or, attack signatures) to tackle with the problem of data-imbalance during the design of the Intrusion Detection System (IDS).}
}


@article{DBLP:journals/compsec/ZhuZZRJ23,
	author = {Hegui Zhu and
                  Ying Zhu and
                  Haoran Zheng and
                  Yuchen Ren and
                  Wuming Jiang},
	title = {{LIGAA:} Generative adversarial attack method based on low-frequency
                  information},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103057},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103057},
	doi = {10.1016/J.COSE.2022.103057},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/ZhuZZRJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have shown that the performance of deep neural network is extremely susceptible to adversarial examples. Slightly perturbation of the input that are not perceptible to the model may generate incorrect prediction results. Most existing attack methods with gradient or optimization operation cannot generate adversarial examples immediately, the robustness and imperceptibility of the adversarial examples are also not very good. To address this limitation, we propose a novel generative adversarial attack method with low-frequency information called LIGAA, which can achieve end-to-end real-time generation of adversarial examples. It mainly consists of a low-frequency information extractors and two symmetric decoders including a noise decoder and a saliency map decoder. The low-frequency information extractor eliminates the “useless” features in the original input. The noise decoder is used to generate perturbation noise for the entire image region that can be misclassified. The saliency map decoder limits the added noise to the specific areas that have a strong impact on classification, which can effectively enhance the imperceptibility of adversarial examples. Experimental results on CIFAR-10, Imagenette and CIFAR-100 of MobileNetv2 illustrate that the proposed LIGAA has obtained an attack success rate of 86.51%, 88.72% and 60.38%, and the time consumption is 0.001107s, 0.001706s and 0.004125s respectively, which are the best performance in all comparable methods. Particularly, the classification accuracy rate of LIGAA on ResNet-18 doesn’t increase even with the JPEG compress defense, but decreases to 3.11%, which also significantly verifies the attack performance and robustness against the defense method.}
}


@article{DBLP:journals/compsec/ButtQAAQ23,
	author = {Muhammad Atif Butt and
                  Adnan Qayyum and
                  Hassan Ali and
                  Ala I. Al{-}Fuqaha and
                  Junaid Qadir},
	title = {Towards secure private and trustworthy human-centric embedded machine
                  learning: An emotion-aware facial recognition case study},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103058},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103058},
	doi = {10.1016/J.COSE.2022.103058},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/ButtQAAQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of artificial intelligence (AI) at the edge is transforming every aspect of the lives of human beings from scheduling daily activities to personalized shopping recommendations. Since the success of AI is to be measured ultimately in terms of how it benefits human beings, and that the data driving the deep learning-based edge AI algorithms are intricately and intimately tied to humans, it is important to look at these AI technologies through a human-centric lens. However, despite the significant impact of AI design on human interests, the security and trustworthiness of edge AI applications are not foolproof and ethicalneither foolproof nor ethical; Moreover, social norms are often ignored duringin the design, implementation, and deployment of edge AI systems. In this paper, we make the following two contributions: Firstly, we analyze the application of edge AI through a human-centric perspective. More specifically, we present a pipeline to develop human-centric embedded machine learning (HC-EML) applications leveraging a generic human-centric AI (HCAI) framework. Alongside, we also analyzediscuss the privacy, trustworthiness, robustness, and security aspects of HC-EML applications with an insider look at their challenges and possible solutions along the way. Secondly, to illustrate the gravity of these issues, we present a case study on the task of human facial emotion recognition (FER) based on AffectNet dataset, where we analyze the effects of widely used input quantization on the security, robustness, fairness, and trustworthiness of an EML model. We find that input quantization partially degrades the efficacy of adversarial and backdoor attacks at the cost of a slight decrease in accuracy over clean inputs. By analyzing the explanations generated by SHAP, we identify that the decision of a FER model is largely influenced by features such as eyes, alar crease, lips, and jaws. Additionally, we note that input quantization is notably biased against the dark skin faces, and hypothesize that low-contrast features of dark skin faces may be responsible for the observed trends. We conclude with precautionary remarks and guidelines for future researchers.}
}


@article{DBLP:journals/compsec/WangDJDLQHMWL23,
	author = {Qing Wang and
                  Cong Dong and
                  Shijie Jian and
                  Dan Du and
                  Zhigang Lu and
                  Yinhao Qi and
                  Dongxu Han and
                  Xiaobo Ma and
                  Fei Wang and
                  Yuling Liu},
	title = {{HANDOM:} Heterogeneous Attention Network Model for Malicious Domain
                  Detection},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103059},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103059},
	doi = {10.1016/J.COSE.2022.103059},
	timestamp = {Wed, 28 Feb 2024 11:01:21 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WangDJDLQHMWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malicious domains are crucial vectors for attackers to conduct malicious activities. With the increasing numbers in domain-based attack activities and the enhancement of attacker evasion methods, the detection of malicious domains has become critical and increasingly difficult. Statistical feature-based and graph structure-based detection methods are mainstream technical approaches. However, highly hidden domains can escape feature detection, and the detection range of graph structure-based methods is limited. Based on these, we propose a malicious detection method called HANDOM. HANDOM combines statistical features and graph structural information to neutralize their limitations, and uses the Heterogeneous Attention Network (HAN) model to jointly handle both information to achieve high-performance malicious domain classification. We conduct experimental evaluations on real-world datasets and compare HANDOM with machine learning methods and other malicious detection methods. The results present that HANDOM has superior and robust performance, and can identify highly hidden domains.}
}


@article{DBLP:journals/compsec/WuBCTI23,
	author = {Chia{-}Yi Wu and
                  Tao Ban and
                  Shin{-}Ming Cheng and
                  Takeshi Takahashi and
                  Daisuke Inoue},
	title = {IoT malware classification based on reinterpreted function-call graphs},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103060},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103060},
	doi = {10.1016/J.COSE.2022.103060},
	timestamp = {Tue, 31 Jan 2023 20:45:20 +0100},
	biburl = {https://dblp.org/rec/journals/compsec/WuBCTI23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Various malware and cyberattacks have arisen along with the proliferation of IoT devices. The evolving malware targeting IoT devices calls forth effective and efficient solutions to protect vulnerable IoT devices from being compromised. In this paper, we investigate the feasibility of a state-of-the-art graph embedding method,\ng\nr\na\np\nh\n2\nv\ne\nc\n, for performing family classification for IoT malware, with promising results reported. To further improve the generalization performance of the classifiers based on\ng\nr\na\np\nh\n2\nv\ne\nc\n-extracted features, we propose two new mechanisms to improve the quality of feature representation. First, we unify user-defined function calls by reinterpreting the opcode sequences therein to better capture the semantics of the function-call relationship in malware binaries. Then, we integrate literal information into the\ng\nr\na\np\nh\n2\nv\ne\nc\nembedding of the function call graph to achieve better discriminant ability. To prove the effectiveness of the proposed scheme, we carried out performance comparison on a large-scale dataset containing more than 108K malware binaries collected from seven CPU architectures. The accuracy rates obtained by five widely adopted classifiers on malware family classification are improved by 2%, on average, by adopting the two proposed mechanisms. Specifically, when combined with the proposed approach, the support vector machine classifier obtained an accuracy rate of 98.88% on malware family classification, outperforming known function-call-graph (FCG)-based methods and previous work on static malware analysis.}
}


@article{DBLP:journals/compsec/WangX23,
	author = {Ruiling Wang and
                  Yakui Xue},
	title = {Stability analysis and optimal control of worm propagation model with
                  saturated incidence rate},
	journal = {Comput. Secur.},
	volume = {125},
	pages = {103063},
	year = {2023},
	url = {https://doi.org/10.1016/j.cose.2022.103063},
	doi = {10.1016/J.COSE.2022.103063},
	timestamp = {Sat, 13 May 2023 01:06:57 +0200},
	biburl = {https://dblp.org/rec/journals/compsec/WangX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Worms spreading through Web-based scanning and removable devices pose a serious threat to Internet security. This paper is devoted to solving the problems of computer worms. A nonlinear mathematical model of the problem is established, and the characteristics and mechanisms of worm propagation are analyzed by means of the stability theory of differential equations, optimal control and computer simulation. The results provide some new insights to computer security, which is to predict the tendency of worm propagation through the stability of endemic equilibrium, identify the epidemic control strategies by the stability of disease-free equilibrium, and evaluate the prevalence of worms based on the final scale of infected devices. The performance of our model is evaluated by numerical simulation, and the results indicate that our combined strategy can combat the worm propagation. The results may be helpful to inhibit the worm spread widely in the network.}
}
