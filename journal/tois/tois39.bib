@article{DBLP:journals/tois/ZhaoY20,
	author = {Guangzhen Zhao and
                  Peng Yang},
	title = {Pretrained Embeddings for Stance Detection with Hierarchical Capsule
                  Network on Social Media},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {1:1--1:32},
	year = {2020},
	url = {https://doi.org/10.1145/3412362},
	doi = {10.1145/3412362},
	timestamp = {Fri, 19 Jan 2024 08:33:22 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhaoY20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stance detection on social media aims to identify the stance of social media users toward a topic or claim, which can provide powerful information for various downstream tasks. Many existing stance detection approaches neglect to model the deep semantic representation information in tweets and do not explore aggregating the hierarchical features among words, thus degrading performance. To address these issues, this article proposes a novel deep learning approach  P retrained  E mbeddings for Stance Detection with  H ierarchical  C apsule  N etwork (PE-HCN) without complicated preprocessing. Specifically, PE-HCN first adopts a pretrained language model and then uses a related textual entailment task for fine-tuning to obtain the deep textual representations of tweets. The PE-HCN approach extends the dynamic routing scheme to cope with these deep textual representations by utilizing primary capsules for routing the information among words in each tweet and applying secondary capsules to transmit the aggregated features to each category capsule accordingly. Moreover, to improve the confidences of the category capsules, we design an adaptive feedback mechanism to dynamically strengthen the routing signals. Through experiments on three benchmark datasets, compared with the state-of-the-art baselines, the extensive results exhibit that PE-HCN achieves competitive improvements of up to 6.32%, 2.09%, and 1.8%, respectively.}
}


@article{DBLP:journals/tois/ZhangSYXOZ20,
	author = {Yuan Zhang and
                  Fei Sun and
                  Xiaoyong Yang and
                  Chen Xu and
                  Wenwu Ou and
                  Yan Zhang},
	title = {Graph-based Regularization on Embedding Layers for Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {2:1--2:27},
	year = {2020},
	url = {https://doi.org/10.1145/3414067},
	doi = {10.1145/3414067},
	timestamp = {Wed, 05 Mar 2025 20:49:22 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangSYXOZ20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Neural networks have been extensively used in recommender systems. Embedding layers are not only necessary but also crucial for neural models in recommendation as a typical discrete task. In this article, we argue that the widely used  l 2  regularization for normal neural layers (e.g., fully connected layers) is not ideal for embedding layers from the perspective of regularization theory in Reproducing Kernel Hilbert Space. More specifically, the  l 2  regularization corresponds to the inner product and the distance in the Euclidean space where correlations between discrete objects (e.g., items) are not well captured. Inspired by this observation, we propose a graph-based regularization approach to serve as a counterpart of the  l 2  regularization for embedding layers. The proposed regularization incurs almost no extra computational overhead especially when being trained with mini-batches. We also discuss its relationships to other approaches (namely, data augmentation, graph convolution, and joint learning) theoretically. We conducted extensive experiments on five publicly available datasets from various domains with two state-of-the-art recommendation models. Results show that given a kNN (k-nearest neighbor) graph constructed directly from training data without external information, the proposed approach significantly outperforms the  l 2  regularization on all the datasets and achieves more notable improvements for long-tail users and items.}
}


@article{DBLP:journals/tois/MoussetPT20,
	author = {Paul Mousset and
                  Yoann Pitarch and
                  Lynda Tamine},
	title = {End-to-End Neural Matching for Semantic Location Prediction of Tweets},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {3:1--3:35},
	year = {2020},
	url = {https://doi.org/10.1145/3415149},
	doi = {10.1145/3415149},
	timestamp = {Sat, 08 Jan 2022 02:21:32 +0100},
	biburl = {https://dblp.org/rec/journals/tois/MoussetPT20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The impressive increasing availability of social media posts has given rise to considerable research challenges. This article is concerned with the problem of semantic location prediction of geotagged tweets. The underlying task is to associate to a social media post, the focal spatial object, if any (e.g., Place Of Interest POI), it topically focuses on. Although relevant for a number of applications such as POI recommendation, this problem has not so far received the attention it deserves. In previous work, the problem has mainly been tackled by means of language models that rely on costly probability estimation of word relevance across spatial regions. We propose the Spatially-aware Geotext Matching (SGM) model, which relies on a neural network learning framework. The model combines exact word-word-local interaction matching signals with semantic global tweet-POI interaction matching signals. The local interactions are built over kernel spatial word distributions that allow revealing spatially driven word pair similarity patterns. The global interactions consider the strength of the interaction between the tweet and the POI from both the spatial and semantic perspectives. Experimental results on two real-world datasets demonstrate the effectiveness of our proposed SGM model compared to state-of-the-art baselines including language models and traditional neural interaction-based models.}
}


@article{DBLP:journals/tois/McDonaldMO20,
	author = {Graham McDonald and
                  Craig Macdonald and
                  Iadh Ounis},
	title = {How the Accuracy and Confidence of Sensitivity Classification Affects
                  Digital Sensitivity Review},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {4:1--4:34},
	year = {2020},
	url = {https://doi.org/10.1145/3417334},
	doi = {10.1145/3417334},
	timestamp = {Sat, 08 Jan 2022 02:21:32 +0100},
	biburl = {https://dblp.org/rec/journals/tois/McDonaldMO20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Government documents must be manually reviewed to identify any  sensitive  information, e.g., confidential information, before being publicly archived. However, human-only sensitivity review is not practical for born-digital documents due to, for example, the volume of documents that are to be reviewed. In this work, we conduct a user study to evaluate the effectiveness of sensitivity classification for  assisting  human sensitivity reviewers. We evaluate how the accuracy and confidence levels of sensitivity classification affects the number of documents that are correctly judged as being sensitive (reviewer accuracy) and the time that it takes to sensitivity review a document (reviewing speed). In our within-subject study, the participants review government documents to identify real sensitivities while being assisted by three sensitivity classification  treatments , namely  None  (no classification predictions),  Medium  (sensitivity predictions from a  simulated  classifier with a balanced accuracy (BAC) of 0.7), and  Perfect  (sensitivity predictions from a classifier with an accuracy of 1.0). Our results show that sensitivity classification leads to significant improvements (ANOVA,  p  < 0.05) in reviewer accuracy in terms of BAC (+37.9%  Medium , +60.0%  Perfect ) and also in terms of F 2  (+40.8%  Medium , +44.9%  Perfect ). Moreover, we show that assisting reviewers with sensitivity classification predictions leads to significantly increased (ANOVA,  p  < 0.05) mean reviewing speeds (+72.2%  Medium , +61.6%  Perfect ). We find that reviewers do not agree with the classifier significantly more as the classifier’s confidence increases. However, reviewing speed is significantly increased when the reviewers agree with the classifier (ANOVA,  p  < 0.05). Our in-depth analysis shows that when the reviewers are not assisted with sensitivity predictions, mean reviewing speeds are 40.5% slower for sensitive judgements compared to not-sensitive judgements. However, when the reviewers  are  assisted with sensitivity predictions, the difference in reviewing speeds between sensitive and not-sensitive judgements is reduced by ˜10%, from 40.5% to 30.8%. We also find that, for sensitive judgements, sensitivity classification predictions significantly increase mean reviewing speeds by 37.7% when the reviewers agree with the classifier’s predictions ( t -test,  p  < 0.05). Overall, our findings demonstrate that sensitivity classification is a viable technology for assisting human reviewers with the sensitivity review of digital documents.}
}


@article{DBLP:journals/tois/MendozaTC20,
	author = {Marcelo Mendoza and
                  Maurizio Tesconi and
                  Stefano Cresci},
	title = {Bots in Social and Interaction Networks: Detection and Impact Estimation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {5:1--5:32},
	year = {2020},
	url = {https://doi.org/10.1145/3419369},
	doi = {10.1145/3419369},
	timestamp = {Fri, 09 Apr 2021 18:19:34 +0200},
	biburl = {https://dblp.org/rec/journals/tois/MendozaTC20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of bots and their influence on social networks is a hot topic that has aroused the interest of many researchers. Despite the efforts to detect social bots, it is still difficult to distinguish them from legitimate users. Here, we propose a simple yet effective semi-supervised method that allows distinguishing between bots and legitimate users with high accuracy. The method learns a joint representation of social connections and interactions between users by leveraging graph-based representation learning. Then, on the proximity graph derived from user embeddings, a sample of bots is used as seeds for a label propagation algorithm. We demonstrate that when the label propagation is done according to pairwise account proximity, our method achieves  F 1 = 0.93, whereas other state-of-the-art techniques achieve  F 1 ≤ 0.87. By applying our method to a large dataset of retweets, we uncover the presence of different clusters of bots in the network of Twitter interactions. Interestingly, such clusters feature different degrees of integration with legitimate users. By analyzing the interactions produced by the different clusters of bots, our results suggest that a significant group of users was systematically exposed to content produced by bots and to interactions with bots, indicating the presence of a selective exposure phenomenon.}
}


@article{DBLP:journals/tois/LiuLZJDC20,
	author = {Bulou Liu and
                  Chenliang Li and
                  Wei Zhou and
                  Feng Ji and
                  Yu Duan and
                  Haiqing Chen},
	title = {An Attention-based Deep Relevance Model for Few-shot Document Filtering},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {6:1--6:35},
	year = {2020},
	url = {https://doi.org/10.1145/3419972},
	doi = {10.1145/3419972},
	timestamp = {Fri, 21 Jan 2022 21:58:23 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiuLZJDC20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the large quantity of textual information produced on the Internet, a critical necessity is to filter out the irrelevant information and organize the rest into categories of interest (e.g., an emerging event). However, supervised-learning document filtering methods heavily rely on a large number of labeled documents for model training. Manually identifying plenty of positive examples for each category is expensive and time-consuming. Also, it is unrealistic to cover all the categories from an evolving text source that covers diverse kinds of events, user opinions, and daily life activities. In this article, we propose a novel attention-based deep relevance model for few-shot document filtering (named ADRM), inspired by the relevance feedback methodology proposed for ad hoc retrieval. ADRM calculates the relevance score between a document and a category by taking a set of seed words and a few seed documents relevant to the category. It constructs the category-specific conceptual representation of the document based on the corresponding seed words and seed documents. Specifically, to filter irrelevant yet noisy information in the seed documents, ADRM employs two types of attention mechanisms (namely  whole-match attention  and  max-match attention ) and generates category-specific representations for them. Then ADRM is devised to extract the relevance signals by modeling the hidden feature interactions in the word embedding space. The relevance signals are extracted through a gated convolutional process, a self-attention layer, and a relevance aggregation layer. Extensive experiments on three real-world datasets show that ADRM consistently outperforms the existing technical alternatives, including the conventional classification and retrieval baselines, and the state-of-the-art deep relevance ranking models for few-shot document filtering. We also perform an ablation study to demonstrate that each component in ADRM is effective for enhancing filtering performance. Further analysis shows that ADRM is robust under varying parameter settings.}
}


@article{DBLP:journals/tois/LanMWGH20,
	author = {Tian Lan and
                  Xian{-}Ling Mao and
                  Wei Wei and
                  Xiaoyan Gao and
                  Heyan Huang},
	title = {{PONE:} {A} Novel Automatic Evaluation Metric for Open-domain Generative
                  Dialogue Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {7:1--7:37},
	year = {2020},
	url = {https://doi.org/10.1145/3423168},
	doi = {10.1145/3423168},
	timestamp = {Sun, 19 Jan 2025 15:03:41 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LanMWGH20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open-domain generative dialogue systems have attracted considerable attention over the past few years. Currently, how to automatically evaluate them is still a big challenge. As far as we know, there are three kinds of automatic evaluations for open-domain generative dialogue systems: (1) Word-overlap-based metrics; (2) Embedding-based metrics; (3) Learning-based metrics. Due to the lack of systematic comparison, it is not clear which kind of metrics is more effective. In this article, we first measure systematically all kinds of metrics to check which kind is best. Extensive experiments demonstrate that learning-based metrics are the most effective evaluation metrics for open-domain generative dialogue systems. Moreover, we observe that nearly all learning-based metrics depend on the negative sampling mechanism, which obtains extremely imbalanced and low-quality samples to train a score model. To address this issue, we propose a novel learning-based metric that significantly improves the correlation with human judgments by using augmented  PO sitive samples and valuable  NE gative samples, called PONE. Extensive experiments demonstrate that PONE significantly outperforms the state-of-the-art learning-based evaluation method. Besides, we have publicly released the codes of our proposed metric and state-of-the-art baselines. 1}
}


@article{DBLP:journals/tois/ChenXZXYH20,
	author = {Xu Chen and
                  Kun Xiong and
                  Yongfeng Zhang and
                  Long Xia and
                  Dawei Yin and
                  Jimmy Xiangji Huang},
	title = {Neural Feature-aware Recommendation with Signed Hypergraph Convolutional
                  Network},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {8:1--8:22},
	year = {2020},
	url = {https://doi.org/10.1145/3423322},
	doi = {10.1145/3423322},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ChenXZXYH20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Understanding user preference is of key importance for an effective recommender system. For comprehensive user profiling, many efforts have been devoted to extract user feature-level preference from the review information. Despite effectiveness, existing methods mostly assume linear relationships among the users, items, and features, and the collaborative information is usually utilized in an implicit and insufficient manner, which limits the recommender capacity in modeling users’ diverse preferences. For bridging this gap, in this article, we propose to formulate user feature-level preferences by a neural signed hypergraph and carefully design the information propagation paths for diffusing collaborative filtering signals in a more effective manner. By taking the advantages of the neural model’s powerful expressiveness, the complex relationship patterns among users, items, and features are sufficiently discovered and well utilized. By infusing graph structure information into the embedding process, the collaborative information is harnessed in a more explicit and effective way. We conduct comprehensive experiments on real-world datasets to demonstrate the superiorities of our model.}
}


@article{DBLP:journals/tois/ManioudakisT20,
	author = {Kostas Manioudakis and
                  Yannis Tzitzikas},
	title = {Faceted Search with Object Ranking and Answer Size Constraints},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {9:1--9:33},
	year = {2020},
	url = {https://doi.org/10.1145/3425603},
	doi = {10.1145/3425603},
	timestamp = {Sat, 08 Jan 2022 02:21:32 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ManioudakisT20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Faceted Search is a widely used interaction scheme in digital libraries, e-commerce, and recently also in Linked Data. Surprisingly, object ranking in the context of Faceted Search is not well studied in the literature. In this article, we propose an extension of the model with two parameters that enable specifying the desired answer size and the granularity of the sought object ranking. These parameters allow tackling the problem of  too big  or  too small  answers and can specify  how refined  the sought ranking should be. Then, we provide an algorithm that takes as input these parameters and by considering the hard-constraints (filters), the soft-constraints (preferences), as well as the statistical properties of the dataset (through various frequency-based ranking schemes), produces an object ranking that satisfies these parameters, in a transparent way for the user. Then, we present extensive simulation-based evaluation results that provide evidence that the proposed model also improves the answers and reduces the user’s cost. Finally, we propose GUI extensions that are required and present an implementation of the model.}
}


@article{DBLP:journals/tois/FangZSG20,
	author = {Hui Fang and
                  Danning Zhang and
                  Yiheng Shu and
                  Guibing Guo},
	title = {Deep Learning for Sequential Recommendation: Algorithms, Influential
                  Factors, and Evaluations},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {1},
	pages = {10:1--10:42},
	year = {2020},
	url = {https://doi.org/10.1145/3426723},
	doi = {10.1145/3426723},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/FangZSG20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the field of sequential recommendation, deep learning--(DL) based methods have received a lot of attention in the past few years and surpassed traditional models such as Markov chain-based and factorization-based ones. However, there is little systematic study on DL-based methods, especially regarding how to design an effective DL model for sequential recommendation. In this view, this survey focuses on DL-based sequential recommender systems by taking the aforementioned issues into consideration. Specifically, we illustrate the concept of sequential recommendation, propose a categorization of existing algorithms in terms of three types of behavioral sequences, summarize the key factors affecting the performance of DL-based models, and conduct corresponding evaluations to showcase and demonstrate the effects of these factors. We conclude this survey by systematically outlining future directions and challenges in this field.}
}


@article{DBLP:journals/tois/MunteanNPTF21,
	author = {Cristina Ioana Muntean and
                  Franco Maria Nardini and
                  Raffaele Perego and
                  Nicola Tonellotto and
                  Ophir Frieder},
	title = {Weighting Passages Enhances Accuracy},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {11:1--11:11},
	year = {2021},
	url = {https://doi.org/10.1145/3428687},
	doi = {10.1145/3428687},
	timestamp = {Tue, 07 May 2024 20:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/tois/MunteanNPTF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We observe that in curated documents the distribution of the occurrences of salient terms, e.g., terms with a high Inverse Document Frequency, is not uniform, and such terms are primarily concentrated towards the beginning and the end of the document. Exploiting this observation, we propose a novel version of the classical BM25 weighting model, called BM25 Passage (BM25P), which scores query results by computing a linear combination of term statistics in the different portions of the document. We study a multiplicity of partitioning schemes of document content into passages and compute the collection-dependent weights associated with them on the basis of the distribution of occurrences of salient terms in documents. Moreover, we tune BM25P hyperparameters and investigate their impact on ad hoc document retrieval through fully reproducible experiments conducted using four publicly available datasets. Our findings demonstrate that our BM25P weighting model markedly and consistently outperforms BM25 in terms of effectiveness by up to 17.44% in NDCG@5 and 85% in NDCG@1, and up to 21% in MRR.}
}


@article{DBLP:journals/tois/GaoCLZY21,
	author = {Shen Gao and
                  Xiuying Chen and
                  Li Liu and
                  Dongyan Zhao and
                  Rui Yan},
	title = {Learning to Respond with Your Favorite Stickers: {A} Framework of
                  Unifying Multi-Modality and User Preference in Multi-Turn Dialog},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {12:1--12:32},
	year = {2021},
	url = {https://doi.org/10.1145/3429980},
	doi = {10.1145/3429980},
	timestamp = {Sat, 08 Jan 2022 02:21:30 +0100},
	biburl = {https://dblp.org/rec/journals/tois/GaoCLZY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stickers with vivid and engaging expressions are becoming increasingly popular in online messaging apps, and some works are dedicated to automatically select sticker response by matching the stickers image with previous utterances. However, existing methods usually focus on measuring the matching degree between the dialog context and sticker image, which ignores the user preference of using stickers. Hence, in this article, we propose to recommend an appropriate sticker to user based on multi-turn dialog context and sticker using history of user. Two main challenges are confronted in this task. One is to model the sticker preference of user based on the previous sticker selection history. Another challenge is to jointly fuse the user preference and the matching between dialog context and candidate sticker into final prediction making. To tackle these challenges, we propose a  Preference Enhanced Sticker Response Selector  (PESRS) model. Specifically, PESRS first employs a convolutional-based sticker image encoder and a self-attention-based multi-turn dialog encoder to obtain the representation of stickers and utterances. Next, deep interaction network is proposed to conduct deep matching between the sticker and each utterance. Then, we model the user preference by using the recently selected stickers as input and use a key-value memory network to store the preference representation. PESRS then learns the short-term and long-term dependency between all interaction results by a fusion network and dynamically fuses the user preference representation into the final sticker selection prediction. Extensive experiments conducted on a large-scale real-world dialog dataset show that our model achieves the state-of-the-art performance for all commonly used metrics. Experiments also verify the effectiveness of each component of PESRS.}
}


@article{DBLP:journals/tois/AdomaviciusBCZ21,
	author = {Gediminas Adomavicius and
                  Jesse C. Bockstedt and
                  Shawn P. Curley and
                  Jingjing Zhang},
	title = {Effects of Personalized and Aggregate Top-N Recommendation Lists on
                  User Preference Ratings},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {13:1--13:38},
	year = {2021},
	url = {https://doi.org/10.1145/3430028},
	doi = {10.1145/3430028},
	timestamp = {Mon, 03 Mar 2025 22:25:54 +0100},
	biburl = {https://dblp.org/rec/journals/tois/AdomaviciusBCZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Prior research has shown a robust effect of personalized product recommendations on user preference judgments for items. Specifically, the display of system-predicted preference ratings as item recommendations has been shown in multiple studies to bias users’ preference ratings after item consumption in the direction of the predicted rating. Top-N lists represent another common approach for presenting item recommendations in recommender systems. Through three controlled laboratory experiments, we show that top-N lists do not induce a discernible bias in user preference judgments. This result is robust, holding for both lists of personalized item recommendations and lists of items that are top-rated based on averages of aggregate user ratings. Adding numerical ratings to the list items does generate a bias, consistent with earlier studies. Thus, in contexts where preference biases are of concern to an online retailer or platform, top-N lists, without numerical predicted ratings, would be a promising format for displaying item recommendations.}
}


@article{DBLP:journals/tois/SakaiZ21,
	author = {Tetsuya Sakai and
                  Zhaohao Zeng},
	title = {Retrieval Evaluation Measures that Agree with Users' {SERP} Preferences:
                  Traditional, Preference-based, and Diversity Measures},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {14:1--14:35},
	year = {2021},
	url = {https://doi.org/10.1145/3431813},
	doi = {10.1145/3431813},
	timestamp = {Mon, 26 Apr 2021 16:14:38 +0200},
	biburl = {https://dblp.org/rec/journals/tois/SakaiZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We examine the “goodness” of ranked retrieval evaluation measures in terms of how well they align with users’ Search Engine Result Page (SERP) preferences for web search. The SERP preferences cover 1,127 topic-SERP-SERP triplets extracted from the NTCIR-9 INTENT task, reflecting the views of 15 different assessors. Each assessor made two SERP preference judgements for each triplet: one in terms of relevance and the other in terms of diversity. For each evaluation measure, we compute the Agreement Rate (AR) of each triplet: the proportion of assessors that agree with the measure’s SERP preference. We then compare the mean ARs of the measures as well as those of best/median/worst assessors using Tukey HSD tests. Our first experiment compares traditional ranked retrieval measures based on the SERP relevance preferences: we find that normalised Discounted Cumulative Gain (nDCG) and intentwise Rank-biased Utility (iRBU) perform best in that they are the only measures that are statistically indistinguishable from our best assessor; nDCG also statistically significantly outperforms our median assessor. Our second experiment utilises 119,646 document preferences that we collected for a subset of the above topic-SERP-SERP triplets (containing 894 triplets) to compare preference-based evaluation measures as well as traditional ones. Again, we evaluate them based on the SERP relevance preferences. The results suggest that measures such as wpref5 are the most promising among the preference-based measures considered, although they underperform the best traditional measures such as nDCG on average. Our third experiment compares diversified search measures based on the SERP diversity preferences as well as the SERP relevance preferences, and it shows that D♯-measures are clearly the most reliable: in particular, D♯-nDCG and D♯-RBP statistically significantly outperform the median assessor and all intent-aware measures; they also outperform the recently proposed RBU on average. Also, in terms of agreement with SERP diversity preferences, D♯-nDCG statistically significantly outperforms RBU. Hence, if IR researchers want to use evaluation measures that align well with users’ SERP preferences, then we recommend nDCG and iRBU for traditional search, and D♯-measures such as D♯-nDCG for diversified search. As for document preference-based measures that we have examined, we do not have a strong reason to recommended them over traditional measures like nDCG, since they align slightly less well with users’ SERP preferences despite their quadratic assessment cost.}
}


@article{DBLP:journals/tois/LiuZG21,
	author = {Peng Liu and
                  Lemei Zhang and
                  Jon Atle Gulla},
	title = {Multilingual Review-aware Deep Recommender System via Aspect-based
                  Sentiment Analysis},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {15:1--15:33},
	year = {2021},
	url = {https://doi.org/10.1145/3432049},
	doi = {10.1145/3432049},
	timestamp = {Mon, 26 Apr 2021 16:14:38 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LiuZG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the dramatic expansion of international markets, consumers write reviews in different languages, which poses a new challenge for Recommender Systems (RSs) dealing with this increasing amount of multilingual information. Recent studies that leverage deep-learning techniques for review-aware RSs have demonstrated their effectiveness in modelling fine-grained user-item interactions through the aspects of reviews. However, most of these models can neither take full advantage of the contextual information from multilingual reviews nor discriminate the inherent ambiguity of words originated from the user’s different tendency in writing. To this end, we propose a novel Multilingual Review-aware Deep Recommendation Model (MrRec) for rating prediction tasks. MrRec mainly consists of two parts: (1) Multilingual aspect-based sentiment analysis module (MABSA), which aims to jointly extract aligned aspects and their associated sentiments in different languages simultaneously with only requiring overall review ratings. (2) Multilingual recommendation module that learns aspect importances of both the user and item with considering different contributions of multiple languages and estimates aspect utility via a dual interactive attention mechanism integrated with aspect-specific sentiments from MABSA. Finally, overall ratings can be inferred by a prediction layer adopting the aspect utility value and aspect importance as inputs. Extensive experimental results on nine real-world datasets demonstrate the superior performance and interpretability of our model.}
}


@article{DBLP:journals/tois/WangMZCLM21,
	author = {Chenyang Wang and
                  Weizhi Ma and
                  Min Zhang and
                  Chong Chen and
                  Yiqun Liu and
                  Shaoping Ma},
	title = {Toward Dynamic User Intention: Temporal Evolutionary Effects of Item
                  Relations in Sequential Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {16:1--16:33},
	year = {2021},
	url = {https://doi.org/10.1145/3432244},
	doi = {10.1145/3432244},
	timestamp = {Mon, 31 Oct 2022 08:39:18 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WangMZCLM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User intention is an important factor to be considered for recommender systems, which always changes dynamically in different contexts. Recent studies (represented by sequential recommendation) begin to focus on predicting what users want beyond what users like, which are better at capturing user intention and have attracted a surge of interest. However, user intention modeling is non-trivial, because it is generally influenced by various factors, among which item relations and their temporal evolutionary effects are of great importance. For example, consumption of a cellphone will have varying impacts on the demands for its relational items: For complements, the demands are likely to be promoted in the short term; while for substitutes, the long-term effect may take advantage, because users do not need another cellphone immediately. Moreover, the temporal evolutions of different relational effects vary across different domains, which makes it challenging to adaptively take them into consideration. As a result, most existing studies only loosely incorporate item relations by encoding their semantics into embeddings, neglecting fine-grained time-aware effects. In this work, we propose Knowledge-aware Dynamic Attention (KDA) to take both relational effects and their temporal evolutions into consideration. Specifically, to model dynamic impacts of historical relational interactions on user intention, we aggregate the history sequence into relation-specific embeddings, where the attention weight consists of two parts. First, we measure the relational intensity between historical items and the target item to model the absolute degree of influence in terms of each relation. Second, to model how the relational effects drift with time, we innovatively introduce Fourier transform with learnable frequency-domain embeddings to estimate temporal decay functions of different relations adaptively. Subsequently, the self-attention mechanism is leveraged to derive the final representation of the whole history sequence, which reflects the dynamic user intention and will be applied to generate the recommendation list. Extensive experiments in three real-world datasets indicate the proposed KDA model significantly outperforms the state-of-the-art methods on the Top- K  recommendation task. Moreover, the proposed Fourier-based method opens up a new avenue to adaptively integrate temporal dynamics into general neural models.}
}


@article{DBLP:journals/tois/WhiteNWEJ21,
	author = {Ryen W. White and
                  Elnaz Nouri and
                  James Woffinden{-}Luey and
                  Mark J. Encarnaci{\'{o}}n and
                  Sujay Kumar Jauhar},
	title = {Microtask Detection},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {17:1--17:29},
	year = {2021},
	url = {https://doi.org/10.1145/3432290},
	doi = {10.1145/3432290},
	timestamp = {Mon, 26 Apr 2021 16:14:38 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WhiteNWEJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information systems, such as task management applications and digital assistants, can help people keep track of tasks of different types and different time durations, ranging from a few minutes to days or weeks. Helping people better manage their tasks and their time are core capabilities of assistive technologies, situated within a broader context of supporting more effective information access and use. Throughout the course of a day, there are typically many short time periods of downtime (e.g., five minutes or less) available to individuals. Microtasks are simple tasks that can be tackled in such short amounts of time. Identifying microtasks in task lists could help people utilize these periods of low activity to make progress on their task backlog. We define  actionable  tasks as self-contained tasks that need to be completed or acted on. However, not all to-do tasks are actionable. Many task lists are collections of miscellaneous items that can be completed at any time (e.g., books to read, movies to watch), notes (e.g., names, addresses), or the individual items are constituents in a list that is itself a task (e.g., a grocery list). In this article, we introduce the novel challenge of microtask detection, and we present machine-learned models for automatically determining which tasks are actionable and which of these actionable tasks are microtasks. Experiments show that our models can accurately identify actionable tasks, accurately detect actionable microtasks, and that we can combine these models to generate a solution that scales microtask detection to all tasks. We discuss our findings in detail, along with their limitations. These findings have implications for the design of systems to help people make the most of their time.}
}


@article{DBLP:journals/tois/GaoCRZY21,
	author = {Shen Gao and
                  Xiuying Chen and
                  Zhaochun Ren and
                  Dongyan Zhao and
                  Rui Yan},
	title = {Meaningful Answer Generation of E-Commerce Question-Answering},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {18:1--18:26},
	year = {2021},
	url = {https://doi.org/10.1145/3432689},
	doi = {10.1145/3432689},
	timestamp = {Thu, 23 Jun 2022 20:05:17 +0200},
	biburl = {https://dblp.org/rec/journals/tois/GaoCRZY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In e-commerce portals, generating answers for product-related questions has become a crucial task. In this article, we focus on the task of  product-aware answer generation , which learns to generate an accurate and complete answer from large-scale unlabeled e-commerce reviews and product attributes. However,  safe answer problems  (i.e., neural models tend to generate meaningless and universal answers) pose significant challenges to text generation tasks, and e-commerce question-answering task is no exception. To generate more meaningful answers, in this article, we propose a novel generative neural model, called the  Meaningful Product Answer Generator  ( MPAG ), which alleviates the safe answer problem by taking product reviews, product attributes, and a prototype answer into consideration. Product reviews and product attributes are used to provide meaningful content, while the prototype answer can yield a more diverse answer pattern. To this end, we propose a novel answer generator with a review reasoning module and a prototype answer reader. Our key idea is to obtain the correct question-aware information from a large-scale collection of reviews and learn how to write a coherent and meaningful answer from an existing prototype answer. To be more specific, we propose a read-and-write memory consisting of selective writing units to conduct  reasoning among these reviews . We then employ a prototype reader consisting of comprehensive matching to extract the  answer skeleton  from the prototype answer. Finally, we propose an answer editor to generate the final answer by taking the question and the above parts as input. Conducted on a real-world dataset collected from an e-commerce platform, extensive experimental results show that our model achieves state-of-the-art performance in terms of both automatic metrics and human evaluations. Human evaluation also demonstrates that our model can consistently generate specific and proper answers.}
}


@article{DBLP:journals/tois/EsuliMS21,
	author = {Andrea Esuli and
                  Alessio Molinari and
                  Fabrizio Sebastiani},
	title = {A Critical Reassessment of the Saerens-Latinne-Decaestecker Algorithm
                  for Posterior Probability Adjustment},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {19:1--19:34},
	year = {2021},
	url = {https://doi.org/10.1145/3433164},
	doi = {10.1145/3433164},
	timestamp = {Sun, 04 Aug 2024 19:51:35 +0200},
	biburl = {https://dblp.org/rec/journals/tois/EsuliMS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We critically re-examine the Saerens-Latinne-Decaestecker (SLD) algorithm, a well-known method for estimating class prior probabilities (“priors”) and adjusting posterior probabilities (“posteriors”) in scenarios characterized by distribution shift, i.e., difference in the distribution of the priors between the training and the unlabelled documents. Given a machine learned classifier and a set of unlabelled documents for which the classifier has returned posterior probabilities and estimates of the prior probabilities, SLD updates them both in an iterative, mutually recursive way, with the goal of making both more accurate; this is of key importance in downstream tasks such as single-label multiclass classification and cost-sensitive text classification. Since its publication, SLD has become the standard algorithm for improving the quality of the posteriors in the presence of distribution shift, and SLD is still considered a top contender when we need to estimate the priors (a task that has become known as “quantification”). However, its real effectiveness in improving the quality of the posteriors has been questioned. We here present the results of systematic experiments conducted on a large, publicly available dataset, across multiple amounts of distribution shift and multiple learners. Our experiments show that SLD improves the quality of the posterior probabilities and of the estimates of the prior probabilities, but only when the number of classes in the classification scheme is very small and the classifier is calibrated. As the number of classes grows, or as we use non-calibrated classifiers, SLD converges more slowly (and often does not converge at all), performance degrades rapidly, and the impact of SLD on the quality of the prior estimates and of the posteriors becomes negative rather than positive.}
}


@article{DBLP:journals/tois/DacremaBCJ21,
	author = {Maurizio Ferrari Dacrema and
                  Simone Boglio and
                  Paolo Cremonesi and
                  Dietmar Jannach},
	title = {A Troubling Analysis of Reproducibility and Progress in Recommender
                  Systems Research},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {20:1--20:49},
	year = {2021},
	url = {https://doi.org/10.1145/3434185},
	doi = {10.1145/3434185},
	timestamp = {Wed, 19 May 2021 08:29:16 +0200},
	biburl = {https://dblp.org/rec/journals/tois/DacremaBCJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The design of algorithms that generate personalized ranked item lists is a central topic of research in the field of recommender systems. In the past few years, in particular, approaches based on deep learning (neural) techniques have become dominant in the literature. For all of them, substantial progress over the state-of-the-art is claimed. However, indications exist of certain problems in today’s research practice, e.g., with respect to the choice and optimization of the baselines used for comparison, raising questions about the published claims. To obtain a better understanding of the actual progress, we have compared recent results in the area of neural recommendation approaches based on collaborative filtering against a consistent set of existing simple baselines. The worrying outcome of the analysis of these recent works—all were published at prestigious scientific conferences between 2015 and 2018—is that 11 of the 12 reproducible neural approaches can be outperformed by conceptually simple methods, e.g., based on the nearest-neighbor heuristic or linear models. None of the computationally complex neural methods was actually consistently better than already existing learning-based techniques, e.g., using matrix factorization or linear models. In our analysis, we discuss common issues in today’s research practice, which, despite the many papers that are published on the topic, have apparently led the field to a certain level of stagnation. 1}
}


@article{DBLP:journals/tois/AiYWM21,
	author = {Qingyao Ai and
                  Tao Yang and
                  Huazheng Wang and
                  Jiaxin Mao},
	title = {Unbiased Learning to Rank: Online or Offline?},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {21:1--21:29},
	year = {2021},
	url = {https://doi.org/10.1145/3439861},
	doi = {10.1145/3439861},
	timestamp = {Wed, 18 Oct 2023 07:48:05 +0200},
	biburl = {https://dblp.org/rec/journals/tois/AiYWM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How to obtain an unbiased ranking model by learning to rank with biased user feedback is an important research question for IR. Existing work on unbiased learning to rank (ULTR) can be broadly categorized into two groups—the studies on unbiased learning algorithms with logged data, namely, the  offline  unbiased learning, and the studies on unbiased parameters estimation with real-time user interactions, namely, the  online  learning to rank. While their definitions of  unbiasness  are different, these two types of ULTR algorithms share the same goal—to find the best models that rank documents based on their intrinsic relevance or utility. However, most studies on offline and online unbiased learning to rank are carried in parallel without detailed comparisons on their background theories and empirical performance. In this article, we formalize the task of unbiased learning to rank and show that existing algorithms for offline unbiased learning and online learning to rank are just the two sides of the same coin. We evaluate eight state-of-the-art ULTR algorithms and find that many of them can be used in both offline settings and online environments with or without minor modifications. Further, we analyze how different offline and online learning paradigms would affect the theoretical foundation and empirical effectiveness of each algorithm on both synthetic and real search data. Our findings provide important insights and guidelines for choosing and deploying ULTR algorithms in practice.}
}


@article{DBLP:journals/tois/WangC21,
	author = {Wei Wang and
                  Longbing Cao},
	title = {{VM-NSP:} Vertical Negative Sequential Pattern Mining with Loose Negative
                  Element Constraints},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {2},
	pages = {22:1--22:27},
	year = {2021},
	url = {https://doi.org/10.1145/3440874},
	doi = {10.1145/3440874},
	timestamp = {Mon, 12 May 2025 21:00:07 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WangC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Negative sequential patterns (NSPs) capture more informative and actionable knowledge than classic positive sequential patterns (PSPs) due to the involvement of both occurring and nonoccurring behaviors and events, which can contribute to many relevant applications. However, NSP mining is nontrivial, as it involves fundamental challenges requiring distinct theoretical foundations and is not directly addressable by PSP mining. In the very limited research reported on NSP mining, a negative element constraint (NEC) is incorporated to only consider the NSPs composed of specific forms of elements (containing either positive or negative items), which results in many valuable NSPs being missed. Here, we loosen the NEC (called  loose negative element constraint  (LNEC)) to include partial negative elements containing both positive and negative items, which enables the discovery of more flexible patterns but incorporates significant new learning challenges, such as representing and mining complete NSPs. Accordingly, we formalize the LNEC-based NSP mining problem and propose a novel  vertical NSP mining framework , VM-NSP, to efficiently mine the complete set of NSPs by a vertical representation (VR) of each sequence. An efficient  bitmap-based vertical NSP mining algorithm , bM-NSP, introduces a bitmap hash table--based VR and a prefix-based negative sequential candidate generation strategy to optimize the discovery performance. VM-NSP and its implementation bM-NSP form the first VR-based approach for complete NSP mining with LNEC. Theoretical analyses and experiments confirm the performance superiority of bM-NSP on synthetic and real-life datasets w.r.t. diverse data factors, which substantially expands existing NSP mining methods toward flexible NSP discovery.}
}


@article{DBLP:journals/tois/Zhang21,
	author = {Min Zhang},
	title = {Editorial Message from the New Editor-in-Chief},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {23e:1--23e:2},
	year = {2021},
	url = {https://doi.org/10.1145/3447945},
	doi = {10.1145/3447945},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/Zhang21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {No abstract available.}
}


@article{DBLP:journals/tois/XuZY21,
	author = {Yanan Xu and
                  Yanmin Zhu and
                  Jiadi Yu},
	title = {Modeling Multiple Coexisting Category-Level Intentions for Next Item
                  Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {23:1--23:24},
	year = {2021},
	url = {https://doi.org/10.1145/3441642},
	doi = {10.1145/3441642},
	timestamp = {Tue, 25 Mar 2025 14:42:32 +0100},
	biburl = {https://dblp.org/rec/journals/tois/XuZY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Purchase intentions have a great impact on future purchases and thus can be exploited for making recommendations. However, purchase intentions are typically complex and may change from time to time. Through empirical study with two e-commerce datasets, we observe that behaviors of multiple types can indicate user intentions and a user may have multiple coexisting category-level intentions that evolve over time. In this article, we propose a novel Intention-Aware Recommender System (IARS) which consists of four components for mining such complex intentions from user behaviors of multiple types. In the first component, we utilize several Recurrent Neural Networks (RNNs) and an attention layer to model diverse user intentions simultaneously and design two kinds of Multi-behavior GRU (MGRU) cells to deal with heterogeneous behaviors. To reveal user intentions, we carefully design three tasks that share representations from MGRUs. The next-item recommendation is the main task and leverages attention to select user intentions according to candidate items. The remaining two (item prediction and sequence comparison) are auxiliary tasks and can reveal user intentions. Extensive experiments on the two real-world datasets demonstrate the effectiveness of our models compared with several state-of-the-art recommendation methods in terms of hit ratio and NDCG.}
}


@article{DBLP:journals/tois/WangC21a,
	author = {Wei Wang and
                  Longbing Cao},
	title = {Interactive Sequential Basket Recommendation by Learning Basket Couplings
                  and Positive/Negative Feedback},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {24:1--24:26},
	year = {2021},
	url = {https://doi.org/10.1145/3444368},
	doi = {10.1145/3444368},
	timestamp = {Mon, 12 May 2025 21:00:07 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WangC21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential recommendation , such as  next-basket recommender systems  (NBRS), which model users’ sequential behaviors and the relevant context/session, has recently attracted much attention from the research community. Existing  session-based NBRS  involve session representation and inter-basket relations but ignore their hybrid couplings with the intra-basket items, often producing irrelevant or similar items in the next basket. In addition, they do not predict next-baskets (more than one next basket recommended).  Interactive recommendation  further involves user feedback on the recommended basket. The existing work on next-item recommendation involves positive feedback on selected items but ignores negative feedback on unselected ones. Here, we introduce a new setting— interactive sequential basket recommendation , which iteratively predicts next baskets by learning the intra-/inter-basket couplings between items and both positive and negative user feedback on recommended baskets. A  hierarchical attentive encoder-decoder model  (HAEM) continuously recommends next baskets one after another during sequential interactions with users after analyzing the item relations both within a basket and between adjacent sequential baskets (i.e., intra-/inter-basket couplings) and incorporating the user selection and unselection (i.e., positive/negative) feedback on the recommended baskets to refine NBRS. HAEM comprises a basket encoder and a sequence decoder to model intra-/inter-basket couplings and a prediction decoder to sequentially predict next-baskets by interactive feedback-based refinement. Empirical analysis shows that HAEM significantly outperforms the state-of-the-art baselines for NBRS and session-based recommenders for accurate and novel recommendation. We also show the effect of continuously refining sequential basket recommendation by including unselection feedback during interactive recommendation.}
}


@article{DBLP:journals/tois/LiuWPWWJ21,
	author = {Hongtao Liu and
                  Wenjun Wang and
                  Qiyao Peng and
                  Nannan Wu and
                  Fangzhao Wu and
                  Pengfei Jiao},
	title = {Toward Comprehensive User and Item Representations via Three-tier
                  Attention Network},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {25:1--25:22},
	year = {2021},
	url = {https://doi.org/10.1145/3446341},
	doi = {10.1145/3446341},
	timestamp = {Wed, 17 Jan 2024 12:44:48 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiuWPWWJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Product reviews can provide rich information about the opinions users have of products. However, it is nontrivial to effectively infer user preference and item characteristics from reviews due to the complicated semantic understanding. Existing methods usually learn features for users and items from reviews in single static fashions and cannot fully capture user preference and item features. In this article, we propose a neural review-based recommendation approach that aims to learn comprehensive representations of users/items under a three-tier attention framework. We design a review encoder to learn review features from words via a word-level attention, an aspect encoder to learn aspect features via a review-level attention, and a user/item encoder to learn the final representations of users/items via an aspect-level attention. In word- and review-level attentions, we adopt the context-aware mechanism to indicate importance of words and reviews dynamically instead of static attention weights. In addition, the attentions in the word and review levels are of multiple paradigms to learn multiple features effectively, which could indicate the diversity of user/item features. Furthermore, we propose a personalized aspect-level attention module in user/item encoder to learn the final comprehensive features. Extensive experiments are conducted and the results in rating prediction validate the effectiveness of our method.}
}


@article{DBLP:journals/tois/ZengZTLG21,
	author = {Weixin Zeng and
                  Xiang Zhao and
                  Jiuyang Tang and
                  Xuemin Lin and
                  Paul Groth},
	title = {Reinforcement Learning-based Collective Entity Alignment with Adaptive
                  Features},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {26:1--26:31},
	year = {2021},
	url = {https://doi.org/10.1145/3446428},
	doi = {10.1145/3446428},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZengZTLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity alignment (EA) is the task of identifying the entities that refer to the same real-world object but are located in different knowledge graphs (KGs). For entities to be aligned, existing EA solutions treat them separately and generate alignment results as ranked lists of entities on the other side. Nevertheless, this decision-making paradigm fails to take into account the interdependence among entities. Although some recent efforts mitigate this issue by imposing the 1-to-1 constraint on the alignment process, they still cannot adequately model the underlying interdependence and the results tend to be sub-optimal. To fill in this gap, in this work, we delve into the dynamics of the decision-making process, and offer a reinforcement learning (RL)–based model to align entities collectively. Under the RL framework, we devise the coherence and exclusiveness constraints to characterize the interdependence and restrict collective alignment. Additionally, to generate more precise inputs to the RL framework, we employ representative features to capture different aspects of the similarity between entities in heterogeneous KGs, which are integrated by an adaptive feature fusion strategy. Our proposal is evaluated on both cross-lingual and mono-lingual EA benchmarks and compared against state-of-the-art solutions. The empirical results verify its effectiveness and superiority.}
}


@article{DBLP:journals/tois/YaoDXW21,
	author = {Jing Yao and
                  Zhicheng Dou and
                  Jun Xu and
                  Ji{-}Rong Wen},
	title = {{RLPS:} {A} Reinforcement Learning-Based Framework for Personalized
                  Search},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {27:1--27:29},
	year = {2021},
	url = {https://doi.org/10.1145/3446617},
	doi = {10.1145/3446617},
	timestamp = {Tue, 21 Mar 2023 21:04:27 +0100},
	biburl = {https://dblp.org/rec/journals/tois/YaoDXW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized search is a promising way to improve search qualities by taking user interests into consideration. Recently, machine learning and deep learning techniques have been successfully applied to search result personalization. Most existing models simply regard the personal search history as a static set of user behaviors and learn fixed ranking strategies based on all the recorded data. Though improvements have been achieved, the essence that the search process is a sequence of interactions between the search engine and user is ignored. The user’s interests may dynamically change during the search process, therefore, it would be more helpful if a personalized search model could track the whole interaction process and adjust its ranking strategy continuously. In this article, we adapt reinforcement learning to personalized search and propose a framework, referred to as RLPS. It utilizes a  Markov Decision Process  ( MDP ) to track sequential interactions between the user and search engine, and continuously update the underlying personalized ranking model with the user’s real-time feedback to learn the user’s dynamic interests. Within this framework, we implement two models: the listwise RLPS-L and the hierarchical RLPS-H. RLPS-L interacts with users and trains the ranking model with document lists, while RLPS-H improves model training by designing a layered structure and introducing document pairs. In addition, we also design a feedback-aware personalized ranking component to capture the user’s feedback, which impacts the user interest profile for the next query. Significant improvements over existing personalized search models are observed in the experiments on the public AOL search log and a commercial log.}
}


@article{DBLP:journals/tois/WangLZW21,
	author = {Jingyuan Wang and
                  Xin Lin and
                  Yuan Zuo and
                  Junjie Wu},
	title = {DGeye: Probabilistic Risk Perception and Prediction for Urban Dangerous
                  Goods Management},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {28:1--28:30},
	year = {2021},
	url = {https://doi.org/10.1145/3448256},
	doi = {10.1145/3448256},
	timestamp = {Mon, 13 Jan 2025 16:16:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WangLZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed the emergence of worldwide megalopolises and the accompanying public safety events, making urban safety a top priority in modern urban management. Among various threats, dangerous goods such as gas and hazardous chemicals transported through cities have bred repeated tragedies and become the deadly “bomb” we sleep with every day. While tremendous research efforts have been devoted to dealing with dangerous goods transportation (DGT) issues, further study is still in great need to quantify this problem and explore its intrinsic dynamics from a big data perspective. In this article, we present a novel system called  DGeye , to feature a fusion between DGT trajectory data and residential population data for dangers perception and prediction. Specifically,  DGeye  first develops a probabilistic graphical model-based approach to mine spatio-temporally adjacent risk patterns from population-aware risk trajectories. Then,  DGeye  builds the novel causality network among risk patterns for risk pain-point identification, risk source attribution, and online risky state prediction. Experiments on both Beijing and Tianjin cities demonstrate the effectiveness of  DGeye  in real-life DGT risk management. As a case in point, our report powered by  DGeye  successfully drove the government to lay down gas pipelines for the famous Guijie food street in Beijing.}
}


@article{DBLP:journals/tois/AliannejadiZCC21,
	author = {Mohammad Aliannejadi and
                  Hamed Zamani and
                  Fabio Crestani and
                  W. Bruce Croft},
	title = {Context-aware Target Apps Selection and Recommendation for Enhancing
                  Personal Mobile Assistants},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {29:1--29:30},
	year = {2021},
	url = {https://doi.org/10.1145/3447678},
	doi = {10.1145/3447678},
	timestamp = {Wed, 07 Dec 2022 23:04:16 +0100},
	biburl = {https://dblp.org/rec/journals/tois/AliannejadiZCC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Users install many apps on their smartphones, raising issues related to information overload for users and resource management for devices. Moreover, the recent increase in the use of personal assistants has made mobile devices even more pervasive in users’ lives. This article addresses two research problems that are vital for developing effective personal mobile assistants:  target apps selection  and  recommendation . The former is the key component of a unified mobile search system: a system that addresses the users’ information needs for all the apps installed on their devices with a unified mode of access. The latter, instead, predicts the next apps that the users would want to launch. Here we focus on context-aware models to leverage the rich contextual information available to mobile devices. We design an  in situ  study to collect thousands of mobile queries enriched with mobile sensor data (now publicly available for research purposes). With the aid of this dataset, we study the user behavior in the context of these tasks and propose a family of context-aware neural models that take into account the sequential, temporal, and personal behavior of users. We study several state-of-the-art models and show that the proposed models significantly outperform the baselines.}
}


@article{DBLP:journals/tois/ChenMLYMWZM21,
	author = {Jia Chen and
                  Jiaxin Mao and
                  Yiqun Liu and
                  Ziyi Ye and
                  Weizhi Ma and
                  Chao Wang and
                  Min Zhang and
                  Shaoping Ma},
	title = {A Hybrid Framework for Session Context Modeling},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {30:1--30:35},
	year = {2021},
	url = {https://doi.org/10.1145/3448127},
	doi = {10.1145/3448127},
	timestamp = {Sat, 26 Aug 2023 17:33:03 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ChenMLYMWZM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Understanding user intent is essential for various retrieval tasks. By leveraging contextual information within sessions, e.g., query history and user click behaviors, search systems can capture user intent more accurately and thus perform better. However, most existing systems only consider intra-session contexts and may suffer from the problem of lacking contextual information, because short search sessions account for a large proportion in practical scenarios. We believe that in these scenarios, considering more contexts, e.g., cross-session dependencies, may help alleviate the problem and contribute to better performance. Therefore, we propose a novel Hybrid framework for Session Context Modeling (HSCM), which realizes session-level multi-task learning based on the self-attention mechanism. To alleviate the problem of lacking contextual information within current sessions, HSCM exploits the cross-session contexts by sampling user interactions under similar search intents in the historical sessions and further aggregating them into the local contexts. Besides, application of the self-attention mechanism rather than RNN-based frameworks in modeling session-level sequences also helps (1) better capture interactions within sessions, (2) represent the session contexts in parallelization. Experimental results on two practical search datasets show that HSCM not only outperforms strong baseline solutions such as HiNT, CARS, and BERTserini in document ranking, but also performs significantly better than most existing query suggestion methods. According to the results in an additional experiment, we have also found that HSCM is superior to most ranking models in click prediction.}
}


@article{DBLP:journals/tois/VuongAJR21,
	author = {Tung Thanh Vuong and
                  Salvatore Andolina and
                  Giulio Jacucci and
                  Tuukka Ruotsalo},
	title = {Spoken Conversational Context Improves Query Auto-completion in Web
                  Search},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {31:1--31:32},
	year = {2021},
	url = {https://doi.org/10.1145/3447875},
	doi = {10.1145/3447875},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/VuongAJR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web searches often originate from conversations in which people engage before they perform a search. Therefore, conversations can be a valuable source of context with which to support the search process. We investigate whether spoken input from conversations can be used as a context to improve query auto-completion. We model the temporal dynamics of the spoken conversational context preceding queries and use these models to re-rank the query auto-completion suggestions. Data were collected from a controlled experiment and comprised conversations among 12 participant pairs conversing about movies or traveling. Search query logs during the conversations were recorded and temporally associated with the conversations. We compared the effects of spoken conversational input in four conditions: a control condition without contextualization; an experimental condition with the model using search query logs; an experimental condition with the model using spoken conversational input; and an experimental condition with the model using both search query logs and spoken conversational input. We show the advantage of combining the spoken conversational context with the Web-search context for improved retrieval performance. Our results suggest that spoken conversations provide a rich context for supporting information searches beyond current user-modeling approaches.}
}


@article{DBLP:journals/tois/YangHSJLN21,
	author = {Tianchi Yang and
                  Linmei Hu and
                  Chuan Shi and
                  Houye Ji and
                  Xiaoli Li and
                  Liqiang Nie},
	title = {{HGAT:} Heterogeneous Graph Attention Networks for Semi-supervised
                  Short Text Classification},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {32:1--32:29},
	year = {2021},
	url = {https://doi.org/10.1145/3450352},
	doi = {10.1145/3450352},
	timestamp = {Sun, 02 Feb 2025 19:33:49 +0100},
	biburl = {https://dblp.org/rec/journals/tois/YangHSJLN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Short text classification has been widely explored in news tagging to provide more efficient search strategies and more effective search results for information retrieval. However, most existing studies, concentrating on long text classification, deliver unsatisfactory performance on short texts due to the sparsity issue and the insufficiency of labeled data. In this article, we propose a novel heterogeneous graph neural network-based method for semi-supervised short text classification, leveraging full advantage of limited labeled data and large unlabeled data through information propagation along the graph. Specifically, we first present a flexible heterogeneous information network (HIN) framework for modeling short texts, which can integrate any type of additional information and meanwhile capture their relations to address the semantic sparsity. Then, we propose Heterogeneous Graph Attention networks (HGAT) to embed the HIN for short text classification based on a dual-level attention mechanism, including node-level and type-level attentions. To efficiently classify new coming texts that do not previously exist in the HIN, we extend our model HGAT for inductive learning, avoiding re-training the model on the evolving HIN. Extensive experiments on single-/multi-label classification demonstrates that our proposed model HGAT significantly outperforms state-of-the-art methods across the benchmark datasets under both transductive and inductive learning.}
}


@article{DBLP:journals/tois/ClarkeVS21,
	author = {Charles L. A. Clarke and
                  Alexandra Vtyurina and
                  Mark D. Smucker},
	title = {Assessing Top- Preferences},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {33:1--33:21},
	year = {2021},
	url = {https://doi.org/10.1145/3451161},
	doi = {10.1145/3451161},
	timestamp = {Sat, 09 Apr 2022 12:20:33 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ClarkeVS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Assessors make preference judgments faster and more consistently than graded judgments. Preference judgments can also recognize distinctions between items that appear equivalent under graded judgments. Unfortunately, preference judgments can require more than linear effort to fully order a pool of items, and evaluation measures for preference judgments are not as well established as those for graded judgments, such as NDCG. In this article, we explore the assessment process for partial preference judgments, with the aim of identifying and ordering the top items in the pool, rather than fully ordering the entire pool. To measure the performance of a ranker, we compare its output to this preferred ordering by applying a rank similarity measure. We demonstrate the practical feasibility of this approach by crowdsourcing partial preferences for the TREC 2019 Conversational Assistance Track, replacing NDCG with a new measure named  compatibility . This new measure has its most striking impact when comparing modern neural rankers, where it is able to recognize significant improvements in quality that would otherwise be missed by NDCG.}
}


@article{DBLP:journals/tois/ChenJWZFCEH21,
	author = {Jiawei Chen and
                  Chengquan Jiang and
                  Can Wang and
                  Sheng Zhou and
                  Yan Feng and
                  Chun Chen and
                  Martin Ester and
                  Xiangnan He},
	title = {CoSam: An Efficient Collaborative Adaptive Sampler for Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {34:1--34:24},
	year = {2021},
	url = {https://doi.org/10.1145/3450289},
	doi = {10.1145/3450289},
	timestamp = {Tue, 26 Apr 2022 15:09:45 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ChenJWZFCEH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sampling strategies have been widely applied in many recommendation systems to accelerate model learning from implicit feedback data. A typical strategy is to draw negative instances with uniform distribution, which, however, will severely affect a model’s convergence, stability, and even recommendation accuracy. A promising solution for this problem is to over-sample the “difficult” (a.k.a. informative) instances that contribute more on training. But this will increase the risk of biasing the model and leading to non-optimal results. Moreover, existing samplers are either heuristic, which require domain knowledge and often fail to capture real “difficult” instances, or rely on a sampler model that suffers from low efficiency. To deal with these problems, we propose CoSam, an efficient and effective collaborative sampling method that consists of (1) a collaborative sampler model that explicitly leverages user-item interaction information in sampling probability and exhibits good properties of normalization, adaption, interaction information awareness, and sampling efficiency, and (2) an integrated sampler-recommender framework, leveraging the sampler model in prediction to offset the bias caused by uneven sampling. Correspondingly, we derive a fast reinforced training algorithm of our framework to boost the sampler performance and sampler-recommender collaboration. Extensive experiments on four real-world datasets demonstrate the superiority of the proposed collaborative sampler model and integrated sampler-recommender framework.}
}


@article{DBLP:journals/tois/ZhangYYHSCJC21,
	author = {Chuxu Zhang and
                  Huaxiu Yao and
                  Lu Yu and
                  Chao Huang and
                  Dongjin Song and
                  Haifeng Chen and
                  Meng Jiang and
                  Nitesh V. Chawla},
	title = {Inductive Contextual Relation Learning for Personalization},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {35:1--35:22},
	year = {2021},
	url = {https://doi.org/10.1145/3450353},
	doi = {10.1145/3450353},
	timestamp = {Thu, 14 Oct 2021 08:47:45 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ZhangYYHSCJC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web personalization, e.g., recommendation or relevance search, tailoring a service/product to accommodate specific online users, is becoming increasingly important. Inductive personalization aims to infer the relations between existing entities and unseen new ones, e.g., searching relevant authors for new papers or recommending new items to users. This problem, however, is challenging since most of recent studies focus on transductive problem for existing entities. In addition, despite some inductive learning approaches have been introduced recently, their performance is sub-optimal due to relatively simple and inflexible architectures for aggregating entity’s content. To this end, we propose the inductive contextual personalization (ICP) framework through contextual relation learning. Specifically, we first formulate the pairwise relations between entities with a ranking optimization scheme that employs neural aggregator to fuse entity’s heterogeneous contents. Next, we introduce a node embedding term to capture entity’s contextual relations, as a smoothness constraint over the prior ranking objective. Finally, the gradient descent procedure with adaptive negative sampling is employed to learn the model parameters. The learned model is capable of inferring the relations between existing entities and inductive ones. Thorough experiments demonstrate that ICP outperforms numerous baseline methods for two different applications, i.e., relevant author search and new item recommendation.}
}


@article{DBLP:journals/tois/Mena-MaldonadoC21,
	author = {Elisa Mena{-}Maldonado and
                  Roc{\'{\i}}o Ca{\~{n}}amares and
                  Pablo Castells and
                  Yongli Ren and
                  Mark Sanderson},
	title = {Popularity Bias in False-positive Metrics for Recommender Systems
                  Evaluation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {36:1--36:43},
	year = {2021},
	url = {https://doi.org/10.1145/3452740},
	doi = {10.1145/3452740},
	timestamp = {Wed, 01 Sep 2021 12:44:06 +0200},
	biburl = {https://dblp.org/rec/journals/tois/Mena-MaldonadoC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the impact of popularity bias in false-positive metrics in the offline evaluation of recommender systems. Unlike their true-positive complements, false-positive metrics reward systems that minimize recommendations disliked by users. Our analysis is, to the best of our knowledge, the first to show that false-positive metrics tend to penalise popular items, the opposite behavior of true-positive metrics—causing a disagreement trend between both types of metrics in the presence of popularity biases. We present a theoretical analysis of the metrics that identifies the reason that the metrics disagree and determines rare situations where the metrics might agree—the key to the situation lies in the relationship between popularity and relevance distributions, in terms of their  agreement  and  steepness —two fundamental concepts we formalize. We then examine three well-known datasets using multiple popular true- and false-positive metrics on 16 recommendation algorithms. Specific datasets are chosen to allow us to estimate both biased and unbiased metric values. The results of the empirical study confirm and illustrate our analytical findings. With the conditions of the disagreement of the two types of metrics established, we then determine under which circumstances true-positive or false-positive metrics should be used by researchers of offline evaluation in recommender systems. 1}
}


@article{DBLP:journals/tois/ZhangZLCX21,
	author = {Qi Zhang and
                  Hengshu Zhu and
                  Qi Liu and
                  Enhong Chen and
                  Hui Xiong},
	title = {Exploiting Real-time Search Engine Queries for Earthquake Detection:
                  {A} Summary of Results},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {3},
	pages = {37:1--37:32},
	year = {2021},
	url = {https://doi.org/10.1145/3453842},
	doi = {10.1145/3453842},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangZLCX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online search engine has been widely regarded as the most convenient approach for information acquisition. Indeed, the intensive information-seeking behaviors of search engine users make it possible to exploit search engine queries as effective “crowd sensors” for event monitoring. While some researchers have investigated the feasibility of using search engine queries for coarse-grained event analysis, the capability of search engine queries for real-time event detection has been largely neglected. To this end, in this article, we introduce a large-scale and systematic study on exploiting real-time search engine queries for outbreak event detection, with a focus on earthquake rapid reporting. In particular, we propose a realistic system of real-time earthquake detection through monitoring millions of queries related to earthquakes from a dominant online search engine in China. Specifically, we first investigate a large set of queries for selecting the representative queries that are highly correlated with the outbreak of earthquakes. Then, based on the real-time streams of selected queries, we design a novel machine learning–enhanced two-stage burst detection approach for detecting earthquake events. Meanwhile, the location of an earthquake epicenter can be accurately estimated based on the spatial-temporal distribution of search engine queries. Finally, through the extensive comparison with earthquake catalogs from China Earthquake Networks Center, 2015, the detection precision of our system can achieve 87.9%, and the accuracy of location estimation (province level) is 95.7%. In particular, 50% of successfully detected results can be found within 62 s after earthquake, and 50% of successful locations can be found within 25.5 km of seismic epicenter. Our system also found more than 23.3% extra earthquakes that were felt by people but not publicly released, 12.1% earthquake-like special outbreaks, and meanwhile, revealed many interesting findings, such as the typical query patterns of earthquake rumor and regular memorial events. Based on these results, our system can timely feed back information to the search engine users according to various cases and accelerate the information release of felt earthquakes.}
}


@article{DBLP:journals/tois/HauffKSZZ21,
	author = {Claudia Hauff and
                  Julia Kiseleva and
                  Mark Sanderson and
                  Hamed Zamani and
                  Yongfeng Zhang},
	title = {Conversational Search and Recommendation: Introduction to the Special
                  Issue},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {38:1--38:6},
	year = {2021},
	url = {https://doi.org/10.1145/3465272},
	doi = {10.1145/3465272},
	timestamp = {Tue, 07 May 2024 20:25:55 +0200},
	biburl = {https://dblp.org/rec/journals/tois/HauffKSZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/tois/ThomasCMC21,
	author = {Paul Thomas and
                  Mary Czerwinski and
                  Daniel McDuff and
                  Nick Craswell},
	title = {Theories of Conversation for Conversational {IR}},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {39:1--39:23},
	year = {2021},
	url = {https://doi.org/10.1145/3439869},
	doi = {10.1145/3439869},
	timestamp = {Mon, 26 Jun 2023 20:57:23 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ThomasCMC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conversational information retrieval is a relatively new and fast-developing research area, but conversation itself has been well studied for decades. Researchers have analysed linguistic phenomena such as structure and semantics but also paralinguistic features such as tone, body language, and even the physiological states of interlocutors. We tend to treat computers as social agents—especially if they have some humanlike features in their design—and so work from human-to-human conversation is highly relevant to how we think about the design of human-to-computer applications. In this article, we summarise some salient past work, focusing on social norms; structures; and affect, prosody, and style. We examine social communication theories briefly as a review to see what we have learned about how humans interact with each other and how that might pertain to agents and robots. We also discuss some implications for research and design of conversational IR systems.}
}


@article{DBLP:journals/tois/LiLWHJC21,
	author = {Shijun Li and
                  Wenqiang Lei and
                  Qingyun Wu and
                  Xiangnan He and
                  Peng Jiang and
                  Tat{-}Seng Chua},
	title = {Seamlessly Unifying Attributes and Items: Conversational Recommendation
                  for Cold-start Users},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {40:1--40:29},
	year = {2021},
	url = {https://doi.org/10.1145/3446427},
	doi = {10.1145/3446427},
	timestamp = {Wed, 12 Feb 2025 15:21:27 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiLWHJC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Static recommendation methods like collaborative filtering suffer from the inherent limitation of performing real-time personalization for cold-start users. Online recommendation, e.g., multi-armed bandit approach, addresses this limitation by interactively exploring user preference online and pursuing the exploration-exploitation (EE) trade-off. However, existing bandit-based methods model recommendation actions homogeneously. Specifically, they only consider the  items  as the arms, being incapable of handling the  item attributes , which naturally provide interpretable information of user’s current demands and can effectively filter out undesired items. In this work, we consider the conversational recommendation for cold-start users, where a system can both ask the attributes from and recommend items to a user interactively. This important scenario was studied in a recent work \xa0[54]. However, it employs a hand-crafted function to decide when to ask attributes or make recommendations. Such separate modeling of attributes and items makes the effectiveness of the system highly rely on the choice of the hand-crafted function, thus introducing fragility to the system. To address this limitation, we seamlessly unify attributes and items in the same arm space and achieve their EE trade-offs automatically using the framework of Thompson Sampling. Our  Conversational Thompson Sampling  (ConTS) model holistically solves all questions in conversational recommendation by choosing the arm with the maximal reward to play. Extensive experiments on three benchmark datasets show that ConTS outperforms the state-of-the-art methods  Conversational UCB  (ConUCB)\xa0[54] and  Estimation—Action—Reflection  model\xa0[27] in both metrics of success rate and average number of conversation turns.}
}


@article{DBLP:journals/tois/ContrerasSB21,
	author = {David Contreras and
                  Maria Salam{\'{o}} and
                  Ludovico Boratto},
	title = {Integrating Collaboration and Leadership in Conversational Group Recommender
                  Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {41:1--41:32},
	year = {2021},
	url = {https://doi.org/10.1145/3462759},
	doi = {10.1145/3462759},
	timestamp = {Sun, 04 Aug 2024 19:51:35 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ContrerasSB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent observational studies highlight the importance of considering the interactions between users in the group recommendation process, but to date their integration has been marginal. In this article, we propose a collaborative model based on the social interactions that take place in a web-based conversational group recommender system. The collaborative model allows the group recommender to implicitly infer the different roles within the group, namely, collaborative and leader user(s). Moreover, it serves as the basis of several novel collaboration-based consensus strategies that integrate both individual and social interactions in the group recommendation process. A live-user evaluation confirms that our approach accurately identifies the collaborative and leader users in a group and produces more effective recommendations.}
}


@article{DBLP:journals/tois/WilkinsonALMVKD21,
	author = {Daricia Wilkinson and
                  {\"{O}}znur Alkan and
                  Q. Vera Liao and
                  Massimiliano Mattetti and
                  Inge Vejsbjerg and
                  Bart P. Knijnenburg and
                  Elizabeth Daly},
	title = {Why or Why Not? The Effect of Justification Styles on Chatbot Recommendations},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {42:1--42:21},
	year = {2021},
	url = {https://doi.org/10.1145/3441715},
	doi = {10.1145/3441715},
	timestamp = {Mon, 03 Mar 2025 22:25:55 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WilkinsonALMVKD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Chatbots or conversational recommenders have gained increasing popularity as a new paradigm for Recommender Systems (RS). Prior work on RS showed that providing explanations can improve transparency and trust, which are critical for the adoption of RS. Their interactive and engaging nature makes conversational recommenders a natural platform to not only provide recommendations but also justify the recommendations through explanations. The recent surge of interest inexplainable AI enables diverse styles of justification, and also invites questions on how styles of justification impact user perception. In this article, we explore the effect of “why” justifications and “why not” justifications on users’ perceptions of explainability and trust. We developed and tested a movie-recommendation chatbot that provides users with different types of justifications for the recommended items. Our online experiment ( n  = 310) demonstrates that the “why” justifications (but not the “why not” justifications) have a significant impact on users’ perception of the conversational recommender. Particularly, “why” justifications increase users’ perception of system transparency, which impacts perceived control, trusting beliefs and in turn influences users’ willingness to depend on the system’s advice. Finally, we discuss the design implications for decision-assisting chatbots.}
}


@article{DBLP:journals/tois/WeiLMGZZHF21,
	author = {Wei Wei and
                  Jiayi Liu and
                  Xianling Mao and
                  Guibing Guo and
                  Feida Zhu and
                  Pan Zhou and
                  Yuchong Hu and
                  Shanshan Feng},
	title = {Target-guided Emotion-aware Chat Machine},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {43:1--43:24},
	year = {2021},
	url = {https://doi.org/10.1145/3456414},
	doi = {10.1145/3456414},
	timestamp = {Sun, 09 Feb 2025 10:52:28 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WeiLMGZZHF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The consistency of a response to a given post at the  semantic  level and  emotional  level is essential for a dialogue system to deliver humanlike interactions. However, this challenge is not well addressed in the literature, since most of the approaches neglect the emotional information conveyed by a post while generating responses. This article addresses this problem and proposes a  unified  end-to-end neural architecture, which is capable of simultaneously encoding the  semantics  and the  emotions  in a post and leveraging target information to generate more intelligent responses with appropriately expressed emotions. Extensive experiments on real-world data demonstrate that the proposed method outperforms the state-of-the-art methods in terms of both content coherence and emotion appropriateness.}
}


@article{DBLP:journals/tois/XuTFWYZ21,
	author = {Ruijian Xu and
                  Chongyang Tao and
                  Jiazhan Feng and
                  Wei Wu and
                  Rui Yan and
                  Dongyan Zhao},
	title = {Response Ranking with Multi-types of Deep Interactive Representations
                  in Retrieval-based Dialogues},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {44:1--44:28},
	year = {2021},
	url = {https://doi.org/10.1145/3462207},
	doi = {10.1145/3462207},
	timestamp = {Sun, 19 Jan 2025 15:03:41 +0100},
	biburl = {https://dblp.org/rec/journals/tois/XuTFWYZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Building an intelligent dialogue system with the ability to select a proper response according to a multi-turn context is challenging in three aspects: (1) the meaning of a context–response pair is built upon language units from multiple granularities (e.g., words, phrases, and sub-sentences, etc.); (2) local (e.g., a small window around a word) and long-range (e.g., words across the context and the response) dependencies may exist in dialogue data; and (3) the relationship between the context and the response candidate lies in multiple relevant semantic clues or relatively implicit semantic clues in some real cases. However, existing approaches usually encode the dialogue with mono-type representation and the interaction processes between the context and the response candidate are executed in a rather shallow manner, which may lead to an inadequate understanding of dialogue content and hinder the recognition of the semantic relevance between the context and response. To tackle these challenges, we propose a representation [ K ] -interaction [ L ] -matching framework that explores multiple types of deep interactive representations to build context-response matching models for response selection. Particularly, we construct different types of representations for utterance–response pairs and deepen them via alternate encoding and interaction. By this means, the model can handle the relation of neighboring elements, phrasal pattern, and long-range dependencies during the representation and make a more accurate prediction through multiple layers of interactions between the context–response pair. Experiment results on three public benchmarks indicate that the proposed model significantly outperforms previous conventional context-response matching models and achieve slightly better results than the BERT model for multi-turn response selection in retrieval-based dialogue systems.}
}


@article{DBLP:journals/tois/LiLTCZZY21,
	author = {Juntao Li and
                  Chang Liu and
                  Chongyang Tao and
                  Zhangming Chan and
                  Dongyan Zhao and
                  Min Zhang and
                  Rui Yan},
	title = {Dialogue History Matters! Personalized Response Selection in Multi-Turn
                  Retrieval-Based Chatbots},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {45:1--45:25},
	year = {2021},
	url = {https://doi.org/10.1145/3453183},
	doi = {10.1145/3453183},
	timestamp = {Mon, 21 Aug 2023 20:37:18 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LiLTCZZY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing multi-turn context-response matching methods mainly concentrate on obtaining multi-level and multi-dimension representations and better interactions between context utterances and response. However, in real-place conversation scenarios, whether a response candidate is suitable not only counts on the given dialogue context but also other backgrounds, e.g., wording habits, user-specific dialogue history content. To fill the gap between these up-to-date methods and the real-world applications, we incorporate user-specific dialogue history into the response selection and propose a personalized hybrid matching network (PHMN). Our contributions are two-fold: (1) our model extracts personalized wording behaviors from user-specific dialogue history as extra matching information; (2) we perform hybrid representation learning on context-response utterances and explicitly incorporate a customized attention mechanism to extract vital information from context-response interactions so as to improve the accuracy of matching. We evaluate our model on two large datasets with user identification, i.e., personalized Ubuntu dialogue Corpus (P-Ubuntu) and personalized Weibo dataset (P-Weibo). Experimental results confirm that our method significantly outperforms several strong models by combining personalized attention, wording behaviors, and hybrid representation learning.}
}


@article{DBLP:journals/tois/MustoNPGLS21,
	author = {Cataldo Musto and
                  Fedelucio Narducci and
                  Marco Polignano and
                  Marco de Gemmis and
                  Pasquale Lops and
                  Giovanni Semeraro},
	title = {MyrrorBot: {A} Digital Assistant Based on Holistic User Models for
                  Personalized Access to Online Services},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {46:1--46:34},
	year = {2021},
	url = {https://doi.org/10.1145/3447679},
	doi = {10.1145/3447679},
	timestamp = {Thu, 18 Nov 2021 09:20:11 +0100},
	biburl = {https://dblp.org/rec/journals/tois/MustoNPGLS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we present  MyrrorBot , a  personal digital assistant  implementing a natural language interface that allows the users to: (i) access online services, such as  music, video, news,  and food recommendation s, in a  personalized  way, by exploiting a strategy for implicit user modeling called  holistic user profiling ; (ii) query their own user models, to inspect the features encoded in their profiles and to increase their awareness of the personalization process. Basically, the system allows the users to formulate  natural language  requests related to their information needs. Such needs are roughly classified in two groups:  quantified self-related  needs (e.g.,  Did I sleep enough? Am I extrovert? ) and  personalized access  to online services (e.g.,  Play a song I like ). The  intent recognition  strategy implemented in the platform automatically identifies the intent expressed by the user and forwards the request to specific services and modules that generate an appropriate answer that fulfills the query. In the experimental evaluation, we evaluated both  qualitative  (users’ acceptance of the system, usability) as well as  quantitative  (time required to complete basic tasks, effectiveness of the personalization strategy) aspects of the system, and the results showed that  MyrrorBot  can improve the way people access online services and applications. This leads to a more effective interaction and paves the way for further development of our system.}
}


@article{DBLP:journals/tois/RenCRKMR21,
	author = {Pengjie Ren and
                  Zhumin Chen and
                  Zhaochun Ren and
                  Evangelos Kanoulas and
                  Christof Monz and
                  Maarten de Rijke},
	title = {Conversations with Search Engines: SERP-based Conversational Response
                  Generation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {47:1--47:29},
	year = {2021},
	url = {https://doi.org/10.1145/3432726},
	doi = {10.1145/3432726},
	timestamp = {Wed, 07 Dec 2022 23:04:16 +0100},
	biburl = {https://dblp.org/rec/journals/tois/RenCRKMR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we address the problem of answering complex information needs by conducting  conversations with search engines , in the sense that users can express their queries in natural language and directly receive the information they need from a short system response in a conversational manner. Recently, there have been some attempts towards a similar goal, e.g., studies on  Conversational Agent s (CAs) and  Conversational Search  (CS). However, they either do not address complex information needs in search scenarios or they are limited to the development of conceptual frameworks and/or laboratory-based user studies. We pursue two goals in this article: (1) the creation of a suitable dataset, the  Search as a Conversation  (SaaC) dataset, for the development of pipelines for conversations with search engines, and (2) the development of a state-of-the-art pipeline for conversations with search engines,  Conversations with Search Engines  (CaSE), using this dataset. SaaC is built based on a multi-turn conversational search dataset, where we further employ workers from a crowdsourcing platform to summarize each relevant passage into a short, conversational response. CaSE enhances the state-of-the-art by introducing a supporting token identification module and a prior-aware pointer generator, which enables us to generate more accurate responses. We carry out experiments to show that CaSE is able to outperform strong baselines. We also conduct extensive analyses on the SaaC dataset to show where there is room for further improvement beyond CaSE. Finally, we release the SaaC dataset and the code for CaSE and all models used for comparison to facilitate future research on this topic.}
}


@article{DBLP:journals/tois/LinYNTWL21,
	author = {Sheng{-}Chieh Lin and
                  Jheng{-}Hong Yang and
                  Rodrigo Nogueira and
                  Ming{-}Feng Tsai and
                  Chuan{-}Ju Wang and
                  Jimmy Lin},
	title = {Multi-Stage Conversational Passage Retrieval: An Approach to Fusing
                  Term Importance Estimation and Neural Query Rewriting},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {48:1--48:29},
	year = {2021},
	url = {https://doi.org/10.1145/3446426},
	doi = {10.1145/3446426},
	timestamp = {Tue, 25 Feb 2025 13:21:07 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LinYNTWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conversational search plays a vital role in conversational information seeking. As queries in information seeking dialogues are ambiguous for traditional ad hoc information retrieval (IR) systems due to the coreference and omission resolution problems inherent in natural language dialogue, resolving these ambiguities is crucial. In this article, we tackle conversational passage retrieval, an important component of conversational search, by addressing query ambiguities with query reformulation integrated into a multi-stage ad hoc IR system. Specifically, we propose two conversational query reformulation (CQR) methods: (1) term importance estimation and (2) neural query rewriting. For the former, we expand conversational queries using important terms extracted from the conversational context with frequency-based signals. For the latter, we reformulate conversational queries into natural, stand-alone, human-understandable queries with a pretrained sequence-to-sequence model. Detailed analyses of the two CQR methods are provided quantitatively and qualitatively, explaining their advantages, disadvantages, and distinct behaviors. Moreover, to leverage the strengths of both CQR methods, we propose combining their output with reciprocal rank fusion, yielding state-of-the-art retrieval effectiveness, 30% improvement in terms of NDCG@3 compared to the best submission of  Text REtrieval Conference (TREC) Conversational Assistant Track (CAsT)  2019.}
}


@article{DBLP:journals/tois/VakulenkoKR21,
	author = {Svitlana Vakulenko and
                  Evangelos Kanoulas and
                  Maarten de Rijke},
	title = {A Large-scale Analysis of Mixed Initiative in Information-Seeking
                  Dialogues for Conversational Search},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {49:1--49:32},
	year = {2021},
	url = {https://doi.org/10.1145/3466796},
	doi = {10.1145/3466796},
	timestamp = {Wed, 07 Dec 2022 23:04:16 +0100},
	biburl = {https://dblp.org/rec/journals/tois/VakulenkoKR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conversational search is a relatively young area of research that aims at automating an information-seeking dialogue. In this article, we help to position it with respect to other research areas within conversational artificial intelligence (AI) by analysing the structural properties of an information-seeking dialogue. To this end, we perform a large-scale dialogue analysis of more than 150K transcripts from 16 publicly available dialogue datasets. These datasets were collected to inform different dialogue-based tasks including conversational search. We extract different patterns of mixed initiative from these dialogue transcripts and use them to compare dialogues of different types. Moreover, we contrast the patterns found in information-seeking dialogues that are being used for research purposes with the patterns found in virtual reference interviews that were conducted by professional librarians. The insights we provide (1) establish close relations between conversational search and other conversational AI tasks and (2) uncover limitations of existing conversational datasets to inform future data collection tasks.}
}


@article{DBLP:journals/tois/KieselMPS21,
	author = {Johannes Kiesel and
                  Lars Meyer and
                  Martin Potthast and
                  Benno Stein},
	title = {Meta-Information in Conversational Search},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {50:1--50:44},
	year = {2021},
	url = {https://doi.org/10.1145/3468868},
	doi = {10.1145/3468868},
	timestamp = {Sun, 19 Jan 2025 15:03:44 +0100},
	biburl = {https://dblp.org/rec/journals/tois/KieselMPS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The exchange of meta-information has always formed part of information behavior. In this article, we show that this rule also extends to conversational search. Information about the user’s information need, their preferences, and the quality of search results are only some of the most salient examples of meta-information that are exchanged as a matter of course in a search conversation. To understand the importance of meta-information for conversational search, we revisit its definition and survey how meta-information has been taken into account in the past in information retrieval. Meta-information has gone by many names, about which a concise overview is provided. An in-depth analysis of the role of meta-information in search and conversation theories reveals that they provide significant support for the importance of meta-information in conversational search. We further identify conversational search datasets are suitable for a deeper inspection with regard to meta-information, namely, Spoken Conversational Search and Microsoft Information-Seeking Conversations. A quantitative data analysis demonstrates the practical significance of meta-information in information-seeking conversations, whereas a qualitative analysis shows the effects of exchanging different types. Finally, we discuss practical applications and challenges of meta-information in conversational search, including a case study of VERSE, an existing search system for the visually impaired.}
}


@article{DBLP:journals/tois/LipaniCY21,
	author = {Aldo Lipani and
                  Ben Carterette and
                  Emine Yilmaz},
	title = {How Am {I} Doing?: Evaluating Conversational Search Systems Offline},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {51:1--51:22},
	year = {2021},
	url = {https://doi.org/10.1145/3451160},
	doi = {10.1145/3451160},
	timestamp = {Mon, 03 Jan 2022 21:53:18 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LipaniCY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As conversational agents like Siri and Alexa gain in popularity and use, conversation is becoming a more and more important mode of interaction for search. Conversational search shares some features with traditional search, but differs in some important respects: conversational search systems are less likely to return ranked lists of results (a SERP), more likely to involve iterated interactions, and more likely to feature longer, well-formed user queries in the form of natural language questions. Because of these differences, traditional methods for search evaluation (such as the Cranfield paradigm) do not translate easily to conversational search. In this work, we propose a framework for offline evaluation of conversational search, which includes a methodology for creating test collections with relevance judgments, an evaluation measure based on a user interaction model, and an approach to collecting user interaction data to train the model. The framework is based on the idea of “subtopics”, often used to model novelty and diversity in search and recommendation, and the user model is similar to the geometric browsing model introduced by RBP and used in ERR. As far as we know, this is the first work to combine these ideas into a comprehensive framework for offline evaluation of conversational search.}
}


@article{DBLP:journals/tois/LiuZW21,
	author = {Zeyang Liu and
                  Ke Zhou and
                  Max L. Wilson},
	title = {Meta-evaluation of Conversational Search Evaluation Metrics},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {52:1--52:42},
	year = {2021},
	url = {https://doi.org/10.1145/3445029},
	doi = {10.1145/3445029},
	timestamp = {Thu, 18 Nov 2021 09:20:11 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiuZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conversational search systems, such as Google assistant and Microsoft Cortana, enable users to interact with search systems in multiple rounds through natural language dialogues. Evaluating such systems is very challenging, given that any natural language responses could be generated, and users commonly interact for multiple semantically coherent rounds to accomplish a search task. Although prior studies proposed many evaluation metrics, the extent of how those measures effectively capture user preference remain to be investigated. In this article, we systematically meta-evaluate a variety of conversational search metrics. We specifically study three perspectives on those metrics: (1)  reliability : the ability to detect “actual” performance differences as opposed to those observed by chance; (2)  fidelity : the ability to agree with ultimate user preference; and (3)  intuitiveness : the ability to capture any property deemed important: adequacy, informativeness, and fluency in the context of conversational search. By conducting experiments on two test collections, we find that the performance of different metrics vary significantly across different scenarios, whereas consistent with prior studies, existing metrics only achieve weak correlation with ultimate user preference and satisfaction. METEOR is, comparatively speaking, the best existing single-turn metric considering all three perspectives. We also demonstrate that adapted session-based evaluation metrics can be used to measure multi-turn conversational search, achieving moderate concordance with user satisfaction. To our knowledge, our work establishes the most comprehensive meta-evaluation for conversational search to date.}
}


@article{DBLP:journals/tois/CornoRR21,
	author = {Fulvio Corno and
                  Luigi De Russis and
                  Alberto Monge Roffarello},
	title = {From Users' Intentions to {IF-THEN} Rules in the Internet of Things},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {53:1--53:33},
	year = {2021},
	url = {https://doi.org/10.1145/3447264},
	doi = {10.1145/3447264},
	timestamp = {Sun, 19 Jan 2025 15:03:41 +0100},
	biburl = {https://dblp.org/rec/journals/tois/CornoRR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the Internet of Things era, users are willing to personalize the joint behavior of their connected entities, i.e., smart devices and online service, by means of trigger-action rules such as “IF the entrance  Nest  security camera detects a movement, THEN blink the  Philips Hue  lamp in the kitchen.” Unfortunately, the spread of new supported technologies makes the number of possible combinations between triggers and actions continuously growing, thus motivating the need of assisting users in discovering new rules and functionality, e.g., through recommendation techniques. To this end, we present  , a semantic Conversational Search and Recommendation (CSR) system able to suggest pertinent IF-THEN rules that can be easily deployed in different contexts starting from an abstract user’s need. By exploiting a conversational agent, the user can communicate her current personalization intention by specifying a set of functionality at a high level, e.g., to decrease the temperature of a room when she left it. Stemming from this input,   implements a semantic recommendation process that takes into account ( a ) the current user’s  intention , ( b ) the connected entities owned by the user, and ( c ) the user’s  long-term preferences  revealed by her profile. If not satisfied with the suggestions, then the user can converse with the system to provide further feedback, i.e., a  short-term preference , thus allowing   to provide refined recommendations that better align with the original intention. We evaluate   by running different offline experiments with simulated users and real-world data. First, we test the recommendation process in different configurations, and we show that recommendation accuracy and similarity with target items increase as the interaction between the algorithm and the user proceeds. Then, we compare   with other similar baseline recommender systems. Results are promising and demonstrate the effectiveness of   in recommending IF-THEN rules that satisfy the current personalization intention of the user.}
}


@article{DBLP:journals/tois/YanLZW21,
	author = {Rui Yan and
                  Weiheng Liao and
                  Dongyan Zhao and
                  Ji{-}Rong Wen},
	title = {Multi-Response Awareness for Retrieval-Based Conversations: Respond
                  with Diversity via Dynamic Representation Learning},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {39},
	number = {4},
	pages = {54:1--54:29},
	year = {2021},
	url = {https://doi.org/10.1145/3470450},
	doi = {10.1145/3470450},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/YanLZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conversational systems now attract great attention due to their promising potential and commercial values. To build a conversational system with moderate intelligence is challenging and requires big (conversational) data, as well as interdisciplinary techniques. Thanks to the prosperity of the Web, the massive data available greatly facilitate data-driven methods such as deep learning for human-computer conversational systems. In general, retrieval-based conversational systems apply various matching schema between query utterances and responses, but the classic retrieval paradigm suffers from prominent weakness for conversations: the system finds similar responses given a particular query. For real human-to-human conversations, on the contrary, responses can be greatly different yet all are possibly appropriate. The observation reveals the  diversity  phenomenon in conversations. In this article, we ascribe the lack of conversational diversity to the reason that the query utterances are statically modeled regardless of candidate responses through traditional methods. To this end, we propose a dynamic representation learning strategy that models the query utterances and different response candidates in an interactive way. To be more specific, we propose a  Respond-with-Diversity  model augmented by the memory module interacting with both the query utterances and multiple candidate responses. Hence, we obtain dynamic representations for the input queries conditioned on different response candidates. We frame the model as an end-to-end learnable neural network. In the experiments, we demonstrate the effectiveness of the proposed model by achieving a good appropriateness score and much better diversity in retrieval-based conversations between humans and computers.}
}
