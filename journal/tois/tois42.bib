@article{DBLP:journals/tois/WeiZHY24,
	author = {Lanning Wei and
                  Huan Zhao and
                  Zhiqiang He and
                  Quanming Yao},
	title = {Neural Architecture Search for GNN-Based Graph Classification},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {1:1--1:29},
	year = {2024},
	url = {https://doi.org/10.1145/3584945},
	doi = {10.1145/3584945},
	timestamp = {Mon, 09 Sep 2024 19:07:22 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WeiZHY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph classification is an important problem with applications across many domains, for which graph neural networks (GNNs) have been state-of-the-art (SOTA) methods. In the literature, to adopt GNNs for the graph classification task, there are two groups of methods: global pooling and hierarchical pooling. The global pooling methods obtain the graph representation vectors by globally pooling all of the node embeddings together at the end of several GNN layers, whereas the hierarchical pooling methods provide one extra pooling operation between the GNN layers to extract hierarchical information and improve the graph representations. Both global and hierarchical pooling methods are effective in different scenarios. Due to highly diverse applications, it is challenging to design data-specific pooling methods with human expertise. To address this problem, we propose PAS (Pooling Architecture Search) to design adaptive pooling architectures by using the neural architecture search (NAS). To enable the search space design, we propose a unified pooling framework consisting of four modules: Aggregation, Pooling, Readout, and Merge. Two variants, PAS-G and PAS-NE, are provided to design the pooling operations in different scales. A set of candidate operations is designed in the search space using this framework. Then, existing human-designed pooling methods, including global and hierarchical ones, can be incorporated. To enable efficient search, a coarsening strategy is developed to continuously relax the search space, and then a differentiable search method can be adopted. We conduct extensive experiments on six real-world datasets, including the large-scale datasets MR and ogbg-molhiv. Experimental results in this article demonstrate the effectiveness and efficiency of the proposed PAS in designing the pooling architectures for graph classification. The Top-1 performance on two Open Graph Benchmark (OGB) datasets 1  further indicates the utility of PAS when facing diverse realistic data. The implementation of PAS is available at: https://github.com/AutoML-Research/PAS.}
}


@article{DBLP:journals/tois/McGregorAH24,
	author = {Molly McGregor and
                  Leif Azzopardi and
                  Martin Halvey},
	title = {A Systematic Review of Cost, Effort, and Load Research in Information
                  Search and Retrieval, 1972-2020},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {2:1--2:39},
	year = {2024},
	url = {https://doi.org/10.1145/3583069},
	doi = {10.1145/3583069},
	timestamp = {Sun, 10 Dec 2023 17:01:03 +0100},
	biburl = {https://dblp.org/rec/journals/tois/McGregorAH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {During the information search and retrieval (ISR) process, user-system interactions such as submitting queries, examining results, and engaging with information impose some degree of demand on the user’s resources. Within ISR, these demands are well recognised, and numerous studies have demonstrated that the cost, effort, and load (CEL) experienced during the search process are affected by a variety of factors. Despite this recognition, there is no universally accepted definition of the constructs of CEL within the field of ISR. Ultimately, this has led to problems with how these constructs have been interpreted and subsequently measured. This systematic review contributes a synthesis of literature, summarising key findings relating to how researchers have been defining and measuring CEL within ISR over the past 50 years. After manually screening 1,109 articles, we detailed and analysed 91 articles which examine CEL within ISR. The discussion focuses on comparing the similarities and differences between CEL definitions and measures before identifying the limitations of the current state of the nomenclature. Opportunities for future research are also identified. Going forward, we propose a CEL taxonomy that integrates the relationships between CEL and their related constructs, which will help focus and disambiguate future research in this important area.}
}


@article{DBLP:journals/tois/XuPLSW24,
	author = {Hongyan Xu and
                  Qiyao Peng and
                  Hongtao Liu and
                  Yueheng Sun and
                  Wenjun Wang},
	title = {Group-Based Personalized News Recommendation with Long- and Short-Term
                  Fine-Grained Matching},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {3:1--3:27},
	year = {2024},
	url = {https://doi.org/10.1145/3584946},
	doi = {10.1145/3584946},
	timestamp = {Wed, 23 Apr 2025 14:00:53 +0200},
	biburl = {https://dblp.org/rec/journals/tois/XuPLSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized news recommendation aims to help users find news content they prefer, which has attracted increasing attention recently. There are two core issues in news recommendation: learning news representation and matching candidate news with user interests. In this context, “candidate” indicates potential for interest. Due to the superior ability to understand natural language demonstrated by Pretrained Language Models (PLMs), recent works utilize PLMs (e.g., BERT) to strengthen news modeling, obtaining more accurate user interest matching and achieving notable improvement in news recommendation. However, the existing PLM-based methods are usually incapable of fully exploring the fine-grained (i.e., word-level) relatedness between user behaviors and candidate news due to the heavy computational cost brought by PLMs. In this article, we propose a group-based personalized news recommendation method with long- and short-term matching mechanisms between users and candidate news based on PLMs to learn fine-grained matching efficiently and effectively. In our approach, we design to group user historical clicked news into chunks with quite shorter news sequences according to their clicked timestamps, which could alleviate the computation issues of PLMs. PLMs are applied in each group jointly with the candidate news to capture their word-level interaction, and global group-level matching is learned across different groups. In addition, the group-based mechanism could be naturally adapted for long- and short-term user representation learning, in which we build users’ long preferences from the representations of all groups and treat the last group as short interests, respectively. Finally, we employ a gate network to dynamically unify the group-level, long- and short-term representations, yielding comprehensive user-news matching effectively. Extensive experiments are conducted on two real-world datasets. The results show that our proposed method achieves superior performance in news recommendations.}
}


@article{DBLP:journals/tois/ZhangLW24,
	author = {Jin Zhang and
                  Xinrui Li and
                  Liye Wang},
	title = {A Review Selection Method Based on Consumer Decision Phases in E-commerce},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {4:1--4:27},
	year = {2024},
	url = {https://doi.org/10.1145/3587265},
	doi = {10.1145/3587265},
	timestamp = {Sat, 11 Jan 2025 00:33:53 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A valuable small subset strategically selected from massive online reviews is beneficial to improve consumers’ decision-making efficiency in e-commerce. Existing review selection methods primarily concentrate on the informativeness of reviews and aim to find a subset of reviews that can reflect the informational properties of the original review set. However, changes in consumers’ review diets during the two-phase decision process are not fully considered. In this study, we propose a novel review selection problem of finding a diet-matched review subset with high diversity and representativeness, which can better adapt to consumers’ review-diet conversion from attribute-oriented to experience-oriented reviews between two decision phases. A novel decision-phase-based review selection method named DPRS is further proposed, which involves two steps: review classification and review selection. In the review classification step, the probability of a review being attribute-oriented or experience-oriented is estimated by prior knowledge-aware attentive neural network. In the second step, a novel heuristic algorithm, namely, stepwise non-dominated selection with superiority strategy, is introduced to seek the solution to the review selection problem. Extensive experiments on a real-world dataset demonstrate that DPRS outperforms state-of-the-art methods in terms of both review classification and review selection.}
}


@article{DBLP:journals/tois/WuCX24,
	author = {Yao Wu and
                  Jian Cao and
                  Guandong Xu},
	title = {{FASTER:} {A} Dynamic Fairness-assurance Strategy for Session-based
                  Recommender Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {5:1--5:26},
	year = {2024},
	url = {https://doi.org/10.1145/3586993},
	doi = {10.1145/3586993},
	timestamp = {Thu, 02 May 2024 20:50:53 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WuCX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When only users’ preferences and interests are considered by a recommendation algorithm, it will lead to the severe long-tail problem over items. Therefore, the unfair exposure phenomenon of recommended items caused by this problem has attracted widespread attention in recent years. For the first time, we reveal the fact that there is a more serious unfair exposure problem in session-based recommender systems (SRSs), which learn the short-term and dynamic preferences of users from anonymous sessions. Considering the fact that in SRSs, recommendations are provided multiple times and item exposures are accumulated over interactions in a session, we define new metrics both for the fairness of item exposure and recommendation quality among sessions. Moreover, we design a dynamic  F airness- A ssurance  ST rategy for s E ssion-based  R ecommender systems ( FASTER ).  FASTER  is a post-processing strategy that tries to keep a balance between item exposure fairness and recommendation quality. It can also maintain the fairness of recommendation quality among sessions. The effectiveness of  FASTER  is verified on three real-world datasets and five original algorithms. The experiment results show that  FASTER  can generally reduce the unfair exposure of different session-based recommendation algorithms while still ensuring a high level of recommendation quality.}
}


@article{DBLP:journals/tois/LiQJZXW24,
	author = {Xinhang Li and
                  Zhaopeng Qiu and
                  Jiacheng Jiang and
                  Yong Zhang and
                  Chunxiao Xing and
                  Xian Wu},
	title = {Conditional Cross-Platform User Engagement Prediction},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {6:1--6:28},
	year = {2024},
	url = {https://doi.org/10.1145/3589226},
	doi = {10.1145/3589226},
	timestamp = {Fri, 24 Jan 2025 11:16:03 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiQJZXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The bursting of media sharing platforms like TikTok, YouTube, and Kwai enables normal users to create and share content with worldwide audiences. The most popular YouTuber can attract up to 100 million followers. Since there are multiple popular platforms, it’s quite common that a YouTuber publishes the same media to multiple platforms, or replicates all media from one platform to another. However, the users of different platforms have different tastes. The media that is popular on one platform may not be a great vogue on other platforms. Observing such cross-platform variance, we propose a new task: estimating the user engagement score of a media on one platform given its popularity on other platforms. This task can benefit both the YouTubers and the platform. On one hand, YouTubers can use the predicted engagement to guide the media reworking; on the other hand, the platform can use the predicted engagement to establish promotion and advertising plans. Therefore, this task is of great practical value. To tackle this task, we propose a disentangled neural network that can separate the general media adorability from platform inclinations. In this manner, by substituting the inclination from the source platform to the target platform, we are able to predict the user engagement in the target platform. To validate the proposed model, we manage to build a dataset of micro-videos which are published on four platforms TikTok, Kwai, Bilibili, and WESEE. The experimental results prove the effectiveness of the proposed model.}
}


@article{DBLP:journals/tois/RadFBKSS24,
	author = {Radin Hamidi Rad and
                  Hossein Fani and
                  Ebrahim Bagheri and
                  Mehdi Kargar and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {A Variational Neural Architecture for Skill-based Team Formation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {7:1--7:28},
	year = {2024},
	url = {https://doi.org/10.1145/3589762},
	doi = {10.1145/3589762},
	timestamp = {Wed, 24 Apr 2024 14:55:55 +0200},
	biburl = {https://dblp.org/rec/journals/tois/RadFBKSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Team formation is concerned with the identification of a group of experts who have a high likelihood of effectively collaborating with each other to satisfy a collection of input skills. Solutions to this task have mainly adopted graph operations and at least have the following limitations: (1) they are computationally demanding, as they require finding shortest paths on large collaboration networks; (2) they use various types of heuristics to reduce the exploration space over the collaboration network to become practically feasible; therefore, their results are not necessarily optimal; and (3) they are not well-suited for collaboration network structures given the sparsity of these networks. Our work proposes a variational Bayesian neural network architecture that learns representations for teams whose members have collaborated with each other in the past. The learned representations allow our proposed approach to mine teams that have a past collaborative history and collectively cover the requested desirable set of skills. Through our experiments, we demonstrate that our approach shows stronger performance compared to a range of strong team formation techniques from both quantitative and qualitative perspectives.}
}


@article{DBLP:journals/tois/HeLWTW24,
	author = {Liangliang He and
                  Xiao Li and
                  Pancheng Wang and
                  Jintao Tang and
                  Ting Wang},
	title = {{MAN:} Memory-augmented Attentive Networks for Deep Learning-based
                  Knowledge Tracing},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {8:1--8:22},
	year = {2024},
	url = {https://doi.org/10.1145/3589340},
	doi = {10.1145/3589340},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/HeLWTW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge Tracing (KT) is the task of modeling a learner’s knowledge state to predict future performance in e-learning systems based on past performance. Deep learning-based methods, such as recurrent neural networks, memory-augmented neural networks, and attention-based neural networks, have recently been used in KT. Such methods have demonstrated excellent performance in capturing the latent dependencies of a learner’s knowledge state on recent exercises. However, these methods have limitations when it comes to dealing with the so-called Skill Switching Phenomenon (SSP), i.e., when learners respond to exercises in an e-learning system, the latent skills in the exercises typically switch irregularly. SSP will deteriorate the performance of deep learning-based approaches for simulating the learner’s knowledge state during skill switching, particularly when the association between the switching skills and the previously learned skills is weak. To address this problem, we propose the Memory-augmented Attentive Network (MAN), which combines the advantages of memory-augmented neural networks and attention-based neural networks. Specifically, in MAN, memory-augmented neural networks are used to model learners’ longer term memory knowledge, while attention-based neural networks are used to model learners’ recent term knowledge. In addition, we design a context-aware attention mechanism that automatically weighs the tradeoff between these two types of knowledge. With extensive experiments on several e-learning datasets, we show that MAN effectively improve predictive accuracies of existing state-of-the-art DLKT methods.}
}


@article{DBLP:journals/tois/ChenQLZSZ24,
	author = {Hai Chen and
                  Fulan Qian and
                  Chang Liu and
                  Yanping Zhang and
                  Hang Su and
                  Shu Zhao},
	title = {Training Robust Deep Collaborative Filtering Models via Adversarial
                  Noise Propagation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {9:1--9:27},
	year = {2024},
	url = {https://doi.org/10.1145/3589000},
	doi = {10.1145/3589000},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ChenQLZSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recommendation performance of deep collaborative filtering models drops sharply under imperceptible adversarial perturbations. Some methods promote the robustness of recommendation systems by adversarial training. However, these methods only study shallow models and lack the exploration of deep models. Furthermore, the way these methods add adversarial noise to the weight parameters of users and items is not fully applicable to deep collaborative filtering models, because the adversarial noise is not sufficient to fully affect its network structure with multiple hidden layers. In this article, we propose a novel adversarial training framework, Random Layer-wise Adversarial Training (RAT), which trains a robust deep collaborative filtering model via adversarial noise propagation. Specifically, we inject adversarial noise into the output of the hidden layer in a random layer-wise manner. The adversarial noise propagates forward from the injected position to obtain more flexible model parameters during the adversarial training process. We validate the effectiveness of RAT on multilayer perceptron (MLP) and implement RAT on MLP-based and convolutional neural networks-based deep collaborative filtering models. Experiments on three publicly available datasets show that the deep collaborative filtering model trained by RAT not only defends against adversarial noise but also guarantees recommendation performance.}
}


@article{DBLP:journals/tois/YanCGSLSL24,
	author = {Mingshi Yan and
                  Zhiyong Cheng and
                  Chen Gao and
                  Jing Sun and
                  Fan Liu and
                  Fuming Sun and
                  Haojie Li},
	title = {Cascading Residual Graph Convolutional Network for Multi-Behavior
                  Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {10:1--10:26},
	year = {2024},
	url = {https://doi.org/10.1145/3587693},
	doi = {10.1145/3587693},
	timestamp = {Thu, 17 Apr 2025 17:00:33 +0200},
	biburl = {https://dblp.org/rec/journals/tois/YanCGSLSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-behavior recommendation exploits multiple types of user-item interactions, such as  view  and  cart , to learn user preferences and has demonstrated to be an effective solution to alleviate the data sparsity problem faced by the traditional models that often utilize only one type of interaction for recommendation. In real scenarios, users often take a sequence of actions to interact with an item, in order to get more information about the item and thus accurately evaluate whether an item fits their personal preferences. Those interaction behaviors often obey a certain order, and more importantly, different behaviors reveal different information or aspects of user preferences towards the target item. Most existing multi-behavior recommendation methods take the strategy to first extract information from different behaviors separately and then fuse them for final prediction. However, they have not exploited the connections between different behaviors to learn user preferences. Besides, they often introduce complex model structures and more parameters to model multiple behaviors, largely increasing the space and time complexity. In this work, we propose a lightweight multi-behavior recommendation model named  Cascading Residual Graph Convolutional Network  ( CRGCN  for short) for multi-behavior recommendation, which can explicitly exploit the connections between different behaviors into the embedding learning process without introducing any additional parameters (with comparison to the single-behavior based recommendation model). In particular, we design a cascading residual  graph convolutional network (GCN)  structure, which enables our model to learn user preferences by continuously refining the embeddings across different types of behaviors. The multi-task learning method is adopted to jointly optimize our model based on different behaviors. Extensive experimental results on three real-world benchmark datasets show that CRGCN can substantially outperform the state-of-the-art methods, achieving 24.76%, 27.28%, and 25.10% relative gains on average in terms of HR@K (K = {10,20,50,80}) over the best baseline across the three datasets. Further studies also analyze the effects of leveraging multi-behaviors in different numbers and orders on the final performance.}
}


@article{DBLP:journals/tois/SakaiKK24,
	author = {Tetsuya Sakai and
                  Jinyoung Kim and
                  Inho Kang},
	title = {A Versatile Framework for Evaluating Ranked Lists in Terms of Group
                  Fairness and Relevance},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {11:1--11:36},
	year = {2024},
	url = {https://doi.org/10.1145/3589763},
	doi = {10.1145/3589763},
	timestamp = {Sun, 10 Dec 2023 17:01:03 +0100},
	biburl = {https://dblp.org/rec/journals/tois/SakaiKK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a simple and versatile framework for evaluating ranked lists in terms of Group Fairness and Relevance, in which the groups (i.e., possible attribute values) can be either nominal or ordinal in nature. First, we demonstrate that when our framework is applied to a binary hard group membership setting, our Group Fairness and Relevance (GFR) measures can easily quantify the overall polarity of each ranked list. Second, by utilising an existing diversified search test collection and treating each intent as an attribute value, we demonstrate that our framework can also handle soft group membership and that the GFR measures are highly correlated with a diversified information retrieval (IR) measure in this context as well. Third, using real data from a Japanese local search service, we demonstrate how our framework enables researchers to study intersectional group fairness based on multiple attribute sets. We also show that the similarity function for comparing the achieved and target distributions over the attribute values should be chosen carefully when the attribute values are ordinal. For such situations, our recommendation is to use multiple similarity functions with our framework: for example, one based on Jensen-Shannon Divergence (which disregards the ordinal nature of the groups) and another based on Root Normalised Order-aware Divergence (which has been designed specifically for handling ordinal groups). In addition, we highlight the fundamental differences between our framework and Attention-Weighted Rank Fairness (AWRF), a group fairness measure used at the TREC Fair Ranking Track.}
}


@article{DBLP:journals/tois/WangLWFMC24,
	author = {Wenjie Wang and
                  Xinyu Lin and
                  Liuhui Wang and
                  Fuli Feng and
                  Yunshan Ma and
                  Tat{-}Seng Chua},
	title = {Causal Disentangled Recommendation against User Preference Shifts},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {12:1--12:27},
	year = {2024},
	url = {https://doi.org/10.1145/3593022},
	doi = {10.1145/3593022},
	timestamp = {Tue, 18 Feb 2025 15:22:19 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WangLWFMC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems easily face the issue of user preference shifts. User representations will become out-of-date and lead to inappropriate recommendations if user preference has shifted over time. To solve the issue, existing work focuses on learning robust representations or predicting the shifting pattern. There lacks a comprehensive view to discover the underlying reasons for user preference shifts. To understand the preference shift, we abstract a causal graph to describe the generation procedure of user interaction sequences. Assuming user preference is stable within a short period, we abstract the interaction sequence as a set of chronological environments. From the causal graph, we find that the changes of some unobserved factors (e.g., becoming pregnant) cause preference shifts between environments. Besides, the fine-grained user preference over item categories sparsely affects the interactions with different items. Inspired by the causal graph, our key considerations to handle preference shifts lie in modeling the interaction generation procedure by: (1) capturing the preference shifts across environments for accurate preference prediction and (2) disentangling the sparse influence from user preference to interactions for accurate effect estimation of preference. To this end, we propose a Causal Disentangled Recommendation (CDR) framework, which captures preference shifts via a temporal variational autoencoder and learns the sparse influence from multiple environments. Specifically, an encoder is adopted to infer the unobserved factors from user interactions while a decoder is to model the interaction generation process. Besides, we introduce two learnable matrices to disentangle the sparse influence from user preference to interactions. Last, we devise a multi-objective loss to optimize CDR. Extensive experiments on three datasets show the superiority of CDR in enhancing the generalization ability under user preference shifts.}
}


@article{DBLP:journals/tois/ZhangJWZZLHJSQ24,
	author = {Yazhou Zhang and
                  Ao Jia and
                  Bo Wang and
                  Peng Zhang and
                  Dongming Zhao and
                  Pu Li and
                  Yuexian Hou and
                  Xiaojia Jin and
                  Dawei Song and
                  Jing Qin},
	title = {{M3GAT:} {A} Multi-modal, Multi-task Interactive Graph Attention Network
                  for Conversational Sentiment Analysis and Emotion Recognition},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {13:1--13:32},
	year = {2024},
	url = {https://doi.org/10.1145/3593583},
	doi = {10.1145/3593583},
	timestamp = {Fri, 26 Jul 2024 07:35:34 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ZhangJWZZLHJSQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sentiment and emotion, which correspond to long-term and short-lived human feelings, are closely linked to each other, leading to the fact that sentiment analysis and emotion recognition are also two interdependent tasks in natural language processing (NLP). One task often leverages the shared knowledge from another task and performs better when solved in a joint learning paradigm. Conversational context dependency, multi-modal interaction, and multi-task correlation are three key factors that contribute to this joint paradigm. However, none of the recent approaches have considered them in a unified framework. To fill this gap, we propose a multi-modal, multi-task interactive graph attention network, termed M3GAT, to simultaneously solve the three problems. At the heart of the model is a proposed interactive conversation graph layer containing three core sub-modules, which are: (1) local-global context connection for modeling both local and global conversational context, (2) cross-modal connection for learning multi-modal complementary and (3) cross-task connection for capturing the correlation across two tasks. Comprehensive experiments on three benchmarking datasets, MELD, MEISD, and MSED, show the effectiveness of M3GAT over state-of-the-art baselines with the margin of 1.88%, 5.37%, and 0.19% for sentiment analysis, and 1.99%, 3.65%, and 0.13% for emotion recognition, respectively. In addition, we also show the superiority of multi-task learning over the single-task framework.}
}


@article{DBLP:journals/tois/GaoWLCHLLZJ24,
	author = {Chongming Gao and
                  Shiqi Wang and
                  Shijun Li and
                  Jiawei Chen and
                  Xiangnan He and
                  Wenqiang Lei and
                  Biao Li and
                  Yuan Zhang and
                  Peng Jiang},
	title = {{CIRS:} Bursting Filter Bubbles by Counterfactual Interactive Recommender
                  System},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {14:1--14:27},
	year = {2024},
	url = {https://doi.org/10.1145/3594871},
	doi = {10.1145/3594871},
	timestamp = {Mon, 03 Mar 2025 20:19:56 +0100},
	biburl = {https://dblp.org/rec/journals/tois/GaoWLCHLLZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While personalization increases the utility of recommender systems, it also brings the issue of  filter bubbles . e.g., if the system keeps exposing and recommending the items that the user is interested in, it may also make the user feel bored and less satisfied. Existing work studies filter bubbles in static recommendation, where the effect of overexposure is hard to capture. In contrast, we believe it is more meaningful to study the issue in interactive recommendation and optimize long-term user satisfaction. Nevertheless, it is unrealistic to train the model online due to the high cost. As such, we have to leverage offline training data and disentangle the causal effect on user satisfaction. To achieve this goal, we propose a counterfactual interactive recommender system (CIRS) that augments offline reinforcement learning (offline RL) with causal inference. The basic idea is to first learn a causal user model on historical data to capture the overexposure effect of items on user satisfaction. It then uses the learned causal user model to help the planning of the RL policy. To conduct evaluation offline, we innovatively create an authentic RL environment (KuaiEnv) based on a real-world fully observed user rating dataset. The experiments show the effectiveness of CIRS in bursting filter bubbles and achieving long-term success in interactive recommendation. The implementation of CIRS is available via https://github.com/chongminggao/ CIRS-codes.}
}


@article{DBLP:journals/tois/SunLZLOZ24,
	author = {Zhu Sun and
                  Yu Lei and
                  Lu Zhang and
                  Chen Li and
                  Yew{-}Soon Ong and
                  Jie Zhang},
	title = {A Multi-channel Next {POI} Recommendation Framework with Multi-granularity
                  Check-in Signals},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {15:1--15:28},
	year = {2024},
	url = {https://doi.org/10.1145/3592789},
	doi = {10.1145/3592789},
	timestamp = {Mon, 10 Feb 2025 14:42:45 +0100},
	biburl = {https://dblp.org/rec/journals/tois/SunLZLOZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current study on next point-of-interest (POI) recommendation mainly explores user sequential transitions with the fine-grained individual-user POI check-in trajectories only, which suffers from the severe check-in data sparsity issue. In fact, coarse-grained signals (i.e., region- and global-level check-ins) in such sparse check-ins would also benefit to augment user preference learning. Specifically, our data analysis unveils that user movement exhibits noticeable patterns w.r.t. the regions of visited POIs. Meanwhile, the global all-user check-ins can help reflect sequential regularities shared by the crowd. We are, therefore, inspired to propose the MCMG: a Multi-Channel next POI recommendation framework with Multi-Granularity signals categorized from two orthogonal perspectives, i.e., fine-coarse grained check-ins at either POI/region level or local/global level. The MCMG is equipped with three modules, namely, global user behavior encoder, local multi-channel (i.e., region, category, and POI channels) encoder, and region-aware weighting strategy. Such design enables MCMG to be capable of capturing both fine- and coarse-grained sequential regularities as well as exploring the dynamic impact of multi-channel by differentiating the check-in patterns w.r.t. visited regions. Extensive experiments on four real-world datasets show that our MCMG significantly outperforms state-of-the-art next POI recommendation approaches.}
}


@article{DBLP:journals/tois/WangZYYXD24,
	author = {Dongjing Wang and
                  Xin Zhang and
                  Yuyu Yin and
                  Dongjin Yu and
                  Guandong Xu and
                  Shuiguang Deng},
	title = {Multi-View Enhanced Graph Attention Network for Session-Based Music
                  Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {16:1--16:30},
	year = {2024},
	url = {https://doi.org/10.1145/3592853},
	doi = {10.1145/3592853},
	timestamp = {Thu, 02 May 2024 20:50:53 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WangZYYXD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional music recommender systems are mainly based on users’ interactions, which limit their performance. Particularly, various kinds of content information, such as metadata and description can be used to improve music recommendation. However, it remains to be addressed how to fully incorporate the rich auxiliary/side information and effectively deal with heterogeneity in it. In this paper, we propose a  M ulti-view  E nhanced  G raph  A ttention  N etwork (named  MEGAN ) for session-based music recommendation. MEGAN can learn informative representations (embeddings) of music pieces and users from heterogeneous information based on graph neural network and attention mechanism. Specifically, the proposed approach MEGAN firstly models users’ listening behaviors and the textual content of music pieces with a Heterogeneous Music Graph (HMG). Then, a devised Graph Attention Network is used to learn the low-dimensional embedding of music pieces and users and by integrating various kinds of information, which is enhanced by multi-view from HMG in an adaptive and unified way. Finally, users’ hybrid preferences are learned from users’ listening behaviors and music pieces that satisfy users real-time requirements are recommended. Comprehensive experiments are conducted on two real-world datasets, and the results show that MEGAN achieves better performance than baselines, including several state-of-the-art recommendation methods.}
}


@article{DBLP:journals/tois/SunGZRCRR24,
	author = {Weiwei Sun and
                  Shuyu Guo and
                  Shuo Zhang and
                  Pengjie Ren and
                  Zhumin Chen and
                  Maarten de Rijke and
                  Zhaochun Ren},
	title = {Metaphorical User Simulators for Evaluating Task-oriented Dialogue
                  Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {17:1--17:29},
	year = {2024},
	url = {https://doi.org/10.1145/3596510},
	doi = {10.1145/3596510},
	timestamp = {Sun, 10 Dec 2023 17:01:03 +0100},
	biburl = {https://dblp.org/rec/journals/tois/SunGZRCRR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Task-oriented dialogue systems (TDSs) are assessed mainly in an offline setting or through human evaluation. The evaluation is often limited to single-turn or is very time-intensive. As an alternative, user simulators that mimic user behavior allow us to consider a broad set of user goals to generate human-like conversations for simulated evaluation. Employing existing user simulators to evaluate TDSs is challenging as user simulators are primarily designed to optimize dialogue policies for TDSs and have limited evaluation capabilities. Moreover, the evaluation of user simulators is an open challenge. In this work, we propose a metaphorical user simulator for end-to-end TDS evaluation, where we define a simulator to be metaphorical if it simulates a user’s analogical thinking in interactions with systems. We also propose a tester-based evaluation framework to generate variants, i.e., dialogue systems with different capabilities. Our user simulator constructs a metaphorical user model that assists the simulator in reasoning by referring to prior knowledge when encountering new items. We estimate the quality of simulators by checking the simulated interactions between simulators and variants. Our experiments are conducted using three TDS datasets. The proposed user simulator demonstrates better consistency with manual evaluation than an agenda-based simulator and a seq2seq model on three datasets; our tester framework demonstrates efficiency and has been tested on multiple tasks, such as conversational recommendation and e-commerce dialogues.}
}


@article{DBLP:journals/tois/QinGWWJYZLHL24,
	author = {Yingrong Qin and
                  Chen Gao and
                  Shuangqing Wei and
                  Yue Wang and
                  Depeng Jin and
                  Jian Yuan and
                  Lin Zhang and
                  Dong Li and
                  Jianye Hao and
                  Yong Li},
	title = {Learning from Hierarchical Structure of Knowledge Graph for Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {18:1--18:24},
	year = {2024},
	url = {https://doi.org/10.1145/3595632},
	doi = {10.1145/3595632},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/QinGWWJYZLHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge graphs (KGs) can help enhance recommendations, especially for the data-sparsity scenarios with limited user-item interaction data. Due to the strong power of representation learning of graph neural networks (GNNs), recent works of KG-based recommendation deploy GNN models to learn from both knowledge graph and user-item bipartite interaction graph. However, these works have not well considered the  hierarchical structure  of knowledge graph, leading to sub-optimal results. Despite the benefit of hierarchical structure, leveraging it is challenging since the structure is always partly-observed. In this work, we first propose to reveal unknown hierarchical structures with a supervised signal detection method and then exploit the hierarchical structure with disentangling representation learning. We conduct experiments on two large-scale datasets, of which the results well verify the superiority and rationality of the proposed method. Further experiments of ablation study with respect to key model designs have demonstrated the effectiveness and rationality of our proposed model. The code is available at  https://github.com/tsinghua-fib-lab/HIKE .}
}


@article{DBLP:journals/tois/RashidiZM24,
	author = {Lida Rashidi and
                  Justin Zobel and
                  Alistair Moffat},
	title = {The Impact of Judgment Variability on the Consistency of Offline Effectiveness
                  Measures},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {19:1--19:31},
	year = {2024},
	url = {https://doi.org/10.1145/3596511},
	doi = {10.1145/3596511},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/RashidiZM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Measurement of the effectiveness of search engines is often based on use of relevance judgments. It is well known that judgments can be inconsistent between judges, leading to discrepancies that potentially affect not only scores but also system relativities and confidence in the experimental outcomes. We take the perspective that the relevance judgments are an amalgam of perfect relevance assessments plus errors; making use of a model of systematic errors in binary relevance judgments that can be tuned to reflect the kind of judge that is being used, we explore the behavior of measures of effectiveness as error is introduced. Using a novel methodology in which we examine the distribution of “true” effectiveness measurements that could be underlying measurements based on sets of judgments that include error, we find that even moderate amounts of error can lead to conclusions such as orderings of systems that statistical tests report as significant but are nonetheless incorrect. Further, in these results the widely used recall-based measures AP and NDCG are notably more fragile in the presence of judgment error than is the utility-based measure\xa0RBP, but all the measures failed under even moderate error rates. We conclude that knowledge of likely error rates in judgments is critical to interpretation of experimental outcomes.}
}


@article{DBLP:journals/tois/BruchGI24,
	author = {Sebastian Bruch and
                  Siyu Gai and
                  Amir Ingber},
	title = {An Analysis of Fusion Functions for Hybrid Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {20:1--20:35},
	year = {2024},
	url = {https://doi.org/10.1145/3596512},
	doi = {10.1145/3596512},
	timestamp = {Sun, 25 May 2025 13:43:34 +0200},
	biburl = {https://dblp.org/rec/journals/tois/BruchGI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study hybrid search in text retrieval where lexical and semantic search are  fused  together with the intuition that the two are complementary in how they model relevance. In particular, we examine fusion by a convex combination of lexical and semantic scores, as well as the reciprocal rank fusion (RRF) method, and identify their advantages and potential pitfalls. Contrary to existing studies, we find RRF to be sensitive to its parameters; that the learning of a convex combination fusion is generally agnostic to the choice of score normalization; that convex combination outperforms RRF in in-domain and out-of-domain settings; and finally, that convex combination is sample efficient, requiring only a small set of training examples to tune its only parameter to a target domain.}
}


@article{DBLP:journals/tois/RoiteroBSDMS24,
	author = {Kevin Roitero and
                  David La Barbera and
                  Michael Soprano and
                  Gianluca Demartini and
                  Stefano Mizzaro and
                  Tetsuya Sakai},
	title = {How Many Crowd Workers Do {I} Need? On Statistical Power when Crowdsourcing
                  Relevance Judgments},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {21:1--21:26},
	year = {2024},
	url = {https://doi.org/10.1145/3597201},
	doi = {10.1145/3597201},
	timestamp = {Sun, 10 Dec 2023 17:01:03 +0100},
	biburl = {https://dblp.org/rec/journals/tois/RoiteroBSDMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To scale the size of Information Retrieval collections, crowdsourcing has become a common way to collect relevance judgments at scale. Crowdsourcing experiments usually employ 100–10,000 workers, but such a number is often decided in a heuristic way. The downside is that the resulting dataset does not have any guarantee of meeting predefined statistical requirements as, for example, have enough statistical power to be able to distinguish in a statistically significant way between the relevance of two documents. We propose a methodology adapted from literature on sound topic set size design, based on t-test and ANOVA, which aims at guaranteeing the resulting dataset to meet a predefined set of statistical requirements. We validate our approach on several public datasets. Our results show that we can reliably estimate the recommended number of workers needed to achieve statistical power, and that such estimation is dependent on the topic, while the effect of the relevance scale is limited. Furthermore, we found that such estimation is dependent on worker features such as agreement. Finally, we describe a set of practical estimation strategies that can be used to estimate the worker set size, and we also provide results on the estimation of document set sizes.}
}


@article{DBLP:journals/tois/HuangYLC24,
	author = {Heyan Huang and
                  Changsen Yuan and
                  Qian Liu and
                  Yixin Cao},
	title = {Document-level Relation Extraction via Separate Relation Representation
                  and Logical Reasoning},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {22:1--22:24},
	year = {2024},
	url = {https://doi.org/10.1145/3597610},
	doi = {10.1145/3597610},
	timestamp = {Thu, 15 Feb 2024 11:39:07 +0100},
	biburl = {https://dblp.org/rec/journals/tois/HuangYLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Document-level relation extraction (RE) extends the identification of entity/mentions’ relation from the single sentence to the long document. It is more realistic and poses new challenges to relation representation and reasoning skills. In this article, we propose a novel model,  SRLR , using  S eparate Relation  R epresentation and  L ogical  R easoning considering the indirect relation representation and complex reasoning of evidence sentence problems. Specifically, we first expand the judgment of relational facts from the entity-level to the mention-level, highlighting fine-grained information to capture the relation representation for the entity pair. Second, we propose a logical reasoning module to identify evidence sentences and conduct relational reasoning. Extensive experiments on two publicly available benchmark datasets demonstrate the effectiveness of our proposed SRLR as compared to 19 baseline models. Further ablation study also verifies the effects of the key components.}
}


@article{DBLP:journals/tois/SakaiTCLMCF24,
	author = {Tetsuya Sakai and
                  Sijie Tao and
                  Nuo Chen and
                  Yujing Li and
                  Maria Maistro and
                  Zhumin Chu and
                  Nicola Ferro},
	title = {On the Ordering of Pooled Web Pages, Gold Assessments, and Bronze
                  Assessments},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {23:1--23:31},
	year = {2024},
	url = {https://doi.org/10.1145/3600227},
	doi = {10.1145/3600227},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/SakaiTCLMCF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The present study leverages a recent opportunity we had to create a new English web search test collection for the NTCIR-16 We Want Web (WWW-4) task, which concluded in June 2022. More specifically, through the test collection construction effort, we examined two factors that may affect the relevance assessments of depth- k  pools, which in turn may affect the relative evaluation of different IR systems. The first factor is the document ordering strategy for the assessors, namely, prioritisation (PRI) and randomisation (RND). PRI is a method that has been used in NTCIR tasks for over a decade; it ranks the pooled documents by a kind of pseudorelevance for the assessors. The second factor is assessor type, i.e., Gold or Bronze. Gold assessors are the topic creators and therefore they “know” which documents are (highly) relevant and which are not; Bronze assessors are not the topic creators and may lack sufficient knowledge about the topics. We believe that our study is unique in that the authors of this article served as the Gold assessors when creating the WWW-4 test collection, which enabled us to closely examine why Bronze assessments differ from the Gold ones. Our research questions examine assessor efficiency ( RQ1 ), inter-assessor agreement ( RQ2 ), system ranking similarity with different qrels files ( RQ3 ), system ranking robustness to the choice of test topics ( RQ4 ), and the reasons why Bronze assessors tend to be more liberal than Gold assessors ( RQ5 ). The most remarkable of our results are as follows: First, in the comparisons for  RQ1  through  RQ4 , it turned out that what may matter more than the document ordering strategy (PRI vs. RND) and the assessor type (Gold vs. Bronze) is how well-motivated and/or well-trained the Bronze assessors are. Second, regarding  RQ5 , of the documents originally judged nonrelevant by the Gold assessors contrary to the Bronze assessors in our experiments, almost one half were truly relevant according to the Gold assessors’ own reconsiderations. This result suggests that even Gold assessors are far from perfect; budget permitting, it may be beneficial to hire highly motivated Bronze assessors in addition to Gold assessors so they can complement each other.}
}


@article{DBLP:journals/tois/YinFSO24,
	author = {Qing Yin and
                  Hui Fang and
                  Zhu Sun and
                  Yew{-}Soon Ong},
	title = {Understanding Diversity in Session-based Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {24:1--24:34},
	year = {2024},
	url = {https://doi.org/10.1145/3600226},
	doi = {10.1145/3600226},
	timestamp = {Thu, 30 May 2024 00:10:52 +0200},
	biburl = {https://dblp.org/rec/journals/tois/YinFSO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current session-based recommender systems (SBRSs) mainly focus on maximizing recommendation accuracy, while few studies have been devoted to improve diversity beyond accuracy. Meanwhile, it is unclear how the accuracy-oriented SBRSs perform in terms of diversity. In addition, the asserted “tradeoff” relationship between accuracy and diversity has been increasingly questioned in the literature. Toward the aforementioned issues, we conduct a holistic study to particularly examine the recommendation performance of representative SBRSs w.r.t. both accuracy and diversity, striving for better understanding of the diversity-related issues for SBRSs and providing guidance on designing diversified SBRSs. Particularly, for a fair and thorough comparison, we deliberately select state-of-the-art non-neural, deep neural, and diversified SBRSs by covering more scenarios with appropriate experimental setups, e.g., representative datasets, evaluation metrics, and hyper-parameter optimization technique. The source code can be obtained via  github.com/qyin863/Understanding-Diversity-in-SBRSs . Our empirical results unveil that (1) non-diversified methods can also obtain satisfying performance on diversity, which can even surpass diversified ones, and (2) the relationship between accuracy and diversity is quite complex. Besides the “tradeoff” relationship, they can be positively correlated with each other, that is, having a same-trend (win–win or lose–lose) relationship, which varies across different methods and datasets. Additionally, we further identify three possible influential factors on diversity in SBRSs (i.e., granularity of item categorization, session diversity of datasets, and length of recommendation lists) and offer an intuitive guideline and a potential solution regarding learned item embeddings for more effective session-based recommendation.}
}


@article{DBLP:journals/tois/JingSLZZN24,
	author = {Liqiang Jing and
                  Xuemeng Song and
                  Xuming Lin and
                  Zhongzhou Zhao and
                  Wei Zhou and
                  Liqiang Nie},
	title = {Stylized Data-to-text Generation: {A} Case Study in the E-Commerce
                  Domain},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {25:1--25:24},
	year = {2024},
	url = {https://doi.org/10.1145/3603374},
	doi = {10.1145/3603374},
	timestamp = {Thu, 23 Nov 2023 21:16:26 +0100},
	biburl = {https://dblp.org/rec/journals/tois/JingSLZZN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing data-to-text generation efforts mainly focus on generating a coherent text from non-linguistic input data, such as tables and attribute–value pairs, but overlook that different application scenarios may require texts of different styles. Inspired by this, we define a new task, namely stylized data-to-text generation, whose aim is to generate coherent text for the given non-linguistic data according to a specific style. This task is non-trivial, due to three challenges: the logic of the generated text, unstructured style reference and biased training samples. To address these challenges, we propose a novel stylized data-to-text generation model, named StyleD2T, comprising three components: logic planning-enhanced data embedding, mask-based style embedding, and unbiased stylized text generation. In the first component, we introduce a graph-guided logic planner for attribute organization to ensure the logic of generated text. In the second component, we devise feature-level mask-based style embedding to extract the essential style signal from the given unstructured style reference. In the last one, pseudo triplet augmentation is utilized to achieve unbiased text generation, and a multi-condition based confidence assignment function is designed to ensure the quality of pseudo samples. Extensive experiments on a newly collected dataset from Taobao have been conducted, and the results show the superiority of our model over existing methods.}
}


@article{DBLP:journals/tois/LiZWZ24,
	author = {Haoyang Li and
                  Ziwei Zhang and
                  Xin Wang and
                  Wenwu Zhu},
	title = {Invariant Node Representation Learning under Distribution Shifts with
                  Multiple Latent Environments},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {26:1--26:30},
	year = {2024},
	url = {https://doi.org/10.1145/3604427},
	doi = {10.1145/3604427},
	timestamp = {Wed, 09 Oct 2024 07:56:13 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LiZWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Node representation learning methods, such as graph neural networks, show promising results when testing and training graph data come from the same distribution. However, the existing approaches fail to generalize under distribution shifts when the nodes reside in multiple latent environments. How to learn invariant node representations to handle distribution shifts with multiple latent environments remains unexplored. In this article, we propose a novel  I nvariant  N ode representation  L earning (INL) approach capable of generating invariant node representations based on the invariant patterns under distribution shifts with multiple latent environments by leveraging the invariance principle. Specifically, we define invariant and variant patterns as ego-subgraphs of each node and identify the invariant ego-subgraphs through jointly accounting for node features and graph structures. To infer the latent environments of nodes, we propose a contrastive modularity-based graph clustering method based on the variant patterns. We further propose an invariant learning module to learn node representations that can generalize to distribution shifts. We theoretically show that our proposed method can achieve guaranteed performance under distribution shifts. Extensive experiments on both synthetic and real-world node classification benchmarks demonstrate that our method greatly outperforms state-of-the-art baselines under distribution shifts.}
}


@article{DBLP:journals/tois/QinZSSYWX24,
	author = {Chuan Qin and
                  Hengshu Zhu and
                  Dazhong Shen and
                  Ying Sun and
                  Kaichun Yao and
                  Peng Wang and
                  Hui Xiong},
	title = {Automatic Skill-Oriented Question Generation and Recommendation for
                  Intelligent Job Interviews},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {27:1--27:32},
	year = {2024},
	url = {https://doi.org/10.1145/3604552},
	doi = {10.1145/3604552},
	timestamp = {Sun, 19 Jan 2025 15:03:41 +0100},
	biburl = {https://dblp.org/rec/journals/tois/QinZSSYWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Job interviews are the most widely accepted method for companies to select suitable candidates, and a critical challenge is finding the right questions to ask job candidates. Moreover, there is a lack of integrated tools for automatically generating interview questions and recommending the right questions to interviewers. To this end, in this paper, we propose an intelligent system for assisting job interviews, namely, DuerQues. To build this system, we first investigate how to automatically generate skill-oriented interview questions in a scalable way by learning external knowledge from online knowledge-sharing communities. Along this line, we develop a novel distantly supervised skill entity recognition method to identify skill entities from large-scale search queries and web page titles with less need for human annotation. Additionally, we propose a neural generative model for generating skill-oriented interview questions. In particular, we introduce a data-driven solution to create high-quality training instances and design a learning algorithm to improve the performance of question generation. Furthermore, we exploit click-through data from query logs and design a recommender system for recommending suitable questions to interviewers. Specifically, we introduce a graph-enhanced algorithm to efficiently recommend suitable questions given a set of queried skills. Finally, extensive experiments on real-world datasets demonstrate the effectiveness of our DuerQues system in terms of the quality of generated skill-oriented questions and the performance of question recommendation.}
}


@article{DBLP:journals/tois/NiXFLKLYZ24,
	author = {Yuxin Ni and
                  Yunwen Xia and
                  Hui Fang and
                  Chong Long and
                  Xinyu Kong and
                  Daqian Li and
                  Dong Yang and
                  Jie Zhang},
	title = {Meta-CRS: {A} Dynamic Meta-Learning Approach for Effective Conversational
                  Recommender System},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {28:1--28:27},
	year = {2024},
	url = {https://doi.org/10.1145/3604804},
	doi = {10.1145/3604804},
	timestamp = {Sun, 10 Dec 2023 17:01:03 +0100},
	biburl = {https://dblp.org/rec/journals/tois/NiXFLKLYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conversational recommender system (CRS) enhances the recommender system by acquiring the latest user preference through dialogues, where an agent needs to decide “whether to ask or recommend”, “which attributes to ask”, and “which items to recommend” in each round. To explore these questions, reinforcement learning is adopted in most CRS frameworks. However, existing studies somewhat ignore to consider the connection between the previous rounds and the current round of the conversation, which might lead to the lack of prior knowledge and inaccurate decisions. In this view, we propose to facilitate the connections between different rounds of conversations in a dialogue session through deep transformer-based multi-channel meta-reinforcement learning, so that the CRS agent can decide each action/decision based on previous states, actions, and their rewards. Besides, to better utilize a user’s historical preferences, we propose a more dynamic and personalized graph structure to support the conversation module and the recommendation module. Experiment results on five real-world datasets and an online evaluation with real users in an industrial environment validate the improvement of our method over the state-of-the-art approaches and the effectiveness of our designs.}
}


@article{DBLP:journals/tois/XuZTFZA24,
	author = {Zhichao Xu and
                  Hansi Zeng and
                  Juntao Tan and
                  Zuohui Fu and
                  Yongfeng Zhang and
                  Qingyao Ai},
	title = {A Reusable Model-agnostic Framework for Faithfully Explainable Recommendation
                  and System Scrutability},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {29:1--29:29},
	year = {2024},
	url = {https://doi.org/10.1145/3605357},
	doi = {10.1145/3605357},
	timestamp = {Fri, 31 Jan 2025 17:22:17 +0100},
	biburl = {https://dblp.org/rec/journals/tois/XuZTFZA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {State-of-the-art industrial-level recommender system applications mostly adopt complicated model structures such as deep neural networks. While this helps with the model performance, the lack of system explainability caused by these nearly blackbox models also raises concerns and potentially weakens the users’ trust in the system. Existing work on explainable recommendation mostly focuses on designing interpretable model structures to generate model-intrinsic explanations. However, most of them have complex structures, and it is difficult to directly apply these designs onto existing recommendation applications due to the effectiveness and efficiency concerns. However, while there have been some studies on explaining recommendation models without knowing their internal structures (i.e., model-agnostic explanations), these methods have been criticized for not reflecting the actual reasoning process of the recommendation model or, in other words,  faithfulness . How to develop model-agnostic explanation methods and evaluate them in terms of faithfulness is mostly unknown. In this work, we propose a reusable evaluation pipeline for model-agnostic explainable recommendation. Our pipeline evaluates the quality of model-agnostic explanation from the perspectives of faithfulness and scrutability. We further propose a model-agnostic explanation framework for recommendation and verify it with the proposed evaluation pipeline. Extensive experiments on public datasets demonstrate that our model-agnostic framework is able to generate explanations that are faithful to the recommendation model. We additionally provide quantitative and qualitative study to show that our explanation framework could enhance the scrutability of blackbox recommendation model. With proper modification, our evaluation pipeline and model-agnostic explanation framework could be easily migrated to existing applications. Through this work, we hope to encourage the community to focus more on faithfulness evaluation of explainable recommender systems.}
}


@article{DBLP:journals/tois/MengZGZWGLLT24,
	author = {Chang Meng and
                  Ziqi Zhao and
                  Wei Guo and
                  Yingxue Zhang and
                  Haolun Wu and
                  Chen Gao and
                  Dong Li and
                  Xiu Li and
                  Ruiming Tang},
	title = {Coarse-to-Fine Knowledge-Enhanced Multi-Interest Learning Framework
                  for Multi-Behavior Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {30:1--30:27},
	year = {2024},
	url = {https://doi.org/10.1145/3606369},
	doi = {10.1145/3606369},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/MengZGZWGLLT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-types of behaviors (e.g., clicking, carting, purchasing, etc.) widely exist in most real-world recommendation scenarios, which are beneficial to learn users’ multi-faceted preferences. As dependencies are explicitly exhibited by the multiple types of behaviors, effectively modeling complex behavior dependencies is crucial for multi-behavior prediction. The state-of-the-art multi-behavior models learn behavior dependencies indistinguishably with all historical interactions as input. However, different behaviors may reflect different aspects of user preference, which means that some irrelevant interactions may play as noises to the target behavior to be predicted. To address the aforementioned limitations, we introduce multi-interest learning to the multi-behavior recommendation. More specifically, we propose a novel Coarse-to-fine Knowledge-enhanced Multi-interest Learning (CKML) framework to learn shared and behavior-specific interests for different behaviors. CKML introduces two advanced modules, namely  Coarse-grained Interest Extracting (CIE)  and  Fine-grained Behavioral Correlation (FBC) , which work jointly to capture fine-grained behavioral dependencies. CIE uses knowledge-aware information to extract initial representations of each interest. FBC incorporates a dynamic routing scheme to further assign each behavior among interests. Empirical results on three real-world datasets verify the effectiveness and efficiency of our model in exploiting multi-behavior data.}
}


@article{DBLP:journals/tois/MotheU24,
	author = {Josiane Mothe and
                  Md. Zia Ullah},
	title = {Selective Query Processing: {A} Risk-Sensitive Selection of Search
                  Configurations},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {31:1--31:35},
	year = {2024},
	url = {https://doi.org/10.1145/3608474},
	doi = {10.1145/3608474},
	timestamp = {Mon, 24 Jun 2024 13:38:51 +0200},
	biburl = {https://dblp.org/rec/journals/tois/MotheU24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In information retrieval systems, search parameters are optimized to ensure high effectiveness based on a set of past searches, and these optimized parameters are then used as the search configuration for all subsequent queries. A better approach, however, would be to adapt the parameters to fit the query at hand. Selective query expansion is one such an approach, in which the system decides automatically whether or not to expand the query, resulting in two possible search configurations. This approach was extended recently to include many other parameters, leading to many possible search configurations where the system automatically selects the best configuration on a per-query basis. One problem with this approach is the system training, which requires evaluation of each training query with every possible configuration. In real-world systems, so many parameters and possible values must be evaluated that this approach is impractical, especially when the system must be updated frequently, as is the case for commercial search engines. In general, the more configurations, the greater the effectiveness when configuration selection is appropriate but also the greater the risk of decreasing effectiveness in the case of an inappropriate configuration selection. To determine the ideal configurations to be used for each query in real-world systems, we have developed a method in which a limited number of possible configurations are pre-selected, then used in a meta-search engine that decides the best search configuration for each query. We define a risk-sensitive approach for configuration pre-selection that considers the risk-reward tradeoff between the number of configurations kept and system effectiveness. We define two alternative risk functions to apply to different goals. For final configuration selection, the decision is based on query feature similarities. We compare two alternative risk functions on two query types (ad hoc and diversity) and compare these to more sophisticated machine learning based methods. We find that a relatively small number of configurations (20) selected by our risk-sensitive model is sufficient to obtain results close to the best achievable results for each query. Effectiveness is increased by about 15% according to the P@10 and nDCG@10 evaluation metrics when compared to traditional grid search using a single configuration and by about 20% when compared to learning to rank documents. Our risk-sensitive approach works for both diversity- and ad hoc oriented searches. Moreover, the similarity-based selection method outperforms the more sophisticated approaches. Thus, we demonstrate the feasibility of developing per-query information retrieval systems, which will guide future research in this direction.}
}


@article{DBLP:journals/tois/ChengZJZCG24,
	author = {Zifeng Cheng and
                  Qingyu Zhou and
                  Zhiwei Jiang and
                  Xuemin Zhao and
                  Yunbo Cao and
                  Qing Gu},
	title = {Unifying Token- and Span-level Supervisions for Few-shot Sequence
                  Labeling},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {1},
	pages = {32:1--32:27},
	year = {2024},
	url = {https://doi.org/10.1145/3610403},
	doi = {10.1145/3610403},
	timestamp = {Thu, 10 Apr 2025 22:38:03 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ChengZJZCG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Few-shot sequence labeling aims to identify novel classes based on only a few labeled samples. Existing methods solve the data scarcity problem mainly by designing token-level or span-level labeling models based on metric learning. However, these methods are only trained at a single granularity (i.e., either token-level or span-level) and have some weaknesses of the corresponding granularity. In this article, we first unify token- and span-level supervisions and propose a Consistent Dual Adaptive Prototypical (CDAP) network for few-shot sequence labeling. CDAP contains the token- and span-level networks, jointly trained at different granularities. To align the outputs of two networks, we further propose a consistent loss to enable them to learn from each other. During the inference phase, we propose a consistent greedy inference algorithm that first adjusts the predicted probability and then greedily selects non-overlapping spans with maximum probability. Extensive experiments show that our model achieves new state-of-the-art results on three benchmark datasets. All the code and data of this work will be released at  https://github.com/zifengcheng/CDAP .}
}


@article{DBLP:journals/tois/YangZSDZL24,
	author = {Yang Yang and
                  Chubing Zhang and
                  Xin Song and
                  Zheng Dong and
                  Hengshu Zhu and
                  Wenjie Li},
	title = {Contextualized Knowledge Graph Embedding for Explainable Talent Training
                  Course Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {33:1--33:27},
	year = {2024},
	url = {https://doi.org/10.1145/3597022},
	doi = {10.1145/3597022},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/YangZSDZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learning and development, or L&D, plays an important role in talent management, which aims to improve the knowledge and capabilities of employees through a variety of performance-oriented training activities. Recently, with the rapid development of enterprise management information systems, many research efforts and industrial practices have been devoted to building personalized employee training course recommender systems. Nevertheless, a widespread challenge is how to provide explainable recommendations with the consideration of different learning motivations from talents. To this end, we propose CKGE, a contextualized knowledge graph (KG) embedding approach for developing an explainable training course recommender system. A novel perspective of CKGE is to integrate both the contextualized neighbor semantics and high-order connections as motivation-aware information for learning effective representations of talents and courses. Specifically, in CKGE, for each entity pair (i.e., the talent-course pair), we first construct a meta-graph, including the neighbors of each entity and the meta-paths between entities as motivation-aware information. Then, we develop a novel KG-based Transformer, which can serialize entities and paths in the meta-graph as a sequential input, with the specially designed relational attention and structural encoding mechanisms to better model the global dependence of KG structured data. Meanwhile, the local path mask prediction can effectively reveal the importance of different paths. As a result, CKGE not only can make precise predictions but also can discriminate the saliencies of meta-paths in characterizing corresponding preferences. Extensive experiments on real-world and public datasets clearly validate the effectiveness and interpretability of CKGE compared with state-of-the-art baselines.}
}


@article{DBLP:journals/tois/YaoZZS24,
	author = {Yitong Yao and
                  Jing Zhang and
                  Peng Zhang and
                  Yueheng Sun},
	title = {A Dual-branch Learning Model with Gradient-balanced Loss for Long-tailed
                  Multi-label Text Classification},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {34:1--34:24},
	year = {2024},
	url = {https://doi.org/10.1145/3597416},
	doi = {10.1145/3597416},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/YaoZZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-label text classification has a wide range of applications in the real world. However, the data distribution in the real world is often imbalanced, which leads to serious long-tailed problems. For multi-label classification, due to the vast scale of datasets and existence of label co-occurrence, how to effectively improve the prediction accuracy of tail labels without degrading the overall precision becomes an important challenge. To address this issue, we propose  A Dual-Branch Learning Model with Gradient-Balanced Loss (DBGB)  based on the paradigm of existing pre-trained multi-label classification SOTA models. Our model consists of two main long-tailed module improvements. First, with the shared text representation, the dual-classifier is leveraged to process two kinds of label distributions; one is the original data distribution and the other is the under-sampling distribution for head labels to strengthen the prediction for tail labels. Second, the proposed gradient-balanced loss can adaptively suppress the negative gradient accumulation problem related to labels, especially tail labels. We perform extensive experiments on three multi-label text classification datasets. The results show that the proposed method achieves competitive performance on overall prediction results compared to the state-of-the-art methods in solving the multi-label classification, with significant improvement on tail-label accuracy.}
}


@article{DBLP:journals/tois/LanMWGH24,
	author = {Tian Lan and
                  Xian{-}Ling Mao and
                  Wei Wei and
                  Xiaoyan Gao and
                  Heyan Huang},
	title = {Towards Efficient Coarse-grained Dialogue Response Selection},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {35:1--35:32},
	year = {2024},
	url = {https://doi.org/10.1145/3597609},
	doi = {10.1145/3597609},
	timestamp = {Sun, 19 Jan 2025 15:03:44 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LanMWGH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Coarse-grained response selection is a fundamental and essential subsystem for the widely used retrieval-based chatbots, aiming to recall a coarse-grained candidate set from a large-scale dataset. The dense retrieval technique has recently been proven very effective in building such a subsystem. However, dialogue dense retrieval models face two problems in real scenarios: (1) the multi-turn dialogue history is re-computed in each turn, leading to inefficient inference; (2) the index storage of the offline index is enormous, significantly increasing the deployment cost. To address these problems, we propose an efficient coarse-grained response selection subsystem consisting of two novel methods. Specifically, to address the first problem, we propose the  H ierarchical  D ense  R etrieval. It caches rich multi-vector representations of the dialogue history and only encodes the latest user’s utterance, leading to better inference efficiency. Then, to address the second problem, we design the  D eep  S emantic  H ashing to reduce the index storage while effectively saving its recall accuracy notably. Extensive experimental results prove the advantages of the two proposed methods over previous works. Specifically, with the limited performance loss, our proposed coarse-grained response selection model achieves over 5x FLOPs speedup and over 192x storage compression ratio. Moreover, our source codes have been publicly released.}
}


@article{DBLP:journals/tois/LiYMHS24,
	author = {Canjia Li and
                  Andrew Yates and
                  Sean MacAvaney and
                  Ben He and
                  Yingfei Sun},
	title = {{PARADE:} Passage Representation Aggregation forDocument Reranking},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {36:1--36:26},
	year = {2024},
	url = {https://doi.org/10.1145/3600088},
	doi = {10.1145/3600088},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiYMHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pre-trained transformer models, such as BERT and T5, have shown to be highly effective at ad hoc passage and document ranking. Due to the inherent sequence length limits of these models, they need to process document passages one at a time rather than processing the entire document sequence at once. Although several approaches for aggregating passage-level signals into a document-level relevance score have been proposed, there has yet to be an extensive comparison of these techniques. In this work, we explore strategies for aggregating relevance signals from a document’s passages into a final ranking score. We find that passage representation aggregation techniques can significantly improve over score aggregation techniques proposed in prior work, such as taking the maximum passage score. We call this new approach PARADE. In particular, PARADE can significantly improve results on collections with broad information needs where relevance signals can be spread throughout the document (such as TREC Robust04 and GOV2). Meanwhile, less complex aggregation techniques may work better on collections with an information need that can often be pinpointed to a single passage (such as TREC DL and TREC Genomics). We also conduct efficiency analyses and highlight several strategies for improving transformer-based aggregation.}
}


@article{DBLP:journals/tois/XieC24,
	author = {Jiayi Xie and
                  Zhenzhong Chen},
	title = {Hierarchical Transformer with Spatio-temporal Context Aggregation
                  for Next Point-of-interest Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {37:1--37:30},
	year = {2024},
	url = {https://doi.org/10.1145/3597930},
	doi = {10.1145/3597930},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/XieC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Next point-of-interest (POI) recommendation is a critical task in location-based social networks, yet remains challenging due to a high degree of variation and personalization exhibited in user movements. In this work, we explore the latent hierarchical structure composed of multi-granularity short-term structural patterns in user check-in sequences. We propose a Spatio-Temporal context AggRegated Hierarchical Transformer (STAR-HiT) for next POI recommendation, which employs stacked hierarchical encoders to recursively encode the spatio-temporal context and explicitly locate subsequences of different granularities. More specifically, in each encoder, the global attention layer captures the spatio-temporal context of the sequence, while the local attention layer performed within each subsequence enhances subsequence modeling using the local context. The sequence partition layer infers positions and lengths of subsequences from the global context adaptively, such that semantics in subsequences can be well preserved. Finally, the subsequence aggregation layer fuses representations within each subsequence to form the corresponding subsequence representation, thereby generating a new sequence of higher-level granularity. The stacking of hierarchical encoders captures the latent hierarchical structure of the check-in sequence, which is used to predict the next visiting POI. Extensive experiments on three public datasets demonstrate that the proposed model achieves superior performance while providing explanations for recommendations.}
}


@article{DBLP:journals/tois/XuXDW24,
	author = {Chen Xu and
                  Jun Xu and
                  Zhenhua Dong and
                  Ji{-}Rong Wen},
	title = {Syntactic-Informed Graph Networks for Sentence Matching},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {38:1--38:29},
	year = {2024},
	url = {https://doi.org/10.1145/3609795},
	doi = {10.1145/3609795},
	timestamp = {Sun, 19 Jan 2025 15:03:41 +0100},
	biburl = {https://dblp.org/rec/journals/tois/XuXDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Matching two natural language sentences is a fundamental problem in both natural language processing and information retrieval. Preliminary studies have shown that the syntactic structures help improve the matching accuracy, and different syntactic structures in natural language are complementary to sentence semantic understanding. Ideally, a matching model would leverage all syntactic information. Existing models, however, are only able to combine limited (usually one) types of syntactic information due to the complex and heterogeneous nature of the syntactic information. To deal with the problem, we propose a novel matching model, which formulates sentence matching as a representation learning task on a syntactic-informed heterogeneous graph. The model, referred to as SIGN (Syntactic-Informed Graph Network), first constructs a heterogeneous matching graph based on the multiple syntactic structures of two input sentences. Then the graph attention network algorithm is applied to the matching graph to learn the high-level representations of the nodes. With the help of the graph learning framework, the multiple syntactic structures, as well as the word semantics, can be represented and interacted in the matching graph and therefore collectively enhance the matching accuracy. We conducted comprehensive experiments on three public datasets. The results demonstrate that SIGN outperforms the state of the art and also can discriminate the sentences in an interpretable way.}
}


@article{DBLP:journals/tois/ZhangOML24,
	author = {Xinyu Zhang and
                  Kelechi Ogueji and
                  Xueguang Ma and
                  Jimmy Lin},
	title = {Toward Best Practices for Training Multilingual Dense Retrieval Models},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {39:1--39:33},
	year = {2024},
	url = {https://doi.org/10.1145/3613447},
	doi = {10.1145/3613447},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangOML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dense retrieval models using a transformer-based bi-encoder architecture have emerged as an active area of research. In this article, we focus on the task of monolingual retrieval in a variety of typologically diverse languages using such an architecture. Although recent work with multilingual transformers demonstrates that they exhibit strong cross-lingual generalization capabilities, there remain many open research questions, which we tackle here. Our study is organized as a “best practices” guide for training multilingual dense retrieval models, broken down into three main scenarios: when a multilingual transformer is available, but training data in the form of relevance judgments are not available in the language and domain of interest (“have model, no data”); when both models and training data are available (“have model and data”); and when training data are available but not models (“have data, no model”). In considering these scenarios, we gain a better understanding of the role of multi-stage fine-tuning, the strength of cross-lingual transfer under various conditions, the usefulness of out-of-language data, and the advantages of multilingual vs. monolingual transformers. Our recommendations offer a guide for practitioners building search applications, particularly for low-resource languages, and while our work leaves open a number of research questions, we provide a solid foundation for future work.}
}


@article{DBLP:journals/tois/MaWALSZM24,
	author = {Yixiao Ma and
                  Yueyue Wu and
                  Qingyao Ai and
                  Yiqun Liu and
                  Yunqiu Shao and
                  Min Zhang and
                  Shaoping Ma},
	title = {Incorporating Structural Information into Legal Case Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {40:1--40:28},
	year = {2024},
	url = {https://doi.org/10.1145/3609796},
	doi = {10.1145/3609796},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/MaWALSZM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Legal case retrieval has received increasing attention in recent years. However, compared to ad hoc retrieval tasks, legal case retrieval has its unique challenges. First, case documents are rather lengthy and contain complex legal structures. Therefore, it is difficult for most existing dense retrieval models to encode an entire document and capture its inherent complex structure information. Most existing methods simply truncate part of the document content to meet the input length limit of PLMs, which will lead to information loss. Additionally, the definition of relevance in the legal domain differs from that in the general domain. Previous semantic-based or lexical-based methods fail to provide a comprehensive understanding of the relevance of legal cases. In this article, we propose a Structured Legal case Retrieval (SLR) framework, which incorporates internal and external structural information to address the above two challenges. Specifically, to avoid the truncation of long legal documents, the internal structural information, which is the organization pattern of legal documents, can be utilized to split a case document into segments. By dividing the document-level semantic matching task into segment-level subtasks, SLR can separately process segments using different methods based on the characteristic of each segment. In this way, the key elements of a case document can be highlighted without losing other content information. Second, toward a better understanding of relevance in the legal domain, we investigate the connections between criminal charges appearing in large-scale case corpus to generate a chargewise relation graph. Then, the similarity between criminal charges can be pre-computed as the external structural information to enhance the recognition of relevant cases. Finally, a learning-to-rank algorithm integrates the features collected from internal and external structures to output the final retrieval results. Experimental results on public legal case retrieval benchmarks demonstrate the superior effectiveness of SLR over existing state-of-the-art baselines, including traditional bag-of-words and neural-based methods. Furthermore, we conduct a case study to visualize how the proposed model focuses on key elements and improves retrieval performance.}
}


@article{DBLP:journals/tois/SunYSW24,
	author = {Yatong Sun and
                  Xiaochun Yang and
                  Zhu Sun and
                  Bin Wang},
	title = {{BERD+:} {A} Generic Sequential Recommendation Framework by Eliminating
                  Unreliable Data with Item- and Attribute-level Signals},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {41:1--41:33},
	year = {2024},
	url = {https://doi.org/10.1145/3611008},
	doi = {10.1145/3611008},
	timestamp = {Thu, 30 May 2024 00:10:52 +0200},
	biburl = {https://dblp.org/rec/journals/tois/SunYSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most sequential recommendation systems (SRSs) predict the next item as the target for users given its preceding items as input, assuming the target is definitely related to its input. However, users may unintentionally click items that are inconsistent with their preference due to external factors, causing unreliable instances whose target mismatches the input. We,  for the first time , verify SRSs can be misguided by such unreliable instances and design a generic SRS framework  B y  E liminating un R eliable  D ata (BERD+), which can be flexibly plugged into existing SRSs. Specifically, BRED+ is guided with observations on the training process of instances: Unreliable instances generally have high training loss; high-loss instances are not necessarily unreliable but uncertain ones caused by blurry sequential patterns; and item attributes help rectify instance loss and uncertainty, but may also introduce disturbance. Accordingly, BERD+ models both the loss and uncertainty of each instance via a Gaussian distribution, whereby a heterogeneous uncertainty-aware graph convolution network is designed to learn accurate embeddings for different entities while reducing the disturbance caused by uncertain attribute values. Thereafter, an explicit preference extractor rectifies instance loss and uncertainty and reduces the disturbance caused by less-focused attribute types. Finally, instances with high loss and low uncertainty are eliminated as unreliable data. Extensive experiments verify the efficacy of BERD+.}
}


@article{DBLP:journals/tois/BruchNIL24,
	author = {Sebastian Bruch and
                  Franco Maria Nardini and
                  Amir Ingber and
                  Edo Liberty},
	title = {An Approximate Algorithm for Maximum Inner Product Search over Streaming
                  Sparse Vectors},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {42:1--42:43},
	year = {2024},
	url = {https://doi.org/10.1145/3609797},
	doi = {10.1145/3609797},
	timestamp = {Sun, 25 May 2025 13:43:34 +0200},
	biburl = {https://dblp.org/rec/journals/tois/BruchNIL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximum Inner Product Search or top- k  retrieval on sparse vectors is well understood in information retrieval, with a number of mature algorithms that solve it exactly. However, all existing algorithms are tailored to text and frequency-based similarity measures. To achieve optimal memory footprint and query latency, they rely on the near stationarity of documents and on laws governing natural languages. We consider, instead, a setup in which collections are streaming—necessitating dynamic indexing—and where indexing and retrieval must work with arbitrarily distributed real-valued vectors. As we show, existing algorithms are no longer competitive in this setup, even against naïve solutions. We investigate this gap and present a novel  approximate  solution, called  Sinnamon , that can efficiently retrieve the top- k  results for sparse  real valued  vectors drawn from arbitrary distributions. Notably,  Sinnamon  offers levers to trade off memory consumption, latency, and accuracy, making the algorithm suitable for constrained applications and systems. We give theoretical results on the error introduced by the approximate nature of the algorithm and present an empirical evaluation of its performance on two hardware platforms and synthetic and real-valued datasets. We conclude by laying out concrete directions for future research on this general top- k  retrieval problem over sparse vectors.}
}


@article{DBLP:journals/tois/ZhangJKFYMZZYCW24,
	author = {Shengyu Zhang and
                  Tan Jiang and
                  Kun Kuang and
                  Fuli Feng and
                  Jin Yu and
                  Jianxin Ma and
                  Zhou Zhao and
                  Jianke Zhu and
                  Hongxia Yang and
                  Tat{-}Seng Chua and
                  Fei Wu},
	title = {{SLED:} Structure Learning based Denoising for Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {43:1--43:31},
	year = {2024},
	url = {https://doi.org/10.1145/3611385},
	doi = {10.1145/3611385},
	timestamp = {Fri, 14 Feb 2025 11:54:19 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangJKFYMZZYCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recommender systems, click behaviors play a fundamental role in mining users’ interests and training models (clicked items as positive samples). Such signals are  implicit  feedback and are arguably less representative of users’ inherent interests. Most existing works denoise implicit feedback by introducing external signals, such as gaze, dwell time, and “like” behaviors. However, such  explicit  feedback is not always routinely available, or might be problematic to collect on a large scale. In this paper, we identify that an interaction’s related structural patterns in its neighborhood graph are potentially correlated with some outcome of implicit feedback (i.e., users’ ratings after consuming items), analogous to findings in other domains such as social networks. Inspired by this finding, we propose a novel Structure LEarning based Denoising (SLED) framework for denoising recommendation without explicit signals, which consists of two phases:  center-aware graph structure learning  and  denoised recommendation . Phase 1 pre-trains a structural encoder in a self-supervised manner and learns to capture an interaction’s related structural patterns in its neighborhood graph. Phase 2 transfers the structure encoder to downstream recommendation datasets, which helps to down-weight the effect of noisy interactions on user interest modeling and loss calculation. We collect a relatively noisy industrial dataset across several days during a period of product promotion festival. Extensive experiments on this dataset and multiple public datasets demonstrate that the proposed SLED framework can significantly improve the recommendation quality over various base recommendation models.}
}


@article{DBLP:journals/tois/QuanDGLYJL24,
	author = {Yuhan Quan and
                  Jingtao Ding and
                  Chen Gao and
                  Nian Li and
                  Lingling Yi and
                  Depeng Jin and
                  Yong Li},
	title = {Alleviating Video-length Effect for Micro-video Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {44:1--44:24},
	year = {2024},
	url = {https://doi.org/10.1145/3617826},
	doi = {10.1145/3617826},
	timestamp = {Sat, 03 Aug 2024 16:25:29 +0200},
	biburl = {https://dblp.org/rec/journals/tois/QuanDGLYJL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Micro-video platforms such as TikTok are extremely popular nowadays. One important feature is that users no longer select interested videos from a set; instead, they either watch the recommended video or skip to the next one. As a result, the time length of users’ watching behavior becomes the most important signal for identifying preferences. However, our empirical data analysis has shown a video-length effect that long videos can more easily receive a higher value of average view time, and thus adopting such view-time labels for measuring user preferences can easily induce a biased model that favors the longer videos. In this article, we propose a  V ideo  L ength  D ebiasing  Rec ommendation\xa0(VLDRec) method to alleviate such an effect for micro-video recommendation. VLDRec designs the data labeling approach and the sample generation module that better capture user preferences in a view-time-oriented manner. It further leverages the multi-task learning technique to jointly optimize the above samples with the original biased ones. Extensive experiments show that VLDRec can improve users’ view time by 1.81% and 11.32% on two real-world datasets, given a recommendation list of a fixed overall video length, compared with the best baseline method. Moreover, VLDRec is also more effective in matching users’ interests in terms of the video content.}
}


@article{DBLP:journals/tois/LiuLYSSLZD24,
	author = {Sannyuya Liu and
                  Shengyingjie Liu and
                  Zongkai Yang and
                  Jianwen Sun and
                  Xiaoxuan Shen and
                  Qing Li and
                  Rui Zou and
                  Shangheng Du},
	title = {Heterogeneous Evolution Network Embedding with Temporal Extension
                  for Intelligent Tutoring Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {45:1--45:28},
	year = {2024},
	url = {https://doi.org/10.1145/3617828},
	doi = {10.1145/3617828},
	timestamp = {Sun, 19 Jan 2025 15:03:41 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiuLYSSLZD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph embedding (GE) aims to acquire low-dimensional node representations while maintaining the graph’s structural and semantic attributes. Intelligent tutoring systems (ITS) signify a noteworthy achievement in the fusion of AI and education. Utilizing GE to model ITS can elevate their performance in predictive and annotation tasks. Current GE techniques, whether applied to heterogeneous or dynamic graphs, struggle to efficiently model ITS data. The GEs within ITS should retain their semidynamic, independent, and smooth characteristics. This article introduces a heterogeneous evolution network (HEN) for illustrating entities and relations within an ITS. Additionally, we introduce a temporal extension graph neural network (TEGNN) to model both evolving and static nodes within the HEN. In the TEGNN framework, dynamic nodes are initially improved over time through temporal extension (TE), providing an accurate depiction of each learner’s implicit state at each time step. Subsequently, we propose a stochastic temporal pooling (STP) strategy to estimate the embedding sets of all evolving nodes. This effectively enhances model efficiency and usability. Following this, a heterogeneous aggregation network is devised to proficiently extract heterogeneous features from the HEN. This network employs both node-level and relation-level attention mechanisms to craft aggregated node features. To emphasize the superiority of TEGNN, we perform experiments on several real ITS datasets and show that our method significantly outperforms the state-of-the-art approaches. The experiments validate that TE serves as an efficient framework for modeling temporal information in GE, and STP not only accelerates the training process but also enhances the resultant accuracy.}
}


@article{DBLP:journals/tois/NiuLLHWG24,
	author = {Yanrui Niu and
                  Chao Liang and
                  Ankang Lu and
                  Baojin Huang and
                  Zhongyuan Wang and
                  Jiahao Guo},
	title = {Person-action Instance Search in Story Videos: An Experimental Study},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {46:1--46:34},
	year = {2024},
	url = {https://doi.org/10.1145/3617892},
	doi = {10.1145/3617892},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/NiuLLHWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Person-Action instance search (P-A INS) aims to retrieve the instances of a specific person doing a specific action, which appears in the 2019–2021 INS tasks of the world-famous TREC Video Retrieval Evaluation (TRECVID). Most of the top-ranking solutions can be summarized with a Division-Fusion-Optimization (DFO) framework, in which person and action recognition scores are obtained separately, then fused, and, optionally, further optimized to generate the final ranking. However, TRECVID only evaluates the final ranking results, ignoring the effects of intermediate steps and their implementation methods. We argue that conducting the fine-grained evaluations of intermediate steps of DFO framework will (1) provide a quantitative analysis of the different methods’ performance in intermediate steps; (2) find out better design choices that contribute to improving retrieval performance; and (3) inspire new ideas for future research from the limitation analysis of current techniques. Particularly, we propose an indirect evaluation method motivated by the leave-one-out strategy, which finds an optimal solution surpassing the champion teams in 2020–2021 INS tasks. Moreover, to validate the generalizability and robustness of the proposed solution under various scenarios, we specifically construct a new large-scale P-A INS dataset and conduct comparative experiments with both the leading NIST TRECVID INS solution and the state-of-the-art P-A INS method. Finally, we discuss the limitations of our evaluation work and suggest future research directions.}
}


@article{DBLP:journals/tois/LiuWLWNC24,
	author = {Han Liu and
                  Yinwei Wei and
                  Fan Liu and
                  Wenjie Wang and
                  Liqiang Nie and
                  Tat{-}Seng Chua},
	title = {Dynamic Multimodal Fusion via Meta-Learning Towards Micro-Video Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {47:1--47:26},
	year = {2024},
	url = {https://doi.org/10.1145/3617827},
	doi = {10.1145/3617827},
	timestamp = {Thu, 30 Jan 2025 15:34:23 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiuWLWNC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multimodal information (e.g., visual, acoustic, and textual) has been widely used to enhance representation learning for micro-video recommendation. For integrating multimodal information into a joint representation of micro-video, multimodal fusion plays a vital role in the existing micro-video recommendation approaches. However, the static multimodal fusion used in previous studies is insufficient to model the various relationships among multimodal information of different micro-videos. In this article, we develop a novel meta-learning-based multimodal fusion framework called  Meta Multimodal Fusion  (MetaMMF), which dynamically assigns parameters to the multimodal fusion function for each micro-video during its representation learning. Specifically, MetaMMF regards the multimodal fusion of each micro-video as an independent task. Based on the meta information extracted from the multimodal features of the input task, MetaMMF parameterizes a neural network as the item-specific fusion function via a meta learner. We perform extensive experiments on three benchmark datasets, demonstrating the significant improvements over several state-of-the-art multimodal recommendation models, like MMGCN, LATTICE, and InvRL. Furthermore, we lighten our model by adopting canonical polyadic decomposition to improve the training efficiency, and validate its effectiveness through experimental results. Codes are available at  https://github.com/hanliu95/MetaMMF .}
}


@article{DBLP:journals/tois/GuoLZGC24,
	author = {Lei Guo and
                  Hao Liu and
                  Lei Zhu and
                  Weili Guan and
                  Zhiyong Cheng},
	title = {{DA-DAN:} {A} Dual Adversarial Domain Adaption Network for Unsupervised
                  Non-overlapping Cross-domain Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {48:1--48:27},
	year = {2024},
	url = {https://doi.org/10.1145/3617825},
	doi = {10.1145/3617825},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/GuoLZGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised Non-overlapping Cross-domain Recommendation (UNCR) is the task that recommends source domain items to the target domain users, which is more challenging as the users are non-overlapped, and its learning process is unsupervised. Unsupervised Non-overlapping Cross-domain Recommendation UNCR is still unsolved due to the following: (1) Previous studies need extra auxiliary information to learn transferable features when aligning two domains, which is unrealistic and hard to obtain due to privacy concerns. (2) Since the adoption of the shared network, existing works cannot well eliminate the domain-specific features in the common feature space, which may incorporate domain noise and harm the cross-domain recommendation. In this work, we propose a domain adaption-based method, namely DA-DAN, to address the above challenges. Specifically, to let DA-DAN be free of auxiliary information, we learn users’ preferences by only exploring their sequential patterns, and propose an improved self-attention layer to model them. To well eliminate the domain-specific features from the common feature space, we resort to a dual generative adversarial network with a multi-target adversarial loss, where two generators and discriminators are leveraged to model each domain separately. Experimental results on three real-world datasets demonstrate the advantage of DA-DAN compared with the state-of-the-art recommendation baselines. Moreover, our source codes have been publicly released.}
}


@article{DBLP:journals/tois/MaLLZL24,
	author = {Longxuan Ma and
                  Jiapeng Li and
                  Mingda Li and
                  Weinan Zhang and
                  Ting Liu},
	title = {Policy-driven Knowledge Selection and Response Generation for Document-grounded
                  Dialogue},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {49:1--49:29},
	year = {2024},
	url = {https://doi.org/10.1145/3617829},
	doi = {10.1145/3617829},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/MaLLZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Document-grounded dialogue (DGD) uses documents as external knowledge for dialogue generation. Correctly understanding the dialogue context is crucial for selecting knowledge from the document and generating proper responses. In this article, we propose using a dialogue policy to help the dialogue understanding in DGD. Our dialogue policy consists of two kinds of guiding signals: utterance function and topic transfer intent. The utterance function reflects the purpose and style of an utterance, and the topic transfer intent reflects the topic and content of an utterance. We propose a novel framework exploiting our dialogue policy for two core tasks in DGD, namely, knowledge selection (KS) and response generation (RG). The framework consists of two modules: the policy planner leverages policy-aware dialogue representation to select knowledge and predict the policy of the response; the generator uses policy/knowledge-aware dialogue representation for response generation. Our policy-driven model gets state-of-the-art performance on three public benchmarks, and we provide a detailed analysis of the experimental results. Our code/data will be released on GitHub.}
}


@article{DBLP:journals/tois/HuWLTN24,
	author = {Yupeng Hu and
                  Kun Wang and
                  Meng Liu and
                  Haoyu Tang and
                  Liqiang Nie},
	title = {Semantic Collaborative Learning for Cross-Modal Moment Localization},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {50:1--50:26},
	year = {2024},
	url = {https://doi.org/10.1145/3620669},
	doi = {10.1145/3620669},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/HuWLTN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Localizing a desired moment within an untrimmed video via a given natural language query, i.e., cross-modal moment localization, has attracted widespread research attention recently. However, it is a challenging task because it requires not only accurately understanding intra-modal semantic information, but also explicitly capturing inter-modal semantic correlations\xa0(consistency and complementarity). Existing efforts mainly focus on intra-modal semantic understanding and inter-modal semantic alignment, while ignoring necessary semantic supplement. Consequently, we present a cross-modal semantic perception network for more effective intra-modal semantic understanding and inter-modal semantic collaboration. Concretely, we design a dual-path representation network for intra-modal semantic modeling. Meanwhile, we develop a semantic collaborative network to achieve multi-granularity semantic alignment and hierarchical semantic supplement. Thereby, effective moment localization can be achieved based on sufficient semantic collaborative learning. Extensive comparison experiments demonstrate the promising performance of our model compared with existing state-of-the-art competitors.}
}


@article{DBLP:journals/tois/WangZZWLM24,
	author = {Ke Wang and
                  Yanmin Zhu and
                  Tianzi Zang and
                  Chunyang Wang and
                  Kuan Liu and
                  Peibo Ma},
	title = {Multi-aspect Graph Contrastive Learning for Review-enhanced Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {51:1--51:29},
	year = {2024},
	url = {https://doi.org/10.1145/3618106},
	doi = {10.1145/3618106},
	timestamp = {Tue, 25 Mar 2025 14:42:32 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WangZZWLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Review-based recommender systems explore semantic aspects of users’ preferences by incorporating user-generated reviews into rating-based models. Recent works have demonstrated the potential of review information to improve the recommendation capacity. However, most existing studies rely on optimizing review-based representation learning part, thus failing to explicitly capture the fine-grained semantic aspects, and also ignoring the intrinsic correlation between ratings and reviews. To address these problems, we propose a multi-aspect graph contrastive learning framework, named MAGCL, with three distinctive designs: (i) a multi-aspect representation learning module, which projects semantic relations to different subspaces by decoupling review information, and then obtains high-order decoupled representations in each aspect via graph encoder. (ii) the contrastive learning module performs graph contrastive learning to capture the correlation between rating and review patterns, which utilize unlabeled data to generate self-supervised signals and, in turn, relieve the data sparsity problem of supervision signals. (iii) the multi-task learning module conducts joint training to learn high-order structure-aware yet self-discriminative node representations by combining recommendation task and self-supervised task, which helps alleviate the over-smoothing problem. Extensive experiments are conducted on four real-world review datasets and the results show the superiority of the proposed framework MAGCL compared with several state of the arts. We also provide further analysis on multi-aspect representations and graph contrastive learning to verify the advantage of proposed framework.}
}


@article{DBLP:journals/tois/ShiLXWPSL24,
	author = {Xiaoyu Shi and
                  Quanliang Liu and
                  Hong Xie and
                  Di Wu and
                  Bo Peng and
                  Mingsheng Shang and
                  Defu Lian},
	title = {Relieving Popularity Bias in Interactive Recommendation: {A} Diversity-Novelty-Aware
                  Reinforcement Learning Approach},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {52:1--52:30},
	year = {2024},
	url = {https://doi.org/10.1145/3618107},
	doi = {10.1145/3618107},
	timestamp = {Wed, 13 Nov 2024 15:45:07 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ShiLXWPSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While  personalization  increases the utility of item recommendation, it also suffers from the issue of popularity bias. However, previous methods emphasize adopting supervised learning models to relieve popularity bias in the static recommendation, ignoring the dynamic transfer of user preference and amplification effects of the feedback loop in the recommender system (RS). In this paper, we focus on studying this issue in the interactive recommendation. We argue that diversification and novelty are both equally crucial for improving user satisfaction of IRS in the aforementioned setting. To achieve this goal, we propose a  D iversity- N ovelty- a ware  I nteractive  R ecommendation framework (DNaIR) that augments offline reinforcement learning (RL) to increase the exposure rate of long-tail items with high quality. Its main idea is first to aggregate the item similarity, popularity, and quality into the reward model to help the planning of RL policy. It then designs a diversity-aware stochastic action generator to achieve an efficient and lightweight DNaIR algorithm. Extensive experiments are conducted on the three real-world datasets and an authentic RL environment (Virtual-Taobao). The experiments show that our model can better and full use of the long-tail items to improve recommendation satisfaction, especially those low popularity items with high-quality ones, thus achieving state-of-the-art performance.}
}


@article{DBLP:journals/tois/ChenSJLHN24,
	author = {Xiaolin Chen and
                  Xuemeng Song and
                  Liqiang Jing and
                  Shuo Li and
                  Linmei Hu and
                  Liqiang Nie},
	title = {Multimodal Dialog Systems with Dual Knowledge-enhanced Generative
                  Pretrained Language Model},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {53:1--53:25},
	year = {2024},
	url = {https://doi.org/10.1145/3606368},
	doi = {10.1145/3606368},
	timestamp = {Sun, 19 Jan 2025 15:03:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ChenSJLHN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text response generation for multimodal task-oriented dialog systems, which aims to generate the proper text response given the multimodal context, is an essential yet challenging task. Although existing efforts have achieved compelling success, they still suffer from two pivotal limitations: (1)\xa0 overlook the benefit of generative pretraining  and (2)  ignore the textual context-related knowledge . To address these limitations, we propose a novel dual knowledge-enhanced generative pretrained language mode for multimodal task-oriented dialog systems\xa0(DKMD), consisting of three key components:  dual knowledge selection ,  dual knowledge-enhanced context learning , and  knowledge-enhanced response generation . To be specific, the dual knowledge selection component aims to select the related knowledge according to both textual and visual modalities of the given context. Thereafter, the dual knowledge-enhanced context learning component targets seamlessly, integrating the selected knowledge into the multimodal context learning from both global and local perspectives, where the cross-modal semantic relation is also explored. Moreover, the knowledge-enhanced response generation component comprises a revised BART decoder, where an additional dot-product knowledge-decoder attention sub-layer is introduced for explicitly utilizing the knowledge to advance the text response generation. Extensive experiments on a public dataset verify the superiority of the proposed DKMD over state-of-the-art competitors.}
}


@article{DBLP:journals/tois/QinWJLZ24,
	author = {Yifang Qin and
                  Hongjun Wu and
                  Wei Ju and
                  Xiao Luo and
                  Ming Zhang},
	title = {A Diffusion Model for {POI} Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {54:1--54:27},
	year = {2024},
	url = {https://doi.org/10.1145/3624475},
	doi = {10.1145/3624475},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/QinWJLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Next Point-of-Interest (POI) recommendation is a critical task in location-based services that aim to provide personalized suggestions for the user’s next destination. Previous works on POI recommendation have laid focus on modeling the user’s spatial preference. However, existing works that leverage spatial information are only based on the aggregation of users’ previous visited positions, which discourages the model from recommending POIs in novel areas. This trait of position-based methods will harm the model’s performance in many situations. Additionally, incorporating sequential information into the user’s spatial preference remains a challenge. In this article, we propose  Diff-POI : a  Diffu sion-based model that samples the user’s spatial preference for the next  POI  recommendation. Inspired by the wide application of diffusion algorithm in sampling from distributions, Diff-POI encodes the user’s visiting sequence and spatial character with two tailor-designed graph encoding modules, followed by a diffusion-based sampling strategy to explore the user’s spatial visiting trends. We leverage the diffusion process and its reverse form to sample from the posterior distribution and optimized the corresponding score function. We design a joint training and inference framework to optimize and evaluate the proposed Diff-POI. Extensive experiments on four real-world POI recommendation datasets demonstrate the superiority of our Diff-POI over state-of-the-art baseline methods. Further ablation and parameter studies on Diff-POI reveal the functionality and effectiveness of the proposed diffusion-based sampling strategy for addressing the limitations of existing methods.}
}


@article{DBLP:journals/tois/SiroAR24,
	author = {Clemencia Siro and
                  Mohammad Aliannejadi and
                  Maarten de Rijke},
	title = {Understanding and Predicting User Satisfaction with Conversational
                  Recommender Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {55:1--55:37},
	year = {2024},
	url = {https://doi.org/10.1145/3624989},
	doi = {10.1145/3624989},
	timestamp = {Sun, 06 Oct 2024 21:41:42 +0200},
	biburl = {https://dblp.org/rec/journals/tois/SiroAR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User satisfaction depicts the effectiveness of a system from the user’s perspective. Understanding and predicting user satisfaction is vital for the design of user-oriented evaluation methods for  conversational recommender systems (CRSs) . Current approaches rely on turn-level satisfaction ratings to predict a user’s overall satisfaction with CRS. These methods assume that all users perceive satisfaction similarly, failing to capture the broader dialogue aspects that influence overall user satisfaction. We investigate the effect of several dialogue aspects on user satisfaction when interacting with a CRS. To this end, we annotate dialogues based on six aspects\xa0(i.e.,  relevance ,  interestingness ,  understanding ,  task-completion ,  interest-arousal , and  efficiency ) at the turn and dialogue levels. We find that the concept of satisfaction varies per user. At the turn level, a system’s ability to make relevant recommendations is a significant factor in satisfaction. We adopt these aspects as features for predicting response quality and user satisfaction. We achieve an F1-score of 0.80 in classifying dissatisfactory dialogues, and a Pearson’s  r  of 0.73 for turn-level response quality estimation, demonstrating the effectiveness of the proposed dialogue aspects in predicting user satisfaction and being able to identify dialogues where the system is failing. With this article, we release our annotated data. 1 }
}


@article{DBLP:journals/tois/WangZZQCX24,
	author = {Chao Wang and
                  Hengshu Zhu and
                  Chen Zhu and
                  Chuan Qin and
                  Enhong Chen and
                  Hui Xiong},
	title = {SetRank: {A} Setwise Bayesian Approach for Collaborative Ranking in
                  Recommender System},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {56:1--56:32},
	year = {2024},
	url = {https://doi.org/10.1145/3626194},
	doi = {10.1145/3626194},
	timestamp = {Wed, 07 Aug 2024 07:51:03 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WangZZQCX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent development of recommender systems has a focus on collaborative ranking, which provides users with a sorted list rather than rating prediction. The sorted item lists can more directly reflect the preferences for users and usually perform better than rating prediction in practice. While considerable efforts have been made in this direction, the well-known pairwise and listwise approaches have still been limited by various challenges. Specifically, for the pairwise approaches, the assumption of independent pairwise preference is not always held in practice. Also, the listwise approaches cannot efficiently accommodate “ties” and unobserved data due to the precondition of the entire list permutation. To this end, in this article, we propose a novel setwise Bayesian approach for collaborative ranking, namely, SetRank, to inherently accommodate the characteristics of user feedback in recommender systems. SetRank aims to maximize the posterior probability of novel setwise preference structures and three implementations for SetRank are presented. We also theoretically prove that the bound of excess risk in SetRank can be proportional to  √ 𝑀 / 𝑁 , where  M  and  N  are the numbers of items and users, respectively. Finally, extensive experiments on four real-world datasets clearly validate the superiority of SetRank compared with various state-of-the-art baselines.}
}


@article{DBLP:journals/tois/XuPSC24,
	author = {Shicheng Xu and
                  Liang Pang and
                  Huawei Shen and
                  Xueqi Cheng},
	title = {NIR-Prompt: {A} Multi-task Generalized Neural Information Retrieval
                  Training Framework},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {57:1--57:32},
	year = {2024},
	url = {https://doi.org/10.1145/3626092},
	doi = {10.1145/3626092},
	timestamp = {Sun, 19 Jan 2025 15:03:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/XuPSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information retrieval aims to find information that meets users’ needs from the corpus. Different needs correspond to different IR tasks such as document retrieval, open-domain question answering, retrieval-based dialogue, and so on, while they share the same schema to estimate the relationship between texts. It indicates that a good IR model can generalize to different tasks and domains. However, previous studies indicate that state-of-the-art neural information retrieval (NIR) models, e.g., pre-trained language models (PLMs) are hard to generalize. It is mainly because the end-to-end fine-tuning paradigm makes the model overemphasize task-specific signals and domain biases but loses the ability to capture generalized essential signals. To address this problem, we propose a novel NIR training framework named NIR-Prompt for retrieval and reranking stages based on the idea of decoupling signal capturing and combination. NIR-Prompt exploits Essential Matching Module (EMM) to capture the essential matching signals and gets the description of tasks by Matching Description Module (MDM). The description is used as task-adaptation information to combine the essential matching signals to adapt to different tasks. Experiments under in-domain multi-task, out-of-domain multi-task, and new task adaptation settings show that NIR-Prompt can improve the generalization of PLMs in NIR for both retrieval and reranking stages compared with baselines.}
}


@article{DBLP:journals/tois/WanLWQLGCW24,
	author = {Zhongwei Wan and
                  Xin Liu and
                  Benyou Wang and
                  Jiezhong Qiu and
                  Boyu Li and
                  Ting Guo and
                  Guangyong Chen and
                  Yang Wang},
	title = {Spatio-temporal Contrastive Learning-enhanced GNNs for Session-based
                  Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {58:1--58:26},
	year = {2024},
	url = {https://doi.org/10.1145/3626091},
	doi = {10.1145/3626091},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WanLWQLGCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Session-based recommendation (SBR) systems aim to utilize the user’s short-term behavior sequence to predict the next item without the detailed user profile.  Most recent works try to model the user preference by treating the sessions as between-item transition graphs and utilize various graph neural networks (GNNs) to encode the representations of pair-wise relations among items and their neighbors. Some of the existing GNN-based models mainly focus on aggregating information from the view of spatial graph structure, which ignores the temporal relations within neighbors of an item during message passing and the information loss results in a sub-optimal problem. Other works embrace this challenge by incorporating additional temporal information but lack sufficient interaction between the spatial and temporal patterns. To address this issue, inspired by the uniformity and alignment properties of contrastive learning techniques, we propose a novel framework called Session-based Recommendation with Spatio-temporal Contrastive Learning-enhanced GNNs (RESTC). The idea is to supplement the GNN-based main supervised recommendation task with the temporal representation via an auxiliary cross-view contrastive learning mechanism. Furthermore, a novel global collaborative filtering graph embedding is leveraged to enhance the spatial view in the main task.  Extensive experiments demonstrate the significant performance of RESTC compared with the state-of-the-art baselines. We release our source code at  https://github.com/SUSTechBruce/RESTC-Source-code .}
}


@article{DBLP:journals/tois/JingZZW24,
	author = {Mengyuan Jing and
                  Yanmin Zhu and
                  Tianzi Zang and
                  Ke Wang},
	title = {Contrastive Self-supervised Learning in Recommender Systems: {A} Survey},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {59:1--59:39},
	year = {2024},
	url = {https://doi.org/10.1145/3627158},
	doi = {10.1145/3627158},
	timestamp = {Tue, 25 Mar 2025 14:42:32 +0100},
	biburl = {https://dblp.org/rec/journals/tois/JingZZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based recommender systems have achieved remarkable success in recent years. However, these methods usually heavily rely on labeled data (i.e., user-item interactions), suffering from problems such as data sparsity and cold-start. Self-supervised learning, an emerging paradigm that extracts information from unlabeled data, provides insights into addressing these problems. Specifically, contrastive self-supervised learning, due to its flexibility and promising performance, has attracted considerable interest and recently become a dominant branch in self-supervised learning-based recommendation methods. In this survey, we provide an up-to-date and comprehensive review of current contrastive self-supervised learning-based recommendation methods. Firstly, we propose a unified framework for these methods. We then introduce a taxonomy based on the key components of the framework, including view generation strategy, contrastive task, and contrastive objective. For each component, we provide detailed descriptions and discussions to guide the choice of the appropriate method. Finally, we outline open issues and promising directions for future research.}
}


@article{DBLP:journals/tois/YiOM24,
	author = {Zixuan Yi and
                  Iadh Ounis and
                  Craig MacDonald},
	title = {Contrastive Graph Prompt-tuning for Cross-domain Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {60:1--60:28},
	year = {2024},
	url = {https://doi.org/10.1145/3618298},
	doi = {10.1145/3618298},
	timestamp = {Fri, 26 Jan 2024 07:56:37 +0100},
	biburl = {https://dblp.org/rec/journals/tois/YiOM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems commonly suffer from the long-standing data sparsity problem where insufficient user-item interaction data limits the systems’ ability to make accurate recommendations. This problem can be alleviated using cross-domain recommendation techniques. In particular, in a cross-domain setting, knowledge sharing between domains permits improved effectiveness on the target domain. While recent cross-domain recommendation techniques used a pre-training configuration, we argue that such techniques lead to a low fine-tuning efficiency, especially when using large neural models. In recent language models,  prompts  have been used for parameter-efficient and time-efficient tuning of the models on the downstream tasks—these prompts represent a tunable latent vector that permits to freeze the rest of the language model’s parameters. To address the cross-domain recommendation task in an efficient manner, we propose a novel Personalised Graph Prompt-based Recommendation (PGPRec) framework, which leverages the efficiency benefits from prompt-tuning. In such a framework, we develop personalised and item-wise graph prompts based on relevant items to those items the user has interacted with. In particular, we apply Contrastive Learning to generate the pre-trained embeddings, to allow an increased generalisability in the pre-training stage, and to ensure an effective prompt-tuning stage. To evaluate the effectiveness of our PGPRec framework in a cross-domain setting, we conduct an extensive evaluation with the top- k  recommendation task and perform a cold-start analysis. The obtained empirical results on four Amazon Review datasets show that our proposed PGPRec framework can reduce up to 74% of the tuned parameters with a competitive performance and achieves an 11.41% improved performance compared to the strongest baseline in a cold-start scenario.}
}


@article{DBLP:journals/tois/BassaniTP24,
	author = {Elias Bassani and
                  Nicola Tonellotto and
                  Gabriella Pasi},
	title = {Personalized Query Expansion with Contextual Word Embeddings},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {61:1--61:35},
	year = {2024},
	url = {https://doi.org/10.1145/3624988},
	doi = {10.1145/3624988},
	timestamp = {Sun, 19 Jan 2025 15:03:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/BassaniTP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized Query Expansion, the task of expanding queries with additional terms extracted from the user-related vocabulary, is a well-known solution to improve the retrieval performance of a system w.r.t. short queries. Recent approaches rely on word embeddings to select expansion terms from user-related texts. Although promising results have been delivered with former word embedding techniques, we argue that these methods are not suited for contextual word embeddings, which produce a unique vector representation for each term occurrence. In this article, we propose a Personalized Query Expansion method designed to solve the issues arising from the use of contextual word embeddings with the current Personalized Query Expansion approaches based on word embeddings. Specifically, we employ a clustering-based procedure to identify the terms that better represent the user interests and to improve the diversity of those selected for expansion, achieving improvements of up to 4% w.r.t. the best-performing baseline in terms of MAP@100. Moreover, our approach outperforms previous ones in terms of efficiency, allowing us to achieve sub-millisecond expansion times even in data-rich scenarios. Finally, we introduce a novel metric to evaluate the expansion terms’ diversity and empirically show the unsuitability of previous approaches based on word embeddings when employed along with contextual word embeddings, which cause the selection of semantically overlapping expansion terms.}
}


@article{DBLP:journals/tois/ShaoLWLAMMM24,
	author = {Yunqiu Shao and
                  Haitao Li and
                  Yueyue Wu and
                  Yiqun Liu and
                  Qingyao Ai and
                  Jiaxin Mao and
                  Yixiao Ma and
                  Shaoping Ma},
	title = {An Intent Taxonomy of Legal Case Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {2},
	pages = {62:1--62:27},
	year = {2024},
	url = {https://doi.org/10.1145/3626093},
	doi = {10.1145/3626093},
	timestamp = {Wed, 27 Nov 2024 16:25:28 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ShaoLWLAMMM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Legal case retrieval is a special Information Retrieval\xa0(IR) task focusing on legal case documents. Depending on the downstream tasks of the retrieved case documents, users’ information needs in legal case retrieval could be significantly different from those in Web search and traditional ad hoc retrieval tasks. While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this article, are more complicated than that yet mostly unexplored. To this end, we present a novel hierarchical intent taxonomy of legal case retrieval. It consists of five intent types categorized by three criteria, i.e., search for  Particular Case(s) ,  Characterization ,  Penalty ,  Procedure , and  Interest . The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis. Through a laboratory user study, we reveal significant differences in user behavior and satisfaction under different search intents in legal case retrieval. Furthermore, we apply the proposed taxonomy to various downstream legal retrieval tasks, e.g., result ranking and satisfaction prediction, and demonstrate its effectiveness. Our work provides important insights into the understanding of user intents in legal case retrieval and potentially leads to better retrieval techniques in the legal domain, such as intent-aware ranking strategies and evaluation methodologies.}
}


@article{DBLP:journals/tois/YinHWZ24,
	author = {Zhizhuo Yin and
                  Kai Han and
                  Pengzi Wang and
                  Xi Zhu},
	title = {{H3GNN:} Hybrid Hierarchical HyperGraph Neural Network for Personalized
                  Session-based Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {63:1--63:30},
	year = {2024},
	url = {https://doi.org/10.1145/3630002},
	doi = {10.1145/3630002},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/YinHWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized Session-based recommendation (PSBR) is a general and challenging task in the real world, aiming to recommend a session’s next clicked item based on the session’s item transition information and the corresponding user’s historical sessions. A session is defined as a sequence of interacted items during a short period. The PSBR problem has a natural hierarchical architecture in which each session consists of a series of items, and each user owns a series of sessions. However, the existing PSBR methods can merely capture the pairwise relation information within items and users. To effectively capture the hierarchical information, we propose a novel hierarchical hypergraph neural network to model the hierarchical architecture. Moreover, considering that the items in sessions are sequentially ordered, while the hypergraph can only model the set relation, we propose a directed graph aggregator (DGA) to aggregate the sequential information from the directed global item graph. By attentively combining the embeddings of the above two modules, we propose a framework dubbed H3GNN (Hybrid Hierarchical HyperGraph Neural Network). Extensive experiments on three benchmark datasets demonstrate the superiority of our proposed model compared to the state-of-the-art methods, and ablation experiment results validate the effectiveness of all the proposed components.}
}


@article{DBLP:journals/tois/YuanYYHY24,
	author = {Wei Yuan and
                  Shilong Yuan and
                  Chaoqun Yang and
                  Nguyen Quoc Viet Hung and
                  Hongzhi Yin},
	title = {Manipulating Visually Aware Federated Recommender Systems and Its
                  Countermeasures},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {64:1--64:26},
	year = {2024},
	url = {https://doi.org/10.1145/3630005},
	doi = {10.1145/3630005},
	timestamp = {Sun, 09 Feb 2025 10:51:29 +0100},
	biburl = {https://dblp.org/rec/journals/tois/YuanYYHY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated recommender systems (FedRecs) have been widely explored recently due to their capability to safeguard user data privacy. These systems enable a central server to collaboratively learn recommendation models by sharing public parameters with clients, providing privacy-preserving solutions. However, this collaborative approach also creates a vulnerability that allows adversaries to manipulate FedRecs. Existing works on FedRec security already reveal that items can easily be promoted by malicious users via model poisoning attacks, but all of them mainly focus on FedRecs with only collaborative information (i.e., user–item interactions). We contend that these attacks are effective primarily due to the data sparsity of collaborative signals. In light of this, we propose a method to address data sparsity and model poisoning threats by incorporating product visual information. Intriguingly, our empirical findings demonstrate that the inclusion of visual information renders all existing model poisoning attacks ineffective. Nevertheless, the integration of visual information also introduces a new avenue for adversaries to manipulate federated recommender systems, as this information typically originates from external sources. To assess such threats, we propose a novel form of poisoning attack tailored for visually aware FedRecs, namely image poisoning attacks, where adversaries can gradually modify the uploaded image with human-unaware perturbations to manipulate item ranks during the FedRecs’ training process. Moreover, we provide empirical evidence showcasing a heightened threat when image poisoning attacks are combined with model poisoning attacks, resulting in easier manipulation of the federated recommendation systems. To ensure the safe utilization of visual information, we employ a diffusion model in visually aware FedRecs to purify each uploaded image and detect the adversarial images. Extensive experiments conducted with two FedRecs on two datasets demonstrate the effectiveness and generalization of our proposed attacks and defenses.}
}


@article{DBLP:journals/tois/ChoiCAC24,
	author = {Bogeum Choi and
                  Sarah Casteel and
                  Jaime Arguello and
                  Robert Capra},
	title = {Better Understanding Procedural Search Tasks: Perceptions, Behaviors,
                  and Challenges},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {65:1--65:32},
	year = {2024},
	url = {https://doi.org/10.1145/3630004},
	doi = {10.1145/3630004},
	timestamp = {Thu, 04 Jul 2024 22:03:09 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ChoiCAC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {People often search for information to acquire procedural knowledge–“how to” knowledge about step-by-step procedures, methods, algorithms, techniques, heuristics, and skills. A procedural search task might involve implementing a solution to a problem, evaluating different approaches to a problem, and brainstorming on the types of problems that can be solved with a specific resource. We report on a study ( N =36) that aimed to better understand how people search for procedural knowledge. Much research has investigated how search task characteristics impact people’s perceptions and behaviors. Along these lines, we manipulated procedural search tasks along two orthogonal dimensions: product and goal. The product dimension relates to the main outcome of the task and the goal dimension relates to task’s success criteria. We manipulated tasks across three product categories and two goal categories. The study investigated four research questions. First, we examined the effects of the product and goal on participants’ (RQ1) pre-task perceptions, (RQ2) post-task perceptions, and (RQ3) search behaviors. Second, regardless of the task product and goal, by analyzing participants’ think-aloud comments and screen activities we closely examined how people search for procedural knowledge. Specifically, we report on (RQ4) important relevance criteria, types of information sought, and challenges.}
}


@article{DBLP:journals/tois/LiSL24,
	author = {Zihao Li and
                  Aixin Sun and
                  Chenliang Li},
	title = {DiffuRec: {A} Diffusion Model for Sequential Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {66:1--66:28},
	year = {2024},
	url = {https://doi.org/10.1145/3631116},
	doi = {10.1145/3631116},
	timestamp = {Tue, 16 Jul 2024 11:14:00 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LiSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mainstream solutions to sequential recommendation represent items with fixed vectors. These vectors have limited capability in capturing items’ latent aspects and users’ diverse preferences. As a new generative paradigm,  diffusion models  have achieved excellent performance in areas like computer vision and natural language processing. To our understanding, its unique merit in representation generation well fits the problem setting of sequential recommendation. In this article, we make the very first attempt to adapt the diffusion model to sequential recommendation and propose  DiffuRec  for item representation construction and uncertainty injection. Rather than modeling item representations as fixed vectors, we represent them as distributions in  DiffuRec , which reflect a user’s multiple interests and an item’s various aspects adaptively. In the diffusion phase,  DiffuRec  corrupts the target item embedding into a Gaussian distribution via noise adding, which is further applied for sequential item distribution representation generation and uncertainty injection. Afterward, the item representation is fed into an approximator for target item representation reconstruction. In the reverse phase, based on a user’s historical interaction behaviors, we reverse a Gaussian noise into the target item representation, then apply a rounding operation for target item prediction. Experiments over four datasets show that  DiffuRec  outperforms strong baselines by a large margin.}
}


@article{DBLP:journals/tois/NiXPWWC24,
	author = {Xuelian Ni and
                  Fei Xiong and
                  Shirui Pan and
                  Jia Wu and
                  Liang Wang and
                  Hongshu Chen},
	title = {Community Preserving Social Recommendation with Cyclic Transfer Learning},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {67:1--67:36},
	year = {2024},
	url = {https://doi.org/10.1145/3631115},
	doi = {10.1145/3631115},
	timestamp = {Thu, 04 Jul 2024 22:03:09 +0200},
	biburl = {https://dblp.org/rec/journals/tois/NiXPWWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transfer learning-based recommendation mitigates the sparsity of user-item interactions by introducing auxiliary domains. Social influence extracted from direct connections between users typically serves as an auxiliary domain to improve prediction performance. However, direct social connections also face severe data sparsity problems that limit model performance. In contrast, users’ dependency on communities is another valuable social information that has not yet received sufficient attention. Although studies have incorporated community information into recommendation by aggregating users’ preferences within the same community, they seldom capture the structural discrepancies among communities and the influence of structural discrepancies on users’ preferences. To address these challenges, we propose a community-preserving recommendation framework with cyclic transfer learning, incorporating heterogeneous community influence into the rating domain. We analyze the characteristics of the community domain and its inter-influence on the rating domain, and construct link constraints and preference constraints in the community domain. The shared vectors that bridge the rating domain and the community domain are allowed to be more consistent with the characteristics of both domains. Extensive experiments are conducted on four real-world datasets. The results manifest the excellent performance of our approach in capturing real users’ preferences compared with other state-of-the-art methods.}
}


@article{DBLP:journals/tois/ZhangXMLLL24,
	author = {Xiaokun Zhang and
                  Bo Xu and
                  Fenglong Ma and
                  Chenliang Li and
                  Yuan Lin and
                  Hongfei Lin},
	title = {Bi-preference Learning Heterogeneous Hypergraph Networks for Session-based
                  Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {68:1--68:28},
	year = {2024},
	url = {https://doi.org/10.1145/3631940},
	doi = {10.1145/3631940},
	timestamp = {Thu, 13 Feb 2025 18:39:09 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangXMLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Session-based recommendation intends to predict next purchased items based on anonymous behavior sequences. Numerous economic studies have revealed that item price is a key factor influencing user purchase decisions. Unfortunately, existing methods for session-based recommendation only aim at capturing user interest preference, while ignoring user price preference. Actually, there are primarily two challenges preventing us from accessing price preference. First, the price preference is highly associated to various item features (i.e., category and brand), which asks us to mine price preference from heterogeneous information. Second, price preference and interest preference are interdependent and collectively determine user choice, necessitating that we jointly consider both price and interest preference for intent modeling. To handle above challenges, we propose a novel approach Bi-Preference Learning Heterogeneous Hypergraph Networks (BiPNet) for session-based recommendation. Specifically, the customized heterogeneous hypergraph networks with a triple-level convolution are devised to capture user price and interest preference from heterogeneous features of items. Besides, we develop a Bi-Preference Learning schema to explore mutual relations between price and interest preference and collectively learn these two preferences under the multi-task learning architecture. Extensive experiments on multiple public datasets confirm the superiority of BiPNet over competitive baselines. Additional research also supports the notion that the price is crucial for the task.}
}


@article{DBLP:journals/tois/Giner24,
	author = {Fernando Giner},
	title = {Information Retrieval Evaluation Measures Defined on Some Axiomatic
                  Models of Preferences},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {69:1--69:35},
	year = {2024},
	url = {https://doi.org/10.1145/3632171},
	doi = {10.1145/3632171},
	timestamp = {Thu, 04 Jul 2024 22:03:09 +0200},
	biburl = {https://dblp.org/rec/journals/tois/Giner24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information retrieval (IR) evaluation measures are essential for capturing the relevance of documents to topics and determining the task performance efficiency of retrieval systems. The study of IR evaluation measures through their formal properties enables a better understanding of their suitability for a specific task. Some works have modeled the effectiveness of retrieval measures with axioms, heuristics, or desirable properties, leading to order relationships on the set where they are defined. Each of these ordering structures constitutes an axiomatic model of preferences (AMP), which can be considered as an “ideal” scenario of retrieval. Based on lattice theory and on the representational theory of measurement, this work formally explores numeric, metric, and scale properties of some effectiveness measures defined on AMPs. In some of these scenarios, retrieval measures are completely determined from the scores of a subset of document rankings: join-irreducible elements. All the possible metrics and pseudometrics, defined on these structures are expressed in terms of the join-irreducible elements. The deduced scale properties of the precision, recall,  F -measure,  RBP ,  DCG , and  AP  confirm some recent results in the IR field.}
}


@article{DBLP:journals/tois/ZhangSZZAX24,
	author = {Yuting Zhang and
                  Ying Sun and
                  Fuzhen Zhuang and
                  Yongchun Zhu and
                  Zhulin An and
                  Yongjun Xu},
	title = {Triple Dual Learning for Opinion-based Explainable Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {70:1--70:27},
	year = {2024},
	url = {https://doi.org/10.1145/3631521},
	doi = {10.1145/3631521},
	timestamp = {Tue, 04 Feb 2025 14:47:54 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangSZZAX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, with the aim of enhancing the trustworthiness of recommender systems, explainable recommendation has attracted much attention from the research community. Intuitively, users’ opinions toward different aspects of an item determine their ratings (i.e., users’ preferences) for the item. Therefore, rating prediction from the perspective of opinions can realize personalized explanations at the level of item aspects and user preferences. However, there are several challenges in developing an opinion-based explainable recommendation: (1) The complicated relationship between users’ opinions and ratings. (2) The difficulty of predicting the potential (i.e., unseen) user-item opinions because of the sparsity of opinion information. To tackle these challenges, we propose an  overall preference-aware opinion-based explainable rating prediction  model by jointly modeling the multiple observations of user-item interaction (i.e., review, opinion, rating). To alleviate the sparsity problem and raise the effectiveness of opinion prediction, we further propose a  triple dual learning-based framework with a novelly designed triple dual constraint . Finally, experiments on three popular datasets show the effectiveness and great explanation performance of our framework.}
}


@article{DBLP:journals/tois/ZhangWXWLL24,
	author = {Yitao Zhang and
                  Changxuan Wan and
                  Keli Xiao and
                  Qizhi Wan and
                  Dexi Liu and
                  Xiping Liu},
	title = {rHDP: An Aspect Sharing-Enhanced Hierarchical Topic Model for Multi-Domain
                  Corpus},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {71:1--71:31},
	year = {2024},
	url = {https://doi.org/10.1145/3631352},
	doi = {10.1145/3631352},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ZhangWXWLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learning topic hierarchies from a multi-domain corpus is crucial in topic modeling as it reveals valuable structural information embedded within documents. Despite the extensive literature on hierarchical topic models, effectively discovering inter-topic correlations and differences among subtopics at the same level in the topic hierarchy, obtained from multiple domains, remains an unresolved challenge. This article proposes an enhanced nested Chinese restaurant process (nCRP), nCRP+, by introducing an additional mechanism based on Chinese restaurant franchise (CRF) for aspect-sharing pattern extraction in the original nCRP. Subsequently, by employing the distribution extracted from nCRP+ as the prior distribution for topic hierarchy in the hierarchical Dirichlet processes (HDP), we develop a hierarchical topic model for multi-domain corpus, named rHDP. We describe the model with the analogy of Chinese restaurant franchise based on the central kitchen and propose a hierarchical Gibbs sampling scheme to infer the model. Our method effectively constructs well-established topic hierarchies, accurately reflecting diverse parent-child topic relationships, explicit topic aspect sharing correlations for inter-topics, and differences between these shared topics. To validate the efficacy of our approach, we conduct experiments using a renowned public dataset and an online collection of Chinese financial documents. The experimental results confirm the superiority of our method over the state-of-the-art techniques in identifying multi-domain topic hierarchies, according to multiple evaluation metrics.}
}


@article{DBLP:journals/tois/HuLXLTX24,
	author = {Kaixi Hu and
                  Lin Li and
                  Qing Xie and
                  Jianquan Liu and
                  Xiaohui Tao and
                  Guandong Xu},
	title = {Decoupled Progressive Distillation for Sequential Prediction with
                  Interaction Dynamics},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {72:1--72:35},
	year = {2024},
	url = {https://doi.org/10.1145/3632403},
	doi = {10.1145/3632403},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/HuLXLTX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential prediction has great value for resource allocation due to its capability in analyzing intents for next prediction. A fundamental challenge arises from real-world interaction dynamics where similar sequences involving multiple intents may exhibit different next items. More importantly, the character of volume candidate items in sequential prediction may amplify such dynamics, making deep networks hard to capture comprehensive intents. This article presents a sequential prediction framework with Decoupled Progressive Distillation (DePoD), drawing on the progressive nature of human cognition. We redefine target and non-target item distillation according to their different effects in the decoupled formulation. This can be achieved through two aspects: (1) Regarding how to learn, our target item distillation with progressive difficulty increases the contribution of low-confidence samples in the later training phase while keeping high-confidence samples in the earlier phase. And, the non-target item distillation starts from a small subset of non-target items from which size increases according to the item frequency. (2) Regarding whom to learn from, a difference evaluator is utilized to progressively select an expert that provides informative knowledge among items from the cohort of peers. Extensive experiments on four public datasets show DePoD outperforms state-of-the-art methods in terms of accuracy-based metrics.}
}


@article{DBLP:journals/tois/StevensonH24,
	author = {Mark Stevenson and
                  Reem Bin Hezam},
	title = {Stopping Methods for Technology-assisted Reviews Based on Point Processes},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {73:1--73:37},
	year = {2024},
	url = {https://doi.org/10.1145/3631990},
	doi = {10.1145/3631990},
	timestamp = {Wed, 14 May 2025 22:16:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/StevensonH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Technology-assisted Review (TAR), which aims to reduce the effort required to screen collections of documents for relevance, is used to develop systematic reviews of medical evidence and identify documents that must be disclosed in response to legal proceedings. Stopping methods are algorithms that determine when to stop screening documents during the TAR process, helping to ensure that workload is minimised while still achieving a high level of recall. This article proposes a novel stopping method based on point processes, which are statistical models that can be used to represent the occurrence of random events. The approach uses rate functions to model the occurrence of relevant documents in the ranking and compares four candidates, including one that has not previously been used for this purpose (hyperbolic). Evaluation is carried out using standard datasets (CLEF e-Health, TREC Total Recall, TREC Legal), and this work is the first to explore stopping method robustness by reporting performance on a range of rankings of varying effectiveness. Results show that the proposed method achieves the desired level of recall without requiring an excessive number of documents to be examined in the majority of cases and also compares well against multiple alternative approaches.}
}


@article{DBLP:journals/tois/MeiMHTCW24,
	author = {Lang Mei and
                  Jiaxin Mao and
                  Juan Hu and
                  Naiqiang Tan and
                  Hua Chai and
                  Ji{-}Rong Wen},
	title = {Improving First-stage Retrieval of Point-of-interest Search by Pre-training
                  Models},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {74:1--74:27},
	year = {2024},
	url = {https://doi.org/10.1145/3631937},
	doi = {10.1145/3631937},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/MeiMHTCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Point-of-interest (POI) search is important for location-based services, such as navigation and online ride-hailing service. The goal of POI search is to find the most relevant destinations from a large-scale POI database given a text query. To improve the effectiveness and efficiency of POI search, most existing approaches are based on a multi-stage pipeline that consists of an efficiency-oriented retrieval stage and one or more effectiveness-oriented re-rank stages. In this article, we focus on the first efficiency-oriented retrieval stage of the POI search. We first identify the limitations of existing first-stage POI retrieval models in capturing the semantic-geography relationship and modeling the fine-grained geographical context information. Then, we propose a Geo-Enhanced Dense Retrieval framework for POI search to alleviate the above problems. Specifically, the proposed framework leverages the capacity of pre-trained language models (e.g., BERT) and designs a pre-training approach to better model the semantic match between the query prefix and POIs. With the POI collection, we first perform a token-level pre-training task based on a geographical-sensitive masked language prediction and design two retrieval-oriented pre-training tasks that link the address of each POI to its name and geo-location. With the user behavior logs collected from an online POI search system, we design two additional pre-training tasks based on users’ query reformulation behavior and the transitions between POIs. We also utilize a late-interaction network structure to model the fine-grained interactions between the text and geographical context information within an acceptable query latency. Extensive experiments on the real-world datasets collected from the Didichuxing application demonstrate that the proposed framework can achieve superior retrieval performance over existing first-stage POI retrieval methods.}
}


@article{DBLP:journals/tois/WuNCH24,
	author = {Jiaxin Wu and
                  Chong{-}Wah Ngo and
                  Wing{-}Kwong Chan and
                  Zhijian Hou},
	title = {(Un)likelihood Training for Interpretable Embedding},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {75:1--75:26},
	year = {2024},
	url = {https://doi.org/10.1145/3632752},
	doi = {10.1145/3632752},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WuNCH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-modal representation learning has become a new normal for bridging the semantic gap between text and visual data. Learning modality agnostic representations in a continuous latent space, however, is often treated as a black-box data-driven training process. It is well known that the effectiveness of representation learning depends heavily on the quality and scale of training data. For video representation learning, having a complete set of labels that annotate the full spectrum of video content for training is highly difficult, if not impossible. These issues, black-box training and dataset bias, make representation learning practically challenging to be deployed for video understanding due to unexplainable and unpredictable results. In this article, we propose two novel training objectives, likelihood and unlikelihood functions, to unroll the semantics behind embeddings while addressing the label sparsity problem in training. The likelihood training aims to interpret semantics of embeddings beyond training labels, while the unlikelihood training leverages prior knowledge for regularization to ensure semantically coherent interpretation. With both training objectives, a new encoder-decoder network, which learns interpretable cross-modal representation, is proposed for ad-hoc video search. Extensive experiments on TRECVid and MSR-VTT datasets show that the proposed network outperforms several state-of-the-art retrieval models with a statistically significant performance margin.}
}


@article{DBLP:journals/tois/ZangZZWWY24,
	author = {Tianzi Zang and
                  Yanmin Zhu and
                  Ruohan Zhang and
                  Chunyang Wang and
                  Ke Wang and
                  Jiadi Yu},
	title = {Contrastive Multi-view Interest Learning for Cross-domain Sequential
                  Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {76:1--76:30},
	year = {2024},
	url = {https://doi.org/10.1145/3632402},
	doi = {10.1145/3632402},
	timestamp = {Tue, 25 Mar 2025 14:42:32 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZangZZWWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-domain recommendation (CDR), which leverages information collected from other domains, has been empirically demonstrated to effectively alleviate data sparsity and cold-start problems encountered in traditional recommendation systems. However, current CDR methods, including those considering time information, do not jointly model the general and current interests within and across domains, which is pivotal for accurately predicting users’ future interactions. In this article, we propose a Contrastive learning-enhanced Multi-View interest learning model (CMVCDR) for cross-domain sequential recommendation. Specifically, we design a static view and a sequential view to model uses’ general interests and current interests, respectively. We divide a user’s general interest representation into a domain-invariant part and a domain-specific part. A cross-domain contrastive learning objective is introduced to impose constraints for optimizing these representations. In the sequential view, we first devise an attention mechanism guided by users’ domain-invariant interest representations to distill cross-domain knowledge pertaining to domain-invariant factors while reducing noise from irrelevant factors. We further design a domain-specific interest-guided temporal information aggregation mechanism to generate users’ current interest representations. Extensive experiments demonstrate the effectiveness of our proposed model compared with state-of-the-art methods.}
}


@article{DBLP:journals/tois/KrasakisYK24,
	author = {Antonios Minas Krasakis and
                  Andrew Yates and
                  Evangelos Kanoulas},
	title = {Contextualizing and Expanding Conversational Queries without Supervision},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {77:1--77:30},
	year = {2024},
	url = {https://doi.org/10.1145/3632622},
	doi = {10.1145/3632622},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/KrasakisYK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most conversational passage retrieval systems try to resolve conversational dependencies by using an intermediate query resolution step. To do so, they synthesize conversational data or assume the availability of large-scale question rewriting datasets. To relax those conditions, we propose a zero-shot unified resolution–retrieval approach, that (i) contextualizes and (ii) expands query embeddings using the conversation history and without fine-tuning on conversational data. Contextualization biases the last user question embeddings towards the conversation. Query expansion is used in two ways: (i) abstractive expansion generates embeddings based on the current question and previous history, whereas (ii) extractive expansion tries to identify history term embeddings based on attention weights from the retriever. Our experiments demonstrate the effectiveness of both contextualization and unified expansion in improving conversational retrieval. Contextualization does so mostly by resolving anaphoras to the conversation and bringing their embeddings closer to the important resolution terms that were omitted. By adding embeddings to the query, expansion targets phenomena of ellipsis more explicitly, with our analysis verifying its effectiveness on identifying and adding important resolutions to the query. By combining contextualization and expansion, we find that our zero-shot unified resolution–retrieval methods are competitive and can even outperform supervised methods.}
}


@article{DBLP:journals/tois/CuiYZMMRZK24,
	author = {Chaoran Cui and
                  Yumo Yao and
                  Chunyun Zhang and
                  Hebo Ma and
                  Yuling Ma and
                  Zhaochun Ren and
                  Chen Zhang and
                  James Ko},
	title = {{DGEKT:} {A} Dual Graph Ensemble Learning Method for Knowledge Tracing},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {78:1--78:24},
	year = {2024},
	url = {https://doi.org/10.1145/3638350},
	doi = {10.1145/3638350},
	timestamp = {Mon, 04 Nov 2024 08:18:05 +0100},
	biburl = {https://dblp.org/rec/journals/tois/CuiYZMMRZK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge tracing aims to trace students’ evolving knowledge states by predicting their future performance on concept-related exercises. Recently, some graph-based models have been developed to incorporate the relationships between exercises to improve knowledge tracing, but only a single type of relationship information is generally explored. In this article, we present a novel Dual Graph Ensemble learning method for Knowledge Tracing (DGEKT), which establishes a dual graph structure of students’ learning interactions to capture the heterogeneous exercise–concept associations and interaction transitions by hypergraph modeling and directed graph modeling, respectively. To combine the dual graph models, we introduce the technique of online knowledge distillation. This choice arises from the observation that, while the knowledge tracing model is designed to predict students’ responses to the exercises related to different concepts, it is optimized merely with respect to the prediction accuracy on a single exercise at each step. With online knowledge distillation, the dual graph models are adaptively combined to form a stronger ensemble teacher model, which provides its predictions on all exercises as extra supervision for better modeling ability. In the experiments, we compare DGEKT against eight knowledge tracing baselines on three benchmark datasets, and the results demonstrate that DGEKT achieves state-of-the-art performance.}
}


@article{DBLP:journals/tois/MichalkovaPM24,
	author = {Dominika Michalkova and
                  Mario Parra{-}Rodriguez and
                  Yashar Moshfeghi},
	title = {Understanding Feeling-of-Knowing in Information Search: An {EEG} Study},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {79:1--79:30},
	year = {2024},
	url = {https://doi.org/10.1145/3611384},
	doi = {10.1145/3611384},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/MichalkovaPM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The realisation and the variability of information needs (IN) with respect to a searcher’s gap in knowledge is driven by the perceived Anomalous State of Knowledge (ASK). The concept of Feeling-of-Knowing (FOK), as the introspective feeling of knowledge awareness, shares the characteristics of an ASK state. From an IR perspective, FOK as a premise to trigger IN is unexplored. Motivated by the neuroimaging studies in IR, we investigate the neurophysiological drivers associated with FOK, to provide evidence validating FOK as a distinctive state in IN realisation. We employ Electroencephalography to capture the brain activity of 24 healthy participants performing a textual Question Answering IR scenario. We analyse the evoked neural patterns corresponding to three states of knowledge: i.e., (1)“I know”, (2)“FOK”, (3)“I do not know”. Our findings show the distinct neurophysiological signatures (N1, P2, N400, P6) in response to information segments processed in the context of our three levels. They further reveal that the brain manifestation associated with “FOK” does not significantly differ from the ones associated with “I do not know”, indicating their association with recognition of a gap in knowledge and as such could further inform the IN formation on different levels of knowing.}
}


@article{DBLP:journals/tois/ZhangMZWC24,
	author = {An Zhang and
                  Wenchang Ma and
                  Jingnan Zheng and
                  Xiang Wang and
                  Tat{-}Seng Chua},
	title = {Robust Collaborative Filtering to Popularity Distribution Shift},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {80:1--80:25},
	year = {2024},
	url = {https://doi.org/10.1145/3627159},
	doi = {10.1145/3627159},
	timestamp = {Wed, 19 Jun 2024 22:22:30 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ZhangMZWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In leading collaborative filtering (CF) models, representations of users and items are prone to learn popularity bias in the training data as shortcuts. The popularity shortcut tricks are good for in-distribution (ID) performance but poorly generalized to out-of-distribution (OOD) data, i.e., when popularity distribution of test data shifts w.r.t. the training one. To close the gap, debiasing strategies try to assess the shortcut degrees and mitigate them from the representations. However, there exist two deficiencies: (1)\xa0when measuring the shortcut degrees, most strategies only use statistical metrics on a single aspect (i.e., item frequency on item and user frequency on user aspect), failing to accommodate the compositional degree of a user–item pair; (2)\xa0when mitigating shortcuts, many strategies assume that the test distribution is known in advance. This results in low-quality debiased representations. Worse still, these strategies achieve OOD generalizability with a sacrifice on ID performance. In this work, we present a simple yet effective debiasing strategy,  PopGo , which quantifies and reduces the interaction-wise popularity shortcut without any assumptions on the test data. It first learns a shortcut model, which yields a shortcut degree of a user–item pair based on their popularity representations. Then, it trains the CF model by adjusting the predictions with the interaction-wise shortcut degrees. By taking both causal- and information-theoretical looks at PopGo, we can justify why it encourages the CF model to capture the critical popularity-agnostic features while leaving the spurious popularity-relevant patterns out. We use PopGo to debias two high-performing CF models (matrix factorization\xa0[ 28 ] and LightGCN\xa0[ 19 ]) on four benchmark datasets. On both ID and OOD test sets, PopGo achieves significant gains over the state-of-the-art debiasing strategies (e.g., DICE\xa0[ 71 ] and MACR\xa0[ 58 ]). Codes and datasets are available at  https://github.com/anzhang314/PopGo .}
}


@article{DBLP:journals/tois/WangDLZW24,
	author = {Shuting Wang and
                  Zhicheng Dou and
                  Jiongnan Liu and
                  Qiannan Zhu and
                  Ji{-}Rong Wen},
	title = {Personalized and Diversified: Ranking Search Results in an Integrated
                  Way},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {81:1--81:25},
	year = {2024},
	url = {https://doi.org/10.1145/3631989},
	doi = {10.1145/3631989},
	timestamp = {Mon, 29 Jul 2024 09:05:35 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WangDLZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ambiguity in queries is a common problem in information retrieval. There are currently two solutions: search result personalization and diversification. The former aims to tailor results for different users based on their preferences, but the limitations are redundant results and incomplete capture of user intents. The goal of the latter is to return results that cover as many aspects related to the query as possible. It improves diversity yet loses personality and cannot return the exact results the user wants. Intuitively, such two solutions can complement each other and bring more satisfactory reranking results. In this article, we propose a novel framework, namely,  PnD , to integrate personalization and diversification reasonably. We employ the degree of refinding to determine the weight of personalization dynamically. Moreover, to improve the diversity and relevance of reranked results simultaneously, we design a reset RNN structure (RRNN) with the “reset gate” to measure the influence of the newly selected document on novelty. Besides, we devise a “subtopic learning layer” to learn the virtual subtopics, which can yield fine-grained representations of queries, documents, and user profiles. Experimental results illustrate that our model can significantly outperform existing search result personalization and diversification methods.}
}


@article{DBLP:journals/tois/FuWGLLJ24,
	author = {Wenjie Fu and
                  Huandong Wang and
                  Chen Gao and
                  Guanghua Liu and
                  Yong Li and
                  Tao Jiang},
	title = {Privacy-Preserving Individual-Level {COVID-19} Infection Prediction
                  via Federated Graph Learning},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {82:1--82:29},
	year = {2024},
	url = {https://doi.org/10.1145/3633202},
	doi = {10.1145/3633202},
	timestamp = {Sun, 19 Jan 2025 15:03:41 +0100},
	biburl = {https://dblp.org/rec/journals/tois/FuWGLLJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurately predicting individual-level infection state is of great value since its essential role in reducing the damage of the epidemic. However, there exists an inescapable risk of privacy leakage in the fine-grained user mobility trajectories required by individual-level infection prediction. In this article, we focus on developing a framework of privacy-preserving individual-level infection prediction based on federated learning (FL) and graph neural networks (GNN). We propose  Falcon , a  F ederated gr A ph  L earning method for privacy-preserving individual-level infe C tion predicti ON . It utilizes a novel hypergraph structure with spatio-temporal hyperedges to describe the complex interactions between individuals and locations in the contagion process. By organically combining the FL framework with hypergraph neural networks, the information propagation process of the graph machine learning is able to be divided into two stages distributed on the server and the clients, respectively, so as to effectively protect user privacy while transmitting high-level information. Furthermore, it elaborately designs a differential privacy perturbation mechanism as well as a plausible pseudo location generation approach to preserve user privacy in the graph structure. Besides, it introduces a cooperative coupling mechanism between the individual-level prediction model and an additional region-level model to mitigate the detrimental impacts caused by the injected obfuscation mechanisms. Extensive experimental results show that our methodology outperforms state-of-the-art algorithms and is able to protect user privacy against actual privacy attacks. Our code and datasets are available at the link:  https://github.com/wjfu99/FL-epidemic .}
}


@article{DBLP:journals/tois/SuLDZLS24,
	author = {Hongzu Su and
                  Jingjing Li and
                  Zhekai Du and
                  Lei Zhu and
                  Ke Lu and
                  Heng Tao Shen},
	title = {Cross-domain Recommendation via Dual Adversarial Adaptation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {83:1--83:26},
	year = {2024},
	url = {https://doi.org/10.1145/3632524},
	doi = {10.1145/3632524},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/SuLDZLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data scarcity is a perpetual challenge of recommendation systems, and researchers have proposed a variety of cross-domain recommendation methods to alleviate the problem of data scarcity in target domains. However, in many real-world cross-domain recommendation systems, the source domain and the target domain are sampled from different data distributions, which obstructs the cross-domain knowledge transfer. In this article, we propose to specifically align the data distributions between the source domain and the target domain to alleviate imbalanced sample distribution and thus challenge the data scarcity issue in the target domain. Technically, our proposed approach builds a dual adversarial adaptation (DAA) framework to adversarially train the target model together with a pre-trained source model. Two domain discriminators play the two-player minmax game with the target model and guide the target model to learn reliable domain-invariant features that can be transferred across domains. At the same time, the target model is calibrated to learn domain-specific information of the target domain. In addition, we formulate our approach as a plug-and-play module to boost existing recommendation systems. We apply the proposed method to address the issues of insufficient data and imbalanced sample distribution in real-world Click-through Rate/Conversion Rate predictions on two large-scale industrial datasets. We evaluate the proposed method in scenarios with and without overlapping users/items, and extensive experiments verify that the proposed method is able to significantly improve the prediction performance on the target domain. For instance, our method can boost PLE with a performance improvement of 15.4% in terms of Area Under Curve compared with single-domain PLE on our private game dataset. In addition, our method is able to surpass single-domain MMoE by 6.85% on the public datasets. Code:  https://github.com/TL-UESTC/DAA .}
}


@article{DBLP:journals/tois/LanCWSHM24,
	author = {Tian Lan and
                  Deng Cai and
                  Yan Wang and
                  Yixuan Su and
                  Heyan Huang and
                  Xian{-}Ling Mao},
	title = {Exploring Dense Retrieval for Dialogue Response Selection},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {84:1--84:29},
	year = {2024},
	url = {https://doi.org/10.1145/3632750},
	doi = {10.1145/3632750},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LanCWSHM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent progress in deep learning has continuously improved the accuracy of dialogue response selection. However, in real-world scenarios, the high computation cost forces existing dialogue response selection models to rank only a small number of candidates, recalled by a coarse-grained model, precluding many high-quality candidates. To overcome this problem, we present a novel and efficient response selection model and a set of tailor-designed learning strategies to train it effectively. The proposed model consists of a dense retrieval module and an interaction layer, which could directly select the proper response from a large corpus. We conduct re-rank and full-rank evaluations on widely used benchmarks to evaluate our proposed model. Extensive experimental results demonstrate that our proposed model notably outperforms the state-of-the-art baselines on both re-rank and full-rank evaluations. Moreover, human evaluation results show that the response quality could be improved further by enlarging the candidate pool with nonparallel corpora. In addition, we also release high-quality benchmarks that are carefully annotated for more accurate dialogue response selection evaluation. All source codes, datasets, model parameters, and other related resources have been publicly available.}
}


@article{DBLP:journals/tois/PengSM24,
	author = {Shaowen Peng and
                  Kazunari Sugiyama and
                  Tsunenori Mine},
	title = {Less is More: Removing Redundancy of Graph Convolutional Networks
                  for Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {85:1--85:26},
	year = {2024},
	url = {https://doi.org/10.1145/3632751},
	doi = {10.1145/3632751},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/PengSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While Graph Convolutional Networks (GCNs) have shown great potential in recommender systems and collaborative filtering (CF), they suffer from expensive computational complexity and poor scalability. On top of that, recent works mostly combine GCNs with other advanced algorithms which further sacrifice model efficiency and scalability. In this work, we unveil the redundancy of existing GCN-based methods in three aspects: (1)  Feature redundancy . By reviewing GCNs from a spectral perspective, we show that most spectral graph features are noisy for recommendation, while stacking graph convolution layers can suppress but cannot completely remove the noisy features, which we mostly summarize from our previous work; (2)  Structure redundancy . By providing a deep insight into how user/item representations are generated, we show that what makes them distinctive lies in the spectral graph features, while the core idea of GCNs (i.e., neighborhood aggregation) is not the reason making GCNs effective; and (3)  Distribution redundancy . Following observations from (1), we further show that the number of required spectral features is closely related to the spectral distribution, where important information tends to be concentrated in more (fewer) spectral features on a flatter (sharper) distribution. To make important information be concentrated in as few features as possible, we sharpen the spectral distribution by increasing the node similarity without changing the original data, thereby reducing the computational cost. To remove these three kinds of redundancies, we propose a Simplified Graph Denoising Encoder (SGDE) only exploiting the top- K  singular vectors without explicitly aggregating neighborhood, which significantly reduces the complexity of GCN-based methods. We further propose a scalable contrastive learning framework to alleviate data sparsity and to boost model robustness and generalization, leading to significant improvement. Extensive experiments on three real-world datasets show that our proposed SGDE not only achieves state-of-the-art but also shows higher scalability and efficiency than our previously proposed GDE as well as traditional and GCN-based CF methods.}
}


@article{DBLP:journals/tois/GaoZLZWGLY24,
	author = {Jingtong Gao and
                  Xiangyu Zhao and
                  Muyang Li and
                  Minghao Zhao and
                  Runze Wu and
                  Ruocheng Guo and
                  Yiding Liu and
                  Dawei Yin},
	title = {SMLP4Rec: An Efficient All-MLP Architecture for Sequential Recommendations},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {86:1--86:23},
	year = {2024},
	url = {https://doi.org/10.1145/3637871},
	doi = {10.1145/3637871},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/GaoZLZWGLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-attention models have achieved the state-of-the-art performance in sequential recommender systems by capturing the sequential dependencies among user–item interactions. However, they rely on adding positional embeddings to the item sequence to retain the sequential information, which may break the semantics of item embeddings due to the heterogeneity between these two types of embeddings. In addition, most existing works assume that such dependencies exist solely in the item embeddings, but neglect their existence among the item features. In our previous study, we proposed a novel sequential recommendation model, i.e., MLP4Rec, based on the recent advances of MLP-Mixer architectures, which is naturally sensitive to the order of items in a sequence because matrix elements related to different positions of a sequence will be given different weights in training. We developed a tri-directional fusion scheme to coherently capture sequential, cross-channel, and cross-feature correlations with linear computational complexity as well as much fewer model parameters than existing self-attention methods. However, the cascading mixer structure, the large number of normalization layers between different mixer layers, and the noise generated by these operations limit the efficiency of information extraction and the effectiveness of MLP4Rec. In this extended version, we propose a novel framework – SMLP4Rec for sequential recommendation to address the aforementioned issues. The new framework changes the flawed cascading structure to a parallel mode, and integrates normalization layers to minimize their impact on the model’s efficiency while maximizing their effectiveness. As a result, the training speed and prediction accuracy of SMLP4Rec are vastly improved in comparison to MLP4Rec. Extensive experimental results demonstrate that the proposed method is significantly superior to the state-of-the-art approaches. The implementation code is available online to ease reproducibility.}
}


@article{DBLP:journals/tois/XuHSD24,
	author = {Jiechen Xu and
                  Lei Han and
                  Shazia Sadiq and
                  Gianluca Demartini},
	title = {On the Impact of Showing Evidence from Peers in Crowdsourced Truthfulness
                  Assessments},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {3},
	pages = {87:1--87:26},
	year = {2024},
	url = {https://doi.org/10.1145/3637872},
	doi = {10.1145/3637872},
	timestamp = {Mon, 27 Jan 2025 20:03:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/XuHSD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Misinformation has been rapidly spreading online. The common approach to dealing with it is deploying expert fact-checkers who follow forensic processes to identify the veracity of statements. Unfortunately, such an approach does not scale well. To deal with this, crowdsourcing has been looked at as an opportunity to complement the work done by trained journalists. In this article, we look at the effect of presenting the crowd with evidence from others while judging the veracity of statements. We implement variants of the judgment task design to understand whether and how the presented evidence may or may not affect the way crowd workers judge truthfulness and their performance. Our results show that, in certain cases, the presented evidence and the way in which it is presented may mislead crowd workers who would otherwise be more accurate if judging independently from others. Those who make appropriate use of the provided evidence, however, can benefit from it and generate better judgments.}
}


@article{DBLP:journals/tois/GaoZWFHL24,
	author = {Chen Gao and
                  Yu Zheng and
                  Wenjie Wang and
                  Fuli Feng and
                  Xiangnan He and
                  Yong Li},
	title = {Causal Inference in Recommender Systems: {A} Survey and Future Directions},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {88:1--88:32},
	year = {2024},
	url = {https://doi.org/10.1145/3639048},
	doi = {10.1145/3639048},
	timestamp = {Sat, 03 Aug 2024 16:25:29 +0200},
	biburl = {https://dblp.org/rec/journals/tois/GaoZWFHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems have become crucial in information filtering nowadays. Existing recommender systems extract user preferences based on the correlation in data, such as behavioral correlation in collaborative filtering, feature-feature, or feature-behavior correlation in click-through rate prediction. However, unfortunately, the real world is driven by  causality , not just correlation, and correlation does not imply causation. For instance, recommender systems might recommend a battery charger to a user after buying a phone, where the latter can serve as the cause of the former; such a causal relation cannot be reversed. Recently, to address this, researchers in recommender systems have begun utilizing causal inference to extract causality, thereby enhancing the recommender system. In this survey, we offer a comprehensive review of the literature on causal inference-based recommendation. Initially, we introduce the fundamental concepts of both recommender system and causal inference as the foundation for subsequent content. We then highlight the typical issues faced by non-causality recommender system. Following that, we thoroughly review the existing work on causal inference-based recommender systems, based on a taxonomy of three-aspect challenges that causal inference can address. Finally, we discuss the open problems in this critical research area and suggest important potential future works.}
}


@article{DBLP:journals/tois/ZhaoLRW24,
	author = {Wayne Xin Zhao and
                  Jing Liu and
                  Ruiyang Ren and
                  Ji{-}Rong Wen},
	title = {Dense Text Retrieval Based on Pretrained Language Models: {A} Survey},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {89:1--89:60},
	year = {2024},
	url = {https://doi.org/10.1145/3637870},
	doi = {10.1145/3637870},
	timestamp = {Sun, 19 Jan 2025 15:03:41 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhaoLRW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text retrieval is a long-standing research topic on information seeking, where a system is required to return relevant information resources to user’s queries in natural language. From heuristic-based retrieval methods to learning-based ranking functions, the underlying retrieval models have been continually evolved with the ever-lasting technical innovation. To design effective retrieval models, a key point lies in how to learn text representations and model the relevance matching. The recent success of pretrained language models\xa0(PLM) sheds light on developing more capable text-retrieval approaches by leveraging the excellent modeling capacity of PLMs. With powerful PLMs, we can effectively learn the semantic representations of queries and texts in the latent representation space, and further construct the semantic matching function between the dense vectors for relevance modeling. Such a retrieval approach is called  dense retrieval , since it employs dense vectors to represent the texts. Considering the rapid progress on dense retrieval, this survey systematically reviews the recent progress on PLM-based dense retrieval. Different from previous surveys on dense retrieval, we take a new perspective to organize the related studies by four major aspects, including architecture, training, indexing and integration, and thoroughly summarize the mainstream techniques for each aspect. We extensively collect the recent advances on this topic, and include 300+ reference papers. To support our survey, we create a website for providing useful resources, and release a code repository for dense retrieval. This survey aims to provide a comprehensive, practical reference focused on the major progress for dense text retrieval.}
}


@article{DBLP:journals/tois/ZhuQHDYYZ24,
	author = {Zhengbang Zhu and
                  Rongjun Qin and
                  Junjie Huang and
                  Xinyi Dai and
                  Yang Yu and
                  Yong Yu and
                  Weinan Zhang},
	title = {Understanding or Manipulation: Rethinking Online Performance Gains
                  of Modern Recommender Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {90:1--90:32},
	year = {2024},
	url = {https://doi.org/10.1145/3637869},
	doi = {10.1145/3637869},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ZhuQHDYYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems are expected to be assistants that help human users find relevant information automatically without explicit queries. As recommender systems evolve, increasingly sophisticated learning techniques are applied and have achieved better performance in terms of user engagement metrics such as clicks and browsing time. The increase in the measured performance, however, can have two possible attributions: a better understanding of user preferences, and a more proactive ability to utilize human bounded rationality to seduce user over-consumption. A natural following question is whether current recommendation algorithms are manipulating user preferences. If so, can we measure the manipulation level? In this article, we present a general framework for benchmarking the degree of manipulations of recommendation algorithms, in both slate recommendation and sequential recommendation scenarios. The framework consists of four stages, initial preference calculation, training data collection, algorithm training and interaction, and metrics calculation that involves two proposed metrics, Manipulation Score and Preference Shift. We benchmark some representative recommendation algorithms in both synthetic and real-world datasets under the proposed framework. We have observed that a high online click-through rate does not necessarily mean a better understanding of user initial preference, but ends in prompting users to choose more documents they initially did not favor. Moreover, we find that the training data have notable impacts on the manipulation degrees, and algorithms with more powerful modeling abilities are more sensitive to such impacts. The experiments also verified the usefulness of the proposed metrics for measuring the degree of manipulations. We advocate that future recommendation algorithm studies should be treated as an optimization problem with constrained user preference manipulations.}
}


@article{DBLP:journals/tois/MaXMCZLZ24,
	author = {Haokai Ma and
                  Ruobing Xie and
                  Lei Meng and
                  Xin Chen and
                  Xu Zhang and
                  Leyu Lin and
                  Jie Zhou},
	title = {Triple Sequence Learning for Cross-domain Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {91:1--91:29},
	year = {2024},
	url = {https://doi.org/10.1145/3638351},
	doi = {10.1145/3638351},
	timestamp = {Wed, 26 Mar 2025 18:42:01 +0100},
	biburl = {https://dblp.org/rec/journals/tois/MaXMCZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-domain recommendation (CDR) aims at leveraging the correlation of users’ behaviors in both the source and target domains to improve the user preference modeling in the target domain. Conventional CDR methods typically explore the dual-relations between the source and target domains’ behaviors. However, this may ignore the informative mixed behaviors that naturally reflect the user’s global preference. To address this issue, we present a novel framework, termed triple sequence learning for cross-domain recommendation (Tri-CDR), which jointly models the source, target, and mixed behavior sequences to highlight the global and target preference and precisely model the triple correlation in CDR. Specifically, Tri-CDR independently models the hidden representations for the triple behavior sequences and proposes a triple cross-domain attention (TCA) method to emphasize the informative knowledge related to both user’s global and target-domain preference. To comprehensively explore the cross-domain correlations, we design a triple contrastive learning (TCL) strategy that simultaneously considers the coarse-grained similarities and fine-grained distinctions among the triple sequences, ensuring the alignment while preserving information diversity in multi-domain. We conduct extensive experiments and analyses on six cross-domain settings. The significant improvements of Tri-CDR with different sequential encoders verify its effectiveness and universality. The source code is available at  https://github.com/hulkima/Tri-CDR .}
}


@article{DBLP:journals/tois/RazgallahVALSS24,
	author = {H{\'{e}}di Razgallah and
                  Michalis Vlachos and
                  Ahmad Ajalloeian and
                  Ninghao Liu and
                  Johannes Schneider and
                  Alexis Steinmann},
	title = {Using Neural and Graph Neural Recommender Systems to Overcome Choice
                  Overload: Evidence From a Music Education Platform},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {92:1--92:26},
	year = {2024},
	url = {https://doi.org/10.1145/3637873},
	doi = {10.1145/3637873},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/RazgallahVALSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The application of recommendation technologies has been crucial in the promotion of physical and digital content across numerous global platforms such as Amazon, Apple, and Netflix. Our study aims to investigate the advantages of employing recommendation technologies on educational platforms, with a particular focus on an educational platform for learning and practicing music. Our research is based on data from Tomplay, a music platform that offers sheet music with professional audio recordings, enabling users to discover and practice music content at varying levels of difficulty. Through our analysis, we emphasize the distinct interaction patterns on educational platforms like Tomplay, which we compare with other commonly used recommendation datasets. We find that interactions are comparatively sparse on educational platforms, with users often focusing on specific content as they learn, rather than interacting with a broader range of material. Therefore, our primary goal is to address the issue of data sparsity. We achieve this through entity resolution principles and propose a neural network (NN)-based recommendation model. Further, we improve this model by utilizing graph neural networks (GNNs), which provide superior predictive accuracy compared to NNs. Notably, our study demonstrates that GNNs are highly effective even for users with little or no historical preferences (cold-start problem). Our cold-start experiments also provide valuable insights into an independent issue, namely, the number of historical interactions needed by a recommendation model to gain a comprehensive understanding of a user. Our findings demonstrate that a platform acquires a solid knowledge of a user’s general preferences and characteristics with 50 past interactions. Overall, our study makes significant contributions to information systems research on business analytics and prescriptive analytics. Moreover, our framework and evaluation results offer implications for various stakeholders, including online educational institutions, education policymakers, and learning platform users.}
}


@article{DBLP:journals/tois/YeXALWSZ24,
	author = {Ziyi Ye and
                  Xiaohui Xie and
                  Qingyao Ai and
                  Yiqun Liu and
                  Zhihong Wang and
                  Weihang Su and
                  Min Zhang},
	title = {Relevance Feedback with Brain Signals},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {93:1--93:37},
	year = {2024},
	url = {https://doi.org/10.1145/3637874},
	doi = {10.1145/3637874},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/YeXALWSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Relevance Feedback\xa0(RF) process relies on accurate and real-time relevance estimation of feedback documents to improve retrieval performance. Since collecting explicit relevance annotations imposes an extra burden on the user, extensive studies have explored using pseudo-relevance signals and implicit feedback signals as substitutes. However, such signals are indirect indicators of relevance and suffer from complex search scenarios where user interactions are absent or biased. Recently, the advances in portable and high-precision brain-computer interface\xa0(BCI) devices have shown the possibility to monitor user’s brain activities during search process. Brain signals can directly reflect user’s psychological responses to search results and thus it can act as additional and unbiased RF signals. To explore the effectiveness of brain signals in the context of RF, we propose a novel RF framework that combines BCI-based RF with pseudo-relevance signals and implicit signals to improve the performance of document re-ranking. The experimental results on the user study dataset show that incorporating brain signals leads to significant performance improvement in our RF framework. Besides, we observe that brain signals perform particularly well in several hard search scenarios, especially when implicit signals as feedback are missing or noisy. This reveals when and how to exploit brain signals in the context of RF.}
}


@article{DBLP:journals/tois/ChenWZZHXX24,
	author = {Wei Chen and
                  Yiqing Wu and
                  Zhao Zhang and
                  Fuzhen Zhuang and
                  Zhongshi He and
                  Ruobing Xie and
                  Feng Xia},
	title = {FairGap: Fairness-Aware Recommendation via Generating Counterfactual
                  Graph},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {94:1--94:25},
	year = {2024},
	url = {https://doi.org/10.1145/3638352},
	doi = {10.1145/3638352},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ChenWZZHXX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of Graph Neural Networks (GNNs) has greatly advanced the development of recommendation systems. Recently, many researchers have leveraged GNN-based models to learn fair representations for users and items. However, current GNN-based models suffer from biased user–item interaction data, which negatively impacts recommendation fairness. Although there have been several studies employing adversarial learning to mitigate this issue in recommendation systems, they mostly focus on modifying the model training approach with fairness regularization and neglect direct intervention of biased interaction. In contrast to these models, this article introduces a novel perspective by directly intervening in observed interactions to generate a counterfactual graph (called FairGap) that is not influenced by sensitive node attributes, enabling us to learn fair representations for users and items easily. We design FairGap to answer the key counterfactual question: “Would interactions with an item remain unchanged if a user’s sensitive attributes were concealed?”. We also provide theoretical proofs to show that our learning strategy via the counterfactual graph is unbiased in expectation. Moreover, we propose a fairness-enhancing mechanism to continuously improve user fairness in the graph-based recommendation. Extensive experimental results against state-of-the-art competitors and base models on three real-world datasets validate the effectiveness of our proposed model.}
}


@article{DBLP:journals/tois/VuongR24,
	author = {Tung Thanh Vuong and
                  Tuukka Ruotsalo},
	title = {Predicting Representations of Information Needs from Digital Activity
                  Context},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {95:1--95:29},
	year = {2024},
	url = {https://doi.org/10.1145/3639819},
	doi = {10.1145/3639819},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/VuongR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information retrieval systems often consider search-session and immediately preceding web-browsing history as the context for predicting users’ present information needs. However, such context is only available when a user’s information needs originate from web context or when users have issued preceding queries in the search session. Here, we study the effect of more extensive context information recorded from users’ everyday digital activities by monitoring all information interacted with and communicated using personal computers. Twenty individuals were recruited for 14 days of 24/7 continuous monitoring of their digital activities, including screen contents, clicks, and operating system logs on Web and non-Web applications. Using this data, a transformer architecture is applied to model the digital activity context and predict representations of personalized information needs. Subsequently, the representations of information needs are used for query prediction, query auto-completion, selected search result prediction, and Web search re-ranking. The predictions of the models are evaluated against the ground truth data obtained from the activity recordings. The results reveal that the models accurately predict representations of information needs improving over the conventional search session and web-browsing contexts. The results indicate that the present practice for utilizing users’ contextual information is limited and can be significantly extended to achieve improved search interaction support and performance.}
}


@article{DBLP:journals/tois/BaiZDW24,
	author = {Yutong Bai and
                  Yujia Zhou and
                  Zhicheng Dou and
                  Ji{-}Rong Wen},
	title = {Intent-Oriented Dynamic Interest Modeling for Personalized Web Search},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {96:1--96:30},
	year = {2024},
	url = {https://doi.org/10.1145/3639817},
	doi = {10.1145/3639817},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/BaiZDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a user, a personalized search model relies on her historical behaviors, such as issued queries and their clicked documents, to generate an interest profile and personalize search results accordingly. In interest profiling, most existing personalized search approaches use “static” document representations as the inputs, which do not change with the current search. However, a document is usually long and contains multiple pieces of information, a static fix-length document vector is usually insufficient to represent the important information related to the original query or the current query, and makes the profile noisy and ambiguous. To tackle this problem, we propose building dynamic and intent-oriented document representations which highlight important parts of a document rather than simply encode the entire text. Specifically, we divide each document into multiple passages, and then separately use the original query and the current query to interact with the passages. Thereafter we generate two “dynamic” document representations containing the key information around the historical and the current user intent, respectively. We then profile interest by capturing the interactions between these document representations, the historical queries, and the current query. Experimental results on a real-world search log dataset demonstrate that our model significantly outperforms state-of-the-art personalization methods.}
}


@article{DBLP:journals/tois/LiuGZJGY24,
	author = {Hao Liu and
                  Lei Guo and
                  Lei Zhu and
                  Yongqiang Jiang and
                  Min Gao and
                  Hongzhi Yin},
	title = {{MCRPL:} {A} Pretrain, Prompt, and Fine-tune Paradigm for Non-overlapping
                  Many-to-one Cross-domain Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {97:1--97:24},
	year = {2024},
	url = {https://doi.org/10.1145/3641860},
	doi = {10.1145/3641860},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LiuGZJGY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-domain Recommendation is the task that tends to improve the recommendations in the sparse target domain by leveraging the information from other rich domains. Existing methods of cross-domain recommendation mainly focus on overlapping scenarios by assuming users are totally or partially overlapped, which are taken as bridges to connect different domains. However, this assumption does not always hold, since it is illegal to leak users’ identity information to other domains. Conducting Non-overlapping MCR (NMCR) is challenging, since (1) the absence of overlapping information prevents us from directly aligning different domains, and this situation may get worse in the MCR scenario, and (2) the distribution between source and target domains makes it difficult for us to learn common information across domains. To overcome the above challenges, we focus on NMCR and devise MCRPL as our solution. To address Challenge 1, we first learn shared domain-agnostic and domain-dependent prompts and pre-train them in the pre-training stage. To address Challenge 2, we further update the domain-dependent prompts with other parameters kept fixed to transfer the domain knowledge to the target domain. We conduct experiments on five real-world domains, and the results show the advance of our MCRPL method compared with several recent SOTA baselines. Moreover, our source codes have been publicly released.}
}


@article{DBLP:journals/tois/WuWGCFQ24,
	author = {Jiancan Wu and
                  Xiang Wang and
                  Xingyu Gao and
                  Jiawei Chen and
                  Hongcheng Fu and
                  Tianyu Qiu},
	title = {On the Effectiveness of Sampled Softmax Loss for Item Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {98:1--98:26},
	year = {2024},
	url = {https://doi.org/10.1145/3637061},
	doi = {10.1145/3637061},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WuWGCFQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The learning objective plays a fundamental role to build a recommender system. Most methods routinely adopt either pointwise (e.g., binary cross-entropy) or pairwise (e.g., BPR) loss to train the model parameters, while rarely pay attention to softmax loss, which assumes the probabilities of all classes sum up to 1, due to its computational complexity when scaling up to large datasets or intractability for streaming data where the complete item space is not always available. The sampled softmax (SSM) loss emerges as an efficient substitute for softmax loss. Its special case, InfoNCE loss, has been widely used in self-supervised learning and exhibited remarkable performance for contrastive learning. Nonetheless, limited recommendation work uses the SSM loss as the learning objective. Worse still, none of them explores its properties thoroughly and answers “Does SSM loss suit for item recommendation?” and “What are the conceptual advantages of SSM loss, as compared with the prevalent losses?”, to the best of our knowledge. In this work, we aim at offering a better understanding of SSM for item recommendation. Specifically, we first theoretically reveal three model-agnostic advantages: (1) mitigating popularity bias, which is beneficial to long-tail recommendation; (2) mining hard negative samples, which offers informative gradients to optimize model parameters; and (3) maximizing the ranking metric, which facilitates top- K  performance. However, based on our empirical studies, we recognize that the default choice of cosine similarity function in SSM limits its ability in learning the magnitudes of representation vectors. As such, the combinations of SSM with the models that also fall short in adjusting magnitudes (e.g., matrix factorization) may result in poor representations. One step further, we provide mathematical proof that message passing schemes in graph convolution networks can adjust representation magnitude according to node degree, which naturally compensates for the shortcoming of SSM. Extensive experiments on four benchmark datasets justify our analyses, demonstrating the superiority of SSM for item recommendation. Our implementations are available in both TensorFlow and PyTorch.}
}


@article{DBLP:journals/tois/LalorAOYF24,
	author = {John P. Lalor and
                  Ahmed Abbasi and
                  Kezia Oketch and
                  Yi Yang and
                  Nicole Forsgren},
	title = {Should Fairness be a Metric or a Model? {A} Model-based Framework
                  for Assessing Bias in Machine Learning Pipelines},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {99:1--99:41},
	year = {2024},
	url = {https://doi.org/10.1145/3641276},
	doi = {10.1145/3641276},
	timestamp = {Sun, 19 Jan 2025 15:03:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LalorAOYF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fairness measurement is crucial for assessing algorithmic bias in various types of machine learning (ML) models, including ones used for search relevance, recommendation, personalization, talent analytics, and natural language processing. However, the fairness measurement paradigm is currently dominated by fairness metrics that examine disparities in allocation and/or prediction error as univariate key performance indicators (KPIs) for a protected attribute or group. Although important and effective in assessing ML bias in certain contexts such as recidivism, existing metrics don’t work well in many real-world applications of ML characterized by imperfect models applied to an array of instances encompassing a multivariate mixture of protected attributes, that are part of a broader process pipeline. Consequently, the upstream representational harm quantified by existing metrics based on how the model represents protected groups doesn’t necessarily relate to allocational harm in the application of such models in downstream policy/decision contexts. We propose FAIR-Frame, a model-based framework for parsimoniously modeling fairness across multiple protected attributes in regard to the representational and allocational harm associated with the upstream design/development and downstream usage of ML models. We evaluate the efficacy of our proposed framework on two testbeds pertaining to text classification using pretrained language models. The upstream testbeds encompass over fifty thousand documents associated with twenty-eight thousand users, seven protected attributes and five different classification tasks. The downstream testbeds span three policy outcomes and over 5.41 million total observations. Results in comparison with several existing metrics show that the upstream representational harm measures produced by FAIR-Frame and other metrics are significantly different from one another, and that FAIR-Frame’s representational fairness measures have the highest percentage alignment and lowest error with allocational harm observed in downstream applications. Our findings have important implications for various ML contexts, including information retrieval, user modeling, digital platforms, and text classification, where responsible and trustworthy AI is becoming an imperative.}
}


@article{DBLP:journals/tois/MaHWWDFC24,
	author = {Yunshan Ma and
                  Yingzhi He and
                  Xiang Wang and
                  Yinwei Wei and
                  Xiaoyu Du and
                  Yuyangzi Fu and
                  Tat{-}Seng Chua},
	title = {MultiCBR: Multi-view Contrastive Learning for Bundle Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {100:1--100:23},
	year = {2024},
	url = {https://doi.org/10.1145/3640810},
	doi = {10.1145/3640810},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/MaHWWDFC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bundle recommendation seeks to recommend a bundle of related items to users to improve both user experience and the profits of platform. Existing bundle recommendation models have progressed from capturing only user-bundle interactions to the modeling of multiple relations among users, bundles, and items. CrossCBR, in particular, incorporates cross-view contrastive learning into a two-view preference learning framework, significantly improving SOTA performance. It does, however, have two limitations: (1) the two-view formulation does not fully exploit all the heterogeneous relations among users, bundles, and items; and (2) the “early contrast and late fusion” framework is less effective in capturing user preference and difficult to generalize to multiple views. In this article, we present MultiCBR, a novel  Multi -view  C ontrastive learning framework for  B undle  R ecommendation. First, we devise a multi-view representation learning framework capable of capturing all the user-bundle, user-item, and bundle-item relations, especially better utilizing the bundle-item affiliations to enhance sparse bundles’ representations. Second, we innovatively adopt an “early fusion and late contrast” design that first fuses the multi-view representations before performing self-supervised contrastive learning. In comparison to existing approaches, our framework reverses the order of fusion and contrast, introducing the following advantages: (1) Our framework is capable of modeling both cross-view and ego-view preferences, allowing us to achieve enhanced user preference modeling; and (2) instead of requiring quadratic number of cross-view contrastive losses, we only require two self-supervised contrastive losses, resulting in minimal extra costs. Experimental results on three public datasets indicate that our method outperforms SOTA methods. The code and dataset can be found in the github repo  https://github.com/HappyPointer/MultiCBR .}
}


@article{DBLP:journals/tois/ChengHZ24,
	author = {Jiezhu Cheng and
                  Kaizhu Huang and
                  Zibin Zheng},
	title = {Can Perturbations Help Reduce Investment Risks? Risk-aware Stock Recommendation
                  via Split Variational Adversarial Training},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {101:1--101:28},
	year = {2024},
	url = {https://doi.org/10.1145/3643131},
	doi = {10.1145/3643131},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ChengHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the stock market, a successful investment requires a good balance between profits and risks. Based on the  learning to rank  paradigm, stock recommendation has been widely studied in quantitative finance to recommend stocks with higher return ratios for investors. Despite the efforts to make profits, many existing recommendation approaches still have some limitations in risk control, which may lead to intolerable paper losses in practical stock investing. To effectively reduce risks, we draw inspiration from adversarial learning and propose a novel  Split Variational Adversarial Training  (SVAT) method for risk-aware stock recommendation. Essentially, SVAT encourages the stock model to be sensitive to adversarial perturbations of risky stock examples and enhances the model’s risk awareness by learning from perturbations. To generate representative adversarial examples as risk indicators, we devise a variational perturbation generator to model diverse risk factors. Particularly, the variational architecture enables our method to provide a rough risk quantification for investors, showing an additional advantage of interpretability. Experiments on several real-world stock market datasets demonstrate the superiority of our SVAT method. By lowering the volatility of the stock-recommendation model, SVAT effectively reduces investment risks and outperforms state-of-the-art baselines by more than 30% in terms of risk-adjusted profits. All the experimental data and source code are available at  https://drive.google.com/drive/folders/14AdM7WENEvIp5x5bV3zV_i4Aev21C9g6?usp=sharing .}
}


@article{DBLP:journals/tois/CheLL24,
	author = {Shangkun Che and
                  Hongyan Liu and
                  Shen Liu},
	title = {Tagging Items with Emerging Tags: {A} Neural Topic Model Based Few-Shot
                  Learning Approach},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {102:1--102:37},
	year = {2024},
	url = {https://doi.org/10.1145/3641859},
	doi = {10.1145/3641859},
	timestamp = {Sun, 19 Jan 2025 15:03:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/CheLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The tagging system has become a primary tool to organize information resources on the Internet, which benefits both users and the platforms. To build a successful tagging system, automatic tagging methods are desired. With the development of society, new tags keep emerging. The problem of tagging items with emerging tags is an open challenge for an automatic tagging system, and it has not been well studied in the literature. We define this problem as a tag-centered cold-start problem in this study and propose a novel neural topic model based few-shot learning method named  NTFSL  to solve the problem. In our proposed method, we innovatively fuse the topic modeling task with the few-shot learning task, endowing the model with the capability to infer effective topics to solve the tag-centered cold-start problem with the property of interpretability. Meanwhile, we propose a novel neural topic model for the topic modeling task to improve the quality of inferred topics, which helps enhance the tagging performance. Furthermore, we develop a novel inference method based on the variational auto-encoding framework for model inference. We conducted extensive experiments on two real-world datasets, and the results demonstrate the superior performance of our proposed model compared with state-of-the-art machine learning methods. Case studies also show the interpretability of the model.}
}


@article{DBLP:journals/tois/ZhangMNLCFKW24,
	author = {Shengyu Zhang and
                  Qiaowei Miao and
                  Ping Nie and
                  Mengze Li and
                  Zhengyu Chen and
                  Fuli Feng and
                  Kun Kuang and
                  Fei Wu},
	title = {Transferring Causal Mechanism over Meta-representations for Target-Unknown
                  Cross-domain Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {103:1--103:27},
	year = {2024},
	url = {https://doi.org/10.1145/3643807},
	doi = {10.1145/3643807},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ZhangMNLCFKW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tackling the pervasive issue of data sparsity in recommender systems, we present an insightful investigation into the burgeoning area of non-overlapping cross-domain recommendation, a technique that facilitates the transfer of interaction knowledge across domains without necessitating inter-domain user/item correspondence. Existing approaches have predominantly depended on auxiliary information, such as user reviews and item tags, to establish inter-domain connectivity, but these resources may become inaccessible due to privacy and commercial constraints. To address these limitations, our study introduces an in-depth exploration of Target-unknown Cross-domain Recommendation (CDR), which contends with the distinct challenge of lacking target domain information during the training phase in the source domain. We illustrate two critical obstacles inherent to Target-unknown CDR: the lack of an inter-domain bridge due to insufficient user/item correspondence or side information and the potential pitfalls of source-domain training biases when confronting distribution shifts across domains. To surmount these obstacles, we propose the CMCDR framework, a novel approach that leverages causal mechanisms extracted from meta-user/item representations. The CMCDR framework employs a vector-quantized encoder–decoder architecture, enabling the disentanglement of user/item characteristics. We posit that domain-transferable knowledge is more readily discernible from user/item characteristics, i.e., the meta-representations, rather than raw users and items. Capitalizing on these meta-representations, our CMCDR framework adeptly incorporates an attention-driven predictor that approximates the front-door adjustment method grounded in causal theory. This cutting-edge strategy effectively mitigates source-domain training biases and enhances generalization capabilities against distribution shifts. Extensive experiments demonstrate the empirical effectiveness and the rationality of CMCDR for target-unknown cross-domain recommendation.}
}


@article{DBLP:journals/tois/WanWXXLLH24,
	author = {Qizhi Wan and
                  Changxuan Wan and
                  Keli Xiao and
                  Hui Xiong and
                  Dexi Liu and
                  Xiping Liu and
                  Rong Hu},
	title = {Token-Event-Role Structure-Based Multi-Channel Document-Level Event
                  Extraction},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {104:1--104:27},
	year = {2024},
	url = {https://doi.org/10.1145/3643885},
	doi = {10.1145/3643885},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WanWXXLLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Document-level event extraction is a long-standing challenging information retrieval problem involving a sequence of sub-tasks: entity extraction, event type judgment, and event type-specific multi-event extraction. However, addressing the problem as multiple learning tasks leads to increased model complexity. Also, existing methods insufficiently utilize the correlation of entities crossing different events, resulting in limited event extraction performance. This article introduces a novel framework for document-level event extraction, incorporating a new data structure called token-event-role and a multi-channel argument role prediction module. The proposed data structure enables our model to uncover the primary role of tokens in multiple events, facilitating a more comprehensive understanding of event relationships. By leveraging the multi-channel prediction module, we transform entity and multi-event extraction into a single task of predicting token–event pairs, thereby reducing the overall parameter size and enhancing model efficiency. The results demonstrate that our approach outperforms the state-of-the-art method by 9.5 percentage points in terms of the  F 1 score, highlighting its superior performance in event extraction. Furthermore, an ablation study confirms the significant value of the proposed data structure in improving event extraction tasks, further validating its importance in enhancing the overall performance of the framework.}
}


@article{DBLP:journals/tois/LiCWHYD24,
	author = {Shuzhe Li and
                  Wei Chen and
                  Bin Wang and
                  Chao Huang and
                  Yanwei Yu and
                  Junyu Dong},
	title = {MCN4Rec: Multi-level Collaborative Neural Network for Next Location
                  Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {105:1--105:26},
	year = {2024},
	url = {https://doi.org/10.1145/3643669},
	doi = {10.1145/3643669},
	timestamp = {Wed, 16 Apr 2025 07:38:03 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LiCWHYD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Next location recommendation plays an important role in various location-based services, yielding great value for both users and service providers. Existing methods usually model temporal dependencies with explicit time intervals or learn representation from customized point of interest (POI) graphs with rich context information to capture the sequential patterns among POIs. However, this problem is perceptibly complex, because various factors, e.g., users’ preferences, spatial locations, time contexts, activity category semantics, and temporal relations, need to be considered together, while most studies lack sufficient consideration of the collaborative signals. Toward this goal, we propose a novel  M ulti-Level  C ollaborative Neural  N etwork for next location  Rec ommendation (MCN4Rec). Specifically, we design a multi-level view representation learning with level-wise contrastive learning to collaboratively learn representation from local and global perspectives to capture complex heterogeneous relationships among user, POI, time, and activity categories. Then, a causal encoder-decoder is applied to the learned representations of check-in sequences to recommend the next location. Extensive experiments on four real-world check-in mobility datasets demonstrate that our model significantly outperforms the existing state-of-the-art baselines for the next location recommendation. Ablation study further validates the benefits of the collaboration of the designed sub-modules. The source code is available at  https://github.com/quai-mengxiang/MCN4Rec .}
}


@article{DBLP:journals/tois/WangLYLX24,
	author = {Xiangmeng Wang and
                  Qian Li and
                  Dianer Yu and
                  Qing Li and
                  Guandong Xu},
	title = {Counterfactual Explanation for Fairness in Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {106:1--106:30},
	year = {2024},
	url = {https://doi.org/10.1145/3643670},
	doi = {10.1145/3643670},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WangLYLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fairness-aware recommendation alleviates discrimination issues to build trustworthy recommendation systems. Explaining the causes of unfair recommendations is critical, as it promotes fairness diagnostics, and thus secures users’ trust in recommendation models. Existing fairness explanation methods suffer high computation burdens due to the large-scale search space and the greedy nature of the explanation search process. Besides, they perform feature-level optimizations with continuous values, which are not applicable to discrete attributes such as gender and age. In this work, we adopt counterfactual explanations from causal inference and propose to generate attribute-level counterfactual explanations, adapting to discrete attributes in recommendation models. We use real-world attributes from Heterogeneous Information Networks (HINs) to empower counterfactual reasoning on discrete attributes. We propose a  Counterfactual Explanation for Fairness (CFairER)  that generates attribute-level counterfactual explanations from HINs for item exposure fairness. Our  CFairER  conducts off-policy reinforcement learning to seek high-quality counterfactual explanations, with attentive action pruning reducing the search space of candidate counterfactuals. The counterfactual explanations help to provide rational and proximate explanations for model fairness, while the attentive action pruning narrows the search space of attributes. Extensive experiments demonstrate our proposed model can generate faithful explanations while maintaining favorable recommendation performance.}
}


@article{DBLP:journals/tois/FangZXR24,
	author = {Yang Fang and
                  Xiang Zhao and
                  Weidong Xiao and
                  Maarten de Rijke},
	title = {Few-shot Learning for Heterogeneous Information Networks},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {107:1--107:24},
	year = {2024},
	url = {https://doi.org/10.1145/3649311},
	doi = {10.1145/3649311},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/FangZXR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous information networks (HINs)  are a key resource in many domain-specific retrieval and recommendation scenarios and in conversational environments. Current approaches to mining graph data often rely on abundant supervised information. However, supervised signals for graph learning tend to be scarce for a new task and only a handful of labeled nodes may be available. Meta-learning mechanisms are able to harness prior knowledge that can be adapted to new tasks. In this article, we design meta-learning framework for heterogeneous information networks ( META-HIN ), for few-shot learning problems on HINs. To the best of our knowledge, we are among the first to design a unified framework to realize the few-shot learning of HINs and facilitate different downstream tasks across different domains of graphs. Unlike most previous models, which focus on a single task on a single graph,  META-HIN  is able to deal with different tasks (node classification, link prediction, and anomaly detection are used as examples) across multiple graphs. Subgraphs are sampled to build the support and query set. Before being processed by the meta-learning module, subgraphs are modeled via a structure module to capture structural features. Then, a heterogeneous Graph Neural Network module is used as the base model to express the features of subgraphs. We also design a Generative Adversarial Network-based contrastive learning module that is able to exploit unsupervised information of the subgraphs. In our experiments, we fuse several datasets from multiple domains to verify  META-HIN ’s broad applicability in a multiple-graph scenario.  META-HIN  consistently and significantly outperforms state-of-the-art alternatives on every task and across all datasets that we consider.}
}


@article{DBLP:journals/tois/LiBMYHC24,
	author = {Jun Li and
                  Yi Bin and
                  Yunshan Ma and
                  Yang Yang and
                  Zi Huang and
                  Tat{-}Seng Chua},
	title = {Filter-based Stance Network for Rumor Verification},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {108:1--108:28},
	year = {2024},
	url = {https://doi.org/10.1145/3649462},
	doi = {10.1145/3649462},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LiBMYHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rumor verification on social media aims to identify the truth value of a rumor, which is important to decrease the detrimental public effects. A rumor might arouse heated discussions and replies, conveying different stances of users that could be helpful in identifying the rumor. Thus, several works have been proposed to verify a rumor by modelling its entire stance sequence in the time domain. However, these works ignore that such a stance sequence could be decomposed into controversies with different intensities, which could be used to cluster the stance sequences with the same consensus. In addition, the existing stance extractors fail to consider both the impact of all previously posted tweets and the reply chain on obtaining the stance of a new reply. To address the above problems, in this article, we propose a novel stance-based network to aggregate the controversies of the stance sequence for rumor verification, termed Filter-based Stance Network (FSNet). As controversies with different intensities are reflected as the different changes of stances, it is convenient to represent different controversies in the frequency domain, but it is hard in the time domain. Our proposed FSNet decomposes the stance sequence into multiple controversies in the frequency domain and obtains the weighted aggregation of them. Specifically, FSNet consists of two modules: the stance extractor and the filter block. To obtain better stance features toward the source, the stance extractor contains two stages. In the first stage, the tweet representation of each reply is obtained by aggregating information from all previously posted tweets in a conversation. Then, the features of stance toward the source, i.e., rumor-aware stance, are extracted with the reply chains in the second stage. In the filter block module, a rumor-aware stance sequence is constructed by sorting all the tweets of a conversation in chronological order. Fourier Transform thereafter is employed to convert the stance sequence into the frequency domain, where different frequency components reflect controversies of different intensities. Finally, a frequency filter is applied to explore the different contributions of controversies. We supervise our FSNet with both stance labels and rumor labels to strengthen the relations between rumor veracity and crowd stances. Extensive experiments on two benchmark datasets demonstrate that our model substantially outperforms all the baselines.}
}


@article{DBLP:journals/tois/LiYYSLXZ24,
	author = {Shujie Li and
                  Guanghu Yuan and
                  Min Yang and
                  Ying Shen and
                  Chengming Li and
                  Ruifeng Xu and
                  Xiaoyan Zhao},
	title = {Improving Semi-Supervised Text Classification with Dual Meta-Learning},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {109:1--109:28},
	year = {2024},
	url = {https://doi.org/10.1145/3648612},
	doi = {10.1145/3648612},
	timestamp = {Tue, 25 Feb 2025 12:47:06 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiYYSLXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The goal of semi-supervised text classification (SSTC) is to train a model by exploring both a small number of labeled data and a large number of unlabeled data, such that the learned semi-supervised classifier performs better than the supervised classifier trained on solely the labeled samples. Pseudo-labeling is one of the most widely used SSTC techniques, which trains a teacher classifier with a small number of labeled examples to predict pseudo labels for the unlabeled data. The generated pseudo-labeled examples are then utilized to train a student classifier, such that the learned student classifier can outperform the teacher classifier. Nevertheless, the predicted pseudo labels may be inaccurate, making the performance of the student classifier degraded. The student classifier may perform even worse than the teacher classifier. To alleviate this issue, in this paper, we introduce a dual meta-learning ( DML ) technique for semi-supervised text classification, which improves the teacher and student classifiers simultaneously in an iterative manner. Specifically, we propose a meta-noise correction method to improve the student classifier by proposing a Noise Transition Matrix (NTM) with meta-learning to rectify the noisy pseudo labels. In addition, we devise a meta pseudo supervision method to improve the teacher classifier. Concretely, we exploit the feedback performance from the student classifier to further guide the teacher classifier to produce more accurate pseudo labels for the unlabeled data. In this way, both teacher and student classifiers can co-evolve in the iterative training process. Extensive experiments on four benchmark datasets highlight the effectiveness of our DML method against existing state-of-the-art methods for semi-supervised text classification. We release our code and data of this paper publicly at https://github.com/GRIT621/DML.}
}


@article{DBLP:journals/tois/ZhaSQZXZC24,
	author = {Rui Zha and
                  Ying Sun and
                  Chuan Qin and
                  Le Zhang and
                  Tong Xu and
                  Hengshu Zhu and
                  Enhong Chen},
	title = {Towards Unified Representation Learning for Career Mobility Analysis
                  with Trajectory Hypergraph},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {110:1--110:28},
	year = {2024},
	url = {https://doi.org/10.1145/3651158},
	doi = {10.1145/3651158},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhaSQZXZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Career mobility analysis aims at understanding the occupational movement patterns of talents across distinct labor market entities, which enables a wide range of talent-centered applications, such as job recommendation, labor demand forecasting, and company competitive analysis. Existing studies in this field mainly focus on a single fixed scale, investigating either individual trajectories at the micro-level or crowd flows among market entities at the macro-level. Consequently, the intrinsic cross-scale interactions between talents and the labor market are largely overlooked. To bridge this gap, we propose  UniTRep , a novel unified representation learning framework for cross-scale career mobility analysis. Specifically, we first introduce a trajectory hypergraph structure to organize the career mobility patterns in a low-information-loss manner, where market entities and talent trajectories are represented as nodes and hyperedges, respectively. Then, for learning the  market-aware talent representations , we attentively propagate the node information to the hyperedges and incorporate the market contextual features into the process of individual trajectory modeling. For learning the  trajectory-enhanced market representations , we aggregate the message from hyperedges associated with a specific node to integrate the fine-grained semantics of trajectories into labor market modeling. Moreover, we design two auxiliary tasks to optimize both intra-scale and cross-scale learning with a self-supervised strategy. Extensive experiments on a real-world dataset clearly validate that UniTRep can significantly outperform state-of-the-art baselines for various tasks.}
}


@article{DBLP:journals/tois/WangLZLZS24,
	author = {Tianshi Wang and
                  Fengling Li and
                  Lei Zhu and
                  Jingjing Li and
                  Zheng Zhang and
                  Heng Tao Shen},
	title = {Invisible Black-Box Backdoor Attack against Deep Cross-Modal Hashing
                  Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {111:1--111:27},
	year = {2024},
	url = {https://doi.org/10.1145/3650205},
	doi = {10.1145/3650205},
	timestamp = {Mon, 05 May 2025 20:19:11 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WangLZLZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep cross-modal hashing has promoted the field of multi-modal retrieval due to its excellent efficiency and storage, but its vulnerability to backdoor attacks is rarely studied. Notably, current deep cross-modal hashing methods inevitably require large-scale training data, resulting in poisoned samples with imperceptible triggers that can easily be camouflaged into the training data to bury backdoors in the victim model. Nevertheless, existing backdoor attacks focus on the uni-modal vision domain, while the multi-modal gap and hash quantization weaken their attack performance. In addressing the aforementioned challenges, we undertake an invisible black-box backdoor attack against deep cross-modal hashing retrieval in this article. To the best of our knowledge, this is the first attempt in this research field. Specifically, we develop a flexible trigger generator to generate the attacker’s specified triggers, which learns the sample semantics of the non-poisoned modality to bridge the cross-modal attack gap. Then, we devise an input-aware injection network, which embeds the generated triggers into benign samples in the form of sample-specific stealth and realizes cross-modal semantic interaction between triggers and poisoned samples. Owing to the knowledge-agnostic of victim models, we enable any cross-modal hashing knockoff to facilitate the black-box backdoor attack and alleviate the attack weakening of hash quantization. Moreover, we propose a confusing perturbation and mask strategy to induce the high-performance victim models to focus on imperceptible triggers in poisoned samples. Extensive experiments on benchmark datasets demonstrate that our method has a state-of-the-art attack performance against deep cross-modal hashing retrieval. Besides, we investigate the influences of transferable attacks, few-shot poisoning, multi-modal poisoning, perceptibility, and potential defenses on backdoor attacks. Our codes and datasets are available at https://github.com/tswang0116/IB3A.}
}


@article{DBLP:journals/tois/PuLSYCPW24,
	author = {Yanjun Pu and
                  Fang Liu and
                  Rongye Shi and
                  Haitao Yuan and
                  Ruibo Chen and
                  Tianhao Peng and
                  Wenjun Wu},
	title = {{ELAKT:} Enhancing Locality for Attentive Knowledge Tracing},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {4},
	pages = {112:1--112:27},
	year = {2024},
	url = {https://doi.org/10.1145/3652601},
	doi = {10.1145/3652601},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/PuLSYCPW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge tracing models based on deep learning can achieve impressive predictive performance by leveraging attention mechanisms. However, there still exist two challenges in attentive knowledge tracing (AKT): First, the mechanism of classical models of AKT demonstrates relatively low attention when processing exercise sequences with shifting knowledge concepts (KC), making it difficult to capture the comprehensive state of knowledge across sequences. Second, classical models do not consider stochastic behaviors, which negatively affects models of AKT in terms of capturing anomalous knowledge states. This article proposes a model of AKT, called Enhancing Locality for Attentive Knowledge Tracing (ELAKT), that is a variant of the deep KT model. The proposed model leverages the encoder module of the transformer to aggregate knowledge embedding generated by both exercises and responses over all timesteps. In addition, it uses causal convolutions to aggregate and smooth the states of local knowledge. The ELAKT model uses the states of comprehensive KCs to introduce a prediction correction module to forecast the future responses of students to deal with noise caused by stochastic behaviors. The results of experiments demonstrated that the ELAKT model consistently outperforms state-of-the-art baseline KT models.}
}


@article{DBLP:journals/tois/BruchLMN24,
	author = {Sebastian Bruch and
                  Claudio Lucchese and
                  Maria Maistro and
                  Franco Maria Nardini},
	title = {Special Section on Efficiency in Neural Information Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {113:1--113:4},
	year = {2024},
	url = {https://doi.org/10.1145/3641203},
	doi = {10.1145/3641203},
	timestamp = {Sun, 25 May 2025 13:43:34 +0200},
	biburl = {https://dblp.org/rec/journals/tois/BruchLMN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/tois/RauDK24,
	author = {David Rau and
                  Mostafa Dehghani and
                  Jaap Kamps},
	title = {Revisiting Bag of Words Document Representations for Efficient Ranking
                  with Transformers},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {114:1--114:27},
	year = {2024},
	url = {https://doi.org/10.1145/3640460},
	doi = {10.1145/3640460},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/RauDK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern transformer-based information retrieval models achieve state-of-the-art performance across various benchmarks. The self-attention of the transformer models is a powerful mechanism to contextualize terms over the whole input but quickly becomes prohibitively expensive for long input as required in document retrieval. Instead of focusing on the model itself to improve efficiency, this paper explores different bag of words document representations that encode full documents by only a fraction of their characteristic terms, allowing us to control and reduce the input length. We experiment with various models for document retrieval on MS MARCO data, as well as zero-shot document retrieval on Robust04, and show large gains in efficiency while retaining reasonable effectiveness. Inference time efficiency gains are both lowering the time and memory complexity in a controllable way, allowing for further trading off memory footprint and query latency. More generally, this line of research connects traditional IR models with neural “NLP” models and offers novel ways to explore the space between (efficient, but less effective) traditional rankers and (effective, but less efficient) neural rankers elegantly.}
}


@article{DBLP:journals/tois/AskariVAKP24,
	author = {Arian Askari and
                  Suzan Verberne and
                  Amin Abolghasemi and
                  Wessel Kraaij and
                  Gabriella Pasi},
	title = {Retrieval for Extremely Long Queries and Documents with {RPRS:} {A}
                  Highly Efficient and Effective Transformer-based Re-Ranker},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {115:1--115:32},
	year = {2024},
	url = {https://doi.org/10.1145/3631938},
	doi = {10.1145/3631938},
	timestamp = {Sun, 19 Jan 2025 15:03:44 +0100},
	biburl = {https://dblp.org/rec/journals/tois/AskariVAKP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval with extremely long queries and documents is a well-known and challenging task in information retrieval and is commonly known as Query-by-Document (QBD) retrieval. Specifically designed Transformer models that can handle long input sequences have not shown high effectiveness in QBD tasks in previous work. We propose a Re-Ranker based on the novel Proportional Relevance Score (RPRS) to compute the relevance score between a query and the top- k  candidate documents. Our extensive evaluation shows RPRS obtains significantly better results than the state-of-the-art models on five different datasets. Furthermore, RPRS is highly efficient, since all documents can be pre-processed, embedded, and indexed before query time that gives our re-ranker the advantage of having a complexity of  O(N) , where  N  is the total number of sentences in the query and candidate documents. Furthermore, our method solves the problem of the low-resource training in QBD retrieval tasks as it does not need large amounts of training data and has only three parameters with a limited range that can be optimized with a grid search even if a small amount of labeled data is available. Our detailed analysis shows that RPRS benefits from covering the full length of candidate documents and queries.}
}


@article{DBLP:journals/tois/FormalLPC24,
	author = {Thibault Formal and
                  Carlos Lassance and
                  Benjamin Piwowarski and
                  St{\'{e}}phane Clinchant},
	title = {Towards Effective and Efficient Sparse Neural Information Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {116:1--116:46},
	year = {2024},
	url = {https://doi.org/10.1145/3634912},
	doi = {10.1145/3634912},
	timestamp = {Sun, 04 Aug 2024 19:51:35 +0200},
	biburl = {https://dblp.org/rec/journals/tois/FormalLPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sparse representation learning based on Pre-trained Language Models has seen a growing interest in Information Retrieval. Such approaches can take advantage of the proven efficiency of inverted indexes and inherit desirable IR priors such as explicit lexical matching or some degree of interpretability. In this work, we thoroughly develop the framework of sparse representation learning in IR, which unifies term weighting and expansion in a supervised setting. We then build on SPLADE—a sparse expansion-based retriever—and show to which extent it is able to benefit from the same training improvements as dense bi-encoders by studying the effect of distillation, hard negative mining, as well as the Pre-trained Language Model’s initialization on its  effectiveness , leading to state-of-the-art results in both in- and out-of-domain evaluation settings (SPLADE++). We furthermore propose  efficiency  improvements, allowing us to reach latency requirements on par with traditional keyword-based approaches (Efficient-SPLADE).}
}


@article{DBLP:journals/tois/LeonhardtMRKAA24,
	author = {Jurek Leonhardt and
                  Henrik M{\"{u}}ller and
                  Koustav Rudra and
                  Megha Khosla and
                  Abhijit Anand and
                  Avishek Anand},
	title = {Efficient Neural Ranking Using Forward Indexes and Lightweight Encoders},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {117:1--117:34},
	year = {2024},
	url = {https://doi.org/10.1145/3631939},
	doi = {10.1145/3631939},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LeonhardtMRKAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dual-encoder-based dense retrieval models have become the standard in IR. They employ large Transformer-based language models, which are notoriously inefficient in terms of resources and latency. We propose  Fast-Forward  indexes—vector forward indexes which exploit the semantic matching capabilities of dual-encoder models for efficient and effective re-ranking. Our framework enables re-ranking at very high retrieval depths and combines the merits of both lexical and semantic matching via score interpolation. Furthermore, in order to mitigate the limitations of dual-encoders, we tackle two main challenges: Firstly, we improve computational efficiency by either pre-computing representations, avoiding unnecessary computations altogether, or reducing the complexity of encoders. This allows us to considerably improve ranking efficiency and latency. Secondly, we optimize the memory footprint and maintenance cost of indexes; we propose two complementary techniques to reduce the index size and show that, by dynamically dropping irrelevant document tokens, the index maintenance efficiency can be improved substantially. We perform an evaluation to show the effectiveness and efficiency of  Fast-Forward  indexes—our method has low latency and achieves competitive results without the need for hardware acceleration, such as GPUs.}
}


@article{DBLP:journals/tois/LiuGMDWJZC24,
	author = {Qi Liu and
                  Gang Guo and
                  Jiaxin Mao and
                  Zhicheng Dou and
                  Ji{-}Rong Wen and
                  Hao Jiang and
                  Xinyu Zhang and
                  Zhao Cao},
	title = {An Analysis on Matching Mechanisms and Token Pruning for Late-interaction
                  Models},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {118:1--118:28},
	year = {2024},
	url = {https://doi.org/10.1145/3639818},
	doi = {10.1145/3639818},
	timestamp = {Mon, 14 Apr 2025 22:19:02 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LiuGMDWJZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of pre-trained language models, the dense retrieval models have become promising alternatives to the traditional retrieval models that rely on exact match and sparse bag-of-words representations. Different from most dense retrieval models using a bi-encoder to encode each query or document into a dense vector, the recently proposed late-interaction multi-vector models (i.e., ColBERT and COIL) achieve state-of-the-art retrieval effectiveness by using all token embeddings to represent documents and queries and modeling their relevance with a sum-of-max operation. However, these fine-grained representations may cause unacceptable storage overhead for practical search systems. In this study, we systematically analyze the matching mechanism of these late-interaction models and show that the sum-of-max operation heavily relies on the co-occurrence signals and some important words in the document. Based on these findings, we then propose several simple document pruning methods to reduce the storage overhead and compare the effectiveness of different pruning methods on different late-interaction models. We also leverage query pruning methods to further reduce the retrieval latency. We conduct extensive experiments on both in-domain and out-domain datasets and show that some of the used pruning methods can significantly improve the efficiency of these late-interaction models without substantially hurting their retrieval effectiveness.}
}


@article{DBLP:journals/tois/AnandLSRA24,
	author = {Abhijit Anand and
                  Jurek Leonhardt and
                  Jaspreet Singh and
                  Koustav Rudra and
                  Avishek Anand},
	title = {Data Augmentation for Sample Efficient and Robust Document Ranking},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {119:1--119:29},
	year = {2024},
	url = {https://doi.org/10.1145/3634911},
	doi = {10.1145/3634911},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/AnandLSRA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contextual ranking models have delivered impressive performance improvements over classical models in the document ranking task. However, these highly over-parameterized models tend to be data-hungry and require large amounts of data even for fine-tuning. In this article, we propose data-augmentation methods for effective and robust ranking performance. One of the key benefits of using data augmentation is in achieving  sample efficiency  or learning effectively when we have only a small amount of training data. We propose supervised and unsupervised data augmentation schemes by creating training data using parts of the relevant documents in the query-document pairs. We then adapt a family of contrastive losses for the document ranking task that can exploit the augmented data to learn an effective ranking model. Our extensive experiments on subsets of the  MS MARCO  and  TREC-DL  test sets show that data augmentation, along with the ranking-adapted contrastive losses, results in performance improvements under most dataset sizes. Apart from sample efficiency, we conclusively show that data augmentation results in robust models when transferred to out-of-domain benchmarks. Our performance improvements in in-domain and more prominently in out-of-domain benchmarks show that augmentation regularizes the ranking model and improves its robustness and generalization capability.}
}


@article{DBLP:journals/tois/YanSWCJGL24,
	author = {Surong Yan and
                  Chenglong Shi and
                  Haosen Wang and
                  Lei Chen and
                  Ling Jiang and
                  Ruilin Guo and
                  Kwei{-}Jay Lin},
	title = {Teach and Explore: {A} Multiplex Information-guided Effective and
                  Efficient Reinforcement Learning for Sequential Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {120:1--120:26},
	year = {2024},
	url = {https://doi.org/10.1145/3630003},
	doi = {10.1145/3630003},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/YanSWCJGL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Casting sequential recommendation (SR) as a reinforcement learning (RL) problem is promising and some RL-based methods have been proposed for SR. However, these models are sub-optimal due to the following limitations: (a) they fail to leverage the supervision signals in the RL training to capture users’ explicit preferences, leading to slow convergence; and (b) they do not utilize auxiliary information (e.g., knowledge graph) to avoid blindness when exploring users’ potential interests. To address the above-mentioned limitations, we propose a multiplex information-guided RL model (MELOD), which employs a novel RL training framework with Teach and Explore components for SR. We adopt a Teach component to accurately capture users’ explicit preferences and speed up RL convergence. Meanwhile, we design a dynamic intent induction network (DIIN) as a policy function to generate diverse predictions. We utilize the DIIN for the Explore component to mine users’ potential interests by conducting a sequential and knowledge information joint-guided exploration. Moreover, a sequential and knowledge-aware reward function is designed to achieve stable RL training. These components significantly improve MELOD’s performance and convergence against existing RL algorithms to achieve effectiveness and efficiency. Experimental results on seven real-world datasets show that our model significantly outperforms state-of-the-art methods.}
}


@article{DBLP:journals/tois/LienZC24,
	author = {Yen{-}Chieh Lien and
                  Hamed Zamani and
                  W. Bruce Croft},
	title = {Generalized Weak Supervision for Neural Information Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {121:1--121:26},
	year = {2024},
	url = {https://doi.org/10.1145/3647639},
	doi = {10.1145/3647639},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/LienZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Neural ranking models (NRMs) have demonstrated effective performance in several information retrieval (IR) tasks. However, training NRMs often requires large-scale training data, which is difficult and expensive to obtain. To address this issue, one can train NRMs via weak supervision, where a large dataset is automatically generated using an existing ranking model (called the weak labeler) for training NRMs. Weakly supervised NRMs can generalize from the observed data and significantly outperform the weak labeler. This paper generalizes this idea through an iterative re-labeling process, demonstrating that weakly supervised models can iteratively play the role of weak labeler and significantly improve ranking performance without using manually labeled data. The proposed Generalized Weak Supervision (GWS) solution is generic and orthogonal to the ranking model architecture. This paper offers four implementations of GWS: self-labeling, cross-labeling, joint cross- and self-labeling, and greedy multi-labeling. GWS also benefits from a query importance weighting mechanism based on query performance prediction methods to reduce noise in the generated training data. We further draw a theoretical connection between self-labeling and Expectation-Maximization. Our experiments on four retrieval benchmarks suggest that our implementations of GWS lead to substantial improvements compared to weak supervision if the weak labeler is sufficiently reliable.}
}


@article{DBLP:journals/tois/FrummetSELD24,
	author = {Alexander Frummet and
                  Alessandro Speggiorin and
                  David Elsweiler and
                  Anton Leuski and
                  Jeff Dalton},
	title = {Cooking with Conversation: Enhancing User Engagement and Learning
                  with a Knowledge-Enhancing Assistant},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {122:1--122:29},
	year = {2024},
	url = {https://doi.org/10.1145/3649500},
	doi = {10.1145/3649500},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/FrummetSELD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present two empirical studies to investigate users’ expectations and behaviours when using digital assistants, such as Alexa and Google Home, in a kitchen context: First, a survey (N = 200) queries participants on their expectations for the kinds of information that such systems should be able to provide. While consensus exists on expecting information about cooking steps and processes, younger participants who enjoy cooking express a higher likelihood of expecting details on food history or the science of cooking. In a follow-up Wizard-of-Oz study (N = 48), users were guided through the steps of a recipe either by an  active  wizard that alerted participants to information it could provide or a  passive  wizard who only answered questions that were provided by the user. The  active  policy led to almost double the number of conversational utterances and 1.5 times more knowledge-related user questions compared to the  passive  policy. Also, it resulted in 1.7 times more knowledge communicated than the  passive  policy. We discuss the findings in the context of related work and reveal implications for the design and use of such assistants for cooking and other purposes such as DIY and craft tasks, as well as the lessons we learned for evaluating such systems.}
}


@article{DBLP:journals/tois/ZhuPWLSC24,
	author = {Yunchang Zhu and
                  Liang Pang and
                  Kangxi Wu and
                  Yanyan Lan and
                  Huawei Shen and
                  Xueqi Cheng},
	title = {Cross-Model Comparative Loss for Enhancing Neuronal Utility in Language
                  Understanding},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {123:1--123:29},
	year = {2024},
	url = {https://doi.org/10.1145/3652599},
	doi = {10.1145/3652599},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhuPWLSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current natural language understanding (NLU) models have been continuously scaling up, both in terms of model size and input context, introducing more hidden and input neurons. While this generally improves performance on average, the extra neurons do not yield a consistent improvement for all instances. This is because some hidden neurons are redundant, and the noise mixed in input neurons tends to distract the model. Previous work mainly focuses on extrinsically reducing low-utility neurons by additional post- or pre-processing, such as network pruning and context selection, to avoid this problem. Beyond that, can we make the model reduce redundant parameters and suppress input noise by intrinsically enhancing the utility of each neuron? If a model can efficiently utilize neurons, no matter which neurons are ablated (disabled), the ablated submodel should perform no better than the original full model. Based on such a comparison principle between models, we propose a cross-model comparative loss for a broad range of tasks. Comparative loss is essentially a ranking loss on top of the task-specific losses of the full and ablated models, with the expectation that the task-specific loss of the full model is minimal. We demonstrate the universal effectiveness of comparative loss through extensive experiments on 14 datasets from three distinct NLU tasks based on five widely used pre-trained language models and find it particularly superior for models with few parameters or long input.}
}


@article{DBLP:journals/tois/WangLL24,
	author = {Jian Wang and
                  Dongding Lin and
                  Wenjie Li},
	title = {Target-constrained Bidirectional Planning for Generation of Target-oriented
                  Proactive Dialogue},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {124:1--124:27},
	year = {2024},
	url = {https://doi.org/10.1145/3652598},
	doi = {10.1145/3652598},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WangLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Target-oriented proactive dialogue systems aim at leading conversations from a dialogue context toward a pre-determined target, such as making recommendations on designated items or introducing new specific topics. To this end, it is critical for such dialogue systems to plan reasonable actions to drive the conversation proactively, and meanwhile, to plan appropriate topics to move the conversation forward to the target topic smoothly. In this work, we mainly focus on effective dialogue planning for target-oriented dialogue generation. Inspired by decision-making theories in cognitive science, we propose a novel target-constrained bidirectional planning (TRIP) approach, which plans an appropriate dialogue path by looking ahead and looking back. By formulating the planning as a generation task, our TRIP bidirectionally generates a dialogue path consisting of a sequence of <action, topic> pairs using two Transformer decoders. They are expected to supervise each other and converge on consistent actions and topics by minimizing the decision gap and contrastive generation of targets. Moreover, we propose a target-constrained decoding algorithm with a bidirectional agreement to better control the planning process. Subsequently, we adopt the planned dialogue paths to guide dialogue generation in a pipeline manner, where we explore two variants: prompt-based generation and plan-controlled generation. Extensive experiments are conducted on two challenging dialogue datasets, which are re-purposed for exploring target-oriented dialogue. Our automatic and human evaluations demonstrate that the proposed methods significantly outperform various baseline models.}
}


@article{DBLP:journals/tois/YangPYM24,
	author = {Enyue Yang and
                  Weike Pan and
                  Qiang Yang and
                  Zhong Ming},
	title = {Discrete Federated Multi-behavior Recommendation for Privacy-Preserving
                  Heterogeneous One-Class Collaborative Filtering},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {125:1--125:50},
	year = {2024},
	url = {https://doi.org/10.1145/3652853},
	doi = {10.1145/3652853},
	timestamp = {Mon, 22 Jul 2024 08:23:39 +0200},
	biburl = {https://dblp.org/rec/journals/tois/YangPYM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, federated recommendation has become a research hotspot mainly because of users’ awareness of privacy in data. As a recent and important recommendation problem, in heterogeneous one-class collaborative filtering (HOCCF), each user may involve of two different types of implicit feedback, that is, examinations and purchases. So far, privacy-preserving HOCCF has received relatively little attention. Existing federated recommendation works often overlook the fact that some privacy sensitive behaviors such as purchases should be collected to ensure the basic business imperatives in e-commerce for example. Hence, the user privacy constraints can and should be relaxed while deploying a recommendation system in real scenarios. In this article, we study the federated multi-behavior recommendation problem under the assumption that purchase behaviors can be collected. Moreover, there are two additional challenges that need to be addressed when deploying federated recommendation. One is the low storage capacity for users’ devices to store all the item vectors, and the other is the low computational power for users to participate in federated learning. To release the potential of privacy-preserving HOCCF, we propose a novel framework, named discrete federated multi-behavior recommendation (DFMR), which allows the collection of the business necessary behaviors (i.e., purchases) by the server. As to reduce the storage overhead, we use discrete hashing techniques, which can compress the parameters down to 1.56% of the real-valued parameters. To further improve the computation-efficiency, we design a memorization strategy in the cache updating module to accelerate the training process. Extensive experiments on four public datasets show the superiority of our DFMR in terms of both accuracy and efficiency.}
}


@article{DBLP:journals/tois/DengDSW24,
	author = {Zhirui Deng and
                  Zhicheng Dou and
                  Zhan Su and
                  Ji{-}Rong Wen},
	title = {Multi-grained Document Modeling for Search Result Diversification},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {126:1--126:22},
	year = {2024},
	url = {https://doi.org/10.1145/3652852},
	doi = {10.1145/3652852},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/DengDSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Search result diversification plays a crucial role in improving users’ search experience by providing users with documents covering more subtopics. Previous studies have made great progress in leveraging inter-document interactions to measure the similarity among documents. However, different parts of the document may embody different subtopics and existing models ignore the subtle similarities and differences of content within each document. In this article, we propose a hierarchical attention framework to combine intra-document interactions with inter-document interactions in a complementary manner in order to conduct multi-grained document modeling. Specifically, we separate the document into passages to model the document content from multi-grained perspectives. Then, we design stacked interaction blocks to conduct inter-document and intra-document interactions. Moreover, to measure the subtopic coverage of each document more accurately, we propose a passage-aware document-subtopic interaction to perform fine-grained document-subtopic interaction. Experimental results demonstrate that our model achieves state-of-the-art performance compared with existing methods.}
}


@article{DBLP:journals/tois/YiZHSHAN24,
	author = {Kun Yi and
                  Qi Zhang and
                  Hui He and
                  Kaize Shi and
                  Liang Hu and
                  Ning An and
                  Zhendong Niu},
	title = {Deep Coupling Network for Multivariate Time Series Forecasting},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {127:1--127:28},
	year = {2024},
	url = {https://doi.org/10.1145/3653447},
	doi = {10.1145/3653447},
	timestamp = {Thu, 29 Aug 2024 14:25:54 +0200},
	biburl = {https://dblp.org/rec/journals/tois/YiZHSHAN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time series (MTS) forecasting is crucial in many real-world applications. To achieve accurate MTS forecasting, it is essential to simultaneously consider both intra- and inter-series relationships among time series data. However, previous work has typically modeled intra- and inter-series relationships separately and has disregarded multi-order interactions present within and between time series data, which can seriously degrade forecasting accuracy. In this article, we reexamine intra- and inter-series relationships from the perspective of mutual information and accordingly construct a comprehensive relationship learning mechanism tailored to simultaneously capture the intricate multi-order intra- and inter-series couplings. Based on the mechanism, we propose a novel deep coupling network for MTS forecasting, named DeepCN, which consists of a coupling mechanism dedicated to explicitly exploring the multi-order intra- and inter-series relationships among time series data concurrently, a coupled variable representation module aimed at encoding diverse variable patterns, and an inference module facilitating predictions through one forward step. Extensive experiments conducted on seven real-world datasets demonstrate that our proposed DeepCN achieves superior performance compared with the state-of-the-art baselines.}
}


@article{DBLP:journals/tois/LiGLSLDSX24,
	author = {Hanzhe Li and
                  Jingjing Gu and
                  Xinjiang Lu and
                  Dazhong Shen and
                  Yuting Liu and
                  YaNan Deng and
                  Guoliang Shi and
                  Hui Xiong},
	title = {Beyond Relevance: Factor-level Causal Explanation for User Travel
                  Decisions with Counterfactual Data Augmentation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {128:1--128:31},
	year = {2024},
	url = {https://doi.org/10.1145/3653673},
	doi = {10.1145/3653673},
	timestamp = {Fri, 07 Feb 2025 20:42:18 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiGLSLDSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Point-of-Interest (POI) recommendation, an important research hotspot in the field of urban computing, plays a crucial role in urban construction. While understanding the process of users’ travel decisions and exploring the causality of POI choosing is not easy due to the complex and diverse influencing factors in urban travel scenarios. Moreover, the spurious explanations caused by severe data sparsity, i.e., misrepresenting universal relevance as causality, may also hinder us from understanding users’ travel decisions. To this end, in this article, we propose a factor-level causal explanation generation framework based on counterfactual data augmentation for user travel decisions, named Factor-level Causal Explanation for User Travel Decisions (FCE-UTD), which can distinguish between true and false causal factors and generate true causal explanations. Specifically, we first assume that a user decision is composed of a set of several different factors. Then, by preserving the user decision structure with a joint counterfactual contrastive learning paradigm, we learn the representation of factors and detect the relevant factors. Next, we further identify true causal factors by constructing counterfactual decisions with a counterfactual representation generator, in particular, it can not only augment the dataset and mitigate the sparsity but also contribute to clarifying the causal factors from other false causal factors that may cause spurious explanations. Besides, a causal dependency learner is proposed to identify causal factors for each decision by learning causal dependency scores. Extensive experiments conducted on three real-world datasets demonstrate the superiority of our approach in terms of check-in rate, fidelity, and downstream tasks under different behavior scenarios. The extra case studies also demonstrate the ability of FCE-UTD to generate causal explanations in POI choosing.}
}


@article{DBLP:journals/tois/TangCSL24,
	author = {Xing Tang and
                  Ling Chen and
                  Hongyu Shi and
                  Dandan Lyu},
	title = {DHyper: {A} Recurrent Dual Hypergraph Neural Network for Event Prediction
                  in Temporal Knowledge Graphs},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {129:1--129:23},
	year = {2024},
	url = {https://doi.org/10.1145/3653015},
	doi = {10.1145/3653015},
	timestamp = {Sun, 19 Jan 2025 15:03:44 +0100},
	biburl = {https://dblp.org/rec/journals/tois/TangCSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Event prediction is a vital and challenging task in temporal knowledge graphs (TKGs), which have played crucial roles in various applications. Recently, many graph neural networks based approaches are proposed to model the graph structure information in TKGs. However, these approaches only construct graphs based on quadruplets and model the pairwise correlation between entities, which fail to capture the high-order correlations among entities. To this end, we propose DHyper, a recurrent Dual Hypergraph neural network for event prediction in TKGs, which simultaneously models the influences of the high-order correlations among both entities and relations. Specifically, a dual hypergraph learning module is proposed to discover the high-order correlations among entities and among relations in a parameterized way. A dual hypergraph message passing network is introduced to perform the information aggregation and representation fusion on the entity hypergraph and the relation hypergraph. Extensive experiments on six real-world datasets demonstrate that DHyper achieves the state-of-the-art performances, outperforming the best baseline by an average of 13.09%, 4.26%, 17.60%, and 18.03% in MRR, Hits@1, Hits@3, and Hits@10, respectively.}
}


@article{DBLP:journals/tois/ChenZJH24,
	author = {Junfan Chen and
                  Richong Zhang and
                  Xiaohan Jiang and
                  Chunming Hu},
	title = {SPContrastNet: {A} Self-Paced Contrastive Learning Model for Few-Shot
                  Text Classification},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {130:1--130:25},
	year = {2024},
	url = {https://doi.org/10.1145/3652600},
	doi = {10.1145/3652600},
	timestamp = {Thu, 06 Mar 2025 15:48:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ChenZJH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Meta-learning has recently promoted few-shot text classification, which identifies target classes based on information transferred from source classes through a series of small tasks or episodes. Existing works constructing their meta-learner on Prototypical Networks need improvement in learning discriminative text representations between similar classes that may lead to conflicts in label prediction. The overfitting problems caused by a few training instances need to be adequately addressed. In addition, efficient episode sampling procedures that could enhance few-shot training should be utilized. To address the problems mentioned above, we first present a contrastive learning framework that simultaneously learns discriminative text representations via supervised contrastive learning while mitigating the overfitting problem via unsupervised contrastive regularization, and then we build an efficient self-paced episode sampling approach on top of it to include more difficult episodes as training progresses. Empirical results on eight few-shot text classification datasets show that our model outperforms the current state-of-the-art models. The extensive experimental analysis demonstrates that our supervised contrastive representation learning and unsupervised contrastive regularization techniques improve the performance of few-shot text classification. The episode-sampling analysis reveals that our self-paced sampling strategy improves training efficiency.}
}


@article{DBLP:journals/tois/YangWQZC24,
	author = {Hao Yang and
                  Xian Wu and
                  Zhaopeng Qiu and
                  Yefeng Zheng and
                  Xu Chen},
	title = {Distributional Fairness-aware Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {131:1--131:28},
	year = {2024},
	url = {https://doi.org/10.1145/3652854},
	doi = {10.1145/3652854},
	timestamp = {Tue, 09 Jul 2024 15:32:27 +0200},
	biburl = {https://dblp.org/rec/journals/tois/YangWQZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fairness has been gradually recognized as a significant problem in the recommendation domain. Previous models usually achieve fairness by reducing the average performance gap between different user groups. However, the average performance may not sufficiently represent all the characteristics of the performances in a user group. Thus, equivalent average performance may not mean the recommender model is fair, for example, the variance of the performances can be different. To alleviate this problem, in this article, we define a novel type of fairness, where we require that the performance distributions across different user groups should be similar. We prove that with the same performance distribution, the numerical characteristics of the group performance, including the expectation, variance, and any higher-order moment, are also the same. To achieve distributional fairness, we propose a generative and adversarial training framework. Specifically, we regard the recommender model as the generator to compute the performance for each user in different groups, and then we deploy a discriminator to judge which group the performance is drawn from. By iteratively optimizing the generator and the discriminator, we can theoretically prove that the optimal generator (the recommender model) can indeed lead to the equivalent performance distributions. To smooth the adversarial training process, we propose a novel dual curriculum learning strategy for optimal scheduling of training samples. Additionally, we tailor our framework to better suit top-N recommendation tasks by incorporating softened ranking metrics as measures of performance discrepancies. We conduct extensive experiments based on real-world datasets to demonstrate the effectiveness of our model.}
}


@article{DBLP:journals/tois/ShiRFXYCRC24,
	author = {Chaoyu Shi and
                  Pengjie Ren and
                  Dongjie Fu and
                  Xin Xin and
                  Shansong Yang and
                  Fei Cai and
                  Zhaochun Ren and
                  Zhumin Chen},
	title = {Diversifying Sequential Recommendation with Retrospective and Prospective
                  Transformers},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {132:1--132:37},
	year = {2024},
	url = {https://doi.org/10.1145/3653016},
	doi = {10.1145/3653016},
	timestamp = {Thu, 04 Jul 2024 22:03:10 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ShiRFXYCRC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Previous studies on sequential recommendation (SR) have predominantly concentrated on optimizing recommendation accuracy. However, there remains a significant gap in enhancing recommendation diversity, particularly for short interaction sequences. The limited availability of interaction information in short sequences hampers the recommender’s ability to comprehensively model users’ intents, consequently affecting both the diversity and accuracy of recommendation. In light of the above challenge, we propose  reTrospective and pRospective Transformers for dIversified sEquential Recommendation (TRIER) . The TRIER addresses the issue of insufficient information in short interaction sequences by first retrospectively learning to predict users’ potential historical interactions, thereby introducing additional information and expanding short interaction sequences, and then capturing users’ potential intents from multiple augmented sequences. Finally, the TRIER learns to generate diverse recommendation lists by covering as many potential intents as possible. To evaluate the effectiveness of TRIER, we conduct extensive experiments on three benchmark datasets. The experimental results demonstrate that TRIER significantly outperforms state-of-the-art methods, exhibiting diversity improvement of up to 11.36% in terms of intra-list distance (ILD@5) on the Steam dataset, 3.43% ILD@5 on the Yelp dataset and 3.77% in terms of category coverage (CC@5) on the Beauty dataset. As for accuracy, on the Yelp dataset, we observe notable improvement of 7.62% and 8.63% in HR@5 and NDCG@5, respectively. Moreover, we found that TRIER reveals more significant accuracy and diversity improvement for short interaction sequences.}
}


@article{DBLP:journals/tois/TangZGRCC24,
	author = {Yubao Tang and
                  Ruqing Zhang and
                  Jiafeng Guo and
                  Maarten de Rijke and
                  Wei Chen and
                  Xueqi Cheng},
	title = {Listwise Generative Retrieval Models via a Sequential Learning Process},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {133:1--133:31},
	year = {2024},
	url = {https://doi.org/10.1145/3653712},
	doi = {10.1145/3653712},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/TangZGRCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, a novel generative retrieval (GR) paradigm has been proposed, where a single sequence-to-sequence model is learned to directly generate a list of relevant document identifiers (docids) given a query. Existing GR models commonly employ maximum likelihood estimation (MLE) for optimization: This involves maximizing the likelihood of a single relevant docid given an input query, with the assumption that the likelihood for each docid is independent of the other docids in the list. We refer to these models as the pointwise approach in this article. While the pointwise approach has been shown to be effective in the context of GR, it is considered sub-optimal due to its disregard for the fundamental principle that ranking involves making predictions about lists. In this article, we address this limitation by introducing an alternative listwise approach, which empowers the GR model to optimize the relevance at the docid list level. Specifically, we view the generation of a ranked docid list as a sequence learning process: At each step, we learn a subset of parameters that maximizes the corresponding generation likelihood of the  i th docid given the (preceding) top  i -1 docids. To formalize the sequence learning process, we design a positional conditional probability for GR. To alleviate the potential impact of beam search on the generation quality during inference, we perform relevance calibration on the generation likelihood of model-generated docids according to relevance grades. We conduct extensive experiments on representative binary and multi-graded relevance datasets. Our empirical results demonstrate that our method outperforms state-of-the-art GR baselines in terms of retrieval performance.}
}


@article{DBLP:journals/tois/WenCSYLS24,
	author = {Zhiyuan Wen and
                  Jiannong Cao and
                  Jiaxing Shen and
                  Ruosong Yang and
                  Shuaiqi Liu and
                  Maosong Sun},
	title = {Personality-affected Emotion Generation in Dialog Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {134:1--134:27},
	year = {2024},
	url = {https://doi.org/10.1145/3655616},
	doi = {10.1145/3655616},
	timestamp = {Thu, 04 Jul 2024 22:03:11 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WenCSYLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generating appropriate emotions for responses is essential for dialogue systems to provide human-like interaction in various application scenarios. Most previous dialogue systems tried to achieve this goal by learning empathetic manners from anonymous conversational data. However, emotional responses generated by those methods may be inconsistent, which will decrease user engagement and service quality. Psychological findings suggest that the emotional expressions of humans are rooted in personality traits. Therefore, we propose a new task, Personality-affected Emotion Generation, to generate emotion based on the personality given to the dialogue system and further investigate a solution through the personality-affected mood transition. Specifically, we first construct a daily dialogue dataset, Personality EmotionLines Dataset ( PELD ), with emotion and personality annotations. Subsequently, we analyze the challenges in this task, i.e., (1) heterogeneously integrating personality and emotional factors and (2) extracting multi-granularity emotional information in the dialogue context. Finally, we propose to model the personality as the transition weight by simulating the mood transition process in the dialogue system and solve the challenges above. We conduct extensive experiments on PELD for evaluation. Results suggest that by adopting our method, the emotion generation performance is improved by  13%  in macro-F1 and  5%  in weighted-F1 from the BERT-base model.}
}


@article{DBLP:journals/tois/TianXCLZ24,
	author = {Changxin Tian and
                  Yuexiang Xie and
                  Xu Chen and
                  Yaliang Li and
                  Xin Zhao},
	title = {Privacy-preserving Cross-domain Recommendation with Federated Graph
                  Learning},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {135:1--135:29},
	year = {2024},
	url = {https://doi.org/10.1145/3653448},
	doi = {10.1145/3653448},
	timestamp = {Thu, 04 Jul 2024 22:03:11 +0200},
	biburl = {https://dblp.org/rec/journals/tois/TianXCLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As people inevitably interact with items across multiple domains or various platforms, cross-domain recommendation (CDR) has gained increasing attention. However, the rising privacy concerns limit the practical applications of existing CDR models, since they assume that full or partial data are accessible among different domains. Recent studies on privacy-aware CDR models neglect the heterogeneity from multiple-domain data and fail to achieve consistent improvements in cross-domain recommendation; thus, it remains a challenging task to conduct effective CDR in a privacy-preserving way. In this article, we propose a novel, as far as we know, federated graph learning approach for Privacy-Preserving Cross-Domain Recommendation (PPCDR) to capture users’ preferences based on distributed multi-domain data and improve recommendation performance for all domains without privacy leakage. The main idea of PPCDR is to model both global preference among multiple domains and local preference at a specific domain for a given user, which characterizes the user’s shared and domain-specific tastes toward the items for interaction. Specifically, in the private update process of PPCDR, we design a graph transfer module for each domain to fuse global and local user preferences and update them based on local domain data. In the federated update process, through applying the local differential privacy technique for privacy-preserving, we collaboratively learn global user preferences based on multi-domain data and adapt these global preferences to heterogeneous domain data via personalized aggregation. In this way, PPCDR can effectively approximate the multi-domain training process that directly shares local interaction data in a privacy-preserving way. Extensive experiments on three CDR datasets demonstrate that PPCDR consistently outperforms competitive single- and cross-domain baselines and effectively protects domain privacy.}
}


@article{DBLP:journals/tois/SuDZW24,
	author = {Zhan Su and
                  Zhicheng Dou and
                  Yutao Zhu and
                  Ji{-}Rong Wen},
	title = {Passage-aware Search Result Diversification},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {136:1--136:29},
	year = {2024},
	url = {https://doi.org/10.1145/3653672},
	doi = {10.1145/3653672},
	timestamp = {Thu, 04 Jul 2024 22:03:11 +0200},
	biburl = {https://dblp.org/rec/journals/tois/SuDZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Research on search result diversification strives to enhance the variety of subtopics within the list of search results. Existing studies usually treat a document as a whole and represent it with one fixed-length vector. However, considering that a long document could cover different aspects of a query, using a single vector to represent the document is usually insufficient. To tackle this problem, we propose to exploit multiple passages to better represent documents in search result diversification. Different passages of each document may reflect different subtopics of the query and comparison among the passages can improve result diversity. Specifically, we segment the entire document into multiple passages and train a classifier to filter out the irrelevant ones. Then the document diversity is measured based on several passages that can offer the information needs of the query. Thereafter, we devise a passage-aware search result diversification framework that takes into account the topic information contained in the selected document sequence and candidate documents. The candidate documents’ novelty is evaluated based on their passages while considering the dynamically selected document sequence. We conducted experiments on a commonly utilized dataset, and the results indicate that our proposed method performs better than the most leading methods.}
}


@article{DBLP:journals/tois/ZhangYCSLLX24,
	author = {Xinghua Zhang and
                  Bowen Yu and
                  Xin Cong and
                  Taoyu Su and
                  Quangang Li and
                  Tingwen Liu and
                  Hongbo Xu},
	title = {Cross-Domain {NER} under a Divide-and-Transfer Paradigm},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {137:1--137:32},
	year = {2024},
	url = {https://doi.org/10.1145/3655618},
	doi = {10.1145/3655618},
	timestamp = {Thu, 04 Jul 2024 22:03:11 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ZhangYCSLLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-domain Named Entity Recognition (NER) transfers knowledge learned from a rich-resource source domain to improve the learning in a low-resource target domain. Most existing works are designed based on the sequence labeling framework, defining entity detection and type prediction as a monolithic process. However, they typically ignore the discrepant transferability of these two sub-tasks: the former locating spans corresponding to entities is largely domain-robust, whereas the latter owns distinct entity types across domains. Combining them into an entangled learning problem may contribute to the complexity of domain transfer. In this work, we propose the novel divide-and-transfer paradigm in which different sub-tasks are learned using separate functional modules for respective cross-domain transfer. To demonstrate the effectiveness of divide-and-transfer, we concretely implement two NER frameworks by applying this paradigm with different cross-domain transfer strategies. Experimental results on 10 different domain pairs show the notable superiority of our proposed frameworks. Experimental analyses indicate that significant advantages of the divide-and-transfer paradigm over prior monolithic ones originate from its better performance on low-resource data and a much greater transferability. It gives us a new insight into cross-domain NER. Our code is available on GitHub. 1}
}


@article{DBLP:journals/tois/ZhangWZSY24,
	author = {Yu{-}Xiang Zhang and
                  Junjie Wang and
                  Xinyu Zhu and
                  Tetsuya Sakai and
                  Hayato Yamana},
	title = {{SSR:} Solving Named Entity Recognition Problems via a Single-stream
                  Reasoner},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {138:1--138:28},
	year = {2024},
	url = {https://doi.org/10.1145/3655619},
	doi = {10.1145/3655619},
	timestamp = {Thu, 04 Jul 2024 22:03:11 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ZhangWZSY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information Extraction (IE) focuses on transforming unstructured data into structured knowledge, of which Named Entity Recognition (NER) is a fundamental component. In the realm of Information Retrieval (IR), effectively recognizing entities can substantially enhance the precision of search and recommendation systems. Existing methods frame NER as a sequence labeling task, which requires extra data and, therefore may be limited in terms of sustainability. One promising solution is to employ a Machine Reading Comprehension (MRC) approach for NER tasks, thereby eliminating the dependence on additional data. This process encounters key challenges, including: (1) Unconventional predictions; (2) Inefficient multi-stream processing; (3) Absence of a proficient reasoning strategy. To this end, we present the Single-Stream Reasoner (SSR), a solution utilizing a reasoning strategy and standardized inputs. This yields a type-agnostic solution for both flat and nested NER tasks, without the need for additional data. On ten NER benchmarks, SSR achieved state-of-the-art results, highlighting its robustness. Furthermore, we illustrated its efficiency through convergence, inference speed, and low-resource scenario performance comparisons. Our architecture displays adaptability and can effortlessly merge with various foundational models and reasoning strategies, fostering advancements in both the IR and IE fields.}
}


@article{DBLP:journals/tois/LiuBZWYH24,
	author = {Fei Liu and
                  Chenyang Bu and
                  Haotian Zhang and
                  Le Wu and
                  Kui Yu and
                  Xuegang Hu},
	title = {{FDKT:} Towards an Interpretable Deep Knowledge Tracing via Fuzzy
                  Reasoning},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {139:1--139:26},
	year = {2024},
	url = {https://doi.org/10.1145/3656167},
	doi = {10.1145/3656167},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiuBZWYH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In educational data mining, knowledge tracing (KT) aims to model learning performance based on student knowledge mastery. Deep-learning-based KT models perform remarkably better than traditional KT and have attracted considerable attention. However, most of them lack interpretability, making it challenging to explain why the model performed well in the prediction. In this paper, we propose an interpretable deep KT model, referred to as fuzzy deep knowledge tracing (FDKT) via fuzzy reasoning. Specifically, we formalize continuous scores into several fuzzy scores using the fuzzification module. Then, we input the fuzzy scores into the fuzzy reasoning module (FRM). FRM is designed to deduce the current cognitive ability, based on which the future performance was predicted. FDKT greatly enhanced the intrinsic interpretability of deep-learning-based KT through the interpretation of the deduction of student cognition. Furthermore, it broadened the application of KT to continuous scores. Improved performance with regard to both the advantages of FDKT was demonstrated through comparisons with the state-of-the-art models.}
}


@article{DBLP:journals/tois/ShaoWZLHLW24,
	author = {Pengyang Shao and
                  Le Wu and
                  Kun Zhang and
                  Defu Lian and
                  Richang Hong and
                  Yong Li and
                  Meng Wang},
	title = {Average User-Side Counterfactual Fairness for Collaborative Filtering},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {5},
	pages = {140:1--140:26},
	year = {2024},
	url = {https://doi.org/10.1145/3656639},
	doi = {10.1145/3656639},
	timestamp = {Thu, 04 Jul 2024 22:03:11 +0200},
	biburl = {https://dblp.org/rec/journals/tois/ShaoWZLHLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the user-side fairness issue in Collaborative Filtering (CF) algorithms has gained considerable attention, arguing that results should not discriminate an individual or a sub-user group based on users’ sensitive attributes\xa0(e.g., gender). Researchers have proposed fairness-aware CF models by decreasing statistical associations between predictions and sensitive attributes. A more natural idea is to achieve model fairness from a causal perspective. The remaining challenge is that we have no access to interventions, i.e., the counterfactual world that produces recommendations when each user has changed the sensitive attribute value. To this end, we first borrow the Rubin-Neyman potential outcome framework to define average causal effects of sensitive attributes. Next, we show that removing causal effects of sensitive attributes is equal to average counterfactual fairness in CF. Then, we use the propensity re-weighting paradigm to estimate the average causal effects of sensitive attributes and formulate the estimated causal effects as an additional regularization term. To the best of our knowledge, we are one of the first few attempts to achieve counterfactual fairness from the causal effect estimation perspective in CF, which frees us from building sophisticated causal graphs. Finally, experiments on three real-world datasets show the superiority of our proposed model.}
}


@article{DBLP:journals/tois/LuoLP24,
	author = {Tianze Luo and
                  Yong Liu and
                  Sinno Jialin Pan},
	title = {Collaborative Sequential Recommendations via Multi-view GNN-transformers},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {141:1--141:27},
	year = {2024},
	url = {https://doi.org/10.1145/3649436},
	doi = {10.1145/3649436},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LuoLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential recommendation systems aim to exploit users’ sequential behavior patterns to capture their interaction intentions and improve recommendation accuracy. Existing sequential recommendation methods mainly focus on modeling the items’ chronological relationships in each individual user behavior sequence, which may not be effective in making accurate and robust recommendations. On the one hand, the performance of existing sequential recommendation methods is usually sensitive to the length of a user’s behavior sequence (i.e., the list of a user’s historically interacted items). On the other hand, besides the context information in each individual user behavior sequence, the collaborative information among different users’ behavior sequences is also crucial to make accurate recommendations. However, this kind of information is usually ignored by existing sequential recommendation methods. In this work, we propose a new sequential recommendation framework, which encodes the context information in each individual user behavior sequence as well as the collaborative information among the behavior sequences of different users, through building a local dependency graph for each item. We conduct extensive experiments to compare the proposed model with state-of-the-art sequential recommendation methods on five benchmark datasets. The experimental results demonstrate that the proposed model is able to achieve better recommendation performance than existing methods, by incorporating collaborative information.}
}


@article{DBLP:journals/tois/WangZLWCYL24,
	author = {Zhidan Wang and
                  Lixin Zou and
                  Chenliang Li and
                  Shuaiqiang Wang and
                  Xu Chen and
                  Dawei Yin and
                  Weidong Liu},
	title = {Toward Bias-Agnostic Recommender Systems: {A} Universal Generative
                  Framework},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {142:1--142:30},
	year = {2024},
	url = {https://doi.org/10.1145/3655617},
	doi = {10.1145/3655617},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WangZLWCYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User behavior data, such as ratings and clicks, has been widely used to build personalizing models for recommender systems. However, many unflattering factors\xa0(e.g., popularity, ranking position, users’ selection) significantly affect the performance of the learned recommendation model. Most existing work on unbiased recommendation addressed these biases from sample granularity\xa0(e.g., sample reweighting, data augmentation) or from the perspective of representation learning\xa0(e.g., bias-modeling). However, these methods are usually designed for a specific bias, lacking the universal capability to handle complex situations where multiple biases co-exist. Besides, rare work frees itself from laborious and sophisticated debiasing configurations\xa0(e.g., propensity scores, imputed values, or user behavior-generating process). Towards this research gap, in this article, we propose a universal  G enerative framework for  B ias  D isentanglement termed as  GBD , constantly generating calibration perturbations for the intermediate representations during training to keep them from being affected by the bias. Specifically, a bias-identifier that tries to retrieve the bias-related information from the representations is first introduced. Subsequently, the calibration perturbations are generated to significantly deteriorate the bias-identifier’s performance, making the bias gradually disentangled from the calibrated representations. Therefore, without relying on notorious debiasing configurations, a bias-agnostic model is obtained under the guidance of the bias identifier. We further present its universality by subsuming the representative biases and their mixture under the proposed framework. Finally, extensive experiments on the real-world, synthetic, and semi-synthetic datasets have demonstrated the superiority of the proposed approach against a wide range of recommendation debiasing methods. The code is available at  https://github.com/Zhidan-Wang/GBD .}
}


@article{DBLP:journals/tois/WangMGZ24,
	author = {Quan Wang and
                  Zhendong Mao and
                  Jie Gao and
                  Yongdong Zhang},
	title = {Document-level Relation Extraction with Progressive Self-distillation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {143:1--143:34},
	year = {2024},
	url = {https://doi.org/10.1145/3656168},
	doi = {10.1145/3656168},
	timestamp = {Mon, 14 Apr 2025 15:38:16 +0200},
	biburl = {https://dblp.org/rec/journals/tois/WangMGZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Document-level relation extraction (RE) aims to simultaneously predict relations (including no-relation cases denoted as NA) between all entity pairs in a document. It is typically formulated as a relation classification task with entities pre-detected in advance and solved by a hard-label training regime, which, however, neglects the divergence of the NA class and the correlations among other classes. This article introduces  progressive self-distillation  (PSD), a new training regime that employs online, self-knowledge distillation (KD) to produce and incorporate soft labels for document-level RE.The key idea of PSD is to gradually soften hard labels using past predictions from an RE model itself, which are adjusted adaptively as training proceeds. As such, PSD has to learn only one RE model within a single training pass, requiring no extra computation or annotation to pretrain another high-capacity teacher. PSD is conceptually simple, easy to implement, and generally applicable to various RE models to further improve their performance, without introducing additional parameters or significantly increasing training overheads into the models. It is also a general framework that can be flexibly extended to distilling various types of knowledge, rather than being restricted to soft labels themselves. Extensive experiments on four benchmarking datasets verify the effectiveness and generality of the proposed approach. The code is available at  https://github.com/GaoJieCN/psd}
}


@article{DBLP:journals/tois/ZhuoQHDLW24,
	author = {Xingrui Zhuo and
                  Shengsheng Qian and
                  Jun Hu and
                  Fuxin Dai and
                  Kangyi Lin and
                  Gongqing Wu},
	title = {Multi-Hop Multi-View Memory Transformer for Session-Based Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {144:1--144:28},
	year = {2024},
	url = {https://doi.org/10.1145/3663760},
	doi = {10.1145/3663760},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhuoQHDLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A Session-Based Recommendation (SBR) seeks to predict users’ future item preferences by analyzing their interactions with previously clicked items. In recent approaches, Graph Neural Networks (GNNs) have been commonly applied to capture item relations within a session to infer user intentions. However, these GNN-based methods typically struggle with feature ambiguity between the sequential session information and the item conversion within an item graph, which may impede the model’s ability to accurately infer user intentions. In this article, we propose a novel Multi-hop Multi-view Memory Transformer (M 3 T) to effectively integrate the sequence-view information and relation conversion (graph-view information) of items in a session. First, we propose a Multi-view Memory Transformer (M 2 T) module to concurrently obtain multi-view information of items. Then, a set of trainable memory matrices are employed to store sharable item features, which mitigates cross-view item feature ambiguity. To comprehensively capture latent user intentions, an M 3 T framework is designed to integrate user intentions across different hops of an item graph. Specifically, a k-order power method is proposed to manage the item graph to alleviate the over-smoothing problem when obtaining high-order relations of items. Extensive experiments conducted on three real-world datasets demonstrate the superiority of our method.}
}


@article{DBLP:journals/tois/ZengJLZHZPQLLF24,
	author = {Kaisheng Zeng and
                  Hailong Jin and
                  Xin Lv and
                  Fangwei Zhu and
                  Lei Hou and
                  Yi Zhang and
                  Fan Pang and
                  Yu Qi and
                  Dingxiao Liu and
                  Juanzi Li and
                  Ling Feng},
	title = {{XLORE} 3: {A} Large-Scale Multilingual Knowledge Graph from Heterogeneous
                  Wiki Knowledge Resources},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {145:1--145:47},
	year = {2024},
	url = {https://doi.org/10.1145/3660521},
	doi = {10.1145/3660521},
	timestamp = {Sun, 19 Jan 2025 15:03:42 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZengJLZHZPQLLF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, knowledge graph (KG) has attracted significant attention from academia and industry, resulting in the development of numerous technologies for KG construction, completion, and application. XLORE is one of the largest multilingual KGs built from Baidu Baike and Wikipedia via a series of knowledge modeling and acquisition methods. In this article, we utilize systematic methods to improve XLORE's data quality and present its latest version, XLORE 3, which enables the effective integration and management of heterogeneous knowledge from diverse resources. Compared with previous versions, XLORE 3 has three major advantages: (1) We design a comprehensive and reasonable schema, namely XLORE ontology, which can effectively organize and manage entities from various resources. (2) We merge equivalent entities in different languages to facilitate knowledge sharing. We provide a large-scale entity linking system to establish the associations between unstructured text and structured KG. (3) We design a multi-strategy knowledge completion framework, which leverages pre-trained language models and vast amounts of unstructured text to discover missing and new facts. The resulting KG contains 446 concepts, 2,608 properties, 66 million entities, and more than 2 billion facts. It is available and downloadable online at  https://www.xlore.cn/ , providing a valuable resource for researchers and practitioners in various fields.}
}


@article{DBLP:journals/tois/WangGLLC24,
	author = {Yanan Wang and
                  Yong Ge and
                  Zhepeng Li and
                  Li Li and
                  Rui Chen},
	title = {M\({}^{\mbox{3}}\)Rec: {A} Context-Aware Offline Meta-Level Model-Based
                  Reinforcement Learning Approach for Cold-Start Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {146:1--146:27},
	year = {2024},
	url = {https://doi.org/10.1145/3659947},
	doi = {10.1145/3659947},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/WangGLLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reinforcement learning (RL) has shown great promise in optimizing long-term user interest in recommender systems. However, existing RL-based recommendation methods need a large number of interactions for each user to learn the recommendation policy. The challenge becomes more critical when recommending to new users who have a limited number of interactions. To that end, in this article, we address the cold-start challenge in the RL-based recommender systems by proposing a novel context-aware offline meta-level model-based RL approach for user adaptation. Our proposed approach learns to infer each user's preference with a user context variable that enables recommendation systems to better adapt to new users with limited contextual information. To improve adaptation efficiency, our approach learns to recover the user choice function and reward from limited contextual information through an inverse RL method, which is used to assist the training of a meta-level recommendation agent. To avoid the need for online interaction, the proposed method is trained using historically collected offline data. Moreover, to tackle the challenge of offline policy training, we introduce a mutual information constraint between the user model and recommendation agent. Evaluation results show the superiority of our developed offline policy learning method when adapting to new users with limited contextual information. In addition, we provide a theoretical analysis of the recommendation performance bound.}
}


@article{DBLP:journals/tois/ShiZYWD24,
	author = {Chuan Shi and
                  Meiqi Zhu and
                  Yue Yu and
                  Xiao Wang and
                  Junping Du},
	title = {Unifying Graph Neural Networks with a Generalized Optimization Framework},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {147:1--147:32},
	year = {2024},
	url = {https://doi.org/10.1145/3660852},
	doi = {10.1145/3660852},
	timestamp = {Fri, 21 Feb 2025 15:09:17 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ShiZYWD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have received considerable attention on graph-structured data learning for a wide variety of tasks. The well-designed propagation mechanism, which has been demonstrated effective, is the most fundamental part of GNNs. Although most of the GNNs basically follow a message passing manner, little effort has been made to discover and analyze their essential relations. In this article, we establish a surprising connection between different propagation mechanisms with an optimization problem. We show that despite the proliferation of various GNNs, in fact, their proposed propagation mechanisms are the optimal solutions of a generalized optimization framework with a flexible feature fitting function and a generalized graph regularization term. Actually, the optimization framework can not only help understand the propagation mechanisms of GNNs but also open up opportunities for flexibly designing new GNNs. Through analyzing the general solutions of the optimization framework, we provide a more convenient way for deriving corresponding propagation results of GNNs. We further discover that existing works usually utilize naïve graph convolutional kernels for feature fitting function or just utilize one-hop structural information (original topology graph) for graph regularization term. Correspondingly, we develop two novel objective functions considering adjustable graph kernels showing low-pass or high-pass filtering capabilities and one novel objective function considering high-order structural information during propagation, respectively. Extensive experiments on benchmark datasets clearly show that the newly proposed GNNs not only outperform the state-of-the-art methods but also have good ability to alleviate over-smoothing and further verify the feasibility for designing GNNs with the generalized unified optimization framework.}
}


@article{DBLP:journals/tois/PengZHHLYY24,
	author = {Hao Peng and
                  Jingyun Zhang and
                  Xiang Huang and
                  Zhifeng Hao and
                  Angsheng Li and
                  Zhengtao Yu and
                  Philip S. Yu},
	title = {Unsupervised Social Bot Detection via Structural Information Theory},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {148:1--148:42},
	year = {2024},
	url = {https://doi.org/10.1145/3660522},
	doi = {10.1145/3660522},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/PengZHHLYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Research on social bot detection plays a crucial role in maintaining the order and reliability of information dissemination while increasing trust in social interactions. The current mainstream social bot detection models rely on black-box neural network technology, for example, Graph Neural Network, Transformer, and so on, which lacks interpretability. In this work, we present UnDBot, a novel unsupervised, interpretable, yet effective, and practical framework for detecting social bots. This framework is built upon structural information theory. We begin by designing three social relationship metrics that capture various aspects of social bot behaviors:  posting type distribution ,  posting influence , and  follow-to-follower ratio . Three new relationships are utilized to construct a new, unified, and weighted social multi-relational graph, aiming to model the relevance of social user behaviors and discover long-distance correlations between users. Second, we introduce a novel method for optimizing heterogeneous structural entropy. This method involves the personalized aggregation of edge information from the social multi-relational graph to generate a two-dimensional encoding tree. The heterogeneous structural entropy facilitates decoding of the substantial structure of the social bots network and enables hierarchical clustering of social bots. Third, a new community labeling method is presented to distinguish social bot communities by computing the user’s stationary distribution, measuring user contributions to network structure, and counting the intensity of user aggregation within the community. Compared with 10 representative social bot detection approaches, comprehensive experiments demonstrate the advantages of effectiveness and interpretability of UnDBot on 4 real social network datasets.}
}


@article{DBLP:journals/tois/ShiLMSHN24,
	author = {Haitao Shi and
                  Meng Liu and
                  Xiaoxuan Mu and
                  Xuemeng Song and
                  Yupeng Hu and
                  Liqiang Nie},
	title = {Breaking Through the Noisy Correspondence: {A} Robust Model for Image-Text
                  Matching},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {149:1--149:26},
	year = {2024},
	url = {https://doi.org/10.1145/3662732},
	doi = {10.1145/3662732},
	timestamp = {Mon, 03 Feb 2025 08:45:16 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ShiLMSHN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unleashing the power of image-text matching in real-world applications is hampered by noisy correspondence. Manually curating high-quality datasets is expensive and time-consuming, and datasets generated using diffusion models are not adequately well-aligned. The most promising way is to collect image-text pairs from the Internet, but it will inevitably introduce noisy correspondence. To reduce the negative impact of noisy correspondence, we propose a novel model that first transforms the noisy correspondence filtering problem into a similarity distribution modeling problem by exploiting the powerful capabilities of pre-trained models. Specifically, we use the Gaussian Mixture model to model the similarity obtained by CLIP as clean distribution and noisy distribution, to filter out most of the noisy correspondence in the dataset. Afterward, we used relatively clean data to fine-tune the model. To further reduce the negative impact of unfiltered noisy correspondence, i.e., a minimal part where two distributions intersect during the fine-tuning process, we propose a distribution-sensitive dynamic margin ranking loss, further increasing the distance between the two distributions. Through continuous iteration, the noisy correspondence gradually decreases and the model performance gradually improves. Our extensive experiments demonstrate the effectiveness and robustness of our model even under high noise rates.}
}


@article{DBLP:journals/tois/ChenWMJY24,
	author = {Xiaocong Chen and
                  Siyu Wang and
                  Julian J. McAuley and
                  Dietmar Jannach and
                  Lina Yao},
	title = {On the Opportunities and Challenges of Offline Reinforcement Learning
                  for Recommender Systems},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {150:1--150:26},
	year = {2024},
	url = {https://doi.org/10.1145/3661996},
	doi = {10.1145/3661996},
	timestamp = {Fri, 07 Feb 2025 13:01:40 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ChenWMJY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reinforcement learning serves as a potent tool for modeling dynamic user interests within recommender systems, garnering increasing research attention of late. However, a significant drawback persists: its poor data efficiency, stemming from its interactive nature. The training of reinforcement learning-based recommender systems demands expensive online interactions to amass adequate trajectories, essential for agents to learn user preferences. This inefficiency renders reinforcement learning-based recommender systems a formidable undertaking, necessitating the exploration of potential solutions. Recent strides in offline reinforcement learning present a new perspective. Offline reinforcement learning empowers agents to glean insights from offline datasets and deploy learned policies in online settings. Given that recommender systems possess extensive offline datasets, the framework of offline reinforcement learning aligns seamlessly. Despite being a burgeoning field, works centered on recommender systems utilizing offline reinforcement learning remain limited. This survey aims to introduce and delve into offline reinforcement learning within recommender systems, offering an inclusive review of existing literature in this domain. Furthermore, we strive to underscore prevalent challenges, opportunities, and future pathways, poised to propel research in this evolving field.}
}


@article{DBLP:journals/tois/BruchNIL24a,
	author = {Sebastian Bruch and
                  Franco Maria Nardini and
                  Amir Ingber and
                  Edo Liberty},
	title = {Bridging Dense and Sparse Maximum Inner Product Search},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {151:1--151:38},
	year = {2024},
	url = {https://doi.org/10.1145/3665324},
	doi = {10.1145/3665324},
	timestamp = {Sun, 25 May 2025 13:43:34 +0200},
	biburl = {https://dblp.org/rec/journals/tois/BruchNIL24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximum inner product search (MIPS) over dense and sparse vectors have progressed independently in a bifurcated literature for decades; the latter is better known as top- 𝑘  retrieval in Information Retrieval. This duality exists because sparse and dense vectors serve different end goals. That is despite the fact that they are manifestations of the same mathematical problem. In this work, we ask if algorithms for dense vectors could be applied effectively to sparse vectors, particularly those that violate the assumptions underlying top- 𝑘  retrieval methods. We study clustering-based approximate MIPS where vectors are partitioned into clusters and only a fraction of clusters are searched during retrieval. We conduct a comprehensive analysis of dimensionality reduction for sparse vectors, and examine standard and spherical  k -means for partitioning. Our experiments demonstrate that clustering-based retrieval serves as an efficient solution for sparse MIPS. As byproducts, we identify two research opportunities and explore their potential. First, we cast the clustering-based paradigm as dynamic pruning and turn that insight into a novel organization of the inverted index for approximate MIPS over general sparse vectors. Second, we offer a unified regime for MIPS over vectors that have dense and sparse subspaces, that is robust to query distributions.}
}


@article{DBLP:journals/tois/AnGT24,
	author = {Jingmin An and
                  Ming Gao and
                  Jiafu Tang},
	title = {MvStHgL: Multi-View Hypergraph Learning with Spatial-Temporal Periodic
                  Interests for Next {POI} Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {152:1--152:29},
	year = {2024},
	url = {https://doi.org/10.1145/3664651},
	doi = {10.1145/3664651},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/AnGT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Providing potential next point-of-interest (POI) suggestions for users has become a prominent task in location-based social networks, which receives more and more attention from the industry and academia and it remains challenging due to highly dynamic and personalized interactions in user movements. Currently, state-of-the-art works develop various graph- and sequential-based learning methods to model user-POI interactions and transition regularities. However, there are still two significant shortcomings in these works: (1) ignoring personalized spatial and temporal-aspect interactive characteristics capable of exhibiting periodic interests of users and (2) insufficiently leveraging the sequential patterns of interactions for beyond-pairwise high-order collaborative signals among users’ sequences. To jointly address these challenges, we propose a novel multi-view hypergraph learning with spatial-temporal periodic interests for next POI recommendation (MvStHgL). In the local view, we attempt to learn the POI representation of each interaction via jointing periodic characteristics of spatial and temporal aspects. In the global view, we design a hypergraph by regarding interactive sequences as hyperedges to capture high-order collaborative signals across users, for further POI representations. More specifically, the output of POI representations in the local view is used for the initialized embedding, and the aggregation and propagation in the hypergraph are performed by a novel Node-to-Hypergraph-to-Node scheme. Furthermore, the captured POI embeddings are applied to achieve sequential dependency modeling for next POI prediction. Extensive experiments on three real-world datasets demonstrate that our proposed model outperforms the state-of-the-art models.}
}


@article{DBLP:journals/tois/SunLQ24,
	author = {Ke Sun and
                  Chenliang Li and
                  Tieyun Qian},
	title = {City Matters! {A} Dual-Target Cross-City Sequential {POI} Recommendation
                  Model},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {153:1--153:27},
	year = {2024},
	url = {https://doi.org/10.1145/3664284},
	doi = {10.1145/3664284},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/SunLQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing sequential  Point of Interest (POI)  recommendation methods overlook a fact that each city exhibits distinct characteristics and totally ignore the city signature. In this study, we claim that city matters in sequential POI recommendation and fully exploring city signature can highlight the characteristics of each city and facilitate cross-city complementary learning. To this end, we consider the two-city scenario and propose a  Dual-Target Cross-City Sequential POI Recommendation  model  (DCSPR)  to achieve the purpose of complementary learning across cities. On one hand,  DCSPR  respectively captures  geographical and cultural characteristics  for each city by mining intra-city regions and intra-city functions of POIs. On the other hand,  DCSPR  builds  a transfer channel  between cities based on intra-city functions, and adopts a novel transfer strategy to transfer useful cultural characteristics across cities by mining inter-city functions of POIs. Moreover, to utilize these captured characteristics for sequential POI recommendation,  DCSPR  involves a new  region- and function-aware network  for each city to learn transition patterns from multiple views. Extensive experiments conducted on two real-world datasets with four cities demonstrate the effectiveness of  DCSPR .}
}


@article{DBLP:journals/tois/ZhangWYHJGC24,
	author = {Yabin Zhang and
                  Zhenlei Wang and
                  Wenhui Yu and
                  Lantao Hu and
                  Peng Jiang and
                  Kun Gai and
                  Xu Chen},
	title = {Soft Contrastive Sequential Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {154:1--154:28},
	year = {2024},
	url = {https://doi.org/10.1145/3665325},
	doi = {10.1145/3665325},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangWYHJGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contrastive learning has recently emerged as an effective strategy for improving the performance of sequential recommendation. However, traditional models commonly construct the contrastive loss by directly optimizing human-designed positive and negative samples, resulting in a model that is overly sensitive to heuristic rules. To address this limitation, we propose a novel soft contrastive framework for sequential recommendation in this article. Our main idea is to extend the point-wise contrast to a region-level comparison, where we aim to identify instances near the initially selected positive/negative samples that exhibit similar contrastive properties. This extension improves the model’s robustness to human heuristics. To achieve this objective, we introduce an adversarial contrastive loss that allows us to explore the sample regions more effectively. Specifically, we begin by considering the user behavior sequence as a holistic entity. We construct adversarial samples by introducing a continuous perturbation vector to the sequence representation. This perturbation vector adds variability to the sequence, enabling more flexible exploration of the sample regions. Moreover, we extend the aforementioned strategy by applying perturbations directly to the items within the sequence. This accounts for the sequential nature of the items. To capture these sequential relationships, we utilize a recurrent neural network to associate the perturbations, which introduces an inductive bias for more efficient exploration of adversarial samples. To demonstrate the effectiveness of our model, we conduct extensive experiments on five real-world datasets.}
}


@article{DBLP:journals/tois/ZhouYDTWCW24,
	author = {Yujia Zhou and
                  Jing Yao and
                  Zhicheng Dou and
                  Yiteng Tu and
                  Ledell Wu and
                  Tat{-}Seng Chua and
                  Ji{-}Rong Wen},
	title = {{ROGER:} Ranking-Oriented Generative Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {155:1--155:25},
	year = {2024},
	url = {https://doi.org/10.1145/3603167},
	doi = {10.1145/3603167},
	timestamp = {Sun, 19 Jan 2025 15:03:43 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhouYDTWCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, various dense retrieval methods have been developed to improve the performance of search engines with a vectorized index. However, these approaches require a large pre-computed index and have a limited capacity to memorize all semantics in a document within a single vector. To address these issues, researchers have explored end-to-end generative retrieval models that use a seq-to-seq generative model to directly return identifiers of relevant documents. Although these models have been effective, they are often trained with the MLE method. It only encourages the model to assign a high probability to the relevant document identifier, ignoring the relevance comparisons of other documents. This may lead to performance degradation in ranking tasks, where the core is to compare the relevance between documents. To address this issue, we propose a ranking-oriented generative retrieval model that incorporates relevance signals to better estimate the relative relevance of different documents in ranking tasks. Based upon the analysis of the optimization objectives of dense retrieval and generative retrieval, we propose utilizing dense retrieval to provide relevance feedback for generative retrieval. Under an alternate training framework, the generative retrieval model gradually acquires higher-quality ranking signals to optimize the model. Experimental results show that our approach increasing Recall@1 by 12.9% with respect to the baselines on MS MARCO dataset.}
}


@article{DBLP:journals/tois/ChenYCYHY24,
	author = {Lijian Chen and
                  Wei Yuan and
                  Tong Chen and
                  Guanhua Ye and
                  Nguyen Quoc Viet Hung and
                  Hongzhi Yin},
	title = {Adversarial Item Promotion on Visually-Aware Recommender Systems by
                  Guided Diffusion},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {156:1--156:26},
	year = {2024},
	url = {https://doi.org/10.1145/3666088},
	doi = {10.1145/3666088},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ChenYCYHY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visually-aware recommender systems have found widespread applications in domains where visual elements significantly contribute to the inference of users’ potential preferences. While the incorporation of visual information holds the promise of enhancing recommendation accuracy and alleviating the cold-start problem, it is essential to point out that the inclusion of item images may introduce substantial security challenges. Some existing works have shown that the item provider can manipulate item exposure rates to its advantage by constructing adversarial images. However, these works cannot reveal the real vulnerability of visually-aware recommender systems because (1) the generated adversarial images are markedly distorted, rendering them easily detected by human observers; and (2) the effectiveness of these attacks is inconsistent and even ineffective in some scenarios or datasets. To shed light on the real vulnerabilities of visually-aware recommender systems when confronted with adversarial images, this article introduces a novel attack method, Item Promotion by Diffusion Generated Image (IPDGI). Specifically, IPDGI employs a guided diffusion model to generate adversarial samples designed to promote the exposure rates of target items (e.g., long-tail items). Taking advantage of accurately modeling benign images’ distribution by diffusion models, the generated adversarial images have high fidelity with original images, ensuring the stealth of our IPDGI. To demonstrate the effectiveness of our proposed methods, we conduct extensive experiments on two commonly used e-commerce recommendation datasets (Amazon Beauty and Amazon Baby) with several typical visually-aware recommender systems. The experimental results show that our attack method significantly improves both the performance of promoting the long-tailed (i.e., unpopular) items and the quality of generated adversarial images.}
}


@article{DBLP:journals/tois/JiangXYYWLZX24,
	author = {Yiheng Jiang and
                  Yuanbo Xu and
                  Yongjian Yang and
                  Funing Yang and
                  Pengyang Wang and
                  Chaozhuo Li and
                  Fuzhen Zhuang and
                  Hui Xiong},
	title = {TriMLP: {A} Foundational MLP-Like Architecture for Sequential Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {157:1--157:34},
	year = {2024},
	url = {https://doi.org/10.1145/3670995},
	doi = {10.1145/3670995},
	timestamp = {Wed, 02 Apr 2025 17:03:42 +0200},
	biburl = {https://dblp.org/rec/journals/tois/JiangXYYWLZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we present  TriMLP  as a foundational MLP-like architecture for the sequential recommendation, simultaneously achieving computational efficiency and promising performance. First, we empirically study the incompatibility between existing purely MLP-based models and sequential recommendation, that the inherent fully-connective structure endows historical user–item interactions (referred as tokens) with unrestricted communications and overlooks the essential chronological order in sequences. Then, we propose the MLP-based  Triangular Mixer  to establish ordered contact among tokens and excavate the primary sequential modeling capability under the standard auto-regressive training fashion. It contains (1) a global mixing layer that drops the lower-triangle neurons in MLP to block the anti-chronological connections from future tokens and (2) a local mixing layer that further disables specific upper-triangle neurons to split the sequence as multiple independent sessions. The mixer serially alternates these two layers to support fine-grained preferences modeling, where the global one focuses on the long-range dependency in the whole sequence, and the local one calls for the short-term patterns in sessions. Experimental results on 12 datasets of different scales from 4 benchmarks elucidate that  TriMLP  consistently attains favorable accuracy/efficiency tradeoff over all validated datasets, where the average performance boost against several state-of-the-art baselines achieves up to 14.88%, and the maximum reduction of inference time reaches 23.73%. The intriguing properties render  TriMLP  a strong contender to the well-established RNN-, CNN-, and Transformer-based sequential recommenders. Code is available at  https://github.com/jiangyiheng1/TriMLP .}
}


@article{DBLP:journals/tois/LinZCFSCLW24,
	author = {Siyi Lin and
                  Sheng Zhou and
                  Jiawei Chen and
                  Yan Feng and
                  Qihao Shi and
                  Chun Chen and
                  Ying Li and
                  Can Wang},
	title = {ReCRec: Reasoning the Causes of Implicit Feedback for Debiased Recommendation},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {158:1--158:26},
	year = {2024},
	url = {https://doi.org/10.1145/3672275},
	doi = {10.1145/3672275},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LinZCFSCLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Implicit feedback (e.g., user clicks) is widely used in building recommender systems (RS). However, the inherent notorious  exposure bias  significantly affects recommendation performance. Exposure bias refers a phenomenon that implicit feedback is influenced by user exposure and does not precisely reflect user preference. Current methods for addressing exposure bias primarily reduce confidence in unclicked data, employ exposure models, or leverage propensity scores. Regrettably, these approaches often lead to biased estimations or elevated model variance, yielding sub-optimal results. To overcome these limitations, we propose a new method  ReCRec  that  Reasons the  C auses behind the implicit feedback for debiased R ec ommendation . ReCRec identifies three scenarios behind unclicked data—i.e., unexposed, dislike, or a combination of both. A reasoning module is employed to infer the category to which each instance pertains. Consequently, the model is capable of extracting reliable positive and negative signals from unclicked data, thereby facilitating more accurate learning of user preferences. We also conduct thorough theoretical analyses to demonstrate the debiased nature and low variance of ReCRec. Extensive experiments on both semi-synthetic and real-world datasets validate its superiority over state-of-the-art methods.}
}


@article{DBLP:journals/tois/FanJZS24,
	author = {Yu{-}Chen Fan and
                  Yitong Ji and
                  Jie Zhang and
                  Aixin Sun},
	title = {Our Model Achieves Excellent Performance on MovieLens: What Does It
                  Mean?},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {159:1--159:25},
	year = {2024},
	url = {https://doi.org/10.1145/3675163},
	doi = {10.1145/3675163},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/FanJZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A typical benchmark dataset for recommender system (RecSys) evaluation consists of user-item interactions generated on a platform within a time period. The interaction generation mechanism partially explains why a user interacts with (e.g., like, purchase, rate) an item, and the context of when a particular interaction happened. In this study, we conduct a meticulous analysis of the MovieLens dataset and explain the potential impact of using the dataset for evaluating recommendation algorithms. We make a few main findings from our analysis. First, there are significant differences in user interactions at the different stages when a user interacts with the MovieLens platform. The early interactions largely define the user portrait which affect the subsequent interactions. Second, user interactions are highly affected by the candidate movies that are recommended by the platform's internal recommendation algorithm(s). Third, changing the order of user interactions makes it more difficult for sequential algorithms to capture the progressive interaction process. We further discuss the discrepancy between the interaction generation mechanism that is employed by the MovieLens system and that of typical real-world recommendation scenarios. That is, the MovieLens dataset records  ⟨ 𝑢 \u2062 𝑠 \u2062 𝑒 \u2062 𝑟 − 𝑀 \u2062 𝑜 \u2062 𝑣 \u2062 𝑖 \u2062 𝑒 \u2062 𝐿 \u2062 𝑒 \u2062 𝑛 \u2062 𝑠 ⟩  interactions, but not  ⟨ 𝑢 \u2062 𝑠 \u2062 𝑒 \u2062 𝑟 − 𝑚 \u2062 𝑜 \u2062 𝑣 \u2062 𝑖 \u2062 𝑒 ⟩  interactions. All research articles using the MovieLens dataset model the  ⟨ 𝑢 \u2062 𝑠 \u2062 𝑒 \u2062 𝑟 − 𝑀 \u2062 𝑜 \u2062 𝑣 \u2062 𝑖 \u2062 𝑒 \u2062 𝐿 \u2062 𝑒 \u2062 𝑛 \u2062 𝑠 ⟩  rather than the  ⟨ 𝑢 \u2062 𝑠 \u2062 𝑒 \u2062 𝑟 − 𝑚 \u2062 𝑜 \u2062 𝑣 \u2062 𝑖 \u2062 𝑒 ⟩  interactions, making their results less generalizable to many practical recommendation scenarios in real-world settings. In summary, the MovieLens platform demonstrates an efficient and effective way of collecting user preferences to address cold-starts. However,  models that achieve excellent recommendation accuracy on the MovieLens dataset may not demonstrate superior performance in practice , for at least two kinds of differences: (1) the differences in the contexts of user-item interaction generation, and (2) the differences in user knowledge about the item collections. While results on MovieLens can be useful as a reference, they should not be solely relied upon as the primary justification for the effectiveness of a recommendation system model.}
}


@article{DBLP:journals/tois/ZouYYSDW24,
	author = {Tao Zou and
                  Le Yu and
                  Junchen Ye and
                  Leilei Sun and
                  Bowen Du and
                  Deqing Wang},
	title = {Adaptive Taxonomy Learning and Historical Patterns Modeling for Patent
                  Classification},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {160:1--160:24},
	year = {2024},
	url = {https://doi.org/10.1145/3674834},
	doi = {10.1145/3674834},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZouYYSDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Patent classification aims to assign multiple International Patent Classification (IPC) codes to a given patent. Existing methods for automated patent classification primarily focus on analyzing the text descriptions of patents. However, apart from the textual information, each patent is also associated with some assignees, and the knowledge of their previously applied patents can often be valuable for accurate classification. Furthermore, the hierarchical taxonomy defined by the IPC system provides crucial contextual information and enables models to leverage the correlations between IPC codes for improved classification accuracy. However, existing methods fail to incorporate the above aspects and lead to reduced performance. To address these limitations, we propose an integrated framework that comprehensively considers patent-related information for patent classification. To be specific, we first present an IPC codes correlations learning module to capture both horizontal and vertical information within the IPC codes. This module effectively captures the correlations by adaptively exchanging and aggregating messages among IPC codes at the same level (horizontal information) and from both parent and children codes (vertical information), which allows for a comprehensive integration of knowledge and relationships within the IPC hierarchical taxonomy. Additionally, we design a historical application patterns learning component to incorporate previous patents of the corresponding assignee by aggregating high-order temporal information via a dual-channel graph neural network. Finally, our approach combines the contextual information from patent texts, which encompasses the semantics of IPC codes, with assignees’ sequential preferences to make predictions. Experimental evaluations on real-world datasets demonstrate the superiority of our proposed approach over existing methods. Moreover, we present the model’s ability to capture the temporal patterns of assignees and the semantic dependencies among IPC codes.}
}


@article{DBLP:journals/tois/ZhangWS24,
	author = {Chen Zhang and
                  Benyou Wang and
                  Dawei Song},
	title = {On Elastic Language Models},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {161:1--161:29},
	year = {2024},
	url = {https://doi.org/10.1145/3677375},
	doi = {10.1145/3677375},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZhangWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large-scale pretrained language models have achieved compelling performance in a wide range of language understanding and information retrieval tasks. While their large scales ensure capacity, they also hinder deployment. Knowledge distillation offers an opportunity to compress a large language model to a small one, in order to reach a reasonable latency-performance tradeoff. However, for scenarios where the number of requests (e.g., queries submitted to a search engine) is highly variant, the static tradeoff attained by the compressed language model might not always fit. Once a model is assigned with a static tradeoff, it could be inadequate in that the latency is too high when the number of requests is large, or the performance is too low when the number of requests is small. To this end, we propose an elastic language model ( ElasticLM ) that elastically adjusts the tradeoff according to the request stream. The basic idea is to introduce a compute elasticity to the compressed language model, so that the tradeoff could vary on-the-fly along a scalable and controllable compute. Specifically, we impose an elastic structure to equip  ElasticLM  with compute elasticity and design an elastic optimization method to learn  ElasticLM  under compute elasticity. To serve  ElasticLM , we apply an elastic schedule. Considering the specificity of information retrieval, we adapt  ElasticLM  to dense retrieval and reranking, and present an  ElasticDenser  and an  ElasticRanker,  respectively. Offline evaluation is conducted on a language understanding benchmark GLUE, and several information retrieval tasks including Natural Question, Trivia QA and MS MARCO. The results show that  ElasticLM  along with  ElasticDenser  and  ElasticRanker  can perform correctly and competitively compared with an array of static baselines. Furthermore, an online simulation with concurrency is also carried out. The results demonstrate that  ElasticLM  can provide elastic tradeoffs with respect to varying request stream.}
}


@article{DBLP:journals/tois/ZouSLK24,
	author = {Jie Zou and
                  Aixin Sun and
                  Cheng Long and
                  Evangelos Kanoulas},
	title = {Knowledge-Enhanced Conversational Recommendation via Transformer-Based
                  Sequential Modeling},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {162:1--162:27},
	year = {2024},
	url = {https://doi.org/10.1145/3677376},
	doi = {10.1145/3677376},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/ZouSLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In conversational recommender systems (CRSs), conversations usually involve a set of items and item-related entities or attributes, e.g., director is a related entity of a movie. These items and item-related entities are often mentioned along the development of a dialog, leading to potential sequential dependencies among them. However, most of existing CRSs neglect these potential sequential dependencies. In this article, we first propose a Transformer-based sequential conversational recommendation method, named TSCR, to model the sequential dependencies in the conversations to improve CRS. In TSCR, we represent conversations by items and the item-related entities, and construct user sequences to discover user preferences by considering both the mentioned items and item-related entities. Based on the constructed sequences, we deploy a Cloze task to predict the recommended items along a sequence. Meanwhile, in certain domains, knowledge graphs formed by the items and their related entities are readily available, which provide various different kinds of associations among them. Given that TSCR does not benefit from such knowledge graphs, we then propose a knowledge graph enhanced version of TSCR, called TSCRKG. In specific, we leverage the knowledge graph to offline initialize our model TSCRKG, and augment the user sequence of conversations (i.e., sequence of the mentioned items and item-related entities in the conversation) with multi-hop paths in the knowledge graph. Experimental results demonstrate that our TSCR model significantly outperforms state-of-the-art baselines, and the enhanced version TSCRKG further improves recommendation performance on top of TSCR.}
}


@article{DBLP:journals/tois/XuYCC24,
	author = {Jingyun Xu and
                  Junnan Yu and
                  Yi Cai and
                  Tat{-}Seng Chua},
	title = {Dual Contrastive Learning for Cross-Domain Named Entity Recognition},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {163:1--163:33},
	year = {2024},
	url = {https://doi.org/10.1145/3678879},
	doi = {10.1145/3678879},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/XuYCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Benefiting many information retrieval applications, named entity recognition (NER) has shown impressive progress. Recently, there has been a growing trend to decompose complex NER tasks into two subtasks (e.g., entity span detection (ESD) and entity type classification (ETC), to achieve better performance. Despite the remarkable success, from the perspective of representation, existing methods do not explicitly distinguish non-entities and entities, which may lead to ESD errors. Meanwhile, they do not explicitly distinguish entities with different entity types, which may lead to entity type misclassification. As such, the limited representation abilities may challenge some competitive NER methods, leading to unsatisfactory performance, especially in the low-resource setting (e.g., cross-domain NER). In light of these challenges, we propose to utilize contrastive learning to refine the original chaotic representations and learn the generalized representations for cross-domain NER. In particular, this article proposes a dual contrastive learning model (Dual-CL), which respectively utilizes a token-level contrastive learning module and a sentence-level contrastive learning module to enhance ESD, ETC for cross-domain NER. Empirical results on 10 domain pairs under two different settings show that Dual-CL achieves better performances than compared baselines in terms of several standard metrics. Moreover, we conduct detailed analyses to are presented to better understand each component’s effectiveness.}
}


@article{DBLP:journals/tois/JarvelinS24,
	author = {Kalervo J{\"{a}}rvelin and
                  Eero Sormunen},
	title = {A Blueprint of {IR} Evaluation Integrating Task and User Characteristics},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {164:1--164:38},
	year = {2024},
	url = {https://doi.org/10.1145/3675162},
	doi = {10.1145/3675162},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/JarvelinS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional search result evaluation metrics in information retrieval, such as MAP and NDCG, naively focus on topical relevance between a document and search topic and assume this relationship as mono-dimensional and often binary. They neglect document content overlap and assume gains piling up as the searcher examines the ranked list at greater length. We propose a novel search result evaluation framework based on multidimensional, graded relevance assessments, explicit modelling of document overlaps and attributes affecting document usability beyond relevance. Document relevance to a search task is seen to consist of several content themes and document usability attributes. Documents may also overlap regarding their content themes. Attributes such as document readability, trustworthiness, or language represent the entire document’s usability in the search task context, for a given searcher and her motivating task. The proposed framework evaluates the quality of a ranked search result, taking into account the contribution of each successive document, with estimated overlap across themes, and usability based on its attributes.}
}


@article{DBLP:journals/tois/PeiYRR24,
	author = {Jiahuan Pei and
                  Guojun Yan and
                  Maarten de Rijke and
                  Pengjie Ren},
	title = {Mixture-of-Languages Routing for Multilingual Dialogues},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {165:1--165:33},
	year = {2024},
	url = {https://doi.org/10.1145/3676956},
	doi = {10.1145/3676956},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/PeiYRR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider multilingual dialogue systems and ask how the performance of a dialogue system can be improved by using information that is available in other languages than the language in which a conversation is being conducted. We adopt a collaborative chair-experts framework, where each expert agent can be either monolingual or cross-lingual, and a chair agent follows a mixture-of-experts procedure for globally optimizing multilingual task-oriented dialogue systems. We propose a mixture-of-languages routing framework that includes four functional components, i.e., input embeddings of multilingual dialogues, language model, pairwise alignment between the representation of every two languages, and mixture-of-languages. We quantify language characteristics of unity and diversity using a number of similarity metrics, i.e., genetic similarity and word and sentence similarity based on embeddings. Our main finding is that the performance of multilingual task-oriented dialogue systems can be greatly impacted by three key aspects, i.e., data sufficiency, language characteristics, and model design in a mixture-of-languages routing framework.}
}


@article{DBLP:journals/tois/KeshvariSYE24,
	author = {Sanaz Keshvari and
                  Farzan Saeedi and
                  Hadi Sadoghi Yazdi and
                  Faezeh Ensan},
	title = {A Self-Distilled Learning to Rank Model for \emph{Ad Hoc} Retrieval},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {166:1--166:28},
	year = {2024},
	url = {https://doi.org/10.1145/3681784},
	doi = {10.1145/3681784},
	timestamp = {Wed, 08 Jan 2025 21:11:38 +0100},
	biburl = {https://dblp.org/rec/journals/tois/KeshvariSYE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learning to rank models are broadly applied in  ad hoc  retrieval for scoring and sorting documents based on their relevance to textual queries. The generalizability of the trained model in the learning to rank approach, however, can have an impact on the retrieval performance, particularly when data includes noise and outliers, or is incorrectly collected or measured. In this paper, we introduce a Self-Distilled Learning to Rank (SDLR) framework for  ad hoc  retrieval, and analyze its performance over a range of retrieval datasets and also in the presence of features’ noise. SDLR assigns a confidence weight to each training sample, aiming at reducing the impact of noisy and outlier data in the training process. The confidence weight is approximated based on the feature’s distributions derived from the values observed for the features of the documents labeled for a query in a listwise training sample. SDLR includes a distillation process that facilitates passing on the underlying patterns in assigning confidence weights from the teacher model to the student one. We empirically illustrate that SDLR outperforms state-of-the-art learning to rank models in  ad hoc  retrieval. We thoroughly investigate the SDLR performance in different settings including when no distillation strategy is applied; when different portion of data are used for training the teacher and the student models, and when both teacher and student models are trained over identical data. We show that SDLR is more effective when training data are split between a teacher and a student model. We also show that SDLR’s performance is robust when data features are noisy.}
}


@article{DBLP:journals/tois/LiuZCNK24,
	author = {Fan Liu and
                  Shuai Zhao and
                  Zhiyong Cheng and
                  Liqiang Nie and
                  Mohan S. Kankanhalli},
	title = {Cluster-Based Graph Collaborative Filtering},
	journal = {{ACM} Trans. Inf. Syst.},
	volume = {42},
	number = {6},
	pages = {167:1--167:24},
	year = {2024},
	url = {https://doi.org/10.1145/3687481},
	doi = {10.1145/3687481},
	timestamp = {Thu, 30 Jan 2025 15:34:58 +0100},
	biburl = {https://dblp.org/rec/journals/tois/LiuZCNK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Convolution Networks (GCNs) have significantly succeeded in learning user and item representations for recommendation systems. The core of their efficacy is the ability to explicitly exploit the collaborative signals from both the first- and high-order neighboring nodes. However, most existing GCN-based methods overlook the multiple interests of users while performing high-order graph convolution. Thus, the noisy information from unreliable neighbor nodes (e.g., users with dissimilar interests) negatively impacts the representation learning of the target node. Additionally, conducting graph convolution operations without differentiating high-order neighbors suffers the over-smoothing issue when stacking more layers, resulting in performance degradation. In this article, we aim to capture more valuable information from high-order neighboring nodes while avoiding noise for better representation learning of the target node. To achieve this goal, we propose a novel GCN-based recommendation model, termed Cluster-based Graph Collaborative Filtering (ClusterGCF). This model performs high-order graph convolution on cluster-specific graphs, which are constructed by capturing the multiple interests of users and identifying the common interests among them. Specifically, we design an unsupervised and optimizable soft node clustering approach to classify user and item nodes into multiple clusters. Based on the soft node clustering results and the topology of the user–item interaction graph, we assign the nodes with probabilities for different clusters to construct the cluster-specific graphs. To evaluate the effectiveness of ClusterGCF, we conducted extensive experiments on four publicly available datasets. Experimental results demonstrate that our model can significantly improve recommendation performance.}
}
