@article{DBLP:journals/toit/SingalLGRKGK22,
	author = {Gaurav Singal and
                  Vijay Laxmi and
                  Manoj Singh Gaur and
                  D. Vijay Rao and
                  Riti Kushwaha and
                  Deepak Garg and
                  Neeraj Kumar},
	title = {QoS-aware Mesh-based Multicast Routing Protocols in Edge Ad Hoc Networks:
                  Concepts and Challenges},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {1:1--1:27},
	year = {2022},
	url = {https://doi.org/10.1145/3428150},
	doi = {10.1145/3428150},
	timestamp = {Wed, 07 Dec 2022 23:03:34 +0100},
	biburl = {https://dblp.org/rec/journals/toit/SingalLGRKGK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multicast communication plays a pivotal role in Edge based Mobile Ad hoc Networks\xa0(MANETs). MANETs can provide low-cost self-configuring devices for multimedia data communication that can be used in military battlefield, disaster management, connected living, and public safety networks. A Multicast communication should increase the network performance by decreasing the bandwidth consumption, battery power, and routing overhead. In recent years, a number of multicast routing protocols\xa0(MRPs) have been proposed to resolve above listed challenges. Some of them are used for dynamic establishment of reliable route for multimedia data communication. This article provides a detailed survey of the merits and demerits of the recently developed techniques. An ample study of various Quality of Service\xa0(QoS) techniques and enhancement is also presented. Later, mesh topology-based MRPs are classified according to enhancement in routing mechanism and QoS modification. This article covers the most recent, robust, and reliable QoS-aware mesh based MRPs, classified on the basis of their operational features, and pros and cons. Finally, a comparative study has been presented on the basis of their performance parameters on the proposed protocols.}
}


@article{DBLP:journals/toit/BibiAMKD22,
	author = {Iram Bibi and
                  Adnan Akhunzada and
                  Jahanzaib Malik and
                  Muhammad Khurram Khan and
                  Muhammad Dawood},
	title = {Secure Distributed Mobile Volunteer Computing with Android},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {2:1--2:21},
	year = {2022},
	url = {https://doi.org/10.1145/3428151},
	doi = {10.1145/3428151},
	timestamp = {Sat, 30 Sep 2023 10:29:29 +0200},
	biburl = {https://dblp.org/rec/journals/toit/BibiAMKD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Volunteer Computing provision of seamless connectivity that enables convenient and rapid deployment of greener and cheaper computing infrastructure is extremely promising to complement next-generation distributed computing systems. Undoubtedly, without tactile Internet and secure VC ecosystems, harnessing its full potentials and making it an alternative viable and reliable computing infrastructure is next to impossible. Android-enabled smart devices, applications, and services are inevitable for Volunteer computing. Contrarily, the progressive developments of sophisticated Android malware may reduce its exponential growth. Besides, Android malwares are considered the most potential and persistent cyber threat to mobile VC systems. To secure Android-based mobile volunteer computing, the authors proposed MulDroid, an efficient and self-learning autonomous hybrid (Long-Short-Term Memory, Convolutional Neural Network, Deep Neural Network) multi-vector Android malware threat detection framework. The proposed mechanism is highly scalable with well-coordinated infrastructure and self-optimizing capabilities to proficiently tackle fast-growing dynamic variants of sophisticated malware threats and attacks with 99.01% detection accuracy. For a comprehensive evaluation, the authors employed current state-of-the-art malware datasets (Android Malware Dataset, Androzoo) with standard performance evaluation metrics. Moreover, MulDroid is compared with our constructed contemporary hybrid DL-driven architectures and benchmark algorithms. Our proposed mechanism outperforms in terms of detection accuracy with a trivial tradeoff speed efficiency. Additionally, a 10-fold cross-validation is performed to explicitly show unbiased results.}
}


@article{DBLP:journals/toit/ChenLWHP22,
	author = {Chen Chen and
                  Lei Liu and
                  Shaohua Wan and
                  Xiaozhe Hui and
                  Qingqi Pei},
	title = {Data Dissemination for Industry 4.0 Applications in Internet of Vehicles
                  Based on Short-term Traffic Prediction},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {3:1--3:18},
	year = {2022},
	url = {https://doi.org/10.1145/3430505},
	doi = {10.1145/3430505},
	timestamp = {Mon, 28 Aug 2023 21:41:18 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ChenLWHP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a key use case of Industry 4.0 and the Smart City, the Internet of Vehicles (IoV) provides an efficient way for city managers to regulate the traffic flow, improve the commuting performance, reduce the transportation facility cost, alleviate the traffic jam, and so on. In fact, the significant development of Internet of Vehicles has boosted the emergence of a variety of Industry 4.0 applications, e.g., smart logistics, intelligent transforation, and autonomous driving. The prerequisite of deploying these applications is the design of efficient data dissemination schemes by which the interactive information could be effectively exchanged. However, in Internet of Vehicles, an efficient data scheme should adapt to the high node movement and frequent network changing. To achieve the objective, the ability to predict short-term traffic is crucial for making optimal policy in advance. In this article, we propose a novel data dissemination scheme by exploring short-term traffic prediction for Industry 4.0 applications enabled in Internet of Vehicles. First, we present a three-tier network architecture with the aim to simply network management and reduce communication overheads. To capture dynamic network changing, a deep learning network is employed by the controller in this architecture to predict short-term traffic with the availability of enormous traffic data. Based on the traffic prediction, each road segment can be assigned a weight through the built two-dimensional delay model, enabling the controller to make routing decisions in advance. With the global weight information, the controller leverages the ant colony optimization algorithm to find the optimal routing path with minimum delay. Extensive simulations are carried out to demonstrate the accuracy of the traffic prediction model and the superiority of the proposed data dissemination scheme for Industry 4.0 applications.}
}


@article{DBLP:journals/toit/LinHLSWH22,
	author = {Weiwei Lin and
                  Tiansheng Huang and
                  Xin Li and
                  Fang Shi and
                  Xiumin Wang and
                  Ching{-}Hsien Hsu},
	title = {Energy-Efficient Computation Offloading for UAV-Assisted {MEC:} {A}
                  Two-Stage Optimization Scheme},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {4:1--4:23},
	year = {2022},
	url = {https://doi.org/10.1145/3430503},
	doi = {10.1145/3430503},
	timestamp = {Sun, 06 Aug 2023 20:51:07 +0200},
	biburl = {https://dblp.org/rec/journals/toit/LinHLSWH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In addition to the stationary mobile edge computing (MEC) servers, a few MEC surrogates that possess a certain mobility and computation capacity, e.g., flying unmanned aerial vehicles (UAVs) and private vehicles, have risen as powerful counterparts for service provision. In this article, we design a two-stage online scheduling scheme, targeting computation offloading in a UAV-assisted MEC system. On our stage-one formulation, an online scheduling framework is proposed for dynamic adjustment of mobile users' CPU frequency and their transmission power, aiming at producing a socially beneficial solution to users. But the major impediment during our investigation lies in that users might not unconditionally follow the scheduling decision released by servers as a result of their individual rationality. In this regard, we formulate each step of online scheduling on stage one into a non-cooperative game with potential competition over the limited radio resource. As a solution, a centralized online scheduling algorithm, called ONCCO, is proposed, which significantly promotes social benefit on the basis of the users' individual rationality. On our stage-two formulation, we are working towards the optimization of UAV computation resource provision, aiming at minimizing the energy consumption of UAVs during such a process, and correspondingly, another algorithm, called WS-UAV, is given as a solution. Finally, extensive experiments via numerical simulation are conducted for an evaluation purpose, by which we show that our proposed algorithms achieve satisfying performance enhancement in terms of energy conservation and sustainable service provision.}
}


@article{DBLP:journals/toit/JiangHCWZC22,
	author = {Nan Jiang and
                  Debin Huang and
                  Jing Chen and
                  Jie Wen and
                  Heng Zhang and
                  Honglong Chen},
	title = {Semi-Direct Monocular Visual-Inertial Odometry Using Point and Line
                  Features for IoV},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {5:1--5:23},
	year = {2022},
	url = {https://doi.org/10.1145/3432248},
	doi = {10.1145/3432248},
	timestamp = {Fri, 22 Sep 2023 09:27:54 +0200},
	biburl = {https://dblp.org/rec/journals/toit/JiangHCWZC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The precise measuring of vehicle location has been a critical task in enhancing the autonomous driving in terms of intelligent decision making and safe transportation. Internet of Vehicles (IoV) is an important infrastructure in support of autonomous driving, allowing real-time road information exchanging and sharing for localizing vehicles. Global positioning System (GPS) is widely used in the traditional IoV system. GPS is unable to meet the key application requirements of autonomous driving due to meter level error and signal deterioration. In this article, we propose a novel solution, named Semi-Direct Monocular Visual-Inertial Odometry using Point and Line Features (SDMPL-VIO) for precise vehicle localization. Our SDMPL-VIO model takes advantage of a low-cost Inertial Measurement Unit (IMU) and monocular camera, using them as the sensor to acquire the surrounding environmental information. Visual-Inertial Odometry (VIO), taking into account both point and line features, is proposed, which is able to deal with both weak texture and dynamic environment. We use a semi-direct method to deal with keyframes and non-keyframes, respectively. Dual sliding window mechanisms can effectively fuse point-line and IMU information. To evaluate our SDMPL-VIO system model, we conduct extensive experiments on both an indoor dataset (i.e., EuRoC) and an outdoor dataset (i.e., KITTI) from the real-world applications, respectively. The experimental results show that the accuracy of SDMPL-VIO proposed by us is better than the mainstream VIO system at present. Especially in the weak texture of the datasets, fast-moving datasets, and other challenging datasets, SDMPL-VIO has a relatively high robustness.}
}


@article{DBLP:journals/toit/JunaidSAA22,
	author = {Muhammad Junaid and
                  Adnan Sohail and
                  Fadi M. Al{-}Turjman and
                  Rashid Ali},
	title = {Agile Support Vector Machine for Energy-efficient Resource Allocation
                  in IoT-oriented Cloud using {PSO}},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {6:1--6:35},
	year = {2022},
	url = {https://doi.org/10.1145/3433541},
	doi = {10.1145/3433541},
	timestamp = {Sun, 02 Oct 2022 15:51:54 +0200},
	biburl = {https://dblp.org/rec/journals/toit/JunaidSAA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the years cloud computing has seen significant evolution in terms of improvement in infrastructure and resource provisioning. However the continuous emergence of new applications such as the Internet of Things (IoTs) with thousands of users put a significant load on cloud infrastructure. Load balancing of resource allocation in cloud-oriented IoT is a critical factor that has a significant impact on the smooth operation of cloud services and customer satisfaction. Several load balancing strategies for cloud environment have been proposed in the past. However the existing approaches mostly consider only a few parameters and ignore many critical factors having a pivotal role in load balancing leading to less optimized resource allocation. Load balancing is a challenging problem and therefore the research community has recently focused towards employing machine learning-based metaheuristic approaches for load balancing in the cloud. In this paper we propose a metaheuristics-based scheme Data Format Classification using Support Vector Machine (DFC-SVM), to deal with the load balancing problem. The proposed scheme aims to reduce the online load balancing complexity by offline-based pre-classification of raw-data from diverse sources (such as IoT) into different formats e.g. text images media etc. SVM is utilized to classify “n” types of data formats featuring audio video text digital images and maps etc. A one-to-many classification approach has been developed so that data formats from the cloud are initially classified into their respective classes and assigned to virtual machines through the proposed modified version of Particle Swarm Optimization (PSO) which schedules the data of a particular class efficiently. The experimental results compared with the baselines have shown a significant improvement in the performance of the proposed approach. Overall an average of 94% classification accuracy is achieved along with 11.82% less energy 16% less response time and 16.08% fewer SLA violations are observed.}
}


@article{DBLP:journals/toit/AymanSWPDL22,
	author = {Afiya Ayman and
                  Amutheezan Sivagnanam and
                  Michael Wilbur and
                  Philip Pugliese and
                  Abhishek Dubey and
                  Aron Laszka},
	title = {Data-Driven Prediction and Optimization of Energy Use for Transit
                  Fleets of Electric and {ICE} Vehicles},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {7:1--7:29},
	year = {2022},
	url = {https://doi.org/10.1145/3433992},
	doi = {10.1145/3433992},
	timestamp = {Thu, 18 Nov 2021 15:35:11 +0100},
	biburl = {https://dblp.org/rec/journals/toit/AymanSWPDL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the high upfront cost of electric vehicles, many public transit agencies can afford only mixed fleets of internal combustion and electric vehicles. Optimizing the operation of such mixed fleets is challenging because it requires accurate trip-level predictions of electricity and fuel use as well as efficient algorithms for assigning vehicles to transit routes. We present a novel framework for the data-driven prediction of trip-level energy use for mixed-vehicle transit fleets and for the optimization of vehicle assignments, which we evaluate using data collected from the bus fleet of CARTA, the public transit agency of Chattanooga, TN. We first introduce a data collection, storage, and processing framework for system-level and high-frequency vehicle-level transit data, including domain-specific data cleansing methods. We train and evaluate machine learning models for energy prediction, demonstrating that deep neural networks attain the highest accuracy. Based on these predictions, we formulate the problem of minimizing energy use through assigning vehicles to fixed-route transit trips. We propose an optimal integer program as well as efficient heuristic and meta-heuristic algorithms, demonstrating the scalability and performance of these algorithms numerically using the transit network of CARTA.}
}


@article{DBLP:journals/toit/VerdeBPFS22,
	author = {Laura Verde and
                  Nadia Brancati and
                  Giuseppe De Pietro and
                  Maria Frucci and
                  Giovanna Sannino},
	title = {A Deep Learning Approach for Voice Disorder Detection for Smart Connected
                  Living Environments},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {8:1--8:16},
	year = {2022},
	url = {https://doi.org/10.1145/3433993},
	doi = {10.1145/3433993},
	timestamp = {Wed, 15 Dec 2021 10:32:36 +0100},
	biburl = {https://dblp.org/rec/journals/toit/VerdeBPFS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge Analytics and Artificial Intelligence are important features of the current smart connected living community. In a society where people, homes, cities, and workplaces are simultaneously connected through various devices, primarily through mobile devices, a considerable amount of data is exchanged, and the processing and storage of these data are laborious and difficult tasks. Edge Analytics allows the collection and analysis of such data on mobile devices, such as smartphones and tablets, without involving any cloud-centred architecture that cannot guarantee real-time responsiveness. Meanwhile, Artificial Intelligence techniques can constitute a valid instrument to process data, limiting the computation time, and optimising decisional processes and predictions in several sectors, such as healthcare. Within this field, in this article, an approach able to evaluate the voice quality condition is proposed. A fully automatic algorithm, based on Deep Learning, classifies a voice as healthy or pathological by analysing spectrogram images extracted by means of the recording of vowel /a/, in compliance with the traditional medical protocol. A light Convolutional Neural Network is embedded in a mobile health application in order to provide an instrument capable of assessing voice disorders in a fast, easy, and portable way. Thus, a straightforward mobile device becomes a screening tool useful for the early diagnosis, monitoring, and treatment of voice disorders. The proposed approach has been tested on a broad set of voice samples, not limited to the most common voice diseases but including all the pathologies present in three different databases achieving F1-scores, over the testing set, equal to 80%, 90%, and 73%. Although the proposed network consists of a reduced number of layers, the results are very competitive compared to those of other “cutting edge” approaches constructed using more complex neural networks, and compared to the classic deep neural networks, for example, VGG-16 and ResNet-50.}
}


@article{DBLP:journals/toit/KumarGAR22,
	author = {Rahul Kumar and
                  Ankur Gupta and
                  Harkirat Singh Arora and
                  Balasubramanian Raman},
	title = {{IBRDM:} An Intelligent Framework for Brain Tumor Classification Using
                  Radiomics- and DWT-based Fusion of {MRI} Sequences},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {9:1--9:30},
	year = {2022},
	url = {https://doi.org/10.1145/3434775},
	doi = {10.1145/3434775},
	timestamp = {Wed, 15 Dec 2021 10:32:36 +0100},
	biburl = {https://dblp.org/rec/journals/toit/KumarGAR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Brain tumors are one of the critical malignant neurological cancers with the highest number of deaths and injuries worldwide. They are categorized into two major classes, high-grade glioma (HGG) and low-grade glioma (LGG), with HGG being more aggressive and malignant, whereas LGG tumors are less aggressive, but if left untreated, they get converted to HGG. Thus, the classification of brain tumors into the corresponding grade is a crucial task, especially for making decisions related to treatment. Motivated by the importance of such critical threats to humans, we propose a novel framework for brain tumor classification using discrete wavelet transform-based fusion of MRI sequences and Radiomics feature extraction. We utilized the Brain Tumor Segmentation 2018 challenge training dataset for the performance evaluation of our approach, and we extract features from three regions of interest derived using a combination of several tumor regions. We used wrapper method-based feature selection techniques for selecting a significant set of features and utilize various machine learning classifiers, Random Forest, Decision Tree, and Extra Randomized Tree for training the model. For proper validation of our approach, we adopt the five-fold cross-validation technique. We achieved state-of-the-art performance considering several performance metrics, 〈Acc, Sens, Spec, F1-score, MCC, AUC 〉 ≡ 〈 98.60%, 99.05%, 97.33%, 99.05%, 96.42%, 98.19% 〉, where Acc, Sens, Spec, F1-score, MCC, and AUC represents the accuracy, sensitivity, specificity, F1-score, Matthews correlation coefficient, and area-under-the-curve, respectively. We believe our proposed approach will play a crucial role in the planning of clinical treatment and guidelines before surgery.}
}


@article{DBLP:journals/toit/QiaoZDG22,
	author = {Yanchen Qiao and
                  Weizhe Zhang and
                  Xiaojiang Du and
                  Mohsen Guizani},
	title = {Malware Classification Based on Multilayer Perception and Word2Vec
                  for IoT Security},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {10:1--10:22},
	year = {2022},
	url = {https://doi.org/10.1145/3436751},
	doi = {10.1145/3436751},
	timestamp = {Sat, 09 Apr 2022 12:33:23 +0200},
	biburl = {https://dblp.org/rec/journals/toit/QiaoZDG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the construction of smart cities, the number of Internet of Things (IoT) devices is growing rapidly, leading to an explosive growth of malware designed for IoT devices. These malware pose a serious threat to the security of IoT devices. The traditional malware classification methods mainly rely on feature engineering. To improve accuracy, a large number of different types of features will be extracted from malware files in these methods. That brings a high complexity to the classification. To solve these issues, a malware classification method based on Word2Vec and Multilayer Perception (MLP) is proposed in this article. First, for one malware sample, Word2Vec is used to calculate a word vector for all bytes of the binary file and all instructions in the assembly file. Second, we combine these vectors into a 256x256x2-dimensional matrix. Finally, we designed a deep learning network structure based on MLP to train the model. Then the model is used to classify the testing samples. The experimental results prove that the method has a high accuracy of 99.54%.}
}


@article{DBLP:journals/toit/MajorHCF22,
	author = {David J. Major and
                  Danny Yuxing Huang and
                  Marshini Chetty and
                  Nick Feamster},
	title = {Alexa, Who Am {I} Speaking To?: Understanding Users' Ability to Identify
                  Third-Party Apps on Amazon Alexa},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {11:1--11:22},
	year = {2022},
	url = {https://doi.org/10.1145/3446389},
	doi = {10.1145/3446389},
	timestamp = {Thu, 18 Nov 2021 15:35:11 +0100},
	biburl = {https://dblp.org/rec/journals/toit/MajorHCF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many Internet of Things devices have voice user interfaces. One of the most popular voice user interfaces is Amazon’s Alexa, which supports more than 50,000 third-party applications (“skills”). We study how Alexa’s integration of these skills may confuse users. Our survey of 237 participants found that users do not understand that skills are often operated by third parties, that they often confuse third-party skills with native Alexa functions, and that they are unaware of the functions that the native Alexa system supports. Surprisingly, users who interact with Alexa more frequently are more likely to conclude that a third-party skill is a native Alexa function. The potential for misunderstanding creates new security and privacy risks: attackers can develop third-party skills that operate without users’ knowledge or masquerade as native Alexa functions. To mitigate this threat, we make design recommendations to help users better distinguish native functionality and third-party skills, including audio and visual indicators of native and third-party contexts, as well as a consistent design standard to help users learn what functions are and are not possible on Alexa.}
}


@article{DBLP:journals/toit/DaajiOGBM22,
	author = {Marwa Daaji and
                  Ali Ouni and
                  Mohamed Mohsen Gammoudi and
                  Salah Bouktif and
                  Mohamed Wiem Mkaouer},
	title = {Multi-criteria Web Services Selection: Balancing the Quality of Design
                  and Quality of Service},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {12:1--12:31},
	year = {2022},
	url = {https://doi.org/10.1145/3446388},
	doi = {10.1145/3446388},
	timestamp = {Thu, 23 Jun 2022 20:04:04 +0200},
	biburl = {https://dblp.org/rec/journals/toit/DaajiOGBM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web service composition allows developers to create applications via reusing available services that are interoperable to each other. The process of selecting relevant Web services for a composite service satisfying the developer requirements is commonly acknowledged to be hard and challenging, especially with the exponentially increasing number of available Web services on the Internet. The majority of existing approaches on Web Services Selection are merely based on the Quality of Service (QoS) as a basic criterion to guide the selection process. However, existing approaches tend to ignore the service design quality, which plays a crucial role in discovering, understanding, and reusing service functionalities. Indeed, poorly designed Web service interfaces result in service anti-patterns, which are symptoms of bad design and implementation practices. The existence of anti-pattern instances in Web service interfaces typically complicates their reuse in real-world service-based systems and may lead to several maintenance and evolution problems. To address this issue, we introduce a new approach based on the Multi-Objective and Optimization on the basis of Ratio Analysis method (MOORA) as a multi-criteria decision making (MCDM) method to select Web services based on a combination of their (1) QoS attributes and (2) QoS design. The proposed approach aims to help developers to maintain the soundness and quality of their service composite development processes. We conduct a quantitative and qualitative empirical study to evaluate our approach on a Quality of Web Service dataset. We compare our MOORA-based approach against four commonly used MCDM methods as well as a recent state-of-the-art Web service selection approach. The obtained results show that our approach outperforms state-of-the-art approaches by significantly improving the service selection quality of top-k selected services while providing the best trade-off between both service design quality and desired QoS values. Furthermore, we conducted a qualitative evaluation with developers. The obtained results provide evidence that our approach generates a good trade-off for what developers need regarding both QoS and quality of design. Our selection approach was evaluated as “relevant” from developers point of view, in improving the service selection task with an average score of 3.93, compared to an average of 2.62 for the traditional QoS-based approach.}
}


@article{DBLP:journals/toit/MistryQB22,
	author = {Sajib Mistry and
                  Lie Qu and
                  Athman Bouguettaya},
	title = {Layer-based Composite Reputation Bootstrapping},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {13:1--13:28},
	year = {2022},
	url = {https://doi.org/10.1145/3448610},
	doi = {10.1145/3448610},
	timestamp = {Sat, 25 Dec 2021 15:52:28 +0100},
	biburl = {https://dblp.org/rec/journals/toit/MistryQB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a novel generic reputation bootstrapping framework for composite services. Multiple reputation-related indicators are considered in a layer-based framework to implicitly reflect the reputation of the component services. The importance of an indicator on the future performance of a component service is learned using a modified Random Forest algorithm. We propose a topology-aware Forest Deep Neural Network (fDNN) to find the correlations between the reputation of a composite service and reputation indicators of component services. The trained fDNN model predicts the reputation of a new composite service with the confidence value. Experimental results with real-world dataset prove the efficiency of the proposed approach.}
}


@article{DBLP:journals/toit/ZendehdelKCSS22,
	author = {Ghazale Amel Zendehdel and
                  Ratinder Kaur and
                  Inderpreet Chopra and
                  Natalia Stakhanova and
                  Erik J. Scheme},
	title = {Automated Security Assessment Framework for Wearable BLE-enabled Health
                  Monitoring Devices},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {14:1--14:31},
	year = {2022},
	url = {https://doi.org/10.1145/3448649},
	doi = {10.1145/3448649},
	timestamp = {Thu, 13 Jan 2022 08:43:38 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ZendehdelKCSS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growth of IoT technology, increasing prevalence of embedded devices, and advancements in biomedical technology have led to the emergence of numerous wearable health monitoring devices (WHMDs) in clinical settings and in the community. The majority of these devices are Bluetooth Low Energy (BLE) enabled. Though the advantages offered by BLE-enabled WHMDs in tracking, diagnosing, and intervening with patients are substantial, the risk of cyberattacks on these devices is likely to increase with device complexity and new communication protocols. Furthermore, vendors face risk and financial tradeoffs between speed to market and ensuring device security in all situations. Previous research has explored the security and privacy of such devices by manually testing popular BLE-enabled WHMDs in the market and generally discussed categories of possible attacks, while mostly focused on IP devices. In this work, we propose a new semi-automated framework that can be used to identify and discover both known and unknown vulnerabilities in WHMDs. To demonstrate its implementation, we validate it with a number of commercially available BLE-enabled enabled wearable devices. Our results show that the devices are vulnerable to a number of attacks, including eavesdropping, data manipulation, and denial of service attacks. The proposed framework could therefore be used to evaluate potential devices before adoption into a secure network or, ideally, during the design and implementation of new devices.}
}


@article{DBLP:journals/toit/DaileyCLMZMLT22,
	author = {Ryan Dailey and
                  Aniesh Chawla and
                  Andrew Liu and
                  Sripath Mishra and
                  Ling Zhang and
                  Josh Majors and
                  Yung{-}Hsiang Lu and
                  George K. Thiruvathukal},
	title = {Automated Discovery of Network Cameras in Heterogeneous Web Pages},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {15:1--15:25},
	year = {2022},
	url = {https://doi.org/10.1145/3450629},
	doi = {10.1145/3450629},
	timestamp = {Thu, 18 Nov 2021 15:35:11 +0100},
	biburl = {https://dblp.org/rec/journals/toit/DaileyCLMZMLT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reduction in the cost of Network Cameras along with a rise in connectivity enables entities all around the world to deploy vast arrays of camera networks. Network cameras offer real-time visual data that can be used for studying traffic patterns, emergency response, security, and other applications. Although many sources of Network Camera data are available, collecting the data remains difficult due to variations in programming interface and website structures. Previous solutions rely on manually parsing the target website, taking many hours to complete. We create a general and automated solution for aggregating Network Camera data spread across thousands of uniquely structured web pages. We analyze heterogeneous web page structures and identify common characteristics among 73 sample Network Camera websites (each website has multiple web pages). These characteristics are then used to build an automated camera discovery module that crawls and aggregates Network Camera data. Our system successfully extracts 57,364 Network Cameras from 237,257 unique web pages.}
}


@article{DBLP:journals/toit/AbououfSOMD22,
	author = {Menatalla Abououf and
                  Shakti Singh and
                  Hadi Otrok and
                  Rabeb Mizouni and
                  Ernesto Damiani},
	title = {Machine Learning in Mobile Crowd Sourcing: {A} Behavior-Based Recruitment
                  Model},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {16:1--16:28},
	year = {2022},
	url = {https://doi.org/10.1145/3451163},
	doi = {10.1145/3451163},
	timestamp = {Thu, 18 Nov 2021 15:35:11 +0100},
	biburl = {https://dblp.org/rec/journals/toit/AbououfSOMD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advent of mobile crowd sourcing (MCS) systems and its applications, the selection of the right crowd is gaining utmost importance. The increasing variability in the context of MCS tasks makes the selection of not only the capable but also the willing workers crucial for a high task completion rate. Most of the existing MCS selection frameworks rely primarily on reputation-based feedback mechanisms to assess the level of commitment of potential workers. Such frameworks select workers having high reputation scores but without any contextual awareness of the workers, at the time of selection, or the task. This may lead to an unfair selection of workers who will not perform the task. Hence, reputation on its own only gives an approximation of workers’ behaviors since it assumes that workers always behave consistently regardless of the situational context. However, following the concept of cross-situational consistency, where people tend to show similar behavior in similar situations and behave differently in disparate ones, this work proposes a novel recruitment system in MCS based on behavioral profiling. The proposed approach uses machine learning to predict the probability of the workers performing a given task, based on their learned behavioral models. Subsequently, a group-based selection mechanism, based on the genetic algorithm, uses these behavioral models in complementation with a reputation-based model to recruit a group of workers that maximizes the quality of recruitment of the tasks. Simulations based on a real-life dataset show that considering human behavior in varying situations improves the quality of recruitment achieved by the tasks and their completion confidence when compared with a benchmark that relies solely on reputation.}
}


@article{DBLP:journals/toit/DanPD22,
	author = {Ovidiu Dan and
                  Vaibhav Parikh and
                  Brian D. Davison},
	title = {{IP} Geolocation through Reverse {DNS}},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {17:1--17:29},
	year = {2022},
	url = {https://doi.org/10.1145/3457611},
	doi = {10.1145/3457611},
	timestamp = {Wed, 15 Dec 2021 10:32:36 +0100},
	biburl = {https://dblp.org/rec/journals/toit/DanPD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IP Geolocation databases are widely used in online services to map end-user IP addresses to their geographical location. However, they use proprietary geolocation methods, and in some cases they have poor accuracy. We propose a systematic approach to use reverse DNS hostnames for geolocating IP addresses, with a focus on end-user IP addresses as opposed to router IPs. Our method is designed to be combined with other geolocation data sources. We cast the task as a machine learning problem where, for a given hostname, we first generate a list of potential location candidates, and then we classify each hostname and candidate pair using a binary classifier to determine which location candidates are plausible. Finally, we rank the remaining candidates by confidence (class probability) and break ties by population count. We evaluate our approach against three state-of-the-art academic baselines and two state-of-the-art commercial IP geolocation databases. We show that our work significantly outperforms the academic baselines and is complementary and competitive with commercial databases. To aid reproducibility, we open source our entire approach and make it available to the academic community.}
}


@article{DBLP:journals/toit/ZhangXPYLWLG22,
	author = {Di Zhang and
                  Feng Xu and
                  Chi{-}Man Pun and
                  Yang Yang and
                  Rushi Lan and
                  Liejun Wang and
                  Yujie Li and
                  Hao Gao},
	title = {Virtual Reality Aided High-Quality 3D Reconstruction by Remote Drones},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {18:1--18:20},
	year = {2022},
	url = {https://doi.org/10.1145/3458930},
	doi = {10.1145/3458930},
	timestamp = {Tue, 05 Mar 2024 15:16:46 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ZhangXPYLWLG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Artificial intelligence including deep learning and 3D reconstruction methods is changing the daily life of people. Now, an unmanned aerial vehicle that can move freely in the air and avoid harsh ground conditions has been commonly adopted as a suitable tool for 3D reconstruction. The traditional 3D reconstruction mission based on drones usually consists of two steps: image collection and offline post-processing. But there are two problems: one is the uncertainty of whether all parts of the target object are covered, and another is the tedious post-processing time. Inspired by modern deep learning methods, we build a telexistence drone system with an onboard deep learning computation module and a wireless data transmission module that perform incremental real-time dense reconstruction of urban cities by itself. Two technical contributions are proposed to solve the preceding issues. First, based on the popular depth fusion surface reconstruction framework, we combine it with a visual-inertial odometry estimator that integrates the inertial measurement unit and allows for robust camera tracking as well as high-accuracy online 3D scan. Second, the capability of real-time 3D reconstruction enables a new rendering technique that can visualize the reconstructed geometry of the target as navigation guidance in the HMD. Therefore, it turns the traditional path-planning-based modeling process into an interactive one, leading to a higher level of scan completeness. The experiments in the simulation system and our real prototype demonstrate an improved quality of the 3D model using our artificial intelligence leveraged drone system.}
}


@article{DBLP:journals/toit/BenomarLMP22,
	author = {Zakaria Benomar and
                  Francesco Longo and
                  Giovanni Merlino and
                  Antonio Puliafito},
	title = {Cloud-based Network Virtualization in IoT with OpenStack},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {19:1--19:26},
	year = {2022},
	url = {https://doi.org/10.1145/3460818},
	doi = {10.1145/3460818},
	timestamp = {Sat, 25 Dec 2021 15:52:28 +0100},
	biburl = {https://dblp.org/rec/journals/toit/BenomarLMP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Cloud computing deployments, specifically in the Infrastructure-as-a-Service (IaaS) model, networking is one of the core enabling facilities provided for the users. The IaaS approach ensures significant flexibility and manageability, since the networking resources and topologies are entirely under users’ control. In this context, considerable efforts have been devoted to promoting the Cloud paradigm as a suitable solution for managing IoT environments. Deep and genuine integration between the two ecosystems, Cloud and IoT, may only be attainable at the IaaS level. In light of extending the IoT domain capabilities’ with Cloud-based mechanisms akin to the IaaS Cloud model, network virtualization is a fundamental enabler of infrastructure-oriented IoT deployments. Indeed, an IoT deployment without networking resilience and adaptability makes it unsuitable to meet user-level demands and services’ requirements. Such a limitation makes the IoT-based services adopted in very specific and statically defined scenarios, thus leading to limited plurality and diversity of use cases. This article presents a Cloud-based approach for network virtualization in an IoT context using the de-facto standard IaaS middleware, OpenStack, and its networking subsystem, Neutron. OpenStack is being extended to enable the instantiation of virtual/overlay networks between Cloud-based instances (e.g., virtual machines, containers, and bare metal servers) and/or geographically distributed IoT nodes deployed at the network edge.}
}


@article{DBLP:journals/toit/WangJLWL22,
	author = {Jingjing Wang and
                  Wenjun Jiang and
                  Kenli Li and
                  Guojun Wang and
                  Keqin Li},
	title = {Incremental Group-Level Popularity Prediction in Online Social Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {20:1--20:26},
	year = {2022},
	url = {https://doi.org/10.1145/3461839},
	doi = {10.1145/3461839},
	timestamp = {Fri, 10 Mar 2023 21:24:04 +0100},
	biburl = {https://dblp.org/rec/journals/toit/WangJLWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predicting the popularity of web contents in online social networks is essential for many applications. However, existing works are usually under non-incremental settings. In other words, they have to rebuild models from scratch when new data occurs, which are inefficient in big data environments. It leads to an urgent need for incremental prediction, which can update previous results with new data and conduct prediction incrementally. Moreover, the promising direction of group-level popularity prediction has not been well treated, which explores fine-grained information while keeping a low cost. To this end, we identify the problem of incremental group-level popularity prediction, and propose a novel model IGPP to address it. We first predict the group-level popularity incrementally by exploiting the incremental CANDECOMP/PARAFCAC (CP) tensor decomposition algorithm. Then, to reduce the cumulative error by incremental prediction, we propose three strategies to restart the CP decomposition. To the best of our knowledge, this is the first work that identifies and solves the problem of incremental group-level popularity prediction. Extensive experimental results show significant improvements of the IGPP method over other works both in the prediction accuracy and the efficiency.}
}


@article{DBLP:journals/toit/PaganiWSG22,
	author = {Alessio Pagani and
                  Zhuangkun Wei and
                  Ricardo Silva and
                  Weisi Guo},
	title = {Neural Network Approximation of Graph Fourier Transform for Sparse
                  Sampling of Networked Dynamics},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {21:1--21:18},
	year = {2022},
	url = {https://doi.org/10.1145/3461838},
	doi = {10.1145/3461838},
	timestamp = {Wed, 31 May 2023 19:02:38 +0200},
	biburl = {https://dblp.org/rec/journals/toit/PaganiWSG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Infrastructure monitoring is critical for safe operations and sustainability. Like many networked systems, water distribution networks (WDNs) exhibit both graph topological structure and complex embedded flow dynamics. The resulting networked cascade dynamics are difficult to predict without extensive sensor data. However, ubiquitous sensor monitoring in underground situations is expensive, and a key challenge is to infer the contaminant dynamics from partial sparse monitoring data. Existing approaches use multi-objective optimization to find the minimum set of essential monitoring points but lack performance guarantees and a theoretical framework. Here, we first develop a novel Graph Fourier Transform (GFT) operator to compress networked contamination dynamics to identify the essential principal data collection points with inference performance guarantees. As such, the GFT approach provides the theoretical sampling bound. We then achieve under-sampling performance by building auto-encoder (AE) neural networks (NN) to generalize the GFT sampling process and under-sample further from the initial sampling set, allowing a very small set of data points to largely reconstruct the contamination dynamics over real and artificial WDNs. Various sources of the contamination are tested, and we obtain high accuracy reconstruction using around 5%–10% of the network nodes for known contaminant sources, and 50%–75% for unknown source cases, which although larger than that of the schemes for contaminant detection and source identifications, is smaller than the current sampling schemes for contaminant data recovery. This general approach of compression and under-sampled recovery via NN can be applied to a wide range of networked infrastructures to enable efficient data sampling for digital twins.}
}


@article{DBLP:journals/toit/FanYWCS22,
	author = {Zhenyu Fan and
                  Wang Yang and
                  Fan Wu and
                  Jing Cao and
                  Weisong Shi},
	title = {Serving at the Edge: An Edge Computing Service Architecture Based
                  on {ICN}},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {22:1--22:27},
	year = {2022},
	url = {https://doi.org/10.1145/3464428},
	doi = {10.1145/3464428},
	timestamp = {Wed, 19 Oct 2022 17:21:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/FanYWCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Different from cloud computing, edge computing moves computing away from the centralized data center and closer to the end-user. Therefore, with the large-scale deployment of edge services, it becomes a new challenge of how to dynamically select the appropriate edge server for computing requesters based on the edge server and network status. In the TCP/IP architecture, edge computing applications rely on centralized proxy servers to select an appropriate edge server, which leads to additional network overhead and increases service response latency. Due to its powerful forwarding plane, Information-Centric Networking (ICN) has the potential to provide more efficient networking support for edge computing than TCP/IP. However, traditional ICN only addresses named data and cannot well support the handle of dynamic content. In this article, we propose an edge computing service architecture based on ICN, which contains the edge computing service session model, service request forwarding strategies, and service dynamic deployment mechanism. The proposed service session model can not only keep the overhead low but also push the results to the computing requester immediately once the computing is completed. However, the service request forwarding strategies can forward computing requests to an appropriate edge server in a distributed manner. Compared with the TCP/IP-based proxy solution, our forwarding strategy can avoid unnecessary network transmissions, thereby reducing the service completion time. Moreover, the service dynamic deployment mechanism decides whether to deploy an edge service on an edge server based on service popularity, so that edge services can be dynamically deployed to hotspot, further reducing the service completion time.}
}


@article{DBLP:journals/toit/GeCKDC22,
	author = {Mengmeng Ge and
                  Jin{-}Hee Cho and
                  Dong Seong Kim and
                  Gaurav Dixit and
                  Ing{-}Ray Chen},
	title = {Proactive Defense for Internet-of-things: Moving Target Defense With
                  Cyberdeception},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {24:1--24:31},
	year = {2022},
	url = {https://doi.org/10.1145/3467021},
	doi = {10.1145/3467021},
	timestamp = {Sat, 25 Dec 2021 15:52:28 +0100},
	biburl = {https://dblp.org/rec/journals/toit/GeCKDC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Resource constrained Internet-of-Things (IoT) devices are highly likely to be compromised by attackers, because strong security protections may not be suitable to be deployed. This requires an alternative approach to protect vulnerable components in IoT networks. In this article, we propose an integrated defense technique to achieve intrusion prevention by leveraging cyberdeception (i.e., a decoy system) and moving target defense (i.e., network topology shuffling). We evaluate the effectiveness and efficiency of our proposed technique analytically based on a graphical security model in a software-defined networking (SDN)-based IoT network. We develop four strategies (i.e., fixed/random and adaptive/hybrid) to address “when” to perform network topology shuffling and three strategies (i.e., genetic algorithm/decoy attack path-based optimization/random) to address “how” to perform network topology shuffling on a decoy-populated IoT network, and we analyze which strategy can best achieve a system goal, such as prolonging the system lifetime, maximizing deception effectiveness, maximizing service availability, or minimizing defense cost. We demonstrated that a software-defined IoT network running our intrusion prevention technique at the optimal parameter setting prolongs system lifetime, increases attack complexity of compromising critical nodes, and maintains superior service availability compared with a counterpart IoT network without running our intrusion prevention technique. Further, when given a single goal or a multi-objective goal (e.g., maximizing the system lifetime and service availability while minimizing the defense cost) as input, the best combination of “when” and “how” strategies is identified for executing our proposed technique under which the specified goal can be best achieved.}
}


@article{DBLP:journals/toit/MeierBE22,
	author = {Florian Meier and
                  Alexander Bazo and
                  David Elsweiler},
	title = {Using Social Media Data to Analyse Issue Engagement During the 2017
                  German Federal Election},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {25:1--25:25},
	year = {2022},
	url = {https://doi.org/10.1145/3467020},
	doi = {10.1145/3467020},
	timestamp = {Sat, 09 Apr 2022 12:33:23 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MeierBE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A fundamental tenet of democracy is that political parties present policy alternatives, such that the public can participate in the decision-making process. Parties, however, strategically control public discussion by emphasising topics that they believe will highlight their strengths in voters’ minds. Political strategy has been studied for decades, mostly by manually annotating and analysing party statements, press coverage, or TV ads. Here we build on recent work in the areas of computational social science and eDemocracy, which studied these concepts computationally with social media. We operationalize issue engagement and related political science theories to measure and quantify politicians’ communication behavior using more than 366k Tweets posted by over 1,000 prominent German politicians in the 2017 election year. To this end, we first identify issues in posted Tweets by utilising a hashtag-based approach well known in the literature. This method allows several prominent issues featuring in the political debate on Twitter that year to be identified. We show that different political parties engage to a larger or lesser extent with these issues. The findings reveal differing social media strategies by parties located at different sides of the political left-right scale, in terms of which issues they engage with, how confrontational they are and how their strategies evolve in the lead-up to the election. Whereas previous work has analysed the general public’s use of Twitter or politicians’ communication in terms of cross-party polarisation, this is the first study of political science theories, relating to issue engagement, using politicians’ social media data.}
}


@article{DBLP:journals/toit/AvasalcaiTD22,
	author = {Cosmin Avasalcai and
                  Christos Tsigkanos and
                  Schahram Dustdar},
	title = {Adaptive Management of Volatile Edge Systems at Runtime With Satisfiability},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {26:1--26:21},
	year = {2022},
	url = {https://doi.org/10.1145/3470658},
	doi = {10.1145/3470658},
	timestamp = {Sat, 25 Dec 2021 15:52:28 +0100},
	biburl = {https://dblp.org/rec/journals/toit/AvasalcaiTD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing offers the possibility of deploying applications at the edge of the network. To take advantage of available devices’ distributed resources, applications often are structured as microservices, often having stringent requirements of low latency and high availability. However, a decentralized edge system that the application may be intended for is characterized by high volatility, due to devices making up the system being unreliable or leaving the network unexpectedly. This makes application deployment and assurance that it will continue to operate under volatility challenging. We propose an adaptive framework capable of deploying and efficiently maintaining a microservice-based application at runtime, by tackling two intertwined problems: (i) finding a microservice placement across device hosts and (ii) deriving invocation paths that serve it. Our objective is to maintain correct functionality by satisfying given requirements in terms of end-to-end latency and availability, in a volatile edge environment. We evaluate our solution quantitatively by considering performance and failure recovery.}
}


@article{DBLP:journals/toit/UlusoyY22,
	author = {Onuralp Ulusoy and
                  Pinar Yolum},
	title = {{PANOLA:} {A} Personal Assistant for Supporting Users in Preserving
                  Privacy},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {27:1--27:32},
	year = {2022},
	url = {https://doi.org/10.1145/3471187},
	doi = {10.1145/3471187},
	timestamp = {Thu, 13 Jan 2022 08:43:38 +0100},
	biburl = {https://dblp.org/rec/journals/toit/UlusoyY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy is the right of individuals to keep personal information to themselves. When individuals use online systems, they should be given the right to decide what information they would like to share and what to keep private. When a piece of information pertains only to a single individual, preserving privacy is possible by providing the right access options to the user. However, when a piece of information pertains to multiple individuals, such as a picture of a group of friends or a collaboratively edited document, deciding how to share this information and with whom is challenging. The problem becomes more difficult when the individuals who are affected by the information have different, possibly conflicting privacy constraints. Resolving this problem requires a mechanism that takes into account the relevant individuals’ concerns to decide on the privacy configuration of information. Because these decisions need to be made frequently (i.e., per each piece of shared content), the mechanism should be automated. This article presents a personal assistant to help end-users with managing the privacy of their content. When some content that belongs to multiple users is about to be shared, the personal assistants of the users employ an auction-based privacy mechanism to regulate the privacy of the content. To do so, each personal assistant learns the preferences of its user over time and produces bids accordingly. Our proposed personal assistant is capable of assisting users with different personas and thus ensures that people benefit from it as they need it. Our evaluations over multiagent simulations with online social network content show that our proposed personal assistant enables privacy-respecting content sharing.}
}


@article{DBLP:journals/toit/YadavV22,
	author = {Ashima Yadav and
                  Dinesh Kumar Vishwakarma},
	title = {A Language-independent Network to Analyze the Impact of {COVID-19}
                  on the World via Sentiment Analysis},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {1},
	pages = {28:1--28:30},
	year = {2022},
	url = {https://doi.org/10.1145/3475867},
	doi = {10.1145/3475867},
	timestamp = {Wed, 16 Mar 2022 23:54:51 +0100},
	biburl = {https://dblp.org/rec/journals/toit/YadavV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Towards the end of 2019, Wuhan experienced an outbreak of novel coronavirus, which soon spread worldwide, resulting in a deadly pandemic that infected millions of people around the globe. The public health agencies followed many strategies to counter the fatal virus. However, the virus severely affected the lives of the people. In this paper, we study the sentiments of people from the top five worst affected countries by the virus, namely the USA, Brazil, India, Russia, and South Africa. We propose a deep language-independent Multilevel Attention-based Conv-BiGRU network (MACBiG-Net), which includes embedding layer, word-level encoded attention, and sentence-level encoded attention mechanisms to extract the positive, negative, and neutral sentiments. The network captures the subtle cues in a document by focusing on the local characteristics of text along with the past and future context information for the sentiment classification. We further develop a COVID-19 Sentiment Dataset by crawling the tweets from Twitter and applying topic modeling to extract the hidden thematic structure of the document. The classification results demonstrate that the proposed model achieves an accuracy of 85%, which is higher than other well-known algorithms for sentiment classification. The findings show that the topics which evoked positive sentiments were related to frontline workers, entertainment, motivation, and spending quality time with family. The negative sentiments were related to socio-economic factors like racial injustice, unemployment rates, fake news, and deaths. Finally, this study provides feedback to the government and health professionals to handle future outbreaks and highlight future research directions for scientists and researchers.}
}


@article{DBLP:journals/toit/YuanLCBF22,
	author = {Yali Yuan and
                  Chencheng Liang and
                  Xu Chen and
                  Thar Baker and
                  Xiaoming Fu},
	title = {Adaptive Fuzzy Game-Based Energy-Efficient Localization in 3D Underwater
                  Sensor Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {29:1--29:20},
	year = {2022},
	url = {https://doi.org/10.1145/3406533},
	doi = {10.1145/3406533},
	timestamp = {Tue, 21 Mar 2023 21:15:18 +0100},
	biburl = {https://dblp.org/rec/journals/toit/YuanLCBF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Numerous applications in 3D underwater sensor networks (UWSNs), such as pollution detection, disaster prevention, animal monitoring, navigation assistance, and submarines tracking, heavily rely on accurate localization techniques. However, due to the limited batteries of sensor nodes and the difficulty for energy harvesting in UWSNs, it is challenging to localize sensor nodes successfully within a short sensor node lifetime in an unspecified underwater environment. Therefore, we propose the Adaptive Energy-Efficient Localization Algorithm (Adaptive EELA) to enable energy-efficient node localization while adapting to the dynamic environment changes. Adaptive EELA takes a fuzzy game-theoretic approach, whereby the Stackelberg game is used to model the interactions among sensor and anchor nodes in UWSNs and employs the adaptive neuro-fuzzy method to set the appropriate utility functions. We prove that a socially optimal Stackelberg–Nash equilibrium is achieved in Adaptive EELA. Through extensive numerical simulations under various environmental scenarios, the evaluation results show that our proposed algorithm accomplishes a significant energy reduction, e.g., 66% lower compared to baselines, while achieving a desired performance level in terms of localization coverage, error, and delay.}
}


@article{DBLP:journals/toit/ChoudhuryMML22,
	author = {Nikumani Choudhury and
                  Rakesh Matam and
                  Mithun Mukherjee and
                  Jaime Lloret},
	title = {{DADC:} {A} Novel Duty-cycling Scheme for {IEEE} 802.15.4 Cluster-tree-based
                  IoT Applications},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {30:1--30:26},
	year = {2022},
	url = {https://doi.org/10.1145/3409487},
	doi = {10.1145/3409487},
	timestamp = {Thu, 09 Jun 2022 19:57:21 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ChoudhuryMML22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The IEEE 802.15.4 standard is one of the widely adopted specifications for realizing different applications of the Internet of Things. It defines several physical layer options and Medium Access Control (MAC) sub-layer for devices with low-power operating at low data rates. As devices implementing this standard are primarily battery-powered, minimizing their power consumption is a significant concern. Duty-cycling is one such power conserving mechanism that allows a device to schedule its active and inactive radio periods effectively, thus preventing energy drain due to idle listening. The standard specifies two parameters, beacon order and superframe order, which define the active and inactive period of a device. However, it does not specify a duty-cycling scheme to adapt these parameters for varying network conditions. Existing works in this direction are either based on superframe occupation ratio or buffer/queue length of devices. In this article, the particular limitations of both the approaches mentioned above are presented. Later, a novel duty-cycling mechanism based on MAC parameters is proposed. Also, we analyze the role of synchronization schemes in achieving efficient duty-cycles in synchronized cluster-tree network topologies. A Markov model has also been developed for the MAC protocol to estimate the delay and energy consumption during frame transmission.}
}


@article{DBLP:journals/toit/LuZWLW22,
	author = {Jianfeng Lu and
                  Zhao Zhang and
                  Jiangtao Wang and
                  Ruixuan Li and
                  Shaohua Wan},
	title = {A Green Stackelberg-game Incentive Mechanism for Multi-service Exchange
                  in Mobile Crowdsensing},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {31:1--31:29},
	year = {2022},
	url = {https://doi.org/10.1145/3421506},
	doi = {10.1145/3421506},
	timestamp = {Wed, 28 Jun 2023 16:02:22 +0200},
	biburl = {https://dblp.org/rec/journals/toit/LuZWLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although mobile crowdsensing (MCS) has become a green paradigm of collecting, analyzing, and exploiting massive amounts of sensory data, existing incentive mechanisms are not effective to stimulate users’s active participation and service contribution in multi-service exchange in MCS due to its specific features: a large number of heterogeneous users have asymmetric service requirements, workers have the freedom to choose sensing tasks as well as participation levels, and multiple sensing tasks have heterogeneous values which may be untruthful declared by the corresponding requesters. To address this issue, this article develops a green Stackelberg-game incentive mechanism to achieve selective fairness, truthfulness, and bounded efficiency while reducing the burden on the platform. First, we model the multi-service exchange problem as a Stackelberg multi-service exchange game consisting of multi-leader and multi-follower, in which each requester as a leader first chooses the reward declaration strategy and thus the payment for each sensing task, each worker as a follower then chooses the sensing plan strategy to maximize her own utility. We next introduce the concept of virtual currency to maintain the selective fairness to balance service request and service provision between users, in which a user earns/consumes virtual currency for providing/receiving services, and thus no one can always get services without providing services. Then, we present two novel algorithms to compute the unique Nash equilibrium for the sensing plan determination game and the reward declaration determination game, respectively, which together forms a unique Stackelberg equilibrium for the proposed game. Afterwards, we theoretically prove that the proposed green Stackelberg-game incentive mechanism achieves the desirable properties of selective fairness, truthfulness, bounded efficiency. Finally, extensive evaluation results are provided to support the validity and effectiveness of our mechanism compared with both baseline and theoretical optimal approaches.}
}


@article{DBLP:journals/toit/CarpentieriCSPP22,
	author = {Bruno Carpentieri and
                  Arcangelo Castiglione and
                  Alfredo De Santis and
                  Francesco Palmieri and
                  Raffaele Pizzolante},
	title = {Privacy-preserving Secure Media Streaming for Multi-user Smart Environments},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {32:1--32:21},
	year = {2022},
	url = {https://doi.org/10.1145/3423047},
	doi = {10.1145/3423047},
	timestamp = {Sun, 06 Aug 2023 20:51:07 +0200},
	biburl = {https://dblp.org/rec/journals/toit/CarpentieriCSPP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the last years, our lifestyle has been positively upset by the sudden advent of technology. The Internet of Things (IoT), offering universal and ubiquitous connectivity to both people and objects, revealed to be the silver bullet for enabling a vast number of previously unexpected applications. In particular, media streaming providers are growing in business and scope, and we can forecast that soon, video streaming will substitute TV broadcasting activities. With the increasing success of multi-user smart environments, empowered by new-generation smart devices and IoT architectures, multimedia contents (i.e., images and videos) need to be effectively accessed anytime and anywhere. Recent advances in computer vision technologies have made the development of intelligent monitoring systems for video surveillance and ambient-assisted living. Such a scenario permits better integration among technologies, multimedia content, and end-users. However, there are several challenges, and some are still open. More precisely, due to the sensitivity of some multimedia content (e.g., video-surveillance streams), it is paramount to preserve users’ privacy. Again, it is necessary to guarantee the integrity of usage rights during any multimedia transmission process, starting from the video encoding phase. In this way, the private content is disclosed only when the stream is decoded on the other endpoint, by the legitimate user. In this article, we present a secure video transmission strategy that can address the challenges mentioned above. The proposed strategy takes advantage of both watermarking and video scrambling techniques to make it possible for the secure and privacy-preserving transmission of multimedia streaming. Through our proposal, multimedia streaming is of low quality and thus unusable. However, it can be fully recovered and enjoyed only by authorized users. Finally, due to its low complexity and energy-efficiency, our proposal is particularly suitable for onboard implementations.}
}


@article{DBLP:journals/toit/YanJLWY22,
	author = {Hongyang Yan and
                  Nan Jiang and
                  Kang Li and
                  Yilei Wang and
                  Guoyu Yang},
	title = {Collusion-free for Cloud Verification toward the View of Game Theory},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {33:1--33:21},
	year = {2022},
	url = {https://doi.org/10.1145/3423558},
	doi = {10.1145/3423558},
	timestamp = {Fri, 22 Sep 2023 09:38:29 +0200},
	biburl = {https://dblp.org/rec/journals/toit/YanJLWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {At present, clients can outsource lots of complex and abundant computation, e.g., Internet of things (IoT), tasks to clouds by the “pay as you go” model. Outsourcing computation can save costs for clients and fully utilize the existing cloud infrastructures. However, it is hard for clients to trust the clouds even if blockchain is used as the trusted platform. In this article, we utilize the verification method as SETI@home by only two rational clouds, who hope to maximize their utilities. Utilities are defined as the incomes of clouds when they provide computation results to clients. More specifically, one client outsources two jobs to two clouds and each job contains n tasks, which include k identical sentinels. Two clouds can either honestly compute each task or collude on the identical sentinel tasks by agreeing on random values. If the results of identical sentinels are identical, then client regards the jobs as correctly computed without verification. Obviously, rational clouds have incentives to deviate by collusion and provide identical random results for a higher income. We discuss how to prevent collusion by using deposits, e.g., bit-coins. Furthermore, utilities for each cloud can be automatically assigned by a smart contract. We prove that, given proper parameters, two rational clouds will honestly send correct results to the client without collusion.}
}


@article{DBLP:journals/toit/LiangXZLL22,
	author = {Wei Liang and
                  Songyou Xie and
                  Dafang Zhang and
                  Xiong Li and
                  Kuan{-}Ching Li},
	title = {A Mutual Security Authentication Method for {RFID-PUF} Circuit Based
                  on Deep Learning},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {34:1--34:20},
	year = {2022},
	url = {https://doi.org/10.1145/3426968},
	doi = {10.1145/3426968},
	timestamp = {Sat, 30 Sep 2023 10:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/toit/LiangXZLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Industrial Internet of Things (IIoT) is designed to refine and optimize the process controls, thereby leveraging improvements in economic benefits, such as efficiency and productivity. However, the Radio Frequency Identification (RFID) technology in an IIoT environment has problems such as low security and high cost. To overcome such issues, a mutual authentication scheme that is suitable for RFID systems, wherein techniques in Deep Learning (DL) are incorporated onto the Arbiter Physical Unclonable Function (APUF) for the secured access authentication of the IC circuits on the IoT, is proposed. The design applies the APUF-MPUF mutual authentication structure obtained by DL to generate essential real-time authentication information, thereby taking advantage of the feature that the tag in the PUF circuit structure does not need to store any essential information and resolving the problem of key storage. The proposed scheme also uses a bitwise comparison method, which hides the PUF response information and effectively reduces the resource overhead of the system during the verification process, to verify the correctness of the two strings. Security analysis demonstrates that the proposed scheme has high robustness and security against different conventional attack methods, and the storage and communication costs are 95.7% and 42.0% lower than the existing schemes, respectively.}
}


@article{DBLP:journals/toit/ShorfuzzamanH22,
	author = {Mohammad Shorfuzzaman and
                  M. Shamim Hossain},
	title = {Predictive Analytics of Energy Usage by IoT-Based Smart Home Appliances
                  for Green Urban Development},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {35:1--35:26},
	year = {2022},
	url = {https://doi.org/10.1145/3426970},
	doi = {10.1145/3426970},
	timestamp = {Mon, 28 Aug 2023 21:41:18 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ShorfuzzamanH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Green IoT primarily focuses on increasing IoT sustainability by reducing the large amount of energy required by IoT devices. Whether increasing the efficiency of these devices or conserving energy, predictive analytics is the cornerstone for creating value and insight from large IoT data. This work aims at providing predictive models driven by data collected from various sensors to model the energy usage of appliances in an IoT-based smart home environment. Specifically, we address the prediction problem from two perspectives. Firstly, an overall energy consumption model is developed using both linear and non-linear regression techniques to identify the most relevant features in predicting the energy consumption of appliances. The performances of the proposed models are assessed using a publicly available dataset comprising historical measurements from various humidity and temperature sensors, along with total energy consumption data from appliances in an IoT-based smart home setup. The prediction results comparison show that LSTM regression outperforms other linear and ensemble regression models by showing high variability (R2) with the training (96.2%) and test (96.1%) data for selected features. Secondly, we develop a multi-step time-series model using the auto regressive integrated moving average (ARIMA) technique to effectively forecast future energy consumption based on past energy usage history. Overall, the proposed predictive models will enable consumers to minimize the energy usage of home appliances and the energy providers to better plan and forecast future energy demand to facilitate green urban development.}
}


@article{DBLP:journals/toit/ManogaranRSWHSK22,
	author = {Gunasekaran Manogaran and
                  Bharat S. Rawal and
                  Houbing Song and
                  Huihui Wang and
                  Chinghsien Hsu and
                  Vijayalakshmi Saravanan and
                  Seifedine Nimer Kadry and
                  P. Mohamed Shakeel},
	title = {Optimal Energy-Centric Resource Allocation and Offloading Scheme for
                  Green Internet of Things Using Machine Learning},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {36:1--36:19},
	year = {2022},
	url = {https://doi.org/10.1145/3431500},
	doi = {10.1145/3431500},
	timestamp = {Sat, 30 Sep 2023 10:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ManogaranRSWHSK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Resource allocation and offloading in green Internet of Things (IoT) relies on the multi-level heterogeneous platforms. The energy expenses of the platform determine the reliability of green IoT based services and applications. This manuscript introduces a decisive energy management scheme for optimal resource allocation and offloading along with energy constraints. This scheme handles both the allocation and energy-cost in a balanced manner through deterministic task offloading. In particular, resource allocation solution for non-delay tolerant green IoT applications is focused by confining the failures of discrete tasks through neural learning. The dropout process augmented with the learning process improves the feasible conditions for resource handling and task offloading among the active IoT service providers. Through extensive simulations the performance of the proposed scheme is analyzed and energy consumption, failure rate, processing, and completion time metrics are used for a comparative study. Further, the optimal utilization and on-demand dissipation of such stored resources help to improve the sustainability of green power and communication technologies in the smart city environment.}
}


@article{DBLP:journals/toit/AwanDAKA22,
	author = {Kamran Ahmad Awan and
                  Ikram Ud Din and
                  Abeer S. Almogren and
                  Neeraj Kumar and
                  Ahmad Almogren},
	title = {A Taxonomy of Multimedia-based Graphical User Authentication for Green
                  Internet of Things},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {37:1--37:28},
	year = {2022},
	url = {https://doi.org/10.1145/3433544},
	doi = {10.1145/3433544},
	timestamp = {Wed, 07 Dec 2022 23:03:34 +0100},
	biburl = {https://dblp.org/rec/journals/toit/AwanDAKA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Authentication receives enormous consideration from the research community and is proven to be an interesting field in today’s era. User authentication is the major concern because people have their private data on devices. To strengthen user authentication, passwords have been introduced. In the past, the text-based password was the traditional way of authentication, but this method has particular shortcomings. The graphical password has been introduced as an alternative, which uses a picture or a set of pictures to generate a password. In the future, it is a requirement of such approaches to maintain robustness and consume fewer energy resources to become suitable for the Green Internet of Things (IoT). Similarly, diverse graphical password authentication mechanisms have been used to provide users with better security and usability. In this article, we conduct an extensive survey on the existing approaches of graphical password authentication to highlight the challenges required to be addressed for Green IoT. In comparison to other existing surveys, the objective is to consolidate the graphical password technique and to identify the problem associated with it. Besides, this survey will also identify the vulnerabilities of the graphical password against several potential attacks. We have also examined the strengths and weaknesses of each technique along with the future research directions. This study also evaluates the usability of each approach by considering learnability, memorability, and so forth and also presents a comparative analysis with security.}
}


@article{DBLP:journals/toit/LvLSW22,
	author = {Zhihan Lv and
                  Ranran Lou and
                  Amit Kumar Singh and
                  Qingjun Wang},
	title = {Transfer Learning-powered Resource Optimization for Green Computing
                  in 5G-Aided Industrial Internet of Things},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {38:1--38:16},
	year = {2022},
	url = {https://doi.org/10.1145/3434774},
	doi = {10.1145/3434774},
	timestamp = {Tue, 16 Aug 2022 23:06:31 +0200},
	biburl = {https://dblp.org/rec/journals/toit/LvLSW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Objective: Green computing meets the needs of a low-carbon society and it is an important aspect of promoting social sustainable development and technological progress. In the investigation, green computing for resource management and allocation issues is only discussed. Therefore, in the context of the 5G communication network, the investigation of the data classification and resource optimization of the Internet of Things are conducted. Method: The virtualization architecture of the heterogeneous wireless network resource based on 5G technology is designed. The related investigation is conducted based on 5G network and Internet of Things technology. Under the traditional method, the transfer learning is introduced to improve the AdaBoost (Adaptive Boosting) algorithm to classify the data. The investigated complete resource reuse method is used to optimize resources. A method that a sub-channel can be reused by a cellular link and any number of D2D links at the same time is proposed to conduct resource optimization investigation. Results: The investigation indicates that the classification accuracy of the algorithm is excellent for the data classification of the Internet of Things and has different advantages in various aspects compared with other algorithms. The designed algorithm can find a larger set of resource reuse and have a significant increase in spectrum utilization efficiency. Conclusion: The investigation can contribute to the boom in the Internet of Things in terms of data classification and resource optimization based on 5G.}
}


@article{DBLP:journals/toit/RodicZPSR22,
	author = {Lea Dujic Rodic and
                  Tomislav Zupanovic and
                  Toni Perkovic and
                  Petar Solic and
                  Joel J. P. C. Rodrigues},
	title = {Machine Learning and Soil Humidity Sensing: Signal Strength Approach},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {39:1--39:21},
	year = {2022},
	url = {https://doi.org/10.1145/3418207},
	doi = {10.1145/3418207},
	timestamp = {Mon, 05 Feb 2024 20:21:53 +0100},
	biburl = {https://dblp.org/rec/journals/toit/RodicZPSR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet-of-Things vision of ubiquitous and pervasive computing gives rise to future smart irrigation systems comprising the physical and digital worlds. A smart irrigation ecosystem combined with Machine Learning can provide solutions that successfully solve the soil humidity sensing task in order to ensure optimal water usage. Existing solutions are based on data received from the power hungry/expensive sensors that are transmitting the sensed data over the wireless channel. Over time, the systems become difficult to maintain, especially in remote areas due to the battery replacement issues with a large number of devices. Therefore, a novel solution must provide an alternative, cost- and energy-effective device that has unique advantage over the existing solutions. This work explores the concept of a novel, low-power, LoRa-based, cost-effective system that achieves humidity sensing using Deep Learning techniques that can be employed to sense soil humidity with high accuracy simply by measuring the signal strength of the given underground beacon device.}
}


@article{DBLP:journals/toit/UllahNBA22,
	author = {Farhan Ullah and
                  Muhammad Rashid Naeem and
                  Abdullah S. Bajahzar and
                  Fadi Al{-}Turjman},
	title = {IoT-based Cloud Service for Secured Android Markets using PDG-based
                  Deep Learning Classification},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {40:1--40:17},
	year = {2022},
	url = {https://doi.org/10.1145/3418206},
	doi = {10.1145/3418206},
	timestamp = {Mon, 05 Feb 2024 20:21:53 +0100},
	biburl = {https://dblp.org/rec/journals/toit/UllahNBA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software piracy is an act of illegal stealing and distributing commercial software either for revenue or identify theft. Pirated applications on Android app stores are harming developers and their users by clone scammers. The scammers usually generate pirated versions of the same applications and publish them in different open-source app stores. There is no centralized system between these app stores to prevent scammers from publishing pirated applications. As most of the app stores are hosted on cloud storage, therefore a cloud-based interaction system can prevent scammers from publishing pirated applications. In this paper, we proposed IoT-based cloud architecture for clone detection using program dependency analysis. First, the newly submitted APK and possible original files are selected from app stores. The APK Extractor and JDEX decompiler extract APK and DEX files for Java source code analysis. The dependency graphs of Java files are generated to extract a set of weighted features. The Stacked-Long Short-Term Memory (S-LSTM) deep learning model is designed to predict possible clones. Experimental results have shown that the proposed approach can achieve an average accuracy of 95.48% among clones from different application stores.}
}


@article{DBLP:journals/toit/RawalMMH22,
	author = {Bharat S. Rawal and
                  Poongodi M and
                  Gunasekaran Manogaran and
                  Mounir Hamdi},
	title = {Multi-Tier Stack of Block Chain with Proxy Re-Encryption Method Scheme
                  on the Internet of Things Platform},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {41:1--41:20},
	year = {2022},
	url = {https://doi.org/10.1145/3421508},
	doi = {10.1145/3421508},
	timestamp = {Mon, 28 Aug 2023 21:41:18 +0200},
	biburl = {https://dblp.org/rec/journals/toit/RawalMMH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Block chain provides an innovative solution to information storage, transaction execution, security, and trust building in an open environment. The block chain is technological progress for cyber security and cryptography, with efficiency-related cases varying in smart grids, smart contracts, over the IoT, etc. The movement to exchange data on a server has massively increased with the introduction of the Internet of Things. Hence, in this research, Splitting of proxy re-encryption method (Split-PRE) has been suggested based on the IoT to improve security and privacy in a private block chain. This study proposes a block chain-based proxy re-encryption program to resolve both the trust and scalability problems and to simplify the transactions. After encryption, the system saves the Internet of Things data in a distributed cloud. The framework offers dynamic, smart\xa0contracts between the sensor and the device user without the intervention of a trustworthy third party to exchange the captured IoT data. It uses an efficient proxy re-encryption system, which provides the owner and the person existing in the smart contract to see the data. The experimental outcomes show that the proposed approach enhances the efficiency, security, privacy, and feasibility of the system when compared to other existing methods.}
}


@article{DBLP:journals/toit/MoqurrabAKAAJ22,
	author = {Syed Atif Moqurrab and
                  Adeel Anjum and
                  Abid Khan and
                  Mansoor Ahmed and
                  Awais Ahmad and
                  Gwanggil Jeon},
	title = {\emph{Deep-Confidentiality}: An IoT-Enabled Privacy-Preserving Framework
                  for Unstructured Big Biomedical Data},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {42:1--42:21},
	year = {2022},
	url = {https://doi.org/10.1145/3421509},
	doi = {10.1145/3421509},
	timestamp = {Wed, 07 Dec 2022 23:03:34 +0100},
	biburl = {https://dblp.org/rec/journals/toit/MoqurrabAKAAJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the Internet of Things evolution, the clinical data is exponentially growing and using smart technologies. The generated big biomedical data is confidential, as it contains a patient’s personal information and findings. Usually, big biomedical data is stored over the cloud, making it convenient to be accessed and shared. In this view, the data shared for research purposes helps to reveal useful and unexposed aspects. Unfortunately, sharing of such sensitive data also leads to certain privacy threats. Generally, the clinical data is available in textual format (e.g., perception reports). Under the domain of natural language processing, many research studies have been published to mitigate the privacy breaches in textual clinical data. However, there are still limitations and shortcomings in the current studies that are inevitable to be addressed. In this article, a novel framework for textual medical data privacy has been proposed as Deep-Confidentiality. The proposed framework improves Medical Entity Recognition (MER) using deep neural networks and sanitization compared to the current state-of-the-art techniques. Moreover, the new and generic utility metric is also proposed, which overcomes the shortcomings of the existing utility metric. It provides the true representation of sanitized documents as compared to the original documents. To check our proposed framework’s effectiveness, it is evaluated on the i2b2-2010 NLP challenge dataset, which is considered one of the complex medical data for MER. The proposed framework improves the MER with 7.8% recall, 7% precision, and 3.8% F1-score compared to the existing deep learning models. It also improved the data utility of sanitized documents up to 13.79%, where the value of the\xa0k is 3.}
}


@article{DBLP:journals/toit/WangWJHNX22,
	author = {Derui Wang and
                  Sheng Wen and
                  Alireza Jolfaei and
                  Mohammad Sayad Haghighi and
                  Surya Nepal and
                  Yang Xiang},
	title = {On the Neural Backdoor of Federated Generative Models in Edge Computing},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {43:1--43:21},
	year = {2022},
	url = {https://doi.org/10.1145/3425662},
	doi = {10.1145/3425662},
	timestamp = {Mon, 26 Jun 2023 20:52:11 +0200},
	biburl = {https://dblp.org/rec/journals/toit/WangWJHNX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing, as a relatively recent evolution of cloud computing architecture, is the newest way for enterprises to distribute computational power and lower repetitive referrals to central authorities. In the edge computing environment, Generative Models (GMs) have been found to be valuable and useful in machine learning tasks such as data augmentation and data pre-processing. Federated learning and distributed learning refer to training machine learning models in the edge computing network. However, federated learning and distributed learning also bring additional risks to GMs since all peers in the network have access to the model under training. In this article, we study the vulnerabilities of federated GMs to data-poisoning-based backdoor attacks via gradient uploading. We additionally enhance the attack to reduce the required poisonous data samples and cope with dynamic network environments. Last but not least, the attacks are formally proven to be stealthy and effective toward federated GMs. According to the experiments, neural backdoors can be successfully embedded by including merely \\( 5\\% \\) poisonous samples in the local training dataset of an attacker.}
}


@article{DBLP:journals/toit/YangSZJV22,
	author = {Huijie Yang and
                  Jian Shen and
                  Tianqi Zhou and
                  Sai Ji and
                  Pandi Vijayakumar},
	title = {A Flexible and Privacy-Preserving Collaborative Filtering Scheme in
                  Cloud Computing for VANETs},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {44:1--44:19},
	year = {2022},
	url = {https://doi.org/10.1145/3425708},
	doi = {10.1145/3425708},
	timestamp = {Sun, 02 Oct 2022 15:51:54 +0200},
	biburl = {https://dblp.org/rec/journals/toit/YangSZJV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The vehicular ad hoc network (VANET) has become a hot topic in recent years. With the development of VANETs, how to achieve secure and efficient machine learning in VANETs is an urgent problem to be solved. Besides, how to ensure that users obtain the accurate results of machine learning is also a challenge. Based on the homomorphic encryption and secure multiparty computing technology, a flexible and privacy-preserving collaborative filtering scheme is proposed to accomplish the personalized recommendation for users, which is based on users’ interests and locations. On the one hand, the data can be updated by users flexibly to ensure the freshness and accuracy of the dataset of interest. On the other hand, the weighted values of user interest can be safely sorted to improve the accuracy of collaborative filtering effectively. Moreover, a novel collaborative filtering algorithm based on the homomorphic encryption technology is designed, which can guarantee that the calculated decryption result by machine learning is the same as the plaintext. Note that the privacy of user data can be preserved during machine learning in this algorithm. Both theoretical and experimental analyses demonstrate that the proposed scheme is secure and efficient for collaborative filtering in cloud computing in VANETs.}
}


@article{DBLP:journals/toit/MaMKWSA22,
	author = {Xindi Ma and
                  Jianfeng Ma and
                  Saru Kumari and
                  Fushan Wei and
                  Mohammad Shojafar and
                  Mamoun Alazab},
	title = {Privacy-Preserving Distributed Multi-Task Learning against Inference
                  Attack in Cloud Computing},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {45:1--45:24},
	year = {2022},
	url = {https://doi.org/10.1145/3426969},
	doi = {10.1145/3426969},
	timestamp = {Thu, 09 Jun 2022 19:57:21 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MaMKWSA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Because of the powerful computing and storage capability in cloud computing, machine learning as a service (MLaaS) has recently been valued by the organizations for machine learning training over some related representative datasets. When these datasets are collected from different organizations and have different distributions, multi-task learning (MTL) is usually used to improve the generalization performance by scheduling the related training tasks into the virtual machines in MLaaS and transferring the related knowledge between those tasks. However, because of concerns about privacy breaches (e.g., property inference attack and model inverse attack), organizations cannot directly outsource their training data to MLaaS or share their extracted knowledge in plaintext, especially the organizations in sensitive domains. In this article, we propose a novel privacy-preserving mechanism for distributed MTL, namely NOInfer, to allow several task nodes to train the model locally and transfer their shared knowledge privately. Specifically, we construct a single-server architecture to achieve the private MTL, which protects task nodes’ local data even if \\( n-1 \\) out of \\( n \\) nodes colluded. Then, a new protocol for the Alternating Direction Method of Multipliers (ADMM) is designed to perform the privacy-preserving model training, which resists the inference attack through the intermediate results and ensures that the training efficiency is independent of the number of training samples. When releasing the trained model, we also design a differentially private model releasing mechanism to resist the membership inference attack. Furthermore, we analyze the privacy preservation and efficiency of NOInfer in theory. Finally, we evaluate our NOInfer over two testing datasets and evaluation results demonstrate that NOInfer efficiently and effectively achieves the distributed MTL.}
}


@article{DBLP:journals/toit/StergiouPG22,
	author = {Christos L. Stergiou and
                  Konstantinos E. Psannis and
                  Brij B. Gupta},
	title = {InFeMo: Flexible Big Data Management Through a Federated Cloud System},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {46:1--46:22},
	year = {2022},
	url = {https://doi.org/10.1145/3426972},
	doi = {10.1145/3426972},
	timestamp = {Wed, 07 Dec 2022 23:03:34 +0100},
	biburl = {https://dblp.org/rec/journals/toit/StergiouPG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces and describes a novel architecture scenario based on Cloud Computing and counts on the innovative model of Federated Learning. The proposed model is named Integrated Federated Model, with the acronym InFeMo. InFeMo incorporates all the existing Cloud models with a federated learning scenario, as well as other related technologies that may have integrated use with each other, offering a novel integrated scenario. In addition to this, the proposed model is motivated to deliver a more energy efficient system architecture and environment for the users, which aims to the scope of data management. Also, by applying the InFeMo the user would have less waiting time in every procedure queue. The proposed system was built on the resources made available by Cloud Service Providers (CSPs) and by using the PaaS (Platform as a Service) model, in order to be able to handle user requests better and faster. This research tries to fill a scientific gap in the field of federated Cloud systems. Thus, taking advantage of the existing scenarios of FedAvg and CO-OP, we were keen to end up with a new federated scenario that merges these two algorithms, and aiming for a more efficient model that is able to select, depending on the occasion, if it “trains” the model locally in client or globally in server.}
}


@article{DBLP:journals/toit/Al-Otaibi22,
	author = {Yasser D. Al{-}Otaibi},
	title = {A Shared Two-way Cybersecurity Model for Enhancing Cloud Service Sharing
                  for Distributed User Applications},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {47:1--47:17},
	year = {2022},
	url = {https://doi.org/10.1145/3430508},
	doi = {10.1145/3430508},
	timestamp = {Thu, 09 Jun 2022 19:57:21 +0200},
	biburl = {https://dblp.org/rec/journals/toit/Al-Otaibi22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud services provide decentralized and pervasive access for resources to reduce the complex infrastructure requirements of the user. In decentralized service access, the implication of security is tedious to match the user requirements. Therefore, cloud services incorporate cybersecurity measures for administering standard resource access to users. In this paper, a shared two-way security model (STSM) is proposed to provide adaptable service security for the end-users. In this security model, a cooperative closed access session for information sharing between the cloud and end-user is designed with the help of cybersecurity features. This closed access provides less complex authentication for users and data that is capable of matching the verifications of the cloud services. A deep belief learning algorithm is used to differentiate the cooperative and non-cooperative secure sessions between the users and the cloud to ensure closed access throughout the data sharing time. The output of the belief network decides the actual session time between the user and the cloud, improving the span of the sharing session. Besides, the proposed model reduces false alarm, communication failures, under controlled complexity.}
}


@article{DBLP:journals/toit/NguyenZ22,
	author = {Tu N. Nguyen and
                  Sherali Zeadally},
	title = {Mobile Crowd-sensing Applications: Data Redundancies, Challenges,
                  and Solutions},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {48:1--48:15},
	year = {2022},
	url = {https://doi.org/10.1145/3431502},
	doi = {10.1145/3431502},
	timestamp = {Thu, 09 Jun 2022 19:57:21 +0200},
	biburl = {https://dblp.org/rec/journals/toit/NguyenZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conventional data collection methods that use Wireless Sensor Networks (WSNs) suffer from disadvantages such as deployment location limitation, geographical distance, as well as high construction and deployment costs of WSNs. Recently, various efforts have been promoting mobile crowd-sensing (such as a community with people using mobile devices) as a way to collect data based on existing resources. A Mobile Crowd-Sensing System can be considered as a Cyber-Physical System (CPS), because it allows people with mobile devices to collect and supply data to CPSs’ centers. In practical mobile crowd-sensing applications, due to limited budgets for the different expenditure categories in the system, it is necessary to minimize the collection of redundant information to save more resources for the investor. We study the problem of selecting participants in Mobile Crowd-Sensing Systems without redundant information such that the number of users is minimized and the number of records (events) reported by users is maximized, also known as the Participant-Report-Incident Redundant Avoidance (PRIRA) problem. We propose a new approximation algorithm, called the Maximum-Participant-Report Algorithm\xa0(MPRA) to solve the PRIRA problem. Through rigorous theoretical analysis and experimentation, we demonstrate that our proposed method performs well within reasonable bounds of computational complexity.}
}


@article{DBLP:journals/toit/ZhengLSDCMMP22,
	author = {Xiao Zheng and
                  Mingchu Li and
                  Syed Bilal Hussain Shah and
                  Dinh{-}Thuan Do and
                  Yuanfang Chen and
                  Constandinos X. Mavromoustakis and
                  George Mastorakis and
                  Evangelos Pallis},
	title = {Enhancing Security-Problem-Based Deep Learning in Mobile Edge Computing},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {49:1--49:15},
	year = {2022},
	url = {https://doi.org/10.1145/3458931},
	doi = {10.1145/3458931},
	timestamp = {Mon, 26 Jun 2023 20:52:11 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ZhengLSDCMMP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The implementation of a variety of complex and energy-intensive mobile applications by resource-limited mobile devices (MDs) is a huge challenge. Fortunately, mobile edge computing (MEC) as a new computing paragon can offer rich resources to perform all or part of the MD’s task, which greatly reduces the energy consumption of the MD and improves the quality of service (QoS) for applications. However, offloading tasks to the edge server is vulnerable to attacks such as tampering and snooping, resulting in a deep learning (DL) security feature developed by major cloud service providers. An effective security strategy method to minimize ongoing attacks in the MEC setting is proposed. The algorithm is based on the synthetic principle of a special set of strategies, and it can quickly construct suboptimal solutions even if the number of targets achieves hundreds of millions. In addition, for a given structure and a given number of patrollers, the upper bound of the protection level can be obtained, and the lower bound required for a given protection level can also be inferred. These bounds apply to universal strategies. By comparing with the previous three basic experiments, it can be proved that our algorithm is better than the previous ones in terms of security and running time.}
}


@article{DBLP:journals/toit/ZhangZWBY22,
	author = {Xiongtao Zhang and
                  Xiaomin Zhu and
                  Ji Wang and
                  Weidong Bao and
                  Laurence T. Yang},
	title = {{DANCE:} Distributed Generative Adversarial Networks with Communication
                  Compression},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {50:1--50:32},
	year = {2022},
	url = {https://doi.org/10.1145/3458929},
	doi = {10.1145/3458929},
	timestamp = {Wed, 22 May 2024 17:19:07 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ZhangZWBY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generative adversarial networks (GANs) have shown great success in deep representations learning, data generation, and security enhancement. With the development of the Internet of Things, 5th generation wireless systems (5G), and other technologies, the large volume of data collected at the edge of networks provides a new way to improve the capabilities of GANs. Due to privacy, bandwidth, and legal constraints, it is not appropriate to upload all the data to the cloud or servers for processing. Therefore, this article focuses on deploying and training GANs at the edge rather than converging edge data to the central node. To address this problem, we designed a novel distributed learning architecture for GANs, called DANCE. DANCE can adaptively perform communication compression based on the available bandwidth, while supporting both data and model parallelism training of GANs. In addition, inspired by the gossip mechanism and Stackelberg game, a compatible algorithm, AC-GAN is proposed. The theoretical analysis guarantees the convergence of the model and the existence of approximate equilibrium in AC-GAN. Both simulation and prototype system experiments show that AC-GAN can achieve better training effectiveness with less communication overhead than the SOTA algorithms, i.e., FL-GAN and MD-GAN.}
}


@article{DBLP:journals/toit/ZhangWCHXWL22,
	author = {Rui Zhang and
                  Libing Wu and
                  Shuqin Cao and
                  Xinrong Hu and
                  Shan Xue and
                  Dan Wu and
                  Qingan Li},
	title = {Task Offloading with Task Classification and Offloading Nodes Selection
                  for MEC-Enabled IoV},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {51:1--51:24},
	year = {2022},
	url = {https://doi.org/10.1145/3475871},
	doi = {10.1145/3475871},
	timestamp = {Tue, 21 Mar 2023 21:15:18 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ZhangWCHXWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Mobile Edge Computing (MEC)-based task offloading in the Internet of Vehicles (IoV) scenario, which transfers computational tasks to mobile edge nodes and fixed edge nodes with available computing resources, has attracted interest in recent years. The MEC-based task offloading can achieve low latency and low operational cost under the tasks delay constraints. However, most existing research generally focuses on how to divide and migrate these tasks to the other devices. This research ignores delay constraints and offloading node selection for different tasks. In this article, we design the MEC-enabled IoV architecture, in which all vehicles and MEC servers act as offloading nodes. Mobile offloading nodes (i.e., vehicles) and fixed offloading nodes (i.e., MEC servers) provide low latency offloading services cooperatively through roadside units. Then we propose the task offloading scheme that considers task classification and offloading nodes selection (TO-TCONS). Our goal is to minimize the total execution time of tasks. In TO-TCONS Scheme, we divide the task offloading into the same region offloading mode and cross-region offloading mode, which is based on the delay constraints of tasks and the travel time of the target vehicle. Moreover, we propose the mobile offloading nodes selection strategy to select offloading nodes for each task, which evaluates offloading candidates for each task based on computing resources and transmission rates. Simulation results demonstrate that TO-TCONS Scheme is indeed capable of reducing total latency of tasks execution under the delay constraints in MEC-enabled IoV.}
}


@article{DBLP:journals/toit/WuMWXPNX22,
	author = {Tingmin Wu and
                  Wanlun Ma and
                  Sheng Wen and
                  Xin Xia and
                  C{\'{e}}cile Paris and
                  Surya Nepal and
                  Yang Xiang},
	title = {Analysis of Trending Topics and Text-based Channels of Information
                  Delivery in Cybersecurity},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {52:1--52:27},
	year = {2022},
	url = {https://doi.org/10.1145/3483332},
	doi = {10.1145/3483332},
	timestamp = {Wed, 07 Dec 2022 23:03:34 +0100},
	biburl = {https://dblp.org/rec/journals/toit/WuMWXPNX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computer users are generally faced with difficulties in making correct security decisions. While an increasingly fewer number of people are trying or willing to take formal security training, online sources including news, security blogs, and websites are continuously making security knowledge more accessible. Analysis of cybersecurity texts from this grey literature can provide insights into the trending topics and identify current security issues as well as how cyber attacks evolve over time. These in turn can support researchers and practitioners in predicting and preparing for these attacks. Comparing different sources may facilitate the learning process for normal users by creating the patterns of the security knowledge gained from different sources. Prior studies neither systematically analysed the wide range of digital sources nor provided any standardisation in analysing the trending topics from recent security texts. Moreover, existing topic modelling methods are not capable of identifying the cybersecurity concepts completely and the generated topics considerably overlap. To address this issue, we propose a semi-automated classification method to generate comprehensive security categories to analyse trending topics. We further compare the identified 16 security categories across different sources based on their popularity and impact. We have revealed several surprising findings as follows: (1) The impact reflected from cybersecurity texts strongly correlates with the monetary loss caused by cybercrimes, (2) security blogs have produced the context of cybersecurity most intensively, and (3) websites deliver security information without caring about timeliness much.}
}


@article{DBLP:journals/toit/IvkicSGMT22,
	author = {Igor Ivkic and
                  Patrizia Sailer and
                  Antonios Gouglidis and
                  Andreas Mauthe and
                  Markus Tauber},
	title = {A Security Cost Modelling Framework for Cyber-Physical Systems},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {53:1--53:31},
	year = {2022},
	url = {https://doi.org/10.1145/3450752},
	doi = {10.1145/3450752},
	timestamp = {Mon, 26 Jun 2023 20:52:11 +0200},
	biburl = {https://dblp.org/rec/journals/toit/IvkicSGMT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-Physical Systems (CPS) are formed through interconnected components capable of computation, communication, sensing and changing the physical world. The development of these systems poses a significant challenge, since they have to be designed in a way to ensure cyber-security without impacting their performance. This article presents the Security Cost Modelling Framework (SCMF) and shows supported by an experimental study how it can be used to measure, normalise, and aggregate the overall performance of a CPS. Unlike previous studies, our approach uses different metrics to measure the overall performance of a CPS and provides a methodology for normalising the measurement results of different units to a common Cost Unit. Moreover, we show how the Security Costs can be extracted from the overall performance measurements, which allows us to quantify the overhead imposed by performing security-related tasks. Furthermore, we describe the architecture of our experimental testbed and demonstrate the applicability of SCMF in an experimental study. Our results show that measuring the overall performance and extracting the security costs using SCMF can serve as basis to redesign interactions to achieve the same overall goal at less costs.}
}


@article{DBLP:journals/toit/SonL22,
	author = {Heesuk Son and
                  Dongman Lee},
	title = {An Efficient Interaction Protocol Inference Scheme for Incompatible
                  Updates in IoT Environments},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {2},
	pages = {54:1--54:25},
	year = {2022},
	url = {https://doi.org/10.1145/3430501},
	doi = {10.1145/3430501},
	timestamp = {Thu, 09 Jun 2022 19:57:21 +0200},
	biburl = {https://dblp.org/rec/journals/toit/SonL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incompatible updates of IoT systems and protocols give rise to interoperability problems. Even though various protocol adaptation and unknown protocol inference schemes have been proposed, they either do not work where the updated protocol specifications are not given or suffer from inefficiency issues. In this work, we present an efficient protocol inference scheme for incompatible updates in IoT environments. The scheme refines an active automata learning algorithm, L*, by incorporating a knowledge base of the legacy protocol behavior into its membership query selection procedure for updated protocol behavior inference. It also infers protocol syntax based on our previous work that computes the most probable message field updates and adapts the legacy protocol message accordingly. We evaluate the proposed scheme with two case studies with the most popular IoT protocols and prove that it infers updated protocols efficiently while improving the L* algorithm’s performance for resolving the incompatibility.}
}


@article{DBLP:journals/toit/TiwariJGY22,
	author = {Prayag Tiwari and
                  Amit Kumar Jaiswal and
                  Sahil Garg and
                  Ilsun You},
	title = {{SANTM:} Efficient Self-attention-driven Network for Text Matching},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {55:1--55:21},
	year = {2022},
	url = {https://doi.org/10.1145/3426971},
	doi = {10.1145/3426971},
	timestamp = {Wed, 07 Dec 2022 23:03:34 +0100},
	biburl = {https://dblp.org/rec/journals/toit/TiwariJGY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-attention mechanisms have recently been embraced for a broad range of text-matching applications. Self-attention model takes only one sentence as an input with no extra information, i.e., one can utilize the final hidden state or pooling. However, text-matching problems can be interpreted either in symmetrical or asymmetrical scopes. For instance, paraphrase detection is an asymmetrical task, while textual entailment classification and question-answer matching are considered asymmetrical tasks. In this article, we leverage attractive properties of self-attention mechanism and proposes an attention-based network that incorporates three key components for inter-sequence attention: global pointwise features, preceding attentive features, and contextual features while updating the rest of the components. Our model follows evaluation on two benchmark datasets cover tasks of textual entailment and question-answer matching. The proposed efficient Self-attention-driven Network for Text Matching outperforms the state of the art on the Stanford Natural Language Inference and WikiQA datasets with much fewer parameters.}
}


@article{DBLP:journals/toit/PeiWGQ22,
	author = {Songwen Pei and
                  Yusheng Wu and
                  Jin Guo and
                  Meikang Qiu},
	title = {Neural Network Pruning by Recurrent Weights for Finance Market},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {56:1--56:23},
	year = {2022},
	url = {https://doi.org/10.1145/3433547},
	doi = {10.1145/3433547},
	timestamp = {Mon, 28 Aug 2023 21:41:17 +0200},
	biburl = {https://dblp.org/rec/journals/toit/PeiWGQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Convolutional Neural Networks (CNNs) and deep learning technology are applied in current financial market to rapidly promote the development of finance market and Internet economy. The continuous development of neural networks with more hidden layers improves the performance but increases the computational complexity. Generally, channel pruning methods are useful to compact neural networks. However, typical channel pruning methods would remove layers by mistake due to the static pruning ratio of manual setting, which could destroy the whole structure of neural networks. It is difficult to improve the ratio of compressing neural networks only by pruning channels while maintaining good network structures. Therefore, we propose a novel neural Networks Pruning by Recurrent Weights (NPRW) that can repeatedly evaluate the significance of weights and adaptively adjust them to compress neural networks within acceptable loss of accuracy. The recurrent weights with low sensitivity are compulsorily set to zero by evaluating the magnitude of weights, and pruned network only uses a few significant weights. Then, we add the regularization to the scaling factors on neural networks, in which recurrent weights with high sensitivity can be dynamically updated and weights of low sensitivity stay at zero invariably. By this way, the significance of channels can be quantitatively evaluated by recurrent weights. It has been verified with typical neural networks of LeNet, VGGNet, and ResNet on multiple benchmark datasets involving stock index futures, digital recognition, and image classification. The pruned LeNet-5 achieves the 58.9% reduction amount of parameters with 0.29% loss of total accuracy for Shanghai and Shenzhen 300 stock index futures. As for the CIFAR-10, the pruned VGG-19 reduces more than 50% FLOPs, and the decrease of network accuracy is less than 0.5%. In addition, the pruned ResNet-164 tested on the SVHN reduces more than 58% FLOPs with relative improvement on accuracy by 0.11%.}
}


@article{DBLP:journals/toit/RahmanKYAB22,
	author = {Mohammad Saidur Rahman and
                  Ibrahim Khalil and
                  Xun Yi and
                  Mohammed Atiquzzaman and
                  Elisa Bertino},
	title = {A Lossless Data-Hiding based IoT Data Authenticity Model in Edge-AI
                  for Connected Living},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {57:1--57:25},
	year = {2022},
	url = {https://doi.org/10.1145/3453171},
	doi = {10.1145/3453171},
	timestamp = {Tue, 21 Mar 2023 21:15:18 +0100},
	biburl = {https://dblp.org/rec/journals/toit/RahmanKYAB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing is an emerging technology for the acquisition of Internet-of-Things (IoT) data and provisioning different services in connected living. Artificial Intelligence (AI) powered edge devices (edge-AI) facilitate intelligent IoT data acquisition and services through data analytics. However, data in edge networks are prone to several security threats such as external and internal attacks and transmission errors. Attackers can inject false data during data acquisition or modify stored data in the edge data storage to hamper data analytics. Therefore, an edge-AI device must verify the authenticity of IoT data before using them in data analytics. This article presents an IoT data authenticity model in edge-AI for a connected living using data hiding techniques. Our proposed data authenticity model securely hides the data source’s identification number within IoT data before sending it to edge devices. Edge-AI devices extract hidden information for verifying data authenticity. Existing data hiding approaches for biosignal cannot reconstruct original IoT data after extracting the hidden message from it (i.e., lossy) and are not usable for IoT data authenticity. We propose the first lossless IoT data hiding technique in this article based on error-correcting codes (ECCs). We conduct several experiments to demonstrate the performance of our proposed method. Experimental results establish the lossless property of the proposed approach while maintaining other data hiding properties.}
}


@article{DBLP:journals/toit/ShenZT22,
	author = {Chaonan Shen and
                  Kai Zhang and
                  Jinshan Tang},
	title = {A {COVID-19} Detection Algorithm Using Deep Features and Discrete
                  Social Learning Particle Swarm Optimization for Edge Computing Devices},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {58:1--58:17},
	year = {2022},
	url = {https://doi.org/10.1145/3453170},
	doi = {10.1145/3453170},
	timestamp = {Mon, 28 Aug 2023 21:41:18 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ShenZT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {COVID-19 has been spread around the world and has caused a huge number of deaths. Early detection of this disease is the most efficient way to prevent its rapid spread. Due to the development of internet technology and edge intelligence, developing an early detection system for COVID-19 in the medical environment of the Internet of Things (IoT) can effectively alleviate the spread of the disease. In this paper, a detection algorithm is developed, which can detect COVID-19 effectively by utilizing the features from Chest X-ray (CXR) images. First, a pre-trained model (ResNet18) is adopted for feature extraction. Then, a discrete social learning particle swarm optimization algorithm (DSLPSO) is proposed for feature selection. By filtering redundant and irrelevant features, the dimensionality of the feature vector is reduced. Finally, the images are classified by a Support Vector Machine (SVM) for COVID-19 detection. Experimental results show that the proposed algorithm can achieve competitive performance with fewer features, which is suitable for edge computing devices with lower computation power.}
}


@article{DBLP:journals/toit/LiuZKYNP22,
	author = {Yi Liu and
                  Ruihui Zhao and
                  Jiawen Kang and
                  Abdulsalam Yassine and
                  Dusit Niyato and
                  Jialiang Peng},
	title = {Towards Communication-Efficient and Attack-Resistant Federated Edge
                  Learning for Industrial Internet of Things},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {59:1--59:22},
	year = {2022},
	url = {https://doi.org/10.1145/3453169},
	doi = {10.1145/3453169},
	timestamp = {Fri, 28 Jun 2024 14:57:07 +0200},
	biburl = {https://dblp.org/rec/journals/toit/LiuZKYNP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Edge Learning (FEL) allows edge nodes to train a global deep learning model collaboratively for edge computing in the Industrial Internet of Things (IIoT), which significantly promotes the development of Industrial 4.0. However, FEL faces two critical challenges: communication overhead and data privacy. FEL suffers from expensive communication overhead when training large-scale multi-node models. Furthermore, due to the vulnerability of FEL to gradient leakage and label-flipping attacks, the training process of the global model is easily compromised by adversaries. To address these challenges, we propose a communication-efficient and privacy-enhanced asynchronous FEL framework for edge computing in IIoT. First, we introduce an asynchronous model update scheme to reduce the computation time that edge nodes wait for global model aggregation. Second, we propose an asynchronous local differential privacy mechanism, which improves communication efficiency and mitigates gradient leakage attacks by adding well-designed noise to the gradients of edge nodes. Third, we design a cloud-side malicious node detection mechanism to detect malicious nodes by testing the local model quality. Such a mechanism can avoid malicious nodes participating in training to mitigate label-flipping attacks. Extensive experimental studies on two real-world datasets demonstrate that the proposed framework can not only improve communication efficiency but also mitigate malicious attacks while its accuracy is comparable to traditional FEL frameworks.}
}


@article{DBLP:journals/toit/ChenLSKWQ22,
	author = {Guihong Chen and
                  Xi Liu and
                  Mohammad Shorfuzzaman and
                  Ali Karime and
                  Yonghua Wang and
                  Yuanhang Qi},
	title = {MEC-Based Jamming-Aided Anti-Eavesdropping with Deep Reinforcement
                  Learning for WBANs},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {60:1--60:17},
	year = {2022},
	url = {https://doi.org/10.1145/3453186},
	doi = {10.1145/3453186},
	timestamp = {Mon, 28 Aug 2023 21:41:17 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ChenLSKWQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless body area network (WBAN) suffers secure challenges, especially the eavesdropping attack, due to constraint resources. In this article, deep reinforcement learning (DRL) and mobile edge computing (MEC) technology are adopted to formulate a DRL-MEC-based jamming-aided anti-eavesdropping (DMEC-JAE) scheme to resist the eavesdropping attack without considering the channel state information. In this scheme, a MEC sensor is chosen to send artificial jamming signals to improve the secrecy rate of the system. Power control technique is utilized to optimize the transmission power of both the source sensor and the MEC sensor to save energy. The remaining energy of the MEC sensor is concerned to ensure routine data transmission and jamming signal transmission. Additionally, the DMEC-JAE scheme integrates with transfer learning for a higher learning rate. The performance bounds of the scheme concerning the secrecy rate, energy consumption, and the utility are evaluated. Simulation results show that the DMEC-JAE scheme can approach the performance bounds with high learning speed, which outperforms the benchmark schemes.}
}


@article{DBLP:journals/toit/ShankarPETGE22,
	author = {K. Shankar and
                  Eswaran Perumal and
                  Mohamed Elhoseny and
                  Fatma Taher and
                  B. B. Gupta and
                  Ahmed A. Abd El{-}Latif},
	title = {Synergic Deep Learning for Smart Health Diagnosis of {COVID-19} for
                  Connected Living and Smart Cities},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {61:1--61:14},
	year = {2022},
	url = {https://doi.org/10.1145/3453168},
	doi = {10.1145/3453168},
	timestamp = {Mon, 05 Feb 2024 20:21:53 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ShankarPETGE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {COVID-19 pandemic has led to a significant loss of global deaths, economical status, and so on. To prevent and control COVID-19, a range of smart, complex, spatially heterogeneous, control solutions, and strategies have been conducted. Earlier classification of 2019 novel coronavirus disease (COVID-19) is needed to cure and control the disease. It results in a requirement of secondary diagnosis models, since no precise automated toolkits exist. The latest finding attained using radiological imaging techniques highlighted that the images hold noticeable details regarding the COVID-19 virus. The application of recent artificial intelligence (AI) and deep learning (DL) approaches integrated to radiological images finds useful to accurately detect the disease. This article introduces a new synergic deep learning (SDL)-based smart health diagnosis of COVID-19 using Chest X-Ray Images. The SDL makes use of dual deep convolutional neural networks (DCNNs) and involves a mutual learning process from one another. Particularly, the representation of images learned by both DCNNs is provided as the input of a synergic network, which has a fully connected structure and predicts whether the pair of input images come under the identical class. Besides, the proposed SDL model involves a fuzzy bilateral filtering (FBF) model to pre-process the input image. The integration of FBL and SDL resulted in the effective classification of COVID-19. To investigate the classifier outcome of the SDL model, a detailed set of simulations takes place and ensures the effective performance of the FBF-SDL model over the compared methods.}
}


@article{DBLP:journals/toit/ChenSWMJHHTHL22,
	author = {Min Chen and
                  Ke Shen and
                  Rui Wang and
                  Yiming Miao and
                  Yingying Jiang and
                  Kai Hwang and
                  Yixue Hao and
                  Guangming Tao and
                  Long Hu and
                  Zhongchun Liu},
	title = {Negative Information Measurement at {AI} Edge: {A} New Perspective
                  for Mental Health Monitoring},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {62:1--62:16},
	year = {2022},
	url = {https://doi.org/10.1145/3471902},
	doi = {10.1145/3471902},
	timestamp = {Mon, 27 Nov 2023 13:31:32 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ChenSWMJHHTHL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The outbreak of the corona virus disease 2019 (COVID-19) has caused serious harm to people’s physical and mental health. Due to the serious situation of the epidemic, a lot of negative energy information increases people’s psychological burden. However, effective interventions against mental health problems are not in abundance. To address such challenges, in this article, we propose the concept of negative information to describe information that has a negative impact on people’s mental health. To achieve the measurement of negative information, the level of mental health inversely measures the degree of negative information. Specifically, we design a system to measure the negative information used to monitor the mental health state of the user under the impact of negative information. The cognition of mental health is realized based on the intelligent algorithm deployed on the edge cloud, and the needs of users can be responded to in real time in practical applications. Finally, we use real collected dataset to verify the influence of negative information. The experiments show that the system can achieve negative information measurement and provide an effective countermeasure for solving mental health problems during a pandemic situation.}
}


@article{DBLP:journals/toit/LvLL22,
	author = {Zhihan Lv and
                  Ranran Lou and
                  Haibin Lv},
	title = {Edge Computing to Solve Security Issues for Infectious Disease Intelligence
                  Prevention},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {63:1--63:20},
	year = {2022},
	url = {https://doi.org/10.1145/3475869},
	doi = {10.1145/3475869},
	timestamp = {Wed, 07 Dec 2022 23:03:34 +0100},
	biburl = {https://dblp.org/rec/journals/toit/LvLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, with the rapid development of intelligent technology, it is urgent to effectively prevent infectious diseases and ensure people's privacy. The present work constructs the intelligent prevention system of infectious diseases based on edge computing by using the edge computing algorithm, and further deploys and optimizes the privacy information security defense strategy of users in the system, controls the cost, constructs the optimal conditions of the system security defense, and finally analyzes the performance of the model. The results show that the system delay decreases with the increase of power in the downlink. In the analysis of the security performance of personal privacy information, it is found that six different nodes can maintain the optimal strategy when the cost is minimized in the finite time domain and infinite time domain. In comparison with other classical algorithms in the communication field, when the intelligent prevention system of infectious diseases constructed adopts the best defense strategy, it can effectively reduce the consumption of computing resources of edge network equipment, and the prediction accuracy is obviously better than that of other algorithms, reaching 83%. Hence, the results demonstrate that the model constructed can ensure the safety performance and forecast accuracy, and achieve the best defense strategy at low cost, which provides experimental reference for the prevention and detection of infectious diseases in the later period.}
}


@article{DBLP:journals/toit/JiangGHLTL22,
	author = {Yizhang Jiang and
                  Xiaoqing Gu and
                  Lei Hua and
                  Kang Li and
                  Yuwen Tao and
                  Bo Li},
	title = {Forecasting Trend of Coronavirus Disease 2019 using Multi-Task Weighted
                  {TSK} Fuzzy System},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {64:1--64:24},
	year = {2022},
	url = {https://doi.org/10.1145/3475870},
	doi = {10.1145/3475870},
	timestamp = {Wed, 10 Apr 2024 16:20:18 +0200},
	biburl = {https://dblp.org/rec/journals/toit/JiangGHLTL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Artificial intelligence– (AI) based fog/edge computing has become a promising paradigm for infectious disease. Various AI algorithms are embedded in cooperative fog/edge devices to construct medical Internet of Things environments, infectious disease forecast systems, smart health, and so on. However, these systems are usually done in isolation, which is called single-task learning. They do not consider the correlation and relationship between multiple/different tasks, so some common information in the model parameters or data characteristics is lost. In this study, each data center in fog/edge computing is considered as a task in the multi-task learning framework. In such a learning framework, a multi-task weighted Takagi-Sugeno-Kang (TSK) fuzzy system, called MW-TSKFS, is developed to forecast the trend of Coronavirus disease 2019 (COVID-19). MW-TSKFS provides a multi-task learning strategy for both antecedent and consequent parameters of fuzzy rules. First, a multi-task weighted fuzzy c-means clustering algorithm is developed for antecedent parameter learning, which extracts the public information among all tasks and the private information of each task. By sharing the public cluster centroid and public membership matrix, the differences of commonality and individuality can be further exploited. For consequent parameter learning of MW-TSKFS, a multi-task collaborative learning mechanism is developed based on ε-insensitive criterion and L2 norm penalty term, which can enhance the generalization and forecasting ability of the proposed fuzzy system. The experimental results on the real COVID-19 time series show that the forecasting tend model based on multi-task the weighted TSK fuzzy system has a high application value.}
}


@article{DBLP:journals/toit/NiZQX22,
	author = {Tongguang Ni and
                  Jiaqun Zhu and
                  Jia Qu and
                  Jing Xue},
	title = {Labeling Privacy Protection {SVM} Using Privileged Information for
                  {COVID-19} Diagnosis},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {65:1--65:21},
	year = {2022},
	url = {https://doi.org/10.1145/3475868},
	doi = {10.1145/3475868},
	timestamp = {Sun, 15 Jan 2023 18:31:59 +0100},
	biburl = {https://dblp.org/rec/journals/toit/NiZQX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge/fog computing works at the local area network level or devices connected to the sensor or the gateway close to the sensor. These nodes are located in different degrees of proximity to the user, while the data processing and storage are distributed among multiple nodes. In healthcare applications in the Internet of things, when data is transmitted through insecure channels, its privacy and security are the main issues. In recent years, learning from label proportion methods, represented by inverse calibration (InvCal) method, have tried to predict the class label based on class label proportions in certain groups. For privacy protection, the class label of the sample is often sensitive and invisible. As a compromise, only the proportion of class labels in certain groups can be used in these methods. However, due to their weak labeling scheme, their classification performance is often unsatisfactory. In this article, a labeling privacy protection support vector machine using privileged information, called LPP-SVM-PI, is proposed to promote the accuracy of the classifier in infectious disease diagnosis. Based on the framework of the InvCal method, besides using the proportion information of the class label, the idea of learning using privileged information is also introduced to capture the additional information of groups. The slack variables in LPP-SVM-PI are represented as correcting function and projected into the correcting space so that the hidden information of training samples in groups is captured by relaxing the constraints of the classification model. The solution of LPP-SVM-PI can be transformed into a classic quadratic programming problem. The experimental dataset is collected from the Coronavirus disease 2019 (COVID-19) transcription polymerase chain reaction at Hospital Israelita Albert Einstein in Brazil. In the experiment, LPP-SVM-PI is efficiently applied for COVID-19 diagnosis.}
}


@article{DBLP:journals/toit/WangLB22,
	author = {Changda Wang and
                  Xiaowei Li and
                  Elisa Bertino},
	title = {Network Temperature: {A} Novel Statistical Index for Networks Measurement
                  and Management},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {66:1--66:20},
	year = {2022},
	url = {https://doi.org/10.1145/3511093},
	doi = {10.1145/3511093},
	timestamp = {Fri, 16 Sep 2022 20:50:07 +0200},
	biburl = {https://dblp.org/rec/journals/toit/WangLB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Being able to monitor each packet path is critical for effective measurement and management of networks. However, such detailed monitoring can be very expensive especially for large-scale networks. To address such problem, inspired by thermodynamics, which uses the statistical characteristics of a large number of molecules’ motion but not each molecule’s trajectory for analysis, we propose the new concept of network temperature together with the notions of network-specific heat and network temperature gradient. Our approach does not only provide a statistical view of the current network state consisting of all the active packet paths at each time instant, but can be used to represent transitions among network states. Our network temperature-based methods have a broad applicability, such as to DDoS detection, dynamic node importance ranking, network stability and robustness evaluation, reliable packets routing, provenance compression assessment, and so on. Numerical and/or the experimental results show that our methods are effective.}
}


@article{DBLP:journals/toit/ChenDJLMS22,
	author = {Haipeng Chen and
                  Andrew Duncklee and
                  Sushil Jajodia and
                  Rui Liu and
                  Sean R. McNamara and
                  V. S. Subrahmanian},
	title = {{PCAM:} {A} Data-driven Probabilistic Cyber-alert Management Framework},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {67:1--67:24},
	year = {2022},
	url = {https://doi.org/10.1145/3511101},
	doi = {10.1145/3511101},
	timestamp = {Mon, 05 Feb 2024 20:21:53 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ChenDJLMS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose PCAM, a Probabilistic Cyber-Alert Management framework, that enables chief information security officers to better manage cyber-alerts. Workers in Cyber Security Operation Centers usually work in 8- or 12-hour shifts. Before a shift, PCAM analyzes data about all past alerts and true alerts during the shift time-frame to schedule a given set of analysts in accordance with workplace constraints so that the expected number of “uncovered” true alerts (i.e., true alerts not shown to an analyst) is minimized. PCAM achieves this by formulating the problem as a bi-level non-linear optimization problem and then shows how to linearize and solve this complex problem. We have tested PCAM extensively. Using statistics derived from 44 days of real-world alert data, we are able to minimize the expected number of true alerts that are not manually examined by a team consisting of junior, senior, and principal analysts. We are also able to identify the optimal mix of junior, senior, and principal analysts needed during both day and night shifts given a budget, outperforming some reasonable baselines. We tested PCAM’s proposed schedule (from statistics on 44 days) on a further 6 days of data, using an off-the-shelf false alarm classifier to predict which alerts are real and which ones are false. Moreover, we show experimentally that PCAM is robust to various kinds of errors in the statistics used.}
}


@article{DBLP:journals/toit/GuALZH22,
	author = {Bo Gu and
                  Mamoun Alazab and
                  Ziqi Lin and
                  Xu Zhang and
                  Jun Huang},
	title = {AI-Enabled Task Offloading for Improving Quality of Computational
                  Experience in Ultra Dense Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {68:1--68:17},
	year = {2022},
	url = {https://doi.org/10.1145/3491217},
	doi = {10.1145/3491217},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/GuALZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-access edge computing (MEC) and ultra-dense networking (UDN) are recognized as two promising paradigms for future mobile networks that can be utilized to improve the spectrum efficiency and the quality of computational experience (QoCE). In this paper, we study the task offloading problem in an MEC-enabled UDN architecture with the aim to minimize the task duration while satisfying the energy budget constraints. Due to the dynamics associated with the environment and parameter uncertainty, designing an optimal task offloading algorithm is highly challenging. Consequently, we propose an online task offloading algorithm based on a state-of-the-art deep reinforcement learning (DRL) technique: asynchronous advantage actor-critic (A3C). It is worthy of remark that the proposed method requires neither instantaneous channel state information (CSI) nor prior knowledge of the computational capabilities of the base stations. Simulations show that the our method is able to learn a good offloading policy to obtain a near-optimal task allocation while meeting energy budget constraints of mobile devices in the UDN environment.}
}


@article{DBLP:journals/toit/XuIS22,
	author = {Lanyu Xu and
                  Arun Iyengar and
                  Weisong Shi},
	title = {\emph{NLUBroker}: {A} QoE-driven Broker System for Natural Language
                  Understanding Services},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {69:1--69:29},
	year = {2022},
	url = {https://doi.org/10.1145/3497807},
	doi = {10.1145/3497807},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/XuIS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud-based Natural Language Understanding (NLU) services are becoming more popular with the development of artificial intelligence. More applications are integrated with cloud-based NLU services to enhance the way people communicate with machines. However, with NLU services provided by different companies powered by unrevealed AI technology, how to choose the best one is a problem for developers. Existing tools that can provide guidance to developers and make recommendations based on their needs are severely limited. This article comprehensively evaluates multiple state-of-the-art NLU services, and the results indicate that there is no absolute winner for different usage requirements. Motivated by this observation, we provide several insights and propose\xa0NLUBroker, a Quality of Experience-driven (QoE-driven) broker system, to select the proper service according to the environment. NLUBroker senses the client and service status and leverages a solution to the multi-armed bandit problem to conduct online learning, aiming to achieve maximum expected QoE. The performance of\xa0NLUBroker is evaluated in both simulation and real-world environments, and the evaluation results demonstrate that\xa0NLUBroker is an efficient solution for selecting NLU services. It is adaptive to changes in the environment, outperforms three baseline methods we evaluated and improves overall QoE up to 1.5× for the evaluated state-of-the-art NLU services.}
}


@article{DBLP:journals/toit/DoanRHB22,
	author = {Trinh Viet Doan and
                  Roland van Rijswijk{-}Deij and
                  Oliver Hohlfeld and
                  Vaibhav Bajpai},
	title = {An Empirical View on Consolidation of the Web},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {70:1--70:30},
	year = {2022},
	url = {https://doi.org/10.1145/3503158},
	doi = {10.1145/3503158},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/DoanRHB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The majority of Web content is delivered by only a few companies that provide Content Delivery Infrastructuress (CDIss) such as Content Delivery Networkss (CDNss) and cloud hosts. Due to increasing concerns about trends of centralization, empirical studies on the extent and implications of resulting Internet consolidation are necessary. Thus, we present an empirical view on consolidation of the Web by leveraging datasets from two different measurement platforms. We first analyze Web consolidation around CDIs at the level of landing webpages, before narrowing down the analysis to a level of embedded page resources. The datasets cover 1(a) longitudinal measurements of DNS records for 166.5 M Web domains over five years, 1(b) measurements of DNS records for Alexa Top 1 M over a month and (2) measurements of page loads and renders for 4.3 M webpages, which include data on 392.3 M requested resources. We then define CDIs penetration as the ratio of CDI-hosted objects to all measured objects, which we use to quantify consolidation around CDIs. We observe that CDI penetration has close to doubled since 2015, reaching a lower bound of 15% for all .com, .net, and .org Web domains as of January 2020. Overall, we find a set of six CDIss to deliver the majority of content across all datasets, with these six CDIss being responsible for more than 80% of all 221.9 M CDI-delivered resources (56.6% of all resources in total). We find high dependencies of Web content on a small group of CDIss, in particular, for fonts, ads, and trackers, as well as JavaScript resources such as jQuery. We further observe CDIss to play important roles in rolling out IPv6 and TLS\xa01.3 support. Overall, these observations indicate a potential oligopoly, which brings both benefits but also risks to the future of the Web.}
}


@article{DBLP:journals/toit/HossainHSJKV22,
	author = {Md. Arafat Hossain and
                  Jun Han and
                  Jean{-}Guy Schneider and
                  Jiaojiao Jiang and
                  Muhammad Ashad Kabir and
                  Steve Versteeg},
	title = {Extracting Formats of Service Messages with Varying Payloads},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {71:1--71:31},
	year = {2022},
	url = {https://doi.org/10.1145/3503159},
	doi = {10.1145/3503159},
	timestamp = {Sun, 02 Oct 2022 15:51:54 +0200},
	biburl = {https://dblp.org/rec/journals/toit/HossainHSJKV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Having precise specifications of service APIs is essential for many Software Engineering activities. Unfortunately, available documentation of services is often inadequate and/or imprecise and, hence, cannot be fully relied upon. Generating service documentation manually is a tedious and error-prone task, especially in light of changes to services. Therefore, there is a need for automated support in generating service documentation. In this work, we present a novel approach to infer the API of a service by analyzing recorded messages sent to and received from this service. Our approach includes a novel, two-level clustering technique to cluster messages, a step that many existing approaches to infer message formats fail to perform precisely in the presence of significant variation of payload information of the available messages. We have evaluated our approach on message traces from four different real-world services. The experimental result shows that our approach is more effective than existing techniques in extracting correct message formats from recorded messages.}
}


@article{DBLP:journals/toit/Vargas-SolarKEZ22,
	author = {Genoveva Vargas{-}Solar and
                  Maysaa Khalil and
                  Javier A. Espinosa{-}Oviedo and
                  Jos{\'{e}}{-}Luis Zechinelli{-}Martini},
	title = {{GREENHOME:} {A} Household Energy Consumption and CO\({}_{\mbox{2}}\)
                  Footprint Metering Environment},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {72:1--72:31},
	year = {2022},
	url = {https://doi.org/10.1145/3505264},
	doi = {10.1145/3505264},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/Vargas-SolarKEZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article presents the GREENHOME environment, a toolkit providing several data analytical tools for metering household energy consumption and CO2 footprint under different perspectives. GREENHOME enables a multi-perspective analysis of household energy consumption and CO2 footprint using and combining several variables through various statistics and data mining algorithms. To test GREENHOME, the article reports on experiments conducted for modelling and forecasting energy consumption and CO2 footprint in the context of the Triple-A European project.}
}


@article{DBLP:journals/toit/PavlopoulouC22,
	author = {Niki Pavlopoulou and
                  Edward Curry},
	title = {PoSSUM: An Entity-centric Publish/Subscribe System for Diverse Summarization
                  in Internet of Things},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {73:1--73:30},
	year = {2022},
	url = {https://doi.org/10.1145/3507911},
	doi = {10.1145/3507911},
	timestamp = {Mon, 28 Aug 2023 21:41:18 +0200},
	biburl = {https://dblp.org/rec/journals/toit/PavlopoulouC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Users are interested in entity information provided by multiple sensors in the Internet of Things. The challenges regarding this environment span from data-centric ones due to data integration, heterogeneity, and enrichment, to user-centric ones due to the need for high-level data interpretation and usability for non-expert users, to system-centric ones due to resource constraints. Publish/Subscribe systems (PSSs) are suitable schemes for large-scale applications, but they are limited in dealing with the data and user challenges. In this article, we propose PoSSUM, a novel entity-centric PSS that provides entity summaries for user-friendly subscriptions through data integration, a novel Density-Based VARiance Clustering (DBVARC) for diverse entity summarization that is parameter-free and partly incremental, reasoning rules, and a novel Triple2Rank scoring for top-k filtering based on importance, informativeness, and diversity. We introduce a novel evaluation methodology that creates ground truths and metrics that capture the quality of entity summaries. We compare our approach with a previous dynamic approach and a static diverse entity summarization approach that we adapted to dynamic environments. The evaluation results for two use cases, Healthcare and Smart Cities, show that when users are provided with less information, their data diversity desire could reach up to 80%. Summarization approaches achieve from 80% to 99% message reduction, with PoSSUM having the best-ranking quality for more than half of the entities by a significant margin. PoSSUM has the highest conceptual clustering F-score, ranging from 0.69 to 0.83, and a redundancy-aware F-score up to 0.95, with cases, where it is almost two times better than the other approaches. PoSSUM takes 50% or less clustering processing time and it performs scoring significantly faster for larger windows. It also has comparable end-to-end latency and throughput values, and it occupies a third of the memory compared to the second-best approach.}
}


@article{DBLP:journals/toit/SoldaniCPB22,
	author = {Jacopo Soldani and
                  Marco Cameriero and
                  Giulio Paparelli and
                  Antonio Brogi},
	title = {Modelling and Analysing Replica- and Fault-aware Management of Horizontally
                  Scalable Applications},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {74:1--74:32},
	year = {2022},
	url = {https://doi.org/10.1145/3511302},
	doi = {10.1145/3511302},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/SoldaniCPB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern enterprise applications integrate multiple interdependent software components, whose management must be suitably coordinated. This must be done by taking into account all inter-component dependencies, the faults potentially affecting them, and the fact that each component can be horizontally scaled, i.e., \xa0that multiple instances of each component can be spawned or destroyed, depending on application needs. In this article, we introduce a novel solution for suitably modelling and analysing the replica- and fault-aware management of multi-component applications, based on topology graphs and management protocols. More precisely, we first introduce a compositional model of the management behaviour of the (possibly multiple) instances of the components forming an application, faults included. We then show how this model enables automating various useful analyses, from checking the validity of management plans to automatically determining management plans allowing the instance of an application to reach and maintain a desired target configuration.}
}


@article{DBLP:journals/toit/XuSWGYX22,
	author = {Minxian Xu and
                  Chenghao Song and
                  Huaming Wu and
                  Sukhpal Singh Gill and
                  Kejiang Ye and
                  Chengzhong Xu},
	title = {esDNN: Deep Neural Network Based Multivariate Workload Prediction
                  in Cloud Computing Environments},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {75:1--75:24},
	year = {2022},
	url = {https://doi.org/10.1145/3524114},
	doi = {10.1145/3524114},
	timestamp = {Mon, 28 Aug 2023 21:41:18 +0200},
	biburl = {https://dblp.org/rec/journals/toit/XuSWGYX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud computing has been regarded as a successful paradigm for IT industry by providing benefits for both service providers and customers. In spite of the advantages, cloud computing also suffers from distinct challenges, and one of them is the inefficient resource provisioning for dynamic workloads. Accurate workload predictions for cloud computing can support efficient resource provisioning and avoid resource wastage. However, due to the high-dimensional and high-variable features of cloud workloads, it is difficult to predict the workloads effectively and accurately. The current dominant work for cloud workload prediction is based on regression approaches or recurrent neural networks, which fail to capture the long-term variance of workloads. To address the challenges and overcome the limitations of existing works, we proposed an efficient supervised learning-based Deep Neural Network (esDNN) approach for cloud workload prediction. First, we utilize a sliding window to convert the multivariate data into a supervised learning time series that allows deep learning for processing. Then, we apply a revised Gated Recurrent Unit (GRU) to achieve accurate prediction. To show the effectiveness of esDNN, we also conduct comprehensive experiments based on realistic traces derived from Alibaba and Google cloud data centers. The experimental results demonstrate that esDNN can accurately and efficiently predict cloud workloads. Compared with the state-of-the-art baselines, esDNN can reduce the mean square errors significantly, e.g., 15%. rather than the approach using GRU only. We also apply esDNN for machines auto-scaling, which illustrates that esDNN can reduce the number of active hosts efficiently, thus the costs of service providers can be optimized.}
}


@article{DBLP:journals/toit/YusBMV22,
	author = {Roberto Yus and
                  Georgios Bouloukakis and
                  Sharad Mehrotra and
                  Nalini Venkatasubramanian},
	title = {The SemIoTic Ecosystem: {A} Semantic Bridge between IoT Devices and
                  Smart Spaces},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {76:1--76:33},
	year = {2022},
	url = {https://doi.org/10.1145/3527241},
	doi = {10.1145/3527241},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/YusBMV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart space administration and application development is challenging in part due to the semantic gap that exists between the high-level requirements of users and the low-level capabilities of IoT devices. The stakeholders in a smart space are required to deal with communicating with specific IoT devices, capturing data, processing it, and abstracting it out to generate useful inferences. Additionally, this makes reusability of smart space applications difficult, since they are developed for specific sensor deployments. In this article, we present a holistic approach to IoT smart spaces, the SemIoTic ecosystem, to facilitate application development, space management, and service provision to its inhabitants. The ecosystem is based on a centralized repository, where developers can advertise their space-agnostic applications, and a SemIoTic system deployed in each smart space that interacts with those applications to provide them with the required information. SemIoTic applications are developed using a metamodel that defines high-level concepts abstracted from the smart space about the space itself and the people within it. Application requirements can be expressed then in terms of user-friendly high-level concepts, which are automatically translated by SemIoTic into sensor/actuator commands adapted to the underlying device deployment in each space. We present a reference implementation of the ecosystem that has been deployed at the University of California, Irvine and is abstracting data from hundreds of sensors in the space and providing applications to campus members.}
}


@article{DBLP:journals/toit/TedeschiNJJ22,
	author = {Enrico Tedeschi and
                  Tor{-}Arne S. Nordmo and
                  Dag Johansen and
                  H{\aa}vard D. Johansen},
	title = {On Optimizing Transaction Fees in Bitcoin using {AI:} Investigation
                  on Miners Inclusion Pattern},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {77:1--77:28},
	year = {2022},
	url = {https://doi.org/10.1145/3528669},
	doi = {10.1145/3528669},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/TedeschiNJJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The transaction-rate bottleneck built into popular proof-of-work (PoW)-based cryptocurrencies, like Bitcoin and Ethereum, leads to fee markets where transactions are included according to a first-price auction for block space. Many attempts have been made to adjust and predict the fee volatility, but even well-formed transactions sometimes experience unexpected delays and evictions unless a substantial fee is offered. In this article, we propose a novel transaction inclusion model that describes the mechanisms and patterns governing miners decisions to include individual transactions in the Bitcoin system. Using this model we devise a Machine Learning (ML) approach to predict transaction inclusion. We evaluate our predictions method using historical observations of the Bitcoin network from a five month period that includes more than 30 million transactions and 120 million entries. We find that our Machine Learning (ML) model can predict fee volatility with an accuracy of up to 91%. Our findings enable Bitcoin users to improve their fee expenses and the approval time for their transactions.}
}


@article{DBLP:journals/toit/MurturiD22,
	author = {Ilir Murturi and
                  Schahram Dustdar},
	title = {{DECENT:} {A} Decentralized Configurator for Controlling Elasticity
                  in Dynamic Edge Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {78:1--78:21},
	year = {2022},
	url = {https://doi.org/10.1145/3530692},
	doi = {10.1145/3530692},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MurturiD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advancements in distributed systems have enabled deploying low-latency and highly resilient edge applications close to the IoT domain at the edge of the network. The broad range of edge application requirements combined with heterogeneous, resource-constrained, and dynamic edge networks make it particularly challenging to configure and deploy them. Besides that, missing elastic capabilities on the edge makes it difficult to operate such applications under dynamic workloads. To this end, this article proposes a lightweight, self-adaptive, and decentralized mechanism (DECENT) for (1) deploying edge applications on edge resources and on premises of Edge-Cloud infrastructure and (2) controlling elasticity requirements. DECENT enables developers to characterize their edge applications by specifying elasticity requirements, which are automatically captured, interpreted, and enforced by our decentralized elasticity interpreters. In response to dynamic workloads, edge applications automatically adapt in compliance with their elasticity requirements. We discuss the architecture, processes of the approach, and the experiment conducted on a real-world testbed to validate its feasibility on low-powered edge devices. Furthermore, we show performance and adaptation aspects through an edge safety application and its evolution in elasticity space (i.e., cost, resource, and quality).}
}


@article{DBLP:journals/toit/LeHAT22,
	author = {Tu Le and
                  Danny Yuxing Huang and
                  Noah J. Apthorpe and
                  Yuan Tian},
	title = {SkillBot: Identifying Risky Content for Children in Alexa Skills},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {79:1--79:31},
	year = {2022},
	url = {https://doi.org/10.1145/3539609},
	doi = {10.1145/3539609},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/LeHAT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many households include children who use voice personal assistants (VPA) such as Amazon Alexa. Children benefit from the rich functionalities of VPAs and third-party apps but are also exposed to new risks in the VPA ecosystem. In this article, we first investigate “risky” child-directed voice apps that contain inappropriate content or ask for personal information through voice interactions. We build SkillBot—a natural language processing-based system to automatically interact with VPA apps and analyze the resulting conversations. We find 28 risky child-directed apps and maintain a growing dataset of 31,966 non-overlapping app behaviors collected from 3,434 Alexa apps. Our findings suggest that although child-directed VPA apps are subject to stricter policy requirements and more intensive vetting, children remain vulnerable to inappropriate content and privacy violations. We then conduct a user study showing that parents are concerned about the identified risky apps. Many parents do not believe that these apps are available and designed for families/kids, although these apps are actually published in Amazon’s “Kids” product category. We also find that parents often neglect basic precautions, such as enabling parental controls on Alexa devices. Finally, we identify a novel risk in the VPA ecosystem: confounding utterances or voice commands shared by multiple apps that may cause a user to interact with a different app than intended. We identify 4,487 confounding utterances, including 581 shared by child-directed and non-child-directed apps. We find that 27% of these confounding utterances prioritize invoking a non-child-directed app over a child-directed app. This indicates that children are at real risk of accidentally invoking non-child-directed apps due to confounding utterances.}
}


@article{DBLP:journals/toit/ShinKH22,
	author = {Hyungjune Shin and
                  Dongyoung Koo and
                  Junbeom Hur},
	title = {Secure and Efficient Hybrid Data Deduplication in Edge Computing},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {3},
	pages = {80:1--80:25},
	year = {2022},
	url = {https://doi.org/10.1145/3537675},
	doi = {10.1145/3537675},
	timestamp = {Thu, 22 Sep 2022 19:57:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ShinKH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an extension of cloud computing, edge computing introduces additional intermediate devices, called edge nodes near clients, providing computing services on behalf of the central cloud more efficiently. Although edge computing brings several benefits such as low latency and bandwidth savings on the edge side, rapid increase in the amount of data transmitted to the central cloud hinders efficient utilization of the storage system on the central cloud side especially when the data from edge devices are encrypted. To mitigate this issue in a privacy-preserving manner, data deduplication techniques for encrypted data have been extensively studied to enhance both the security and efficiency in the conventional cloud system with two different approaches. A server-side secure deduplication approach protects data privacy but impairs network efficiency by allowing duplicate uploads, while a client-side one improves network efficiency but suffers from potential information leakage due to its vulnerability to the side-channel attack. In this article, we propose a hybrid secure deduplication scheme for edge computing, which guarantees both advantages of the aforementioned two approaches. Specifically, our scheme guarantees data privacy by applying the server-side deduplication technique between the client and the edge nodes and maximizes network efficiency through the client-side deduplication technique between the edge nodes and the cloud. In addition, we devise a novel additively homomorphic encryption for efficient deduplication operations in the resource-limited edge nodes. Based on our experimental results, the proposed scheme reduces the communication costs by approximately 2.5 times for a storage server when the duplicate ratio is 50%, and the response time is reduced by about 2 times when the data size is 16 MB.}
}


@article{DBLP:journals/toit/YiCHCN22,
	author = {Haibo Yi and
                  Ruinan Chi and
                  Xin Huang and
                  Xuejun Cai and
                  Zhe Nie},
	title = {Improving Security of Internet of Vehicles Based on Post-quantum Signatures
                  with Systolic Divisions},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {82:1--82:15},
	year = {2022},
	url = {https://doi.org/10.1145/3410445},
	doi = {10.1145/3410445},
	timestamp = {Sat, 29 Apr 2023 19:27:47 +0200},
	biburl = {https://dblp.org/rec/journals/toit/YiCHCN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) techniques have been employed in many areas, e.g., vehicles, smart home, and medicine. Among the applications of IoTs, the Internet of Vehicles (IoV) is one of the most popular techniques. IoVs are protected by public key cryptographic systems, such as RSA and ECC. However, such systems are vulnerable to quantum computer attacks. Thus, we improve the security of IoV-based post-quantum signatures, which can resist quantum computer attacks. The key operations are divisions in a finite field. Hence, we improve the security of IoV-based post-quantum signatures with division by employing systolic architectures. We propose a systolic architecture for computing division in composite fields. After that, we improve the IoT security-based post-quantum signatures with systolic divisions. We test and verify our design on a Field-Programmable Gate Array (FPGA); the experimental results confirm our estimates. Furthermore, the optimized method proposed can be further applied to various applications like solving system of linear equations and cryptographic applications for IoT security.}
}


@article{DBLP:journals/toit/SongCRY22,
	author = {Xiao Song and
                  Kai Chen and
                  Xiaoxiang Ren and
                  Haitao Yuan},
	title = {Pedestrian Trajectory Prediction in Heterogeneous Traffic using Facial
                  Keypoints-based Convolutional Encoder-decoder Network},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {83:1--83:14},
	year = {2022},
	url = {https://doi.org/10.1145/3410444},
	doi = {10.1145/3410444},
	timestamp = {Tue, 22 Aug 2023 13:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/toit/SongCRY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future pedestrian trajectory prediction offers great prospects for many practical applications such as unmanned vehicles, building evacuation design and robotic path planning. Most existing methods focus on social interaction among pedestrians but ignore the fact that heterogeneous traffic objects (cars, dogs, bicycles, motorcycles, etc.) have significant influence on the future trajectory of a subject pedestrian. Also, the walking direction intention of a pedestrian may be referred by his/her facial keypoints. Considering this, this work proposes to predict a pedestrian's future trajectory by jointly using neighboring heterogeneous traffic information and his/her facial keypoints. To fulfill this, an end-to-end facial keypoints-based convolutional encoder-decoder network (FK-CEN) is designed, in which the heterogeneous traffic and facial keypoints are input. After training, FK-CEN is evaluated on 5 crowded video sequences collected from the public datasets MOT-16 and MOT-17. Experimental results demonstrate that it outperforms state-of-the-art approaches, in terms of prediction errors.}
}


@article{DBLP:journals/toit/RaviTRHA22,
	author = {Chandrasekar Ravi and
                  Anmol Tigga and
                  G. Thippa Reddy and
                  Saqib Hakak and
                  Mamoun Alazab},
	title = {Driver Identification Using Optimized Deep Learning Model in Smart
                  Transportation},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {84:1--84:17},
	year = {2022},
	url = {https://doi.org/10.1145/3412353},
	doi = {10.1145/3412353},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/RaviTRHA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Intelligent Transportation System (ITS) is said to revolutionize the travel experience by making it safe, secure, and comfortable for the people. Although vehicles have been automated up to a certain extent, it still has critical security issues that require thorough study and advanced solutions. The security vulnerabilities of ITS allows the attacker to steal the vehicle. Therefore, the identification of drivers is required in order to develop a safe and secure system so that the vehicles can be protected from theft. There are two ways in which a driver can be identified: 1) face recognition of the driver, and 2) based on driving behavior. Face recognition includes image processing of 2-D images and learning of the features, which require high computational power. Drivers are known to have unique driving styles, whose data can be captured by the sensors. Therefore, the second method identifies drivers based on the analysis of the sensor data and it requires comparatively lesser computational power. In this paper, an optimized deep learning model is trained on the sensor data to correctly identify the drivers. The Long Short-Term Memory (LSTM) deep learning model is optimized for better performance. The novelty of the approach in this work is the inclusion of hyperparameter tuning using a nature-inspired optimization algorithm, which is an important and essential step in discovering the optimal hyperparameters for training the model which in turn increases the accuracy. The CAN-BUS dataset is used for experimentation and evaluation of the training model. Evaluation parameters such as accuracy, precision score, F1 score, and ROC AUC curve are considered to evaluate the performance of the model.}
}


@article{DBLP:journals/toit/LiangLG22,
	author = {Yangfan Liang and
                  Yining Liu and
                  Brij B. Gupta},
	title = {{PPRP:} Preserving-Privacy Route Planning Scheme in VANETs},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {85:1--85:18},
	year = {2022},
	url = {https://doi.org/10.1145/3430507},
	doi = {10.1145/3430507},
	timestamp = {Sun, 12 Nov 2023 02:19:58 +0100},
	biburl = {https://dblp.org/rec/journals/toit/LiangLG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Route planning helps a vehicle to share a message with the roadside units (RSUs) on its path in advance, which greatly speeds the authentication between the vehicle and the RSUs when the vehicle enters the RSUs’ coverage. In addition, since only a small amount of necessary information needs to be shared between the vehicle and the RSUs, route planning can reduce the storage overhead of the vehicle’s on-board unit (OBU) and the RSUs. However, the message sharing requires the assistance of the certification authority (CA), which will lead CA easily to obtain the vehicle’s planning route. Although CA knows the vehicle’s registration information and helps the vehicle to communicate with RSUs, it is unacceptable that the path of their vehicle is obtained by CA for most drivers. In fact, vehicle’s sensitive information such as planning route, starting time, stop place, should be privacy for others including CA. Inspired with the method of oblivious transfer, a preserving-privacy route planning scheme in VANETs is proposed in this article, in which, a vehicle deduces the information of RSUs on its path with the help of CA, while CA knows nothing about which RSUs’ information has been deduced by the vehicle. Later, fast authentication or other service is easily achieved between the vehicle and the RSUs (V2R) with the pre-shared information. After V2R authentication, vehicles could easily communicate with adjacent vehicles with the help of RSUs (V2V). Finally, compared with related schemes, performance evaluation illustrates the proposed scheme is better in terms of time consumption.}
}


@article{DBLP:journals/toit/MehrabiJ22,
	author = {Mohamad Ali Mehrabi and
                  Alireza Jolfaei},
	title = {Efficient Cryptographic Hardware for Safety Message Verification in
                  Internet of Connected Vehicles},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {86:1--86:16},
	year = {2022},
	url = {https://doi.org/10.1145/3431499},
	doi = {10.1145/3431499},
	timestamp = {Mon, 28 Aug 2023 21:41:18 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MehrabiJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An important security requirement in automotive networks is to authenticate, sign, and verify thousands of short messages per second by each vehicle. This requirement mandates the use of a high speed Elliptic Curve Cryptography (ECC) hardware. The Residue Number Systems (RNS) provide a natural parallelism and carry-free operations that could speed-up long integer arithmetics of cryptographic algorithms. In this article, we propose a high-speed RNS Montgomery modular reduction units with parallel computing to reduce the latency of the field modular operations. We propose a fully RNS-based ECC scalar multiplication co-processor for NIST-P256r1 and Brainpool256r1 standard curves and improved the scalar multiplication speed using NAF and DBC numbering systems. Compared to the literature, our scheme provides faster computation without compromising the security level. The performance of our fully RNS-ECC point multiplication meets the requirements of the automotive industry.}
}


@article{DBLP:journals/toit/WangNNGWGK22,
	author = {Xiaojie Wang and
                  Laisen Nie and
                  Zhaolong Ning and
                  Lei Guo and
                  Guoyin Wang and
                  Xinbo Gao and
                  Neeraj Kumar},
	title = {Deep Learning-Based Network Traffic Prediction for Secure Backbone
                  Networks in Internet of Vehicles},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {87:1--87:20},
	year = {2022},
	url = {https://doi.org/10.1145/3433548},
	doi = {10.1145/3433548},
	timestamp = {Tue, 06 Feb 2024 13:16:33 +0100},
	biburl = {https://dblp.org/rec/journals/toit/WangNNGWGK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Vehicles (IoV), as a special application of Internet of Things (IoT), has been widely used for Intelligent Transportation System (ITS), which leads to complex and heterogeneous IoV backbone networks. Network traffic prediction techniques are crucial for efficient and secure network management, such as routing algorithm, network planning, and anomaly and intrusion detection. This article studies the problem of end-to-end network traffic prediction in IoV backbone networks, and proposes a deep learning-based method. The constructed system considers the spatio-temporal feature of network traffic, and can capture the long-range dependence of network traffic. Furthermore, a threshold-based update mechanism is put forward to improve the real-time performance of the designed method by using Q-learning. The effectiveness of the proposed method is evaluated by a real network traffic dataset.}
}


@article{DBLP:journals/toit/TianPQC22,
	author = {Hui Tian and
                  Fang Peng and
                  Hanyu Quan and
                  Chin{-}Chen Chang},
	title = {Identity-Based Public Auditing for Cloud Storage of Internet-of-Vehicles
                  Data},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {88:1--88:24},
	year = {2022},
	url = {https://doi.org/10.1145/3433543},
	doi = {10.1145/3433543},
	timestamp = {Wed, 29 Mar 2023 13:54:56 +0200},
	biburl = {https://dblp.org/rec/journals/toit/TianPQC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Vehicles (IoV), with the help of cloud computing, can provide rich and powerful application services for vehicles and drivers by sharing and analysing various IoV data. However, how to ensure the integrity of IoV data with multiple sources and diversity outsourced in the cloud is still an open challenge. To address this concern, this paper first presents an identity-based public auditing scheme for cloud storage of IoV data, which can fully achieve the essential function and security requirements, such as classified auditing, multi-source auditing and privacy protection. Particularly, we design a new authenticated data structure, called data mapping table, to track the distribution of each type of IoV data to ensure fine and rapid audits. Moreover, our scheme can reduce the overheads for both the key management and the generation of block tags. We formally prove the security of the presented scheme and evaluate its performance by comprehensive comparisons with the state-of-the-art schemes designed for traditional scenarios. The theoretical analyses and experimental results demonstrate that our scheme can securely and efficiently realize public auditing for IoV data, and outperforms the previous ones in both the computation and communication overheads in most cases.}
}


@article{DBLP:journals/toit/SekaranAPR22,
	author = {Ramesh Sekaran and
                  Fadi M. Al{-}Turjman and
                  Rizwan Patan and
                  Velmani Ramasamy},
	title = {Tripartite Transmitting Methodology for Intermittently Connected Mobile
                  Network {(ICMN)}},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {89:1--89:18},
	year = {2022},
	url = {https://doi.org/10.1145/3433545},
	doi = {10.1145/3433545},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/SekaranAPR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile network is a collection of devices with dynamic behavior where devices keep moving, which may lead to the network track to be connected or disconnected. This type of network is called Intermittently Connected Mobile Network (ICMN). The ICMN network is designed by splitting the region into `n' regions, ensuring it is a disconnected network. This network holds the same topological structure with mobile devices in it. This type of network routing is a challenging task. Though research keeps deriving techniques to achieve efficient routing in ICMN such as Epidemic, Flooding, Spray, copy case, Probabilistic, and Wait, these derived techniques for routing in ICMN are wise with higher packet delivery ratio, minimum latency, lesser overhead, and so on. A new routing schedule has been enacted comprising three optimization techniques such as Privacy-Preserving Ant Routing Protocol (PPARP), Privacy-Preserving Routing Protocol (PPRP), and Privacy-Preserving Bee Routing Protocol (PPBRP). In this paper, the enacted technique gives an optimal result following various network characteristics. Algorithms embedded with productive routing provide maximum security. Results are pointed out by analysis taken from spreading false devices into the network and its effectiveness at worst case. This paper also aids with the comparative results of enacted algorithms for secure routing in ICMN.}
}


@article{DBLP:journals/toit/ManogaranRSKXS22,
	author = {Gunasekaran Manogaran and
                  Bharat S. Rawal and
                  Vijayalakshmi Saravanan and
                  Priyan Malarvizhi Kumar and
                  Qin Xin and
                  P. Mohamed Shakeel},
	title = {Token-Based Authorization and Authentication for Secure Internet of
                  Vehicles Communication},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {90:1--90:20},
	year = {2022},
	url = {https://doi.org/10.1145/3491202},
	doi = {10.1145/3491202},
	timestamp = {Sun, 18 Feb 2024 17:03:25 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ManogaranRSKXS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Vehicles (IoV) communication platform provides seamless information exchange facilities in a dynamic mobile city environment. Heterogeneous communication is a common medium for information exchange through autonomous resources distributed and accessed using infrastructure units. Cyber-security is a primary concern in accessing autonomous information from the distributed resources due to anonymity and different types of targeted adversaries. This article proposes token-based authorization and authentication (TAA) for securing IoV communications. The proposed method relies on blockchain technology and random forest learning for authorization and key management for authentication, respectively. In this process, frequent change in tokens and key update features are restricted in a view to maximize the seamlessness in information exchange. Authentication is preceded by knowledge of the data classification without errors to prevent additional overhead. Blockchain-based authorization helps to update specific fields of the tokens to retain the communication ratio by reducing vehicle-to-vehicle losses. The performance of the proposed method is assessed using appropriate simulations for these metrics by varying vehicle density, error rate, and classification sets.}
}


@article{DBLP:journals/toit/ZhouMGW22,
	author = {Ao Zhou and
                  Xiao Ma and
                  Siyi Gao and
                  Shangguang Wang},
	title = {Providing Reliable Service for Parked-vehicle-assisted Mobile Edge
                  Computing},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {91:1--91:24},
	year = {2022},
	url = {https://doi.org/10.1145/3514242},
	doi = {10.1145/3514242},
	timestamp = {Mon, 30 Oct 2023 12:08:58 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ZhouMGW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, a growing number of computation-intensive applications appear in our daily life. Those applications make the loads of both the core network and the mobile devices, in terms of energy and bandwidth, hugely increase. Offloading computation-intensive tasks to edge cloud is proposed to address this issue. Since edge clouds have limited computation resources compared with the remote cloud, they would get over-loaded because of the heavy computation burden. Parked-vehicle-assisted mobile edge computing becomes one of the promising solutions for this problem. However, several critical issues in parked-vehicle-assisted mobile edge computing would result in low reliable edge service. The open environment would bring about uncertainty, and the data privacy is hard to ensure. In addition, different from edge cloud, each parked vehicle only has limited parking duration and can leave unexpectedly for personal reasons. Moreover, edge cloud and vehicle adopt different execution models of computation and communication. The heterogeneous environment may result in negative effect on cooperativeness. Ignoring those issues can result in substantial performance degradation. To tackle this challenge and explore the benefits of parked-vehicle-assisted offloading, we study the task offloading and resource-allocation problem by fully considering the above issues. First, we propose a resource-management scheme to address the privacy issue. Second, we review the execution model of computation and communication in parked-vehicle-assisted computation offloading. Then, we formulate the problem into a mixed-integer nonlinear programming. The problem is hard to tackle due to its non-convex nature, which means that the time complexity of finding global optimal solution is unaffordable. Finally, we decompose the original problem into two sub-problems with lower complexity, and related algorithms are given to deal with the sub-problems. Simulation results demonstrate the effectiveness of the proposed solution.}
}


@article{DBLP:journals/toit/JangPCL22,
	author = {Si Young Jang and
                  Sung Kyu Park and
                  Jin{-}Hee Cho and
                  Dongman Lee},
	title = {{CARES:} Context-Aware Trust Estimation for Realtime Crowdsensing
                  Services in Vehicular Edge Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {92:1--92:24},
	year = {2022},
	url = {https://doi.org/10.1145/3514243},
	doi = {10.1145/3514243},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/JangPCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing number of smart vehicles makes it possible to envision a crowdsensing service where vehicles can share video data of their surroundings for seeking out traffic conditions and car accidents ahead. However, the service may need to deal with situations like malicious vehicles propagating false information to divert other vehicles to arrive at destinations earlier or lead them to dangerous locations. This article proposes a context-aware trust estimation scheme that can allow roadside units in a vehicular edge network to provide real-time crowdsensing services in a reliable manner by selectively using information from trustworthy sources. Our proposed scheme is novel in that its trust estimation does not require any prior knowledge of vehicles on roads but quickly obtains the accurate trust value of each vehicle by leveraging transfer learning. and its Q-learning-based dynamic adjustment scheme autonomously estimates trust levels of oncoming vehicles with the aim of detecting malicious vehicles and accordingly filtering out untrustworthy input from them. Based on an extensive simulation study, we prove that the proposed scheme outperforms existing ones in terms of malicious vehicle detection accuracy.}
}


@article{DBLP:journals/toit/PolachanSP22,
	author = {Kurian Polachan and
                  Chandramani Singh and
                  Tamma V. Prabhakar},
	title = {Decentralized Dynamic Scheduling of {TCPS} Flows and a Simulator for
                  Time-sensitive Networking},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {94:1--94:30},
	year = {2022},
	url = {https://doi.org/10.1145/3498729},
	doi = {10.1145/3498729},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/PolachanSP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybersickness and control-loop instabilities are two main concerns in Tactile Cyber-Physical Systems (TCPS). TCPS applications demand stringent bounds on end-to-end latencies to avoid their occurrences. Traditional best-effort networks cannot guarantee packet latencies in the presence of external traffic. However, emerging deterministic networks such as IEEE 802.1 Time-Sensitive Networking (TSN) can isolate time-critical flows from external traffic using IEEE 802.1Qbv Time-Aware Shaper (TAS) to guarantee bounded end-to-end packet latencies. In this work, we develop eDDSCH-TSN, a decentralized dynamic scheduling protocol to configure non-overlapping gate slots in TAS-enabled TSN switches to support TCPS flows. eDDSCH-TSN supports plug-and-play operation of compatible TCPS terminals with guaranteed minimal end-to-end packet latencies. Compared to the state-of-the-art, eDDSCH-TSN provides three orders lower end-to-end packet latencies for TCPS flows in mid-size networks with 10 hops between source and destination terminals. Further, we also present PYTSN, an open-source discrete-event TSN simulator that we use for evaluating eDDSCH-TSN. In particular, we use PYTSN to show the isolation of TCPS flows from external traffic and plug-and-play operation of TCPS terminals.}
}


@article{DBLP:journals/toit/ShudrenkoPKT22,
	author = {Yevhenii Shudrenko and
                  Daniel Pl{\"{o}}ger and
                  Koojana Kuladinithi and
                  Andreas Timm{-}Giel},
	title = {A Novel Approach to Enhance the End-to-End Quality of Service for
                  Avionic Wireless Sensor Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {95:1--95:29},
	year = {2022},
	url = {https://doi.org/10.1145/3520441},
	doi = {10.1145/3520441},
	timestamp = {Mon, 01 May 2023 13:02:11 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ShudrenkoPKT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Going wireless is one of the key industrial trends, which assists the emergence of new manufacturing and maintenance processes by reducing the complexity and cost of physical equipment. However, the adoption of Wireless Sensor Networks (WSNs) in production environments is limited due to the strict Quality of Service (QoS) requirements of industrial applications. In particular, Wireless Avionics Intra-Communication (WAIC) systems operating in 4.3 GHz band are designed for intra-aircraft use cases with considerable restrictions on the transmission power of sensors, which results in multi-hop topologies, complicating a guaranteed QoS. The Internet Engineering Task Force (IETF) has developed the protocol stack IPv6 over the Time Slotted Channel Hopping (TSCH) mode of IEEE 802.15.4 (6TiSCH) based on the IEEE 802.15.4 Standard for Low-Rate Wireless Networks, which combines the TSCH reliability with ubiquitous IPv6 connectivity and with the robust Routing Protocol for Low-Power and Lossy Networks (RPL). The Scheduling Function (SF) is a core IPv6 over the TSCH mode of IEEE 802.15.4 (6TiSCH) component, but the specification of the SF is an open research topic: numerous scientific articles investigated how QoS for a wide range of applications can be met by developing specialized SFs. However, no full-scale information exchange between the layers of the 6TiSCH stack was considered to optimize the SFs and to improve the network performance. In this work, we propose a novel solution named 6TiSCH-CLX to satisfy demanding QoS requirements using cross-layer communication. It is an extension of the 6TiSCH framework at the network and Medium Access Control (MAC) layers, addressing latency and reliability challenges agnostic of the physical layer. 6TiSCH-CLX is evaluated both analytically and in simulations for several safety-critical avionic intra-communication use cases in WAIC. Preliminary results indicate considerable improvements to latency, while maintaining almost 100% Packet Delivery Ratio (PDR) without retransmissions and they highlight the capability of the cross-layer approach compared to existing solutions.}
}


@article{DBLP:journals/toit/SilvaBLNDPR22,
	author = {Thiago Pereira da Silva and
                  Tha{\'{\i}}s Vasconcelos Batista and
                  Frederico Lopes and
                  Aluizio Rocha Neto and
                  Fl{\'{a}}via Coimbra Delicato and
                  Paulo F. Pires and
                  Atslands Rego da Rocha},
	title = {Fog Computing Platforms for Smart City Applications: {A} Survey},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {96:1--96:32},
	year = {2022},
	url = {https://doi.org/10.1145/3488585},
	doi = {10.1145/3488585},
	timestamp = {Mon, 01 May 2023 13:02:11 +0200},
	biburl = {https://dblp.org/rec/journals/toit/SilvaBLNDPR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging IoT applications with stringent requirements on latency and data processing have posed many challenges to cloud-centric platforms for Smart Cities. Recently, Fog Computing has been advocated as a promising approach to support such new applications and handle the increasing volume of IoT data and devices. The Fog Computing paradigm is characterized by a horizontal system-level architecture where devices close to end-users and IoT devices are used for processing, storage, and networking functions. Fog Computing platforms aim to facilitate the development of applications and systems for Smart Cities by providing services and abstractions designed to integrate data from IoT devices and various information systems deployed in the city. Despite the potential of the Fog Computing paradigm, the literature still lacks a broad, comprehensive overview of what has been investigated on the use of such paradigm in platforms for Smart Cities and open issues to be addressed in future research and development. In this paper, a systematic mapping study was performed and we present a comprehensive understanding of the use of the Fog Computing paradigm in Smart Cities platforms, providing an overview of the current state of research on this topic, and identifying important gaps in the existing approaches and promising research directions.}
}


@article{DBLP:journals/toit/DopmannFLT22,
	author = {Christoph D{\"{o}}pmann and
                  Felix Fiedler and
                  Sergio Lucia and
                  Florian Tschorsch},
	title = {Optimization-Based Predictive Congestion Control for the Tor Network:
                  Opportunities and Challenges},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {97:1--97:30},
	year = {2022},
	url = {https://doi.org/10.1145/3520440},
	doi = {10.1145/3520440},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/DopmannFLT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Based on the principle of onion routing, the Tor network achieves anonymity for its users by relaying user data over a series of intermediate relays. This approach makes congestion control in the network a challenging task. As of this writing, this results in higher latencies due to considerable backlog as well as unfair data rate allocation. In this article, we present a concept study of PredicTor, a novel approach to congestion control that tackles clogged overlay networks. Unlike traditional approaches, it is built upon the idea of distributed model predictive control, a recent advancement from the area of control theory. PredicTor is tailored to minimizing latency in the network and achieving max-min fairness. We contribute a thorough evaluation of its behavior in both toy scenarios to assess the optimizer and complex networks to assess its potential. For this, we conduct large-scale simulation studies and compare PredicTor to existing congestion control mechanisms in Tor. We show that PredicTor is highly effective in reducing latency and realizing fair rate allocations. In addition, we strive to bring the ideas of modern control theory to the networking community, enabling the development of improved, future congestion control. Thus, we demonstrate benefits and issues alike with this novel research direction.}
}


@article{DBLP:journals/toit/WuHMKT22,
	author = {Chao Wu and
                  Shingo Horiuchi and
                  Kenji Murase and
                  Hiroaki Kikushima and
                  Kenichi Tayama},
	title = {An Intent-driven DaaS Management Framework to Enhance User Quality
                  of Experience},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {98:1--98:25},
	year = {2022},
	url = {https://doi.org/10.1145/3488586},
	doi = {10.1145/3488586},
	timestamp = {Mon, 04 Sep 2023 20:40:38 +0200},
	biburl = {https://dblp.org/rec/journals/toit/WuHMKT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Desktop as a Service (DaaS) has become widely used by enterprises. In 2020, the use of DaaS increased dramatically due to the demand to work remotely from home during the COVID-19 pandemic. The DaaS market is expected to continue growing rapidly [1]. The quality of experience (QoE) of a DaaS service has been one of the main factors to enhance DaaS user satisfaction. To ensure user QoE, the amount of cloud computation resources for a DaaS service must be appropriately designed. We propose an Intent-driven DaaS Management (IDM) framework to autonomously determine the cloud-resource-amount configurations for a given DaaS QoE requirement. IDM enables autonomous resource design by abstracting the knowledge about the dependency between DaaS workload, resource configuration, and performance from previous DaaS performance log data. To ensure the IDM framework's applicability to actual DaaS services, we analyzed five main challenges in applying the IDM framework to actual DaaS services: identifying the resource-design objective, quantifying DaaS QoE, addressing low log data availability, designing performance-inference models, and addressing low resource variations in the log data. We addressed these challenges through detailed designing of IDM modules. The effectiveness of the IDM framework was assessed from the aspects of DaaS performance-inference precision, DaaS resource design, and time and human-resource cost reduction.}
}


@article{DBLP:journals/toit/RustPR22,
	author = {Pierre Rust and
                  Gauthier Picard and
                  Fano Ramparany},
	title = {Resilient Distributed Constraint Reasoning to Autonomously Configure
                  and Adapt IoT Environments},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {100:1--100:31},
	year = {2022},
	url = {https://doi.org/10.1145/3507907},
	doi = {10.1145/3507907},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/RustPR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we investigate multi-agent techniques to install autonomy and adaptation in IoT-based smart environment settings, like smart home scenarios. We particularly make use of the smart environment configuration problem (SECP) framework, and map it to a distributed optimization problem (DCOP). This consists in enabling smart objects to coordinate and self-configure as to meet both user-defined requirements and energy efficiency, by operating a distributed constraint reasoning process over a computation graph. As to cope with the dynamics of the environment and infrastructure (e.g., by adding or removing devices), we also specify the k-resilient distribution of graph-structured computations supporting agent decisions, over dynamic and physical multi-agent systems. We implement a self-organizing distributed repair method, based on a distributed constraint optimization algorithm to adapt the distribution as to ensure the system still performs collective decisions and remains resilient to upcoming changes. We provide a full stack of mechanisms to install resilience in operating stateless DCOP solution methods, which results in a robust approach using a fast DCOP algorithm to repair any stateless DCOP solution methods at runtime. We experimentally evaluate the performances of these techniques when operating stateless DCOP algorithms to solve SECP instances.}
}


@article{DBLP:journals/toit/RicciCMMP22,
	author = {Alessandro Ricci and
                  Angelo Croatti and
                  Stefano Mariani and
                  Sara Montagna and
                  Marco Picone},
	title = {Web of Digital Twins},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {101:1--101:30},
	year = {2022},
	url = {https://doi.org/10.1145/3507909},
	doi = {10.1145/3507909},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/RicciCMMP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, digital twins have been pervading different application domains—from manufacturing to healthcare—as an approach for virtualising different kinds of physical entities (things, products, machines). The dominant view developed in the literature so far is about the virtualisation of individual physical assets in a closed-system perspective. In this article, we introduce and explore a broader perspective that we call Web of Digital Twins (WoDT), in which the digital twin paradigm is exploited for the pervasive softwarisation of possibly large-scale interrelated physical realities. A WoDT can be conceived as an open, distributed and dynamic ecosystem of connected digital twins, functioning as an interoperable service-oriented layer for applications running on top, especially smart applications and multiagent systems. The article introduces an abstract model and architecture aimed to capture key aspects of the idea not bound to any specific application domains or implementing technologies and discusses their adoption in engineering real-world systems. To this purpose, two concrete case studies are considered, in the context of healthcare and smart mobility. Finally, the article includes a discussion of a selected set of research directions.}
}


@article{DBLP:journals/toit/RenAR22,
	author = {Haoyu Ren and
                  Darko Anicic and
                  Thomas A. Runkler},
	title = {Towards Semantic Management of On-Device Applications in Industrial
                  IoT},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {102:1--102:30},
	year = {2022},
	url = {https://doi.org/10.1145/3510820},
	doi = {10.1145/3510820},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/RenAR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is revolutionizing the industry. Powered by pervasive embedded devices, the Industrial IoT (IIoT) provides a unique solution for retrieving and analyzing data near the source in real-time. Many emerging techniques, such as Tiny Machine Learning (TinyML) and Complex Event Processing (CEP), are actively being developed to support decision making at the edge, shifting the paradigm from centralized processing to distributed computing. However, distributed computing presents management challenges, as IoT devices are diverse and constrained, and their number is growing exponentially. The situation is even more challenging when various on-device applications (so-called artifacts) are deployed across decentralized IoT networks. Questions to be addressed include how to discover an appropriate function, whether that function can be executed on a certain device, and how to orchestrate a cross-platform service. To tackle these challenges, we propose an approach for the scalable management of on-device applications among distributed IoT devices. By leveraging the W3C Web of Things (WoT), the capabilities of each IoT device, or more precisely, its interaction patterns, can be semantically expressed in a Thing Description (TD). In addition, we introduce semantic modeling of on-device applications to supplement an TD with additional information regarding applications on the device. Specifically, we demonstrate two examples of semantic modeling: neural networks (NN) and CEP rules. The ontologies are evaluated by answering a set of competency questions. By hosting the enriched semantic knowledge of the entire IoT system in a Knowledge Graph (KG), we can discover and interoperate edge devices and artifacts across the decentralized network. This can reduce fragmentation and increase the reusability of IoT components. We demonstrate the feasibility of our concept on an industrial workstation consisting of a conveyor belt and several IoT devices. Finally, the requirements for constructing an IoT semantic management system are discussed.}
}


@article{DBLP:journals/toit/BarakatTGM22,
	author = {Lina Barakat and
                  Phillip Taylor and
                  Nathan Griffiths and
                  Simon Miles},
	title = {A Reputation-based Framework for Honest Provenance Reporting},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {103:1--103:31},
	year = {2022},
	url = {https://doi.org/10.1145/3507908},
	doi = {10.1145/3507908},
	timestamp = {Mon, 01 May 2023 13:02:11 +0200},
	biburl = {https://dblp.org/rec/journals/toit/BarakatTGM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the distributed, heterogenous, and dynamic nature of service-based IoT systems, capturing circumstances data underlying service provisions becomes increasingly important for understanding process flow and tracing how outputs came about, thus enabling clients to make more informed decisions regarding future interaction partners. Whilst service providers are the main source of such circumstances data, they may often be reluctant to release it, e.g., due to the cost and effort required, or to protect their interests. In response, this article introduces a reputation-based framework, guided by intelligent software agents, to support the sharing of truthful circumstances information by providers. In this framework, assessor agents, acting on behalf of clients, rank and select service providers according to reputation, while provider agents, acting on behalf of service providers, learn from the environment and adjust provider’s circumstances provision policies in the direction that increases provider profit with respect to perceived reputation. The novelty of the reputation assessment model adopted by assessor agents lies in affecting provider reputation scores by whether or not they reveal truthful circumstances data underlying their service provisions, in addition to other factors commonly adopted by existing reputation schemes. The effectiveness of the proposed framework is demonstrated through an agent-based simulation including robustness against a number of attacks, with a comparative performance analysis against FIRE as a baseline reputation model.}
}


@article{DBLP:journals/toit/KampikMBKPPSTZ22,
	author = {Timotheus Kampik and
                  Adnane Mansour and
                  Olivier Boissier and
                  Sabrina Kirrane and
                  Julian A. Padget and
                  Terry R. Payne and
                  Munindar P. Singh and
                  Valentina A. M. Tamma and
                  Antoine Zimmermann},
	title = {Governance of Autonomous Agents on the Web: Challenges and Opportunities},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {104:1--104:31},
	year = {2022},
	url = {https://doi.org/10.1145/3507910},
	doi = {10.1145/3507910},
	timestamp = {Sat, 29 Apr 2023 19:27:47 +0200},
	biburl = {https://dblp.org/rec/journals/toit/KampikMBKPPSTZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The study of autonomous agents has a long history in the Multiagent System and the Semantic Web communities, with applications ranging from automating business processes to personal assistants. More recently, the Web of Things (WoT), which is an extension of the Internet of Things (IoT) with metadata expressed in Web standards, and its community provide further motivation for pushing the autonomous agents research agenda forward. Although representing and reasoning about norms, policies, and preferences is crucial to ensuring that autonomous agents act in a manner that satisfies stakeholder requirements, normative concepts, policies, and preferences have yet to be considered as first-class abstractions in Web-based multiagent systems. Towards this end, this article motivates the need for alignment and joint research across the Multiagent Systems, Semantic Web, and WoT communities, introduces a conceptual framework for governance of autonomous agents on the Web, and identifies several research challenges and opportunities.}
}


@article{DBLP:journals/toit/ChavhanGGCKSR22,
	author = {Suresh Chavhan and
                  Deepak Gupta and
                  Sarada Prasad Gochhayat and
                  B. N. Chandana and
                  Ashish Khanna and
                  K. Shankar and
                  Joel J. P. C. Rodrigues},
	title = {Edge Computing AI-IoT Integrated Energy-efficient Intelligent Transportation
                  System for Smart Cities},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {106:1--106:18},
	year = {2022},
	url = {https://doi.org/10.1145/3507906},
	doi = {10.1145/3507906},
	timestamp = {Mon, 05 Feb 2024 20:21:53 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ChavhanGGCKSR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advancement of information and communication technologies (ICTs), there has been high-scale utilization of IoT and adoption of AI in the transportation system to improve the utilization of energy, reduce greenhouse gas (GHG) emissions, increase quality of services, and provide many extensive benefits to the commuters and transportation authorities. In this article, we propose a novel edge-based AI-IoT integrated energy-efficient intelligent transport system for smart cities by using a distributed multi-agent system. An urban area is divided into multiple regions, and each region is sub-divided into a finite number of zones. At each zone an optimal number of RSUs are installed along with the edge computing devices. The MAS deployed at each RSU collects a huge volume of data from the various sensors, devices, and infrastructures. The edge computing device uses the collected raw data from the MAS to process, analyze, and predict. The predicted information will be shared with the neighborhood RSUs, vehicles, and cloud by using MAS with the help of IoT. The predicted information can be used by freight vehicles to maintain smooth and steady movement, which results in reduction in GHG emissions and energy consumption, and finally improves the freight vehicles’ mileage by reducing traffic congestion in the urban areas. We have exhaustively carried out the simulation results and demonstrated the effectiveness of the proposed system.}
}


@article{DBLP:journals/toit/XiaZGLJ22,
	author = {Zhuoqun Xia and
                  Lingxuan Zeng and
                  Ke Gu and
                  Xiong Li and
                  Weijia Jia},
	title = {Conditional Identity Privacy-preserving Authentication Scheme Based
                  on Cooperation of Multiple Fog Servers under Fog Computing-based IoVs},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {107:1--107:28},
	year = {2022},
	url = {https://doi.org/10.1145/3538381},
	doi = {10.1145/3538381},
	timestamp = {Fri, 14 Jul 2023 09:13:59 +0200},
	biburl = {https://dblp.org/rec/journals/toit/XiaZGLJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of vehicles (IoVs) is a variant of vehicular ad hoc network, which provides an efficient communication method for vehicles. However, some traffic messages usually include sensitive identity information, which is easy to bring about the leakage of vehicular identities during data communications. Further, if vehicular identities are fully protected, then it can lead to trusted authority cannot reveal the real identities of malicious vehicles, which incurs more security issues in IoVs. Therefore, in this article, we propose an efficient conditional identity privacy-preserving authentication scheme based on cooperation of multiple fog servers under fog computing-based IoVs, where fog servers are used to verify (authenticate) the legitimacy of vehicles without revealing their real identities. Further, an associated vehicular identity updating mechanism is constructed to solve the problem that some compromised fog servers may leak their stored verification information to pool real vehicular identities. Additionally, a malicious vehicular identity tracing mechanism is proposed to support related fog servers that receive signed false messages can trace the real identities of malicious vehicles. Compared with other related schemes, our scheme further improves its security. Experimental results show our scheme is efficient under fog computing-based IoVs.}
}


@article{DBLP:journals/toit/BoergerLTH22,
	author = {Michell Boerger and
                  Philipp L{\"{a}}mmel and
                  Nikolay Tcholtchev and
                  Manfred Hauswirth},
	title = {Enabling Short-Term Energy Flexibility Markets Through Blockchain},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {108:1--108:25},
	year = {2022},
	url = {https://doi.org/10.1145/3542949},
	doi = {10.1145/3542949},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/BoergerLTH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Climate change has put significant pressure on energy markets. Political decisions such as the plan of the German government to shut down coal power plants by 2038 are shifting electricity production towards renewable and distributed energy resources. The share of these resources will continue to grow significantly in the coming years. This trend changes the ways how energy markets work which mandates fundamental changes in the underlying IT infrastructure. In this paper, we propose a blockchain-based solution which enables an economically viable and grid-serving integration of distributed energy resources into the existing energy system. Our blockchain-based approach targets intraday and day-ahead operating reserve markets, on which energy grid operators and operators of distributed energy resources can trade flexibilities within the schedulable energy production and consumption of their resources. By utilizing these flexibilities as an operating reserve, renewable and climate-friendly technologies can contribute to maintaining the grid stability and security of supply while simultaneously creating economically interesting business models for their operators. We propose to define blockchain-based short-term energy markets by utilizing the concept of general-purpose smart contracts and cryptocurrencies. This enables direct and decentralized trading of energy flexibilities without any intermediary or central instance. We demonstrate the feasibility of our approach through an implementation of a prototype of the proposed markets based on the Ethereum blockchain and provide a detailed evaluation of its efficiency and scalability.}
}


@article{DBLP:journals/toit/ChenYWW22,
	author = {Long Chen and
                  Mianyang Yao and
                  Yalan Wu and
                  Jigang Wu},
	title = {{EECDN:} Energy-efficient Cooperative {DNN} Edge Inference in Wireless
                  Sensor Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {109:1--109:30},
	year = {2022},
	url = {https://doi.org/10.1145/3544969},
	doi = {10.1145/3544969},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ChenYWW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-access edge computing (MEC) is emerging to improve the quality of experience of mobile devices including internet of things sensors by offloading computing intensive tasks to MEC servers. Existing MEC-enabled cooperative computation offloading works focus on the optimization of total energy consumption but fail to exploit multi-relay diversity and min-max fairness of energy consumption on participated sensors. We explore a typical wireless sensor network with multi-source, multi-relay, and one edge server, where relay nodes can provide both cooperative communication and computation services. We divide the energy efficiency optimization problem into two sub-problems: One is to minimize the weighted average total energy consumption per time slot, and the other is to minimize the maximum weighted energy consumption. For the first sub-problem, we propose an optimal algorithm named as optimal weighted average total energy consumption algorithm (OTCA) based on bipartite matching. For the second sub-problem, greedy algorithm for fairness guarantee (GAF) is proposed with an approximation ratio of (1 + ε), where ε is a small positive constant. Extensive numerical results show that OTCA outperforms the baseline algorithms by 26.7–77.4% on the average total weighted energy consumption while GAF outperforms benchmark algorithms by 30.7–84.4%. NS-3 simulation experiments comply with numerical results.}
}


@article{DBLP:journals/toit/SoodRK22,
	author = {Sandeep Kumar Sood and
                  Keshav Singh Rawat and
                  Dheeraj Kumar},
	title = {Emerging Trends of {ICT} in Airborne Disease Prevention},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {22},
	number = {4},
	pages = {110:1--110:18},
	year = {2022},
	url = {https://doi.org/10.1145/3564783},
	doi = {10.1145/3564783},
	timestamp = {Sun, 16 Apr 2023 20:30:33 +0200},
	biburl = {https://dblp.org/rec/journals/toit/SoodRK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information and Communication Technologies (ICT) are becoming indispensable nowadays for the healthcare industry. The utilization of ICT in healthcare services has accelerated even faster after the commencement of the COVID-19 outbreak. This study aims to perform a scientometric analysis of scholarly literature on airborne diseases in the discipline of science and technology. It explores the recent advancement of internet technologies in healthcare to control the prevalence of deadly airborne illnesses by applying analytical approaches. It presents publication trends, citation structure, influential sources, co-citation, and co-occurrence network analysis using the CiteSpace tool. It identifies the important research topics, current research hotspots, most active research areas, and leading technologies in this scientific knowledge domain. It inferred significant results from analyses that will benefit researchers and the academic fraternity across the globe to understand the evolving paths and recent scientific progress of ICT in airborne disease management.}
}
