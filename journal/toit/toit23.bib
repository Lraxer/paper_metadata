@article{DBLP:journals/toit/MishraM023,
	author = {Pankaj Mishra and
                  Ahmed Moustafa and
                  Takayuki Ito},
	title = {Real-time Pricing-based Resource Allocation in Open Market Environments},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {1:1--1:22},
	year = {2023},
	url = {https://doi.org/10.1145/3465237},
	doi = {10.1145/3465237},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MishraM023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open market environments consist of a set of participants (vendors and consumers) that dynamically leave or join the market. As a result, the arising dynamism leads to uncertainties in supply and demand of the resources in these open markets. In specific, in such uncertain markets, vendors attempt to maximise their revenue by dynamically changing their selling prices according to the market demand. In this regard, an optimal resource allocation approach becomes immensely needed to optimise the selling prices based on the supply and demand of the resources in the open market. Therefore, optimal selling prices should maximise the revenue of vendors while protecting the utility of buyers. In this context, we propose a real-time pricing approach for resource allocation in open market environments. The proposed approach introduces a priority-based fairness mechanism to allocate the available resources in a reverse-auction paradigm. Finally, we compare the proposed approach with two state-of-the-art resource allocation approaches. The experimental results show that the proposed approach outperforms the other two resource allocation approaches in its ability to maximise the vendors’ revenue.}
}


@article{DBLP:journals/toit/HaoSRK23,
	author = {Jianwei Hao and
                  Piyush Subedi and
                  Lakshmish Ramaswamy and
                  In Kee Kim},
	title = {Reaching for the Sky: Maximizing Deep Learning Inference Throughput
                  on Edge Devices with {AI} Multi-Tenancy},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {2:1--2:33},
	year = {2023},
	url = {https://doi.org/10.1145/3546192},
	doi = {10.1145/3546192},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/HaoSRK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The wide adoption of smart devices and Internet-of-Things (IoT) sensors has led to massive growth in data generation at the edge of the Internet over the past decade. Intelligent real-time analysis of such a high volume of data, particularly leveraging highly accurate deep learning (DL) models, often requires the data to be processed as close to the data sources (or at the edge of the Internet) to minimize the network and processing latency. The advent of specialized, low-cost, and power-efficient edge devices has greatly facilitated DL inference tasks at the edge. However, limited research has been done to improve the inference throughput (e.g., number of inferences per second) by exploiting various system techniques. This study investigates system techniques, such as batched inferencing, AI multi-tenancy, and cluster of AI accelerators, which can significantly enhance the overall inference throughput on edge devices with DL models for image classification tasks. In particular, AI multi-tenancy enables collective utilization of edge devices’ system resources (CPU, GPU) and AI accelerators (e.g., Edge Tensor Processing Units; EdgeTPUs). The evaluation results show that batched inferencing results in more than 2.4× throughput improvement on devices equipped with high-performance GPUs like Jetson Xavier NX. Moreover, with multi-tenancy approaches, e.g., concurrent model executions (CME) and dynamic model placements (DMP), the DL inference throughput on edge devices (with GPUs) and EdgeTPU can be further improved by up to 3× and 10×, respectively. Furthermore, we present a detailed analysis of hardware and software factors that change the DL inference throughput on edge devices and EdgeTPUs, thereby shedding light on areas that could be further improved to achieve high-performance DL inference at the edge.}
}


@article{DBLP:journals/toit/ZhangWWNP023,
	author = {Rongjunchen Zhang and
                  Tingmin Wu and
                  Sheng Wen and
                  Surya Nepal and
                  C{\'{e}}cile Paris and
                  Yang Xiang},
	title = {{SAM:} Multi-turn Response Selection Based on Semantic Awareness Matching},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {3:1--3:18},
	year = {2023},
	url = {https://doi.org/10.1145/3545570},
	doi = {10.1145/3545570},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ZhangWWNP023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-turn response selection is a key issue in retrieval-based chatbots and has attracted considerable attention in the NLP (Natural Language processing) field. So far, researchers have developed many solutions that can select appropriate responses for multi-turn conversations. However, these works are still suffering from the semantic mismatch problem when responses and context share similar words with different meanings. In this article, we propose a novel chatbot model based on Semantic Awareness Matching, called SAM. SAM can capture both similarity and semantic features in the context by a two-layer matching network. Appropriate responses are selected according to the matching probability made through the aggregation of the two feature types. In the evaluation, we pick 4 widely used datasets and compare SAM’s performance to that of 12 other models. Experiment results show that SAM achieves substantial improvements, with up to 1.5% R10@1 on Ubuntu Dialogue Corpus V2, 0.5% R10@1 on Douban Conversation Corpus, and 1.3% R10@1 on E-commerce Corpus.}
}


@article{DBLP:journals/toit/HirschNGN23,
	author = {Sharon Hirsch and
                  Slava Novgorodov and
                  Ido Guy and
                  Alexander Nus},
	title = {The Tip of the Buyer: Extracting Product Tips from Reviews},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {4:1--4:30},
	year = {2023},
	url = {https://doi.org/10.1145/3547140},
	doi = {10.1145/3547140},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/HirschNGN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Product reviews play a key role in e-commerce platforms. Studies show that many users read product reviews before a purchase and trust them to the same extent as personal recommendations. However, in many cases, the number of reviews per product is large and extracting useful information becomes a challenging task. Several websites have recently added an option to post tips—short, concise, practical, and self-contained pieces of advice about the products. These tips are complementary to the reviews and usually add a new non-trivial insight about the product, beyond its title, attributes, and description. Yet, most if not all major e-commerce platforms lack the notion of a tip as a first-class citizen and customers typically express their advice through other means, such as reviews. In this work, we propose an extractive method for tip generation from product reviews. We focus on five popular e-commerce domains whose reviews tend to contain useful non-trivial tips that are beneficial for potential customers. We formally define the task of tip extraction in e-commerce by providing the list of tip types, tip timing (before and/or after the purchase), and connection to the surrounding context sentences. To extract the tips, we propose a supervised approach and leverage a publicly available dataset, annotated by human editors, containing 14,000 product reviews. To demonstrate the potential of our approach, we compare different tip generation methods and evaluate them both manually and over the labeled set. Our approach demonstrates particularly high performance for popular products in the Baby, Home Improvement, and Sports & Outdoors domains, with precision of over 95% for the top 3 tips per product. In addition, we evaluate the performance of our methods on previously unseen domains. Finally, we discuss the practical usage of our approach in real-world applications. Concretely, we explain how tips generated from user reviews can be integrated in various use cases within e-commerce platforms and benefit both buyers and sellers.}
}


@article{DBLP:journals/toit/Hernandez-Castro23,
	author = {Carlos Javier Hern{\'{a}}ndez{-}Castro and
                  David F. Barrero and
                  Mar{\'{\i}}a Dolores Rodr{\'{\i}}guez{-}Moreno},
	title = {Breaking CaptchaStar Using the {BASECASS} Methodology},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {5:1--5:12},
	year = {2023},
	url = {https://doi.org/10.1145/3546867},
	doi = {10.1145/3546867},
	timestamp = {Sun, 06 Aug 2023 20:51:07 +0200},
	biburl = {https://dblp.org/rec/journals/toit/Hernandez-Castro23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we present fundamental design flaws of CaptchaStar. We also present a full analysis using the BASECASS methodology that employs machine learning techniques. By means of this methodology, we find an attack that bypasses CaptchaStar with almost 100% accuracy.}
}


@article{DBLP:journals/toit/AsprinoDGM23,
	author = {Luigi Asprino and
                  Enrico Daga and
                  Aldo Gangemi and
                  Paul Mulholland},
	title = {Knowledge Graph Construction with a \emph{Fa{\c{c}}ade}: {A} Unified
                  Method to Access Heterogeneous Data Sources on the Web},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {6:1--6:31},
	year = {2023},
	url = {https://doi.org/10.1145/3555312},
	doi = {10.1145/3555312},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/AsprinoDGM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data integration is the dominant use case for RDF Knowledge Graphs. However, Web resources come in formats with weak semantics (for example, CSV and JSON), or formats specific to a given application (for example, BibTex, HTML, and Markdown). To solve this problem, Knowledge Graph Construction (KGC) is gaining momentum due to its focus on supporting users in transforming data into RDF. However, using existing KGC frameworks result in complex data processing pipelines, which mix structural and semantic mappings, whose development and maintenance constitute a significant bottleneck for KG engineers. Such frameworks force users to rely on different tools, sometimes based on heterogeneous languages, for inspecting sources, designing mappings, and generating triples, thus making the process unnecessarily complicated. We argue that it is possible and desirable to equip KG engineers with the ability of interacting with Web data formats by relying on their expertise in RDF and the well-established SPARQL query language\xa0[2]. In this article, we study a unified method for data access to heterogeneous data sources with Facade-X, a meta-model implemented in a new data integration system called SPARQL Anything. We demonstrate that our approach is theoretically sound, since it allows a single meta-model, based on RDF, to represent data from (a) any file format expressible in BNF syntax, as well as (b) any relational database. We compare our method to state-of-the-art approaches in terms of usability (cognitive complexity of the mappings) and general performance. Finally, we discuss the benefits and challenges of this novel approach by engaging with the reference user community.}
}


@article{DBLP:journals/toit/FangXYX23,
	author = {Weiwei Fang and
                  Wenyuan Xu and
                  Chongchong Yu and
                  Neal N. Xiong},
	title = {Joint Architecture Design and Workload Partitioning for {DNN} Inference
                  on Industrial IoT Clusters},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {7:1--7:21},
	year = {2023},
	url = {https://doi.org/10.1145/3551638},
	doi = {10.1145/3551638},
	timestamp = {Fri, 05 Apr 2024 08:54:11 +0200},
	biburl = {https://dblp.org/rec/journals/toit/FangXYX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advent of Deep Neural Networks (DNNs) has empowered numerous computer-vision applications. Due to the high computational intensity of DNN models, as well as the resource constrained nature of Industrial Internet-of-Things (IIoT) devices, it is generally very challenging to deploy and execute DNNs efficiently in the industrial scenarios. Substantial research has focused on model compression or edge-cloud offloading, which trades off accuracy for efficiency or depends on high-quality infrastructure support, respectively. In this article, we present EdgeDI, a framework for executing DNN inference in a partitioned, distributed manner on a cluster of IIoT devices. To improve the inference performance, EdgeDI exploits two key optimization knobs, including: (1) Model compression based on deep architecture design, which transforms the target DNN model into a compact one that reduces the resource requirements for IIoT devices without sacrificing accuracy; (2) Distributed inference based on adaptive workload partitioning, which achieves high parallelism by adaptively balancing the workload distribution among IIoT devices under heterogeneous resource conditions. We have implemented EdgeDI based on PyTorch, and evaluated its performance with the NEU-CLS defect classification task and two typical DNN models (i.e., VGG and ResNet) on a cluster of heterogeneous Raspberry Pi devices. The results indicate that the proposed two optimization approaches significantly outperform the existing solutions in their specific domains. When they are well combined, EdgeDI can provide scalable DNN inference speedups that are very close to or even much higher than the theoretical speedup bounds, while still maintaining the desired accuracy.}
}


@article{DBLP:journals/toit/PaunMN23,
	author = {Iulia Paun and
                  Yashar Moshfeghi and
                  Nikos Ntarmos},
	title = {White Box: On the Prediction of Collaborative Filtering Recommendation
                  Systems' Performance},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {8:1--8:29},
	year = {2023},
	url = {https://doi.org/10.1145/3554979},
	doi = {10.1145/3554979},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/PaunMN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative Filtering (CF) recommendation algorithms are a popular solution to the information overload problem, aiding users in the item selection process. Relevant research has long focused on refining and improving these models to produce better (more effective) recommendations, and has converged on a methodology to predict their effectiveness on target datasets by evaluating them on random samples of the latter. However, predicting the efficiency of the solutions—especially with regard to their time- and resource-hungry training phase, whose requirements dwarf those of the prediction/recommendation phase—has received little to no attention in the literature. This article addresses this gap for a number of representative and highly popular CF models, including algorithms based on matrix factorization, k-nearest neighbors, co-clustering, and slope one schemes. To this end, we first study the computational complexity of the training phase of said CF models and derive time and space complexity equations. Then, using characteristics of the input and the aforementioned equations, we contribute a methodology for predicting the processing time and memory usage of their training phase. Our contributions further include an adaptive sampling strategy, to address the tradeoff between resource usage costs and prediction accuracy, and a framework that quantifies both the efficiency and effectiveness of CF. Finally, a systematic experimental evaluation demonstrates that our method outperforms state-of-the-art regression schemes by a considerable margin, with an overhead that is a small fraction of the overall requirements of CF training.}
}


@article{DBLP:journals/toit/Dai00C23,
	author = {Yuanjun Dai and
                  An Wang and
                  Yang Guo and
                  Songqing Chen},
	title = {Elastically Augmenting the Control-path Throughput in {SDN} to Deal
                  with Internet DDoS Attacks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {9:1--9:25},
	year = {2023},
	url = {https://doi.org/10.1145/3559759},
	doi = {10.1145/3559759},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/Dai00C23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed denial of service (DDoS) attacks have been prevalent on the Internet for decades. Albeit various defenses, they keep growing in size, frequency, and duration. The new network paradigm, Software-defined networking (SDN), is also vulnerable to DDoS attacks. SDN uses logically centralized control, bringing the advantages in maintaining a global network view and simplifying programmability. When attacks happen, the control path between the switches and their associated controllers may become congested due to their limited capacity. However, the data plane visibility of SDN provides new opportunities to defend against DDoS attacks in the cloud computing environment. To this end, we conduct measurements to evaluate the throughput of the software control agents on some of the hardware switches when they are under attacks. Then, we design a new mechanism, called Scotch, to enable the network to scale up its capability and handle the DDoS attack traffic. In our design, the congestion works as an indicator to trigger the mitigation mechanism. Scotch elastically scales up the control plane capacity by using an Open vSwitch-based overlay. Scotch takes advantage of both the high control plane capacity of a large number of vSwitches and the high data plane capacity of commodity physical switches to increase the SDN network scalability and resiliency under abnormal (e.g., DDoS attacks) traffic surges. We have implemented a prototype and experimentally evaluated Scotch. Our experiments in the small-scale lab environment and large-scale GENI testbed demonstrate that Scotch can elastically scale up the control channel bandwidth upon attacks.}
}


@article{DBLP:journals/toit/WuYCL023,
	author = {Feijie Wu and
                  Ho Yin Yuen and
                  Henry C. B. Chan and
                  Victor C. M. Leung and
                  Wei Cai},
	title = {Facilitating Serverless Match-based Online Games with Novel Blockchain
                  Technologies},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {10:1--10:26},
	year = {2023},
	url = {https://doi.org/10.1145/3565884},
	doi = {10.1145/3565884},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/WuYCL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Applying peer-to-peer (P2P) architecture to online video games has already attracted both academic and industrial interests, since it removes the need for expensive server maintenance. However, there are two major issues preventing the use of a P2P architecture, namely how to provide an effective distributed data storage solution, and how to tackle potential cheating behaviors. Inspired by emerging blockchain techniques, we propose a novel consensus model called Proof-of-Play (PoP) to provide a decentralized data storage system that incorporates an anti-cheating mechanism for P2P games, by rewarding players that interact with the game as intended, along with consideration of security measures to address the Nothing-at-stake Problem and the Long-range Attack. To validate our design, we utilize a game-theory model to show that under certain assumptions, the integrity of the PoP system would not be undermined due to the best interests of any user. Then, as a proof-of-concept, we developed a P2P game (Infinity Battle) to demonstrate how a game can be integrated with PoP in practice. Finally, experiments were conducted to study PoP in comparison with Proof-of-Work (PoW) to show its advantages in various aspects.}
}


@article{DBLP:journals/toit/MorgiaMSS23,
	author = {Massimo La Morgia and
                  Alessandro Mei and
                  Francesco Sassi and
                  Julinda Stefa},
	title = {The Doge of Wall Street: Analysis and Detection of Pump and Dump Cryptocurrency
                  Manipulations},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {11:1--11:28},
	year = {2023},
	url = {https://doi.org/10.1145/3561300},
	doi = {10.1145/3561300},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MorgiaMSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptocurrencies are increasingly popular. Even people who are not experts have started to invest in these assets, and nowadays, cryptocurrency exchanges process transactions for over 100 billion US dollars per month. Despite this, many cryptocurrencies have low liquidity and are highly prone to market manipulation. This paper performs an in-depth analysis of two market manipulations organized by communities over the Internet: The pump and dump and the crowd pump. The pump and dump scheme is a fraud as old as the stock market. Now, it has new vitality in the loosely regulated market of cryptocurrencies. Groups of highly coordinated people systematically arrange this scam, usually on Telegram and Discord. We monitored these groups for more than 3 years, detecting around 900 individual events. We report on three case studies related to pump and dump groups. We leverage our unique dataset of the verified pump and dumps to build a machine learning model able to detect a pump and dump in 25 seconds from the moment it starts, achieving the results of 94.5% of F1-score. Then, we move on to the crowd pump, a new phenomenon that hit the news in the first months of 2021, when a Reddit community inflated the price of the GameStop stocks (GME) by over 1,900% on Wall Street, the world’s largest stock exchange. Later, other Reddit communities replicated the operation on the cryptocurrency markets. The targets were DogeCoin (DOGE) and Ripple (XRP). We reconstruct how these operations developed and discuss differences and analogies with the standard pump and dump. We believe this study helps understand a widespread phenomenon affecting cryptocurrency markets. The detection algorithms we develop effectively detect these events in real-time and helps investors stay out of the market when these frauds are in action.}
}


@article{DBLP:journals/toit/ZengL00H23,
	author = {Man Zeng and
                  Dandan Li and
                  Pei Zhang and
                  Kun Xie and
                  Xiaohong Huang},
	title = {Federated Route Leak Detection in Inter-domain Routing with Privacy
                  Guarantee},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {12:1--12:22},
	year = {2023},
	url = {https://doi.org/10.1145/3561051},
	doi = {10.1145/3561051},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ZengL00H23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the inter-domain network, route leaks can disrupt the Internet traffic and cause large outages. The accurate detection of route leaks requires the sharing of AS business relationship information. However, the business relationship information between ASes is confidential. ASes are usually unwilling to reveal this information to the other ASes, especially their competitors. In this paper, we propose a method named FL-RLD to detect route leaks while maintaining the privacy of business relationships between ASes by using a blockchain-based federated learning framework, where ASes can collaboratively train a global detection model without directly disclosing their specific business relationships. To mitigate the lack of ground-truth validation data in route leaks, FL-RLD provides a self-validation scheme by labeling AS triples with local routing policies. We evaluate FL-RLD under a variety of datasets including imbalanced and balanced datasets, and examine different deployment strategies of FL-RLD under different topologies. According to the results, FL-RLD performs better in detecting route leaks than the single AS detection, whether the datasets are balanced or imbalanced. Additionally, the results indicate that selecting ASes with the most peers to first deploy FL-RLD brings more significant benefits in detecting route leaks than selecting ASes with the most providers and customers.}
}


@article{DBLP:journals/toit/AyciSOY23,
	author = {Gonul Ayci and
                  Murat Sensoy and
                  Arzucan {\"{O}}zg{\"{u}}r and
                  Pinar Yolum},
	title = {Uncertainty-Aware Personal Assistant for Making Personalized Privacy
                  Decisions},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {13:1--13:24},
	year = {2023},
	url = {https://doi.org/10.1145/3561820},
	doi = {10.1145/3561820},
	timestamp = {Mon, 28 Aug 2023 21:41:17 +0200},
	biburl = {https://dblp.org/rec/journals/toit/AyciSOY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many software systems, such as online social networks, enable users to share information about themselves. Although the action of sharing is simple, it requires an elaborate thought process on privacy: what to share, with whom to share, and for what purposes. Thinking about these for each piece of content to be shared is tedious. Recent approaches to tackle this problem build personal assistants that can help users by learning what is private over time and recommending privacy labels such as private or public to individual content that a user considers sharing. However, privacy is inherently ambiguous and highly personal. Existing approaches to recommend privacy decisions do not address these aspects of privacy sufficiently. Ideally, a personal assistant should be able to adjust its recommendation based on a given user, considering that user’s privacy understanding. Moreover, the personal assistant should be able to assess when its recommendation would be uncertain and let the user make the decision on her own. Accordingly, this article proposes a personal assistant that uses evidential deep learning to classify content based on its privacy label. An important characteristic of the personal assistant is that it can model its uncertainty in its decisions explicitly, determine that it does not know the answer, and delegate from making a recommendation when its uncertainty is high. By factoring in the user’s own understanding of privacy, such as risk factors or own labels, the personal assistant can personalize its recommendations per user. We evaluate our proposed personal assistant using a well-known dataset. Our results show that our personal assistant can accurately identify uncertain cases, personalize them to its user’s needs, and thus helps users preserve their privacy well.}
}


@article{DBLP:journals/toit/Salve0LMR23,
	author = {Andrea De Salve and
                  Luca Franceschi and
                  Andrea Lisi and
                  Paolo Mori and
                  Laura Ricci},
	title = {{L2DART:} {A} Trust Management System Integrating Blockchain and Off-Chain
                  Computation},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {14:1--14:30},
	year = {2023},
	url = {https://doi.org/10.1145/3561386},
	doi = {10.1145/3561386},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/Salve0LMR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The blockchain technology has been gaining an increasing popularity for the last years, and smart contracts are being used for a growing number of applications in several scenarios. The execution of smart contracts on public blockchains can be invoked by any user with a transaction, although in many scenarios there would be the need for restricting the right of executing smart contracts only to a restricted set of users. To help deal with this issue, this article proposes a system based on a popular access control framework called RT, Role-based Trust Management, to regulate smart contracts execution rights. The proposed system, called Layer 2 DecentrAlized Role-based Trust management (L2DART), implements the RT framework on a public blockchain, and it is designed as a layer-2 technology that involves both on-chain and off-chain functionalities to reduce the blockchain costs while keeping blockchain auditability, i.e., immutability and transparency. The on-chain costs of L2DART have been evaluated on Ethereum and compared with a previous solution implementing on-chain all the functionalities. The results show that the on-chain costs of L2DART are relatively low, making the system deployable in real-world scenarios.}
}


@article{DBLP:journals/toit/ZhangZF0023,
	author = {Wenzhao Zhang and
                  Yuxuan Zhang and
                  Hongchang Fan and
                  Yi Gao and
                  Wei Dong},
	title = {A Low-code Development Framework for Cloud-native Edge Systems},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {15:1--15:22},
	year = {2023},
	url = {https://doi.org/10.1145/3563215},
	doi = {10.1145/3563215},
	timestamp = {Tue, 05 Mar 2024 17:13:40 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ZhangZF0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Customizing and deploying an edge system are time-consuming and complex tasks because of hardware heterogeneity, third-party software compatibility, diverse performance requirements, and so on. In this article, we present TinyEdge, a holistic framework for the low-code development of edge systems. The key idea of TinyEdge is to use a top-down approach for designing edge systems. Developers select and configure TinyEdge modules to specify their interaction logic without dealing with the specific hardware or software. Taking the configuration as input, TinyEdge automatically generates the deployment package and estimates the performance with sufficient profiling. TinyEdge provides a unified development toolkit to specify module dependencies, functionalities, interactions, and configurations. We implement TinyEdge and evaluate its performance using real-world edge systems. Results show that: (1) TinyEdge achieves rapid customization of edge systems, reducing 44.15% of development time and 67.79% of lines of code on average compared with the state-of-the-art edge computing platforms; (2) TinyEdge builds compact modules and optimizes the latent circular dependency detection and message routing efficiency; (3) TinyEdge performance estimation has low absolute errors in various settings.}
}


@article{DBLP:journals/toit/BudhiC23,
	author = {Gregorius Satia Budhi and
                  Raymond Chiong},
	title = {A Multi-type Classifier Ensemble for Detecting Fake Reviews Through
                  Textual-based Feature Extraction},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {16:1--16:24},
	year = {2023},
	url = {https://doi.org/10.1145/3568676},
	doi = {10.1145/3568676},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/BudhiC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The financial impact of online reviews has prompted some fraudulent sellers to generate fake consumer reviews for either promoting their products or discrediting competing products. In this study, we propose a novel ensemble model—the Multi-type Classifier Ensemble (MtCE)—combined with a textual-based featuring method, which is relatively independent of the system, to detect fake online consumer reviews. Unlike other ensemble models that utilise only the same type of single classifier, our proposed ensemble utilises several customised machine learning classifiers (including deep learning models) as its base classifiers. The results of our experiments show that the MtCE can adequately detect fake reviews, and that it outperforms other single and ensemble methods in terms of accuracy and other measurements for all the relevant public datasets used in this study. Moreover, if set correctly, the parameters of MtCE, such as base-classifier types, the total number of base classifiers, bootstrap, and the method to vote on output (e.g., majority or priority), can further improve the performance of the proposed ensemble.}
}


@article{DBLP:journals/toit/ZhangGFDCLWZ23,
	author = {Chong Zhang and
                  Qiang Guo and
                  Luoyi Fu and
                  Jiaxin Ding and
                  Xinde Cao and
                  Fei Long and
                  Xinbing Wang and
                  Chenghu Zhou},
	title = {Finding the Source in Networks: An Approach Based on Structural Entropy},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {17:1--17:25},
	year = {2023},
	url = {https://doi.org/10.1145/3568309},
	doi = {10.1145/3568309},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ZhangGFDCLWZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The popularity of intelligent devices provides straightforward access to the Internet and online social networks. However, the quick and easy data updates from networks also benefit the risk spreading, such as rumor, malware, or computer viruses. To this end, this article studies the problem of source detection, which is to infer the source node out of an aftermath of a cascade, that is, the observed infected graph GN of the network at some time. Prior arts have adopted various statistical quantities such as degree, distance, or infection size to reflect the structural centrality of the source. In this article, we propose a new metric that we call the infected tree entropy (ITE), to utilize richer underlying structural features for source detection. Our idea of ITE is inspired by the conception of structural entropy\xa0[21], which demonstrated that the minimization of average bits to encode the network structures with different partitions is the principle for detecting the natural or true structures in real-world networks. Accordingly, our proposed ITE based estimator for the source tries to minimize the coding of network partitions brought by the infected tree rooted at all the potential sources, thus minimizing the structural deviation between the cascades from the potential sources and the actual infection process included in GN. On polynomially growing geometric trees, with increasing tree heterogeneity, the ITE estimator remarkably yields more reliable detection under only moderate infection sizes, and returns an asymptotically complete detection. In contrast, for regular expanding trees, we still observe guaranteed detection probability of ITE estimator even with an infinite infection size, thanks to the degree regularity property. We also algorithmically realize the ITE based detection that enjoys linear time complexity via a message-passing scheme, and further extend it to general graphs. Extensive experiments on synthetic and real datasets confirm the superiority of ITE to the baselines. For example, ITE returns an accuracy of 85%, ranking the source among the top 10%, far exceeding 55% of the classic algorithm on scale-free networks.}
}


@article{DBLP:journals/toit/MostafaeiA23,
	author = {Habib Mostafaei and
                  Shafi Afridi},
	title = {SDN-enabled Resource Provisioning Framework for Geo-Distributed Streaming
                  Analytics},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {18:1--18:21},
	year = {2023},
	url = {https://doi.org/10.1145/3571158},
	doi = {10.1145/3571158},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MostafaeiA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Geographically distributed (geo-distributed) datacenters for stream data processing typically comprise multiple edges and core datacenters connected through Wide-Area Network (WAN) with a master node responsible for allocating tasks to worker nodes. Since WAN links significantly impact the performance of distributed task execution, the existing task assignment approach is unsuitable for distributed stream data processing with low latency and high throughput demand. In this paper, we propose SAFA, a resource provisioning framework using the Software-Defined Networking (SDN) concept with an SDN controller responsible for monitoring the WAN, selecting an appropriate subset of worker nodes, and assigning tasks to the designated worker nodes. We implemented the data plane of the framework in P4 and the control plane components in Python. We tested the performance of the proposed system on Apache Spark, Apache Storm, and Apache Flink using the Yahoo! streaming benchmark on a set of custom topologies. The results of the experiments validate that the proposed approach is viable for distributed stream processing and confirm that it can improve at least 1.64× the processing time of incoming events of the current stream processing systems.}
}


@article{DBLP:journals/toit/TrevisanSMDM23,
	author = {Martino Trevisan and
                  Francesca Soro and
                  Marco Mellia and
                  Idilio Drago and
                  Ricardo Morla},
	title = {Attacking DoH and {ECH:} Does Server Name Encryption Protect Users'
                  Privacy?},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {19:1--19:22},
	year = {2023},
	url = {https://doi.org/10.1145/3570726},
	doi = {10.1145/3570726},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/TrevisanSMDM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy on the Internet has become a priority, and several efforts have been devoted to limit the leakage of personal information. Domain names, both in the TLS Client Hello and DNS traffic, are among the last pieces of information still visible to an observer in the network. The Encrypted Client Hello extension for TLS, DNS over HTTPS or over QUIC protocols aim to further increase network confidentiality by encrypting the domain names of the visited servers. In this article, we check whether an attacker able to passively observe the traffic of users could still recover the domain name of websites they visit even if names are encrypted. By relying on large-scale network traces, we show that simplistic features and off-the-shelf machine learning models are sufficient to achieve surprisingly high precision and recall when recovering encrypted domain names. We consider three attack scenarios, i.e., recovering the per-flow name, rebuilding the set of visited websites by a user, and checking which users visit a given target website. We next evaluate the efficacy of padding-based mitigation, finding that all three attacks are still effective, despite resources wasted with padding. We conclude that current proposals for domain encryption may produce a false sense of privacy, and more robust techniques should be envisioned to offer protection to end users.}
}


@article{DBLP:journals/toit/SharmaKAVG23,
	author = {Sidharth Sharma and
                  Aniruddha Kushwaha and
                  Mohammad Alizadeh and
                  George Varghese and
                  Ashwin Gumaste},
	title = {Tuneman: Customizing Networks to Guarantee Application Bandwidth and
                  Latency},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {20:1--20:26},
	year = {2023},
	url = {https://doi.org/10.1145/3575657},
	doi = {10.1145/3575657},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/SharmaKAVG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We examine how to provide applications with dedicated bandwidth and guaranteed latency in a programmable mission-critical network. Unlike other SDN approaches such as B4 or SWAN, our system Tuneman optimizes both routes and packet schedules at each node to provide flows with sub-second bandwidth changes. Tuneman uses node-level optimization to compute node schedules in a slotted switch and does dynamic routing using a search procedure with Quality of Service– (QoS) based weights. This allows Tuneman to provide an efficient solution for mission-critical networks that have stringent QoS requirements. We evaluate Tuneman on a telesurgery network using a switch prototype built using FPGAs and also via simulations on India’s Tata Network. For mission-critical networks with multiple QoS levels, Tuneman has comparable or better utilization than SWAN while providing delay bounds guarantees.}
}


@article{DBLP:journals/toit/ZhangTHCX23,
	author = {Bolin Zhang and
                  Zhiying Tu and
                  Shaoshi Hang and
                  Dianhui Chu and
                  Xiaofei Xu},
	title = {Conco-ERNIE: Complex User Intent Detect Model for Smart Healthcare
                  Cognitive Bot},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {21:1--21:24},
	year = {2023},
	url = {https://doi.org/10.1145/3574135},
	doi = {10.1145/3574135},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ZhangTHCX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The outbreak of Covid-19 has exposed the lack of medical resources, especially the lack of medical personnel. This results in time and space restrictions for medical services, and patients cannot obtain health information all the time and everywhere. Based on the medical knowledge graph, healthcare bots alleviate this burden effectively by providing patients with diagnosis guidance, pre-diagnosis, and post-diagnosis consultation services in the way of human-machine dialogue. However, the medical utterance is more complicated in language structure, and there are complex intention phenomena in semantics. It is a challenge to detect the single intent, multi-intent, and implicit intent of a patient’s utterance. To this end, we create a high-quality annotated Chinese Medical query (utterance) dataset, CMedQ (about 16.8k queries in medical domain which includes single, multiple, and implicit intents). It is hard to detect intent on such a complex dataset through traditional text classification models. Thus, we propose a novel detect model Conco-ERNIE, using concept co-occurrence patterns to enhance the representation of pre-trained model ERNIE. These patterns are mined using Apriori algorithm and will be embedded via Node2Vec. Their features will be aggregated with semantic features into Conco-ERNIE by using an attention module, which can catch user explicit intents and also predict user implicit intents. Experiments on CMedQ demonstrates that Conco-ERNIE achieves outstanding performance over baseline. Based on Conco-ERNIE, we develop an intelligent healthcare bot, MedicalBot. To provide knowledge support for MedicalBot, we also build a Chinese medical graph, CMedKG (about 45k entities and 283k relationships).}
}


@article{DBLP:journals/toit/FouquetLR23,
	author = {Romain Fouquet and
                  Pierre Laperdrix and
                  Romain Rouvoy},
	title = {Breaking Bad: Quantifying the Addiction of Web Elements to JavaScript},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {22:1--22:28},
	year = {2023},
	url = {https://doi.org/10.1145/3579846},
	doi = {10.1145/3579846},
	timestamp = {Fri, 14 Jul 2023 15:02:12 +0200},
	biburl = {https://dblp.org/rec/journals/toit/FouquetLR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While JavaScript established itself as a cornerstone of the modern web, it also constitutes a major tracking and security vector, thus raising critical privacy and security concerns. In this context, some browser extensions propose to systematically block scripts reported by crowdsourced trackers lists. However, this solution heavily depends on the quality of these built-in lists, which may be deprecated or incomplete, thus exposing the visitor to unknown trackers. In this article, we explore a different strategy by investigating the benefits of disabling JavaScript in the browser. More specifically, by adopting such a strict policy, we aim to quantify the JavaScript addiction of web elements composing a web page through the observation of web breakages. As there is no standard mechanism for detecting such breakages, we introduce a framework to inspect several page features when blocking JavaScript, that we deploy to analyze 6,384\xa0pages, including landing and internal web pages. We discover that 43% of web pages are not strictly dependent on JavaScript and that more than 67% of pages are likely to be usable as long as the visitor only requires the content from the main section of the page, for which the user most likely reached the page, while reducing the number of tracking requests by\xa085% on average. Finally, we discuss the viability of currently browsing the web without JavaScript and detail multiple incentives for websites to be kept usable without JavaScript.}
}


@article{DBLP:journals/toit/WangL23,
	author = {Yu{-}Jhen Wang and
                  Anthony J. T. Lee},
	title = {Movie Account Recommendation on Instagram},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {1},
	pages = {23:1--23:21},
	year = {2023},
	url = {https://doi.org/10.1145/3579852},
	doi = {10.1145/3579852},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/WangL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing popularity of social networks, many businesses have started implementing their branding or targeted advertising strategies to reach potential customers through social media platforms. It is desirable and essential to help businesses to reach mass audiences and assist users to find favorite business accounts on social media platforms. In the movie industry, movie companies often create business accounts (movie accounts) to promote their movies and capture the attention of followers on Instagram. Instagram contains rich information about movies and user feedback, while IMDb, one of the most popular online databases, contains well-organized information related to movies. The features extracted from the data collected from Instagram and IMDb can complement each other. Therefore, in this study, we propose a framework for recommending movie accounts to users on Instagram by using the data collected from Instagram and IMDb platforms. The experiment results show that our proposed framework outperforms the comparing methods in terms of precision, recall, F1-score, and Normalized Discounted Cumulative Gain (NDCG), and mitigates the effect of cold start problems. The proposed framework can help movie companies or businesses reach potential audiences and implement effective targeted advertising strategies.}
}


@article{DBLP:journals/toit/ChenLL23,
	author = {Mu{-}Yen Chen and
                  Yi{-}Wei Lai and
                  Jiunn{-}Woei Lian},
	title = {Using Deep Learning Models to Detect Fake News about {COVID-19}},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {25:1--25:23},
	year = {2023},
	url = {https://doi.org/10.1145/3533431},
	doi = {10.1145/3533431},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ChenLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of mobile networked devices has made it easier and faster than ever for people to obtain and share information. However, this occasionally results in the propagation of erroneous information, which may be difficult to distinguish from the truth. The widespread diffusion of such information can result in irrational and poor decision making on potentially important issues. In 2020, this coincided with the global outbreak of Coronavirus Disease (COVID-19), a highly contagious and deadly virus. The proliferation of misinformation about COVID-19 on social media has already been identified as an “infodemic” by the World Health Organization (WHO), posing significant challenges for global governments seeking to manage the pandemic. This has driven an urgent need for methods to automatically detect and identify such misinformation. The research uses multiple deep learning model frameworks to detect misinformation in Chinese and English, and compare them based on different text feature selections. The model learns the textual characteristics of each type of true and misinformation for subsequent true/false prediction. The long and short-term memory (LSTM) model, the gated recurrent unit (GRU) model, and the bidirectional long and short-term memory (BiLSTM) model were selected for fake news detection. BiLSTM produces the best detection result, with detection accuracy reaching 94% for short-sentence English texts, and 99% for long-sentence English texts, while the accuracy for Chinese texts was 82%.}
}


@article{DBLP:journals/toit/DongRCL023,
	author = {Yucheng Dong and
                  Qin Ran and
                  Xiangrui Chao and
                  Congcong Li and
                  Shui Yu},
	title = {Personalized Individual Semantics Learning to Support a Large-Scale
                  Linguistic Consensus Process},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {26:1--26:27},
	year = {2023},
	url = {https://doi.org/10.1145/3533432},
	doi = {10.1145/3533432},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/DongRCL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When making decisions, individuals often express their preferences linguistically. The computing with words methodology is a key basis for supporting linguistic decision making, and the words in that methodology may mean different things to different individuals. Thus, in this article, we propose a continual personalized individual semantics learning model to support a consensus-reaching process in large-scale linguistic group decision making. Specifically, we first derive personalized numerical scales from the data of linguistic preference relations. We then perform a clustering ensemble method to divide large-scale group and conduct consensus management. Finally, we present a case study of intelligent route optimization in shared mobility to illustrate the usability of our proposed model. We also demonstrate its effectiveness and feasibility through a comparative analysis.}
}


@article{DBLP:journals/toit/ZhangMTZMS023,
	author = {Yazhou Zhang and
                  Dan Ma and
                  Prayag Tiwari and
                  Chen Zhang and
                  Mehedi Masud and
                  Mohammad Shorfuzzaman and
                  Dawei Song},
	title = {Stance-level Sarcasm Detection with {BERT} and Stance-centered Graph
                  Attention Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {27:1--27:21},
	year = {2023},
	url = {https://doi.org/10.1145/3533430},
	doi = {10.1145/3533430},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ZhangMTZMS023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computational Linguistics (CL) associated with the Internet of Multimedia Things (IoMT)-enabled multimedia computing applications brings several research challenges, such as real-time speech understanding, deep fake video detection, emotion recognition, home automation, and so on. Due to the emergence of machine translation, CL solutions have increased tremendously for different natural language processing (NLP) applications. Nowadays, NLP-enabled IoMT is essential for its success. Sarcasm detection, a recently emerging artificial intelligence (AI) and NLP task, aims at discovering sarcastic, ironic, and metaphoric information implied in texts that are generated in the IoMT. It has drawn much attention from the AI and IoMT research community. The advance of sarcasm detection and NLP techniques will provide a cost-effective, intelligent way to work together with machine devices and high-level human-to-device interactions. However, existing sarcasm detection approaches neglect the hidden stance behind texts, thus insufficient to exploit the full potential of the task. Indeed, the stance, i.e., whether the author of a text is in favor of, against, or neutral toward the proposition or target talked in the text, largely determines the text’s actual sarcasm orientation. To fill the gap, in this research, we propose a new task: stance-level sarcasm detection (SLSD), where the goal is to uncover the author’s latent stance and based on it to identify the sarcasm polarity expressed in the text. We then propose an integral framework, which consists of Bidirectional Encoder Representations from Transformers (BERT) and a novel stance-centered graph attention networks (SCGAT). Specifically, BERT is used to capture the sentence representation, and SCGAT is designed to capture the stance information on specific target. Extensive experiments are conducted on a Chinese sarcasm sentiment dataset we created and the SemEval-2018 Task 3 English sarcasm dataset. The experimental results prove the effectiveness of the SCGAT framework over state-of-the-art baselines by a large margin.}
}


@article{DBLP:journals/toit/LinLCHW23,
	author = {Yi{-}Bing Lin and
                  Yuan{-}Fu Liao and
                  Sin{-}Horng Chen and
                  Shaw{-}Hwa Hwang and
                  Yih{-}Ru Wang},
	title = {VoiceTalk: Multimedia-IoT Applications for Mixing Mandarin, Taiwanese,
                  and English},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {28:1--28:30},
	year = {2023},
	url = {https://doi.org/10.1145/3543854},
	doi = {10.1145/3543854},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/LinLCHW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The voice-based Internet of Multimedia Things (IoMT) is the combination of IoT interfaces and protocols with associated voice-related information, which enables advanced applications based on human-to-device interactions. An example is Automatic Speech Recognition (ASR) for live captioning and voice translation. Three major issues of ASR for IoMT are IoT development cost, speech recognition accuracy, and execution time complexity. For the first issue, most non-voice IoT applications are upgraded with the ASR feature through hard coding, which are error prone. For the second issue, recognition accuracy must be improved for ASR. For the third issue, many multimedia IoT services are real-time applications and, therefore, the ASR delay must be short. This article elaborates on the above issues based on an IoT platform called VoiceTalk. We built the largest Taiwanese spoken corpus to train VoiceTalk ASR (VT-ASR) and show how the VT-ASR mechanism can be transparently integrated with existing IoT applications. We consider two performance measures for VoiceTalk: speech recognition accuracy and VT-ASR delay. For the acoustic tests of PAL-Labs, VT-ASR's accuracy is 96.47%, while Google's accuracy is 94.28%. We are the first to develop an analytic model to investigate the probability that the VT-ASR delay for the first speaker is complete before the second speaker starts talking. From the measurements and analytic modeling, we show that the VT-ASR delay is short enough to result in a very good user experience. Our solution has won several important government and commercial TV contracts in Taiwan. VT-ASR has demonstrated better Taiwanese Mandarin speech recognition accuracy than famous commercial products (including Google and Iflytek) in Formosa Speech Recognition Challenge 2018 (FSR-2018) and was the best among all participating ASR systems for Taiwanese recognition accuracy in FSR-2020.}
}


@article{DBLP:journals/toit/0001TCCCB23,
	author = {Pedro Victor Borges and
                  Chantal Taconet and
                  Sophie Chabridon and
                  Denis Conan and
                  Everton Cavalcante and
                  Tha{\'{\i}}s Batista},
	title = {Taming Internet of Things Application Development with the IoTvar
                  Middleware},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {29:1--29:21},
	year = {2023},
	url = {https://doi.org/10.1145/3586010},
	doi = {10.1145/3586010},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/0001TCCCB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last years, Internet of Things (IoT) platforms have been designed to provide IoT applications with various services such as device discovery, context management, and data filtering. The lack of standardization has led each IoT platform to propose its own abstractions, APIs, and data models. As a consequence, programming interactions between an IoT consuming application and an IoT platform is time-consuming, is error prone, and depends on the developers’ level of knowledge about the IoT platform. To address these issues, this article introduces IoTvar, a middleware library deployed on the IoT consumer application that manages all its interactions with IoT platforms. IoTvar relies on declaring variables automatically mapped to sensors whose values are transparently updated with sensor observations through proxies on the client side. This article presents the IoTvar architecture and shows how it has been integrated into the FIWARE, OM2M, and muDEBS platforms. We also report the results of experiments performed to evaluate IoTvar, showing that it reduces the effort required to declare and manage IoT variables and has no considerable impact on CPU, memory, and energy consumption.}
}


@article{DBLP:journals/toit/Wang00L023,
	author = {Hucheng Wang and
                  Zhi Wang and
                  Lei Zhang and
                  Xiaonan Luo and
                  Xinheng Wang},
	title = {A Highly Stable Fusion Positioning System of Smartphone under NLoS
                  Acoustic Indoor Environment},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {30:1--30:19},
	year = {2023},
	url = {https://doi.org/10.1145/3589765},
	doi = {10.1145/3589765},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/Wang00L023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fusion positioning technology requires stable and effective positioning data, but this is often challenging to achieve in complex Non-Line-of-Sight (NLoS) environments. This paper proposes a fusion positioning method that can achieve stable and no hop points by adjusting parameters and predicting trends, even with a one-sided lack of fusion data. The method combines acoustic signal and Inertial Measurement Unit (IMU) data, exploiting their respective advantages. The fusion is achieved using the Kalman filter and Bayesian parameter estimation is performed for tuning IMU parameters and predicting motion trends. The proposed method overcomes the problem of fusion failure caused by long-term unilateral data loss in traditional fusion positioning. The positioning trajectory and error distribution analysis show that the proposed method performs optimally in severe NLoS experiments.}
}


@article{DBLP:journals/toit/GangwarK23,
	author = {Arvind Kumar Gangwar and
                  Sandeep Kumar},
	title = {Concept Drift in Software Defect Prediction: {A} Method for Detecting
                  and Handling the Drift},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {31:1--31:28},
	year = {2023},
	url = {https://doi.org/10.1145/3589342},
	doi = {10.1145/3589342},
	timestamp = {Mon, 24 Jul 2023 23:34:32 +0200},
	biburl = {https://dblp.org/rec/journals/toit/GangwarK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software Defect Prediction (SDP) is crucial towards software quality assurance in software engineering. SDP analyzes the software metrics data for timely prediction of defect prone software modules. Prediction process is automated by constructing defect prediction classification models using machine learning techniques. These models are trained using metrics data from historical projects of similar types. Based on the learned experience, models are used to predict defect prone modules in currently tested software. These models perform well if the concept is stationary in a dynamic software development environment. But their performance degrades unexpectedly in the presence of change in concept (Concept Drift). Therefore, concept drift (CD) detection is an important activity for improving the overall accuracy of the prediction model. Previous studies on SDP have shown that CD may occur in software defect data and the used defect prediction model may require to be updated to deal with CD. This phenomenon of handling the CD is known as CD adaptation. It is observed that still efforts need to be done in this direction in the SDP domain. In this article, we have proposed a pair of paired learners (PoPL) approach for handling CD in SDP. We combined the drift detection capabilities of two independent paired learners and used the paired learner (PL) with the best performance in recent time for next prediction. We experimented on various publicly available software defect datasets garnered from public data repositories. Experimentation results showed that our proposed approach performed better than the existing similar works and the base PL model based on various performance measures.}
}


@article{DBLP:journals/toit/ChenJ00023,
	author = {Jing Chen and
                  Wenjun Jiang and
                  Jie Wu and
                  Kenli Li and
                  Keqin Li},
	title = {Dynamic Personalized {POI} Sequence Recommendation with Fine-Grained
                  Contexts},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {32:1--32:28},
	year = {2023},
	url = {https://doi.org/10.1145/3583687},
	doi = {10.1145/3583687},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ChenJ00023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Point Of Interest (POI) sequence recommendation is the key task in itinerary and travel route planning. Existing works usually consider the temporal and spatial factors in travel planning. However, the external environment, such as the weather, is usually overlooked. In fact, the weather is an important factor because it can affect a user’s check-in behaviors. Furthermore, most of the existing research is based on a static environment for POI sequence recommendation. While the external environment (e.g., the weather) may change during travel, it is difficult for existing works to adjust the POI sequence in time. What’s more, people usually prefer the attractive routes when traveling. To address these issues, we first conduct comprehensive data analysis on two real-world check-in datasets to study the effects of weather and time, as well as the features of the POI sequence. Based on this, we propose a model of Dynamic Personalized POI Sequence Recommendation with fine-grained contexts (DPSR for short). It extracts user interest and POI popularity with fine-grained contexts and captures the attractiveness of the POI sequence. Next, we apply the Monte Carlo Tree Search model (MCTS for short) to simulate the process of recommending POI sequence in the dynamic environment, i.e., the weather and time change after visiting a POI. What’s more, we consider different speeds to reflect the fact that people may take different transportation to transfer between POIs. To validate the efficacy of DPSR, we conduct extensive experiments. The results show that our model can improve the accuracy of the recommendation significantly. Furthermore, it can better meet user preferences and enhance experiences.}
}


@article{DBLP:journals/toit/MuscarielloPRSV23,
	author = {Luca Muscariello and
                  Michele Papalini and
                  Olivier Roques and
                  Mauro Sardara and
                  Arthur Tran Van},
	title = {Securing Scalable Real-time Multiparty Communications with Hybrid
                  Information-centric Networking},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {33:1--33:20},
	year = {2023},
	url = {https://doi.org/10.1145/3593585},
	doi = {10.1145/3593585},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MuscarielloPRSV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we consider security aspects of online meeting applications based on protocols such as WebRTC that leverage the Information-centric Networking (ICN) architecture to make the system fundamentally more scalable. If the scalability properties provided by ICN have been proved in recent literature, the security challenges and implications for real-time applications have not been reviewed. We show that this class of applications can benefit from strong security and scalability jointly without any major tradeoff and with significant performance improvements over traditional WebRTC systems. To achieve this goal, some modifications to the current ICN architecture must be implemented in the way integrity and authentication are verified. Extensive performance analysis of the architecture based on the open source implementation of Hybrid-ICN proves that real-time applications can greatly benefit from this novel network architecture in terms of strong security and scalable communications.}
}


@article{DBLP:journals/toit/Xu0SD23,
	author = {Yibin Xu and
                  Jianhua Shao and
                  Tijs Slaats and
                  Boris D{\"{u}}dder},
	title = {MWPoW+: {A} Strong Consensus Protocol for Intra-Shard Consensus in
                  Blockchain Sharding},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {34:1--34:27},
	year = {2023},
	url = {https://doi.org/10.1145/3584020},
	doi = {10.1145/3584020},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/Xu0SD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain sharding splits a blockchain into several shards where consensus is reached at the shard level rather than over the entire blockchain. It improves transaction throughput and reduces the computational resources required of individual nodes. But a derivation of trustworthy consensus within a shard becomes an issue as the longest chain based mechanisms used in conventional blockchains can no longer be used. Instead, a vote-based consensus mechanism must be employed. However, existing vote-based Byzantine fault tolerance consensus protocols do not offer sufficient security guarantees for sharded blockchains. First, when used to support consensus where only one block is allowed at a time (binary consensus), these protocols are susceptible to progress-hindering attacks (i.e., unable to reach a consensus). Second, when used to support a stronger type of consensus where multiple concurrent blocks are allowed (strong consensus), their tolerance of adversary nodes is low. This article proposes a new consensus protocol to address all these issues. We call the new protocol MWPoW+, as its basic framework is based on the existing Multiple Winners Proof of Work (MWPoW) protocol but includes new mechanisms to address the issues mentioned previously. MWPoW+ is a vote-based protocol for strong consensus, asynchronous in consensus derivation but synchronous in communication. We prove that it can tolerate up to f < n/2 adversary nodes in a n-node system as if using a binary consensus protocol and does not suffer from progress-hindering attacks.}
}


@article{DBLP:journals/toit/0005LMLX023,
	author = {Li Yang and
                  Xi Li and
                  Zhuoru Ma and
                  Lu Li and
                  Neal N. Xiong and
                  Jianfeng Ma},
	title = {{IRGA:} An Intelligent Implicit Real-time Gait Authentication System
                  in Heterogeneous Complex Scenarios},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {2},
	pages = {35:1--35:29},
	year = {2023},
	url = {https://doi.org/10.1145/3594538},
	doi = {10.1145/3594538},
	timestamp = {Fri, 21 Jul 2023 22:26:50 +0200},
	biburl = {https://dblp.org/rec/journals/toit/0005LMLX023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gait authentication as a technique that can continuously provide identity recognition on mobile devices for security has been investigated by academics in the community for decades. However, most of the existing work achieves insufficient generalization to complex real-world environments due to the complexity of the noisy real-world gait data. To address this limitation, we propose an intelligent Implicit Real-time Gait Authentication (IRGA) system based on Deep Neural Networks (DNNs) for enhancing the adaptability of gait authentication in practice. In the proposed system, the gait data (whether with complex interference signals) will first be processed sequentially by the imperceptible collection module and data preprocessing module for improving data quality. In order to illustrate and verify the suitability of our proposal, we provide analysis of the impact of individual gait changes on data feature distribution. Finally, a fusion neural network composed of a Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) is designed to perform feature extraction and user authentication. We evaluate the proposed IRGA system in heterogeneous complex scenarios and present start-of-the-art comparisons on three datasets. Extensive experiments demonstrate that the IRGA system achieves improved performance simultaneously in several different metrics.}
}


@article{DBLP:journals/toit/LiYW23,
	author = {Ying Li and
                  Yaxin Yu and
                  Xingwei Wang},
	title = {Three-tier Storage Framework Based on TBchain and {IPFS} for Protecting
                  IoT Security and Privacy},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {37:1--37:28},
	year = {2023},
	url = {https://doi.org/10.1145/3549910},
	doi = {10.1145/3549910},
	timestamp = {Sat, 28 Oct 2023 13:59:34 +0200},
	biburl = {https://dblp.org/rec/journals/toit/LiYW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, most of the Internet of things (IoT) infrastructures are highly centralized with single points of failure, which results in serious security and privacy issues of IoT data. Fortunately, blockchain technique can provide a decentralized and secure IoT framework to deal with security issues based on the characteristics of decentralization, non-tampering, openness, transparency, and traceability. However, the blockchain consensus protocol guarantees the safety and reliability of data, but it also brings problems such as scalability limitations and poor storage extensibility, resulting in the inability to directly integrate blockchain and the IoT in existing conditions. In this article, a private three-tier local blockchain, Three-tier architecture Blockchain (TBchain), is proposed to solve the problem by splitting part of the transactions in the public blockchain and locking them in a higher-level blockchain TBchain. Additionally, the private blockchain TBchain is connected to the public blockchain to build a hierarchical blockchain network to provide privacy protection for the IoT data stored on the blockchain. Finally, we implement an IoT framework based on TBchain and the InterPlanetary File System (IPFS) to realize the decentralized IoT, which guarantees the user’s access control right to personal data. Experimental results show that the IoT framework based on TBchain and IPFS realizes the user’s access control right to personal data by verifying in advance to ensure the confidentiality and security of shared data, and improves the security and privacy of IoT data and transactions. Moreover, we prove that the scalability and storage extensibility of the blockchain is positively correlated with the number of data blocks in TBchain.}
}


@article{DBLP:journals/toit/GaiSZCW23,
	author = {Keke Gai and
                  Yufeng She and
                  Liehuang Zhu and
                  Kim{-}Kwang Raymond Choo and
                  Zhiguo Wan},
	title = {A Blockchain-Based Access Control Scheme for Zero Trust Cross-Organizational
                  Data Sharing},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {38:1--38:25},
	year = {2023},
	url = {https://doi.org/10.1145/3511899},
	doi = {10.1145/3511899},
	timestamp = {Fri, 27 Oct 2023 20:40:01 +0200},
	biburl = {https://dblp.org/rec/journals/toit/GaiSZCW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-organization data sharing is becoming increasingly prevalent due to the interconnectivity of systems and the need for collaboration across organizations (e.g., exchange of data in a supply chain involving multiple upstream and downstream vendors). There are, however, data security concerns due to lack of trust between organizations that may be located in jurisdictions with varying security and privacy legislation and culture (also referred to as a zero trust environment). Hence, in such a zero trust setting, one should introduce strengthened, yet efficient, access control mechanisms to facilitate cross-organizational data access and exchange requests. Contemporary access control schemes generally focus on protecting a single objective rather than multiple parties, due to higher security costs. In this article, we propose a blockchain-based access control scheme, designed to facilitate lightweight data sharing among different organizations. Specifically, our approach utilizes the consortium blockchain to establish a trustworthy environment, in which a Role-Based Access Control (RBAC) model is then deployed using our proposed multi-signature protocol and smart contract methods. Evaluation of our proposed approach is performed on the HyperLedger Fabric consortium blockchain platform using both Caliper and BFT-SMaRT benchmarks, and the findings demonstrate the utility of our approach.}
}


@article{DBLP:journals/toit/WazidG23,
	author = {Mohammad Wazid and
                  Prosanta Gope},
	title = {{BACKM-EHA:} {A} Novel Blockchain-enabled Security Solution for IoMT-based
                  E-healthcare Applications},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {39:1--39:28},
	year = {2023},
	url = {https://doi.org/10.1145/3511898},
	doi = {10.1145/3511898},
	timestamp = {Wed, 18 Oct 2023 17:45:15 +0200},
	biburl = {https://dblp.org/rec/journals/toit/WazidG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {E-health is the use of information and communication technology (ICT) for the healthcare-related services. It uses various types of digital technologies and telecommunications, such as computers, sensing devices, Internet, and mobile devices to deliver medical services. Internet of Medical Things (IoMT) is a communication environment optimized for low-power devices (for example, health sensors and actuators) and operation on, in, or around the human body (i.e., a patient). It can be used in various applications that are related to healthcare, such as “body automation,” “healthcare,” “medical monitoring,” “body interaction,” and “medical implants (i.e., pacemaker).” Most of the communications happen in IoMT-based e-healthcare system are wireless in nature. This may cause severe threats to the security of the system. Various information security-related attacks, i.e., replay, man-in-the-middle attack (MiTM), impersonation, privileged insider, unauthorised session key computation, credentials leakage, stolen verifier, malware injection are possible in IoMT-based e-healthcare system. These threats and attacks can create serious problems in the social life of an individual, as this may reveal their confidential healthcare information to other unauthorised parties. Therefore, it is essential to propose an access control and key management scheme to secure the communication of a IoMT-based e-healthcare system. Moreover, the security of such kind of scheme can also be enhanced through the deployment of a blockchain mechanism. Therefore, in this article, we propose a blockchain-enabled access control and key management protocol for IoMT-based e-healthcare system that is named as “BACKM-EHA” in short. The security analysis of proposed BACKM-EHA is also provided through the standard, i.e., “Real-Or-Random model.” The various conducted security analyses prove the security of BACKM-EHA against the different types of potential attacks. The performance of BACKM-EHA is better than the other existing schemes, as it requires less communication cost, computation cost, and provides more “security and functionality features.”}
}


@article{DBLP:journals/toit/MaRYSSSJL23,
	author = {Fuchen Ma and
                  Meng Ren and
                  Fu Ying and
                  Wanting Sun and
                  Houbing Song and
                  Heyuan Shi and
                  Yu Jiang and
                  Huizhong Li},
	title = {V-Gas: Generating High Gas Consumption Inputs to Avoid Out-of-Gas
                  Vulnerability},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {40:1--40:22},
	year = {2023},
	url = {https://doi.org/10.1145/3511900},
	doi = {10.1145/3511900},
	timestamp = {Fri, 27 Oct 2023 20:40:01 +0200},
	biburl = {https://dblp.org/rec/journals/toit/MaRYSSSJL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Out-of-gas errors occur when smart contract programs are provided with inputs that cause excessive gas consumption and which will be easily exploited to perform Denial-of-Service attacks. Various approaches have been proposed to estimate the gas limit of a function in smart contracts to avoid such error. However, underestimation often occurs when the contract is complex In this work, we propose V-Gas, which automatically generates inputs that maximize the gas cost and reduce underestimation. V-Gas is designed based on static analysis and feedback-directed mutational fuzz testing. First, V-Gas builds the gas weighted control flow graph of functions in smart contracts. Then, V-Gas develops gas consumption guided selection and mutation strategies to generate the input that maximize the gas consumption. For evaluation, we implement V-Gas based on js-evm, a widely used Ethereum virtual machine written in Javascript, and conduct experiments on 736 real-world transactions recorded on Ethereum. A total of 44.02% of the transactions would have out-of-gas errors based on the estimation results given by solc, meaning that the recorded real gas consumption for those transactions is larger than the gas limit estimated by solc. In comparison, V-Gas could reduce the underestimation ratio to 13.86%. To evaluate the performance of feedback-directed engine in V-Gas, we implemented other directed fuzzing engines and compared their performance with that of V-Gas. The results showed that V-Gas generates the same or higher gas estimation value on 97.8% of the transactions with less time, usually within 5 minutes. Furthermore, V-Gas has exposed 25 previously unknown out-of-gas vulnerabilities in widely used smart contracts, 6 of which have been assigned unique CVE identifiers in the U.S. National Vulnerability Database.}
}


@article{DBLP:journals/toit/LiDGQWL23,
	author = {Zhenyu Li and
                  Yong Ding and
                  Honghao Gao and
                  Bo Qu and
                  Yujue Wang and
                  Jun Li},
	title = {A Highly Compatible Verification Framework with Minimal Upgrades to
                  Secure an Existing Edge Network},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {41:1--41:23},
	year = {2023},
	url = {https://doi.org/10.1145/3511901},
	doi = {10.1145/3511901},
	timestamp = {Mon, 05 Feb 2024 20:21:53 +0100},
	biburl = {https://dblp.org/rec/journals/toit/LiDGQWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge networks are providing services for an increasing number of companies, and they can be used for communication between edge devices and edge gateways. However, the performance of edge devices varies greatly, and it is not easy to upgrade low-performance edge devices. Therefore, cyber attackers can use the vulnerability of edge devices to implement advanced persistent threat attacks. This article proposes a network verification framework for edge networks that can minimize the upgrades needed to strengthen edge network security. First, the communication parties use the data transmitted by the given edge network. Our method uses our proposed PacketVerifier to attach verification information to the packet after it is sent and to verify and restore the packet before it reaches the receiver. Second, due to the performance requirements of edge networks, we design a new data processing structure, namely, a sliding window double ring, to improve the performance of strict sequential protocols in parallel validation. Finally, experimental simulations show that our parallel processing algorithm has good performance in terms of network bandwidth compared with two existing packet processing algorithms. Furthermore, the proposed packet with verification information is compatible with the existing network topology, which helps PacketVerifier establish trustworthy transmission in a zero-trust environment.}
}


@article{DBLP:journals/toit/WangCXATR23,
	author = {Jin Wang and
                  Jiahao Chen and
                  Neal Xiong and
                  Osama Alfarraj and
                  Amr Tolba and
                  Yongjun Ren},
	title = {{S-BDS:} An Effective Blockchain-based Data Storage Scheme in Zero-Trust
                  IoT},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {42:1--42:23},
	year = {2023},
	url = {https://doi.org/10.1145/3511902},
	doi = {10.1145/3511902},
	timestamp = {Tue, 07 May 2024 20:27:47 +0200},
	biburl = {https://dblp.org/rec/journals/toit/WangCXATR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of the Internet of Things (IoT), a large-scale, heterogeneous, and dynamic distributed network has been formed among IoT devices. There is an extreme need to establish a trust mechanism between devices, and blockchain can provide a zero-trust security framework for IoT. However, the efficiency of the blockchain is far from meeting the application requirements of the IoT, which has become the biggest resistance to the application of the blockchain in the IoT. Therefore, this paper combines sharding to build an effective Blockchain-based IoT data storage scheme (S-BDS). Sharding can solve the problem of blockchain capacity and scalability. While the blockchain provides data immutability and traceability for the IoT, it also brings huge demands for data credibility verification. The communication delay in the IoT system seriously affects the security of the system, while the Merkle proof of traditional blockchain occupies a lot of communication resources. This paper constructs Insertable Vector Commitment (IVC) in the bilinear group and replaces the Merkle tree with IVC to store IoT data in the blockchain. The construct has small-sized proof. It also has the ability to record the number of updates, which can prevent replay-attacks. Experiments show that each block processes 1,000 transactions, the proof size of a single data piece is 30% of the original scheme, and proofs from different shards can be aggregated. IVC can effectively reduce communication congestion and improve the stability and security of the IoT system.}
}


@article{DBLP:journals/toit/AlsirhaniKAMYISA23,
	author = {Amjad Alsirhani and
                  Muhammad Ali Khan and
                  Abdullah Alomari and
                  Sauda Maryam and
                  Aiman Younas and
                  Muddesar Iqbal and
                  Muhammad Hameed Siqqidi and
                  Amjad Ali},
	title = {Securing Low-Power Blockchain-enabled IoT Devices against Energy Depletion
                  Attack},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {43:1--43:17},
	year = {2023},
	url = {https://doi.org/10.1145/3511903},
	doi = {10.1145/3511903},
	timestamp = {Sat, 27 Apr 2024 21:29:23 +0200},
	biburl = {https://dblp.org/rec/journals/toit/AlsirhaniKAMYISA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain-enabled Internet of Things (IoT) envisions a world with rapid development and implementations to change our everyday lives based on smart devices. These devices are attached to the internet that can communicate with each other without human interference. A well-known wireless network in blockchain-enabled IoT frameworks is the Low Power and Lossy Network (LLN) that uses a novel protocol known as Routing protocol for low power and lossy networks (RPL) to provide effective and energy-efficient routing. LLNs that run on RPL are inherently prone to multiple Denial of Service (DoS) attacks due to the low cost, shared medium, and resource-constrained nature of blockchain-enabled IoT devices. A Spam DODAG Information Solicitation (DIS) attack is one of the novel attacks that drains the energy source of legitimate nodes and ends up causing the legitimate nodes to suffer from DoS. To address this problem, a mitigation scheme named DIS Spam Attack Mitigation (DISAM) is proposed. The proposed scheme effectively mitigates the effects of the Spam DIS attack on the network’s performance. The experimental results show that DISAM detects and mitigates the attack quickly and efficiently.}
}


@article{DBLP:journals/toit/WangLWRKLLQ23,
	author = {Fan Wang and
                  Guangshun Li and
                  Yilei Wang and
                  Wajid Rafique and
                  Mohammad Reza Khosravi and
                  Guanfeng Liu and
                  Yuwen Liu and
                  Lianyong Qi},
	title = {Privacy-Aware Traffic Flow Prediction Based on Multi-Party Sensor
                  Data with Zero Trust in Smart City},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {44:1--44:19},
	year = {2023},
	url = {https://doi.org/10.1145/3511904},
	doi = {10.1145/3511904},
	timestamp = {Fri, 27 Oct 2023 20:40:01 +0200},
	biburl = {https://dblp.org/rec/journals/toit/WangLWRKLLQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the continuous increment of city volume and size, a number of traffic-related urban units (e.g., vehicles, roads, buildings, etc.) are emerging rapidly, which plays a heavy burden on the scientific traffic control of smart cities. In this situation, it is becoming a necessity to utilize the sensor data from massive cameras deployed at city crossings for accurate traffic flow prediction. However, the traffic sensor data are often distributed and stored by different organizations or parties with zero trust, which impedes the multi-party sensor data sharing significantly due to privacy concerns. Therefore, it requires challenging efforts to balance the trade-off between data sharing and data privacy to enable cross-organization traffic data fusion and prediction. In light of this challenge, we put forward an accurate LSH (locality-sensitive hashing)-based traffic flow prediction approach with the ability to protect privacy. Finally, through a series of experiments deployed on a real-world traffic dataset, we demonstrate the feasibility of our proposal in terms of prediction accuracy and efficiency while guaranteeing sensor data privacy.}
}


@article{DBLP:journals/toit/GioacchiniVMDBR23,
	author = {Luca Gioacchini and
                  Luca Vassio and
                  Marco Mellia and
                  Idilio Drago and
                  Zied Ben{-}Houidi and
                  Dario Rossi},
	title = {i-DarkVec: Incremental Embeddings for Darknet Traffic Analysis},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {45:1--45:28},
	year = {2023},
	url = {https://doi.org/10.1145/3595378},
	doi = {10.1145/3595378},
	timestamp = {Fri, 27 Oct 2023 20:40:01 +0200},
	biburl = {https://dblp.org/rec/journals/toit/GioacchiniVMDBR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Darknets are probes listening to traffic reaching IP addresses that host no services. Traffic reaching a darknet results from the actions of internet scanners, botnets, and possibly misconfigured hosts. Such peculiar nature of the darknet traffic makes darknets a valuable instrument to discover malicious online activities, e.g., identifying coordinated actions performed by bots or scanners. However, the massive amount of packets and sources that darknets observe makes it hard to extract meaningful insights, calling for scalable tools to automatically identify and group sources that share similar behaviour. We here present i-DarkVec, a methodology to learn meaningful representations of Darknet traffic. i-DarkVec leverages Natural Language Processing techniques (e.g., Word2Vec) to capture the co-occurrence patterns that emerge when scanners or bots launch coordinated actions. As in NLP problems, the embeddings learned with i-DarkVec enable several new machine learning tasks on the darknet traffic, such as identifying clusters of senders engaged in similar activities. We extensively test i-DarkVec and explore its design space in a case study using real darknets. We show that with a proper definition of services, the learned embeddings can be used to (i) solve the classification problem to associate unknown sources’ IP addresses to the correct classes of coordinated actors and (ii) automatically identify clusters of previously unknown sources performing similar attacks and scans, easing the security analyst’s job. i-DarkVec leverages a novel incremental embedding learning approach that is scalable and robust to traffic changes, making it applicable to dynamic and large-scale scenarios.}
}


@article{DBLP:journals/toit/BahutairB23,
	author = {Mohammed Bahutair and
                  Athman Bouguettaya},
	title = {An End-to-end Trust Management Framework for Crowdsourced IoT Services},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {46:1--46:32},
	year = {2023},
	url = {https://doi.org/10.1145/3600232},
	doi = {10.1145/3600232},
	timestamp = {Fri, 27 Oct 2023 20:40:01 +0200},
	biburl = {https://dblp.org/rec/journals/toit/BahutairB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a novel end-to-end trust management framework for crowdsourced Internet of Things (IoT) services. The framework targets three main aspects: trust assessment, trust information credibility and accuracy, and trust information storage. We harness the usage patterns of IoT consumers to offer a trust assessment that adapts to IoT consumers’ uses. Additionally, our framework ascertains the credibility and accuracy of trust-related information before trust assessment. This is achieved by validating the data collected by IoT consumers and providers. In addition, our framework ensures the contextual fairness between IoT services and trust information. Moreover, we propose a blockchain-based trust information storage approach. Our proposed storage solution preserves the integrity and availability of trust information.}
}


@article{DBLP:journals/toit/ChenGS23,
	author = {Keke Chen and
                  Yuechun Gu and
                  Sagar Sharma},
	title = {DisguisedNets: Secure Image Outsourcing for Confidential Model Training
                  in Clouds},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {47:1--47:26},
	year = {2023},
	url = {https://doi.org/10.1145/3609506},
	doi = {10.1145/3609506},
	timestamp = {Fri, 27 Oct 2023 20:40:01 +0200},
	biburl = {https://dblp.org/rec/journals/toit/ChenGS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large training data and expensive model tweaking are standard features of deep learning with images. As a result, data owners often utilize cloud resources to develop large-scale complex models, which also raises privacy concerns. Existing cryptographic solutions for training deep neural networks (DNNs) are too expensive, cannot effectively utilize cloud GPU resources, and also put a significant burden on client-side pre-processing. This article presents an image disguising approach: DisguisedNets, which allows users to securely outsource images to the cloud and enables confidential, efficient GPU-based model training. DisguisedNets uses a novel combination of image blocktization, block-level random permutation, and block-level secure transformations: random multidimensional projection (RMT) or AES pixel-level encryption (AES) to transform training data. Users can use existing DNN training methods and GPU resources without any modification to training models with disguised images. We have analyzed and evaluated the methods under a multi-level threat model and compared them with another similar method—InstaHide. We also show that the image disguising approach, including both DisguisedNets and InstaHide, can effectively protect models from model-targeted attacks.}
}


@article{DBLP:journals/toit/CheginiBM23,
	author = {Hossein Chegini and
                  Fernando Beltran and
                  Aniket Mahanti},
	title = {Designing and Developing a Weed Detection Model for California Thistle},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {3},
	pages = {48:1--48:29},
	year = {2023},
	url = {https://doi.org/10.1145/3544491},
	doi = {10.1145/3544491},
	timestamp = {Fri, 27 Oct 2023 20:40:01 +0200},
	biburl = {https://dblp.org/rec/journals/toit/CheginiBM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With a great percentage of farms in New Zealand as pastures, they are mainly important in contributing to the milk and meat industries. Pasture quality is highly affected by weeds. Weeds grow fast and invade pastures by seed pollination. They consume the nutrients, water, and other minerals, and once they are bitter, cattle do not eat them. Therefore, dairy farmers have to allocate a significant portion of their budget and time to monitor and clean weeds. Unfortunately, most weed management tasks are manual with no consistent technology. Thus, the motivation behind this article was to design an object detection model for weed monitoring and control in pastures. The model was designed and tested on California thistle, a dominant and widespread weed on New Zealand pastures. Our study is one of the major model designs for identifying weeds in an in-pasture environment, one of the most complicated environments for any object detection model. A synthetic methodology was used to create three types of datasets: plant-based, leaf-based, and mixed. The trained model based on the leaf-based dataset is one of the major contributions of our work and has not been conducted by any other weed detection models. After models had been trained, tuning experimentation was undertaken to improve the model’s performance. This involved studying the model’s hyperparameters in various ranges and then recording their values at the optimum points. The improved model showed a 93% mAP accuracy in the detection of training images and over 95% accuracy for testing images. The experimentation showed that the leaf-based model was slightly better than other models. The model can automate highly any weed management system. The use of this model will save farmers time and money and help them reduce the errors of manual work.}
}


@article{DBLP:journals/toit/FuPAGLF23,
	author = {Xiuwen Fu and
                  Pasquale Pace and
                  Gianluca Aloi and
                  Antonio Guerrieri and
                  Wenfeng Li and
                  Giancarlo Fortino},
	title = {Tolerance Analysis of Cyber-Manufacturing Systems to Cascading Failures},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {50:1--50:23},
	year = {2023},
	url = {https://doi.org/10.1145/3579847},
	doi = {10.1145/3579847},
	timestamp = {Sat, 13 Jan 2024 17:36:50 +0100},
	biburl = {https://dblp.org/rec/journals/toit/FuPAGLF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In practical cyber-manufacturing systems (CMS), the node component is the forwarder of information and the provider of services. This dual role makes the whole system have the typical physical-services interaction characteristic, making CMS more vulnerable to cascading failures than general manufacturing systems. In this work, in order to reasonably characterize the cascading process of CMS, we first develop an interdependent network model for CMS from a physical-service networking perspective. On this basis, a realistic cascading failure model for CMS is designed with full consideration of the routing-oriented load distribution characteristics of the physical network and selective load distribution characteristics of the service network. Through extensive experiments, the soundness of the proposed model has been verified and some meaningful findings have been obtained: (1) attacks on the physical network are more likely to trigger cascading failures and may cause more damage; (2) interdependency failures are the main cause of performance degradation in the service network during cascading failures; and (3) isolation failures are the main cause of performance degradation in the physical network during cascading failures. The obtained results can certainly help users to design a more reliable CMS against cascading failures.}
}


@article{DBLP:journals/toit/WuCYLW23,
	author = {Yirui Wu and
                  Hao Cao and
                  Guoqiang Yang and
                  Tong Lu and
                  Shaohua Wan},
	title = {Digital Twin of Intelligent Small Surface Defect Detection with Cyber-manufacturing
                  Systems},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {51:1--51:20},
	year = {2023},
	url = {https://doi.org/10.1145/3571734},
	doi = {10.1145/3571734},
	timestamp = {Sat, 13 Jan 2024 17:36:50 +0100},
	biburl = {https://dblp.org/rec/journals/toit/WuCYLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the remarkable technological development in cyber-physical systems, industry 4.0 has evolved by use of a significant concept named digital twin (DT). However, it is still difficult to construct a relationship between twin simulation and a real scenario considering dynamic variations, especially when dealing with small surface defect detection tasks with high performance and computation resource requirements. In this article, we aim to construct cyber-manufacturing systems to achieve a DT solution for small surface defect detection task. Focusing on DT-based solution, the proposed system consists of an Edge–Cloud architecture and a surface defect detection algorithm. Considering dynamic characteristics and real-time response requirement, Edge–Cloud architecture is built to achieve smart manufacturing by efficiently collecting, processing, analyzing, and storing data produced by factory. A deep learning–based algorithm is then constructed to detect surface defeats based on multi-modal data, i.e., imaging and depth data. Experiments show the proposed algorithm could achieve high accuracy and recall in small defeat detection task, thus constructing DT in cyber-manufacturing.}
}


@article{DBLP:journals/toit/DengXPZZ23,
	author = {Lizhen Deng and
                  Guoxia Xu and
                  Jiaqi Pi and
                  Hu Zhu and
                  Xiaokang Zhou},
	title = {Unpaired Self-supervised Learning for Industrial Cyber-Manufacturing
                  Spectrum Blind Deconvolution},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {52:1--52:18},
	year = {2023},
	url = {https://doi.org/10.1145/3590963},
	doi = {10.1145/3590963},
	timestamp = {Sat, 20 Jan 2024 18:19:55 +0100},
	biburl = {https://dblp.org/rec/journals/toit/DengXPZZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-Manufacturing combines industrial big data with intelligent analysis to find and understand the intangible problems in decision-making, which requires a systematic method to deal with rich signal data. With the development of spectral detection and photoelectric imaging technology, spectral blind deconvolution has achieved remarkable results. However, spectral processing is limited by one-dimensional signal, and there is no available structural information with few training samples. Moreover, in the majority of practical applications, it is entirely feasible to gather unpaired spectrum dataset for training. This training method of unpaired learning is practical and valuable. Therefore, a two-stage deconvolution scheme combining self supervised learning and feature extraction is proposed in this paper, which generates two complementary paired sets through self supervised learning to extract the final deconvolution network. In addition, a new deconvolution network is designed for feature extraction. The spectrum is pre-trained through spectral feature extraction and noise estimation network to improve the training efficiency and meet the assumed noise characteristics. Experimental results show that this method is effective in dealing with different types of synthetic noise.}
}


@article{DBLP:journals/toit/PennekampDFHKGLSW23,
	author = {Jan Pennekamp and
                  Markus Dahlmanns and
                  Frederik Fuhrmann and
                  Timo Heutmann and
                  Alexander Kreppein and
                  Dennis Grunert and
                  Christoph Lange and
                  Robert H. Schmitt and
                  Klaus Wehrle},
	title = {Offering Two-way Privacy for Evolved Purchase Inquiries},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {53:1--53:32},
	year = {2023},
	url = {https://doi.org/10.1145/3599968},
	doi = {10.1145/3599968},
	timestamp = {Sat, 13 Jan 2024 17:36:50 +0100},
	biburl = {https://dblp.org/rec/journals/toit/PennekampDFHKGLSW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic and flexible business relationships are expected to become more important in the future to accommodate specialized change requests or small-batch production. Today, buyers and sellers must disclose sensitive information on products upfront before the actual manufacturing. However, without a trust relation, this situation is precarious for the involved companies as they fear for their competitiveness. Related work overlooks this issue so far: existing approaches protect the information of a single party only, hindering dynamic and on-demand business relationships. To account for the corresponding research gap of inadequately privacy-protected information and to deal with companies without an established trust relation, we pursue the direction of innovative privacy-preserving purchase inquiries that seamlessly integrate into today’s established supplier management and procurement processes. Utilizing well-established building blocks from private computing, such as private set intersection and homomorphic encryption, we propose two designs with slightly different privacy and performance implications to securely realize purchase inquiries over the Internet. In particular, we allow buyers to consider more potential sellers without sharing sensitive information and relieve sellers of the burden of repeatedly preparing elaborate yet discarded offers. We demonstrate our approaches’ scalability using two real-world use cases from the domain of production technology. Overall, we present deployable designs that offer two-way privacy for purchase inquiries and, in turn, fill a gap that currently hinders establishing dynamic and flexible business relationships. In the future, we expect significantly increasing research activity in this overlooked area to address the needs of an evolving production landscape.}
}


@article{DBLP:journals/toit/AhmedLS23,
	author = {Usman Ahmed and
                  Jerry Chun{-}Wei Lin and
                  Gautam Srivastava},
	title = {Exploring the Potential of Cyber Manufacturing System in the Digital
                  Age},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {54:1--54:38},
	year = {2023},
	url = {https://doi.org/10.1145/3596602},
	doi = {10.1145/3596602},
	timestamp = {Sat, 13 Jan 2024 17:36:50 +0100},
	biburl = {https://dblp.org/rec/journals/toit/AhmedLS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-manufacturing Systems (CMS) have been growing in popularity, transitioning from conventional manufacturing to an innovative paradigm that emphasizes innovation, automation, better customer service, and intelligent systems. A new manufacturing model can improve efficiency and productivity, and provide better customer service and response times. In addition, it may revolutionize the way products are produced, from design to completion. Therefore, it is likely that this new manufacturing model will become increasingly popular. By building new technologies on top of existing CMS, these systems will ensure that data exchange and integration between decentralized systems are reliable and secure. Recently published case studies from industry and the literature support this claim; some challenges remain to be overcome. In general, the use of CMS can revolutionize the manufacturing industry. This study comprehensively analyzes these systems and their potential applications and implications. An overview of the field is then given and various aspects of CMS are also explored with more details. A taxonomy of the most common and current approaches to CMS is presented, including networked cyber-manufacturing systems, distributed cyber-manufacturing systems, cloud-based cyber-manufacturing systems, and cyber-physical systems (CPS). Furthermore, our survey identifies several popular open-source software and datasets and discusses how these resources can reduce barriers to CMS research. In addition, we identify several important issues and research opportunities associated with CMS, including better integration between hardware and software, improved security and privacy protocols, communication protocols, and improved data management systems. In summary, this paper presents a comprehensive overview of current technology and valuable insights are provided for the potential impact of CMS on society and industry.}
}


@article{DBLP:journals/toit/SongPCC23,
	author = {Pei{-}Cheng Song and
                  Jeng{-}Shyang Pan and
                  Han{-}Chieh Chao and
                  Shu{-}Chuan Chu},
	title = {Collaborative Hotspot Data Collection with Drones and 5G Edge Computing
                  in Smart City},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {55:1--55:15},
	year = {2023},
	url = {https://doi.org/10.1145/3617373},
	doi = {10.1145/3617373},
	timestamp = {Sat, 13 Jan 2024 17:36:50 +0100},
	biburl = {https://dblp.org/rec/journals/toit/SongPCC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The construction and governance of smart cities require the collaboration of different systems and different regions. How to realize the monitoring of abnormal hot spots through the collaboration of subsystems with limited resources is related to the stability and efficiency of the city. This work constructs a hot data processing framework for drones and 5G edge computing infrastructure, as well as an Ensemble Multi-Objective Cooperative Learning method to process three different types of hot data. The data collection phase combines set operations with the 0-1 multi-knapsack model, and the cooperative learning phase realizes the degree of cooperation control while retaining the ability of independent optimization of the subsystem. Finally, the advantages of the framework are verified by hot data coverage and collaborative processing efficiency, resource use cost, and balance.}
}


@article{DBLP:journals/toit/ZhangGD23,
	author = {Wenzhao Zhang and
                  Yi Gao and
                  Wei Dong},
	title = {Providing Realtime Support for Containerized Edge Services},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {56:1--56:25},
	year = {2023},
	url = {https://doi.org/10.1145/3617123},
	doi = {10.1145/3617123},
	timestamp = {Sat, 13 Jan 2024 17:36:50 +0100},
	biburl = {https://dblp.org/rec/journals/toit/ZhangGD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Containers have emerged as a popular technology for edge computing platforms. Although there are varieties of container orchestration frameworks, e.g., Kubernetes to provide high-reliable services for cloud infrastructure, providing real-time support at the containerized edge systems (CESs) remains a challenge. In this paper, we propose EdgeMan, a holistic edge service management framework for CESs, which consists of (1) a model-assisted event-driven lightweight online scheduling algorithm to provide request-level execution plans; (2) a bottleneck-metric-aware progressive resource allocation mechanism to improve resource efficiency. We then build a testbed that installed three containerized services with different latency sensitivities for concrete evaluation. Additionally, we adopt real-world data traces from Alibaba and Twitter for large-scale emulations. Extensive experiments demonstrate that the deadline miss ratio of time-sensitive services run with EdgeMan\xa0is reduced by 85.9%\xa0on average compared with that of existing methods in both industry and academia.}
}


@article{DBLP:journals/toit/CaruccioCCDPT23,
	author = {Loredana Caruccio and
                  Gaetano Cimino and
                  Stefano Cirillo and
                  Domenico Desiato and
                  Giuseppe Polese and
                  Genoveffa Tortora},
	title = {Malicious Account Identification in Social Network Platforms},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {57:1--57:25},
	year = {2023},
	url = {https://doi.org/10.1145/3625097},
	doi = {10.1145/3625097},
	timestamp = {Sat, 13 Jan 2024 17:36:50 +0100},
	biburl = {https://dblp.org/rec/journals/toit/CaruccioCCDPT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today, people of all ages are increasingly using Web platforms for social interaction. Consequently, many tasks are being transferred over social networks, like advertisements, political communications, and so on, yielding vast volumes of data disseminated over the network. However, this raises several concerns regarding the truthfulness of such data and the accounts generating them. Malicious users often manipulate data to gain profit. For example, malicious users often create fake accounts and fake followers to increase their popularity and attract more sponsors, followers, and so on, potentially producing several negative implications that impact the whole society. To deal with these issues, it is necessary to increase the capability to properly identify fake accounts and followers. By exploiting automatically extracted data correlations characterizing meaningful patterns of malicious accounts, in this article we propose a new feature engineering strategy to augment the social network account dataset with additional features, aiming to enhance the capability of existing machine learning strategies to discriminate fake accounts. Experimental results produced through several machine learning models on account datasets of both the Twitter and the Instagram platforms highlight the effectiveness of the proposed approach toward the automatic discrimination of fake accounts. The choice of Twitter is mainly due to its strict privacy laws, and because its the only social network platform making data of their accounts publicly available.}
}


@article{DBLP:journals/toit/YangMYLC23,
	author = {Fanyi Yang and
                  Huifang Ma and
                  Cairui Yan and
                  Zhixin Li and
                  Liang Chang},
	title = {Polarized Communities Search via Co-guided Random Walk in Attributed
                  Signed Networks},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {58:1--58:22},
	year = {2023},
	url = {https://doi.org/10.1145/3613449},
	doi = {10.1145/3613449},
	timestamp = {Fri, 09 Feb 2024 20:35:59 +0100},
	biburl = {https://dblp.org/rec/journals/toit/YangMYLC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Polarized communities search aims at locating query-dependent communities, in which mostly nodes within each community form intensive positive connections, while mostly nodes across two communities are connected by negative links. Current approaches towards polarized communities search typically model the network topology, while the key factor of node, i.e., the attributes, are largely ignored. Existing studies have shown that community formation is strongly influenced by node attributes and the formation of communities are determined by both network topology and node attributes simultaneously. However, it is nontrivial to incorporate node attributes for polarized communities search. Firstly, it is hard to handle the heterogeneous information from node attributes. Secondly, it is difficult to model the complex relations between network topology and node attributes in identifying polarized communities. To address the above challenges, we propose a novel method Co-guided Random Walk in Attributed signed networks (CoRWA) for polarized communities search by equipping with reasonable attribute setting. For the first challenge, we devise an attribute-based signed network to model the auxiliary relation between nodes and a weight assignment mechanism is designed to measure the reliability of the edges in the signed network. As to the second challenge, a co-guided random walk scheme in two signed networks is designed to explicitly model the relations between topology-based signed network and attribute-based signed network so as to enhance the search result of each other. Finally, we can identify polarized communities by a well-designed Rayleigh quotient in the signed network. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed CoRWA. Further analysis reveals the significance of node attributes for polarized communities search.}
}


@article{DBLP:journals/toit/XiaoFLWZ23,
	author = {Wenhua Xiao and
                  Xudong Fang and
                  Bixin Liu and
                  Ji Wang and
                  Xiaomin Zhu},
	title = {{UNION:} Fault-tolerant Cooperative Computing in Opportunistic Mobile
                  Edge Cloud},
	journal = {{ACM} Trans. Internet Techn.},
	volume = {23},
	number = {4},
	pages = {59:1--59:27},
	year = {2023},
	url = {https://doi.org/10.1145/3617994},
	doi = {10.1145/3617994},
	timestamp = {Sat, 13 Jan 2024 17:36:50 +0100},
	biburl = {https://dblp.org/rec/journals/toit/XiaoFLWZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Opportunistic Mobile Edge Cloud in which opportunistically connected mobile devices run in a cooperative way to augment the capability of a single device has become a timely and essential topic due to its widespread prospect under resource-constrained scenarios (e.g., disaster rescue). Because of the mobility of devices and the uncertainty of environments, it is inevitable that failures occur among the mobile nodes. Being different from existing studies that mainly focus on either data offloading or computing offloading among mobile devices in an ideal environment, we concentrate on how to guarantee the reliability of the task execution with the consideration of both data offloading and computing offloading under opportunistically connected mobile edge cloud. To this end, an optimization of mobile task offloading when considering reliability is formulated. Then, we propose a probabilistic model for task offloading and a reliability model for task execution, which estimates the probability of successful execution for a specific opportunistic path and describes the dynamic reliability of the task execution. Based on these models, a heuristic algorithm UNION (Fault-Tolerant Cooperative Computing) is proposed to solve this NP-hard problem. Theoretical analysis shows that the complexity of UNION is 𝒪(|ℐ|2+|𝒩|) with guaranteeing the reliability of 0.99. Also, extensive experiments on real-world traces validate the superiority of the proposed algorithm UNION over existing typical strategies.}
}
